embedding:
  model_name: intfloat/multilingual-e5-large-instruct
  chunk_size: 170 #85 #null
  max_chunks: 20 #10
  chunk_batch_size: 32
  paper_batch_size: 1000 #256//20
  n_jobs: 40

qdrant:
  docker_timeout: 30.0
  watch_tmp_timeout: 60.0
  max_threads: 5
  port: 6333
  host: localhost

reranking:
  nhead: 4
  num_layers: 2
  dropout: 0.1
  max_len: 128
  temperature: 0.01
  cite_deltaMonths: 0
  topK_near_cite_range: [0, 50]
  years_cite_range: [2024, 2025]
  training_epochs: 10
  test_size: 0.2
  learning_rate: 0.0001
  
ollama:
  model_name: 'gemma3:12b' #'mistral-small:24b' #'deepseek-r1:32b' #'gemma2:27b' #'deepseek-r1:14b' #
  port: 11434
  host: localhost
  docker_timeout: 30.0
  watch_tmp_timeout: 60.0
  max_threads: 5
  expand_instruct: >
            You are a helpful assistant that expand queries sent by users to retrieve relevant scientific articles.\n
            Expand the following search query by rephrasing it in a more descriptive and complete sentence, 
            suitable for retrieving relevant scientific documents. Correct any spelling mistake when necessary.
            Do not return anything else than just the expanded query.\n\n
            Here is the original query:\n
  parse_instruct: > 
            You are a helpful assistant that parse queries and only return the requested fields.\n
            Parse the following search query to extract the cleaned query and any metadata it contains.
            Specifically, identify and separate:\n
            - author last names\n
            - Date to start searching from (formatted as %Y-%m-%d even if there's just a year mentioned)\n
            - Date to stop searching at (formatted as %Y-%m-%d even if there's just a year mentioned)\n
            Then reformulate the query without sections specifying authors names or dates.\n
            Return results as a dictionary with cleaned query and fields:\n
            {\"cleaned_query\" \"author_names\", \"start_date\", \"end_date\"}\n\n
            If you can't find answers for any of these fields just fill it with 'null'.\n
            Here is the original query:\n

search:
  hash_len: 20
  topk_rerank: 10
  ntopk_qdrant: 5
  topk_per_article: 1
  timeout: 15.0
  use_query_cache: false

chat:
  hash_len: 20
  allowed_origins:
    - http://localhost:5173
    - https://goose-beloved-kit.ngrok-free.app #frontend tunnel

  min_history_length: 1000
  summary_length: 100
  inference_service: groq

  instruct_chatSummary: >
            You are a scientific assistant summarizing conversations.\n
            You are given a conversation recent history between a user and an assistant with summaries of older turns.\n
            Your task is to extract and summarize the key topics discussed in the recent history in <SUMMARY_LENGTH> words.\n
            Output format:
            <FIELDS>\n\n
            Output the result as a strictly valid JSON and nothing else.\n
            Here is the conversation history with previous summaries:\n
            <HISTORY>
  instruct_title: > 
            You are a scientific assistant that generates short notebook titles.\n
            Given a user query, produce a short, clear, high-level title.\n
            Output format:
            <FIELDS>\n\n
            Output the result as a strictly valid JSON and nothing else.\n
            Here is the original user's query:\n
            <QUERY>
  instruct_parse: > 
            You are a a scientific query parser that parse queries and only return the requested fields as valid JSON.\n
            Parse the following search query to extract the cleaned query and the metadata it may contain.\n
            Specifically, identify and separate:\n
            <FIELDS>\n\n
            If you can't find answers for a field just fill it with 'null'.\n
            Output the result as a strictly valid JSON and nothing else.\n
            Here is the original query:\n
            <QUERY>
  instruct_expand: >
            You are a scientific assistant helping users structure their research questions into actionable literature queries.\n

             Given the full conversation context and the user request, you must extract a search expansion plan:\n
            - Break it down into 2-5 clear sub-queries that collectively cover its scope.\n
            - Indicate whether the user's questions is acceptable in terms of ethical boundaries.\n
            - Indicate whether the user's question is in the scope of your domain of expertise as a scientific assistant.\n
            - If the user's question is about a specific article mentioned previously in the conversation, returns the corresponding article ID.\n

            Format your output as a JSON object with the following fields:\n
            <FIELDS>\n\n

            Output the result as a strictly valid JSON and nothing else.\n
            Here is the original query:\n
            <QUERY>
  instruct_keyword: >
            You are a research assistant helping classify scientific queries.\n

            For the given query:
            - Identify its broad research field (Computer science, Physics, Biology, or Medicine).
            - List 3 to 5 main research topics it touches.
            - List 3 to 5 specific key concepts or methods that are likely central to answering it.

            Output a JSON object with the following fields:
            <FIELDS>

            Output the result as a strictly valid JSON and nothing else.\n
            Here is the original query:\n
            <QUERY>

  # instruct_expand: >
  #           You are a scientific query planner and expansion agent.\n
  #           Given the full conversation context and the user request, you must extract a search expansion plan.\n
  #           Your output must fill the following fields:\n
  #           <FIELDS>\n\n
  #           If you can't find answers for a field just fill it with 'null'.\n
  #           Output strictly valid JSON.\n
  #           Here is the original query:\n
  #           <QUERY>
  instruct_genplan: >
            You are a generation planner for scientific answering.\n
            You receive:\n
            - The user's query.\n
            - A list of retrieved articles, each with their article ID, title and author's names.\n

             Given the list of retrieved articles provided in the context, your task is to:\n
            1- Break the answer into multiple **sections**
            2- For each section, generate a title and a short description of the scope of this section.\n
            3- Assign relevant paperIds for each section based on their content.\n
            4- At the end, generate an **abstract** that answers the user's query by summarizing the content of all sections\n
              and cites your sources by including where appropriate [<ID>] where ID are the hashed article ID provided for each article.\n
              

            Format your answer as follows:\n
            <FIELDS>\n\n

            Limit to 4-8 sections. All sections must include at least one relevant paperId.\n
            Output the result as a strictly valid JSON and nothing else.\n
            Here below is the user's query:\n
            <QUERY>
  instruct_gensection: >
            You are a scientific writer generating an answer for a scientific section.\n\n

            You are given:\n
            - The section title to answer.\n
            - A short description of the scope of this section.\n

            Given the list of retrieved articles provided in the context, your task is to:\n
            - Generate a clear and factual content grounded in the provided documents and your own knowledge.\n
              that directly dive into the specific scope of the section (no introductory sentence)
            - Cite your sources by including where appropriate [<ID>] where ID are the hashed article ID provided for each article.\n
            - You must NEVER cite anything that is not in the provided article IDs.\n
            - DO NOT generate section titles or headings â€” only the answer body.
            - If no source supports a statement, avoid making it.\n

            Here below are the section title and scope:\n
            - Section Title: <TITLE>\n
            - Section Scope: <CONTENT>
  instruct_quickreply: >
            You are a scientific assistant generating a quick factual response to a user question.\n\n

            You are provided the user's expanded query.\n
            
            Given the list of retrieved articles provided in the context, your task is to:\n
            - Generate a concise, factual answer no longer than 2-3 paragraphs.
            - Only use information found in the provided documents or widely accepted scientific knowledge.
            - Cite your sources by including where appropriate [<ID>] where ID are the hashed article ID provided for each article.\n
            - Avoid fabricating article IDs.
            - If you are unsure, state that more research may be needed.

            Answer directly to the user.
            Here is the user's query:\n
            <CONTENT>\n
  instruct_update: >
            You are a scientific assistant generating a short summary of new articles related to the past user's query.\n\n

            You are provided the user's queries.\n
            
            Given the list of retrieved articles provided in the context, your task is to:\n
            - Generate a concise summary of each article.
            - Only use information found in the provided documents or widely accepted scientific knowledge.
            - Refer to each article using their corresponding hashed article ID provided in the context.\n
            - Avoid fabricating article IDs.
            - For each article mention how it could interest the user given its past queries.

            Answer directly to the user.
            Mention at the end of your response that the article have been automatically added to the user's notebook but can be removed by using the delete button.\n
            Here are the user's past queries:\n
            <CONTENT>\n


  # instruct_parse: > 
  #           You are a helpful assistant that parse queries and only return the requested fields.\n
  #           Parse the following search query to extract the cleaned query and any metadata it contains.
  #           Specifically, identify and separate:\n
  #           - author last names\n
  #           - Date to start searching from (formatted as %Y-%m-%d even if there's just a year mentioned)\n
  #           - Date to stop searching at (formatted as %Y-%m-%d even if there's just a year mentioned)\n
  #           Then reformulate the query without sections specifying authors names or dates.\n
  #           Return results as a dictionary with cleaned query and fields:\n
  #           {\"cleaned_query\" \"author_names\", \"start_date\", \"end_date\"}\n\n
  #           If you can't find answers for any of these fields just fill it with 'null'.\n
  #           Here is the original query:\n
  instruct_init: >
            \nImportant instructions:\n
            * **If you can answer the user's question accurately based on your knowledge and previous messages in the conversation**:\n
              answer it direclty and cite your source by including (<ARTICLE_ID>) where ARTICLE_ID is the hashed id of an article already cited in the previous context of the conversation\n
              DO NOT include external references. DO NOT make up references\n
            * **If to answer you need additional articles relevant to the user's question**:\n
              Step 1: Expand the user's questions by rephrasing it in a more descriptive and complete sentence, \n
              suitable for retrieving relevant scientific documents. Make complete sentences not just key words. \n
              Step 2: At the end, return the question defined at step 1, as: \n
              '\n\nSEARCHING: {question} \n\n'.
  instruct_refine: >
            * Provide an accurate answer to the user's question based on the provided articles and on your knowledge.\n
            * Structure your response in multiple paragraph describing one element of the response.
              Cite your sources by including where appropriate (<ARTICLE_ID>) where ARTICLE_ID are the hashed ids provided in the context\n
              for each article.\n

download:
  min_citations_per_year: 1
  fields_of_study:
    - Computer Science
    - Biology
  fields_to_return:
    - title
    - citationCount
    - abstract
    - venue
    - authors
    - publicationDate
    - fieldsOfStudy
    - influentialCitationCount
    - openAccessPdf
    - references

pdf:
  n_jobs_download: 20
  n_jobs_extract: 40
  timeout_per_article: 15
  run_headless: True
  max_pages_start: 20
  max_pages_end: null
  extract_ref: False
  timeout_loadpage: 15
  timeout_startdw: 15
  save_pdfs_to: null
  keep_pdfs: false

load:
  n_jobs: 20