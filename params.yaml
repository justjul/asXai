embedding:
  model_name: intfloat/multilingual-e5-large-instruct
  chunk_size: 170 #85 #null
  max_chunks: 20 #10
  chunk_batch_size: 32
  paper_batch_size: 1000 #256//20
  n_jobs: 40

qdrant:
  docker_timeout: 30.0
  watch_tmp_timeout: 60.0
  max_threads: 5
  port: 6333
  host: localhost

reranking:
  nhead: 4
  num_layers: 2
  dropout: 0.1
  max_len: 128
  temperature: 0.01
  cite_deltaMonths: 0
  topK_near_cite_range: [0, 50]
  years_cite_range: [2024, 2025]
  training_epochs: 10
  test_size: 0.2
  learning_rate: 0.0001
  
ollama:
  model_name: 'gemma3:12b' #'mistral-small:24b' #'deepseek-r1:32b' #'gemma2:27b' #'deepseek-r1:14b' #
  port: 11434
  host: localhost
  docker_timeout: 30.0
  watch_tmp_timeout: 60.0
  max_threads: 5
  expand_instruct: >
            You are a helpful assistant that expand queries sent by users to retrieve relevant scientific articles.\n
            Expand the following search query by rephrasing it in a more descriptive and complete sentence, 
            suitable for retrieving relevant scientific documents. Correct any spelling mistake when necessary.
            Do not return anything else than just the expanded query.\n\n
            Here is the original query:\n
  parse_instruct: > 
            You are a helpful assistant that parse queries and only return the requested fields.\n
            Parse the following search query to extract the cleaned query and any metadata it contains.
            Specifically, identify and separate:\n
            - author last names\n
            - Date to start searching from (formatted as %Y-%m-%d even if there's just a year mentioned)\n
            - Date to stop searching at (formatted as %Y-%m-%d even if there's just a year mentioned)\n
            Then reformulate the query without sections specifying authors names or dates.\n
            Return results as a dictionary with cleaned query and fields:\n
            {\"cleaned_query\" \"author_names\", \"start_date\", \"end_date\"}\n\n
            If you can't find answers for any of these fields just fill it with 'null'.\n
            Here is the original query:\n

search:
  hash_len: 20
  topk_rerank: 10
  ntopk_qdrant: 5
  topk_per_article: 1
  timeout: 15.0
  use_query_cache: false

chat:
  hash_len: 20
  allowed_origins:
    - http://localhost:5173
    - https://goose-beloved-kit.ngrok-free.app #frontend tunnel

  min_history_length: 1000
  summary_length: 100

  instruct_chatSummary: >
            You are a scientific assistant summarizing conversations.\n
            You are given a conversation recent history between a user and an assistant with summaries of older turns.\n
            Your task is to extract and summarize the key topics discussed in the recent history in <SUMMARY_LENGTH> words.\n
            Output format:
            <FIELDS>\n\n
            Output strictly valid JSON.\n
            Here is the conversation history with previous summaries:\n
            <HISTORY>
  instruct_title: > 
            You are a scientific assistant that generates short notebook titles.\n
            Given a user query, produce a short, clear, high-level title.\n
            Output format:
            <FIELDS>\n\n
            Output strictly valid JSON.\n
            Here is the original user's query:\n
            <QUERY>
  instruct_parse: > 
            You are a a scientific query parser that parse queries and only return the requested fields as valid JSON.\n
            Parse the following search query to extract the cleaned query and the metadata it may contain.\n
            Specifically, identify and separate:\n
            <FIELDS>\n\n
            If you can't find answers for a field just fill it with 'null'.\n
            Output strictly valid JSON.\n
            Here is the original query:\n
            <QUERY>
  instruct_expand: >
            You are a scientific query planner and expansion agent.\n
            Given the full conversation context and the user request, you must extract a search expansion plan.\n
            Your output must fill the following fields:\n
            <FIELDS>\n\n
            If you can't find answers for a field just fill it with 'null'.\n
            Output strictly valid JSON.\n
            Here is the original query:\n
            <QUERY>
  instruct_genplan: >
            You are a generation planner for scientific answering.\n
            You receive:\n
            - The user's query.\n
            - A list of articles retrieved, each with their article ID, title and author's names.\n

            Your task is to:\n
              1- Break the answer into multiple sections
              2- The first section should be an intro section
              3- The last section should be a TLDR section.\n
              4- For each section, generate a short description of the scope of this section.\n
              5- Assign relevant paperIds for each section based on their content.\n

            Output format:\n
            <FIELDS>\n\n

            Limit to 4-8 sections. Each section must include at least one relevant paperId.\n
            Output strictly valid JSON.\n
            Here below is the list of articles with the query at the end:\n
            <QUERY>
  instruct_gensection: >
            You are a scientific writer generating an answer for a scientific section.\n\n

            You are given:\n
            - The section title to answer.\n
            - A short description of the scope of this section.\n

            Given the list of retrieved articles provided in the context, your task is to:\n
            - Generate a clear and factual content for this section grounded in the provided documents and your own knowledge.\n
            - Cite your sources by including where appropriate [<ID>] where ID are the hashed article ID provided for each article.\n
            - You must NEVER cite anything that is not in the provided article IDs.\n
            - DO NOT generate section titles or headings â€” only the answer body.
            - If no source supports a statement, avoid making it.\n
            - If the title does not contain Introduction, DO NOT make any introductory sentence but dive right away into the specific scope of the section.\n

            - Section Title: <TITLE>\n
            - Content Description: <CONTENT>

            """

            

  # instruct_parse: > 
  #           You are a helpful assistant that parse queries and only return the requested fields.\n
  #           Parse the following search query to extract the cleaned query and any metadata it contains.
  #           Specifically, identify and separate:\n
  #           - author last names\n
  #           - Date to start searching from (formatted as %Y-%m-%d even if there's just a year mentioned)\n
  #           - Date to stop searching at (formatted as %Y-%m-%d even if there's just a year mentioned)\n
  #           Then reformulate the query without sections specifying authors names or dates.\n
  #           Return results as a dictionary with cleaned query and fields:\n
  #           {\"cleaned_query\" \"author_names\", \"start_date\", \"end_date\"}\n\n
  #           If you can't find answers for any of these fields just fill it with 'null'.\n
  #           Here is the original query:\n
  instruct_init: >
            \nImportant instructions:\n
            * **If you can answer the user's question accurately based on your knowledge and previous messages in the conversation**:\n
              answer it direclty and cite your source by including (<ARTICLE_ID>) where ARTICLE_ID is the hashed id of an article already cited in the previous context of the conversation\n
              DO NOT include external references. DO NOT make up references\n
            * **If to answer you need additional articles relevant to the user's question**:\n
              Step 1: Expand the user's questions by rephrasing it in a more descriptive and complete sentence, \n
              suitable for retrieving relevant scientific documents. Make complete sentences not just key words. \n
              Step 2: At the end, return the question defined at step 1, as: \n
              '\n\nSEARCHING: {question} \n\n'.
  instruct_refine: >
            * Provide an accurate answer to the user's question based on the provided articles and on your knowledge.\n
            * Structure your response in multiple paragraph describing one element of the response.
              Cite your sources by including where appropriate (<ARTICLE_ID>) where ARTICLE_ID are the hashed ids provided in the context\n
              for each article.\n

download:
  min_citations_per_year: 1
  fields_of_study:
    - Computer Science
    - Biology
  fields_to_return:
    - title
    - citationCount
    - abstract
    - venue
    - authors
    - publicationDate
    - fieldsOfStudy
    - influentialCitationCount
    - openAccessPdf
    - references

pdf:
  n_jobs_download: 20
  n_jobs_extract: 40
  timeout_per_article: 15
  run_headless: True
  max_pages_start: 20
  max_pages_end: null
  extract_ref: False
  timeout_loadpage: 15
  timeout_startdw: 15
  save_pdfs_to: null
  keep_pdfs: false

load:
  n_jobs: 20