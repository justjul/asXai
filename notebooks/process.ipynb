{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from asxai.dataset import update, process, update_payloads\n",
    "from asxai.dataIO import load_data\n",
    "\n",
    "from asxai.services.database import update_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_database(years=[2025], mode='push')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-04-23 10:24:38,048 - dataset.download - INFO - updated arXiv links for year 2025\n"
     ]
    }
   ],
   "source": [
    "from asxai.dataset import arXlinks_update\n",
    "arXlinks_update(years=[2025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-04-13 17:17:54,583 - vectorDB.qdrant - INFO - No Qdrant container running. Starting a new one now...\n",
      "\n",
      "2025-04-13 17:18:44,608 - dataset.extract_embed_and_push - INFO - Updating payloads for year 2025\n",
      "Updating payloads: 100%|██████████| 5/5 [01:00<00:00, 12.11s/it]\n",
      "\n",
      "2025-04-13 17:19:48,588 - vectorDB.qdrant - INFO - Will try to stop Qdrant container...\n",
      "\n",
      "2025-04-13 17:19:50,741 - vectorDB.qdrant - INFO - Qdrant container stopped and removed...\n"
     ]
    }
   ],
   "source": [
    "update_payloads(years=[2025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process(years=[2025], n_jobs=[20, 70], filters=None, download_extract=True, embed_push=True,\n",
    "        timeout_per_article=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-04-24 09:48:32,182 - dataset.download - INFO - will now load papers for [2025] \n",
      "fields of study: Computer Science,Biology\n",
      "returning fields: title,citationCount,abstract,venue,authors,publicationDate,fieldsOfStudy\n",
      "\n",
      "2025-04-24 09:48:32,639 - dataset.download - INFO - Failed to download batch. Will try again...\n",
      "2025 (4685 papers):  40%|████      | 2/5 [01:02<01:33, 31.05s/it, batch start=1001, token=PCOKWVSKJJGM4TWNJNI3EUSQJIWVNUSRKBFEYK2JFUBHFI4VZSJAZDASBWJVFDKTBXGEYDKMJUGIYDISSOJJHDJNJUJZHTMNCKJ42UQMKPJQZTKTSVRGWAPUIUKKG, status=990 new articles]\n",
      "2025-04-24 09:49:40,556 - dataset.download - INFO - Failed to download batch. Will try again...\n",
      "2025 (4685 papers):  80%|████████  | 4/5 [02:48<00:47, 47.23s/it, batch start=3001, token=PCOKWVSKJJGM4TWNJNI3EUSQJIWVNUSRKBFEYK2JFUBHFI4VKIJM2TMMSPGQZUYMSJJUZE4NZXGREDISSPJVELEMZSJA2TOMJQJQ3DANRUWSYLCSSRRGWAP55MKFW, status=990 new articles]\n",
      "2025-04-24 09:51:26,533 - dataset.download - INFO - Failed to download batch. Will try again...\n",
      "2025 (4685 papers):  80%|████████  | 4/5 [03:15<00:48, 48.87s/it, batch start=4001, token=None, status=679 new articles]                                                                                                                         \n",
      "\n",
      "2025-04-24 09:51:53,346 - dataset.download - INFO - Total articles for 2025: 4635\n",
      "\n",
      "2025-04-24 09:52:31,568 - dataset.download - INFO - updated arXiv links for year 2025\n"
     ]
    }
   ],
   "source": [
    "update(years=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citationCount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fieldsOfStudy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publicationDate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authorId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authorName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publicationYear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "influentialCitationCount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "openAccessPdf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "referenceIds",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "referenceTitles",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6727f8f6-ec8b-45f4-ba88-b51371efaeaf",
       "rows": [
        [
         "0",
         "000160a2fe73e426cad54f5ba7d1e45703a77b98",
         "IEEE Transactions on Network and Service Management",
         "0",
         "",
         "None",
         "2152052057,2268674717",
         "Panagiotis I. Nikolaidis,John S. Baras",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.18254v1.pdf",
         "",
         ""
        ],
        [
         "1",
         "0004c478be53ae7cc93461846992842c73778e7e",
         "ACM-SIAM Symposium on Discrete Algorithms",
         "0",
         "Computer Science",
         "None",
         "2266750381,1721077",
         "Louis Golowich,V. Guruswami",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.08653v1.pdf",
         "",
         ""
        ],
        [
         "2",
         "000a3e6667afb4ca8476ce15555b05244c3b458a",
         "Scientific Reports",
         "0",
         "Medicine",
         "2025-01-15",
         "2064292642,2340550389,2109040952",
         "Fenghui Lian,Yingjie Sun,Meiyu Li",
         "2025",
         "s2",
         "0.0",
         "https://www.nature.com/articles/s41598-025-86087-8.pdf",
         "a7d548167ae65df1b46782fe4055babbe968aaba;8d1e042add48525b4538d4630158b5cac0364797;b618d43e7c0ca2606b0e31fe9ca0b67e0bd026d7;eb1769438fdcac2564d250eb0726029471cda7da;27cebb08aca785444166209593fc0ec740469b1b;a8705cfb2d080592bcb55feff48b5883063cbbe7;cede0ad429de07437698421f453b0c161c9f4b0b;49ca9597280aa43d65df291d7991b25059cf8a3c;2a4595d4156aa43d9980f7eb079d81cc9b05157c;0bffe8c90fda09f7181a97e1b1b705aab483755b;01035661ccdb5388a3c040df42d5309f71101316;65147d0652741e886243549123dab142699e07eb;e0067a9c3f30aab46d9e6f8844dc36e83c85869f;3d44a1a97b6c768ae3080adf717326167457b0ad;569977bdb3f31d4b7c78ab3834fd34b370330e4e;59249dcd2e67bab1ab68e771092138392479d7ea;729b60c364f8ff04352681204260616d3861dd4f;9e2d1a10e5732c1d9efca5ec72193a3252869b02;ee13f51bd226aadac440b68c2825a907275c217c;3c1156945fb82e59d85f88fe3d0de37a22c3aece;5dd2e5b21d7d72696920069225e0a252fee402e3;ca29aaab1ecdd80120b80a405ecec530ec4d63a8;6364fdaa0a0eccd823a779fcdd489173f938e91a;62a9e7308622a4a42e850ed97dc231b774027a11;251c39c1b9372f3055cd53d0001fc122bfb2e418;75352a06f8f39701d59c3a3a78e5cce6dd469ea9;3964ba947347eb59c19d4b42d7a5623e357a81d5;c68796f833a7151f0a63d1d1608dc902b4fdc9b6",
         "Pancreas segmentation based on an adversarial model under two-tier constraints;Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images;Globally Guided Progressive Fusion Network for 3D Pancreas Segmentation;Fully Automatic Liver Attenuation Estimation Combing CNN Segmentation and Morphological Operations;Automatic liver tumor segmentation in CT with fully convolutional neural networks and object-based postprocessing;A Novel Bayesian Model Incorporating Deep Neural Network and Statistical Shape Model for Pancreas Segmentation;Fully automated organ segmentation in male pelvic CT images;Interleaved 3D-CNNs for joint segmentation of small-volume structures in head and neck CT images.;Automatic Organ Segmentation for CT Scans Based on Super-Pixel and Convolutional Neural Networks;Recurrent Saliency Transformation Network: Incorporating Multi-stage Visual Cues for Small Organ Segmentation;3D U-net with Multi-level Deep Supervision: Fully Automatic Segmentation of Proximal Femur in 3D MR Images;Improving Deep Pancreas Segmentation in CT and MRI Images via Recurrent Neural Contextual Learning and Direct Loss Function;Automatic Brain Tumor Detection and Segmentation Using U-Net Based Fully Convolutional Networks;Spatial aggregation of holistically‐nested convolutional neural networks for automated pancreas localization and segmentation☆;A Fixed-Point Model for Pancreas Segmentation in Abdominal CT Scans;Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets;Efficient liver segmentation in CT images based on graph cuts and bottleneck detection.;3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes;Shape–intensity prior level set combining probabilistic atlas and probability map constrains for automatic liver segmentation from abdominal CT images;Automatic Liver Segmentation on Volumetric CT Images Using Supervoxel-Based Graph Cuts;Automatic Liver Segmentation Based on Shape Constraints and Deformable Graph Cut in CT Images;DeepOrgan: Multi-level Deep Convolutional Networks for Automated Pancreas Segmentation;U-Net: Convolutional Networks for Biomedical Image Segmentation;A Generic, Robust and Fully-Automatic Workflow for 3D CT Liver Segmentation;The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository;Comparison and Evaluation of Methods for Liver Segmentation From CT Datasets;Automatic Pancreas Segmentation via Coarse Location and Ensemble Learning;GENERATIVE ADVERSARIAL NETS;Data from Pancreas-CT"
        ],
        [
         "3",
         "000c965a4857c0da7d9df07065b48920a6a756c6",
         "Journal of Medical Artificial Intelligence",
         "0",
         "",
         "None",
         "2331573849,2256970731",
         "Sandeep Reddy,Sameer Shaikh",
         "2025",
         "s2",
         "0.0",
         "https://eprints.qut.edu.au/252096/1/9284-PB1-6129-R1.pdf",
         "",
         ""
        ],
        [
         "4",
         "00139e24da15df3f2f4ef70a92a781ccf315ef47",
         "bioRxiv",
         "0",
         "Biology",
         "2025-02-19",
         "2346560940,2277617384,1992769227,1398654276",
         "Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaard‐Andersen",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2025/02/19/2025.02.19.639066.full.pdf",
         "",
         ""
        ],
        [
         "5",
         "0024c33a8cca7175b92880b8c47940deeb05e87c",
         "IEEE Access",
         "10",
         "Computer Science",
         "None",
         "81957285,2175056686,6558082,2294763180,1970251,2260001835,2227650844",
         "Tarek Khater,A. Hussain,R. Bendardaf,Iman M. Talaat,H. Tawfik,Sam Ansari,Soliman A. Mahmoud",
         "2025",
         "s2",
         "2.0",
         "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10229149.pdf",
         "",
         ""
        ],
        [
         "6",
         "0027ea27f5986f9c6ee9776e10289c7f2aa089ca",
         "International Conference on Compiler Construction",
         "1",
         "Computer Science",
         "2025-01-23",
         "2168878518,1714681,1692663",
         "Robert Szafarczyk,S. Nabi,W. Vanderbauwhede",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.13553v1.pdf",
         "",
         ""
        ],
        [
         "7",
         "00291c982d2d9e69d8fe8c89a7db1fbb25f15687",
         "bioRxiv",
         "0",
         "Biology,Medicine",
         "2025-01-02",
         "30455986,2283562588,2182492272,2308111697,2338816502,2338815388,2243227743,2296667017,2338816370,2283585238,2256102695",
         "Affiong I. Oqua,Kin Chao,Liliane El Eid,Lisa Casteller,Billy P Baxter,Alba Miguéns-Gómez,Sebastian Barg,Ben Jones,Jorge Bernadino de la Serna,Sarah L Rouse,Alejandra Tomas",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/06/25/2024.06.22.600087.full.pdf",
         "5b1c612edf20afd6c4885bdaa41404600cafb355;2c117e1bed41946070c9b2a6befc5c0a10942b3d;5138f96cd3d70bf44ec33c7ac789db0046746206;a51eb9149ebaa701d4e9ae356a2135b7433c4b22;a3a8b84292ee4f25da95def137e7c98acd9fc554;ceb85b6a68ae4e918d2e7b0a0709ec7d54130a48;89efe8f96612f9f041344c0ece935c77966a76c9;91f6e545dd964e760f40ae19b21ae56700757542;8aa4d0997f360caf6513f7265a0e53ef37bab1fd;845b790948eb66f2318095adb35b2dbc6b9fb22b;6ce51b17cbf3f8d965afac4a11dba42b6ef19df4;7e7782e78cfb0e1ef21d5f488436b1ae90efe8c5;7caed6f88a2637d577792df15723739e5cc04aed;50970216ab97806f1073e93acfe14b9b45fade87;ecbce30e0fc2f71017c49fc10df9618f6f872165;66a8ea9910dc0f9cb0533093a4bac55fac60530d;29d0c8384e815643d4ee45157130360acd465973;5cd9346a596e25c40099b706bd3ecd935532d893;56f2ebc15d14bf15f087896bf4dbcd29a08aafbc;881efdfa4d82fd58d4d645ce9e1806bd28edeb80;134f4ecb86505d781da92f87bbef1aab31d2867a;6c4fb6bbd5d62ef1350d09792120f121afce8fd4;db9f7005e76bf1fd307f1bdf2a019e0ba0658f78;be64af89ffad0e46e0639f9e850a8340a686c4be;edac29722b9448c00c727352ccca02bfb0a746ba;9a3aedd3556732af0bc72cefcd5b9a4fb6b5739c;5afd643a76f5973a1179e6d6b5b3bd4963b0861d;430ba46e178c491225c1dd673ae97742a3fab9f1;7b7b2d771921c66f6b295697c180ccb3d414deeb;962cecc2a2bd00473bc28cd3dc6f4e2f415bc5ca;4ccc59d942e51a62ecdec9fc2a722c343d76b8ef;34ac9603aa5d422093d0cd6a0a1429b831c768e2;fa78c0a11866a0364bc49d8d5b5c5b512426532e;16f30b76142304c99acf39478df464a3b1828401;9a3f4a783e5dff9056b68fe9fa7cffca5e44998d;a4607a83a2479e2654ea490b5c106b631feddf5d;def72ea245a151a238b85f7eb5e4dc8cf1b6bd5b;c959a32cf14b79cd0ec1e9c8847f4da923a891d3;19ca14d882b6885224e711d44d379c24d2a14bd2;346ef7fdf555fc0396f9e954bcda723a2fb1b356;0e7c330a5dcfe23e6a91f9539ce4a1764214bc18;606a1b5b5c56ac50bb1536910d93de20b951266d;b42d5d66bfb3253cb6f3ab3d8261e3aba2103cdb;af56a3d04b7a7088f0a6ab1090453cfe40bce39a;b82648533c62326ef616c46d065cd08b680f6bdb;52d0c3391873f7bb6767d7f98bdc2b615c5e31fa;88d57db91a1bd6f2a7bd094fda05b4a011c1d047;ce4bbbe09c137bac890c294fe9ca9588fe5225a7;79ecf855e4fc4241430b8e028fe2aa7dfce6e636;e2c67c99ef6037c2d987adac8d26a16a4d8b345e;166e256d1f03ad64b73ee35e1923d653b77d4485;57d9bb86d1e87f2e69fc8d6c3c5622e4099e3f61;274774b17b1fd9674ec16020a27b2cd4f7176133;7392a344973548009ebc8668895cb97162163de5;7ba777dc3fc96b079aa2571508309b27afd7fca9;3f2ea62f69c4b158b676815f56b98b57444fab86;ae675566584b233209bd062a0a44fb12324d44cd;0f92d3b97898a90f3a0972e31b59925eba580fa4;60d9a51fe29f97bbbaa756d863d39061262bb1fc;49b2356120411dd5945da922789a216b31dcd2a7;cc4365329d26ad61b4403da6dc5e1431bac70623;3a74982c56a7e4c8b03ca05bf7ab085ed9bae30f;338916a87b053260d55b95a4464fd298c584dc43;1fb5ffb13916d98d635473b01dddbd107b0c4e9f;76f48961e77227e276e5d7f5cf2ef2ec712a2be7;f4a69fc0ffc5de5305b1cc0c4be33a3a37487b11;51dd07564a6ae6f5aa28c8f078fed2a816caafc6;54b51fb9b10c9472b071dd902c157e43fca7699d;08fcc96b122ba76138b2832c48263f9908bc26a1;7d63e5ab05f878ae4f526d89a004a9d7d73a412e;79cf193a31cb123add0873ce33f6d3f2c60889b3;c55d959289907278cc5eb40fe2055b4632ad275d;1c7de2f7986813f2e368d32ceb46c68c2ac74ba1;6bd4ccb9204a8e94906ece8b874a8e3f11ab4d97;12635e085c01badd4c3dcaa74c54165493e83c81;cf7cd5306c8c448797644501f390f82e8a929089;384d724e0cba03cd1848dfb29fb89d9709549860;aee68eda11f1e289e73f1077da775f2dcbd747ec;1ae96936f9a22b8d0627791a9ff21fea7e9d0cee;9b7bf64ef8df832a1b1424374e03687f2c6bad59;ebe3d5e0287401ae9453e39a5dc865a5360e4eb1;344c7523b0b051bf4c6fed4e7bcd69a8e19a4c23;4dcf1ba0e71f692fac74ba0343a97f1c38e4a0d4;376f474b3556b87544a7005ddc91964de27f9f91;77d049b5961f57d9d42154144432a8fb039f1230;86e659db4d4c8a45175ffe8bb0cd372e3f3e5e82;73cbf3714cf74b7c75792df296c83b4eb3169c68;eae45f6e52d294f403dea56f3210cbba3a66fcac;521027c14a7ef622a4f03106799706d0824e192a;18140934c20df9e96b4eef86ecf5d4dd8c1188ea;897172c2bff121370e4454cccb685a51dd2a2fba;58f237c8daf2eb6b4c7710694c96c3ed654a734d",
         "GLP-1R associates with VAPB and SPHKAP at ERMCSs to regulate β-cell mitochondrial remodelling and function;Missense3D-TM: Predicting the Effect of Missense Variants in Helical Transmembrane Protein Regions Using 3D Protein Structures;Newer pharmacological interventions directed at gut hormones for obesity;Martini 3 Coarse-Grained Force Field for Cholesterol.;Statins and risk of type 2 diabetes: mechanism and clinical implications;An updated patent review of GLP-1 receptor agonists (2020-present);Divergent acute versus prolonged pharmacological GLP-1R responses in adult β cell–specific β-arrestin 2 knockout mice;The expanding incretin universe: from basic biology to clinical translation;Enhanced Endosomal Signaling and Desensitization of GLP-1R vs GIPR in Pancreatic Beta Cells;Fluorescent Probes for Lipid Membranes: From the Cell Surface to Organelles.;Interactions of cholesterol molecules with GPCRs in different states: A comparative analysis of GPCRs' structures.;Martinize2 and Vermouth: Unified Framework for Topology Generation;Exenatide prevents statin-related LDL receptor increase and improves insulin secretion in pancreatic beta cells (1.1E7) in a protein kinase A-dependent manner.;GPCRdb in 2023: state-specific structure models using AlphaFold2 and new ligand resources;Cholesterol-Dependent Dynamics of the Serotonin1A Receptor Utilizing Single Particle Tracking: Analysis of Diffusion Modes.;Biased Agonism and Polymorphic Variation at the GLP-1 Receptor: Implications for the Development of Personalised Therapeutics.;1457-P: Cholesterol Accumulation in Islets Increases Steroidogenic Acute Regulatory (StAR) Protein Expression and Decreases Islet Cell Viability and ß-Cell Function;Cholesterol Dependent Activity of the Adenosine A2A Receptor Is Modulated via the Cholesterol Consensus Motif;The role of the lipid environment in the activity of G protein coupled receptors.;Cholesterol-dependent endocytosis of GPCRs: implications in pathophysiology and therapeutics;Spatial arrangement of proteins in planar and curved membranes by PPM 3.0;Brain GLP‐1 and the regulation of food intake: GLP‐1 action in the brain and its implications for GLP‐1 receptor agonists in obesity treatment;Super-Resolution Microscopy Using a Bioorthogonal-Based Cholesterol Probe Provides Unprecedented Capabilities for Imaging Nanoscale Lipid Heterogeneity in Living Cells.;Acylation of the Incretin Peptide Exendin-4 Directly Impacts Glucagon-Like Peptide-1 Receptor Signaling and Trafficking;PyLipID: A Python Package for Analysis of Protein–Lipid Interactions from Molecular Dynamics Simulations;Contribution of Mitochondria to Insulin Secretion by Various Secretagogues;Improved Parameterization of Phosphatidylinositide Lipid Headgroups for the Martini 3 Coarse-Grain Force Field.;Molecular insights into ago-allosteric modulation of the human glucagon-like peptide-1 receptor;The Interplay of Glucagon-Like Peptide-1 Receptor Trafficking and Signalling in Pancreatic Beta Cells;The therapeutic potential of GLP‐1 receptor biased agonism;Martini 3: a general purpose force field for coarse-grained molecular dynamics;Multi-dimensional and spatiotemporal correlative imaging at the plasma membrane of live cells to determine the continuum nano-to-micro scale lipid adaptation and collective motion;LAURDAN since Weber: The Quest for Visualizing Membrane Heterogeneity.;Predictable cholesterol binding sites in GPCRs lack consensus motifs.;Allosteric Modulation of GPCRs of Class A by Cholesterol;Evolving cryo-EM structural approaches for GPCR drug discovery;Adaptive Lipid Immiscibility and Membrane Remodeling Are Active Functional Determinants of Primary Ciliogenesis.;Genetic and biased agonist-mediated reductions in β-arrestin recruitment prolong cAMP signaling at glucagon family receptors;Incretin Hormones and Type 2 Diabetes—Mechanistic Insights and Therapeutic Approaches;Imperial;Ligand-Specific Factors Influencing GLP-1 Receptor Post-Endocytic Trafficking and Degradation in Pancreatic Beta Cells;Structure and Dynamics of GPCRs in Lipid Membranes: Physical Principles and Experimental Approaches;Differential GLP-1R binding and activation by peptide and non-peptide agonists;Lipid-Protein Interactions Are a Unique Property and Defining Feature of G Protein-Coupled Receptors.;Full-length human GLP-1 receptor structure without orthosteric ligands;Signalling, trafficking and glucoregulatory properties of glucagon‐like peptide‐1 receptor agonists exendin‐4 and lixisenatide;ER-lysosome contacts enable cholesterol sensing by mTORC1 and drive aberrant growth signaling in Niemann-Pick type C;Agonist-induced membrane nanodomain clustering drives GLP-1 receptor responses in pancreatic beta cells;2125-P: Increased StAR (Steroidogenic Acute Regulatory Protein) Is Detrimental to ß Cells and Promotes Mitochondrial Dysfunction;An Overview, Advantages and Therapeutic Potential of Nonpeptide Positive Allosteric Modulators of Glucagon‐Like Peptide‐1 Receptor;RNA-seq-based identification of Star upregulation by islet amyloid formation.;State-dependent Lipid Interactions with the A2a Receptor Revealed by MD Simulations Using In Vivo-Mimetic Membranes;Targeting GLP-1 receptor trafficking to improve agonist efficacy;Cholesterol metabolism—physiological regulation and pathophysiological deregulation by the endoplasmic reticulum;Phase-plate cryo-EM structure of a biased agonist-bound human GLP-1 receptor–Gs complex;Dissecting single–cell molecular spatiotemporal mobility and clustering at Focal Adhesions in polarised cells by fluorescence fluctuation spectroscopy methods;Membrane lipids and cell signaling;Cryo-EM structure of the activated GLP-1 receptor in complex with G protein;The New Biology and Pharmacology of Glucagon.;The mystery of membrane organization: composition, regulation and roles of lipid rafts;Lipid–Protein Interactions Are Unique Fingerprints for Membrane Proteins;Glucagon-Like Peptide-1 and Its Class B G Protein–Coupled Receptors: A Long March to Therapeutic Successes;There Is No Simple Model of the Plasma Membrane Organization;Use of CRISPR/Cas9-engineered INS-1 pancreatic β cells to define the pharmacology of dual GIPR/GLP-1R agonists.;Restoring Mitochondrial Function: A Small Molecule-mediated Approach to Enhance Glucose Stimulated Insulin Secretion in Cholesterol Accumulated Pancreatic beta cells;Simvastatin Impairs Insulin Secretion by Multiple Mechanisms in MIN6 Cells;GROMACS: High performance molecular simulations through multi-level parallelism from laptops to supercomputers;CHARMM-GUI Martini Maker for Coarse-Grained Simulations with the Martini Force Field.;Glucagon-Like Peptide-1 Increases Mitochondrial Biogenesis and Function in INS-1 Rat Insulinoma Cells;Computational Lipidomics with insane: A Versatile Tool for Generating Custom Membranes for Molecular Simulations.;The class B G-protein-coupled GLP-1 receptor: an important target for the treatment of type-2 diabetes mellitus.;Structure of Class B GPCRs: new horizons for drug discovery;Physiology and pharmacology of the enteroendocrine hormone glucagon-like peptide-2.;Nutrition and L and K-enteroendocrine cells;Identification of cholesterol recognition amino acid consensus (CRAC) motif in G-protein coupled receptors.;Syntaxin clusters assemble reversibly at sites of secretory granules in live cells;Raster image correlation spectroscopy in live cells;Multiphoton excitation fluorescence microscopy in planar membrane systems.;Combining an Elastic Network With a Coarse-Grained Molecular Force Field: Structure, Dynamics, and Intermolecular Recognition.;A specific cholesterol binding site is established by the 2.8 A structure of the human beta2-adrenergic receptor.;Cholesterol homeostasis in T cells. Methyl-beta-cyclodextrin treatment results in equal loss of cholesterol from Triton X-100 soluble and insoluble fractions.;The physiology of glucagon-like peptide 1.;Canonical sampling through velocity rescaling.;Caveolin-1 regulates cellular trafficking and function of the glucagon-like Peptide 1 receptor.;Comparative Protein Structure Modeling Using Modeller;Simvastatin: a review;The 3-hydroxy-3-methylglutaryl coenzyme-A (HMG-CoA) reductases;Isolation of INS-1-derived cell lines with robust ATP-sensitive K+ channel-dependent and -independent glucose-stimulated insulin secretion.;VMD: visual molecular dynamics.;Simvastatin. A reappraisal of its pharmacology and therapeutic efficacy in hypercholesterolaemia.;Polymorphic transitions in single crystals: A new molecular dynamics method;Zhang X;29 of 31 Frontiers;Röhrl C;Role of the steroidogenic acute regulatory protein in health and disease"
        ],
        [
         "8",
         "00317a3206df00f0c3c91595a349bc81b7118929",
         "IEEE Robotics and Automation Letters",
         "1",
         "Computer Science",
         "2025-02-05",
         "2115738494,2066395412",
         "Yeping Wang,M. Gleicher",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2502/2502.03676v1.pdf",
         "",
         ""
        ],
        [
         "9",
         "0034e238be40924c815d89333e50afeb8fde846e",
         "bioRxiv",
         "0",
         "Biology",
         "2025-02-19",
         "7167369,2327626722,2069020677,2279798536,143647897,2283176107,3528292,2298230556,2294582175",
         "Meghan M. Moran,Jun Li,Quan Shen,Sheona P. Drummond,C. Milner,Anthony J. Day,A. Naqib,D. R. Sumner,Anna Plaas",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/10/17/2024.10.17.618923.full.pdf",
         "",
         ""
        ],
        [
         "10",
         "003c35a5bdd27f7089275036709cde1785dcf8d3",
         "Entropy",
         "1",
         "Medicine",
         "2025-02-21",
         "2346760286,1805780,2290077772",
         "Yana Garipova,Shogo Yonekura,Yasuo Kuniyoshi",
         "2025",
         "s2",
         "0.0",
         "https://www.mdpi.com/1099-4300/27/3/219/pdf?version=1740123018",
         "",
         ""
        ],
        [
         "11",
         "00466e50bb0d57aaf1949c4f295bd6203236a42a",
         "International Journal of Ecophysiology",
         "0",
         "",
         "2025-03-18",
         "2351883966,2351883196,2351881456",
         "Anliana,Henry Panguhutan Sitorus,Melva Silitonga",
         "2025",
         "s2",
         "0.0",
         "https://talenta.usu.ac.id/ijoep/article/download/19118/8494",
         "",
         ""
        ],
        [
         "12",
         "0053ae5c37112efe02b3a9990bfd51510a567637",
         "Gene Reports",
         "0",
         "",
         "None",
         "2278831224,2348067825,2319090578,2278782559,2346555569,2346650042,2346604604,2346856142,2346592241,2346729741,2189473479,2278801390,9177697,2316304307,2115348942",
         "Jun Ma,Yanfeng Yue,Yuanhao Ren,Liu Cao,Haishan Wang,Yan Chen,Wenqi Zhuo,Zhou Wang,Tingting Dang,Xueyi Wang,Pan Chen,Xingrong Hou,Hai Huang,Keji Jiang,Tingting Lin",
         "2025",
         "s2",
         "0.0",
         "https://www.researchsquare.com/article/rs-352287/latest.pdf",
         "",
         ""
        ],
        [
         "13",
         "0054da67677e57ad0e4329f204539db27329c1d8",
         "IEEE transactions on circuits and systems for video technology (Print)",
         "0",
         "",
         "None",
         "1825748143,2157246670,2114745862,2162723557",
         "Donghua Wang,Wenyan Yao,Tingsong Jiang,Chao Li",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2407/2407.06688v1.pdf",
         "",
         ""
        ],
        [
         "14",
         "006409cdca137cfc222cee85ad960caace21b7d5",
         "Advances in Mathematics of Communications",
         "0",
         "Computer Science",
         "None",
         "2150472849,2837381",
         "Soumak Biswas,Maheshanand Bhaintwal",
         "2025",
         "s2",
         "0.0",
         "https://www.aimsciences.org/data/article/export-pdf?id=658400c292d3ad47ddca22bd",
         "1d98fa414f8de6dc8219e40323f4a98d116bb531;4c1aba13dd389332ddf0176c2ca7ba4bc9c8fe65;d2e12b7fa673ec6de9dc4836be955171a4acbc72;9a4db75f571cafeb80e284adb09f2cb2e66fdb45;a92a801137119506e93d8698fd9d4864167f289f;834d0a64bae4345bc1a859bef3c215da11511077;30bb5cffa50d502e6ae2a1552f667401a8291128;46fa5877f4955be079e8c73cfb539af8257b8f08;de70aef2843fe112d4e0ddcd7ea83b379b00ba07;63e371f28f670e499d71b5c98d4d74678432a64d;405df1cbab905f53558417e9b7fbd78913e4dc5c;1c1201a1712cd5d987ed38624f3c0fb127160032",
         "Quasi-Cyclic Constructions of Quantum Codes;Structure and performance of generalized quasi-cyclic codes;On ℤprℤps-additive codes;On ℤ2ℤ2[u]-additive codes;On cyclic self-orthogonal codes over Z2m;On double cyclic codes over Z4;Z2\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$${{\\mathbb {Z}}}_2$$\\end{document}-double cyclic codes;On quasi-cyclic codes over $${\\mathbb{Z}_q}$$;$${{{\\mathbb Z}_2}{{\\mathbb Z}_4}}$$ -linear codes: generator matrices and duality;On the algebraic structure of quasi-cyclic codes I: Finite fields;Cyclic Codes over the Integers Modulopm;On ℤprℤps-additive cyclic codes"
        ],
        [
         "15",
         "006b512306cc252e48b8999f5e52acf05b115889",
         "IEEE Transactions on Control Systems Technology",
         "0",
         "",
         "None",
         "2185647310,122887881,3106400,2250212404,9305238",
         "Luuk Poort,Lars A.L. Janssen,B. Besselink,Rob H. B. Fey,N. Wouw",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2411/2411.13344v1.pdf",
         "",
         ""
        ],
        [
         "16",
         "0070139c46648999df1072c940d0b9f7ad25f258",
         "IEEE Transactions on Sustainable Computing",
         "2",
         "Computer Science",
         "2025-03-01",
         "2305191872,2305491478,2119430859,2144802055,2276106040,1726391,2281968797,2292536829",
         "Muhammad Rizwan,Mudassir Ali,Ammar Hawbani,Xingfu Wang,Adeel Anjum,Pelin Angin,Olaoluwa R. Popoola,M. A. Imran",
         "2025",
         "s2",
         "0.0",
         "https://eprints.gla.ac.uk/328280/2/328280.pdf",
         "bc22b48612e9f15168171e5f72cfb67027de128a;5eaf653d184304c6f91f46dcd5b62e6ec45c0972;df44d242dee3034af13dc84ef7f45e9c843c961a;cefaba37ce64ab7ecddef5406ad70b5327353840;56bcaef6de5b077f29f75a820ddc5199cf50e681;831ddcfd1ddfa0d5b9e34a625fab89d39d16f6a0;5dee597647e62b79d07d34a3f31459456801ca28;e26bb40c2539855cbd6e914f3e3e2dfa6a5f9899;5603dc2ef70cde2de7af9140480f7756884ee5c5;6b8140759f57db9adc84868d4f2eaa586c28cc86;7e97d7a7dbb43d9f854264aba64ae52aae74c759;2aea56422dd6dcf2da6ea523fe6fa246978a9864;cd2cecd48c73db7cdeacb32b2eb349ac9c1af829;9934803184a2076317fd9b6930fd1cb10b06931b;708d3d946651e3f7e95cb85868df0ba2f55a3f83;6535a6e20ad025d209f98a906c4413bcd0bf536e;19dc966f0fb70abffaea682b81d3554c15551fda;9867f9875db68f987eb72003b58c95ef15de6641;c5fd1605484f6b15b344695749c9178423185fb1;a0d79338fb52ec77ec9af257b4978d69b02537bc;1de07a93953b8820da11aefe1cbfb41430ddd903;6fe0cd0c531ac2072826eed3be4a5a18d007987f;153d8ae953ec81c6f9dba86a1f355429ad432c1f;6ebb0223cdf655a11f75df812e817453b02454d3;43586b34b054b48891d478407d4e7435702653e0",
         "Hierarchical Online Game-Theoretic Framework for Real-Time Energy Trading in Smart Grid;sTrade: Blockchain based secure energy trading using vehicle-to-grid mutual authentication in smart transportation;Designing Fairness in Autonomous Peer-to-peer Energy Trading;A Consortium Blockchain-Enabled Secure and Privacy-Preserving Optimized Charging and Discharging Trading Scheme for Electric Vehicles;Blockchain-Enhanced High-Confidence Energy Sharing in Internet of Electric Vehicles;A Bayesian Game Based Vehicle-to-Vehicle Electricity Trading Scheme for Blockchain-Enabled Internet of Vehicles;A Distributed Framework for Energy Trading Between UAVs and Charging Stations for Critical Applications;Blockchain-Enabled Secure Energy Trading With Verifiable Fairness in Industrial Internet of Things;A Blockchain-Based Framework for Lightweight Data Sharing and Energy Trading in V2G Network;Blockchain-Based Secure Spectrum Trading for Unmanned-Aerial-Vehicle-Assisted Cellular Networks: An Operator’s Perspective;Electric Vehicle Power Trading Mechanism Based on Blockchain and Smart Contract in V2G Network;A Novel Debt-Credit Mechanism for Blockchain-Based Data-Trading in Internet of Vehicles;A Secure and Efficient Blockchain-Based Data Trading Approach for Internet of Vehicles;PTAS: Privacy-preserving Thin-client Authentication Scheme in blockchain-based PKI;Blockchain and Computational Intelligence Inspired Incentive-Compatible Demand Response in Internet of Electric Vehicles;Real-time renewable energy incentive system for electric vehicles using prioritization and cryptocurrency;CreditCoin: A Privacy-Preserving Blockchain-Based Incentive Announcement Network for Communications of Smart Vehicles;Estimation of cost savings from participation of electric vehicles in vehicle to grid (V2G) schemes;Dependable Demand Response Management in the Smart Grid: A Stackelberg Game Approach;Optimal decentralized protocol for electric vehicle charging;ELECTRIC VEHICLES AS A NEW POWER SOURCE FOR ELECTRIC UTILITIES;Technology;“Anovelstochastic blockchain-basedenergymanagementinsmartcitiesusingV2SandV2G,”;V2GNet: Robust Blockchain-Based Energy Trading Method and Implementation in Vehicle-to-Grid Network;International Semantic Intelligence Conference, ISIC 2021, New Delhi, India, 25 - 27 February 2021, vol.2786 pp.60-66 VII. A Novel SDN Dataset for Intrusion Detection in IoT Networks;“DEAL:Differentiallyprivate auctionforblockchain-basedmicrogridsenergytrading,”;“Secure and efﬁcient vehicle-to-grid energy trading in cyber physical systems: Integration of blockchain andedgecomputing,”;Semantic Intelligence;. A self-protecting agents based model for high-performance mobile-cloud A self-protecting agents based model for high-performance mobile-cloud;“IOTA’s tangle powers IAMPASS biometric palm vein authentication for digital identity,”;“Privacy-preservingblockchain-basedelectricvehiclechargingwithdynamictariffdecisions,”;The Tangle;“Ananalysisofanonymityinthebitcoinsystem,”in;Human-Centric Analysis;AmmarHawbaniiswiththeSchoolofComputerScience,Shenyang AerospaceUniversity,Shenyang110136,China"
        ],
        [
         "17",
         "007e7d6cb64a7dfcdcad9fc6f4f0ba69fdc88203",
         "IEEE Internet of Things Journal",
         "11",
         "",
         "None",
         "2129402047,2303981394,2258558083,2302991619,143966963",
         "Mingjin Zhang,Xiaoming Shen,Jiannong Cao,Zeyang Cui,Shan Jiang",
         "2025",
         "s2",
         "1.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2405/2405.14371v1.pdf",
         "",
         ""
        ],
        [
         "18",
         "007f0fb7f697b3fe52d828a5b9d4472583d69d41",
         "J. Documentation",
         "0",
         "Computer Science",
         "2025-01-06",
         "3126502,2224688207,2338428327,2265268198,2338430538",
         "Konstantina Martzoukou,Errol Sadullah Luders,Fiona Work,Petros A. Kostagiolas,Neil Johnson",
         "2025",
         "s2",
         "0.0",
         "https://rgu-repository.worktribe.com/preview/2571863/MARTZOUKOU%202024%20Digital%20divides%20in%20nursing%20%28AAM%29.pdf",
         "37d46fea09804c52cface7993048eff3b2bbae4f;98b27424b79876ffb8c34fc826b8e64f84c3c1e8;ea4a290273f95eca770a2b55427f8df869715e3e;dc2985cf1895a2a56f6bab4bbd612d1022346ba9;c7bb3fc502f62469bd42d7bd65dab42e3ef057c3;7d0f10c477595ba4a19dbf0d8c38c4f5a3acdecf;baef05b26267729e6e14246b0e6edb66d03272f6;48ca6adf640c7c6b005fe70d1e6aaee5bb0b5246;65b52ea4fe92510591df45ccac5e709b3bcb8c8a;37c51cc4194e8d67ea0435999ca9fc20e1f6fe69;08fc47a1a97527fccbc5aa406dcf892b5e8bb239;6ca8bdfd07871b6c14b6bea83f2776d45a70b102;9ac2751c5ccc4d5ffb115fe998393a4b07fe4548;2ca3e6b3d37e634baa12c251d9bf945ed73fe3f0;aaa13a22117b9e48371f2d24ea2e6fe586e7c0f3;9ff53708c41e86f77623bbd592e29475f04447c7;b49a9ab78f044ef5e94baf6e17b8de1898b5f337;7eaee7d2a94cd76fd4fa66928d561e5445f4e991;449923b9b005c06eea033d03368aace0f3c8c979;08f025a1d5c95849c056e02591c97681ac6ba87a;db9a9c840bce0f7ec513e3b40576d49cab0ddc3e;fb2a07f5a1b72e9d56b0ee9b76fba0813241134c;99411a5190a40e901168a2e042bae21c805c3bf8;8f7cfbb384a6377589d313d569930f78689f6715;9a2605803d872c1da44fb0ba0bb394d0e13790fc;bb8ad4b587652c1f4654b962ae33c01c103e683c;eedb385c899528232213a051c3bca8283ab50900;1bdd16389e5a79e64f653986a16ff5508733b364;1085422212c1b7a8c5c41b905fbda83c5b1a49a1;cd5370f21a696ee3c7c6130956d7550c7bbe1898;30f75c2c7081b609b516c4a8a145b4982dbe488b;7bb8fe05f2a1bb93bb697aa75e08b39d3907b1f5;d8395b0597343adcf88b1bc49987a84d6cae8ba6;bcd321ce98ef2ec6904e497c2e5034d81590dcb5;a7fd522dc98feb6075f07d107bc778cd6f3c0363;802f6feb87bcfa5535bc481125478ec4f1bcdca7;ddf4172cad889f178c2db9b1b6302b3c7d5c0147;9a5da88f5fddb70c5a9eed0f37fedfcafab31aa7;1b09d9424d4441fe413889af009dcc1948cb36e0;d5bb413b47e0682f53d4ef8dd7d6889641c9ea4b;812c65238534ea831924a0a14ff4eb747ace9957;4f415d23f10170b313d1435f8119cc91191d7a8b;ee63d3b5ecbdfd5c377402616ed65c1a4abf8c29;6c84ee4e1354ca4ed39985f232361061f3dc98fc;ef653dbcbdba438fb895f0450504ef2a3fef8e59;edaf2979bd25a29c0abc9bfb9eb59cdb53be88cd;64a19a6728989ee283db441e2a20fd96ea75fae2;459a9f54b5b2bb1533fa5772b9beccbddb09b6a8;2f5af5595600489c27214feded05eb35caa6b519;f593f9ade18a6d67043c828a013830f3690dfd6b;d6f722446b998103e69975a6d07e8373e9e4a96b;f52a7e266c0fba35e72d9791e5e7ec3e7c08da68",
         "Advancing nursing practice with artificial intelligence: Enhancing preparedness for the future;Relationship between digital capabilities and academic performance: the mediating effect of self-efficacy;Influence of technical, cognitive and socio-emotional factors on digital literacy in nursing students assessed using structural equation modeling.;A cross-sectional study of discipline-based self-perceived digital literacy competencies of nursing students.;Revolutionizing nursing education through Ai integration: A reflection on the disruptive impact of ChatGPT.;Knowledge, Perceptions and Attitudes of eHealth and Health Technology among Nursing Students from Gauteng Province, South Africa;Compassionate pedagogy for neurodiversity in higher education: A conceptual analysis;First-year nursing students’ digital literacy: A cross-sectional study;eHealth Literacy of Australian Undergraduate Health Profession Students: A Descriptive Study;Digital health education: the need for a digitally ready workforce;Two sides of the same coin: accessibility practices and neurodivergent users' experience of extended reality;The mediating effects of digital literacy and self-efficacy on the relationship between learning attitudes and Ehealth literacy in nursing students: A cross-sectional study.;Nursing Faculty Informatics Competencies;Study progression and degree completion of autistic students in higher education: a longitudinal study;Digital Technologies and the Role of Health Care Professionals: Scoping Review Exploring Nurses’ Skills in the Digital Era and in the Light of the COVID-19 Pandemic;Tools to support the automation of systematic reviews: A scoping review.;Improving the health assistant in nursing employment model through entry to practice nursing student perceptions: a cross-sectional study;Learning styles, preferences and needs of generation Z healthcare students: Scoping review.;A study of university law students’ self-perceived digital competences;Disparities in Health Care and the Digital Divide;ÜNİVERSİTE ÖĞRENCİLERİNİN DİJİTAL OKURYAZARLIK BECERİLERİ İLE DİJİTAL MAHREMİYET KAYGISI ARASINDAKİ İLİŞKİ;Digital Literacy in UK Health Education: What Can Be Learnt from International Research?;Understanding Generation Z through collective consciousness: Impacts for hospitality work and employment;Frustration With Technology and its Relation to Emotional Exhaustion Among Health Care Workers: Cross-sectional Observational Study;Social Media Used and Teaching Methods Preferred by Generation Z Students in the Nursing Clinical Learning Environment: A Cross-Sectional Research Study;Supporting the development of information literacy skills and knowledge in undergraduate nursing students: An integrative review.;Educational experiences with Generation Z;A study of higher education students' self-perceived digital competences for learning and everyday life online participation;Thematic analysis of qualitative data: AMEE Guide No. 131;Health literacy, digital literacy and eHealth literacy in Danish nursing students at entry and graduate level: a cross sectional study;Student Nurses' Digital Literacy Levels: Lessons for Curricula.;Peer-led information literacy training: a qualitative study of students' experiences of the NICE Evidence search Student Champion Scheme.;Equipping Learners to Evaluate Online Health Care Resources: Longitudinal Study of Learning Design Strategies in a Health Care Massive Open Online Course;Rigor and reproducibility for data analysis and design in the behavioral sciences.;The same course, different access: the digital divide between urban and rural distance education students in South Africa;Identification of Factors Influencing the Adoption of Health Information Technology by Nurses Who Are Digitally Lagging: In-Depth Interview Study;The potential for artificial intelligence in healthcare;A Novel Instrument for Measuring Older People’s Attitudes Toward Technology (TechPH): Development and Validation;Nurse and Nurse Student Attitudes and Perceived Self-efficacy in Use of Information and Communication Technologies: Professional and Cultural Differences;The digital divide: Patterns, policy and scenarios for connecting the ‘final few’ in rural communities across Great Britain;Generation Z students: Will they change our nursing classrooms?;Digital Literacy and Privacy Behavior Online;What is the “Digital Divide” and why is it Important?;Adopting evidence-based practice in clinical decision making: nurses' perceptions, knowledge, and barriers.;Conceptualizing and Testing a Social Cognitive Model of the Digital Divide;The Reliability, Validity, and Utility of Self-Assessment;Do They Really Think Differently;Student Self‐evaluation Processes in Student‐centred Teaching and Learning Contexts of Australia and England;Cambridge LibGuides. AI:Home;Digital engagement in nursing: the benefits and barriers;Technological literacy in nursing education: A scoping review.;COVID-19: exacerbating educational inequalities?;Mobile Learning in Nursing: Tales from the Profession.;The UK nursing labour market review 2008;Nurses and Internet health information: a questionnaire survey.;Discovery tool"
        ],
        [
         "19",
         "0082b6dd5b95334df816971d506e22a0f0da9cc4",
         "Natural Product Research",
         "0",
         "Medicine",
         "2025-01-31",
         "2334697739,2263771937,2334438251,2153398053,2053993487",
         "Xu-Meng Ren,Lin-Fang Zhong,Ke-Yue Wu,Xiao Liang,Shu-Hua Qi",
         "2025",
         "s2",
         "0.0",
         "https://figshare.com/articles/journal_contribution/Two_new_amino_acid-derived_oximes_from_the_mangrove-sediment-derived_fungus_i_Lecanicillium_kalimantanense_i_SCSIO_41702/28323314/1/files/52058141.pdf",
         "",
         ""
        ],
        [
         "20",
         "008b67207bda1f15d92c5c6d9283c2fae1ace158",
         "Displays (Guildford)",
         "1",
         "Computer Science",
         "2025-01-01",
         "2111514858,2111523944,2339793923,13163310,2288956458,2249229457",
         "Samirah Altukhaim,Naoko Sakabe,Kirubananthan Nagaratnam,Neelima Mannava,Toshiyuki Kondo,Yoshikatsu Hayashi",
         "2025",
         "s2",
         "0.0",
         "https://www.researchsquare.com/article/rs-4132920/latest.pdf",
         "6f6e700e37721ea89d058b326ea256c0cf8fa8d9;955f24b7aaccb45c242b9a9b0aa4160b5a109eb4;8bcc4c37694307385527aed48fe740b504bec608;b40e32c020366a26744ea157b393c392da4bf0fe;4914701c3e312fc76be338b30ff83be4229942c1;f33c66df439ed0d0fa38844c54de9c4267b80ecd;57e5dc0c444b47f460531e8004541017207112d9;95823a2bab2321f0d5c12ba55081511e271d52dc;85f8cfa361aebb5c633c2e82d34fa4b3c286e096;304d72b8a1d4cb2ea1dea37c325f824405671e19;1463f8a0f2990694a49263029f9c89878be4ac60;1091ff983b034bbf7d9fc5bf4b10f204ac60dc88;224a82608f57bcf8568159a337ba911c613299e0;834d478732bf78fed106b5fbe6a0a4bc18a1107a;b7eb1db2b92d382778dc818b099dd6491ceea9d8;93d90114efa1863f94bb1f8cfe929197fccb43b0;91b657fae7258eb8dab5845327a03d084fefcbf0;d9d87cc217ce00ce1be0ecf411dbd88f04448861;d48e1cbb4d9ec501acedc2dd6a3456ef2fea77f6;39870d36edcf62f774a2c836e3868462c755579e;8af42ac53127e8deb2d0ce258b74a4b2d2906330;6e23b5a3677e518508a116e0734101af917f7570;11d66ab0b7019f1a51605cdfc86554ce8192e927;aa41d824bbc21a761228c9dd961d8fb1973725ef;054ff45ac81b9477aaaa3d7d9883581030adec0a;6d804ae534d19b0cbde26ec3cc7340bc38072c04;322f2a23f27383922b4c0602954171841f7f4068;40484fea5a2dab3f8a7d207fff38adaca3c59601;0672617f1d7111b9ea7757bfff2c2c4325395375;44c0860feb26ad4b6761feeec26340f888d0d502;21bd2841cc11f2df294279c0b5dda45e1e8ad76e;33d732245e04e38f793da6a02929fc3bbde02e33;e8e181e3c1e77ebcd088a0001c0f2801f55dce0e;1a1a1379d4fa10bddcf52c0aa2f72de8c7d23c49;058986a51b4e46e1efc62b39a51ec33515720f94;0a41d85e192ee0c236c188685e070e6137570acb;631e1183a51bc7fc0445d94413ae0368e07cd736;1b61dc05db02fb00349a5f809e161f2578dbdbc2;69854e21f2ba0eefb0b468a7f7a77f9d8ee726d3;1290baa19d0917e30faddd385e28dcec7b5af800;bace6d72540f41699205edf057af16cbe635431a;2675bac8f3ee81918603fef5b38d1cb3baf1cc28;fa72748b82c6d68c15b8c6bb4a14649a8458cb02;e8215844d84bcdd03104eb9753a31ebbd17dced9;f9fa613e8e53f3da9317993311bf9c286d94ddbe;45aa95e3668b67f1708c9d719233fab1840fcf7d;4c41e1c71404d71698c5dd300ac46ad8e07b6102;377f431de70b9027bf353dbcd93024c2178bcbb7;da28b0ebd337efa846ac7857d34db71ee7221ecd;3ead86286f338886798ccbda98cebc46d90f192a;75554749c0f696088957f14ea620a5ff956cbad4;6d44f492a8bd891e986d68af86c91145669f6c22;71c4a1f734bef36b9ad0a291bdcc29adc5748b7a;98f38f235375b846d71287e1a807dbbbce3f0431;95469539792004d038f94830948f21461cb49c7e;75b4966859bde87d86db57aaabe90bc9a24d4fdd;d0a238f400ff9ea7038f63b982781b0e2c6bf5ca;2c20d97ff237a1882de426237ba84d77917a0e8d;63658167b1fc618ff70be21bdfb264324d696f3e;163f868c756260221edeb4693b8fb320688f1f7b;880abb21380c79fbd89db9fb6d685b9894f48afe;5c576d779839ffd6ef54467bac7bdc0186641d7e;a73f093add8e85bd974bb729ff231ff4f925b8bd;2a7b68006306b8e42676db90aa3fb03818f89d8a;c493f94a24056f4d215d98f28923d7e5566d6709;b03bcca3a5f7b5ac9547b5c49a3ccc9402603385;ab30e1514660f5880ad14a8d93668570e1189f14;1d59e9a675ed8618f72b4a5c3fd851f48549386f;865e1105a843c2d57d7fa8bb0c4dfcf3e02c2dae;02edf22980611f433084a112b490221a3500f4b1;7ac7a228b3cbb08349212e4bbe4c90d9c243cf58;f8531c0ad04c3f850abc88c705224cf21f31c827;ed09074b546ea3e827683415f54a1353ecf901a7;047b58d265e5fffb321f96f034a3c2bdd8883544;172ed1332c0ba51af4c91d3fdc4b244f71fc05a5;e232ede843c9b3f93b6a5d719bfae6043e039953;551f062060c062a026a559d8d5d83ba708bc587b;a459bf376c8fc12884b5024f3fdd24c2c9818a74;1a35527a1956d893601f6f7f4b8e96db51cd69ee;b99269ca05dd571445255e1a5fc8b1f0ca095218;acd68210b5585f70d989370c92cca1a6d4675deb;7f4c64ee8a19336e08fad856353d29ea79b39fa7;6cf57a73ab400ad65df77663187c8296a783700f;a5df9bc637dafe1599619b6c06928680932981b8;1603072459bcf4a40a182460de144b08408d5a7c;c8bc3cf8f506d093452707a189f66d53ac8307b0;907d72f62967272b04b59224c262a4aae95bc234;e0db01812fe8ce272c64ac3f88633f64e19ee168;634c9fde5f1c411e4487658ac738dcf18d98ea8d;7a2422e7cf038232dca8fa1a930249e226382e0a;bb5dc4d4d67d9c472083846567934af7fde9a93c;db166a794c6c4c961e3b25fc688f700684a8e5e0;df4fc9cf0162133758f55424b8ca64856b364afa;021f29dd49fd359178064a1874467627c07d7e11;e995514530d12552a41ecdc279ff07ea00ef212f;8b34b1b83fd819506eb8edb29bf007c034cab70f;5bb7b79c29034c515ee423daffadd8364d2526c4",
         "Immersive Virtual Reality in Post-Stroke Rehabilitation: A Systematic Review;Effectiveness, safety and patients’ perceptions of an immersive virtual reality–based exercise system for poststroke upper limb motor rehabilitation: A proof-of-concept and feasibility randomized controlled trial;New technologies promoting active upper limb rehabilitation after stroke: an overview and network meta-analysis;Effectiveness of Using Virtual Reality–Supported Exercise Therapy for Upper Extremity Motor Rehabilitation in Patients With Stroke: Systematic Review and Meta-analysis of Randomized Controlled Trials;Enhanced Visual Feedback Using Immersive VR Affects Decision Making Regarding Hand Use With a Simulated Impaired Limb;A novel fully immersive virtual reality environment for upper extremity rehabilitation in patients with stroke;Neuroplasticity;Virtual reality games for rehabilitation of upper extremities in stroke patients.;On Shooting Stars;Post-stroke depression: A 2020 updated review.;Virtual reality therapy for upper limb rehabilitation in patients with stroke: a meta-analysis of randomized clinical trials;Principles of Neurorehabilitation After Stroke Based on Motor Learning and Brain Plasticity Mechanisms;Exergaming for stroke rehabilitation: Lessons learned for future implementation strategies;Elements virtual rehabilitation improves motor, cognitive, and functional outcomes in adult stroke: evidence from a randomized controlled pilot study;Comparison of Kinect2Scratch game-based training and therapist-based training for the improvement of upper extremity functions of patients with chronic stroke: a randomized controlled single-blinded trial.;Evaluating the effect and mechanism of upper limb motor function recovery induced by immersive virtual-reality-based rehabilitation for subacute stroke subjects: study protocol for a randomized controlled trial;Virtual Reality in Upper Extremity Rehabilitation of Stroke Patients: A Randomized Controlled Trial.;Project Star Catcher;Rehabilitation via HOMe Based gaming exercise for the Upper-limb post Stroke (RHOMBUS): protocol of an intervention feasibility trial;Virtual Reality Clinical Research: Promises and Challenges;Combining the benefits of tele-rehabilitation and virtual reality-based balance training: a systematic review on feasibility and effectiveness;Towards an Immersive Virtual Reality Game for Smarter Post-Stroke Rehabilitation;Effectiveness of Wii-based rehabilitation in stroke: A randomized controlled study.;Virtual Reality for Upper Limb Rehabilitation in Subacute and Chronic Stroke: A Randomized Controlled Trial.;Game-Based Virtual Reality Canoe Paddling Training to Improve Postural Balance and Upper Extremity Function: A Preliminary Randomized Controlled Study of 30 Patients with Subacute Stroke;What do randomized controlled trials say about virtual rehabilitation in stroke? A systematic literature review and meta-analysis of upper-limb and cognitive outcomes;In-Home Delivery of Constraint-Induced Movement Therapy via Virtual Reality Gaming.;Effects of Kinect-based virtual reality game training on upper extremity motor recovery in chronic stroke;Increasing upper limb training intensity in chronic stroke using embodied virtual reality: a pilot study;Leap Motion-based virtual reality training for improving motor functional recovery of upper limbs and neural reorganization in subacute stroke patients;Stroke recovery and rehabilitation in 2016: a year in review of basic science and clinical science;Effects of virtual reality for stroke individuals based on the International Classification of Functioning and Health: a systematic review;Does the use of Nintendo Wii SportsTM improve arm function? Trial of WiiTM in Stroke: a randomized controlled trial and economics analysis;What Is the Sense of Agency and Why Does it Matter?;Counteracting learned non-use in chronic stroke patients with reinforcement-induced movement therapy;Coaching or gaming? Implications of strategy choice for home based stroke rehabilitation;Post-stroke fatigue: a review on prevalence, correlates, measurement, and management;Constraint-induced movement therapy after stroke;CI Therapy is Beneficial to Patients with Chronic Low-Functioning Hemiparesis after Stroke;Virtual Reality Therapy for Adults Post-Stroke: A Systematic Review and Meta-Analysis Exploring Virtual Environments and Commercial Games in Therapy;What Is the Evidence for Physical Therapy Poststroke? A Systematic Review and Meta-Analysis;Plasticity in the Injured Brain;Connectome: How the Brain’s Wiring Makes Us Who We Are;Mechanism of Kinect-based virtual reality training for motor functional recovery of upper limbs after subacute stroke;Virtual reality for the rehabilitation of the upper limb motor function after stroke: a prospective controlled trial;Depression, activities of daily living and quality of life in patients with stroke;Arm Motor Recovery Using a Virtual Reality Intervention in Chronic Stroke;Maladaptive Plasticity for Motor Recovery after Stroke: Mechanisms and Approaches;Neurorehabilitation of stroke;Virtual reality in neuroscience research and therapy;Virtual Reality for Stroke Rehabilitation;The Stroke Association;Stroke rehabilitation;Potential for new technologies in clinical practice.;Creating an Interface Between the International Classification of Functioning, Disability and Health and Physical Therapist Practice;Apathy following Stroke;The neural basis of constraint-induced movement therapy;Exercises for paretic upper limb after stroke: a combined virtual-reality and telemedicine approach.;Observation of amounts of movement practice provided during stroke rehabilitation.;Repetitive Task Training for Improving Functional Ability After Stroke;Sense of Agency Primes Manual Motor Responses;Training and exercise to drive poststroke recovery;Principles of experience-dependent neural plasticity: implications for rehabilitation after brain damage.;Poststroke shoulder pain: its relationship to motor impairment, activity limitation, and quality of life.;The learned nonuse phenomenon: implications for rehabilitation.;Textbook of Neural Repair and Rehabilitation: Virtual reality in neurorehabilitation;Ambulatory monitoring of arm movement using accelerometry: an objective measure of upper-extremity rehabilitation in persons with chronic stroke.;A Virtual RealityBased Exercise System for Hand Rehabilitation Post-Stroke;Motor Impairment and Recovery in the Upper Limb After Stroke: Behavioral and Neuroanatomical Correlates;Reaching in reality and virtual reality: a comparison of movement kinematics in healthy subjects and in adults with hemiparesis;A Theory of Fun for Game Design;Mixed reality environments in stroke rehabilitation: Development as rehabilitation tools;Rules of play: game design fundamentals;The Fugl-Meyer Assessment of Motor Recovery after Stroke: A Critical Review of Its Measurement Properties;What are the components of effective stroke unit care?;Stroke patients' and therapists' opinions of constraint-induced movement therapy;Research on Presence in Virtual Reality: A Survey;Neurological deterioration in acute ischemic stroke: potential predictors and associated factors in the European cooperative acute stroke study (ECASS) I.;Impairment and disability: their relation during stroke rehabilitation.;From apoplexy to stroke.;Assessment and psychologic factors in stroke rehabilitation.;Motor learning after recovery from hemiparesis;Reliability of the Fugl-Meyer assessment for testing motor performance in patients following stroke.;RECOVERY TIME OF INDEPENDENT FUNCTION POST-STROKE;Neuropsychological impairments associated with lesions caused by tumor or stroke.;A Motor Learning Model for Stroke Rehabilitation;Reliability of the Fugl-Meyer assessment of sensorimotor recovery following cerebrovascular accident.;Long‐lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path;The information capacity of the human motor system in controlling the amplitude of movement.;Virtual Activities of Daily Living for Recovery of Upper Extremity Motor Function;Neurobiology of Sleep and Circadian Rhythms The role of sleep in recovery following ischemic stroke: A review of human and animal data;Motor learning and motor recovery in poststroke individuals: a review of the evidence;Virtual reality training for upper extremity in subacute stroke (VIRTUES): a multicenter RCT;Stroke Rehabilitation A Function Based Approach;The brain's way of healing : stories of remarkable recoveries and discoveries;Febr 25. Stroke deaths in England halved in the �rst decade of the 21st century;Using the international classi�cation of functioning, disability and health in physiotherapy in multidisciplinary vocational rehabilitation: a case study of low back pain;Contribution of the shaping and restraint components of Constraint-Induced Movement therapy to treatment outcome.;Random.org.;Contemporary management of motor control problems;Improving the sensitivity of the Barthel Index for stroke rehabilitation.;The Barthel ADL Index: a reliability study.;Cerebrovascular disease in the community: results of a WHO collaborative study.;ET019) who stayed longer in the hospital were evaluated three times. Nevertheless, data from only the �rst and �fth sessions were analyzed (Table 5A)"
        ],
        [
         "21",
         "008dbf8a0db8fa34cd847d7937b8ddbd2c0b37df",
         "Journal of Experimental Psychology: Human Perception and Performance",
         "0",
         "Medicine",
         "2025-01-23",
         "2151524023,123060968,3602422,4288646",
         "Maura Nevejans,J. Wiersema,J. de Houwer,Emiel Cracco",
         "2025",
         "s2",
         "0.0",
         "https://biblio.ugent.be/publication/01JD53YTP2RKAS44E416FSWMXW/file/01JD54148HSWY3634VH3MMMV6V.pdf",
         "",
         ""
        ],
        [
         "22",
         "00912d6c3d3e9316039ba93baafbbdce9f19414a",
         "International Scientific Journal of Engineering and Management",
         "1",
         "",
         "2025-03-16",
         "2350750960,2350788421,2350750977",
         "Dr. Radha P,Akshayaa S,Vishnu Sree T",
         "2025",
         "s2",
         "0.0",
         "https://dspace.library.uu.nl/bitstream/handle/1874/390597/1_s2.0_S1071581919300552_main.pdf?sequence=1&isAllowed=y",
         "",
         ""
        ],
        [
         "23",
         "00a9a436e7eb5e57de9231fc28b57e8452f45f4c",
         "bioRxiv",
         "0",
         "Biology",
         "2025-03-07",
         "2289486984,34337069,2316858491,2316857892,2353009588,2267763616",
         "Jinru He,A. Klimovich,Sabine Kock,Linus Dahmke,Sören Franzenburg,Thomas C. G. Bosch",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/21/2024.08.20.608462.full.pdf",
         "4edec8a87a12ae490c5514d826ba87c102acb818;86350230568af77a534b914a2a9dff7cdeb6bbb4;b150ffd0dfbaafc78f5a4bca1cdfa8a309edf05b;bc2ff5c0668b1c6d3b8849e472f8a106895cfef5;78b6f1dc0b633d47805a3422c61bf5dc42df1267",
         "The Role of Lung and Gut Microbiota in the Pathology of Asthma;Mouse Microbiota Models: Comparing Germ-Free Mice and Antibiotics Treatment as Tools for Modifying Gut Bacteria;Punctuated Emergences of Genetic and Phenotypic Innovations in Eumetazoan, Bilaterian, Euteleostome, and Hominidae Ancestors;EST Analysis of the Cnidarian Acropora millepora Reveals Extensive Gene Loss and Rapid Sequence Divergence in the Model Invertebrates;Elimination by Hydra interstitial and nerve cells by means of colchicine."
        ],
        [
         "24",
         "00b75582f7204b1bae67a6c5f2fa1652d94c7ce0",
         "bioRxiv",
         "1",
         "Biology",
         "2025-03-09",
         "2267263008,2185763914,2184721903,2158130076,2349787616,2328903866,2267253672,79635348,2257371765,2171794777,2267250090,2256760771",
         "Haoran Sun,Liang He,Pan Deng,Guoqing Liu,Zhiyu Zhao,Yuliang Jiang,Chuan Cao,Fusong Ju,Lijun Wu,Haiguang Liu,Tao Qin,Tie-Yan Liu",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2023/11/17/2023.11.16.565910.full.pdf",
         "277fcf6c9077209c88b1f94cb160c50306b03f8a;805d4dfa665dd24d2fd377e6e69899ee8b9e2d29;9ffc8d59270b01def8bde81a8ec1d759a2029dbb;646053255a924d51e0b6c8727d8e165dde0fc1f1;2c06f01b93acaf9e32331164d1dec4637e41758a;70637f3188a3e44ce059df3adaaede2c774c062d;1675abb8bd2f6725cbdab46f8c406c4278a923df;b7d8827822ba31344a528b9f6e9dd5b7d3a8a50f;c49a0912595a1cc70aab63524f64ed08c92194a8;126c2e0717b57053ba58e8b93e72cc25252a6b9b;e18c67b402c402522adee63d53e7dcb0406be2b7;e75484a56e50db049fce9dc3c0b6d96a786f4cf5;65a3d36f9fb7b141ca59f94c2e4af4db7548a39a;832aa77be74d7d3a8b33b9abc0f48b8b7babac12;7e08e5ec38e1736377e630132512508629cbc753;8fedd23c1604dfeed02b75f8d38c1d7e33beee3a;d766bffc357127e0dc86dd69561d5aeb520d6f4c;cde0a9d774345889598760b5f6b681ca1c68aa3b;3141e5cf27e69e5e8bd8b5c6cc97c23380e8a9c1;48d436d6be896cd04d56c419d426d0a06f632e96;34d079f9fae009fbaf77293163ee6084eb328182;0537c62e32299b8e9b4e3cac44d82ffa123cbbe1;4a6b4f64cad5907d4fbdb3514082e3d160cff39b;dc32a984b651256a8ec282be52310e6bd33d9815;0cfce36622a017a86c2248ebe5dfdd0f8d643df7;04f496f922410653523ddec50880dce165fa721f;b103e87c7727134927d3ffb06934a95c10c02fc0;460ed165c11c3ee5aadc99a674a7c8bdd1405867;a7631698b323ece069ba742266cb9437b5815f2c;c58487f55480c48c0493508ab85a98278f629bef;e63fcc112e08285089908b796702c4c5e105c143;ca9b4fc03ad3ea4680ab2204ecf215f333c616a4;9392f11732c22a1de9db34cf4d8c20d54f544658;821400c84cf2d2f08d12f2fcbba4bcd881cb2088;43f2ad297941db230c089ba353efc3f281ab678c;9cfe870e09f627e2814572aa4e1e7bff8b657fc5;ca1303c9f01ec18a1c8421c5d30925dae064f32b;0668abf02644a52649dffa3160fe3e251d84f779;35f85c3697fd3f5082955a27e234108ce43ce260;abb8c7535d62e5cfaa7332df2479312779988fb4;3c3a2316da91f714f95f8802d6363954024f969c;18a93dc1558bf9d7534d0b416633cebaf75c1145;b49c5ff86c1693fac2706e710949ef8bd873448c;079af46a5f5cca12f1b8856882c8d915e3641cd4;e0a7ab724afc4a598df7cfb39352b21f1b7f8c3e;5e5039e11f3289fc69743c1ba08cd293b0481d0d;49ce5d0021e8bf54ffa2f3268d6a94716b15b7bf;93db9f3b59efd5fd1fcf394434d9cb4aa55ab39f;a47483dca56d93dabc54c8d49a5d03c6fb1e9771;dce6f9d4017b1785979e7520fd0834ef8cf02f4b;204e3073870fae3d05bcbc2f6a8e263d9b72e776;27285d688d1e5752721f022086775638f49683b7;675c3c958640275c2cbafbbcf4973d4c8183549b;0e4258c03e02b0b00d3b386eb954b76c20638eb5;0ade7466e653b3c63674a641780bae72f485c237;ca54ea94ee62aca168f2cb64ec9e3a8606a943c4;a918eb58b148e63d38e1975cecb72a30d02d9cc3;6847551eab200bfa3ef1b19ab2c27aba592aa25b;a5f7c631df9c013ffff1f4420fb45705bdec8e50;795dc87b4727b303d3672539e4578d41dfd3aeb3;238517ecdc0466ec6a25b79319c3a6b473a897c8;a0be445ff2ab38daa61b0db9bb9a531a1e9fd80d;31461c845988606aee12514c071561f8251e473c;a10a405e1529fa3453495d007b1572274b9fb8bc;20db407872faefe075600edc5904b0f6c56dc845;3b523d1dd94579a03ca11c9db739448a67aad639;051f851112b1ace45c86a4d37f0478a3e5d2fa6d;b1d623c7aafa02487d038af433a60c0a444a9db6;f38d1bafa26e66d4238ebc8855ccb680391c9de0;54fe7cbddac43b1bb400193798c78e76d94e6182;7d94c58d1e7bd4f732486bbb0f5681ada85d9333;40e4a7db035c885cb128e108c7f3526f67401e33;0f46b04e1c834cc6160ef44c0402f3e2f40562dd;1c0f772ace99cb7de3667f0776e2ea9e6c95f087",
         "Network of epistatic interactions in an enzyme active site revealed by large-scale deep mutational scanning;Contrastive Fitness Learning: Reprogramming Protein Language Models for Low-N Learning of Protein Fitness Landscape;Convolutions are competitive with transformers for protein sequence pretraining;ProteinNPT: Improving Protein Property Prediction and Design with Non-Parametric Transformers;Self-play reinforcement learning guides protein engineering;Improving protein optimization with smoothed fitness landscapes;Efficient evolution of human antibodies from general protein language models;Enzyme function prediction using contrastive learning;Evolutionary-scale prediction of atomic level protein structure with a language model;Learning Epistasis and Residue Coevolution Patterns: Current Trends and Future Perspectives for Advancing Enzyme Engineering;SPRoBERTa: protein embedding learning with local fragment modeling;Insertions and Deletions (Indels): A Missing Piece of the Protein Engineering Jigsaw.;Proximal Exploration for Model-guided Protein Sequence Design;Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval;Mapping the energetic and allosteric landscapes of protein binding domains;Machine learning-aided engineering of hydrolases for PET depolymerization;Training language models to follow instructions with human feedback;Learning protein fitness models from evolutionary and assay-labeled data;Can AlphaFold2 predict the impact of missense mutations on structure?;FLIP: Benchmark tasks in fitness landscape inference for proteins;Pre-training Co-evolutionary Protein Representation via A Pairwise Masked Language Model;Disease variant prediction with deep generative models of evolutionary data;ECNet is an evolutionary context-integrated deep learning framework for protein engineering;Highly accurate protein structure prediction with AlphaFold;Language models enable zero-shot prediction of the effects of mutations on protein function;Deep diversification of an AAV capsid protein by machine learning;GPT-3: Its Nature, Scope, Limits, and Consequences;Is Transfer Learning Necessary for Protein Landscape Prediction?;Neural networks to learn protein sequence–function relationships from deep mutational scanning data;AdaLead: A simple and robust adaptive greedy search algorithm for sequence design;The genetic landscape for amyloid beta fibril nucleation accurately discriminates familial Alzheimer’s disease mutations;ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Deep Learning and High Performance Computing;Learning the language of viral evolution and escape;Model-based reinforcement learning for biological sequence design;5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding;Low-N protein engineering with data-efficient deep learning;Comprehensive AAV capsid fitness landscape reveals a viral gene and enables machine-guided design;Prediction of mutation effects using a deep temporal convolutional network;Drug resistance and combating drug resistance in cancer;Using deep learning to annotate the protein universe;Pervasive Pairwise Intragenic Epistasis among Sequential Mutations in TEM-1 β-Lactamase.;Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences;DeepGOPlus: improved protein function prediction from sequence;Conditioning by adaptive sampling for robust design;Deep generative models of genetic variation capture the effects of mutations;Multiplexed assays of variant effects contribute to a growing genotype–phenotype atlas;Quantitative Missense Variant Effect Prediction Using Large-Scale Mutagenesis Data.;Evolutionary Trajectories to Antibiotic Resistance.;Minimap2: pairwise alignment for nucleotide sequences;Proximal Policy Optimization Algorithms;Attention is All you Need;High-order epistasis shapes evolutionary trajectories;Mutation effects predicted from sequence co-variation;Beta-lactamase database (BLDB) – structure and function;Epistasis in protein evolution;Local fitness landscape of the green fluorescent protein;Survey of variation in human transcription factors reveals prevalent DNA binding changes;Evolvability as a Function of Purifying Selection in TEM-1 β-Lactamase;A Comprehensive Biophysical Description of Pairwise Epistasis throughout an Entire Protein Domain;UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches;Deep mutational scanning: a new style of protein science;Empirical fitness landscapes and the predictability of evolution;A Comprehensive, High-Resolution Map of a Gene’s Fitness Landscape;Deep mutational scanning of an RRM domain of the Saccharomyces cerevisiae poly(A)-binding protein;Capturing the mutational landscape of the beta-lactamase TEM-1;A fundamental protein property, thermodynamic stability, revealed solely from large-scale measurements of protein function;SIFT web server: predicting effects of amino acid substitutions on proteins;PyRosetta: a script-based interface for implementing molecular modeling algorithms using Rosetta;Stability effects of mutations and protein evolvability.;Balancing Robustness and Evolvability;Darwinian Evolution Can Follow Only Very Few Mutational Paths to Fitter Proteins;The distribution of fitness effects among beneficial mutations.;Introducing ChatGPT;Learning Mutational Semantics;Natural Selection and the Concept of a Protein Space"
        ],
        [
         "25",
         "00f1e24ed9abc1d314d58bad653da4de8e95539e",
         "bioRxiv",
         "0",
         "Biology",
         "2025-02-07",
         "51066936,2239858785,2265653135,30005641,2243713122,2250574407",
         "Felix Langschied,M. Leisegang,Stefan Günther,F. Hahner,Ralf Peter Brandes,Ingo Ebersberger",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/09/2024.12.05.627021.full.pdf",
         "",
         ""
        ],
        [
         "26",
         "010775b2dc942000269badbc223b65a9b9c67e05",
         "International Conference on Machine Vision",
         "0",
         "",
         "2025-02-25",
         "67097589,2282530824,3327507,2220657884",
         "Yunusa Haruna,Shiyin Qin,Adamu Lawan,Abdulrahman Hamman Adama Chukkol",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2408/2408.13160v1.pdf",
         "",
         ""
        ],
        [
         "27",
         "01214e9843a9cb75620b8f1af6eee62236745c96",
         "bioRxiv",
         "0",
         "Biology",
         "2025-04-14",
         "2218662337,2087688653,2334465897,2334520393,2313747284,2333967919,80869767,2110468988,1753521106,144057176,2334521155",
         "Shuntai Yu,Guoliang Yin,Peng Jin,Weilin Zhang,Yingchao Tian,Xiaotong Xu,Tianyu Shao,Yushan Li,Fei Sun,Yun Zhu,Fengchao Wang",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/07/2024.12.03.626701.full.pdf",
         "",
         ""
        ],
        [
         "28",
         "01229dfa2329d554185174e6705a95fae143cf63",
         "bioRxiv",
         "0",
         "Biology",
         "2025-03-23",
         "2279892914,9014548,2279894377,1471212777,2316328160,2256102009,2256100373",
         "Dabedatta Dash,Fumiaki Iwane,William Hayward,R. Salamanca-Giron,Marlene Bonstrup,E. Buch,L. G. Cohen",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/15/2024.08.15.608189.full.pdf",
         "",
         ""
        ],
        [
         "29",
         "013cb58c3526d64e0f8e0d18d71c57250eaa0db2",
         "bioRxiv",
         "1",
         "Biology",
         "2025-02-11",
         "3083562,40259332,4993063,6294722,2261744330,5202463",
         "A. Perry,Joan K. Beaton,J. Stockan,G. Iason,J. Cottrell,S. Cavers",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/20/2024.08.20.608769.full.pdf",
         "68f2bbbb6c4a7a47f62123dc5ede6dcab06185f1;634193909d96a5f49fd2e32aa3efbcba99d0a145;6bf7b936954f45c6bae49d0a8ed9767bf59dd549;545dc5fe906c9c06a8f5aa76b97465e0edc5dbaf;a533606f0001dd5c7ab65863ea871d451102eca2;e34a6f34395f06631fa10ea9e1c2074faff0ff90;44a7d15987553e17a12d5c41fe6ac552881c20eb;6ac638500a919ad8d35f6c2d056b27b760f89723;7d7a83bb31c17511bf3af92f2bfc41b69ce4ce39;c4efa6be19614d943031d0ed4963712406f69ad3;2eda87bd20b3c7a7925bd8d46beb74cfdc6760bb;ce2e127a76809a170fb3e497ea035315ed1aec1a;fc5ef641cff64275fca067cf493ce5122fc07036;a0652d2c46744c9ad7a9ab36885b7d09f9ca4fb0;cb45eb725eee0e9dfd7749c24641afda94289419;165ab0bcde1f80965563a10e968424b176773f76;11f4e8a9ba7b480600703998e54f0f6e7a293231;69ebbd1299ac9b1db121b45dac14b943cdaa2fe7;6e0369af30c8a52fe40a4066b5233416a920f031;94560b886e674d2111eda6600646598bfd03af88;67edcf8e927f39268778be1176ba4737d08def11;3650f71f5b1c307336946e8173769d1601a7b96c;0d53e6631a48a864496b98a9c438230fe1412906;b1efaad71fdc2b532203ddd73fb16b6f6d0e6ef5;d6c72391f565b973032b13fd14d0b7d66c57757c;b3af3c33a32c69333a997a4e27cfffdc7912d305;36629961a3e68527ad128fae880626491a91f3ad;cd42d586dc8eb605e322d2c2d87dc7c1ce50b575;a63f6e60cd55c4e4fefe9f378e3feded2edac8c6;524f9b31dc53fca19846f5a15da3afd63c3ca3ec;2c0c7327e3c373ca0852f7721d28fd6cb8fd43c5;fe6f1e6a8fce05f0d717b9924172d7cbf4c08864;b42b639358029f5724b0b6aea2df0743ed0c3e4b;2a030eba8aa438fd2c93ee1b58dcf75e0c95a735;42435a57486bc4ef5c8606ab84acd2ff0fcd87c7;47ea95c4f1f39fd443d5bba361f92a444ce255e7;9cfd46949708c08bd052a3324e025cb50b32d153;a860a438904acb644ae9ff1c30a8db55e5459286;c850ef64b05740c911951f9527415aee1b632ed3;3ef577e60ddf5e9f596d68b2f61e11482bc395a2;b6834a414f1c9aac1b32ee35c922971f0a8b435e;e86ca8d829ae00253b72836f5a291d9dff4addca;f77afd6a4d437a824fcdb2700b8c5adf72833f13",
         "Meeting tree planting targets on the UK's path to net-zero: A review of lessons learnt from 100 years of land use policies;Phenotypic trait variation in a long-term multisite common garden experiment of Scots pine in Scotland;Explaining Extreme Events of 2020 from a Climate Perspective;Phenotypes of Pinus sylvestris are more coordinated under local harsher conditions across Europe;Selection patterns on early-life phenotypic traits in Pinus sylvestris are associated with precipitation and temperature along a climatic gradient in Europe.;Reaching Natural Growth: The Significance of Light and Temperature Fluctuations in Plant Performance in Indoor Growth Facilities;Guidance for successful tree planting initiatives;Cryptic genetic variation and adaptation to waterlogging in Caledonian Scots pine, Pinus sylvestris L.;Age–age correlations and early selection for growth traits in 40 half-sib families of Larix principis-rupprechtii;Pampered inside, pestered outside? Differences and similarities between plants growing in controlled conditions and in the field.;Has Scots pine (Pinus sylvestris) co‐evolved with Dothistroma septosporum in Scotland? Evidence for spatial heterogeneity in the susceptibility of native provenances;Bud flush phenology and nursery carryover effect of paper birch provenances;Age trend of heritability, genetic correlation, and efficiency of early selection for wood quality traits in Scots pine;Plant growth and mortality under climatic extremes: An overview;What controls tropical forest architecture: testing environmental, structural and floristic drivers;Cultivation of Norway spruce and Scots pine on organic nitrogen improves seedling morphology and field performance;Seasonal patterns of photochemical capacity and spring phenology reveal genetic differentiation amon;A Large and Persistent Carbon Sink in the World’s Forests;Efficiency of the indirect selection and the evaluation of the genotype by environment interaction using Pilodyn for the genetic improvement of wood density in Cryptomeria japonica;A method to construct dose-response curves for a wide range of environmental factors and plant traits by means of a meta-analysis of phenotypic data.;Evaluation of leaf traits for indirect selection of high yielding poplar hybrids;The physiological basis of containerised tree seedling ‘transplant shock’: a review;Age–age and trait–trait correlations for Eucalyptus grandis Hill ex Maiden and their implications for optimal selection age and design of clonal trials;Effects of soil temperature on biomass and carbohydrate allocation in Scots pine (Pinus sylvestris) seedlings at the beginning of the growing season.;Effect of Peat-based Container Media on Establishment of Scots Pine, Norway Spruce and Silver Birch Seedlings after Transplanting in Contrasting Water Conditions;Current and future status of Scots pine (Pinus sylvestris L.) forests in Europe;Heritable variation and evolution under favourable and unfavourable conditions.;The nitrogen economy of mountain birch seedlings: implications for winter survival;Effect of diurnal temperature alternations on plant morphology in some greenhouse crops. A mini review;Seasonal and geographical variation of terpenes, resin acids and total phenolics in nursery grown seedlings of Scots pine (Pinus sylvestris L.);Effects of root temperature on growth and photosynthesis in conifer seedlings during shoot elongation.;Nestling growth in the Great Tit I. Heritability estimates under different environmental conditions;Accelerated short-term genetic testing for loblolly pine families;Effects of Photoperiod on Growth of Trees;Autumn versus spring planting: the initiation of root growth and subsequent field performance of Scots pine and Norway spruce seedlings;Photoperiod- and temperature-mediated control of phenology in trees - a molecular perspective.;GENETIC SURVEY OF PINUS RADIATA. 5: BETWEEN-TRAIT AND AGE-AGE CORRELATIONS FOR GROWTH RATE, MORPHOLOGY, AND DISEASE RESISTANCE;Plant Growth and Climate Change.;Low temperature, but not photoperiod, controls growth cessation and dormancy induction and release in apple and pear.;Selection of parents for the Scots pine breeding population in Britain;Using Native Stock for Planting Native Trees and Shrubs;On the sampling variance of interclass correlations and genetic 786 correlations;Genotype by environment interaction and genetic 795 correlation of greenhouse and field performance in Pinus contorta ssp. latifolia . 796 Silvae;Forest nursery practice.;Effect of fertilization and watering of Scots pine seedlings on the feeding preference of the pine weevil (Hylobius abietis L.).;Tree planting: not a simple solution;Applied Tree Improvement;Growth response of woody plants to photoperiodic stimuli;Table 1. Traits measured in individual seedlings, grouped into ‘Growth’, ‘Form’, ‘Phenology’ and ‘Survival’. Units for;age of the trees increased and as the number of years between comparisons decreased;through to maturity. The trees in this study have now been transplanted to three field;organisms grow should lead to higher or lower heritability of quantitative traits;Introduction to Quantitative Genetics . 4th ed. Essex, UK: Longman, 1996.;variances when data from 2007 are not included. For traits measured in multiple years, only the most recent year is shown;transplanted to their field locations, as measurements can be made over many more years"
        ],
        [
         "30",
         "0142fc80cb50bb72904e314218eaebac59ddfa68",
         "bioRxiv",
         "0",
         "Biology",
         "2025-02-28",
         "40557803,2300078674,4854131,152563647,40067986,1766623,2240377,3501875,2238425153",
         "A. Luca,Tine Swartenbroekx,H. Seelaar,J. V. van Swieten,Suheyla Cetin Karayumak,Y. Rathi,O. Pasternak,L. Jiskoot,A. Leemans",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/05/03/2024.05.01.591994.full.pdf",
         "f936262abe82472e654a020573d897df67032b73;587b07794826ba1a259b8a81c081be2e45a9d399;a0916d400cf6bbeaa0183e4284c254a3b03dfeaf;f80c6027ff2c0909c3b312dc88c8d582c7bafa46;a5119a9c4e77a55a02fe36ea8ade90bb347d26d2;4e5c9eb2663855ed9ddc2595f909b2562b2abdae;a1f06e9a11c6ce9a4aeb0b16111013c533722b74;9ef5e445034d499713ab66f59bd72ecb8684f408;246e03f202de45ea583e14ad55ce5a5de16a66a8;92a2cf9910a4b9a951450a5f9bd052afb77b3731;01021c0be1f4f5949dd735b9b6d16f7cf3fe4eb2;1ed8e2134e45dace29969012e73d32c66d3b2d43;d6dd530802cbb4e49e785b27163f3055a97a9925;9ec1caf9435cb43a8043da965b194d9bf40c87b6;cacfffc6b93abfd8d83ff12f1f578de240ecf6c3;03a360e29a0388e3aa24e713e57815a4177ccf73;bb94aeae150a91408a83d9d6dd8f4d7653c258ff;27f9fd4a9940f68da8ae507c8fdea8f87d8cb0a2;e83c898be03948e7e2fdf0e489fdb0b835e1bb6f;a48ee96ec29683f8d135985219d6b6c10f643033;5cb233988e355605d3deb74de3055447f239ae29;c795a295222bb65cdc3474b48a4350fe2224a09e;2fb7811eed842bf44eb28491f052f3cd37237249;262293db5668fca6b547d579dfbc1b7929e75cb4;5f60ecf17abd6a1983768bf567257126669aaeb0;87fa2bc1a94d9dc5c0fe57a449f18a606275ecce;37d20f6992bba95a418d60ea32c9c7c141672289;eade28d9ee7bd8acc855d3dbcb5161181a430193;21e4b4fbdcaa90b32c56a87a1896751b559e9b64;2dd32ff6608812d9b5d3877340df1cf9fceda08f;453464f815d29dbec5ff7a5afee5100aafa2baa0;7f5fc390ddbcb8cfdeb9ec7d26a32651ad253d21;dc46f1bb1073d5f533ff2141e650267b9e2124d1;66287e72a366ae6f154b3d76001b5641e65f3750;9a8a061834350b7434bbbdd6ef75aefb39eea38b;f92f4418d4a4523a5760414144ecce8ab6472fde;427eaafcd47b3abc620b953ff021f25925ff0e62;2bab19d59e953df2e28cd9d868e769dfc448cc7f;8cb01b154ae81d71a82bfcbacd6de6761891b208;da586e64082236180bb3f48d664d2c5b7fccaebb",
         "Lifespan reference curves for harmonizing multi-site regional brain white matter metrics from diffusion MRI;Neuroimaging standards for research into small vessel disease—advances since 2013;Abnormal white matter changes in Alzheimer's disease based on diffusion tensor imaging: A systematic review;Improved sensitivity and precision in multicentre diffusion MRI network analysis using thresholding and harmonization;Multimodal tract-based MRI metrics outperform whole brain markers in determining cognitive impact of small vessel disease-related brain injury;Cross-site harmonization of multi-shell diffusion MRI measures based on rotational invariant spherical harmonics (RISH);Diffusion MRI harmonization enables joint-analysis of multicentre data of patients with cerebral small vessel disease;Towards multicentre diffusion MRI studies in cerebral small vessel disease;MarkVCID cerebral small vessel consortium: I. Enrollment, clinical, fluid protocols;Cross-scanner and cross-protocol multi-shell diffusion MRI data harmonization: Algorithms and results;A prospective harmonized multicenter DTI study of cerebral white matter degeneration in ALS;Generalized Richardson-Lucy (GRL) for analyzing multi-shell diffusion MRI data;Cross-scanner and cross-protocol diffusion MRI data harmonisation: A benchmark database and evaluation of algorithms;Scanner invariant representations for diffusion MRI harmonization;Retrospective harmonization of multi-site diffusion MRI data acquired with different acquisition parameters;Inter-Scanner Harmonization of High Angular Resolution DW-MRI using Null Space Deep Learning;Presymptomatic white matter integrity loss in familial frontotemporal dementia in the GENFI cohort: A cross‐sectional diffusion tensor imaging study;On modeling;Current Clinical Applications of Diffusion-Tensor Imaging in Neurological Disorders;Harmonization of cortical thickness measurements across scanners and sites;Harmonization of multi-site diffusion tensor imaging data;The importance of correcting for signal drift in diffusion MRI;Denoising of diffusion MRI using random matrix theory;Inter-site and inter-scanner diffusion MRI data harmonization;The effect of Gibbs ringing artifacts on measures derived from diffusion MRI;REKINDLE: Robust extraction of kurtosis INDices with linear estimation;Lifespan maturation and degeneration of human brain white matter;Faculty Opinions recommendation of Tract-based spatial statistics: voxelwise analysis of multi-subject diffusion data.;Diffusion MRI at 25: Exploring brain tissue structure and function;A reproducible evaluation of ANTs similarity metric performance in brain image registration;Microstructural maturation of the human brain from childhood to adulthood;Empirical Bayes Methods;Harmonization;Toward a quantitative assessment of diffusion anisotropy;Matter;multimodal brain 3 T MRI harmonisation approaches;presymptomatic familial frontotemporal dementia;ExploreDTI: a graphical toolbox for processing, analyzing, and visualizing diffusion MR data;Adjusting batch effects in microarray expression data using empirical Bayes methods.;Microstructural and physiological features of tissues elucidated by quantitative-diffusion-tensor MRI.;MR diffusion tensor spectroscopy and imaging.;Spin diffusion measurements : spin echoes in the presence of a time-dependent field gradient;Submitted to Magnetic Resonance in Medicine Corresponding author: Alberto De Luca (a.deluca-2@umcutrecht.nl) Word count: 3924 words;Discussion: RISH-GLM can learn cross-site harmonization both from matched and unmatched groups training subjects, and can effectively be used to harmonize data of multiple sites in;This study is funded by the Bluefield Project to cure FTD;determined with RISH-GLM on data from all three sites in Experiment 3"
        ],
        [
         "31",
         "0155e40ceb6ddc83a93fb431cc86ebe135079cab",
         "Quantum Information Processing",
         "0",
         "Computer Science",
         "2025-01-24",
         "3398784,2152266603,2258620721,2238169673,2342246044,3398895",
         "Yao-Kun Wang,Li-Zhu Ge,Tinggui Zhang,Shao-Ming Fei,Yufeng Gao,Zhixi Wang",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2408/2408.03797v1.pdf",
         "",
         ""
        ],
        [
         "32",
         "016c339d6bd3cbd60275c86ff645ffc29b6ea8e7",
         "Welding in the World",
         "0",
         "",
         "2025-01-04",
         "1896285286,2311643684,2311460362,2243100227",
         "Chunkai Li,Yu Pan,Yu Shi,Wenkai Wang",
         "2025",
         "s2",
         "0.0",
         "https://www.researchsquare.com/article/rs-5274598/latest.pdf",
         "43003bfcc6b3956a0aa99e6f5ee8133a59904059;b6662581062e1c42ad94b3458d343b5aa3825f78;a0d404a581df437d773a5706db0a55cfe38b256e;3bf0426ae6b7ce9ba2d97aad1d6f761c9ea5aa85;3efcb2b21cdb1497320d6b82c149677207446617;2b18882b5583db1b7de5e0e45ae04865b169b93e;351d2bdb0c2350e826ad7b251e17b3413796806c;1bf81ae9731f04f0913eacea17e55b49547105c2;fb9491f6d3ee2e7d4737ad21150ae2c0eb366604;ece66b29fbfd8ab4b26d70a78cc10cbce47a3620;b85e9fbd284e212833f802cfcd7047154ef2f96a;edad3fc07e6192440c590ec60660d40a6b386843;d40f6c80619d26f7a8aad5175aa274a258900d66;82687665e5cffab3940a867617a88412c60e1409;dad0e6b34be3632611e2578b4c40da2c3e26c4f2;62130eeb70a07294ad86306fbab56f40784e10ac;6420669f58a81381b8e1961e71750a4057e6d5c4;a6cc9032b1d6ffef4385c9e6c1090f7237e9ee63;63af0e90729f983539a0eaba62eaf04b61926a70",
         "Searching optimal process parameters for desired layer geometry in wire-laser directed energy deposition based on machine learning;MeltPoolGAN: Auxiliary Classifier Generative Adversarial Network for melt pool classification and generation of laser power, scan speed and scan direction in Laser Powder Bed Fusion;Improving the deposition efficiency and mechanical properties of additive manufactured Inconel 625 through hot wire laser metal deposition;Prediction of melt pool geometry by fusing experimental and simulation data;Predictions of Additive Manufacturing Process Parameters and Molten Pool Dimensions with a Physics-Informed Deep Learning Model;Evaluate the effect of melt pool convection on grain structure of IN625 in laser melting process using experimentally validated process-structure modeling;End-to-end prediction of weld penetration: A deep learning and transfer learning based method;Computational fluid dynamic simulation of gravity and pressure effects in laser metal deposition for potential additive manufacturing in space;Benchmark Study of Thermal Behavior, Surface Topography, and Dendritic Microstructure in Selective Laser Melting of Inconel 625;Comprehensive modeling of transport phenomena in laser hot-wire deposition process;Laser Direct Metal Deposition of 2024 Al Alloy: Trace Geometry Prediction via Machine Learning;Experimental investigation of laser hot-wire cladding;Experimental study and modeling of H13 steel deposition using laser hot-wire additive manufacturing;Thermal Transport Regimes and Effects of Prandtl Number in Molten Pool Transport in Laser Surface Melting Processes;Thermophysical properties of solid and liquidInconel 718 Alloy;The modelling of heat, mass and solute transport in solidification systems;A fixed grid numerical modelling methodology for convection-diffusion mushy region phase-change problems;Prediction of Melt Pool Shape in Additive Manufacturing Based on Machine Learning Methods;Volume of fluid (VOF) method for the dynamics of free boundaries"
        ],
        [
         "33",
         "0173b93515e9956fc5942d3efeb00da8c5edb506",
         "IEEE Transactions on Information Theory",
         "0",
         "Computer Science",
         "2025-04-01",
         "2346578523,2256730709,2351460215,2345462702,145774050",
         "Kuan Cheng,Elena Grigorescu,Xin Li,Madhu Sudan,Minshen Zhu",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2308/2308.14993v2.pdf",
         "",
         ""
        ],
        [
         "34",
         "0183a6ebd27de31937b97dbed8d5736d0711d0cf",
         "Proceedings of The 41st International Symposium on Lattice Field Theory — PoS(LATTICE2024)",
         "0",
         "",
         "2025-01-13",
         "2328011787,2249529536,46659858,2153574931",
         "Diaa E. Habibi,Gert Aarts,L. Wang,Kai Zhou",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2412/2412.01919v1.pdf",
         "",
         ""
        ],
        [
         "35",
         "01891feafb883a81f4c532208e34dcb5806d8ca5",
         "International Microbiology",
         "0",
         "Medicine",
         "2025-02-12",
         "2281168561,2344980752,89314229,8050600,13894937",
         "Mehmet Aytar,Demet Yalçın Bingül,M. Touray,D. A. Uygun,Gamze Başbülbül",
         "2025",
         "s2",
         "0.0",
         "https://www.researchsquare.com/article/rs-5304452/latest.pdf",
         "",
         ""
        ],
        [
         "36",
         "019ef776513d52beff1271152eb2b8c7890bb531",
         "bioRxiv",
         "0",
         "Biology",
         "2025-05-05",
         "4273214,2359438636,47603291,3887239,2224469001,35079590,6311397",
         "Eva Malacaria,Carolina Figlioli,Anita Palma,S. Rinalducci,Maurizio Semproni,A. Franchitto,P. Pichierri",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2022/10/08/2022.10.08.511087.full.pdf",
         "ab64ad64a624fd2bfd9962349e3399b41435b0b0;65239dce5b68e29037e60c4f83d89fb2ced47c00;8f8d7cbb10e6f9ced4269c3c9d9c00207a37fa60;c77ed220049d1fa31c1cf0bf76046eb9d8dd74cb;073b14e3146e96f3d32f7d0dc54dff2f3628031f;ddd5ef0b192838b61c4ff6ea64e5131e00a57d08;ff579065fbb2f4899e2fa7528919a112f81623d5;fcf53a927675dda97d32cb039119e6803fa8fd8f;6b5e1ea8539b247963d766cacc5d3241a8662e19;70a84e5122b981a54ead95aa6127940646598dd4;512f3a3050ded091a6429753476ed852f7c05b64;8616ea47106d670e83573b6d337dc9a26a4368ca;5a07c72717f46fbd87b5560cc94551bbe2cd7398;096b258e585bfb83659d4189c5255cfaaebbf4a1;bb65d823a86094b98475bdcd4b0da3eff5f94257;3cd51350de2e7d78ede1715ab88ba7fd935a32aa;e01abff36ce63e635439e95287c85a55f2fc45c5;98799c400740d544b4b308d4c11706b15e10ec6d;a04e60ef0369acdecafe2cf7e3fa179c767f77cb;064e8d3afbe9f2f21695816d6cbfecb18fce8a84;50075633f7a799674109385240e5dbb91cf2cffe;3b6725fec49b1f0cf31d1e7c35433dc1a1e253d6;8f17f833f8cefdd5d6e69bb3ab293a187322186f;43762cc9f1429b26d61d7d7f999649502d611313;69f7ead03db5a5cd911d00ed816d44cd0f4ac1f9;6402460a2b9b06bee96aff135ff63d254093fbca;e4cf3fdea8cba63d54e214d11a60af0cff0f2475;385ecc840cbc458e5c30229c8f4f12e525f59718;4ceeb9c8904b179fc3622e4aa5cd28475eb8322d;23269d31899ea393bdb5a6b5965203f64e2d860f;21fd7be801f13c55111189440b1c3fe5ffa563ef;e3677d87231dc1074609e7bb29408e8ab8198072;3a8b2b81fc1cc805f7263a9b07f0c2ce1059c776;ef0cd5972bbab116323c32efce7905d34f61504c;31b3abfe010d4cd4ae68e3832611984a9d515393;afa07e9d9c1dc58f54a835c5a67d60b52a84e4c4;deea97031cb295304f3430ba3c38fd71f181f819;b6bad2a724d44a714f75c684f6b30a1d714d6f78;77e5fb12bb54aebede9883d3d05d43db9b4698dd;19028e2fdce5b7bf0da666eafeeaf443f8ee05d8;37491b16e39d0937966797c2e967bd0f42575be4;ff9bb95e5809f6e3cb2613568a6c6708270aec23;18028b8485b608ae2b34f0de7bcba839b0efe08f;cde006f13ed60a98b088615da9cfef6289181210;2f7c168428706bc57e4835d466c0589ea6d3b7ed;656c045f05fd3861373b5f82395ed91d8a899138;3b33dc9f2fa28694e7eda381b23f755deda687db;d11cf98be3e58bf406a5c79465f83499eb31be48;afb8a27885cd9a46f9e4b79654b7f572344aeae3;bb48b7cdb289e597d4e54e93c233fdf302332620;c7e84567131e71be67baa0c983ef502c2eba7d61;335557edb762d141ab6c4883e2444e69ba021074;14bcce09102de96c1e45f14a5692728794d40388;84870387dde54d3b2663dbcdc612d36e15af036f;f1f2df7ba15cd2ac67913acec325b7bed5714a0a;d887f96bf4d8701d77802e695cf477b3017eeedd;536efcafec89388d752e79797ac681ec29a0f37e;483ba7fdbb5bcd7bb7a378ce9775f4fd8edf49c2",
         "The KU-PARP14 axis differentially regulates DNA resection at stalled replication forks by MRE11 and EXO1;Functional Analysis Identifies Damaging CHEK2 Missense Variants Associated with Increased Cancer Risk;Regulation of Mus81-Eme1 structure-specific endonuclease by Eme1 SUMO-binding and Rad3ATR kinase is essential in the absence of Rqh1BLM helicase;CHEK2 Germline Variants in Cancer Predisposition: Stalemate Rather than Checkmate;Physiological and Pathological Roles of RAD52 at DNA Replication Forks;Rad52 prevents excessive replication fork reversal and protects from nascent strand degradation;Advances in understanding DNA processing and protection at stalled replication forks;Phosphorylation by CK2 regulates MUS81/EME1 in mitosis and after replication stress;Replication Fork Reversal: Players and Guardians.;MRE11 and EXO1 nucleases degrade reversed forks and elicit MUS81-dependent fork rescue in BRCA2-deficient cells;EZH2 promotes degradation of stalled replication forks by recruiting MUS81 through histone H3 trimethylation;Replication fork reversal triggers fork degradation in BRCA2-defective cells;Smarcal1-Mediated Fork Reversal Triggers Mre11-Dependent Degradation of Nascent DNA in the Absence of Brca2 and Stable Rad51 Nucleofilaments;RADX Promotes Genome Stability and Modulates Chemosensitivity by Regulating RAD51 at Replication Forks.;FHA domains: Phosphopeptide binding and beyond.;MUS81 nuclease activity is essential for replication stress tolerance and chromosome segregation in BRCA2-deficient cells;Current perspectives on CHEK2 mutations in breast cancer;The SMX DNA Repair Tri-nuclease;Feedback regulation of methyl methanesulfonate and ultraviolet-sensitive gene clone 81 via ATM/Chk2 pathway contributes to the resistance of MCF-7 breast cancer cells to cisplatin;A Mechanism for Controlled Breakage of Under-replicated Chromosomes during Mitosis.;Small-molecule inhibitors identify the RAD52-ssDNA interaction as critical for recovery from replication stress and for survival of BRCA2 deficient cells;Cell cycle control of DNA joint molecule resolution.;Replication Fork Stability Confers Chemoresistance in BRCA-deficient Cells;Signaling from Mus81-Eme2-Dependent DNA Damage Elicited by Chk1 Deficiency Modulates Replication Fork Speed and Origin Usage.;Replication stress: getting back on track;BRCAness revisited;The WRN exonuclease domain protects nascent strands from pathological MRE11/EXO1-dependent degradation;Replication fork reversal in eukaryotes: from dead end to dynamic response;Holliday junction resolution: Regulation in space and time;DNA Replication and Oncogene-Induced Replicative Stress;MUS81-EME2 Promotes Replication Fork Restart;Substrate specificity of the MUS81-EME2 structure selective endonuclease;A Novel Non-canonical Forkhead-associated (FHA) Domain-binding Interface Mediates the Interaction between Rad53 and Dbf4 Proteins*;Survival of the Replication Checkpoint Deficient Cells Requires MUS81-RAD52 Function;Regulation of Mus81–Eme1 Holliday junction resolvase in response to DNA damage;Human RECQ1 promotes restart of replication forks reversed by DNA topoisomerase I inhibition;The WRN and MUS81 proteins limit cell death and genome instability following oncogene activation;THE RAD9-RAD1-HUS1 (9.1.1) COMPLEX INTERACTS WITH WRN AND IS CRUCIAL TO REGULATE ITS RESPONSE TO REPLICATION FORK STALLING;Structure-Specific DNA Endonuclease Mus81/Eme1 Generates DNA Damage Caused by Chk1 Inactivation;Double-Strand Break Repair-Independent Role for BRCA2 in Blocking Stalled Replication Fork Degradation by MRE11;The DNA damage response: making it safe to play with knives.;Homologous recombination restarts blocked replication forks at the expense of genome rearrangements by template exchange.;The checkpoint response to replication stress.;Replication fork stalling in WRN-deficient cells is overcome by prompt activation of a MUS81-dependent pathway;GPS 2.0, a Tool to Predict Kinase-specific Phosphorylation Sites in Hierarchy *S;ATR: an essential regulator of genome integrity;Mechanism of eukaryotic homologous recombination.;The structure-specific endonuclease Mus81 contributes to replication restart by generating double-strand DNA breaks;Replication checkpoint kinase Cds1 regulates Mus81 to preserve genome integrity during replication stress.;Molecular mechanisms of mammalian DNA repair and the DNA damage checkpoints.;The relationship between the roles of BRCA genes in DNA repair and cancer predisposition.;Checking on the fork: the DNA-replication stress-response pathway.;Mus81-Eme1 and Rqh1 Involvement in Processing Stalled and Collapsed Replication Forks*;Structural and functional versatility of the FHA domain in DNA-damage signaling by the tumor suppressor kinase Chk2.;Damage Tolerance Protein Mus81 Associates with the FHA1 Domain of Checkpoint Kinase Cds1;The molecular basis of FHA domain:phosphopeptide binding specificity and implications for phospho-dependent signaling mechanisms.;Heterozygous germ line hCHK2 mutations in Li-Fraumeni syndrome.;Crystal Structure of the Human MUS81-EME2 Complex;Identification and characterization of MUS81 point mutations that abolish interaction with the SLX4 scaffold protein;(2023) Phosphorylation status of MUS81 is a modifier of Olaparib sensitivity in BRCA2-deficient cells"
        ],
        [
         "37",
         "01ae220b363f9f67e47ae800d8483b5b34ecb1d8",
         "Journal of Orthoptera Research",
         "0",
         "",
         "2025-01-07",
         "113555018,1397417641,2339066974,30061782",
         "Nyasha Chikwature,M. Morgan‐Richards,Jessica Vereijssen,S. Trewick",
         "2025",
         "s2",
         "0.0",
         "https://jor.pensoft.net/article/123860/download/pdf/",
         "ac5f1452b0ae2dca83b8cb1757b1c6ae44474051;c10dc1b010d5f6a020e9a8d03cf1384f984eac7b;d5424a14aab3e7f26362d9bac753eaeb269ca8a2;7188a38da4a023f346cafb48238320f6dfcf952d;6162b44166b0e54eabae74cbf04576357b18c702;ceb03a229088540a3512d2c77ec193d4c754cb76;c8dde8b6fb5997c398e61ee1f8a65c3a659b1acc;04a580a04045e01d36ea225ef4b4aab09a178aec;013acfd9b9d44188ffb6301b123984bdda4069f1;e97721b7ddde9b9275c2e7efd365d6e79fceb9ba;dd86fd83a2b887b07d41f9fcecd2dbdf780aca9a;3399bbfc3627b52b2fccbacb33d271a3df032f58;6177b3f1f654cd623fe4a0f2617c261ce32f6a16;f3ed973fe764ad37bd27e556813ca84ad7fc728c;c2c5927f5815bba718a46206fb7f9d30ad1c90d2;1bb1830505ee09c009167338b3dc2f82f04604fa;b2f4f8304f9a5e4445b087fd8e534ba445d17693;6ecc92e1148f02b8db10b89c98a316935611ba7a;c6de4985b507708c033a1b5c8afeb54b5a127eec;6246a4c5c63482eb027931ab50fd7ce854e04d88;671aef7947db9825f8f9c2a91098d5a5b132c611;899335d74e031e09d75560a1a6f31105d6a51651;514a6fbdf7a9bf670c684df342c829431f635caf;114e1354cee7a687ae694f7d8134c7afc87abb47;cc2bd2bfacddf2032b7efd28b6ddf154b96985d7;80172da3bed5b93e2d7058198f5fd527ad6790ad;8ad6759671ed5a1ccceb6bca665a99c84abb98f4;2f926c4d399790ee7efa4db04d388f8df87b10ab;1b25f86db255bfb07f02ac59159f104620f0abc7;ff6e6484af634c949d3d1ee56ca167ae42771e51;e7d2995541844d2950608c2bb8296991f00bdb67;fd58aab9f9d45faf64efa94389c6c3e29ae74aef;84adb4e9bc068bfe3206bc8e1e9bd239060829e4;e08165c1ba6f2e2333fdaff235a466e5b767e096",
         "Sexual selection on a female copulatory device in an insect with nuptial gifts;﻿Relationships among body size components of three flightless New Zealand grasshopper species (Orthoptera, Acrididae) and their ecological applications;Paternity sharing in insects with female competition for nuptial gifts;Recommendations for non-lethal monitoring of tree wētā (Hemideina spp.) using artificial galleries;Ecology and systematics of the wine wētā and allied species, with description of four new Hemiandrus species;ggplot2;Agroecological management of a soil‐dwelling orthopteran pest in vineyards;Macroinvertebrate and soil prokaryote communities in the forest–tundra ecotone of the Subarctic Yukon;Insect temperature-body size trends common to laboratory, latitudinal and seasonal gradients are not found across altitudes;Three new ground wētā species and a redescription of Hemiandrus maculifrons;Ground wētā in vines of the Awatere Valley, Marlborough: biology, density and distribution;Notes on sexual size dimorphism, sex ratio and movements of adult ground weta Hemiandrus maculifrons (Walker) (Orthoptera: Anostostomatidae);Shifting ranges of two tree weta species (Hemideina spp.): competitive exclusion and changing climate;New Zealand ground wētā (Anostostomatidae: Hemiandrus): descriptions of two species with notes on their biology;Large-sized insects show stronger seasonality than small-sized ones: a case study of fruit-feeding butterflies;Mutualism or opportunism? Tree fuchsia (Fuchsia excorticata) and tree weta (Hemideina) interactions;Isotopic fractionation in a large herbivorous insect, the Auckland tree weta.;A comparative study of the biology of the Giant wetas Deinacrida heteracantha and D. fallai (Orthoptera : Henicidae) from New Zealand;Diversification of New Zealand weta (Orthoptera: Ensifera: Anostostomatidae) and their relationships in Australasia;Interspecific interactions in phytophagous insects revisited: a quantitative assessment of competition theory.;Comparative food web structure of larval macrolepidoptera and their parasitoids on two riparian tree species;Egg size variation and its relationship with larval performance in the Lepidoptera: the case of the European grapevine moth Lobesia botrana;Increased competition may promote species coexistence;Model-Based Clustering, Discriminant Analysis, and Density Estimation;A new species of tusked weta from the Raukumara Range, North Island, New Zealand (Orthoptera: Anostostomatidae: Motuweta);What omnivores eat: direct effects of induced plant resistance on herbivores and indirect consequences for diet selection by omnivores.;The Gondwanaland Weta: Family Anostostomatidae (formerly in Stenopelmatidae, Henicidae or Mimnermidae): Nomenclatural Problems, World Checklist, New Genera and Species;Diet of the ground weta Zealandosandrus gracilis (Orthoptera: Stenopelmatidae);LXIV.—Notes on a collection of Gryllidæ, Stenopelmatidæ, Gryllacridæ, and Hetrodidæ formed by Mr. W. L. Distant in the Transvaal and other South- and East-African localities;Sex- and season-dependent behaviour in a flightless insect, the Auckland tree weta (Hemideina thoracica);Mark-recapture.;Life cycle , survival rates and longevity of an alpine weta Hemideina maori ( Orthoptera : Anostostomatidae ) determined using mark-recapture analysis;Distribution and conservation status of ground weta, Hemiandrus species (Orthoptera: Anostostomatidae);Invertebrate fauna of four tree species in Orongorongo valley, New Zealand, as revealed by trunk traps;Feeding behaviour and enemies of Rhaphidophoridae (Orthoptera) from Waitomo Caves, New Zealand.;Notes on the genus Deinacrida in New Zealand.;Fauna Chilena. Insectos. Orden IV. Ortoperos.;Insects of New Zealand."
        ],
        [
         "38",
         "01ae6d81c72cb5b14ae95519f29011609a777351",
         "Oecologia",
         "0",
         "Medicine",
         "2025-02-27",
         "2311799755,3952003,6679991",
         "David P Gregovich,Gretchen H. Roffler,Christina M. Prokopenko",
         "2025",
         "s2",
         "0.0",
         "https://link.springer.com/content/pdf/10.1007/s00442-025-05677-5.pdf",
         "",
         ""
        ],
        [
         "39",
         "01aec6fc8b33f731d3fdb3f878f36e6ba44f9975",
         "bioRxiv",
         "0",
         "Biology",
         "2025-05-05",
         "2279458093,2124810107,2256046812,2293273127,2302273614,2301886594,2301890550,2253470650,2302124783,2359552678,2248061771,2234360519,2359616772,2302365690",
         "Yihang Xiao,Jinyi Liu,Yan Zheng,Shaoqing Jiao,Jianye Hao,Xiaohan Xie,Mingzhi Li,Ruitao Wang,Fei Ni,Yuxiao Li,Zhen Wang,Xuequn Shang,Zhijie Bao,Changxiao Yang,Jiajie Peng",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/05/15/2024.05.13.593861.full.pdf",
         "",
         ""
        ],
        [
         "40",
         "01c145dd6f03ad1e93829d3f9f477ac9166ef6ab",
         "Advances in Mathematics of Communications",
         "1",
         "Computer Science",
         "None",
         "40646055,2292431618",
         "Jyotirmoy Basak,Kaushik Chakraborty",
         "2025",
         "s2",
         "0.0",
         "https://www.aimsciences.org/data/article/export-pdf?id=65f29c2dc26d215a60510a56",
         "4a803bc138c79f11233aee6282ad785aad0a9b6b;b182ee353844232395f6f8ec858bdcfba2f08c75;af12c8bd720b1c9b25286e209a7513141ef9ff79;60a36c5c178a0b9b327dee00aa4e8ab6bee3ac61;968dde11604199dd384999e58e480844b0882aa9;2dd9fc38b8eea9dfd8cf1d41f42881cca5e7baf6;17c16c133ab46e66ea0a08f40d19b3308733c348;2094199f2442aeac88020093b0d9b9dda3360e31;b748b52dc7e9de9c0d96ba31faaf4ea87fc28892;10e22a3e3c0ac6a91774d6d702f5430ad6111c20;30ffd4a8e479d04b1dea5749eac4a466dccde64b",
         "Device-independent oblivious transfer from the bounded-quantum-storage-model and computational assumptions;A device-independent protocol for XOR oblivious transfer;Self-testing nonprojective quantum measurements in prepare-and-measure experiments;Clauser–Horne–Shimony–Holt versus three-party pseudo-telepathy: on the optimal number of samples in device-independent quantum private query;Device-independent two-party cryptography secure against sequential attacks;Device-independent bit commitment based on the CHSH inequality;Quantum cryptography: Public key distribution and coin tossing;Flexible protocol for quantum private query based on B92 protocol;Protecting data privacy in private information retrieval schemes;How to differentiate between non-orthogonal states;Probability Inequalities for Sums of Bounded Random Variables"
        ],
        [
         "41",
         "01c65b584d35362abc5f2425273ec2eefc579594",
         "bioRxiv",
         "0",
         "Biology,Medicine",
         "2025-01-02",
         "120334882,2197261055,3851119,4069239",
         "Germán Robert,Alejandro Enet,Laura Saavedra,R. Lascano",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2023/08/19/2023.08.11.552961.full.pdf",
         "0e55947a43c8c7f58e081cd35abdb39139c2c20c;fe10503cea4a5227fbf6ce5b2031fb33994c7673;6eebb92f4a250bfb4b6a7446f183adfd0919ea23;be59a0bcfb7dac969ce2d6a234972c6e874e711c;5f48b8d43b11813af0bea09b12e9a9d1a98ca3de;cc2960dc5aa4f8e480171acd0934b32eba20e18a;660c0026936283ee9f40c3306d6ea0f48da846be;da88eaed48eccb5483958fba57810b8472e6532c;4bf9971e50250d9e934212dc70afb375b50f8365;ce05cb220db39865ac48f02d551d7e835e2a46d2;b3b7e1a44785636827f9d06ceee0f12b15c29e92;eb245de575316f556cff5e486cdbec58692ad0df;cb36da57f4931f7de14099cad63972fdc90ae40a;57e62022c2eee47981d88e118b483a4c6c0d101b;3a2ad6292e5a49fb4eb23b20c8f46eea3475ddac;6997a951f74602ed52b739d9f6ea246d84071582;64380302378252179b1a7651f77314bf15ab1df4;47127b8918bfecd3505cbc141cd4877905908439;af8cb1ea80237bd876b1c31238814991c2ab6d4f;3dc09247f4fecf63157611840742bfa5f46cee0c;f57b54a720d5456644dc82604b60da3227e2fc4b;a1dcd3c7c975dfd2d7269bcb9fb7c63803d9ec21;0fab1954c714c202e13cecfc6ad7824b4e586005;d75f2d73db4e6773d2283a253c6e2aaefaded4af;94dc63cf5da9ab9344acfd90a7ef6658ace1ac55;06aded4cc2bc62155e16808eb65d4ab14e56d822;28ce80d30af47cd3a81b5e321e2dc1fc67e02507;8e29c9d2041c6b3063027b8360838016e51e078c;67d396ee0da3b5de31ecc32520e2c513487de351;49c1e4a652971d402d2909cc4aa6362ad64b88ac;32cfc0654855a94ec290ce1d039116fdbd3c6b7b;5a4ea96263ad4e6372b48b384b12be73e6bf845b;b3de05db9300531090be534cb11eca9f06eca073;b02dd65023f27d29d55ec3272e3e765d695e37d8;93eb3119d85b7cf4df60f3dcbe85d2c4dd78920c;70f82f75194f07ba948d68b5a4045aa9c4749851;5741b7247a5b7ee7241680870d70be4c64b2b99e;82d6f0f32c8eeb02fb2ec33d221ea9a01f477c7d;08728db8a1dc782c778fe6d1da07d50bc2d0fe30;a150564c8b2ecbea55359ad4c9115f0beb5186fe;7992e59672c86ffa4aa6eea9fcde4fb84ff86f4e;639cd864efe21557005ea5434b0c274d987bdd29;fc65ff691b74683b4fb445ac8c8f07d58dced5a3;d068f05a6ef0895f3d86d41583a6da92a0b099b7;0ebb12f023db7eefe286bea6af61ab630058dd03;2bc839b266e3a80de4734a7beed6303bd86b034b;41ef39f2d6d96d6ac8bf69f7bc8c3c5494eb89b8;06ee9a7b3a14d18557b79f458d1fa354c55bb6c8;58e42c8fe27fa292c93ad41d8130da8ed88ccd8d;c1f40ed5499c7cb865beaa993da371fc58f4cd36;c1777a58c91099ac7bd3c0da44dc7c9ea6103209;ec8b7c96e998725c8393f47356c2ba8f7ed6dcee;fb9e7fdebe88ac6d07e62eb216d0afedcbc52ae4;7ef9e5200a25eecffd4c11cb4fd1268755df43b8;3a18cd896b9c2c23fa48114bfb98837815a47316;3fa772c422d9bd85e451822e4fcc58c98d5c481d;e78c230aba7fa7ea8050aac1b37899a8595fc7c2;77d1d784789e33430961e82161daccc2d62880ce;f8c6f3aaffa407baeaadc12cb3a3fac7c8f31955;4bbf342fe8179cb51bb9d1ab44540d2aec592193;b23ba42c7442fc4d95f6f097b951545c506fd806;72d3f7f9ad98b69728cbbdb1b71f3f3e9cdf9fcd;307a79535736f2a16e9de9899ff17ef3a3d80d5e;56fbb66c0bf307529722b12c32e4b90ecba7a235;c516beb784844c5de4b721f445768da6215e1954;973aef04195a1c5e84592c2021db88840a326ff9;a9c604b3b9f0808868953a1e9bb501514b5be769;69a65d3beaa3e7f48db153405cd596194d8a955a;86527963c51989068446d0db7a5fb8ada1f7a432;159738308b6cd94265c875d583fabc1d4082ab0e;679f4416468860d87c6dd0fca6d2cbd2a63ec4ee;c73ba5a7d3abf38560488d965461c05f6d024da8;ae04125de54f8c84f01dc6030afc43c6bda249c8;f4fb457fc12271f6132459e87d2c35196856f66b;53d3d4e8b4cb1d4c85abfcdb7532f4fd6dc725cd;1f6225cdb56f6dc11005ae3328b63763efb9e0d4;e7c8aa2cb2223f17615c1b1ae3b33095466e95cc;33087cdad00dc0f217f06560896cd50dce090668;9c07eff521dffea47475ae8f46428c98bc33fd8a;89c010bf29987196279230e3fb14a7161dfb98c7;34363b7edb6ff5a5accd7f8b45f6a1d22f498e57;902dcc2efa9971a5e0ba66d8ca462262f795a4d1;583e1e985b915610f556cad4860619c4bac8cc4b;2ba158be73dd5d2325ae6bb4dd10c84fc34938fc;5d4bf362acbe657f14429a580f7a46fdc33bb33d;4a9fb5cb36d7de4b241611fc828e12ddcb8b71f7;06dca39b679978142010d2ad662c99fad17f19d3;d946b9f209da1e0095437b2313b50c6d0f89d015",
         "Contrasting cytosolic glutathione redox dynamics under abiotic and biotic stress in barley as revealed by the biosensor Grx1-roGFP2.;New Insights into Plant Autophagy: Molecular Mechanisms and Roles in Development and Stress Responses.;Redox-mediated activation of ATG3 promotes ATG8 lipidation and autophagy progression in Chlamydomonas reinhardtii;Transcriptional and post-translational regulation of plant autophagy;Pexophagy suppresses ROS-induced damage in leaf cells under high-intensity light;ROS and redox regulation of cell-to-cell and systemic signaling in plants during stress.;ROS production and signalling in chloroplasts: cornerstones and evolving concepts;Understanding paraquat resistance mechanisms in Arabidopsis thaliana to facilitate the development of paraquat-resistant crops;Plant Autophagy: An Intricate Process Controlled by Various Signaling Pathways;The core autophagy machinery is not required for chloroplast singlet oxygen-mediated cell death in the Arabidopsis thaliana plastid ferrochelatase two mutant;Superoxide radical scavenging by sodium 4,5-dihydroxybenzene-1,3-disulfonate dissolved in water: Experimental and quantum chemical studies;Autophagy Contributes to the Quality Control of Leaf Mitochondria;Ammonium stress increases micro-autophagic activity while impairing macro-autophagic flux in Arabidopsis roots.;Singlet Oxygen in Plants: Generation, Detection, and Signaling Roles;Autophagy in plants: Physiological roles and post-translational regulation.;Autophagy: An Intracellular Degradation Pathway Regulating Plant Survival and Stress Response;Rapid systemic signaling during abiotic and biotic stresses: Is the ROS wave master of all trades?;The protease activity of human ATG4B is regulated by reversible oxidative modification;Chloroplast stress signals: regulation of cellular degradation and chloroplast turnover.;Linking Autophagy to Abiotic and Biotic Stress Responses.;Multiple Regulatory Levels Shape Autophagy Activity in Plants;Redox Systemic Signaling and Induced Tolerance Responses During Soybean–Bradyrhizobium japonicum Interaction: Involvement of Nod Factor Receptor and Autoregulation of Nodulation;The fluorescent protein sensor roGFP2-Orp1 monitors in vivo H2 O2 and thiol redox integration and elucidates intracellular H2 O2 dynamics during elicitor-induced oxidative burst in Arabidopsis.;Selective Elimination of Membrane-Damaged Chloroplasts via Microautophagy1[OPEN];Phosphatidylinositol 3-kinase function at very early symbiont perception: a local nodulation control under stress conditions?;Oxidation of Atg3 and Atg7 mediates inhibition of autophagy;Reactive oxygen species, abiotic stress and stress combination.;Entire Photodamaged Chloroplasts Are Transported to the Central Vacuole by Autophagy[OPEN];Control of Autophagy in Chlamydomonas Is Mediated through Redox-Dependent Inactivation of the ATG4 Protease1;The ROS Wheel: Refining ROS Transcriptional Footprints1[OPEN];Dissecting Redox Biology Using Fluorescent Protein Sensors.;Learning the Languages of the Chloroplast: Retrograde Signaling and Beyond.;Endocytic and autophagic pathways crosstalk in plants.;How to control self-digestion: transcriptional, post-transcriptional, and post-translational regulation of autophagy.;Functional characterization of the two ferrochelatases in Arabidopsis thaliana.;The yeast autophagy protease Atg4 is regulated by thioredoxin;Expression of Animal Anti-Apoptotic Gene Ced-9 Enhances Tolerance during Glycine max L.–Bradyrhizobium japonicum Interaction under Saline Stress but Reduces Nodule Formation;Autophagy deficiency leads to accumulation of ubiquitinated proteins, ER stress, and cell death in Arabidopsis;Stitching together the Multiple Dimensions of Autophagy Using Metabolomics and Transcriptomics Reveals Impacts on Metabolism, Development, and Plant Responses to the Environment in Arabidopsis[C][W];ROS as key players in plant stress signalling.;Development of roGFP2-derived redox probes for measurement of the glutathione redox potential in the cytosol of severely glutathione-deficient rml1 seedlings;Highly Oxidized Peroxisomes Are Selectively Degraded via Autophagy in Arabidopsis[C][W];A Mediator of Singlet Oxygen Responses in Chlamydomonas reinhardtii and Arabidopsis Identified by a Luciferase-Based Genetic Screen in Algal Cells[W];1O2-mediated and EXECUTER-dependent retrograde plastid-to-nucleus signaling in norflurazon-treated seedlings of Arabidopsis thaliana.;NBR1-Mediated Selective Autophagy Targets Insoluble Ubiquitinated Protein Aggregates in Plant Stress Responses;Antioxidant properties of benzoic acid derivatives against superoxide radical;Reactive Oxygen Species and Autophagy in Plants and Algae1;Carotenoid deficiency triggers autophagy in the model green alga Chlamydomonas reinhardtii;High-Resolution Temporal Profiling of Transcripts during Arabidopsis Leaf Senescence Reveals a Distinct Chronology of Processes and Regulation[C][W][OA];Ascorbate and Glutathione: The Heart of the Redox Hub1;Members of the LBD Family of Transcription Factors Repress Anthocyanin Synthesis and Affect Additional Nitrogen Responses in Arabidopsis[W][OA];Autophagy is required for tolerance of drought and salt stress in plants;Apoplastic superoxide level in wheat protoplast under photooxidative stress is regulated by chloroplast redox signals: Effects on the antioxidant system;Autophagy Negatively Regulates Cell Death by Controlling NPR1-Dependent Salicylic Acid Signaling during Senescence and the Innate Immune Response in Arabidopsis[W][OA];Monitoring the in vivo redox state of plant mitochondria: effect of respiratory inhibitors, abiotic stress and assessment of recovery from oxidative challenge.;Redox regulation in photosynthetic organisms: signaling, acclimation, and practical implications.;Confocal imaging of glutathione redox potential in living plant cells;Singlet Oxygen Is the Major Reactive Oxygen Species Involved in Photooxidative Damage to Plants1[W];Impact of chloroplastic- and extracellular-sourced ROS on high light-responsive gene expression in Arabidopsis.;Generation of superoxide anion in chloroplasts of Arabidopsis thaliana during active photosynthesis: a focus on rapidly induced genes;A reporter system for the individual detection of hydrogen peroxide and singlet oxygen: its use for the assay of reactive oxygen species produced in vivo.;Disruption of Autophagy Results in Constitutive Oxidative Stress in Arabidopsis;Cross-talk between singlet oxygen- and hydrogen peroxide-dependent signaling of stress responses in Arabidopsis thaliana;Degradation of Oxidized Proteins by Autophagy during Oxidative Stress in Arabidopsis1[W][OA];Reactive Oxygen Species in Plant Cell Death1;Imaging the production of singlet oxygen in vivo using a new fluorescent sensor, Singlet Oxygen Sensor Green.;Autophagy in Development and Stress Responses of Plants;Determination of hydrogen peroxide scavenging activity of cinnamic and benzoic acids employing a highly sensitive peroxyoxalate chemiluminescence-based assay: structure-activity relationships.;Processing of ATG8s, Ubiquitin-Like Proteins, and Their Deconjugation by ATG4s Are Essential for Plant Autophagy;Reactive oxygen species: metabolism, oxidative stress, and signal transduction.;Rapid Induction of Distinct Stress Responses after the Release of Singlet Oxygen in Arabidopsis Online version contains Web-only data. Article, publication date, and citation information can be found at www.plantcell.org/cgi/doi/10.1105/tpc.014662.;Expression of senescence-enhanced genes in response to oxidative stress.;Singlet oxygen production in herbicide‐treated photosystem II;The APG8/12-activating Enzyme APG7 Is Required for Proper Nutrient Recycling and Senescence in Arabidopsis thaliana *;Leaf Senescence and Starvation-Induced Chlorosis Are Accelerated by the Disruption of an Arabidopsis Autophagy Gene1;A multiple-comparisons method based on the distribution of the root node distance of a binary tree;Analysis of relative gene expression data using real-time quantitative PCR and the 2(-Delta Delta C(T)) Method.;FLU: A negative regulator of chlorophyll biosynthesis in Arabidopsis thaliana;The role of active oxygen species in plant signal transduction;Antagonistic Effects of Hydrogen Peroxide and Glutathione on Acclimation to Excess Excitation Energy in Arabidopsis;Systemic signaling and acclimation in response to excess excitation energy in Arabidopsis.;Bipyridylium quaternary salts and related compounds. V. Pulse radiolysis studies of the reaction of paraquat radical with oxygen. Implications for the mode of action of bipyridyl herbicides.;Photoperoxidation in isolated chloroplasts. I. Kinetics and stoichiometry of fatty acid peroxidation.;Spectrophotometric characteristics of chlorophylls a and b and their phenophytins in ethanol;Studies on reactions of illuminated chloroplasts. II. Stimulation and inhibition of the reaction with molecular oxygen.;The assimilation and degradation of carbohydrates by yeast cells.;Hypothesis: Increase of the ratio singlet oxygen plus superoxide radical to hydrogen peroxide changes stress defense response to programmed leaf death;Plant senescence: a self-induced process.;Superoxide dismutase and glutathione reductase overexpression in wheat protoplast: photooxidative stress tolerance and changes in cellular redox state"
        ],
        [
         "42",
         "01e2c0cb2a8adced75528452c58dc12ae704f755",
         "Asia and South Pacific Design Automation Conference",
         "1",
         "Computer Science",
         "2025-01-03",
         "2338832390,2338833028",
         "Kevin Lopez,Amin Rezaei",
         "2025",
         "s2",
         "0.0",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.02118v1.pdf",
         "16b3258cd43cfb939d486a99f40fe6657dfe488f;176a3b504fcd7a0ccbc932c0eba393602abb96eb;4b5979a035917e9538db26cf1f0b39e84cfb90dc;889a05294bd1246876a3befd64e3b2ab7474ddac;ab735a16709a3d96e9fc101b380e0db9f30afa90;a1b4c387fcfc80b22fd588b464d656701f95cef1;40ceecc03c580c9eecd0906589ce868832b99d78",
         "STATION: State Encoding-Based Attack-Resilient Sequential Obfuscation;Machine Learning-Based Security Evaluation and Overhead Analysis of Logic Locking;CoLA: Convolutional Neural Network Model for Secure Low Overhead Logic Locking Assignment;CAS-Lock: A Security-Corruptibility Trade-off Resilient Logic Locking Scheme;Anti-SAT: Mitigating SAT Attack on Logic Locking;CycSAT-Unresolvable Cyclic Logic Encryption Using Unreachable States;Unveiling the ISCAS-85 Benchmarks: A Case Study in Reverse Engineering"
        ],
        [
         "43",
         "01ec6f5401532872db572a31b5db1ca14bbb904f",
         "bioRxiv",
         "0",
         "Biology",
         "2025-04-29",
         "2243217989,2331732093,2358624144,2476022",
         "Aleksandr Korotaev,Quirin Niggli,Valeria Congedi,C. Dehio",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/11/20/2024.11.20.624540.full.pdf",
         "7b411193ec810048a3b935d9d9b848e48c5d1c94;bb5c669e42e05e7a2bea2ce8677c2dda09090885",
         "The phage λ Q gene product: Activity of a transcription antiterminator in vitro;expression marker;*To whom correspondence should be addressed at:;experiments and Dr. Jaroslaw Sedzicki for analysis for the structural preparation of the structure models. This work was supported by the Foundation (SNSF, www.snf.ch) grant 310030B_201273 (to C.D.;conditions. This suggests that the identified conserved site is a functional -10-like element 217 essential for the BrrG-mediated antitermination;of the two BaGTA modules of divergent phage origin"
        ],
        [
         "44",
         "01ee76d50524c8842f3ce68ef656f630485cbec1",
         "Journal of Big Data",
         "2",
         "Computer Science",
         "2025-02-15",
         "2148717073,2345748099,2345756660,2343606498,2345723398",
         "Thompson Stephan,Padma Priya Dharishini Paramana,Chia-Chen Lin,Saurabh Agarwal,Rajan Verma",
         "2025",
         "s2",
         "0.0",
         "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-025-01063-3",
         "",
         ""
        ],
        [
         "45",
         "01f696fabeb35d1337c5cb817ae43ffd30fcdf34",
         "Antioxidants",
         "0",
         "Medicine",
         "2025-03-01",
         "2349940252,2336344612,2350608276,2350218201,2350591139,7196064,50202465",
         "Zhenting He,Senlin Su,Bing Zhang,Dongpang Chen,Siyu Yuan,W. Guan,Shihai Zhang",
         "2025",
         "s2",
         "0.0",
         "https://www.mdpi.com/2076-3921/14/3/334/pdf?version=1741832015",
         "",
         ""
        ],
        [
         "46",
         "02005c9e65bcf62c329533a372895f68b739c991",
         "bioRxiv",
         "0",
         "Biology",
         "2025-02-23",
         "2279404745,2333606643,2255647838,2333597038,2249337375,2245105965",
         "L. Manciocchi,A. Bianchi,Valérie Mazan,Mark Potapov,K. M. Fromm,M. Spichty",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/04/2024.11.28.625676.full.pdf",
         "11d0ea5b241a76380483f44211984ad1a206d9e6;8236cad76ac9ced26ffbc7469121d101ad37e15c;6518433cc4cd3a1dcb757d838ee4854a52249425;b044ffb2a8b548f5b6c8c2e0eb12dcec9fc36e29;59ec593117b385383de56fbfb9850c174f01725f;3c58224850bc9cefbad20e634846278f02de7c73;1c8ccd1488f6d592a65bd4d022eef2969c0aa668;8169ff5bc49e482ef70153dc7b2a56b44eea6d53;4ff4ccc14e1de6440cff57367a4d0ea71ea058a3;01cc10a58d743140037b11b1f33a6a4a842b7d2c;0cbea48e04da728afdf0591c30055e2562bade95;d0ca22248bc835be5d7e9d0af8278f8f994e5ec8;2012be16842b142c3868ebab8e6caa70a05e91c3;bb673759c421a48a9ee9a070d984aebf09f96fed;d8a8be809f95068a8a5e2839666d45209a666b76;87c6156fb290cf3914cd3ed18590200b9a72627a;58172dc45aaacf8a221767401be96aa8c9803ef0;5c15d0ecf392ebe4790e03882f7982709ac712b8;4f2556e717327d18bf6e74ad5beeddfa80382d16;2b9c74e76f86c896db9936e2d0546ffd9dac0fb3;12111256cc53f82a65b8d1c284309754f8a0d596;b08092845d60952fd5d79daf7ee72397f9c35d47;2e4e2fb0d08e93ee597381b3c7225a0f49c18ec1;8a258fe707d1cf444ba506d9e818a1329dd91ea6;4fedae8329960a9b1d1a5f71776a11269bb75583;4a3f9a1d66cb41689b2c8226e643d2eb92b06be4;6028582733d89bbaf0be2ea28dd954fd0f64ebc8;f29fa405bf383ca96df2bc78f13d713f8841a443;3555543153d42636bc967a93ede43e4f0f982391;3390f1f37196a2fafebdab8434a5e4f52456d441;1829d212c1a0f73a34b70ec87ae76123e91a0308;ab06bf6c7c3f7d6db066fcffcd4e06e9b0045b93;96b806a4a3909be212c3d2d14df20665e29ec01b;3e91f8caa53385dc4256634638431d10a8c9173a;ef513693e0885c35483c2264fe6b410f4c07b5b5;d3064425f4110faef5efbfbdc06df968ed91a414;149dc47112d54760cd7c14ef78090816ed56eb46;5a8b899b8edaae8c4c7e662c431360be986ad84d",
         "Toward predicting silver ion binding in proteins;Thermodynamics of Metal-Acetate Interactions.;The battle for silver binding: How the interplay between the SilE, SilF, and SilB proteins contributes to the silver efflux pump mechanism;Accurate Metal-Imidazole Interactions.;Constant pH molecular dynamics simulations: Current status and recent applications.;Re-sensitization of mcr carrying multidrug resistant bacteria to colistin by silver;Scalable Constant pH Molecular Dynamics in GROMACS;Computational strategies to model the interaction and the reactivity of biologically-relevant transition metal complexes;Alpha-helical folding of SilE models upon Ag(His)(Met) motif formation.;Configuration-Sampling-Based Surrogate Models for Rapid Parameterization of Non-Bonded Interactions.;Model peptide studies of Ag+ binding sites from the silver resistance protein SilE.;CHARMM36m: an improved force field for folded and intrinsically disordered proteins;SilE is an intrinsically disordered periplasmic “molecular sponge” involved in bacterial silver resistance;CHARMM TIP3P Water Model Suppresses Peptide Folding by Solvating the Unfolded State.;Enhanced sampling techniques in molecular dynamics simulations of biological systems.;Systematic Parameterization of Monovalent Ions Employing the Nonbonded Model.;Recent Advances in Polarizable Force Fields for Macromolecules: Microsecond Simulations of Proteins Using the Classical Drude Oscillator Model;Force Field Independent Metal Parameters Using a Nonbonded Dummy Model;Nanobio silver: its interactions with peptides and bacteria, and its uses in medicine.;Force field for monovalent, divalent, and trivalent cations developed under the solvent boundary potential.;Syntheses, structures, and antimicrobial activities of remarkably light-stable and water-soluble silver complexes with amino acid derivatives, silver(I) N-acetylmethioninates.;Constant pH Molecular Dynamics in Explicit Solvent with λ-Dynamics;Current status of the AMOEBA polarizable force field.;Antibacterial Activity and Mechanism of Action of the Silver Ion in Staphylococcus aureus and Escherichia coli;Atomistic Simulation Studies of Polymers and Water;The Simple Yet Elusive Crystal Structure of Silver Acetate and the Role of the Ag−Ag Bond in the Formation of Silver Nanoparticles during the Thermally Induced Reduction of Silver Carboxylates;Calculation of absolute protein-ligand binding free energy from computer simulations.;Bacterial silver resistance: molecular biology and uses and misuses of silver compounds.;A mechanistic study of the antibacterial effect of silver ions on Escherichia coli and Staphylococcus aureus.;Synthesis and characterization of water-soluble silver(I) complexes with L-histidine (H2his) and (S)-(-)-2-pyrrolidone-5-carboxylic acid (H2pyrrld) showing a wide spectrum of effective antibacterial and antifungal activities. Crystal structures of chiral helical polymers [Ag(Hhis)]n and ([Ag(Hpyrrld;Critical evaluation of stability constants of metal-imidazole and metal-histamine systems (Technical Report);THE weighted histogram analysis method for free‐energy calculations on biomolecules. I. The method;STEREOREGULAR COORDINATION POLYMERS FORMED ON BINDING OF PEPTIDE-BASED POLYDENTATE LIGANDS TO SILVER(I) AND COPPER(I) - X-RAY STRUCTURE OF ([AG(N-[N-((5-METHYL-2-THIENYL)METHYLIDENE)-L-METHIONYL]HISTAMINE)]+[O3SCF3]-.MEOH)INFINITY AND A SOLUTION STRUCTURE STUDY;Comparison of simple potential functions for simulating liquid water;Nonphysical sampling distributions in Monte Carlo free-energy estimation: Umbrella sampling;NIST SRD 46. Critically Selected Stability Constants of Metal Complexes: Version 8.0 for Windows;unpublished results;Theoretical Studies of Hydrogen Bonding;Comparison of the ligating properties of disulphides and thioethers: dimethyl disulphide, dimethyl sulphide, and related ligands;Sur Le Mélange Des Gaz;Ueber die Anwendung des Satzes vom Virial in der kinetischen Theorie der Gase;Using the procedure given in the section 2.2, the PMF and binding constant are calculated;We performed MD based Umbrella Sampling (US) simulations in explicit water to sample along the reaction coordinate of binding, i.e. the distance between silver(I) ion and the coordinated atom;The Potential of Mean Force (PMF) was determined along the binding reaction coordinate through WHAM;From the PMF, the binding constant log 10 ( K bind , calc ) was calculated (and, consequently, the binding free energy ∆ G bind,calc );If the minimum of the PMF matches the target distance"
        ],
        [
         "47",
         "021450a16398928333d110a0997a59a7a6061253",
         "Social Science Research Network",
         "0",
         "",
         "None",
         "1741105347,2197298236,144501273,1729333351,2197356551,119186286",
         "Primavera de Filippi,Sofia Cossar,M. Mannan,Kelsie Nabben,Tara Merk,Jamilya Kamalova",
         "2025",
         "s2",
         "0.0",
         "https://hal.science/hal-04855853v1/file/ssrn-5029113.pdf",
         "",
         ""
        ],
        [
         "48",
         "021475212b53ecfc81f49506378ee09635f43305",
         "Mathematics",
         "0",
         "",
         "2025-02-25",
         "2351572899,2347377475,2347379498,2347427413,2347436059",
         "Zihao Cui,Kailian Deng,Hongtao Zhang,Zhongyi Zha,Sayed Jobaer",
         "2025",
         "s2",
         "0.0",
         "https://www.mdpi.com/2227-7390/13/5/754/pdf?version=1740497280",
         "",
         ""
        ],
        [
         "49",
         "022103bcb2f73b22a217aaa1bb92d4f8df4a75c2",
         "bioRxiv",
         "0",
         "Biology",
         "2025-01-02",
         "33949687,144155243,1405019368",
         "J. Bunce,Catalina I. Fernández,Caissa Revilla-Minaya",
         "2025",
         "s2",
         "0.0",
         "https://www.biorxiv.org/content/biorxiv/early/2022/10/12/2022.10.10.511559.full.pdf",
         "",
         ""
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5162
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>venue</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>fieldsOfStudy</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authorName</th>\n",
       "      <th>publicationYear</th>\n",
       "      <th>source</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "      <th>openAccessPdf</th>\n",
       "      <th>referenceIds</th>\n",
       "      <th>referenceTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000160a2fe73e426cad54f5ba7d1e45703a77b98</td>\n",
       "      <td>IEEE Transactions on Network and Service Manag...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2152052057,2268674717</td>\n",
       "      <td>Panagiotis I. Nikolaidis,John S. Baras</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004c478be53ae7cc93461846992842c73778e7e</td>\n",
       "      <td>ACM-SIAM Symposium on Discrete Algorithms</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>None</td>\n",
       "      <td>2266750381,1721077</td>\n",
       "      <td>Louis Golowich,V. Guruswami</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a3e6667afb4ca8476ce15555b05244c3b458a</td>\n",
       "      <td>Scientific Reports</td>\n",
       "      <td>0</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>2064292642,2340550389,2109040952</td>\n",
       "      <td>Fenghui Lian,Yingjie Sun,Meiyu Li</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.nature.com/articles/s41598-025-860...</td>\n",
       "      <td>a7d548167ae65df1b46782fe4055babbe968aaba;8d1e0...</td>\n",
       "      <td>Pancreas segmentation based on an adversarial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c965a4857c0da7d9df07065b48920a6a756c6</td>\n",
       "      <td>Journal of Medical Artificial Intelligence</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2331573849,2256970731</td>\n",
       "      <td>Sandeep Reddy,Sameer Shaikh</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://eprints.qut.edu.au/252096/1/9284-PB1-6...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00139e24da15df3f2f4ef70a92a781ccf315ef47</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>0</td>\n",
       "      <td>Biology</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>2346560940,2277617384,1992769227,1398654276</td>\n",
       "      <td>Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaa...</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.biorxiv.org/content/biorxiv/early/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>ffb10b00b180a9ca1311a3f282489901cd244203</td>\n",
       "      <td>SN Computer Science</td>\n",
       "      <td>1</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>2106438773,1725309</td>\n",
       "      <td>Angelo Marchese,O. Tomarchio</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
       "      <td>e3a90a0612b807e7480650fa3736d3003d766171;1ceb1...</td>\n",
       "      <td>A Multiobjective Metaheuristic-Based Container...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>ffb7e36315a3c3329d01e54f68bfdf595c1b4a8a</td>\n",
       "      <td>Computational Optical Imaging and Artificial I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Engineering,Physics</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>2046757618,2342365815,2341716986</td>\n",
       "      <td>Leyla A. Kabuli,Nalini M. Singh,Laura Waller</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>ffd00ce568f98d0febe6aeb407b54f9075ea732b</td>\n",
       "      <td>Proceedings of 42nd International Conference o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Physics</td>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>2339007853</td>\n",
       "      <td>Pietro Vischia</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.0...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>ffd1a1c82aeef26f1e84a8574cc3a0c600112b9e</td>\n",
       "      <td>SIAM Journal on Scientific Computing</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2258716663,2258720652,2258716318</td>\n",
       "      <td>Robin Armstrong,Alex Buzali,Anil Damle</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2310/2310.0...</td>\n",
       "      <td>4a636fd902905901b962ef830b707481155261fc;af7c1...</td>\n",
       "      <td>Simpler is better: a comparative study of rand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>ffeee44908c472ac7fe276498c41826e82a6b5b9</td>\n",
       "      <td>Open Forum Infectious Diseases</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2025-01-29</td>\n",
       "      <td>50681182,2349766573,2310873510,2264069121</td>\n",
       "      <td>Wenting Jin,Ying Shao,Yaozong Gao,Bijie Hu</td>\n",
       "      <td>2025</td>\n",
       "      <td>s2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pubs.acs.org/doi/pdf/10.1021/cen-v030n...</td>\n",
       "      <td>0342684b89853065c1b5c19f38ed6b598179064f;ccf0a...</td>\n",
       "      <td>Does race matter? An experimental vignette stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5162 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paperId  \\\n",
       "0     000160a2fe73e426cad54f5ba7d1e45703a77b98   \n",
       "1     0004c478be53ae7cc93461846992842c73778e7e   \n",
       "2     000a3e6667afb4ca8476ce15555b05244c3b458a   \n",
       "3     000c965a4857c0da7d9df07065b48920a6a756c6   \n",
       "4     00139e24da15df3f2f4ef70a92a781ccf315ef47   \n",
       "...                                        ...   \n",
       "5157  ffb10b00b180a9ca1311a3f282489901cd244203   \n",
       "5158  ffb7e36315a3c3329d01e54f68bfdf595c1b4a8a   \n",
       "5159  ffd00ce568f98d0febe6aeb407b54f9075ea732b   \n",
       "5160  ffd1a1c82aeef26f1e84a8574cc3a0c600112b9e   \n",
       "5161  ffeee44908c472ac7fe276498c41826e82a6b5b9   \n",
       "\n",
       "                                                  venue  citationCount  \\\n",
       "0     IEEE Transactions on Network and Service Manag...              0   \n",
       "1             ACM-SIAM Symposium on Discrete Algorithms              0   \n",
       "2                                    Scientific Reports              0   \n",
       "3            Journal of Medical Artificial Intelligence              0   \n",
       "4                                               bioRxiv              0   \n",
       "...                                                 ...            ...   \n",
       "5157                                SN Computer Science              1   \n",
       "5158  Computational Optical Imaging and Artificial I...              0   \n",
       "5159  Proceedings of 42nd International Conference o...              0   \n",
       "5160               SIAM Journal on Scientific Computing              0   \n",
       "5161                     Open Forum Infectious Diseases              0   \n",
       "\n",
       "            fieldsOfStudy publicationDate  \\\n",
       "0                                    None   \n",
       "1        Computer Science            None   \n",
       "2                Medicine      2025-01-15   \n",
       "3                                    None   \n",
       "4                 Biology      2025-02-19   \n",
       "...                   ...             ...   \n",
       "5157     Computer Science      2025-02-25   \n",
       "5158  Engineering,Physics      2025-01-24   \n",
       "5159              Physics      2025-01-07   \n",
       "5160                           2025-05-05   \n",
       "5161                           2025-01-29   \n",
       "\n",
       "                                         authorId  \\\n",
       "0                           2152052057,2268674717   \n",
       "1                              2266750381,1721077   \n",
       "2                2064292642,2340550389,2109040952   \n",
       "3                           2331573849,2256970731   \n",
       "4     2346560940,2277617384,1992769227,1398654276   \n",
       "...                                           ...   \n",
       "5157                           2106438773,1725309   \n",
       "5158             2046757618,2342365815,2341716986   \n",
       "5159                                   2339007853   \n",
       "5160             2258716663,2258720652,2258716318   \n",
       "5161    50681182,2349766573,2310873510,2264069121   \n",
       "\n",
       "                                             authorName  publicationYear  \\\n",
       "0                Panagiotis I. Nikolaidis,John S. Baras             2025   \n",
       "1                           Louis Golowich,V. Guruswami             2025   \n",
       "2                     Fenghui Lian,Yingjie Sun,Meiyu Li             2025   \n",
       "3                           Sandeep Reddy,Sameer Shaikh             2025   \n",
       "4     Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaa...             2025   \n",
       "...                                                 ...              ...   \n",
       "5157                       Angelo Marchese,O. Tomarchio             2025   \n",
       "5158       Leyla A. Kabuli,Nalini M. Singh,Laura Waller             2025   \n",
       "5159                                     Pietro Vischia             2025   \n",
       "5160             Robin Armstrong,Alex Buzali,Anil Damle             2025   \n",
       "5161         Wenting Jin,Ying Shao,Yaozong Gao,Bijie Hu             2025   \n",
       "\n",
       "     source  influentialCitationCount  \\\n",
       "0        s2                       0.0   \n",
       "1        s2                       0.0   \n",
       "2        s2                       0.0   \n",
       "3        s2                       0.0   \n",
       "4        s2                       0.0   \n",
       "...     ...                       ...   \n",
       "5157     s2                       0.0   \n",
       "5158     s2                       0.0   \n",
       "5159     s2                       0.0   \n",
       "5160     s2                       0.0   \n",
       "5161     s2                       0.0   \n",
       "\n",
       "                                          openAccessPdf  \\\n",
       "0     gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.1...   \n",
       "1     gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.0...   \n",
       "2     https://www.nature.com/articles/s41598-025-860...   \n",
       "3     https://eprints.qut.edu.au/252096/1/9284-PB1-6...   \n",
       "4     https://www.biorxiv.org/content/biorxiv/early/...   \n",
       "...                                                 ...   \n",
       "5157  https://link.springer.com/content/pdf/10.1007/...   \n",
       "5158  gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.1...   \n",
       "5159  gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.0...   \n",
       "5160  gs://arxiv-dataset/arxiv/arxiv/pdf/2310/2310.0...   \n",
       "5161  https://pubs.acs.org/doi/pdf/10.1021/cen-v030n...   \n",
       "\n",
       "                                           referenceIds  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2     a7d548167ae65df1b46782fe4055babbe968aaba;8d1e0...   \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "5157  e3a90a0612b807e7480650fa3736d3003d766171;1ceb1...   \n",
       "5158                                                      \n",
       "5159                                                      \n",
       "5160  4a636fd902905901b962ef830b707481155261fc;af7c1...   \n",
       "5161  0342684b89853065c1b5c19f38ed6b598179064f;ccf0a...   \n",
       "\n",
       "                                        referenceTitles  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2     Pancreas segmentation based on an adversarial ...  \n",
       "3                                                        \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "5157  A Multiobjective Metaheuristic-Based Container...  \n",
       "5158                                                     \n",
       "5159                                                     \n",
       "5160  Simpler is better: a comparative study of rand...  \n",
       "5161  Does race matter? An experimental vignette stu...  \n",
       "\n",
       "[5162 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authorName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "full_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "main_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "openAccessPdf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ref_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "referenceTitles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a5769896-d99b-455d-b354-f0dfeb02d8af",
       "rows": [
        [
         "0",
         "000160a2fe73e426cad54f5ba7d1e45703a77b98",
         "None",
         "Panagiotis I. Nikolaidis,John S. Baras",
         "\n**BLOCK**fs== 23.9**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nRobust Resource Sharing in Network Slicing\nvia Hypothesis Testing\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nPanagiotis Nikolaidis and John Baras\nDepartment of Electrical & Computer Engineering and the Institute for Systems Research\nUniversity of Maryland, College Park, MD 20742, USA\nEmail: {nikolaid, baras}@umd.edu\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nAbstract—In network slicing, the network operator needs to\nsatisfy the service level agreements of multiple slices at the\nsame time and on the same physical infrastructure. To do so\nwith reduced provisioned resources, the operator may consider\nresource sharing mechanisms. However, each slice then becomes\nsusceptible to traffic surges in other slices which degrades\nperformance isolation. To maintain both high efficiency and high\nisolation, we propose the introduction of hypothesis testing in\nresource sharing. Our approach comprises two phases. In the\ntrial phase, the operator obtains a stochastic model for each slice\nthat describes its normal behavior, provisions resources and then\nsigns the service level agreements. In the regular phase, whenever\nthere is resource contention, hypothesis testing is conducted\nto check which slices follow their normal behavior. Slices that\nfail the test are excluded from resource sharing to protect the\nwell-behaved ones. We test our approach on a mobile traffic\ndataset. Results show that our approach fortifies the service level\nagreements against unexpected traffic patterns and achieves high\nefficiency via resource sharing. Overall, our approach provides\nan appealing tradeoff between efficiency and isolation.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nIndex Terms—network slicing, resource sharing, multiplexing,\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\noverbooking, isolation, anomaly detection, LTE, 5G\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nI. INTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nThe need to support applications with diverse Quality of\nService (QoS) requirements introduces several challenges in\nnetworking. A promising solution approach is to leverage net-\nwork virtualization and software-defined networking to deploy\nmultiple virtual networks on the same physical infrastructure.\nEach virtual network is then tailored to a specific application.\nFor instance, a virtual network deployed for autonomous\ndriving applications may drop packets whose age is larger\nthan the sampling period at the vehicle to avoid congesting\nthe network with outdated information. In contrast, virtual\nnetworks for file transfer may instead optimize throughput.\nAlso, virtual networks used by private companies may require\nincreased authentication functionality for security concerns.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThe special case of customized virtual networks on the\ncellular infrastructure has attracted a lot of attention given\nthat many applications require wireless connectivity. These\nvirtual networks are often referred to as Network Slices (NSs).\nThey span the Radio Access Network (RAN), the Transport\nNetwork (TN) and the Core Network (CN) of the cellular\ninfrastructure. Typically, the customer requesting a NS and the\nnetwork operator sign a Service Level Agreement (SLA) that\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nspecifies the desired QoS delivered to the customer’s traffic\nand the price paid to the operator.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThe fulfillment of multiple SLAs at the same time and on\nthe same physical infrastructure is a difficult problem that\noperators need to solve. It\nthe operator\nprovisions enough network resources in advance so that the\nnetwork functions of each NS can deliver the promised QoS.\nBased on the provisioned resources, the operator can then\ncompute the cost of the SLA and charge the customer.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.3**l== 0.7**r== 0.1**\nis necessary that\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nNetwork functions that require provisioned resources span\nthe whole cellular infrastructure. For example, in the RAN, the\noperator needs to provision Physical Resource Blocks (PRBs)\nfor the Medium Access Control (MAC) scheduler of each\nNS. In the TN, routing paths need to be selected, and in the\nCN, processing units need to be reserved to execute various\nnetwork functions such as the Access and Mobility Function\n(AMF) and the User Plane Function (UPF) of 5G systems.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nAn efficient provisioning approach is to enable resource\nsharing among NSs for statistical multiplexing gains. Resource\nsharing allows the deployment of an increased number of\nNSs on the same infrastructure which translates to lowered\ncosts for the customers. Unfortunately, sharing may degrade\nthe performance isolation of a NS. Indeed, unexpected traffic\nsurges in a NS may result in resource contention. As a result,\nsome NSs may not receive their fair share. This is highly\nundesirable since customers request a NS for premium service\nthat should remain unaffected by the traffic in other NSs.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nOn the other hand, the operator may provision resources\nexclusively for each NS which provides full isolation but at the\ncost of low resource efficiency. Motivated by this tradeoff, we\npropose the use of hypothesis testing to enhance performance\nisolation in resource sharing. Our approach consists of two\nphases, the trial phase and the regular phase.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIn the trial phase, the traffic and the resources required by\neach NS are collected over a long period of time. This data\nis used as follows. First, a stochastic model is constructed for\neach NS that describes its normal traffic patterns. Specifically,\na Markov Chain (MC) is used whose states describe the traffic\nand the resource demand in the NS. Second, the required pro-\nvisioned resources are computed by estimating the percentiles\nof the resource demands of the NSs. All these quantities are\ncomputed based on Maximum Likelihood Estimation (MLE).\nWe note that the operator commits to fulfilling the SLA\nunder the condition that the NS follows its normal behavior.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.1**l== 0.1**r== 0.5**\nThis is a reasonable condition since the operator cannot\nprovide QoS guarantees without any knowledge regarding the\ntraffic of the NS. Indeed, the operator needs to know the\ntraffic that the NS normally generates to compute the required\nprovisioned resources and to charge the customer accordingly.\nIn the regular phase, the operator declines service to NSs\nthat deviate from their normal behavior in case of resource\ncontention. This is done to ensure that the well-behaved NSs\nreceive their fair share of resources. The operator checks if\nsuch a deviation is present via hypothesis testing based on\nthe Neyman-Pearson framework. Next, the operator splits the\nprovisioned resources among the NSs that pass the test. Any\nremaining resources are then split among the rest of the NSs.\nWe apply our approach in the RAN where resource sharing\nis needed the most since the licensed spectrum is a scarce\nand expensive resource. Specifically, we wish to reduce the\nPhysical Resource Blocks (PRBs) needed at the Base Station\n(BS) to satisfy the QoS requirements of all NSs.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nTo test our approach, we use a dataset that contains real\ntraffic as observed in base stations of a cellular network.\nThe dataset is used to simulate the trial phase and derive\nthe aforementioned stochastic models. Then, in the regular\nphase, we consider that some NSs follow traffic patterns\nthat deviate from the previous models. Next, we analyze the\neffect of this excess traffic on the performance of the other\nNSs. We compare our approach to two baselines; exclusive\nbandwidth provisioning for each NS without resource sharing,\nand resource sharing without hypothesis testing.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nThe results show that our approach enhances the robustness\nof the SLAs to anomalous traffic patterns while maintaining\nhigh efficiency via resource sharing. Overall, we provide evi-\ndence that resource sharing augmented by hypothesis testing\nstrikes a good balance between efficiency and isolation.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nOur paper is structured as follows. In Sec. II, we present\nthe related literature and compare it with our work. In Sec.\nIII, we present the considered system architecture. In Sec. IV,\nwe formulate the overall goal of the system architecture as\nan optimization problem. In Sec. V, we propose our solution\napproach. The simulation setup is described in Sec. VI and\nthe results in Sec. VII. Lastly, Sec. VIII concludes the paper.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nII. RELATED LITERATURE\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nthe authors studied the effect of overbooking\nstrategies on resource allocation and service violations. Two\nschemes were investigated; perfect sharing and network slicing\nwhich correspond to resource sharing and exclusive resource\nreservation respectively. In perfect sharing, the BS sums the\nresource demands of all NSs and provisions P H -percentile\nresources. In network slicing, performance isolation is consid-\nered by allocating exclusive P L-percentile resources to each\nNS. The remaining resources needed to achieve P H − P L\nfraction of time acceptance for each NS are computed based\non past data. The authors provide insight regarding the tradeoff\nbetween resource efficiency and performance isolation via ex-\nperimentation. However, no mechanisms to enhance isolation\nfor the P H − P L fraction of time are proposed.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.1**l== 0.5**r== 0.1**\nThe aforementioned tradeoff is also investigated in [2]. The\nauthors consider P L\ni -percentile resources assigned exclusively\ni − P L\nto each NS i. For the rest fraction of time P H\ni ,\neach NS i relies on resource sharing. The authors show that\nthe multiplexing strategy that requires the least provisioned\nresources to satisfy the SLAs of all NSs is the Max-Weight\nscheduler if the resource demands follow MCs. However, no\nisolation mechanisms are provided in case of traffic anomalies.\nA similar strategy is developed in [3]. The authors consider\na fixed amount of provisioned resources and reserve some of it\nexclusively for each NS. The remaining resources are viewed\nas auxiliary and are dynamically provided to the NSs. The\nmain focus of the paper is on developing overbooking strate-\ngies for the auxiliary resources with probabilistic guarantees.\nTo do so, the authors assume that the operator has a model\nthat forecasts the traffic of the NSs in the short term future.\nThe NSs are then priced on a resource basis. Once again, this\napproach is susceptible to unexpected traffic patterns.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nIn [4] and [5], a prediction model for the short-term demand\nof a NS is developed. The predictions are used to dynamically\nadapt the allocated resources for higher utilization. However,\nbandwidth adaptation alone cannot ensure the fulfillment of\na SLA. Resources need to be provisioned so that the ones\nrequested by the prediction model are available on short notice\nas often as the SLA requires.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nThe authors in [6] conduct a survey on resource allocation\nschemes in network slicing. The schemes are coarsely divided\ninto reservation-based and share-based. The authors conclude\nthat the former provide higher isolation while the latter higher\nefficiency. Moreover, the schemes are also compared based on\ncustomizability, complexity, privacy and cost predictability.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nA survey dedicated to the different interpretations of iso-\nlation is presented in [7]. The authors discuss the concept of\nisolation in terms of performance, security, and dependability\nfor various network functions in the RAN, TN, and CN. Here,\nwe are primarily concerned with performance isolation.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nA research area that is closely related to our approach\nis anomaly detection for which multiple methods have been\nsuggested over the years [8]–[12]. Here, we use a statistical\nmethod since we consider hypothesis testing. We note that\nanomaly detection has been used before in network slicing\n[13]–[15]. However in these works, the motivation behind its\nuse is primarily security and data privacy. Here, we leverage\nanomaly detection to enhance isolation in resource sharing.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nNext, we note that similar issues regarding the fulfillment of\nSLAs while maintaining high resource utilization also appear\nin cloud computing. In [16], the authors relate the resource\nallocation problem to a variation of an online knapsack prob-\nlem. The authors then note that various other aspects need\nto be included such as SLA violation costs and resource\nmigration delays that further complicate the problem. The\nauthors in [17] consider a neural network to predict user usage\nand dynamically allocate resources for higher utilization, an\napproach that is similar to [4].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nAnother related work in cloud computing is [18] where\nthe tradeoff between performance isolation and fairness is\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\naddressed. The authors also consider the possibility of mis-\nbehaving customers with skewed and shifted demands. They\npropose the decomposition of the system-wide fair sharing\nproblem into four smaller mechanisms and show robustness\nto customer misbehavior.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nOverall, we believe that the related literature mostly con-\nsiders a fixed set of provisioned resources that should be\nsplit among customers in a fair manner based on a utility\nmaximization problem. However, a customer is interested in\nreceiving the promised QoS as stated in the SLA. Hence, the\nfact that the customers receive their fair share according to\nutility maximization is of little value to them if the promised\nQoS is not delivered. Thus, resource provisioning and dynamic\nresource allocation must be studied jointly. Also, we believe\nthat mechanisms to protect the SLAs from misbehaving traffic\nhave not been investigated in detail. Here, we wish to address\nthese two gaps in the literature by proposing provisioning\nmechanisms and hypothesis testing in resource sharing.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nIII. SYSTEM ARCHITECTURE\nWe consider N NSs served by a single BS in the RAN.\nEach NS may have different type of QoS requirements. For\ninstance, a NS may wish to upper bound the average packet\ndelay of its users by a threshold, whereas another NS may wish\nto provide a constant target bitrate to each of its users. Thus,\nwe consider that NSs may use different MAC schedulers.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nLet vector Wi(t) denote the bandwidth demand of NS i at\nslot t. Bandwidth demand Wi(t) corresponds to the number\nof PRBs that the MAC scheduler of NS i needs in order to\nprovide the desired QoS throughout slot t to NS i.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nTo determine demand Wi(t), the operator may need to\nobserve the state of the NS i at time t denoted by Xi(t). For\ninstance, suppose that NS i needs to deliver a constant target\nbitrate to each of its users. To do so, the operator first collects\nthe Modulation and Coding Scheme (MCS) of each user at\nslot t, which composes the state Xi(t) of the NS. Then, given\nthe target bitrate, the operator may use Table 7.1.7.1-1 and\nTable 7.1.7.2.1-1 in 3GPP document [19] to find the necessary\nnumber of PRBs Wi(t).\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nNote that for complex QoS requirements, the online deter-\nmination of Wi(t) based on Xi(t) is not trivial. As a result,\nwe consider a network function deployed at the BS which we\ncall the Bandwidth Demand Estimator (BDE) whose objective\nis to compute Wi(t) based on Xi(t). Notice that the BDE\nenables bandwidth adaptation which is needed to achieve high\nefficiency in resource sharing. In [20], a BDE for packet delay\nrequirements is developed based on a Reinforcement Learning\n(RL) algorithm and is then tested by experimentation on a\n3GPP compliant cellular testbed. The design of new BDE is\nout of the scope of this paper.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nNext, since the provisioned PRBs at the BS may not suffice\n△\nfor all demands W(t)\n= (Wi(t))i∈[N ], the operator needs to\ndecide which ones to accept. For this reason, we consider\nanother network function at the BS which we call the Network\nSlice Multiplexer (NSM) that at each slot t decides whether to\nallocate the Wi(t) PRBs to the MAC scheduler of NS i. The\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFig. 1. We consider two network functions deployed at the BS. First, the BDE\nobserves the state Xi(t) of a NS and estimates the number of PRBs Wi(t)\nneeded to meet its desired QoS. Second, the NSM receives all bandwidth\ndemands and decides which ones to satisfy given the limited bandwidth at\nthe BS by producing binary decisions ui(t). The length of each slot t depends\non the timescales supported by these two network functions.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nNSM outputs a binary decision vector u(t) where ui(t) = 1\ndenotes acceptance of demand Wi(t). Figure 1 depicts the\noverall system architecture.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nNotice that resource sharing is performed by the NSM.\nTherefore, in this paper, we focus only on the development\nof a NSM. We note that a preliminary solution was provided\nin [2] where this system architecture was introduced. How-\never, no mechanisms to protect SLAs against anomalies were\nconsidered and resource provisioning was not fully addressed.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nIV. PROBLEM FORMULATION\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nWe consider that each customer i states in the SLA that the\noperator needs to deliver the desired QoS for P H\nfraction of\ni\ntime. Such availability requirements are widely used in real\nnetworks for resource provisioning purposes, as in Google’s\nsoftware-defined network B4 [21].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nNotice that\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\nthe previous statement\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\nthat ui(t) = 1 for at\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.8**r== 0.1**\nis equivalent\nleast P H\ni\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nto the\nrequirement\nfraction of\ntime. Let Ts denote the number of slots during which all\nNSs are deployed and W c denote the provisioned bandwidth\nat the BS. Clearly, the operator wishes to satisfy all SLAs\nwith minimum provisioned bandwidth. Thus, whenever a new\nNS needs to be deployed, the operator wishes to solve the\nfollowing optimization problem:\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\nminimize\nW c,{u(t)}t∈[Ts]\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\nui(t) ≥ P H\ni\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\nTs\nu(t)⊤W(t) ≤ W c, ∀t ∈ [Ts],\nu(t) ∈ {0, 1}N , ∀t ∈ [Ts].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nThe first constraint is the availability requirement as stated\nin the SLA. The second constraint states that the total accepted\ndemand must be less than the provisioned resources W c. The\nthird constraint implies that the NS either receives the desired\nQoS or it does not. Next, note that (1) is a Mixed Integer\nLinear Programming (MILP) problem. Unfortunately, to solve\nit, the operator must know the future demands {W(t)}t∈Ts\nand the exact system duration Ts which is not possible.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nTo approximately solve (1), we propose an approach with\ntwo phases; the trial phase and the regular phase. During the\ntrial phase, a long sequence of traffic states and bandwidth\ndemands (Xi(t), Wi(t)) is observed for each NS i. Based\non these, a stochastic model is constructed for each NS that\ndescribes its normal behavior and the required provisioned\nbandwidth at the BS is estimated.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nIn the regular phase, the operator provisions the previously\nestimated bandwidth at the BS. Then, if the total bandwidth\ndemand at some time exceeds the provisioned bandwidth, the\nNSM checks if the traffic generated by each NS was in accor-\ndance to its normal behavior as observed during the trial phase.\nThe NSM performs this check by conducting a composite\nhypothesis test for each NS based on the Neyman-Pearson\nframework. The NSs that pass this test have prioritized access\nto the provisioned bandwidth. Any remaining bandwidth is\nthen split among the other NSs. A flowchart of the overall\nsolution approach is shown in Fig. 2.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nA. Trial Phase\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nThis phase is initiated when a new NS is deployed on the\nBS. To monitor the unknown resource demands of the new NS,\nthe operator assigns as much bandwidth as possible to the BS\nto avoid situations where the poor QoS affects the behavior\nof the NS, e.g., users quitting due to large packet delays. The\nmain goal during this phase is to describe the normal behavior\nof each NS by a stochastic model and estimate the provisioned\nbandwidth required at the BS to satisfy the SLAs of all NSs.\nThe stochastic model used greatly affects the estimation of\nthe provisioned bandwidth. To gain insight on what model\nis appropriate, it is helpful to consider the models used by\nthe BDE. For instance, in [20], the BDE is based on Rein-\nforcement Learning (RL). In this case, the stochastic model\nfor (Xi(t), Wi(t)) is a Markov Decision Process (MDP). Let\nHi(t)\nτ =1 be the past state-action pairs.\nThe MDP models the process {(Xi(t), Wi(t))}t∈N as follows:\nP(Xi(t + 1) = x′|Xi(t) = x, Wi(t) = w, Hi(t) = hi)\n= Pi(x′|x, w).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\n△\n={(Xi(τ ), Wi(τ ))}t−1\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nSuppose that the NS is deployed for a large amount of time,\ni.e., Ts → ∞, and that the BDE wishes to minimize some\ntotal expected cost that depends on the state Xi(t) and action\nWi(t). Then, it suffices to consider stationary policies [22]\nthat allocate bandwidth Wi(t) given state Xi(t) as follows:\nP(Wi(t) = w|Xi(t) = x, Hi(t) = hi) = µi(w|x).\n**BLOCK**fs== 8.0**p== 3.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nFig. 2. When a new NS is deployed, the trial phase is initiated to obtain\na stochastic model for the normal behavior of each NS and to estimate the\nrequired provisioned bandwidth. Next, the regular phase is initiated using\nthe previously estimated provisions and models. Whenever there is resource\ncontention, the NSM checks if each NS behaves as expected via hypothesis\ntesting. Anomalous NSs are deprioritized in bandwidth allocation.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n̸= i since information regarding other NSs j do not\nj\nprovide any value to NS i if (Xi(t), Wi(t)) are known. Let\n△\nX(t)\n= (Xi(t))i∈[n]. Then, the vector Z(t) = (X(t), W(t))\nfollows the MC:\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nFrom (2) and (3),\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nis easy to see that\n△\n=(Xi(t), Wi(t)) follows a stationary MC:\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\nthe process\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nP(Z(t + 1) = z′|Z(t) = z, H(t) = h)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nP(Zi(t + 1) = (x′, w′)|Zi(t) = (x, w), Hi(t) = hi)\n△\n= PZi((x′, w′)|(x, w)).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\n= Pi(x′|x, w)µi(w′|x′)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nNote that it is further reasonable to assume that the random\nprocesses Zi(t) and Zj(t) are conditionally independent for\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nHence, the stochastic model of interest is a MC. We further\nconsider that all the above MCs are ergodic since state spaces\nXi and action spaces Wi are finite. Also, each MC Zi(t) is\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nexpected to contains self-loops and to be possible to reach\neach state from all\nthe other states. Therefore, each MC\nZi(t) eventually converges to its unique stationary distribution\nπZi(zi). Thus, the MC Z(t) has a unique stationary distribu-\ntion πZ(z) = N\n**BLOCK**fs== 7.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\ni=1 πZi(zi).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nSince we wish to deliver the desired QoS to NS i for at\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.9**\nleast P H\ni\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nfraction of time, let W H\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.2**r== 0.8**\n△\n= arg min\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\ni be defined as:\nTs\n**BLOCK**fs== 7.0**p== 4.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\n1Wi(t)≤w ≥ P H\ni\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\nLet πW(w)\nW(t) = w. Due to ergodicity, it follows that:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nx πZ(x, w) be the stationary probability of\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.5**r== 0.1**\nUnfortunately, most of these bounds apply only to Independent\nIdentically Distributed (IID) random processes.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nThere are only few results that extend such bounds to MCs.\nFor instance, the result in [24] provides such a bound but\nrequires the knowledge of a quantity that equals the largest\nexpected time to transition from a state x to a state y for the\nfirst time among all (x, y) pairs. Applying the result in [24]\nfor the MC Z(t), it follows that ∀ϵ > 0:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.7**r== 0.1**\n\n\nf (Z(t)) − E[f (Z(1))]\n\n\n\n2T ϵ2\n(b − a)2H 2\nZ\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\ni = arg min\nw\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nπW(w) ≥ P H\ni\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nSince the SLA dictates that the NS should be satisfied\nfor P H\nfraction of time, we may ignore any bandwidth\ni\ndemand Wi(t) > W H\n. Although treating demands higher than\ni\nW H\nas 0 is optimal for resource provisioning purposes, we\ni\nconsider it to be quite punishing. So instead we may transform\nall demands Wi(t) > W H\n, i.e., we may consider\ni\na transformed demand gi(Wi(t)) = min(Wi(t), W H\ni ). Let\ng(W(t))\nthe\nprovisioned bandwidth W c should be:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\n△\n=(gi(Wi(t))i∈[N ] Thus,\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.3**r== 0.5**\nto satisfy all SLAs,\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nW c = arg min\nw\n**BLOCK**fs== 7.0**p== 4.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n11⊤g(W(t))≤w ≥ max\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nSimilarly as before, due to ergodicity, (8) is equivalent to:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nW c = arg min\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nπW(w) ≥ max\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nIf the stationary distribution πW(w) is known, then each\nW H\ncan be found from (7) via binary search. Then, functions\ni\ngi are also known and W c can be computed from (9) also\nvia binary search. Unfortunately, in practice we do not know\nthe transition matrix of the MC Z(t) and therefore we cannot\ncompute any of these quantities. As a result, we need to esti-\nmate the above quantities from the observed data. To estimate\nW H\nand W c, we first estimate the stationary distribution πw\ni\nand proceed as described in (7) and (9).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nWe use the Maximum Likelihood Estimator (MLE) of\nπW(w) denoted by ˆπW(w) which is simply the fraction of\ntime that W(t) ≤ w in the observed sequence of length T and\ncan be easily updated online. We note that the above MLEs\nconverge almost surely to the estimated quantities and the\nasymptotic rate of convergence is known due to asymptotic\nnormality [23].\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nUnfortunately, both these results are asymptotic and hold\nfor large data sequences as T → ∞. However, in practice,\nwe are interested in the number of samples T needed to\nobtain a specific accuracy of the estimated quantity with a\ncertain probability. Hence, concentration inequalities such as\nthe Chernoff-Hoeffding bounds are particularly useful here.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nIn the above, function f maps states to a value in [a, b] and\nHZ = maxx,y E[Ty|Z(1) = x] where Ty = inf{t ≥ 0 :\nZ(t + 1) = y}. The result in [24] applies if the concerned MC\nhas finite states, is irreducible and its initial distribution is one\nof its stationary distributions.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nNote that HZ is not known in practice since it depends on\nthe transition matrix of the MC Z(t). Nonetheless, we argue\nthat the periodic traffic patterns observed in real networks\nprovide insight for its value. For instance, the period of the\ntraffic patterns can be considered as an approximation of HZ.\nTo leverage (10) for the estimation of πw, we consider\nfw(Z(t)) = 1W(t)=w and hence a = 0 and b = 1. Then,\nto bound by δ the probability that\nthe absolute deviation\nof |ˆπW(w) − πW(w)| exceeds ϵ, the following sufficient\ncondition is obtained from (10):\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nAnother Hoeffding bound for MCs is provided in [25]. The\nauthors show an optimal bound which requires the knowledge\nof the spectral gap 1 − λ of its transition matrix, where λ is\nits second largest eigenvalue in absolute value. Similarly as\nbefore, it follows from [25] that it suffices to consider:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.6**r== 0.2**\nis known that λ ∈ [0, 1),\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nthus the lower bound is\nminimized when λ = 0 which occurs when the rows of the\ntransition matrix are equal [25]. In this case (12) coincides\nwith the classical Hoeffding bound for the IID case. Thus, at\nbest case scenario, the number of samples T is ln(2/δ)/(2ϵ2).\nFor some transition matrices obtained during experimenta-\ntion, the lower-bound in (12) was significantly lower than the\none in (11). Thus, suppose that we consider ϵ = 0.01 and\nδ = 0.01 in ln(2/δ)/(2ϵ2). We readily obtain T ≈ 120K.\nNext, suppose that we observe a sample every 10 seconds, i.e.,\nthe slot length in Fig. 1 is 10 seconds. Then, the trial phase\nshould be at least 2 weeks. If we further wish to model every\n8-hour period in the day with a different MC, the duration of\nthe trial phase needs to be at least 1.5 month.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nUnfortunately, we do not have a dataset with that many con-\ntiguous samples. However, we noticed during experimentation\nthat even the best-case scenario bound may be loose since a\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nsmaller number of samples did not lead to SLA violations.\nHence, we consider small T values such as 7200. Once the\nand W c are\nT samples are obtained, the estimates of W H\ni\nobtained from (7) and (9) respectively via binary search.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nApart from the above estimates, we further need to estimate\nthe transition matrix PZi of MC Zi(t) that describes the\nnormal behavior of each NS i. The MLE for the transition\nprobabilities PZi(z′\ni|zi) is simply the number of times there\nwas a transition from state zi to state z′\ni over the total number\nof times state zi occurred. Once again, it is known that the\nMLE converges almost surely to the estimated quantity and\nthat asymptotic normality holds [23]. Unfortunately, we were\nnot able to obtain any bounds for finite samples as previously\neven though [24] provides a Chernoff-Hoeffding bound when\nthe function f receives two arguments.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.3**l== 0.1**r== 0.5**\nThe overall estimation procedure during the trial phase is\nsummarized in Algorithm 1. We note that the algorithm can\nbe simplified if certain conditions are met. First, given the\nindependence assumption regarding the processes Zi(t), we\nmay use the estimator ˆπW(w) = N\ni=1 ˆπWi (wi) and estimate\nthe distribution of the total transformed demand 1⊤ˆg(w) by\nconvolution. Even though we consider the processes Zi(t) to\nbe independent, we do not follow the previous method and\ninstead directly estimate the distribution of the whole demand\nvector πW for simplicity. Next, note that if the demands are\nnot transformed, i.e., gi(x) = x, then we may skip many steps\nin Algorithm 1 since we can directly estimate the cdf of 1⊤w.\nA procedure in Algorithm 1 that requires a large amount of\nmemory involves the estimation of the transition matrices PZi.\nNote that each Zi(t) = (Xi(t), Wi(t)) is composed by a vector\nof dimension dim(Xi)+1 and the size of observed transitionsi\nmay be |Xi × Wi|2. However, notice that if the NSM knows\nthe stationary policy µi(w|x) used by the BDE which is\nlikely to be the case since both the BDE and the NSM\nrun at the BS, then the NSM needs to estimate only the\ntransition probabilities Pi(x′|w, x) as in (4). Furthermore, if\nthe stationary policy used by the BDE is deterministic, i.e.,\nWi(t) = µi(Xi(t)), then the NSM needs to estimate only the\nMC that its state Xi(t) follows. Since ϵ-soft polices are used\nin many popular RL algorithms and they can be approximated\nby a deterministic policy, we may estimate only the MC of\nprocess Xi(t). Also, the estimation of the MC of Xi(t) may\nbe further simplified if its of each components follows an\nindependent MC. Lastly, a crude approximation of the normal\nbehavior of a NS may be obtained by assuming that each\nprocess Wi(t) follows an independent MC.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nB. Regular Phase\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nAt this point, each NS has been through the trial phase\nand a MC that describes its normal behavior has already been\nobtained. Also, the provisioned bandwidth should satisfy all\nNSs for maxi P H\nfraction of time. Nonetheless, for the rest\ni\nof the time, the bandwidth may not suffice. Moreover, a NS\nmay generate unexpected traffic patterns, e.g, due to a special\nevent, that increase its bandwidth demand. In such cases, the\nNSM needs to reject some of the demands.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nAlgorithm 1: Estimation Procedure in Trial Phase\n1 Input: parameters ϵ, δ, HZ, P H\ni\n2 Output: ˆW H\ni\n3 T ≈ 7200\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\n, ˆPZi, ˆW c\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.2**\n/* Collect statistics online\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.5**r== 0.4**\n4 for t ≤ T do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.6**r== 0.2**\nget Z(t) = (X(t), W(t))\nobserved demands.add(W(t))\ncounts(W(t))+=1\nobserved sums.add(1⊤W(t))\ntotal demand count(1⊤W(t))+ = 1\nfor each NS i do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\nobserved transitionsi.add((Zi(t − 1),Zi(t)))\ntransition countsi(Zi(t − 1), Zi(t))+ = 1\nZ countsi(Zi(t))+ = 1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nZ(t − 1) = Z(t)\n/* MLE of pmf πw\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.5**r== 0.2**\n15 for w ∈ observed demands do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.6**r== 0.2**\nˆπW(w) = counts(w)/T\ncountsi(wi)+ = counts(w)\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\n/* MLE of P H\n18 for each NS i do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nsort W in increasing order\nfor w ∈ W do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\ni -percentiles W H\ni\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.6**r== 0.2**\nˆπWi(w) = countsi(w)/T\ns+ = ˆπWi(w)\nif s ≥ P H\ni\nˆW H\ni = s\nbreak\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n/* MLE of provisioned bandwidth W c */\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.5**r== 0.2**\n26 ˆgi(x) = min(x, ˆW H\ni )\n27 for w ∈ observed demands do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.6**r== 0.2**\nobserved gsums.add(1⊤ˆg(w))\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n29 sort observed gsums in increasing order\n30 for s ∈ observed gsums do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.6**r== 0.2**\ncdf+ = total demand count(s)\nif cdf ≥ maxi P H\ni\nˆW c = s\nbreak\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n/* MLE of transition matrices Pi\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n35 for each NS i do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.2**\nfor (z, z′) ∈ observed transitionsi do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nˆPZi(z′|z) =\ntransition countsi(z, z′)/Z countsi(z)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nGiven that the provisioned bandwidth ˆW c was computed\nby considering that each NS follows its normal behavior as\ndescribed by its MC Zi(t), it is fair to reject NSs that do\nnot follow these MCs. For this reason, we consider that the\nNSM performs hypothesis testing when N\ni=1 Wi(t) > ˆW c.\nThe null hypothesis H 0\ni (t) is that NS i follows so far the MC\nˆPZi obtained during the trial period. The alternative hypothesis\nH 1\ni (t) is that the NS at some time t − n + 1 switched to a\ndifferent MC. Hence, a composite hypothesis test is consid-\nered. Selecting H 0\ni (t) implies that NS i behaves normally so\nfar and thus has prioritized access to the bandwidth.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nTo conduct the hypothesis test, we consider the Neyman-\nPearson framework [26]. In this framework, we wish to bound\nthe false alarm rate, i.e., the probability that we incorrectly\nselect the alternative hypothesis H 1\ni (t), while maximizing the\ndetection power, i.e., the probability that we correctly select\nH 1\ni (t). To do so, we check the likelihood ratio of the hypothe-\nses and pick the alternative hypothesis if and only if the ratio\nis larger than a parameter γi. Let Zi(n, t) = {Zi(τ )}t\ndenote the last n samples at time t. Then, the hypothesis H 1\nis selected if and only if:\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.4**l== 0.2**r== 0.7**\nt\n\nτ =t−n+1\nt\n\nτ =t−n+1\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nˆQZi(Zi(τ )|Zi(τ − 1))\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nˆPZi(Zi(τ )|Zi(τ − 1))\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nwhere ˆQZi is the MLE of the transition matrix of the MC that\nsamples Zi(n, t) follow.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nThe γi in (13) that maximizes the detection power while\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nbounding the false alarm rate by αi is selected as follows:\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nγi = arg min\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nP(Zi(n) : L(Zi(n)) > γ|H 0\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nwhere the subscript t was dropped since the MC Zi(t) is\nstationary. The Neyman-Pearson Theorem [26] states that this\nlikelihood ratio test achieves the highest detection power given\na bound on the false alarm rate out of all possible tests.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nNote that ideally we wish to perform the hypothesis test\n∀n ≤ t in order to check whether the transition matrix changed\nat any time in the past which corresponds to model change\ndetection with unknown change time [26]. However, such a\ntest is too computationally intense to be conducted online.\nFor this reason, we consider a fixed sample size n and hence\nonly check whether the MC changed at time t − n + 1.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nUnfortunately, even for a fixed n, (14) is quite complex to\nsolve and therefore γi cannot be computed exactly. Thus, we\nconsider the asymptotic result that as n → ∞, the random\nvariable 2 ln L(Zi(n)) follows the chi-square distribution χ2\nr\nunder hypothesis H 0\ni (t) [26]. The distribution parameter r is\nequal to the total degrees of freedom in the test.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nIn our case, the transition probabilities ˆQZi(z′|z) are |Zi|2\nin total. However, for each z, it holds that \nˆQZi(z′|z) = 1.\nz′\nSince the transition matrix ˆPZi is fixed, then r = |Zi|2 − |Zi|.\nThus, in the asymptotic regime, it follows from (14):\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nSince (15) holds only for large data records as n → ∞,\nthen we may not consider small n to detect model changes\nthat occurred in the recent past. Hence, if the behavior of the\nNS changes only for very brief periods of time and then reverts\nback to normal, we may never detect any anomalies. However,\nwe argue that such fast and brief changes of time may not have\na large effect on the resource allocation process. Lastly, note\nthat the memory required for the test depends on n.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\ni (t) selected} denote the set of NSs\nthat behave normally at time t according to the hypothesis tests\nand let B(t) denote the set of NSs that do not. We then split\nthe resources among the NSs in A(t) using the Max-Weight\nscheduler [27]. Specifically, we consider a deficit di(t) owed\nto each NS i that is defined as follows:\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.6**r== 0.2**\ndi(t + 1) = [di(t) − ui(t)]+ + P H\ni\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n(16)\nThe bandwidth ˆW c is split among the NSs in A(t) as follows:\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.4**l== 0.8**r== 0.2**\nui(t)di(t)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nmaximize\n{ui(t)}i∈A(t)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\ni∈A(t)\nui(t)Wi(t) ≤ ˆW c,\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.7**r== 0.2**\ni:A(t)\nui(t) ∈ {0, 1}, ∀i ∈ A(t).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nThe above scheduling procedure is motivated by the fact\nthat if the deficits in (16) are strongly stable, then the first\nconstraint in (1) holds w.p.1 as Ts → ∞ [27]. Although (17)\nis a binary knapsack problem and thus NP-Hard, we utilize\nthe Google OR-Tools solver in [28] to obtain an exact solution\nrelatively fast using a branch and bound method. Lastly, we\nmention that this scheduler is also used in [2].\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nLet u∗\ni (t) for i ∈ A(t) denote a solution of (17) and\nlet W R(t)\ni (t)Wi(t) denote the remaining\nbandwidth. Upon splitting bandwidth ˆW c as in (17), either all\nNSs in A(t) are satisfied, i.e., u∗\ni (t) = 1 for all i ∈ A(t) or\nthere are some NSs in A(t) whose demand Wi(t) is not fully\nmet. Let AR(t)\ni (t) = 0} denote the NSs in\nA(t) whose demand was not fully met.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nNotice that if AR(t) ̸= ∅, then the remaining bandwidth\nW R(t)\ni (t)Wi(t) ≤ mini∈AR(t) Wi(t).\nOtherwise, u∗(t) would not be an optimal solution to (17). To\nfully utilize the remaining bandwidth W R(t), we may solve\na utility maximization problem for the NSs in AR(t). Let\nW R\ni (t) denote the bandwidth received by NS i. Then, we may\nconsider a simple utility function Ui(W R\ni (t)/Wi(t)\nfor each NS i, and maximize the total utility as follows:\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.8**r== 0.2**\nW R\ni (t)\nWi(t)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nmaximize\ni (t)}i∈AR (t)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.7**r== 0.2**\ni∈AR(t)\ni (t) ≤ W R(t),\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\ni:A(t)\n0 ≤ W R\nW R\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.7**r== 0.1**\ni (t) ≤ Wi(t), ∀i ∈ AR(t),\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nNote that the solution to the above problem is to sequentially\nfind the currently smallest Wj(t) and assign as much band-\nj (t). Notice that if Wj = R, then\nwidth as possible to W R\nwe simply assign the whole remaining bandwidth W R\nj (t) =\nW R(t), where Wj(t) ≤ Wi(t) ∀i ∈ AR(t), since W R(t) ≤\nmini∈AR(t) Wi(t) as explained previously.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nIn case that AR(t) = ∅, we may decide to split\nthe\nremaining bandwidth W R(t) to the NSs in B(t) that do not\nbehave normally according to the hypothesis test. Thus, we\nmay then solve (17) for the set B(t) instead of the set A(t).\nThe overall detection and bandwidth allocation procedure\nduring the regular phase is described in Algorithm 2. Similarly\nas in the trial phase, the algorithm can be significantly sim-\nplified under certain conditions. For instance, if NSM knows\nthe stationary policy µi(w|x) used by the BDE, then we may\ninstead perform two simpler hypothesis tests; one that checks\nwhether the stationary policy µi(w|x) is followed and one\nto check whether the transition probabilities ˆPi(x′|x, w) are\nfollowed as implied by (4). These tests have smaller numbers\nof total degrees of freedom and can be performed in parallel.\nFurthermore, in case the stationary policy is deterministic,\ni.e., Wi(t) = µi(Xi(t)), then the NSM may simply first check\nif Wi(τ ) = µi(Xi(τ )), ∀τ in the observation window. If\nthe condition does not hold, then the alternative hypothesis\nH 1\ni (t) is selected. Otherwise, the hypothesis test needs to only\ninvolve the parameters ˆQi(x′|x, µi(x)). Similarly as before, if\nthe state components of a NS follow independent MCs, then\nwe may consider a simpler hypothesis test for each of them.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nVI. SIMULATION SETUP\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nA. Schemes\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nTo properly evaluate our approach, we compare it to two\nother baselines. Overall, the three schemes are the following:\nSharing and Testing (ShT): This scheme is the proposed\nsolution approach in Sec. V. In this scheme, resource sharing\nis augmented by hypothesis testing to enhance isolation. By\nShTn, we refer to this scheme run with sample size n in\nhypothesis testing.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nSharing (Sh): In the trial phase, this scheme is identical\nto the previous one. In the regular phase ,the scheme skips\nhypothesis testing and sets A(t) = [N ] in Algorithm 2.\nNo Sharing (NoSh): This scheme provisions ˆW H\ni\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nband-\nwidth for each NS i which is the estimation of the P H\ni -\npercentile of process Wi(t) as obtained in the trial phase.\nClearly, the total provisioned bandwidth is \n. In the\nregular phase, the demand Wi(t) is guaranteed to be accepted\nif Wi(t) ≤ ˆW H\n. Any leftover bandwidth is split among the\ni\nother NSs. The scheme is run by skipping hypothesis testing\nand considering i ∈ A(t) iff Wi(t) ≤ ˆW H\ni\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\nin Algorithm 2.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.8**\nB. Metrics\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nThe schemes are compared based on two metrics. The\nfirst one is the required provisioned bandwidth ˆW c as es-\ntimated during the trial phase. The second one is the re-\nsulting acceptance ratio in the regular phase denoted by\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\n, ˆPZi , ˆW c, n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nAlgorithm 2: Resource Sharing in Regular Phase\n1 Input: ˆW H\ni\n2 Output: u(t), WR(t)\n3 set ri = |Zi|2 − |Zi| and γi = exp(F −1\nri\n4 set di(0) = P H\ni\n5 for t ≤ Ts do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nset u(t) = 0 and get Z(t) = (X(t), W(t))\nfor each NS i do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.2**l== 0.6**r== 0.3**\nn samplesi.add(Zi(t))\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nif t > n then\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nn samplesi.pop()\nif 1⊤W(t) ≤ ˆW c then\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\nfor each NS i do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nan=hypothesis test(n samplesi, γi, ˆPZi)\nif an==False then\nA(t).add(i)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nB(t).add(i)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.6**r== 0.2**\nbandwidth allocation()\nif AR(t) = ∅ then\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nset ˆW c = W R(t) and A(t) = B(t)\nbandwidth allocation()\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\ndi(t + 1) = [di(t) − u∗\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\n/* Functions\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.5**r== 0.2**\n25 hypothesis test(n samples, γi, ˆPZi):\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nfor 2 ≤ k ≤ n do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nz′ = n samples[k]\nz = n samples[k-1]\nt counts(z, z′)+ = 1\nZ counts(z′)+ = 1\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\nL0 = L1 = 1\nfor 2 ≤ k ≤ n do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nz′ = n samples[k], z = n samples[k-1]\nˆQZ(z′|z) = t counts(z, z′)/Z counts(z′)\nL1 = ˆQZi(z′|z)L1, L0 = ˆPZi(z′|z)L0\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\nif L1 ≥ γiL0 then\nreturn True\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nreturn False\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n40 bandwidth allocation():\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.6**r== 0.2**\nsolve Binary Knapsack Problem (17)\nfor each NS i ∈ A(t) do\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.6**r== 0.3**\ni (t) == 0 then\nAR(t).add(i)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\nif W R(t) > 0 then\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.6**r== 0.1**\nsolve linear optimization problem (18)\n**BLOCK**fs== 8.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nFig. 3. A small sample of a parquet file found in the dataset. Here, two lines\nexist with the same timestamp and direction = 1. This indicates that two UEs\nwere receiving traffic from the BS during that subframe.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nt=1 ui(t)/Ts. Notice that ai should be at least P H\nai\ni\nshown in the first constraint of optimization problem (1).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\ni and rw\ni\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nNotice that rc\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nMoreover, to gain more insight regarding the performance\nof each scheme, we also plot the ratio of correct and wrong\nrejections of each NS i denoted by rc\nrespectively.\nThe first ratio is the number of times that hypothesis testing\nrejected NS i and it was indeed anomalous at that time over\nthe number of times that hypothesis testing occurred and NS\ni was anomalous. The second quantity measures the ratio of\nwrong rejections similarly.\ni and rw\ni\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nseem similar to the power and\nfalse alarm rate of the detector used in hypothesis testing.\nHowever, they differ from them since the detector checks if all\nn previous samples where generated by the expected stochastic\nmodel, not just the most recent one. Hence, if a NS i stops\nmisbehaving at t, the detector is designed to reject it at time\nt = t + n/2 even if NS i is not anomalous at that time.\nTherefore, the quantities rc\ni and rw\ni allow us to investigate\nthe effect of sample size n on performance during transition\nperiods where a NS starts or stops misbehaving.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nC. Dataset\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\nTo evaluate the aforementioned schemes, we use the dataset\nin [29] which was made publicly available by the IMDEA\nNetworks Institute1. It contains LTE mobile traffic at several\nBSs in Spain that was captured around 2020. The authors\nobtained these measurements by running a passive monitoring\ntool called Falcon [30] on a Linux laptop that was connected\nto a USRP B210 Software Defined Radio (SDR). The authors\nthen connected to various BSs and used Falcon to decode the\nPhysical Downlink Control Channel (PDCCH) sent by the BS\nto the connected User Equipments (UEs) in order to extract\nresource allocation information with millisecond granularity.\nThe obtained raw data is stored as parquet files. Each line in\nthe files contains the following: the unix timestamp, the system\nframe and the subframe number in LTE, the Radio Network\nTemporary Identifier (RNTI) of the UE, the direction of the\ntraffic, i.e., uplink or downlink, the MCS index used by the UE\nand the number of PRBs utilized by the UE at that particular\nsubframe. A sample of the file is shown in Fig. 3.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nD. Extraction of state time series {Xi(t)}t∈N\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nSince the system architecture proposed in Fig. 1 is not\ndeployed at the BSs, we use the dataset to create a time series\nfor Z(t) for the evaluation of our proposed approach. We\nprimarily focus on downlink traffic since it comprises most of\nthe mobile traffic. Hence, we wish to obtain a time series for\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\n1https://git2.networks.imdea.org/wng/madrid-lte-dataset\n**BLOCK**fs== 10.0**p== 8.0**b== 0.9**t== 0.1**l== 0.5**r== 0.1**\nthe states Xi(t) and their corresponding bandwidth demands\nWi(t) for each NS i in downlink.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nTo do so, we consider that the state Xi(t) includes the\nnumber of UEs in Radio Resource Control (RRC) Connected\nstate and their average MCS at time t. Notice that the number\nof RRC connected UEs at some time t differs from the UEs\nthat are actively transmitting or receiving at time t. This is the\ncase since the MAC scheduler may wish to prioritize some\nUEs and allocate the whole bandwidth to them. Therefore,\nalthough some UEs may have data to transmit or receive, the\nMAC scheduler may not schedule them for transmission. As a\nresult, we cannot simply count the number of lines in the data\nfile at some time t as in Fig. 3 to approximate the number of\nUEs in RRC Connected state.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nInstead, we utilize the approach as in [29] where the\nauthors use a method that maps the temporary RNTIs to UE\nidentifiers. This method was originally developed in [31] and\nit essentially attempts to find the expiration period of the\ntemporary RNTIs. Based on this estimation, the number of\nUEs in RRC Connected state can be estimated since an RNTI\nacts as a UE identifier within its expiration period. The authors\napplied the method in [31] on their raw data files and obtained\nan estimation of the number of RRC Connected UEs with one\nsecond granularity which is also included in their final dataset.\nHence, for the first component of the state Xi(t) we use this\nreadily available data.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nRegarding the second component of the state Xi(t), we\nconsider the average MCS over all users actively transmitting\nat time t. We compute this simply by taking the average of\nthe ”mcs idx” column in Fig. 3 for lines with timestamp = t\nand direction = 1 since we are interested in downlink traffic.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nE. Definition of desired QoS\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nIn order to derive the time series for Zi(t) based on the\ntimes series Xi(t), it is necessary to define the desired QoS\nof each NS i. We consider a simple QoS requirement that\nfacilitates an easy map from Xi(t) to Wi(t). Specifically, we\nconsider each NS i requires a constant bitrate Ri for each UE\nthat is in RRC Connected state at each slot t.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nF. Extraction of bandwidth demand time series {Wi(t)}t∈N\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nWe compute the required PRBs Wi(t) to provide bitrate\nRi to each connected UE at time t based on Table 7.1.7.1-1\nand Table 7.1.7.2.1-1 in 3GPP document [19] as mentioned\npreviously in Sec. III. Notice that the second component of\nXi(t), i.e., the average MCS over all users at time t and the\nbitrate Ri are the two elements needed to obtain the PRBs\nneeded for a single UE based on the previous tables. Then, we\nmultiple this amount of PRBs by the first component of Xi(t),\ni.e., the number of connected users, to compute the bandwidth\ndemand Wi(t). Lastly, we assume that all UEs support 2x2 and\nthus we multiple the contents of the second table by 2.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWe note that it would be more accurate to repeat this process\nfor each UE individually. However, this would require that\nXi(t) contains the MCS index of each UE which requires large\nmemory. Although this is feasible, we consider the average\n**BLOCK**fs== 10.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nMCS index over all UEs and then multiple the resulting PRBs\nby the number of UEs for simplicity.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nWe mention that an alternative way to derive the bandwidth\ndemand at time t would be to use the raw data files by sum-\nming the ”nof prb” column for all entries with timestamp = t\nand direction = 1. In this case, the bandwidth demand Wi(t)\nis approximated by the total number of PRBs allocated to the\nNS at time t. This is reasonable assuming that the BS delivered\nthe desired QoS to the UEs.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nAlthough this is a simple approach, we noticed that the total\nPRBs for some subframes t exceeded 100 PRBs which cannot\nbe true since the cell bandwidth at the BS is 20 MHz. Upon\ncontacting the authors in [29], we were informed that such\nanomalies happen when the PDCCH is decoded erroneously\ndue to low Signal to Noise Ratio (SNR) at the SDR. For this\nreason, we consider the method described previously to derive\nthe bandwidth demands Wi(t) over time. We note that we\ncould not find any other publicly available dataset that contains\ngranular resource allocation information at the BS.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nLastly, notice that the above procedure creates a determin-\nistic map Wi(t) = µi(Xi(t)) and hence it suffices to consider\nonly the MC of Xi(t) when conducting hypothesis testing as\nexplained in the last paragraph of Sec. V.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nG. Time, State and Action Aggregation\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nWith the previous procedures, we obtain a time series Zi(t)\nwith one second granularity. However, it may not be realistic\nthat the BDE operates in such a fast time scale. For this reason,\nwe create a new time series Zi(t) by aggregating every D\nseconds where D corresponds to the slot length in Fig. 1. Here,\nwe typically consider D = 10 seconds. The time aggregation\nof the state series Xi(t) is conducted by sampling the original\nseries every D entries. In general, the aggregation of the Wi(t)\nseries is performed by representing every D entries by their\nmaximum to approximate the output of a BDE based on RL\nthat operates every D seconds and learns a map between Xi(t)\nand Wi(t). However, here we aggregate demands in time by\nWi(t) = µi(Xi(t)) as previously.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nWe also consider another form of aggregation. Given that\nthe BDE may run a RL algorithm, we consider aggregation in\nthe state and action space. For instance, we may consider that\nthe first component of Xi(t) takes values that are multiples\nof a constant Ui = 10. Thus,\nif the actual number of\nUEs at time t is between [10, 20), then Xi(t) = 10. Such\naggregations in the state and action space may significantly\nreduce the convergence time and the memory requirements in\nthe BDE with little performance loss. Thus, we consider such\naggregation constants for each NS i denoted by Ui, Mi and\nWi for the first state component, the second state component\nand the action respectively.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.6**\nH. Extraction of time series {Z(t)}t∈N\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nSo far we described how to extract a single time series Zi(t).\nHowever, we need to extract multiple such series to compose\nZ(t) when considering multiple NSs. To this end, each time\nseries Zi(t) should be extracted from traffic data from the\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nsame BS and time period to consider traffic that competes for\nthe same resources. This data should then be split into chunks\nby associating different groups of UEs to different NSs.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nUnfortunately, this is not feasible since the dataset does\nnot contain unique UE identifiers as mentioned earlier. Thus,\nwe should then consider data samples that may originate\nfrom different BSs but still correspond to the same time\nperiod. However, we could not find any such data samples. A\npossible explanation is that the authors in [29] used only one\nSDR for their measurements and thus could not obtain data\nfrom different BSs at the same time. As a result, we collect\ndata samples from different BSs and time periods which we\nthen associate to different NSs. Nonetheless, the time periods\nconsidered have certain common characteristics.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nSpecifically, we consider data collected between specific\nhours, e.g., from 17:00 to 22:00 every day from Monday to\nFriday. Then, the samples collected from Monday to Thursday\nare used for the trial phase and the ones collected on Friday\nare used for the regular phase. The previous example results\nto T = 7200 samples. We note that the selection of a certain\nrange of hours is motivated by the fact that real traffic varies\nconsiderably throughout the day. Thus, we consider that a\nsingle MC PZi cannot model the traffic during the whole day\nbut only during specific hours of each day.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nLastly, we note that the measurement in the raw data files\nare sometimes sparse. Therefore, the specific hours considered\nvary from experiment to experiment in order to obtain data\nsamples that are dense. As a result, we do not utilize (11)\nto determine the number of samples needed during the trial\nphase. Instead, we obtain the data as described previously.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nI. Creation of anomalies\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nAs mentioned in Sec. V,\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nthe anomalies considered are\nchanges in the transition matrix of the process Zi(t). In case\nWi(t) = µi(Xi(t)), then it suffices to consider variations for\nthe PXi transition matrix. Moreover, if the state components\nfollow independent MCs, then it suffices to consider variations\nto one of these MCs. As a result, we primarily modify the\ntransition matrix PUi that the number of connected users Ui(t)\nfollows. Such modifications may model an increase in the\nnumber of connected UEs to the BS.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nLet P ′\ndenote the new transition matrix followed by Ui(t)\nUi\nand let P ′\n(u′|u) denote its elements. To properly evaluate our\nUi\napproach, the new matrix P ′\nmust be constructed carefully.\nUi\nOtherwise,\nthe anomalies may be easily detected by the\nhypothesis testing procedure. For instance, the matrix P ′\nUi\nshould not contain any new entries, i.e., P ′\n(u′|u) = 0 if\nUi\nthe old entry PUi(u′|u) = 0. In addition, we are interested in\nnew matrices P ′\nthat produce higher demands µi(Xi(t)) and\nUi\nresult in resource contention that may negatively impact the\nperformance of the other NSs.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nDue to the above, we construct the new matrix P ′\nby\nUi\ndeleting the lowest β% of states in the MC of Ui(t). To do so\nwithout creating new entries, the transition probability from a\nstate s to a removed state s′ is added to the largest transition\nprobability from s. As a result, we create a new matrix that\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nFig. 4. Anomalies are created by changing the MC of a NS. Here, we remove\nthe lowest β = 50% states of the MC. Then, each state’s largest transition\nprobability is increased so that each row of the new matrix sums to 1.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\nFig. 5. The ECDF of the connected users in the regular phase.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nis similar to the original one but whose states correspond\nto higher number of users. Thus, the new matrix skews the\nbehavior of the NS towards generating higher bandwidth\ndemands. Figure 4 illustrates the previous procedure.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nOnce the new matrix P ′\nUi\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nis obtained, an anomalous se-\nquence {Ui(t)}ts≤t ≤te can be generated where ts and te\ndenote its start and end respectively. Notice that ts must be\nchosen carefully so that there is a smooth transition between\nthe old and new sequence. Otherwise, the anomaly is easy\nto detect. For this reason, we choose ts as the earliest time\nthat the old sequence arrives at one of the new states in P ′\n.\nUi\nHowever, we also wish that the anomaly starts once the sample\nsize n is complete to consider the effect of old samples in the\ndetection. Thus, we impose that ts > n. For similar reasons,\nwe wish that te < Ts − n. Lastly, we set te as high as possible\ngiven the previous constraints so that the anomaly can have an\neffect on resource allocation and create resource contention.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nVII. SIMULATION RESULTS\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nA. Test Scenario 1\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nIn the first test scenario, we consider two NSs. Each NS\nneeds to constantly deliver R0 = R1 = 1 Mbps to each\nconnected UE for at least P H\n1 = 0.9 fraction of slots.\nThe data for NS 0 and NS 1 are taken from the ”I-1815-raw-df-\nms.parquet” and ”I-2650-raw-df.ms.parquet” files respectively.\nThe data collection period for both NSs is from 17:00 to 22:00\neach day from Monday, May 25 to Friday, May 29, 2020.\nThe days from Monday to Thursday comprise the trial phase,\nwhereas Friday comprises the regular phase.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nWe first consider that all NSs behave normally during the\nregular phase to obtain a reference point. Then, we consider\nthat NS 0 is anomalous for various β. We plot the metrics\nmentioned previously for each scheme and for each case. We\nvary the sample size n to determine its effect on performance.\nWe depict some traffic statistics of this test scenario in Fig. 5\nand Fig. 6. The results are shown in Tables I-IV.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nIn Table I, we verify that\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nthe provisioned bandwidths\nestimated in the trial phase suffice for both NSs and the\nSLAs are fulfilled. Notice that a0 and a1 in the regular phase\nare slightly higher than the target P H\n1 = 0.9. This\nmay indicate a small discrepancy between the statistics of the\ndata in the trial phase and in the regular phase. However, the\nincrease is probably due to the fact that the no sharing scheme\nallows the use of the idle W H\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nFig. 6. The ECDF of the bandwidth demand in the regular phase.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nIn Table II, NS 0 is anomalous with β = 0.5. As expected,\nthe no sharing scheme protects the performance of NS 1.\nHowever, in the sharing scheme, the SLA of NS 1 is violated\nsince a1 < 0.9. In contrast, the sharing and testing scheme\nprotects the SLA of NS 1 when n ≥ 100. This is also\nreflected in the fair rejection ratio where rc\n0 becomes high at\nn = 100. This indicates that hypothesis testing starts to detect\nanomalies for n ≥ 100. Also, notice that rw\n0 also increases\nas n does since more outdated samples are stored which is\ndetrimental when an anomaly stops. Since the anomaly exists\nalmost throughout the simulation, these detrimental effects are\nparticularly pronounced here. However, these effects would\nwash off in longer simulations. Also, we note that the above\nissue affects only NSs that at some point were anomalous for\nwhich the operator is not required to fulfill their SLA.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nSimilar observations can be made for the cases where β =\n4/6 and β = 5/6 in Tables III and IV respectively. Here, also\nnote that anomalies can be detected for a smaller sample size\nn = 50 since they are more pronounced and thus the detector\nrequires fewer samples to accurately detect them. Overall, in\nthe cases where the simple sharing scheme fails, the proposed\nscheme satisfies the SLAs with 19% less bandwidth than the\nno sharing scheme.\n**BLOCK**fs== 6.4**p== 10.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nTABLE I\nTEST SCENARIO 1: RESULTS WHEN ALL NSS BEHAVE NORMALLY.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.6**r== 0.3**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 6.4**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nTABLE II\nTEST SCENARIO 1: RESULTS WHEN NS 0 IS ANOMALOUS WITH β = 0.5.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 6.4**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nTABLE III\nTEST SCENARIO 1: RESULTS WHEN NS 0 IS ANOMALOUS WITH β = 0.67.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.6**t== 0.3**l== 0.1**r== 0.8**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\nFig. 7. The ECDF of the connected users in the regular phase.\n**BLOCK**fs== 6.4**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nTABLE V\nTEST SCENARIO 2: RESULTS WHEN ALL NSS BEHAVE NORMALLY.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nB. Test Scenario 2\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nC. Test Scenario 3\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nIn the second test scenario, we consider again two NSs. We\nconsider required constant bitrates R0 = 1 and R1 = 2 Mbps\nand QoS delivery for P H\n1 = 0.9 fraction of slots. The\ndata for NS 0 and NS 1 are taken from the ”I-1796-raw-df-\nms.parquet” and ”I-1815-raw-df.ms.parquet” files respectively.\nThe data collection period for NS 0 is from 14:00 to 19:00\neach day from June 17 to June 19, 2020 and for NS 1 from\n14:00 to 19:00 each day from May 25 to May 27, 2020. The\nlast day corresponds to the regular phase.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nHere, we consider all possible β for each NS to test the\nschemes for various anomalies. For brevity, we do not depict\nthe granular information provided by the previous tables. In\nFig. 7, we depict ECDF of the users. Table V shows that\nall schemes satisfy both SLAs when no NS misbehaves, but\nresource sharing schemes do so with 21% less bandwidth. In\nFig. 8, we show the performance of the schemes as we vary\nthe number of low states removed from the user MC of NS 0.\nThe results show that hypothesis testing protects the SLA of\nthe well-behaved NS 1. The corresponding results when NS 1\nis anomalous are shown in Fig. 9. In this case, no hypothesis\ntesting was needed, possible because the traffic in NS 1 is\nlighter as shown in Fig. 7.\n**BLOCK**fs== 6.4**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nTABLE IV\nTEST SCENARIO 1: RESULTS WHEN NS 0 IS ANOMALOUS WITH β = 0.83.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.1**t== 0.8**l== 0.1**r== 0.8**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nIn the third test scenario, we consider 3 NSs. The required\nconstant bitrates are R0 = R2 = 1 and R1 = 2 Mbps\nwith P H\n2 = 0.9. The data for NS 0, NS 1\nand NS 2 are taken from the ”I-1796-raw-df-ms.parquet”, ”I-\n1815-raw-df.ms.parquet” and ”II-816-raw-df.ms.parquet” files\nrespectively. The collection period for NS 0 is from 9:00 to\n17:00 each day from June 15 to June 19, 2020. For NS 1, we\ncollect data from 9:00 to 17:00 each day from May 11 to May\n15, 2020. Lastly, for NS 2, the collection period is from 9:00\nto 17:00 each day from April 7 to April 11, 2021.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nFig. 8. The kth column corresponds to case where the k lowest states have\nbeen removed from the user MC of NS 0.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nFig. 9. The kth column corresponds to case where the k lowest states have\nbeen removed from the user MC of NS 1.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nFig. 10. The ECDF of the connected users in the regular phase.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nFig. 13. The kth column corresponds to case where the k lowest states have\nbeen removed from the user MC of NS 1.\n**BLOCK**fs== 6.4**p== 12.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nTABLE VI\nTEST SCENARIO 3: RESULTS WHEN ALL NSS BEHAVE NORMALLY.\na0 (%)\n**BLOCK**fs== 9.0**p== 12.0**b== 0.6**t== 0.3**l== 0.1**r== 0.8**\nScheme\nNoSh\nSh\nShT50\nShT100\nShT150\nShT200\nShT250\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nAs previously, we consider all possible β for each NS to\ntest the schemes for various anomalies In Fig. 10, we depict\nthe ECDF of the users for each NS. Table VI shows that\nall schemes satisfy all SLAs when no NS misbehaves, but\nresource sharing schemes do so with 26% less bandwidth. In\nFig. 11, we show the performance of the schemes as we vary\nthe number of low states removed from the user MC of NS\n0. The results show that hypothesis testing protects the SLAs\nof the well-behaved NSs 1 and 2. The corresponding results\nwhen NS 1 and NS 2 are anomalous are shown in Fig. 12 and\nin Fig. 13. In these cases, hypothesis testing is not needed.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nFig. 11. The kth column corresponds to case where the k lowest states have\nbeen removed from the user MC of NS 0.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nFig. 12. The kth column corresponds to case where the k lowest states have\nbeen removed from the user MC of NS 1.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nFig. 14. The mean execution time of the hypothesis tests in test scenario 3.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.4**l== 0.5**r== 0.3**\nD. Time Complexity\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nThe two most time consuming online procedures in Algo-\nrithm 2 are the bandwidth allocation and hypothesis testing.\nThe former involves the solution of a BKP which is NP-Hard.\nThe simulations results in [2, Fig. 3] show that the BKP can\nbe solved optimally within 5 ms if the number of NSs is less\nthan 100. This can be reduced if fully polynomial time approx-\nimation schemes are used. The results were obtained using a\ncomputer with an Intel i7-10700K @3.8 GHz processor.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nRegarding hypothesis testing, we first note that it can be\nperformed in parallel for each NS. Therefore, it suffices to\nconsider a single NS. Next, it is easy to see that its execution\ntime scales linearly w.r.t. the sample size n. In Fig. 14, we\ndepict the mean execution time per sample size n over all the\ntests conducted in test scenario 3. The results were obtained\nusing a laptop with an Intel i5-7200U @2.5 GHz processor.\nOverall, the total execution time of the online procedures\nin the regular phase are in the order of a few milliseconds.\nSince the slot length D is in the order of tens of seconds, the\nproposed scheme can be performed online.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.7**l== 0.5**r== 0.3**\nE. Comments on Results\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nFirst of all, we address the high number of PRBs reported\nin the previous test scenarios. This may be caused since the\ntotal number of connected users as obtained from the dataset is\nhigh and the desired QoS is to constantly provide 1 or 2 Mbps\nto each user throughout their connection time. Also, note that\neach NS comprises all the traffic served by a single BS.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nNext, we summarize all the previous results in a single table\nto compare the resource efficiency and performance isolation\nthat each scheme provides. To this end, we consider that the\nresource efficiency of a scheme is the percentage decrease in\nPRBs it achieves when compared to the no sharing scheme.\n**BLOCK**fs== 6.4**p== 13.0**b== 0.9**t== 0.1**l== 0.2**r== 0.6**\nTABLE VII\nSUMMARY OF RESULTS\n**BLOCK**fs== 9.0**p== 13.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nScheme\nNoSh\nSh\nShT50\nShT100\n**BLOCK**fs== 9.0**p== 13.0**b== 0.8**t== 0.1**l== 0.2**r== 0.7**\nPRB Savings (%)\n**BLOCK**fs== 9.0**p== 13.0**b== 0.8**t== 0.1**l== 0.3**r== 0.5**\nPerformance Isolation (%)\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nPerformance isolation is measured by the percentage of cases\nwhere a NS was anomalous and the SLAs of all well-behaved\nNSs were satisfied. Both these metrics are computed for each\ntest scenario using the previous simulation results. Next, we\ncombine the results by assuming that the test scenarios are\nequiprobable and then we report the averages in Table VII.\nThe table clearly shows that hypothesis testing provides both\nhigh resource efficiency and high performance isolation.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nFinally, the code we developed to analyze the dataset in [29]\nis available on GitHub2. All the previous tables and figures can\nbe reproduced using the dataset in [29] as input to our code.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nVIII. CONCLUSION\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nWe considered the problem of satisfying the SLAs of mul-\ntiple NSs. We argued that resource provisioning and dynamic\nresource adaptation need to be considered jointly to solve this\nproblem. We proposed a solution approach that consists of two\nphases; the trial phase and the regular phase. In the trial phase,\nthe operator estimates the required provisioned resources and\nobtains a model for each NS that describes its normal behavior.\nIn the regular phase, if resource contention occurs, the operator\nuses the previous models to fairly decide which NSs should\nbe rejected via hypothesis testing. Results showed that our\napproach is robust against traffic anomalies and satisfies the\nSLAs of well-behaved NSs with reduced bandwidth.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nWe note that there are several directions for improvement.\nFirst, a bayesian approach may be considered for hypothesis\ntesting if priors can be estimated from past data. Alternatively,\nthe worst case prior may be considered to formulate a minimax\ndetection problem. Second, it may be beneficial to only check\nwhether a NS generates more traffic than it normally does.\nThird, the parametric models may be used to simplify the\ntests. These directions may facilitate a complete performance\nanalysis to derive the metrics in Table VII without simulations.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nREFERENCES\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[1] C. Marquez, M. Gramaglia, M. Fiore, A. Banchs, and X. Costa-P´erez,\n“Resource sharing efficiency in network slicing,” IEEE Trans. Netw.\nService Manag., vol. 16, no. 3, pp. 909–923, 2019.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[2] P. Nikolaidis, A. Zoulkarni, and J. Baras, “Resource efficiency vs\nperformance isolation tradeoff in network slicing,” in 2023 IEEE WiOpt,\n2023, pp. 33–40.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[3] C. Sexton, N. Marchetti, and L. A. DaSilva, “On provisioning slices\nand overbooking resources in service tailored networks of the future,”\nIEEE/ACM Trans. Ntw., vol. 28, no. 5, pp. 2106–2119, 2020.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[4] C. Gutterman, E. Grinshpun, S. Sharma, and G. Zussman, “Ran resource\nusage prediction for a 5g slice broker,” in ACM Mobihoc ’19, New York,\nNY, USA, 2019, p. 231–240.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\n2https://github.com/pnikolaid/robust resource sharing\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[5] S. Alcal´a-Mar´ın, A. Bazco-Nogueras, A. Banchs, and M. Fiore,\n“kansaas: Combining deep learning and optimization for practical over-\nbooking of network slices,” in ACM MobiHoc ’23, 2023, p. 51–60.\n[6] A. Banchs, G. de Veciana, V. Sciancalepore, and X. Costa-Perez,\n“Resource allocation for network slicing in mobile networks,” IEEE\nAccess, vol. 8, pp. 214 696–214 706, 2020.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[7] A. J. Gonzalez et al., “The isolation concept in the 5g network slicing,”\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nin 2020 EuCNC, 2020, pp. 12–16.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[8] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,”\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\nACM Comput. Surv., vol. 41, no. 3, jul 2009.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[9] ——, “Anomaly detection for discrete sequences: A survey,” IEEE\n**BLOCK**fs== 8.0**p== 13.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nTrans. Knowl. Data Eng., vol. 24, no. 5, pp. 823–839, 2012.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[10] S. Wang, J. F. Balarezo, S. Kandeepan, A. Al-Hourani, K. G. Chavez,\nand B. Rubinstein, “Machine learning in network anomaly detection: A\nsurvey,” IEEE Access, vol. 9, pp. 152 379–152 396, 2021.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[11] M. Gupta, J. Gao, C. C. Aggarwal, and J. Han, “Outlier detection for\ntemporal data: A survey,” IEEE Trans. Knowl. Data Eng., vol. 26, no. 9,\npp. 2250–2267, 2014.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[12] V. V. Veeravalli and T. Banerjee, “Chapter 6 - quickest change detection,”\nin Academic Press Library in Signal Processing: Volume 3. Elsevier,\n2014, vol. 3, pp. 209–255.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[13] W. Wang, Q. Chen, T. Liu, X. He, and L. Tang, “A distributed online\nlearning approach to detect anomalies for virtualized network slicing,”\nin 2021 GLOBECOM, 2021, pp. 1–6.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[14] A. Chawla, A.-M. Bosneag, and A. Dalgkitsis, “Graph-based inter-\npretable anomaly detection framework for network slice management\nin beyond 5g networks,” in 2023 IEEE/IFIP NOMS, 2023, pp. 1–6.\n[15] A. Kumar and V. L. Thing, “Malicious lateral movement in 5g core with\nnetwork slicing and its detection,” in 2023 ITNAC. Los Alamitos, CA,\nUSA: IEEE Computer Society, dec 2023, pp. 110–117.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[16] S. A. Baset, L. Wang, and C. Tang, “Towards an understanding of\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\noversubscription in cloud,” in USENIX Hot-ICE ’12, 2012.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[17] F. Caglar and A. Gokhale, “ioverbook: Intelligent resource-overbooking\nto support soft real-time applications in the cloud,” in 2014 IEEE\nCLOUD, 2014, pp. 538–545.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[18] D. Shue, M. J. Freedman, and A. Shaikh, “Performance isolation and\nfairness for Multi-Tenant cloud storage,” in 2012 OSDI. Hollywood,\nCA: USENIX Association, Oct. 2012, pp. 349–362.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[19] 3GPP, “LTE; E-UTRA; Physical layer procedures,” 3GPP, TS 36.213,\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\n02 2015, version 12.4.0.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[20] P. Nikolaidis, A. Zoulkarni, and J. S. Baras, “Data-driven bandwidth\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nadaptation for radio access network slices,” arXiv:2311.17347, 2023.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[21] C.-Y. Hong et al., “B4 and after: Managing hierarchy, partitioning, and\nasymmetry for availability and scale in google’s software-defined wan,”\nin SIGCOMM. Budapest, Hungary: ACM, 2018, p. 74–87.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[22] D. P. Bertsekas, Dynamic Programming and Optimal Control, Vol. II,\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\n3rd ed. Athena Scientific, 2007.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[23] S. M. Kay, Fundamentals of statistical signal processing: estimation\n**BLOCK**fs== 8.0**p== 13.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\ntheory. USA: Prentice-Hall, Inc., 1993.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[24] V. Moulos, “A hoeffding inequality for finite state markov chains and its\napplications to markovian bandits,” in 2020 ISIT, 2020, pp. 2777–2782.\n[25] J. Fan, B. Jiang, and Q. Sun, “Hoeffding’s inequality for general markov\nchains and its applications to statistical learning,” J. Mach. Learning\nResearch, vol. 22, no. 139, pp. 1–35, 2021.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[26] S. Kay, Fundamentals of statistical signal processing: Detection theory.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\nUSA: Prentice-Hall, Inc., 1998.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[27] M. J. Neely, “Stochastic network optimization with application to\ncommunication and queueing systems,” Synthesis Lectures on Commu-\nnication Networks, vol. 3, no. 1, pp. 1–211, 2010.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[28] Google-OR-tools, “The knapsack problem,” 2023. [Online]. Available:\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nhttps://developers.google.com/optimization/pack/knapsack\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[29] P. F. P´erez, C. Fiandrino, and J. Widmer, “Characterizing and modeling\nmobile networks user traffic at millisecond level,” in WiNTECH ’23.\nNew York, NY, USA: ACM, 2023, p. 64–71.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[30] R. Falkenberg and C. Wietfeld, “Falcon: An accurate real-time monitor\nfor client-based mobile network data analytics,” in 2019 GLOBECOM,\n2019, pp. 1–7.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[31] G. Attanasio, C. Fiandrino, M. Fiore, J. Widmer, N. Ludant, B. Bloessl,\n¨Ozg¨u Alay, L. Jacquot, and R. Stanica, “In-depth study\nK. Kousias,\nof rnti management\nin mobile networks: Allocation strategies and\nimplications on data trace analysis,” Computer Networks, vol. 219, p.\n109428, 2022.",
         "Robust Resource Sharing in Network Slicing via Hypothesis Testing Panagiotis Nikolaidis and John Baras Department of Electrical & Computer Engineering and the Institute for Systems Research University of Maryland, College Park, MD 20742, USA Email: {nikolaid, baras}@umd.edu The need to support applications with diverse Quality of Service (QoS) requirements introduces several challenges in networking. A promising solution approach is to leverage net- work virtualization and software-defined networking to deploy multiple virtual networks on the same physical infrastructure. Each virtual network is then tailored to a specific application. For instance, a virtual network deployed for autonomous driving applications may drop packets whose age is larger than the sampling period at the vehicle to avoid congesting the network with outdated information. In contrast, virtual networks for file transfer may instead optimize throughput. Also, virtual networks used by private companies may require increased authentication functionality for security concerns. The special case of customized virtual networks on the cellular infrastructure has attracted a lot of attention given that many applications require wireless connectivity. These virtual networks are often referred to as Network Slices (NSs). They span the Radio Access Network (RAN), the Transport Network (TN) and the Core Network (CN) of the cellular infrastructure. Typically, the customer requesting a NS and the network operator sign a Service Level Agreement (SLA) that specifies the desired QoS delivered to the customer’s traffic and the price paid to the operator. The fulfillment of multiple SLAs at the same time and on the same physical infrastructure is a difficult problem that operators need to solve. It the operator provisions enough network resources in advance so that the network functions of each NS can deliver the promised QoS. Based on the provisioned resources, the operator can then compute the cost of the SLA and charge the customer. is necessary that Network functions that require provisioned resources span the whole cellular infrastructure. For example, in the RAN, the operator needs to provision Physical Resource Blocks (PRBs) for the Medium Access Control (MAC) scheduler of each NS. In the TN, routing paths need to be selected, and in the CN, processing units need to be reserved to execute various network functions such as the Access and Mobility Function (AMF) and the User Plane Function (UPF) of 5G systems. An efficient provisioning approach is to enable resource sharing among NSs for statistical multiplexing gains. Resource sharing allows the deployment of an increased number of NSs on the same infrastructure which translates to lowered costs for the customers. Unfortunately, sharing may degrade the performance isolation of a NS. Indeed, unexpected traffic surges in a NS may result in resource contention. As a result, some NSs may not receive their fair share. This is highly undesirable since customers request a NS for premium service that should remain unaffected by the traffic in other NSs. On the other hand, the operator may provision resources exclusively for each NS which provides full isolation but at the cost of low resource efficiency. Motivated by this tradeoff, we propose the use of hypothesis testing to enhance performance isolation in resource sharing. Our approach consists of two phases, the trial phase and the regular phase. In the trial phase, the traffic and the resources required by each NS are collected over a long period of time. This data is used as follows. First, a stochastic model is constructed for each NS that describes its normal traffic patterns. Specifically, a Markov Chain (MC) is used whose states describe the traffic and the resource demand in the NS. Second, the required pro- visioned resources are computed by estimating the percentiles of the resource demands of the NSs. All these quantities are computed based on Maximum Likelihood Estimation (MLE). We note that the operator commits to fulfilling the SLA under the condition that the NS follows its normal behavior. This is a reasonable condition since the operator cannot provide QoS guarantees without any knowledge regarding the traffic of the NS. Indeed, the operator needs to know the traffic that the NS normally generates to compute the required provisioned resources and to charge the customer accordingly. In the regular phase, the operator declines service to NSs that deviate from their normal behavior in case of resource contention. This is done to ensure that the well-behaved NSs receive their fair share of resources. The operator checks if such a deviation is present via hypothesis testing based on the Neyman-Pearson framework. Next, the operator splits the provisioned resources among the NSs that pass the test. Any remaining resources are then split among the rest of the NSs. We apply our approach in the RAN where resource sharing is needed the most since the licensed spectrum is a scarce and expensive resource. Specifically, we wish to reduce the Physical Resource Blocks (PRBs) needed at the Base Station (BS) to satisfy the QoS requirements of all NSs. To test our approach, we use a dataset that contains real traffic as observed in base stations of a cellular network. The dataset is used to simulate the trial phase and derive the aforementioned stochastic models. Then, in the regular phase, we consider that some NSs follow traffic patterns that deviate from the previous models. Next, we analyze the effect of this excess traffic on the performance of the other NSs. We compare our approach to two baselines; exclusive bandwidth provisioning for each NS without resource sharing, and resource sharing without hypothesis testing. The results show that our approach enhances the robustness of the SLAs to anomalous traffic patterns while maintaining high efficiency via resource sharing. Overall, we provide evi- dence that resource sharing augmented by hypothesis testing strikes a good balance between efficiency and isolation. Our paper is structured as follows. In Sec. II, we present the related literature and compare it with our work. In Sec. III, we present the considered system architecture. In Sec. IV, we formulate the overall goal of the system architecture as an optimization problem. In Sec. V, we propose our solution approach. The simulation setup is described in Sec. VI and the results in Sec. VII. Lastly, Sec. VIII concludes the paper. the authors studied the effect of overbooking strategies on resource allocation and service violations. Two schemes were investigated; perfect sharing and network slicing which correspond to resource sharing and exclusive resource reservation respectively. In perfect sharing, the BS sums the resource demands of all NSs and provisions P H -percentile resources. In network slicing, performance isolation is consid- ered by allocating exclusive P L-percentile resources to each NS. The remaining resources needed to achieve P H − P L fraction of time acceptance for each NS are computed based on past data. The authors provide insight regarding the tradeoff between resource efficiency and performance isolation via ex- perimentation. However, no mechanisms to enhance isolation for the P H − P L fraction of time are proposed. The aforementioned tradeoff is also investigated in [2]. The authors consider P L i -percentile resources assigned exclusively i − P L to each NS i. For the rest fraction of time P H i , each NS i relies on resource sharing. The authors show that the multiplexing strategy that requires the least provisioned resources to satisfy the SLAs of all NSs is the Max-Weight scheduler if the resource demands follow MCs. However, no isolation mechanisms are provided in case of traffic anomalies. A similar strategy is developed in [3]. The authors consider a fixed amount of provisioned resources and reserve some of it exclusively for each NS. The remaining resources are viewed as auxiliary and are dynamically provided to the NSs. The main focus of the paper is on developing overbooking strate- gies for the auxiliary resources with probabilistic guarantees. To do so, the authors assume that the operator has a model that forecasts the traffic of the NSs in the short term future. The NSs are then priced on a resource basis. Once again, this approach is susceptible to unexpected traffic patterns. In [4] and [5], a prediction model for the short-term demand of a NS is developed. The predictions are used to dynamically adapt the allocated resources for higher utilization. However, bandwidth adaptation alone cannot ensure the fulfillment of a SLA. Resources need to be provisioned so that the ones requested by the prediction model are available on short notice as often as the SLA requires. The authors in [6] conduct a survey on resource allocation schemes in network slicing. The schemes are coarsely divided into reservation-based and share-based. The authors conclude that the former provide higher isolation while the latter higher efficiency. Moreover, the schemes are also compared based on customizability, complexity, privacy and cost predictability. A survey dedicated to the different interpretations of iso- lation is presented in [7]. The authors discuss the concept of isolation in terms of performance, security, and dependability for various network functions in the RAN, TN, and CN. Here, we are primarily concerned with performance isolation. A research area that is closely related to our approach is anomaly detection for which multiple methods have been suggested over the years [8]–[12]. Here, we use a statistical method since we consider hypothesis testing. We note that anomaly detection has been used before in network slicing [13]–[15]. However in these works, the motivation behind its use is primarily security and data privacy. Here, we leverage anomaly detection to enhance isolation in resource sharing. Next, we note that similar issues regarding the fulfillment of SLAs while maintaining high resource utilization also appear in cloud computing. In [16], the authors relate the resource allocation problem to a variation of an online knapsack prob- lem. The authors then note that various other aspects need to be included such as SLA violation costs and resource migration delays that further complicate the problem. The authors in [17] consider a neural network to predict user usage and dynamically allocate resources for higher utilization, an approach that is similar to [4]. Another related work in cloud computing is [18] where the tradeoff between performance isolation and fairness is addressed. The authors also consider the possibility of mis- behaving customers with skewed and shifted demands. They propose the decomposition of the system-wide fair sharing problem into four smaller mechanisms and show robustness to customer misbehavior. Overall, we believe that the related literature mostly con- siders a fixed set of provisioned resources that should be split among customers in a fair manner based on a utility maximization problem. However, a customer is interested in receiving the promised QoS as stated in the SLA. Hence, the fact that the customers receive their fair share according to utility maximization is of little value to them if the promised QoS is not delivered. Thus, resource provisioning and dynamic resource allocation must be studied jointly. Also, we believe that mechanisms to protect the SLAs from misbehaving traffic have not been investigated in detail. Here, we wish to address these two gaps in the literature by proposing provisioning mechanisms and hypothesis testing in resource sharing. III. SYSTEM ARCHITECTURE We consider N NSs served by a single BS in the RAN. Each NS may have different type of QoS requirements. For instance, a NS may wish to upper bound the average packet delay of its users by a threshold, whereas another NS may wish to provide a constant target bitrate to each of its users. Thus, we consider that NSs may use different MAC schedulers. Let vector Wi(t) denote the bandwidth demand of NS i at slot t. Bandwidth demand Wi(t) corresponds to the number of PRBs that the MAC scheduler of NS i needs in order to provide the desired QoS throughout slot t to NS i. To determine demand Wi(t), the operator may need to observe the state of the NS i at time t denoted by Xi(t). For instance, suppose that NS i needs to deliver a constant target bitrate to each of its users. To do so, the operator first collects the Modulation and Coding Scheme (MCS) of each user at slot t, which composes the state Xi(t) of the NS. Then, given the target bitrate, the operator may use Table 7.1.7.1-1 and Table 7.1.7.2.1-1 in 3GPP document [19] to find the necessary number of PRBs Wi(t). Note that for complex QoS requirements, the online deter- mination of Wi(t) based on Xi(t) is not trivial. As a result, we consider a network function deployed at the BS which we call the Bandwidth Demand Estimator (BDE) whose objective is to compute Wi(t) based on Xi(t). Notice that the BDE enables bandwidth adaptation which is needed to achieve high efficiency in resource sharing. In [20], a BDE for packet delay requirements is developed based on a Reinforcement Learning (RL) algorithm and is then tested by experimentation on a 3GPP compliant cellular testbed. The design of new BDE is out of the scope of this paper. Next, since the provisioned PRBs at the BS may not suffice △ for all demands W(t) = (Wi(t))i∈[N ], the operator needs to decide which ones to accept. For this reason, we consider another network function at the BS which we call the Network Slice Multiplexer (NSM) that at each slot t decides whether to allocate the Wi(t) PRBs to the MAC scheduler of NS i. The NSM outputs a binary decision vector u(t) where ui(t) = 1 denotes acceptance of demand Wi(t). Figure 1 depicts the overall system architecture. Notice that resource sharing is performed by the NSM. Therefore, in this paper, we focus only on the development of a NSM. We note that a preliminary solution was provided in [2] where this system architecture was introduced. How- ever, no mechanisms to protect SLAs against anomalies were considered and resource provisioning was not fully addressed. We consider that each customer i states in the SLA that the operator needs to deliver the desired QoS for P H fraction of i time. Such availability requirements are widely used in real networks for resource provisioning purposes, as in Google’s software-defined network B4 [21]. Notice that the previous statement that ui(t) = 1 for at is equivalent least P H i to the requirement fraction of time. Let Ts denote the number of slots during which all NSs are deployed and W c denote the provisioned bandwidth at the BS. Clearly, the operator wishes to satisfy all SLAs with minimum provisioned bandwidth. Thus, whenever a new NS needs to be deployed, the operator wishes to solve the following optimization problem: ui(t) ≥ P H i Ts u(t)⊤W(t) ≤ W c, ∀t ∈ [Ts], u(t) ∈ {0, 1}N , ∀t ∈ [Ts]. The first constraint is the availability requirement as stated in the SLA. The second constraint states that the total accepted demand must be less than the provisioned resources W c. The third constraint implies that the NS either receives the desired QoS or it does not. Next, note that (1) is a Mixed Integer Linear Programming (MILP) problem. Unfortunately, to solve it, the operator must know the future demands {W(t)}t∈Ts and the exact system duration Ts which is not possible. To approximately solve (1), we propose an approach with two phases; the trial phase and the regular phase. During the trial phase, a long sequence of traffic states and bandwidth demands (Xi(t), Wi(t)) is observed for each NS i. Based on these, a stochastic model is constructed for each NS that describes its normal behavior and the required provisioned bandwidth at the BS is estimated. In the regular phase, the operator provisions the previously estimated bandwidth at the BS. Then, if the total bandwidth demand at some time exceeds the provisioned bandwidth, the NSM checks if the traffic generated by each NS was in accor- dance to its normal behavior as observed during the trial phase. The NSM performs this check by conducting a composite hypothesis test for each NS based on the Neyman-Pearson framework. The NSs that pass this test have prioritized access to the provisioned bandwidth. Any remaining bandwidth is then split among the other NSs. A flowchart of the overall solution approach is shown in Fig. 2. This phase is initiated when a new NS is deployed on the BS. To monitor the unknown resource demands of the new NS, the operator assigns as much bandwidth as possible to the BS to avoid situations where the poor QoS affects the behavior of the NS, e.g., users quitting due to large packet delays. The main goal during this phase is to describe the normal behavior of each NS by a stochastic model and estimate the provisioned bandwidth required at the BS to satisfy the SLAs of all NSs. The stochastic model used greatly affects the estimation of the provisioned bandwidth. To gain insight on what model is appropriate, it is helpful to consider the models used by the BDE. For instance, in [20], the BDE is based on Rein- forcement Learning (RL). In this case, the stochastic model for (Xi(t), Wi(t)) is a Markov Decision Process (MDP). Let Hi(t) τ =1 be the past state-action pairs. The MDP models the process {(Xi(t), Wi(t))}t∈N as follows: P(Xi(t + 1) = x′|Xi(t) = x, Wi(t) = w, Hi(t) = hi) = Pi(x′|x, w). △ ={(Xi(τ ), Wi(τ ))}t−1 Suppose that the NS is deployed for a large amount of time, i.e., Ts → ∞, and that the BDE wishes to minimize some total expected cost that depends on the state Xi(t) and action Wi(t). Then, it suffices to consider stationary policies [22] that allocate bandwidth Wi(t) given state Xi(t) as follows: P(Wi(t) = w|Xi(t) = x, Hi(t) = hi) = µi(w|x). ̸= i since information regarding other NSs j do not j provide any value to NS i if (Xi(t), Wi(t)) are known. Let △ X(t) = (Xi(t))i∈[n]. Then, the vector Z(t) = (X(t), W(t)) follows the MC: From (2) and (3), is easy to see that △ =(Xi(t), Wi(t)) follows a stationary MC: the process P(Z(t + 1) = z′|Z(t) = z, H(t) = h) P(Zi(t + 1) = (x′, w′)|Zi(t) = (x, w), Hi(t) = hi) △ = PZi((x′, w′)|(x, w)). = Pi(x′|x, w)µi(w′|x′) Note that it is further reasonable to assume that the random processes Zi(t) and Zj(t) are conditionally independent for Hence, the stochastic model of interest is a MC. We further consider that all the above MCs are ergodic since state spaces Xi and action spaces Wi are finite. Also, each MC Zi(t) is expected to contains self-loops and to be possible to reach each state from all the other states. Therefore, each MC Zi(t) eventually converges to its unique stationary distribution πZi(zi). Thus, the MC Z(t) has a unique stationary distribu- tion πZ(z) = N Since we wish to deliver the desired QoS to NS i for at least P H i fraction of time, let W H △ = arg min i be defined as: Ts Let πW(w) W(t) = w. Due to ergodicity, it follows that: x πZ(x, w) be the stationary probability of Unfortunately, most of these bounds apply only to Independent Identically Distributed (IID) random processes. There are only few results that extend such bounds to MCs. For instance, the result in [24] provides such a bound but requires the knowledge of a quantity that equals the largest expected time to transition from a state x to a state y for the first time among all (x, y) pairs. Applying the result in [24] for the MC Z(t), it follows that ∀ϵ > 0: f (Z(t)) − E[f (Z(1))]    2T ϵ2 (b − a)2H 2 Z i = arg min w πW(w) ≥ P H i Since the SLA dictates that the NS should be satisfied for P H fraction of time, we may ignore any bandwidth i demand Wi(t) > W H . Although treating demands higher than i W H as 0 is optimal for resource provisioning purposes, we i consider it to be quite punishing. So instead we may transform all demands Wi(t) > W H , i.e., we may consider i a transformed demand gi(Wi(t)) = min(Wi(t), W H i ). Let g(W(t)) the provisioned bandwidth W c should be: △ =(gi(Wi(t))i∈[N ] Thus, to satisfy all SLAs, W c = arg min w Similarly as before, due to ergodicity, (8) is equivalent to: W c = arg min πW(w) ≥ max If the stationary distribution πW(w) is known, then each W H can be found from (7) via binary search. Then, functions i gi are also known and W c can be computed from (9) also via binary search. Unfortunately, in practice we do not know the transition matrix of the MC Z(t) and therefore we cannot compute any of these quantities. As a result, we need to esti- mate the above quantities from the observed data. To estimate W H and W c, we first estimate the stationary distribution πw i and proceed as described in (7) and (9). We use the Maximum Likelihood Estimator (MLE) of πW(w) denoted by ˆπW(w) which is simply the fraction of time that W(t) ≤ w in the observed sequence of length T and can be easily updated online. We note that the above MLEs converge almost surely to the estimated quantities and the asymptotic rate of convergence is known due to asymptotic normality [23]. Unfortunately, both these results are asymptotic and hold for large data sequences as T → ∞. However, in practice, we are interested in the number of samples T needed to obtain a specific accuracy of the estimated quantity with a certain probability. Hence, concentration inequalities such as the Chernoff-Hoeffding bounds are particularly useful here. In the above, function f maps states to a value in [a, b] and HZ = maxx,y E[Ty|Z(1) = x] where Ty = inf{t ≥ 0 : Z(t + 1) = y}. The result in [24] applies if the concerned MC has finite states, is irreducible and its initial distribution is one of its stationary distributions. Note that HZ is not known in practice since it depends on the transition matrix of the MC Z(t). Nonetheless, we argue that the periodic traffic patterns observed in real networks provide insight for its value. For instance, the period of the traffic patterns can be considered as an approximation of HZ. To leverage (10) for the estimation of πw, we consider fw(Z(t)) = 1W(t)=w and hence a = 0 and b = 1. Then, to bound by δ the probability that the absolute deviation of |ˆπW(w) − πW(w)| exceeds ϵ, the following sufficient condition is obtained from (10): Another Hoeffding bound for MCs is provided in [25]. The authors show an optimal bound which requires the knowledge of the spectral gap 1 − λ of its transition matrix, where λ is its second largest eigenvalue in absolute value. Similarly as before, it follows from [25] that it suffices to consider: is known that λ ∈ [0, 1), thus the lower bound is minimized when λ = 0 which occurs when the rows of the transition matrix are equal [25]. In this case (12) coincides with the classical Hoeffding bound for the IID case. Thus, at best case scenario, the number of samples T is ln(2/δ)/(2ϵ2). For some transition matrices obtained during experimenta- tion, the lower-bound in (12) was significantly lower than the one in (11). Thus, suppose that we consider ϵ = 0.01 and δ = 0.01 in ln(2/δ)/(2ϵ2). We readily obtain T ≈ 120K. Next, suppose that we observe a sample every 10 seconds, i.e., the slot length in Fig. 1 is 10 seconds. Then, the trial phase should be at least 2 weeks. If we further wish to model every 8-hour period in the day with a different MC, the duration of the trial phase needs to be at least 1.5 month. Unfortunately, we do not have a dataset with that many con- tiguous samples. However, we noticed during experimentation that even the best-case scenario bound may be loose since a smaller number of samples did not lead to SLA violations. Hence, we consider small T values such as 7200. Once the and W c are T samples are obtained, the estimates of W H i obtained from (7) and (9) respectively via binary search. Apart from the above estimates, we further need to estimate the transition matrix PZi of MC Zi(t) that describes the normal behavior of each NS i. The MLE for the transition probabilities PZi(z′ i|zi) is simply the number of times there was a transition from state zi to state z′ i over the total number of times state zi occurred. Once again, it is known that the MLE converges almost surely to the estimated quantity and that asymptotic normality holds [23]. Unfortunately, we were not able to obtain any bounds for finite samples as previously even though [24] provides a Chernoff-Hoeffding bound when the function f receives two arguments. The overall estimation procedure during the trial phase is summarized in Algorithm 1. We note that the algorithm can be simplified if certain conditions are met. First, given the independence assumption regarding the processes Zi(t), we may use the estimator ˆπW(w) = N i=1 ˆπWi (wi) and estimate the distribution of the total transformed demand 1⊤ˆg(w) by convolution. Even though we consider the processes Zi(t) to be independent, we do not follow the previous method and instead directly estimate the distribution of the whole demand vector πW for simplicity. Next, note that if the demands are not transformed, i.e., gi(x) = x, then we may skip many steps in Algorithm 1 since we can directly estimate the cdf of 1⊤w. A procedure in Algorithm 1 that requires a large amount of memory involves the estimation of the transition matrices PZi. Note that each Zi(t) = (Xi(t), Wi(t)) is composed by a vector of dimension dim(Xi)+1 and the size of observed transitionsi may be |Xi × Wi|2. However, notice that if the NSM knows the stationary policy µi(w|x) used by the BDE which is likely to be the case since both the BDE and the NSM run at the BS, then the NSM needs to estimate only the transition probabilities Pi(x′|w, x) as in (4). Furthermore, if the stationary policy used by the BDE is deterministic, i.e., Wi(t) = µi(Xi(t)), then the NSM needs to estimate only the MC that its state Xi(t) follows. Since ϵ-soft polices are used in many popular RL algorithms and they can be approximated by a deterministic policy, we may estimate only the MC of process Xi(t). Also, the estimation of the MC of Xi(t) may be further simplified if its of each components follows an independent MC. Lastly, a crude approximation of the normal behavior of a NS may be obtained by assuming that each process Wi(t) follows an independent MC. At this point, each NS has been through the trial phase and a MC that describes its normal behavior has already been obtained. Also, the provisioned bandwidth should satisfy all NSs for maxi P H fraction of time. Nonetheless, for the rest i of the time, the bandwidth may not suffice. Moreover, a NS may generate unexpected traffic patterns, e.g, due to a special event, that increase its bandwidth demand. In such cases, the NSM needs to reject some of the demands. Algorithm 1: Estimation Procedure in Trial Phase 1 Input: parameters ϵ, δ, HZ, P H i 2 Output: ˆW H i 3 T ≈ 7200 , ˆPZi, ˆW c /* Collect statistics online 4 for t ≤ T do get Z(t) = (X(t), W(t)) observed demands.add(W(t)) counts(W(t))+=1 observed sums.add(1⊤W(t)) total demand count(1⊤W(t))+ = 1 for each NS i do observed transitionsi.add((Zi(t − 1),Zi(t))) transition countsi(Zi(t − 1), Zi(t))+ = 1 Z countsi(Zi(t))+ = 1 Z(t − 1) = Z(t) /* MLE of pmf πw 15 for w ∈ observed demands do ˆπW(w) = counts(w)/T countsi(wi)+ = counts(w) /* MLE of P H 18 for each NS i do sort W in increasing order for w ∈ W do i -percentiles W H i ˆπWi(w) = countsi(w)/T s+ = ˆπWi(w) if s ≥ P H i ˆW H i = s break /* MLE of provisioned bandwidth W c */ 26 ˆgi(x) = min(x, ˆW H i ) 27 for w ∈ observed demands do observed gsums.add(1⊤ˆg(w)) 29 sort observed gsums in increasing order 30 for s ∈ observed gsums do cdf+ = total demand count(s) if cdf ≥ maxi P H i ˆW c = s break /* MLE of transition matrices Pi 35 for each NS i do for (z, z′) ∈ observed transitionsi do ˆPZi(z′|z) = transition countsi(z, z′)/Z countsi(z) Given that the provisioned bandwidth ˆW c was computed by considering that each NS follows its normal behavior as described by its MC Zi(t), it is fair to reject NSs that do not follow these MCs. For this reason, we consider that the NSM performs hypothesis testing when N i=1 Wi(t) > ˆW c. The null hypothesis H 0 i (t) is that NS i follows so far the MC ˆPZi obtained during the trial period. The alternative hypothesis H 1 i (t) is that the NS at some time t − n + 1 switched to a different MC. Hence, a composite hypothesis test is consid- ered. Selecting H 0 i (t) implies that NS i behaves normally so far and thus has prioritized access to the bandwidth. To conduct the hypothesis test, we consider the Neyman- Pearson framework [26]. In this framework, we wish to bound the false alarm rate, i.e., the probability that we incorrectly select the alternative hypothesis H 1 i (t), while maximizing the detection power, i.e., the probability that we correctly select H 1 i (t). To do so, we check the likelihood ratio of the hypothe- ses and pick the alternative hypothesis if and only if the ratio is larger than a parameter γi. Let Zi(n, t) = {Zi(τ )}t denote the last n samples at time t. Then, the hypothesis H 1 is selected if and only if: ˆQZi(Zi(τ )|Zi(τ − 1)) ˆPZi(Zi(τ )|Zi(τ − 1)) where ˆQZi is the MLE of the transition matrix of the MC that samples Zi(n, t) follow. The γi in (13) that maximizes the detection power while bounding the false alarm rate by αi is selected as follows: γi = arg min P(Zi(n) : L(Zi(n)) > γ|H 0 where the subscript t was dropped since the MC Zi(t) is stationary. The Neyman-Pearson Theorem [26] states that this likelihood ratio test achieves the highest detection power given a bound on the false alarm rate out of all possible tests. Note that ideally we wish to perform the hypothesis test ∀n ≤ t in order to check whether the transition matrix changed at any time in the past which corresponds to model change detection with unknown change time [26]. However, such a test is too computationally intense to be conducted online. For this reason, we consider a fixed sample size n and hence only check whether the MC changed at time t − n + 1. Unfortunately, even for a fixed n, (14) is quite complex to solve and therefore γi cannot be computed exactly. Thus, we consider the asymptotic result that as n → ∞, the random variable 2 ln L(Zi(n)) follows the chi-square distribution χ2 r under hypothesis H 0 i (t) [26]. The distribution parameter r is equal to the total degrees of freedom in the test. In our case, the transition probabilities ˆQZi(z′|z) are |Zi|2 in total. However, for each z, it holds that  ˆQZi(z′|z) = 1. z′ Since the transition matrix ˆPZi is fixed, then r = |Zi|2 − |Zi|. Thus, in the asymptotic regime, it follows from (14): Since (15) holds only for large data records as n → ∞, then we may not consider small n to detect model changes that occurred in the recent past. Hence, if the behavior of the NS changes only for very brief periods of time and then reverts back to normal, we may never detect any anomalies. However, we argue that such fast and brief changes of time may not have a large effect on the resource allocation process. Lastly, note that the memory required for the test depends on n. i (t) selected} denote the set of NSs that behave normally at time t according to the hypothesis tests and let B(t) denote the set of NSs that do not. We then split the resources among the NSs in A(t) using the Max-Weight scheduler [27]. Specifically, we consider a deficit di(t) owed to each NS i that is defined as follows: di(t + 1) = [di(t) − ui(t)]+ + P H i (16) The bandwidth ˆW c is split among the NSs in A(t) as follows: ui(t)di(t) i∈A(t) ui(t)Wi(t) ≤ ˆW c, i:A(t) ui(t) ∈ {0, 1}, ∀i ∈ A(t). The above scheduling procedure is motivated by the fact that if the deficits in (16) are strongly stable, then the first constraint in (1) holds w.p.1 as Ts → ∞ [27]. Although (17) is a binary knapsack problem and thus NP-Hard, we utilize the Google OR-Tools solver in [28] to obtain an exact solution relatively fast using a branch and bound method. Lastly, we mention that this scheduler is also used in [2]. Let u∗ i (t) for i ∈ A(t) denote a solution of (17) and let W R(t) i (t)Wi(t) denote the remaining bandwidth. Upon splitting bandwidth ˆW c as in (17), either all NSs in A(t) are satisfied, i.e., u∗ i (t) = 1 for all i ∈ A(t) or there are some NSs in A(t) whose demand Wi(t) is not fully met. Let AR(t) i (t) = 0} denote the NSs in A(t) whose demand was not fully met. Notice that if AR(t) ̸= ∅, then the remaining bandwidth W R(t) i (t)Wi(t) ≤ mini∈AR(t) Wi(t). Otherwise, u∗(t) would not be an optimal solution to (17). To fully utilize the remaining bandwidth W R(t), we may solve a utility maximization problem for the NSs in AR(t). Let W R i (t) denote the bandwidth received by NS i. Then, we may consider a simple utility function Ui(W R i (t)/Wi(t) for each NS i, and maximize the total utility as follows: maximize i (t)}i∈AR (t) i∈AR(t) i (t) ≤ W R(t), i (t) ≤ Wi(t), ∀i ∈ AR(t), Note that the solution to the above problem is to sequentially find the currently smallest Wj(t) and assign as much band- j (t). Notice that if Wj = R, then width as possible to W R we simply assign the whole remaining bandwidth W R j (t) = W R(t), where Wj(t) ≤ Wi(t) ∀i ∈ AR(t), since W R(t) ≤ mini∈AR(t) Wi(t) as explained previously. In case that AR(t) = ∅, we may decide to split the remaining bandwidth W R(t) to the NSs in B(t) that do not behave normally according to the hypothesis test. Thus, we may then solve (17) for the set B(t) instead of the set A(t). The overall detection and bandwidth allocation procedure during the regular phase is described in Algorithm 2. Similarly as in the trial phase, the algorithm can be significantly sim- plified under certain conditions. For instance, if NSM knows the stationary policy µi(w|x) used by the BDE, then we may instead perform two simpler hypothesis tests; one that checks whether the stationary policy µi(w|x) is followed and one to check whether the transition probabilities ˆPi(x′|x, w) are followed as implied by (4). These tests have smaller numbers of total degrees of freedom and can be performed in parallel. Furthermore, in case the stationary policy is deterministic, i.e., Wi(t) = µi(Xi(t)), then the NSM may simply first check if Wi(τ ) = µi(Xi(τ )), ∀τ in the observation window. If the condition does not hold, then the alternative hypothesis H 1 i (t) is selected. Otherwise, the hypothesis test needs to only involve the parameters ˆQi(x′|x, µi(x)). Similarly as before, if the state components of a NS follow independent MCs, then we may consider a simpler hypothesis test for each of them. To properly evaluate our approach, we compare it to two other baselines. Overall, the three schemes are the following: Sharing and Testing (ShT): This scheme is the proposed solution approach in Sec. V. In this scheme, resource sharing is augmented by hypothesis testing to enhance isolation. By ShTn, we refer to this scheme run with sample size n in hypothesis testing. Sharing (Sh): In the trial phase, this scheme is identical to the previous one. In the regular phase ,the scheme skips hypothesis testing and sets A(t) = [N ] in Algorithm 2. No Sharing (NoSh): This scheme provisions ˆW H i band- width for each NS i which is the estimation of the P H i - percentile of process Wi(t) as obtained in the trial phase. Clearly, the total provisioned bandwidth is  . In the regular phase, the demand Wi(t) is guaranteed to be accepted if Wi(t) ≤ ˆW H . Any leftover bandwidth is split among the i other NSs. The scheme is run by skipping hypothesis testing and considering i ∈ A(t) iff Wi(t) ≤ ˆW H i in Algorithm 2. The schemes are compared based on two metrics. The first one is the required provisioned bandwidth ˆW c as es- timated during the trial phase. The second one is the re- sulting acceptance ratio in the regular phase denoted by , ˆPZi , ˆW c, n Algorithm 2: Resource Sharing in Regular Phase 1 Input: ˆW H i 2 Output: u(t), WR(t) 3 set ri = |Zi|2 − |Zi| and γi = exp(F −1 ri 4 set di(0) = P H i 5 for t ≤ Ts do set u(t) = 0 and get Z(t) = (X(t), W(t)) for each NS i do n samplesi.add(Zi(t)) if t > n then n samplesi.pop() if 1⊤W(t) ≤ ˆW c then for each NS i do an=hypothesis test(n samplesi, γi, ˆPZi) if an==False then A(t).add(i) bandwidth allocation() if AR(t) = ∅ then set ˆW c = W R(t) and A(t) = B(t) bandwidth allocation() di(t + 1) = [di(t) − u∗ /* Functions 25 hypothesis test(n samples, γi, ˆPZi): for 2 ≤ k ≤ n do z′ = n samples[k] z = n samples[k-1] t counts(z, z′)+ = 1 Z counts(z′)+ = 1 L0 = L1 = 1 for 2 ≤ k ≤ n do z′ = n samples[k], z = n samples[k-1] ˆQZ(z′|z) = t counts(z, z′)/Z counts(z′) L1 = ˆQZi(z′|z)L1, L0 = ˆPZi(z′|z)L0 if L1 ≥ γiL0 then return True return False 40 bandwidth allocation(): solve Binary Knapsack Problem (17) for each NS i ∈ A(t) do i (t) == 0 then AR(t).add(i) if W R(t) > 0 then solve linear optimization problem (18) t=1 ui(t)/Ts. Notice that ai should be at least P H ai i shown in the first constraint of optimization problem (1). i and rw i Notice that rc Moreover, to gain more insight regarding the performance of each scheme, we also plot the ratio of correct and wrong rejections of each NS i denoted by rc respectively. The first ratio is the number of times that hypothesis testing rejected NS i and it was indeed anomalous at that time over the number of times that hypothesis testing occurred and NS i was anomalous. The second quantity measures the ratio of wrong rejections similarly. i and rw i seem similar to the power and false alarm rate of the detector used in hypothesis testing. However, they differ from them since the detector checks if all n previous samples where generated by the expected stochastic model, not just the most recent one. Hence, if a NS i stops misbehaving at t, the detector is designed to reject it at time t = t + n/2 even if NS i is not anomalous at that time. Therefore, the quantities rc i and rw i allow us to investigate the effect of sample size n on performance during transition periods where a NS starts or stops misbehaving. To evaluate the aforementioned schemes, we use the dataset in [29] which was made publicly available by the IMDEA Networks Institute1. It contains LTE mobile traffic at several BSs in Spain that was captured around 2020. The authors obtained these measurements by running a passive monitoring tool called Falcon [30] on a Linux laptop that was connected to a USRP B210 Software Defined Radio (SDR). The authors then connected to various BSs and used Falcon to decode the Physical Downlink Control Channel (PDCCH) sent by the BS to the connected User Equipments (UEs) in order to extract resource allocation information with millisecond granularity. The obtained raw data is stored as parquet files. Each line in the files contains the following: the unix timestamp, the system frame and the subframe number in LTE, the Radio Network Temporary Identifier (RNTI) of the UE, the direction of the traffic, i.e., uplink or downlink, the MCS index used by the UE and the number of PRBs utilized by the UE at that particular subframe. A sample of the file is shown in Fig. 3. D. Extraction of state time series {Xi(t)}t∈N Since the system architecture proposed in Fig. 1 is not deployed at the BSs, we use the dataset to create a time series for Z(t) for the evaluation of our proposed approach. We primarily focus on downlink traffic since it comprises most of the mobile traffic. Hence, we wish to obtain a time series for the states Xi(t) and their corresponding bandwidth demands Wi(t) for each NS i in downlink. To do so, we consider that the state Xi(t) includes the number of UEs in Radio Resource Control (RRC) Connected state and their average MCS at time t. Notice that the number of RRC connected UEs at some time t differs from the UEs that are actively transmitting or receiving at time t. This is the case since the MAC scheduler may wish to prioritize some UEs and allocate the whole bandwidth to them. Therefore, although some UEs may have data to transmit or receive, the MAC scheduler may not schedule them for transmission. As a result, we cannot simply count the number of lines in the data file at some time t as in Fig. 3 to approximate the number of UEs in RRC Connected state. Instead, we utilize the approach as in [29] where the authors use a method that maps the temporary RNTIs to UE identifiers. This method was originally developed in [31] and it essentially attempts to find the expiration period of the temporary RNTIs. Based on this estimation, the number of UEs in RRC Connected state can be estimated since an RNTI acts as a UE identifier within its expiration period. The authors applied the method in [31] on their raw data files and obtained an estimation of the number of RRC Connected UEs with one second granularity which is also included in their final dataset. Hence, for the first component of the state Xi(t) we use this readily available data. Regarding the second component of the state Xi(t), we consider the average MCS over all users actively transmitting at time t. We compute this simply by taking the average of the ”mcs idx” column in Fig. 3 for lines with timestamp = t and direction = 1 since we are interested in downlink traffic. E. Definition of desired QoS In order to derive the time series for Zi(t) based on the times series Xi(t), it is necessary to define the desired QoS of each NS i. We consider a simple QoS requirement that facilitates an easy map from Xi(t) to Wi(t). Specifically, we consider each NS i requires a constant bitrate Ri for each UE that is in RRC Connected state at each slot t. F. Extraction of bandwidth demand time series {Wi(t)}t∈N We compute the required PRBs Wi(t) to provide bitrate Ri to each connected UE at time t based on Table 7.1.7.1-1 and Table 7.1.7.2.1-1 in 3GPP document [19] as mentioned previously in Sec. III. Notice that the second component of Xi(t), i.e., the average MCS over all users at time t and the bitrate Ri are the two elements needed to obtain the PRBs needed for a single UE based on the previous tables. Then, we multiple this amount of PRBs by the first component of Xi(t), i.e., the number of connected users, to compute the bandwidth demand Wi(t). Lastly, we assume that all UEs support 2x2 and thus we multiple the contents of the second table by 2. We note that it would be more accurate to repeat this process for each UE individually. However, this would require that Xi(t) contains the MCS index of each UE which requires large memory. Although this is feasible, we consider the average MCS index over all UEs and then multiple the resulting PRBs by the number of UEs for simplicity. We mention that an alternative way to derive the bandwidth demand at time t would be to use the raw data files by sum- ming the ”nof prb” column for all entries with timestamp = t and direction = 1. In this case, the bandwidth demand Wi(t) is approximated by the total number of PRBs allocated to the NS at time t. This is reasonable assuming that the BS delivered the desired QoS to the UEs. Although this is a simple approach, we noticed that the total PRBs for some subframes t exceeded 100 PRBs which cannot be true since the cell bandwidth at the BS is 20 MHz. Upon contacting the authors in [29], we were informed that such anomalies happen when the PDCCH is decoded erroneously due to low Signal to Noise Ratio (SNR) at the SDR. For this reason, we consider the method described previously to derive the bandwidth demands Wi(t) over time. We note that we could not find any other publicly available dataset that contains granular resource allocation information at the BS. Lastly, notice that the above procedure creates a determin- istic map Wi(t) = µi(Xi(t)) and hence it suffices to consider only the MC of Xi(t) when conducting hypothesis testing as explained in the last paragraph of Sec. V. G. Time, State and Action Aggregation With the previous procedures, we obtain a time series Zi(t) with one second granularity. However, it may not be realistic that the BDE operates in such a fast time scale. For this reason, we create a new time series Zi(t) by aggregating every D seconds where D corresponds to the slot length in Fig. 1. Here, we typically consider D = 10 seconds. The time aggregation of the state series Xi(t) is conducted by sampling the original series every D entries. In general, the aggregation of the Wi(t) series is performed by representing every D entries by their maximum to approximate the output of a BDE based on RL that operates every D seconds and learns a map between Xi(t) and Wi(t). However, here we aggregate demands in time by Wi(t) = µi(Xi(t)) as previously. We also consider another form of aggregation. Given that the BDE may run a RL algorithm, we consider aggregation in the state and action space. For instance, we may consider that the first component of Xi(t) takes values that are multiples of a constant Ui = 10. Thus, if the actual number of UEs at time t is between [10, 20), then Xi(t) = 10. Such aggregations in the state and action space may significantly reduce the convergence time and the memory requirements in the BDE with little performance loss. Thus, we consider such aggregation constants for each NS i denoted by Ui, Mi and Wi for the first state component, the second state component and the action respectively. H. Extraction of time series {Z(t)}t∈N So far we described how to extract a single time series Zi(t). However, we need to extract multiple such series to compose Z(t) when considering multiple NSs. To this end, each time series Zi(t) should be extracted from traffic data from the same BS and time period to consider traffic that competes for the same resources. This data should then be split into chunks by associating different groups of UEs to different NSs. Unfortunately, this is not feasible since the dataset does not contain unique UE identifiers as mentioned earlier. Thus, we should then consider data samples that may originate from different BSs but still correspond to the same time period. However, we could not find any such data samples. A possible explanation is that the authors in [29] used only one SDR for their measurements and thus could not obtain data from different BSs at the same time. As a result, we collect data samples from different BSs and time periods which we then associate to different NSs. Nonetheless, the time periods considered have certain common characteristics. Specifically, we consider data collected between specific hours, e.g., from 17:00 to 22:00 every day from Monday to Friday. Then, the samples collected from Monday to Thursday are used for the trial phase and the ones collected on Friday are used for the regular phase. The previous example results to T = 7200 samples. We note that the selection of a certain range of hours is motivated by the fact that real traffic varies considerably throughout the day. Thus, we consider that a single MC PZi cannot model the traffic during the whole day but only during specific hours of each day. Lastly, we note that the measurement in the raw data files are sometimes sparse. Therefore, the specific hours considered vary from experiment to experiment in order to obtain data samples that are dense. As a result, we do not utilize (11) to determine the number of samples needed during the trial phase. Instead, we obtain the data as described previously. I. Creation of anomalies As mentioned in Sec. V, the anomalies considered are changes in the transition matrix of the process Zi(t). In case Wi(t) = µi(Xi(t)), then it suffices to consider variations for the PXi transition matrix. Moreover, if the state components follow independent MCs, then it suffices to consider variations to one of these MCs. As a result, we primarily modify the transition matrix PUi that the number of connected users Ui(t) follows. Such modifications may model an increase in the number of connected UEs to the BS. Let P ′ denote the new transition matrix followed by Ui(t) Ui and let P ′ (u′|u) denote its elements. To properly evaluate our Ui approach, the new matrix P ′ must be constructed carefully. Ui Otherwise, the anomalies may be easily detected by the hypothesis testing procedure. For instance, the matrix P ′ Ui should not contain any new entries, i.e., P ′ (u′|u) = 0 if Ui the old entry PUi(u′|u) = 0. In addition, we are interested in new matrices P ′ that produce higher demands µi(Xi(t)) and Ui result in resource contention that may negatively impact the performance of the other NSs. Due to the above, we construct the new matrix P ′ by Ui deleting the lowest β% of states in the MC of Ui(t). To do so without creating new entries, the transition probability from a state s to a removed state s′ is added to the largest transition probability from s. As a result, we create a new matrix that is similar to the original one but whose states correspond to higher number of users. Thus, the new matrix skews the behavior of the NS towards generating higher bandwidth demands. Figure 4 illustrates the previous procedure. Once the new matrix P ′ Ui is obtained, an anomalous se- quence {Ui(t)}ts≤t ≤te can be generated where ts and te denote its start and end respectively. Notice that ts must be chosen carefully so that there is a smooth transition between the old and new sequence. Otherwise, the anomaly is easy to detect. For this reason, we choose ts as the earliest time that the old sequence arrives at one of the new states in P ′ . Ui However, we also wish that the anomaly starts once the sample size n is complete to consider the effect of old samples in the detection. Thus, we impose that ts > n. For similar reasons, we wish that te < Ts − n. Lastly, we set te as high as possible given the previous constraints so that the anomaly can have an effect on resource allocation and create resource contention. In the first test scenario, we consider two NSs. Each NS needs to constantly deliver R0 = R1 = 1 Mbps to each connected UE for at least P H 1 = 0.9 fraction of slots. The data for NS 0 and NS 1 are taken from the ”I-1815-raw-df- ms.parquet” and ”I-2650-raw-df.ms.parquet” files respectively. The data collection period for both NSs is from 17:00 to 22:00 each day from Monday, May 25 to Friday, May 29, 2020. The days from Monday to Thursday comprise the trial phase, whereas Friday comprises the regular phase. We first consider that all NSs behave normally during the regular phase to obtain a reference point. Then, we consider that NS 0 is anomalous for various β. We plot the metrics mentioned previously for each scheme and for each case. We vary the sample size n to determine its effect on performance. We depict some traffic statistics of this test scenario in Fig. 5 and Fig. 6. The results are shown in Tables I-IV. In Table I, we verify that the provisioned bandwidths estimated in the trial phase suffice for both NSs and the SLAs are fulfilled. Notice that a0 and a1 in the regular phase are slightly higher than the target P H 1 = 0.9. This may indicate a small discrepancy between the statistics of the data in the trial phase and in the regular phase. However, the increase is probably due to the fact that the no sharing scheme allows the use of the idle W H In Table II, NS 0 is anomalous with β = 0.5. As expected, the no sharing scheme protects the performance of NS 1. However, in the sharing scheme, the SLA of NS 1 is violated since a1 < 0.9. In contrast, the sharing and testing scheme protects the SLA of NS 1 when n ≥ 100. This is also reflected in the fair rejection ratio where rc 0 becomes high at n = 100. This indicates that hypothesis testing starts to detect anomalies for n ≥ 100. Also, notice that rw 0 also increases as n does since more outdated samples are stored which is detrimental when an anomaly stops. Since the anomaly exists almost throughout the simulation, these detrimental effects are particularly pronounced here. However, these effects would wash off in longer simulations. Also, we note that the above issue affects only NSs that at some point were anomalous for which the operator is not required to fulfill their SLA. Similar observations can be made for the cases where β = 4/6 and β = 5/6 in Tables III and IV respectively. Here, also note that anomalies can be detected for a smaller sample size n = 50 since they are more pronounced and thus the detector requires fewer samples to accurately detect them. Overall, in the cases where the simple sharing scheme fails, the proposed scheme satisfies the SLAs with 19% less bandwidth than the no sharing scheme. In the second test scenario, we consider again two NSs. We consider required constant bitrates R0 = 1 and R1 = 2 Mbps and QoS delivery for P H 1 = 0.9 fraction of slots. The data for NS 0 and NS 1 are taken from the ”I-1796-raw-df- ms.parquet” and ”I-1815-raw-df.ms.parquet” files respectively. The data collection period for NS 0 is from 14:00 to 19:00 each day from June 17 to June 19, 2020 and for NS 1 from 14:00 to 19:00 each day from May 25 to May 27, 2020. The last day corresponds to the regular phase. Here, we consider all possible β for each NS to test the schemes for various anomalies. For brevity, we do not depict the granular information provided by the previous tables. In Fig. 7, we depict ECDF of the users. Table V shows that all schemes satisfy both SLAs when no NS misbehaves, but resource sharing schemes do so with 21% less bandwidth. In Fig. 8, we show the performance of the schemes as we vary the number of low states removed from the user MC of NS 0. The results show that hypothesis testing protects the SLA of the well-behaved NS 1. The corresponding results when NS 1 is anomalous are shown in Fig. 9. In this case, no hypothesis testing was needed, possible because the traffic in NS 1 is lighter as shown in Fig. 7. In the third test scenario, we consider 3 NSs. The required constant bitrates are R0 = R2 = 1 and R1 = 2 Mbps with P H 2 = 0.9. The data for NS 0, NS 1 and NS 2 are taken from the ”I-1796-raw-df-ms.parquet”, ”I- 1815-raw-df.ms.parquet” and ”II-816-raw-df.ms.parquet” files respectively. The collection period for NS 0 is from 9:00 to 17:00 each day from June 15 to June 19, 2020. For NS 1, we collect data from 9:00 to 17:00 each day from May 11 to May 15, 2020. Lastly, for NS 2, the collection period is from 9:00 to 17:00 each day from April 7 to April 11, 2021. As previously, we consider all possible β for each NS to test the schemes for various anomalies In Fig. 10, we depict the ECDF of the users for each NS. Table VI shows that all schemes satisfy all SLAs when no NS misbehaves, but resource sharing schemes do so with 26% less bandwidth. In Fig. 11, we show the performance of the schemes as we vary the number of low states removed from the user MC of NS 0. The results show that hypothesis testing protects the SLAs of the well-behaved NSs 1 and 2. The corresponding results when NS 1 and NS 2 are anomalous are shown in Fig. 12 and in Fig. 13. In these cases, hypothesis testing is not needed. The two most time consuming online procedures in Algo- rithm 2 are the bandwidth allocation and hypothesis testing. The former involves the solution of a BKP which is NP-Hard. The simulations results in [2, Fig. 3] show that the BKP can be solved optimally within 5 ms if the number of NSs is less than 100. This can be reduced if fully polynomial time approx- imation schemes are used. The results were obtained using a computer with an Intel i7-10700K @3.8 GHz processor. Regarding hypothesis testing, we first note that it can be performed in parallel for each NS. Therefore, it suffices to consider a single NS. Next, it is easy to see that its execution time scales linearly w.r.t. the sample size n. In Fig. 14, we depict the mean execution time per sample size n over all the tests conducted in test scenario 3. The results were obtained using a laptop with an Intel i5-7200U @2.5 GHz processor. Overall, the total execution time of the online procedures in the regular phase are in the order of a few milliseconds. Since the slot length D is in the order of tens of seconds, the proposed scheme can be performed online. E. Comments on Results First of all, we address the high number of PRBs reported in the previous test scenarios. This may be caused since the total number of connected users as obtained from the dataset is high and the desired QoS is to constantly provide 1 or 2 Mbps to each user throughout their connection time. Also, note that each NS comprises all the traffic served by a single BS. Next, we summarize all the previous results in a single table to compare the resource efficiency and performance isolation that each scheme provides. To this end, we consider that the resource efficiency of a scheme is the percentage decrease in PRBs it achieves when compared to the no sharing scheme. Performance isolation is measured by the percentage of cases where a NS was anomalous and the SLAs of all well-behaved NSs were satisfied. Both these metrics are computed for each test scenario using the previous simulation results. Next, we combine the results by assuming that the test scenarios are equiprobable and then we report the averages in Table VII. The table clearly shows that hypothesis testing provides both high resource efficiency and high performance isolation. Finally, the code we developed to analyze the dataset in [29] is available on GitHub2. All the previous tables and figures can be reproduced using the dataset in [29] as input to our code. We considered the problem of satisfying the SLAs of mul- tiple NSs. We argued that resource provisioning and dynamic resource adaptation need to be considered jointly to solve this problem. We proposed a solution approach that consists of two phases; the trial phase and the regular phase. In the trial phase, the operator estimates the required provisioned resources and obtains a model for each NS that describes its normal behavior. In the regular phase, if resource contention occurs, the operator uses the previous models to fairly decide which NSs should be rejected via hypothesis testing. Results showed that our approach is robust against traffic anomalies and satisfies the SLAs of well-behaved NSs with reduced bandwidth. We note that there are several directions for improvement. First, a bayesian approach may be considered for hypothesis testing if priors can be estimated from past data. Alternatively, the worst case prior may be considered to formulate a minimax detection problem. Second, it may be beneficial to only check whether a NS generates more traffic than it normally does. Third, the parametric models may be used to simplify the tests. These directions may facilitate a complete performance analysis to derive the metrics in Table VII without simulations.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.18254v1.pdf",
         "extracted",
         "None",
         "",
         "Robust Resource Sharing in Network Slicing via Hypothesis Testing"
        ],
        [
         "1",
         "0004c478be53ae7cc93461846992842c73778e7e",
         "None",
         "Louis Golowich,V. Guruswami",
         "\n**BLOCK**fs== 17.2**p== 0.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\nQuantum Locally Recoverable Codes∗\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.2**l== 0.3**r== 0.5**\nLouis Golowich\nUC Berkeley\nlgolowich@berkeley.edu\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.2**l== 0.6**r== 0.2**\nVenkatesan Guruswami\nUC Berkeley\nvenkatg@berkeley.edu\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\nNovember 16, 2023\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nAbstract\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.4**l== 0.2**r== 0.1**\nClassical locally recoverable codes, which permit highly eﬃcient recovery from localized\nerrors as well as global recovery from larger errors, provide some of the most useful codes for\ndistributed data storage in practice. In this paper, we initiate the study of quantum locally\nrecoverable codes (qLRCs).\nIn the long term, like their classical counterparts, such qLRCs\nmay be used for large-scale quantum data storage. Furthermore, our results have concrete\nimplications for quantum LDPC codes, which are widely applicable to near-term quantum error-\ncorrection, as local recoverability is a weakening of the LDPC property.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nAfter deﬁning quantum local recoverability, we provide an explicit construction of qLRCs\nbased on the classical LRCs of Tamo and Barg (2014), which we show have (1) a close-to-optimal\nrate-distance tradeoﬀ (i.e. near the Singleton bound), (2) an eﬃcient decoder, and (3) permit\ngood spatial locality in a physical implementation. The analysis for both the distance and\nthe eﬃcient decoding of these quantum Tamo-Barg (qTB) codes is signiﬁcantly more involved\nthan in the classical case. Nevertheless, we obtain close-to-optimal parameters by introducing\na “folded” version of these qTB codes, which we then analyze using a combination of algebraic\ntechniques. We furthermore present and analyze two additional constructions using more basic\ntechniques, namely random qLRCs, and qLRCs from AEL distance ampliﬁcation. Each of these\nconstructions has some advantages, but neither achieves all 3 properties of our folded qTB codes\ndescribed above.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nWe complement these constructions with Singleton-like bounds that show our qLRC con-\nstructions achieve close-to-optimal parameters. We also apply these results to obtain Singleton-\nlike bounds for qLDPC codes, which to the best of our knowledge are novel. We then show that\neven the weakest form of a stronger locality property called local correctability, which permits\nmore robust local recovery and is achieved by certain classical codes, is impossible quantumly.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nResearch supported in part by a Simons Investigator award, and a UC Noyce initiative award. L. Golowich is\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nsupported by a National Science Foundation Graduate Research Fellowship under Grant No. DGE 2146752.\n**BLOCK**fs== 10.9**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\n1 Introduction\n**BLOCK**fs== 10.9**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\n1.1 Our Contributions\n**BLOCK**fs== 10.9**p== 1.0**b== 0.6**t== 0.2**l== 0.1**r== 0.1**\n. . . . . . . . . . . . . . . . . . . . . . . 11\n1.3 Open Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n**BLOCK**fs== 10.9**p== 1.0**b== 0.6**t== 0.2**l== 0.1**r== 0.1**\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1 Deﬁnition of Quantum Local Recoverability . . . . . . . . . . . . . . . . . . .\n1.1.2 Explicit Construction of qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . .\nSingleton-Like Bound for qLRCs, with Implications for qLDCP Codes . . . .\n1.1.3\n1.1.4 Comparison to Basic Constructions . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.5 Eﬃcient Decoding Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . .\nImpossibility of Quantum Locally Correctable Codes . . . . . . . . . . . . . .\n1.1.6\n1.2 Overview of (Folded) Quantum Tamo-Barg codes . . . . . . . . . . . . . . . . . . . .\n1.2.1 Background and Classical Tamo-Barg Codes\n. . . . . . . . . . . . . . . . . .\n1.2.2 Quantum Tamo-Barg codes . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.3 Folded Quantum Tamo-Barg Codes\n**BLOCK**fs== 10.9**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\n2 Preliminaries\n**BLOCK**fs== 10.9**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n2.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.2 Classical Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.3 Polynomial Evaluation Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.4 Quantum Codes\n**BLOCK**fs== 10.9**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n3 Singleton-Like Bounds for qLRCs\n**BLOCK**fs== 10.9**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\n4 Basic Constructions Using Known Techniques\n**BLOCK**fs== 10.9**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n4.1 Random qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.2 Explicit qLRCs from AEL Distance Ampliﬁcation . . . . . . . . . . . . . . . . . . . . 25\n4.2.1 Review of AEL Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.2.2 Application to qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n**BLOCK**fs== 10.9**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\n5 Explicit Construction of qLRCs: Quantum Tamo-Barg Codes\n**BLOCK**fs== 10.9**p== 1.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n5.1 Classical Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.2 Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.3 Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n**BLOCK**fs== 10.9**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\n6 Bounding the Distance\n**BLOCK**fs== 10.9**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n. . . . . . . . . . . . . . . . . . . 34\n6.1 Distance of Unfolded Quantum Tamo-Barg Codes\n6.2 Distance of Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . 35\n**BLOCK**fs== 10.9**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\n7 Eﬃcient Decoding Algorithm\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n. . . . . . . . . . . . . . . . . . . . . . . . . . 41\n7.1 Unfolded Quantum Tamo-Barg Codes\n7.2 Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.4**\n8 Impossibility of Quantum Locally Correctable Codes\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\n9 Acknowledgments\n**BLOCK**fs== 10.9**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nA Technical Lemmas\n**BLOCK**fs== 10.9**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nB Omitted Proofs\n**BLOCK**fs== 10.9**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nClassical locally recoverable codes (LRCs) provide one of the most important coding theoretic\ntools for distributed data storage. Such codes are deﬁned to permit highly eﬃcient recovery from\ncommon localized errors, as well as larger-scale recovery from rarer but more “catastrophic” global\nerrors.\n**BLOCK**fs== 10.9**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nIn this paper, we initiate the study of quantum locally recoverable codes (qLRCs). In particular,\nwe deﬁne qLRCs, present and analyze constructions, and also prove fundamental limitations on\nthe achievable parameters and properties. While our constructions can be viewed as quantum\ngeneralizations of classical constructions, the analysis becomes surprisingly intricate, and requires\nnew ideas that were not needed classically. Our results may also shed light on the study of locality\nin quantum coding theory, for instance as it pertains to quantum LDPC codes.\n**BLOCK**fs== 10.9**p== 3.0**b== 0.5**t== 0.3**l== 0.1**r== 0.1**\nClassically, the properties of a LRC are well suited for the needs of large datacenters, which can\ncost billions of dollars to build and maintain, and must often account for localized server failures\nwhile also handling occasional more global failures. Indeed, companies such as Microsoft [HSX+12]\nand Facebook [MLR+14] have implemented LRCs to obtain improved performance for data storage.\nCurrently, experimental quantum computers remain at a vastly smaller scale than that of the\nclassical datacenters in which LRCs are often used in practice. However, it is not implausible that\nquantum computing technology eventually follows its classical counterpart by growing to the scale\nwhere codes such as qLRCs become an integral part of quantum data storage.\n**BLOCK**fs== 10.9**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nFurthermore, our study of qLRCs reveals the potential for more broad and near-term impli-\ncations as well. Indeed, locality properties in quantum codes, such as the ability to decode using\nlocal measurements (i.e. LDPC codes), are of particular importance for quantum error correction.\nYet such locality is notoriously diﬃcult to achieve in the quantum setting. Indeed, the ﬁrst linear-\ndistance quantum LDPC (qLDPC) codes were only recently constructed [PK22, LZ22, DHLV23],\nand good quantum codes with stronger properties such as local testability have yet to be con-\nstructed. This diﬃculty of achieving locality is in contrast to the classical setting, where good\nLDPC codes have been known for decades (e.g. [SS96]), good locally testable codes were recently\nconstructed [PK22, DEL+22], and other strong locality properties such as local correctability exist\nin linear-distance, albeit low-rate codes.\n**BLOCK**fs== 10.9**p== 3.0**b== 0.2**t== 0.6**l== 0.1**r== 0.1**\nFrom this perspective, our study of qLRCs provides a new angle to investigate locality properties\nin quantum codes. Indeed, classical local recoverability requires each code component to participate\nin one low-weight parity check, while quantum local recoverability requires each code component\nto participate in two low-weight stabilizers. Thus local recoverability can be viewed as a weaking\nof the LDPC property, in which each code component participates in many low-weight parity\nchecks/stabilizers. Our study of qLRCs can therefore be viewed as progress towards understanding\nstronger locality properties possessed by qLDPC codes. One concrete example of this connection\nis provided in Section 3, where we show that qLRCs, and therefore also qLDPC codes, of constant\nlocality r = O(1) must have relative distance bounded away from 1/2; to the best of our knowledge\nsuch a bound for qLDPC codes had not been previously shown.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nIn this section we present the contributions of our paper. For details on notation or basic deﬁnitions,\nthe reader is referred to Section 2.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.4**\n1.1.1 Deﬁnition of Quantum Local Recoverability\n**BLOCK**fs== 10.9**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nTo begin, we deﬁne qLRCs. Recall that a classical LRC (cLRC) is a classical code C such that for\nC and every component i, the value of ci can be recovered by looking at the restriction\nevery c\nof c to just r\n**BLOCK**fs== 10.9**p== 4.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\n1 other components.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nDeﬁnition 1 (Informal statement of Deﬁnition 32). A quantum locally recoverable code\n(qLRC) of locality r is a quantum code\nC\nis erased (i.e. it experiences a completely depolarizing channel), the original code state\nrecovered by applying a recovery channel that accesses only r\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nψ\nsuch that if any single qudit of a code state\ni ∈ C\n|\ncan be\nψ\ni\n1 other code state qudits.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nFor intuition, recall that a classical linear code is a cLRC of locality r if each component takes\npart in a parity-check of weight\n= CSS(CX , CZ )\nis a qLRC if both CX, CZ are cLRCs, so that every qudit takes part in a low weight X-parity-check\nand a low-weight Z-parity-check (see Corollary 34).\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.4**l== 0.4**r== 0.2**\nr. Similarly, we show that a quantum CSS code\n**BLOCK**fs== 10.9**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nWe remark that classically, there is also a notion of message locally recoverable codes (mLRCs),\nwhich require that every message (instead of codeword) symbol can be recovered from r\n1 code-\nword symbols. As any linear classical code has a systematic encoding, meaning that the ﬁrst k\ncodeword symbols equal the message, classical mLRCs are strictly weaker than LRCs. However,\nthe local indistinguishability property of quantum codes (see Lemma 26) implies that local queries\nto quantum codes cannot reveal anything about the message. Thus mLRCs do not exist quantumly,\nat least in the regime where the locality is less than the distance.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n1.1.2 Explicit Construction of qLRCs\n**BLOCK**fs== 10.9**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nOne of our principal technical contributions is the following explicit construction of qLRCs.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nTheorem 2 (Folded quantum Tamo-Barg codes; informal statement of Corollary 64 combined\nwith Lemma 56). For every prime number r and every 0 < R < 1, there exists an inﬁnite explicit\nfamily of qLRCs of locality r, rate\n**BLOCK**fs== 10.9**p== 4.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\nR, relative distance\n**BLOCK**fs== 10.9**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nand alphabet size nO(r2), where n denotes the block length.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nIn Theorem 2 (and in future informal result statements in Section 1), for readability we state\nslightly looser bounds than the formal result statements. For instance, our actual distance bound\nin Corollary 64 is stronger than than stated in Theorem 2 for high rates, and in particular shows\nthat δ\n**BLOCK**fs== 10.9**p== 4.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nΩ(1/r) for all R\n**BLOCK**fs== 10.9**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nWe remark that while the alphabet size nO(r2) may seem large, in the LRC literature one\ntypically thinks of each code component as being a fairly large entity, so such a polynomial alphabet\n**BLOCK**fs== 10.9**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nsize is not unreasonable. Classically each code component could for instance be a hard drive, while\nquantumly each component would likely be itself a fault-tolerant quantum memeory.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nWe prove Theorem 2 by introducing a quantum CSS version of the classical LRCs of Tamo and\nBarg [TB14], which achieve the optimal classical rate-distance-locality tradeoﬀ [GHSY12]. The\nclassical Tamo-Barg (TB) codes are constructed as subcodes of Reed-Solomon codes by carefully\ninserting low-weight parity checks.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nMultiple complications arise when converting TB codes into CSS codes. Speciﬁcally, to ensure\nthe CSS orthogonality relations are satisﬁed, we deﬁne a quantum Tamo-Barg (qTB) code to be a\nCSS code\n= CSS(C, C) consisting of two copies of a classical code C that contains a TB code as a\nsubcode, but also contains some added low-weight codewords. These added low-weight codewords\nalso lie in C ⊥, so they do not necessarily degrade the distance of\n, which equals the minimum\nC ⊥. However, these added low-weight codewords make the distance\nweight of an element of C\nanalysis signiﬁcantly more challenging, and we are only able to show a “Johnson-like” bound on\nthe distance of qTB codes:\n**BLOCK**fs== 10.9**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nTheorem 3 (Quantum Tamo-Barg codes; informal statement of Theorem 62). For every prime\nnumber r and every 0 < R < 1, there exists an inﬁnite explicit family of qLRCs of locality r, rate\n**BLOCK**fs== 10.9**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nR, relative distance\n**BLOCK**fs== 10.9**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\n\nand alphabet size n + 1, where n denotes the block length.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nTo obtain the improved bound δ\n**BLOCK**fs== 10.9**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nO(1/√r) in Theorem 2, we “fold” together code\ncomponents, thereby reblocking the symbols into larger components. We then use a combination\nof algebraic techniques to bound the distance of these folded qTB (fqTB) codes; the two main tools\nare a root detection method involving a determinant polynomial, and an uncertainty principle over\nﬁnite ﬁelds.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nIn Section 1.2 below, we describe the formal construction of our (f)qTB codes, and outline the\nproofs of Theorem 3 and Theorem 2. A more detailed description of these codes is provided in\nSection 5, and the distance bounds are formally proven in Section 6.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n1.1.3 Singleton-Like Bound for qLRCs, with Implications for qLDCP Codes\n**BLOCK**fs== 10.9**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nOur fqTB codes in Theorem 2 achieve an optimal rate-distance tradeoﬀ as the locality r grows\nlarge. In particular, we prove the following fundamental limitation on any qLRC.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.7**l== 0.1**r== 0.3**\nTheorem 4 (Singleton-like bound; informal statement of Theorem 35). If\nr and rate R, then\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.7**l== 0.3**r== 0.5**\nhas relative distance\n**BLOCK**fs== 10.9**p== 5.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nis a qLRC of locality\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nThe reader is referred to Theorem 35 for the speciﬁc value of the constant hidden in the the\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nΩ(1/r) term above.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nFor comparison, recall that the ordinary quantum Singleton bound states that every quantum\nR)/2+O(1/n), where n denotes the block length. Thus\n**BLOCK**fs== 10.9**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\ncode of rate R has relative distance δ\n**BLOCK**fs== 10.9**p== 6.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nfor a ﬁxed rate, Theorem 4 shows that imposing local recoverability with locality r decreases the\noptimal relative distance of a quantum code by at least Ω(1/r). Meanwhile, our explicit construction\nin Theorem 64 has relative distance O(1/√r) below that of the Singleton bound.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.3**\nR + O(1/n), while for cLRCs of locality r this bound becomes δ\n**BLOCK**fs== 10.9**p== 6.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nTheorem 4 implies a fundamental diﬀerence between the classical and quantum cases for LRCs\nof low rate. Classically, the ordinary Singleton bound says that a code of rate R has relative distance\nδ\n1) + O(1/n).\nThe TB codes achieve this latter bound, proving its tightness. Therefore in particular, for ﬁxed\n0, we see that there exist classical LRCs of relative distance\nlocality r, by letting the rate R\nIn contrast, whereas there exist quantum codes of relative distance approaching 1/2,\nδ\nTheorem 4 shows every qLRC has relative distance at most 1/2\nΩ(1/r), which is bounded away\nfrom 1/2 for ﬁxed r.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nAs we mentioned previously, because every (q)LRC is a by deﬁnition a (q)LDPC code, it follows\nthat qLDPC codes of locality r have relative distance\nΩ(1/r) for arbitrarily large alphabets.\nTo the best of our knowledge, such a bound has not been previously shown in the literature. This\nresult is in again in contrast to the classical case, where for instance the q-ary Hadamard code is\nan LDPC code of locality 3 with relative distance approaching 1 as q grows large.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nThe discussion above raises the interesting question as to how tight Theorem 4 is for qLDPC\ncodes. That is, what is the additional cost to the optimal rate-distance tradeoﬀ of requiring a\nquantum code be LDPC, compared to just being an LRC?\n**BLOCK**fs== 10.9**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n1.1.4 Comparison to Basic Constructions\n**BLOCK**fs== 10.9**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nWhile our explicit fqTB codes in Theorem 2 are O(1/√r) below the Singleton-like bound in The-\norem 4, we show that a randomized construction improves this gap to O(1/r), at the cost of\nexplicitness and eﬃciency.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nProposition 5 (Random qLRCs; informal statement of Proposition 40). For every r\n3 and\nδ > 0, there exists a randomized construction that with high probability gives a qLRC of locality r,\nrate R, relative distance\n**BLOCK**fs== 10.9**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nand alphabet size 2O(r).\n**BLOCK**fs== 10.9**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nThe constant hidden in the O(1/r) term in Proposition 5 is larger than the constant in the\nΩ(1/r) term in Theorem 4, so our bound on the randomized construction is still O(1/r) below that\nof our Singleton-like bound.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nThus the randomized construction in Proposition 40 achieves relative distance O(1/r) below\nour Singleton-like bound with has alphabet size 2O(r). These parameters improve upon our fqTB\nconstruction, which has relative distance O(1/√r) below the Singleton-like bound, and has alphabet\nsize nO(r2).\n**BLOCK**fs== 10.9**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nHowever, the main disadvantage of the randomized construction is its non-explicitness. As a\nresult, we have no eﬃcient algorithm to certify that a randomly sampled qLRC has good distance,\nand we have no eﬃcient decoding algorithm for errors in unknown locations. In contrast, our fqTB\ncodes are explicit, so their distance bound is guaranteed. Furthermore, we show that they have an\neﬃcient decoding algorithm (see Section 1.1.5 below).\n**BLOCK**fs== 10.9**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nOne way of derandomizing the random qLRCs in Proposition 5 is to use them as in inner code in\nthe concatenation and distance ampliﬁcation scheme of Alon, Edmunds, and Luby (AEL) [AEL95].\nThis technique has been used extensively in classical coding theory [GI01, GI02, GI03, GR08,\nHW18, KMRZS16, GKO+18, HRZW20], but has only recently been considered in the quantum\nsetting [BGG22, WLH23]. We show that applying AEL using a random qLRC as an “inner code,”\nwhich is small enough to be found eﬃciently via brute force, yields the following result.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nProposition 6 (qLRCs from AEL; informal statement of Proposition 49). For every ﬁxed 0 <\nN that there exists an inﬁnite family of eﬃciently\nR < 1, it holds for all suﬃciently large r\nconstructable qLRCs of locality r, rate R, relative distance\n**BLOCK**fs== 10.9**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nand alphabet size q = 2O(r), where the OR above hides a constant depending on R.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nAs described in Remark 50, the codes in Proposition 6 are technically only eﬃciently con-\nstructable by a randomized algorithm with high probability, but can be made truly explicit by\nusing a slightly more complicated construction, with slightly worse parameters. Also, like our fqTB\ncodes, we show that these codes from AEL have eﬃcient decoders from errors in unknown locations.\nThe alphabet size q = 2O(r) in Proposition 6 is smaller than the q = nO(r2) of our fqTB codes in\nTheorem 2. However, qLRCs from AEL have worse rate-distance-locality tradeoﬀ, as their relative\ndistance is OR(1/r1/4) below the Singleton-like bound, compared to only O(1/√r) for our fqTB\ncodes.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.3**t== 0.5**l== 0.1**r== 0.1**\nOur (f)qTB codes may have additional practical advantages over the qLRCs from AEL. For\ninstance, our (f)qTB codes can achieve locality as small as r = 3, whereas the the minimum pos-\nsible locality in the qLRCs from AEL is r = 9. Furthermore, as one step in the AEL construction\nredistributes code symbols according to the edges of an expander graph, the resulting size-r sets of\ncode components used for local recovery form an r-uniform hypergraph with a complex expanding\nstructure. In contrast, the recovery sets of our (f)qTB codes form a partition of the code com-\nponents, which is ideally suited for a physical implementation with good spatial locality. That is,\nour (f)qTB codes can easily be implemented in 1, 2, or 3-dimensional space such that each local\nrecovery operation only involves code components that are close together; such a spatially local\nimplementation would be much less feasible for a qLRC from AEL.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n1.1.5 Eﬃcient Decoding Algorithms\n**BLOCK**fs== 10.9**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nThis section presents our results on the decodability of our qLRCs. As we discussed previously, in\nthe classical setting, LRCs are typically used for data storage where errors correspond to events\nsuch as server failures that are detectable. Such errors occur in known locations, so they can be\ntreated as erasures. Because every linear code can be eﬃciently decoded from a number of erasures\nup to the distance using Gaussian elimination, the eﬃciency of decoding is often not a primary\nconcern for cLRCs. Note that all of our qLRC constructions are stabilizer (and in fact CSS) codes,\nwhich can similarly be decoded eﬃciently from erasures.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nHowever, in the quantum setting there are additional potential applications of eﬃcient decoding\nfrom errors in unknown locations. Due to the inherently noisy nature of quantum states, even if\n**BLOCK**fs== 10.9**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\na qLRC is used to store a large quantum state where each code component is itself stored in a\nfault-tolerant memory, these individual fault-tolerant memories may eventually accumulate errors.\nAs such, it may be beneﬁcial to occasionally perform a global decoding procedure to reduce the\noverall error rate in the long term.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nFurthermore, as we have previously discussed, qLRCs can be viewed as a stepping stone towards\nbetter understanding stronger locality properties, such as the LDPC property, which are important\nfor near-term quantum error correction. As eﬃcient decoding is critical for these error correction\napplications, it is desirable that the qLRCs we study are also eﬃciently decodable.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nBelow we present a polynomial-time decoding algorithm for the fqTB codes in Theorem 2.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nTheorem 7 (Decoding fqTB codes; informal statement of Corollary 72). The fqTB codes in The-\norem 2 of block length n, prime locality parameter r, and rate R can be decoded from errors acting\non an unknown\n**BLOCK**fs== 10.9**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nfraction of the code components in time nOr(1), provided the alphabet size is increased to some\nsuﬃciently large q = nOr(1) with respect to r. Here Or(1) denotes a suﬃciently large constant\ndepending only on r.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nTheorem 7 provides a decoding algorithm for the fqTB codes with decoding radius up to half our\ndistance bound in Theorem 2, which is therefore optimal barring an improvement in the distance\nbound. While the algorithm runs in polynomial time nOr(1) for ﬁxed locality parameter r, this\nalgorithm is ineﬃcient for growing r. We address this issue by providing the following decoding\nalgorithm for unfolded qTB codes, which therefore also applies to folded qTB codes, and whose\nrunning time is a polynomial independent of r.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nTheorem 8 (Decoding (f)qTB codes; informal statement of Theorem 69). An (unfolded or folded)\nqTB code of block length n, prime locality parameter r, and rate R can be decoded from errors acting\non an unknown\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n− r\nfraction of the code components in time nO(1).\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nThe decoder in Theorem 8 simply performs r\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n1 calls to a classical Reed-Solomon (list) decoder,\n−\nand then performs some postprocessing on the resulting outputs (see Algorithm 1). Therefore\nthis algorithm should be eﬃcient in practice, as Reed-Solomon decoders have been optimized for\npractical use.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nThe decoding radius in Theorem 8 is half our distance bound in Theorem 3. Therefore this\ndecoding radius is optimal among decoders for qTB codes, barring an improvement to our distance\nbound in Theorem 3. As\n**BLOCK**fs== 10.9**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nthe unfolded qTB codes achieve distance and decoding radius within roughly a factor of 2 of the\noptimal values as dictated by our Singleton-like bound in Theorem 4.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\n= CSS(C, C) denote the qTB code. The decoding task for\n**BLOCK**fs== 10.9**p== 9.0**b== 0.7**t== 0.1**l== 0.1**r== 0.1**\nWe prove both Theorem 8 and Theorem 7 using similar techniques as in the proof of Theorem 3.\nSpeciﬁcally, let\ncan be reduced to\nthe following problem: given a corrupted codeword a of C, we want an eﬃcient algorithm the\nrecovers some c\nC that is close to a in Hamming weight. For this purpose, we show how every\nC can be modiﬁed to obtain some c′ that is a codeword of a Reed-Solomon code. Applying\nc\nthe same modiﬁcation to a, we obtain a corrupted Reed-Solomon codeword a′. We then apply a\nReed-Solomon (list) decoder to recover c′, which we can then map back to the desired codeword c.\nTo decode fqTB codes in Theorem 7, we use the same algorithm, except now we apply a folded\nReed-Solomon list decoder [GR08] to recover c′ from a′. As folded Reed-Solomon codes have a\nlarger list-decoding radius than ordinary Reed-Solomon codes, and our fqTB distance bound in\nTheorem 2 is better than our qTB distance bound in Theorem 3, we obtain a larger decoding\nradius in Theorem 7 than in Theorem 8.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.3**\nImpossibility of Quantum Locally Correctable Codes\n**BLOCK**fs== 10.9**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nOur results on qLRCs described above indicate that while optimal local recoverability is more\nnuanced and diﬃcult to achieve quantumly than classically, there do exist constructions of qLRCs\napproaching the optimal parameters.\nIt is therefore natural to consider quantum analogues of\nstronger forms of locality that exist classically.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nLocal correctability and local decodability provide particularly notable examples of such prop-\nerties. Recall that an LRC of block length n and locality r has the property that any single code\n[n] is erased, the value of a codeword at that component can be recovered from\ncomponent i\n1 unerased components. A locally correctable code (LCC) has the stronger property that\n≤\nafter a linear number Ω(n) of code components are erased, the value of a codeword at each erased\ncomponent i can be recovered from\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.5**l== 0.5**r== 0.3**\n1 unerased components.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.2**\n−\nEquivalently, an LRC requires the value of a codeword at each component i\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nerable from some recovery set of\ncomponent i\nthat can be used to recover the codeword’s value at i.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.3**\n[n] to have Ω(n) disjoint recovery sets, each of which contains\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\n[n] to be recov-\n1 other components. In contrast, an LCC requires each\n1 components\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nLocal decodable codes (LDCs) are deﬁned similarly, except they only need to support local\n**BLOCK**fs== 10.9**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nThe Hadamard and Reed-Muller codes provide examples of classical LCCs and LDCs.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\ntherefore natural to ask whether there are quantum versions of these types of codes.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nAs local access to a quantum code of large distance cannot reveal any information about the\nmessage, local decodability seems to make little sense quantumly, at least in the regime of large\ndistance and small locality. However, quantum local correctability may seem to be a reasonable\nstrengthening of quantum local recoverability.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nWe show below that quantum local correctability is impossible in a strong sense: if a quantum\ncode has even two disjoint recovery sets for a single qudit, then that qudit is unentangled with\nthe remainder of the code state, and contains no information about the message state. Recall\nthat LCCs are typically required to have linearly many such disjoint recovery sets for each code\ncomponent. Thus qLRCs, which have a single recovery set for each qudit, are in some sense the\nlimit of what is possible for quantum local correctability.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.2**\nTheorem 9 (Impossibility of quantum LCCs; informal statement of Theorem 74). Let\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\nWhile we prove Theorem 9 for general quantum codes\n**BLOCK**fs== 10.9**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n[n]\nquantum code of block length n such that for some qudit i\n∈\nsatisfying I 1\nsuch that the following holds for each b = 1, 2: if qudit i of a code state\nis erased (i.e. it experiences a completely depolarizing channel), the original code state ψ\nψ\ncan be recovered by applying a recovery channel that only accesses qudits in I b\ni . Then there exists a\n.\n1-qudit state α such that every ψ\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.2**l== 0.1**r== 0.1**\ncan be decomposed as ψ = αi ⊗\n(Cd)⊗\nn, it is illustrative to consider\ni\n= CSS(CX, CZ ), a set Ii ∋\nCSS or stabilizer codes. Recall from Section 1.1.1 that for a CSS code\ncan be used to recover qudit i if both CX and CZ have parity checks whose support contains i and\nI 2\nlies inside Ii. Thus if I 1\n, then there\ni\ni =\ni ∩\n}\n{\nI 2\ni . But\nsupp(c′Z )\nare parity checks c′X ∈\n∈\n= 0, which contradicts the orthogonality\nc′Z = (c′X )i(c′Z )i 6\nthen supp(c′X )\n∩\nto be a well deﬁned CSS code. Thus Theorem 9 holds for CSS\ncondition C ⊥X ⊆\ncodes. A similar proof holds for stabilizer codes; In Theorem 74 we prove the more general result\nfor arbitrary quantum codes.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.3**l== 0.3**r== 0.6**\ni , I 2\nC ⊥X and c′Z ∈\n, so c′X ·\ni\nsupp(c′Z ) =\n}\n{\nCZ required for\nC\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\ni are both recovery sets for component i with I 1\nI 1\ni and i\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nC ⊥Z such that i\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.6**r== 0.4**\nsupp(c′X )\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\n1.2 Overview of (Folded) Quantum Tamo-Barg codes\n**BLOCK**fs== 10.9**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nIn this section, we provide more details on our (folded) quantum Tamo-Barg codes described in\nSection 1.1.2, and we overview the techniques we use to prove the distance bounds in Theorem 2\nand Theorem 3. The construction and analysis of these codes comprise one of the main technical\ncontributions of our paper.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\n1.2.1 Background and Classical Tamo-Barg Codes\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nOur qTB codes are CSS codes whose associated classical codes are polynomial evaluation codes\nthat are closely related to the classical LRCs of Tamo and Barg [TB14]. To describe these codes,\nwe use the following notation. For a subset S\ndenote\nthe space of polynomials for which only monomials X i for i\nS can have nonzero coeﬃcients.\nq ∼= Fq\nThen let ev : Fq[X]S\ndenote the evaluation map on nonzero points in Fq, so that\nev(f ) = (f (x))x\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nS aiX i : a\n∈\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\n0, let Fq[X]S =\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nWith this notation, a classical Tamo-Barg (TB) code [TB14] speciﬁed by a prime power q, a\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nlocality parameter r\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.5**\n1), and an integer ℓ\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\n[q] is given by ev(Fq[X]S ) for\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\n[TB14] showed that this code has alphabet size q, block length q\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.7**l== 0.2**r== 0.5**\nℓ, and is locally recoverable with locality r.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\n1, dimension ℓ\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.8**r== 0.1**\n, distance\n⌋\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\n1.2.2 Quantum Tamo-Barg codes\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nIn this section, we deﬁne our quantum analogue of TB codes, and give an overview of the analysis.\nFor more details, the reader is referred to Section 5.2 and Section 6.1.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nAs described in Section 1.1.2, to deﬁne a qTB code, we must ﬁrst modify the classical TB code\nby adding some low-weight codewords in order to construct a well-deﬁned associated quantum\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nCSS code. These added low-weight codewords can be interpreted as piecewise linear functions, as\ndescribed below.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nDeﬁnition 10 (Quantum Tamo-Barg codes; restatement of Deﬁnition 53). For a prime power q, a\n[q], we deﬁne the quantum Tamo-Barg\n1) with r\nlocality parameter r\n(qTB) code to be the CSS code\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.2**l== 0.4**r== 0.3**\n3, and an integer ℓ\n∈\n= CSS(C, C) with C = ev(Fq[X]S ) for\n**BLOCK**fs== 10.9**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\n.\n1 (mod r)\n}\nBy some basic algebraic manipulations (see Lemma 55), we show that C ⊥ ⊆\nC\n**BLOCK**fs== 10.9**p== 11.0**b== 0.7**t== 0.3**l== 0.4**r== 0.1**\nC, so the qTB\nhas\n1. A straightforward calculation (see Lemma 56) shows that\n**BLOCK**fs== 10.9**p== 11.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\n= CSS(C, C) is indeed a well-deﬁned quantum CSS code. Note that by construction\n**BLOCK**fs== 10.9**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\ncode\nalphabet size q and block length q\n**BLOCK**fs== 10.9**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nhas dimension\n**BLOCK**fs== 10.9**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nfor some ǫ\n**BLOCK**fs== 10.9**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nThe code C in the deﬁnition above is by deﬁnition the sum of a classical TB code ev(Fq[X][ℓ]\n**BLOCK**fs== 10.9**p== 11.0**b== 0.5**t== 0.4**l== 0.4**r== 0.1**\n(1+rZ)). We call this latter code P the space of piecewise linear\n∩\n**BLOCK**fs== 10.9**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.6**\nwith the code1 P := ev(Fq[X][q\nfunctions due to the following lemma.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nLemma 11 (Restatement of Lemma 57). Let Ωr =\nThen P = ev(Fq[X][q\nform f (x) = βxΩr ·\n**BLOCK**fs== 10.9**p== 11.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nx for some β\n**BLOCK**fs== 10.9**p== 11.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nF∗q : xr = 1\ndenote the rth roots of unity.\n}\n(1+rZ)) consists of all functions f : F∗q →\nFq that can be expressed in the\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nLemma 11 follows directly from the fact that the evaluation of a polynomial h(X) on inputs in\nxr) on such inputs. The lemma implies that every\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nxΩr equals the evaluation of h(X) (mod X r\nfunction in P equals a linear function on the restriction to inputs in each coset xΩr.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nWe show in Lemma 55 that P\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.6**l== 0.4**r== 0.2**\nC ⊥, from which we obtain the local recoverability of\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nCorollary 12 (Restatement of Corollary 58). The qTB code\nis locally recoverable with locality r.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\n= CSS(C, C) given in Deﬁnition 10\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nF∗q, there exists some f\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nProof. As described in Section 1.1.1 and formalized in Corollary 34, it suﬃces to show that for each\nC ⊥\nα\n⊆\n∈\n∈\nas described above, the piecewise linear function f : F∗q →\nαΩr and\nf (x) = 0 for x /\n∈\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.6**r== 0.2**\n| ≤\nFq given by f (x) = x for x\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nαΩr satisﬁes these criteria, as desired.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nr. But because P\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\nC ⊥ such that α\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\nsupp(f ) and\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\nIt only remains to bound the distance of the qTB code\n**BLOCK**fs== 10.9**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nfollowing result, which directly implies Theorem 3.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\n. For this purpose, we show the\n**BLOCK**fs== 10.9**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nTheorem 13 (Restatement of Theorem 62). The qTB code\nparameter r has distance at least\n**BLOCK**fs== 10.9**p== 11.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nin Deﬁnition 10 with a prime locality\n**BLOCK**fs== 9.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n1In Section 5.3 we denote the code ev(Fq[X][q−1]∩(1+rZ)) by B⊥, but for simplicity of notation in this section we\n**BLOCK**fs== 9.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\ndenote it by P .\n**BLOCK**fs== 10.9**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nAs was mentioned in Section 1.1.2, this bound is reminiscent of the Johnson bound (see e.g. The-\norem 7.3.1 of [GRS22]), which in particular implies that a classical code of dimension ℓ and block\n1 whose distance approaches the Singleton bound is list-decodable from at least a fraction\nlength q\nof errors approaching 1\n**BLOCK**fs== 10.9**p== 12.0**b== 0.7**t== 0.3**l== 0.4**r== 0.2**\n1) as the alphabet size and block length grow large.\n**BLOCK**fs== 10.9**p== 12.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nIt is unclear if there is a deeper reason for this similarity between the Johnson bound and\nTheorem 62. However, it is interesting that we are able to improve the distance beyond this\nJohnson-like bound by folding our qTB codes, just as [GR08] introduced folded RS codes to improve\nbeyond the Johnson bound for the list-decoding radius of RS codes.\n**BLOCK**fs== 10.9**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\nProof sketch of Theorem 13. Recall that the distance of\nC ⊥. As P\nof any element of C\nweight at least the value d given in (2).\nFor this purpose, consider any ev(f )\n**BLOCK**fs== 10.9**p== 12.0**b== 0.6**t== 0.4**l== 0.4**r== 0.2**\nC ⊥, it therefore suﬃces show that every element of C\n**BLOCK**fs== 10.9**p== 12.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\n= CSS(C, C) equals the minimum weight\nP has\n**BLOCK**fs== 10.9**p== 12.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nP . At a high level, the proof will proceed as follows.\nC\n∈\nF∗q, G also has\nWe deﬁne a polynomial G such that whenever f has multiple roots in a coset xΩr ⊆\nmany roots in that coset. We can then bound the number of roots of f by bounding the number\nof roots of G, which we in turn bound by the degree of G. By constructing G to have low degree\nrelative to the number of roots of f , we obtain the desired result.\n**BLOCK**fs== 10.9**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nWe now formally deﬁne G. By deﬁnition we may decompose f (X) = g(X) + h(X), where\n(1+rZ)\n**BLOCK**fs== 10.9**p== 12.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\n1+rZ) evaluates to a nonzero classical TB codeword, and h(X)\n**BLOCK**fs== 10.9**p== 12.0**b== 0.4**t== 0.5**l== 0.1**r== 0.3**\ng(X)\nevaluates to a piecewise linear function. Deﬁne the polynomial G(X)\n**BLOCK**fs== 10.9**p== 12.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nBy deﬁnition, the degree of G satisﬁes\n**BLOCK**fs== 10.9**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nMeanwhile, we bound the number of roots of G as follows. For every x\nsuch that f (x) = 0 and f (ωi\nunity ωi\n**BLOCK**fs== 10.9**p== 12.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\nrx) = 0, then\n**BLOCK**fs== 10.9**p== 12.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nF∗q and every rth root of\n**BLOCK**fs== 10.9**p== 12.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nr g(ωi\ni\nω−\n**BLOCK**fs== 10.9**p== 12.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\nr h(ωi\ni\nω−\n**BLOCK**fs== 10.9**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nwhere the second equality above holds because h is piecewise linear. Thus G has a root for every\nordered pair (x, ωi\nr. Summing over all such\npairs of roots of f (see Section 6.1 for details), we ﬁnd that the total number of roots of G is at\nleast\n**BLOCK**fs== 10.9**p== 12.0**b== 0.2**t== 0.8**l== 0.3**r== 0.3**\nrx) of roots of f whose ratio is an rth root of unity ωi\n**BLOCK**fs== 10.9**p== 12.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nThis expression must be bounded above by the RHS of (4); rearranging terms in the resulting\ninequality yields the desired bound\n**BLOCK**fs== 10.9**p== 12.0**b== 0.1**t== 0.9**l== 0.5**r== 0.4**\nd for d given in (2).\n**BLOCK**fs== 10.9**p== 13.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nAs described in Section 1.1.2 and Section 1.2.2, we were only able to prove a “Johnson-like” bound\non the distance of qTB codes, which does not approach our Singleton-like bounds for qLRCs\ndescribed in Section 1.1.3. We address this issue by introducing a “folded” version of qTB codes,\nfor which we show the distance does approach the Singleton bound for large localities r. The proof\nof this distance bound for folded qTB codes (Theorem 2) is quite involved, so in this section we\nsimply provide a brief description of the main ideas involved. The reader is referred to Section 6.2\nfor the full proof.\n**BLOCK**fs== 10.9**p== 13.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nWe deﬁne folded qTB codes by grouping together symbols of qTB codes as described below.\n**BLOCK**fs== 10.9**p== 13.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nDeﬁnition 14 (Restatement of Deﬁnition 59). As in Deﬁnition 10, let\n= CSS(C, C) be the qTB\nC\n1)/r, we deﬁne the folded\n(q\ncode with parameters q, r, ℓ. Given an additional folding parameter s\n−\n|\nquantum Tamo-Barg (fqTB) code ˜\nto be the quantum code of alphabet size qs and block\nC\n1 for F∗q, and then for every i\nlength (q\n1)/s],\n\n1, ωsi+1\nwe block together the s components (each of alphabet size q) at positions\nq\n−\ninto a single component (of alphabet size qs) of the folded code ˜\n.\nin\nC\n**BLOCK**fs== 10.9**p== 13.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\n1)/s obtained as follows. Fix a generator ωq\n**BLOCK**fs== 10.9**p== 13.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nA folded qTB code by construction inherits the rate and local recoverability of the underlying\nunfolded qTB code. Thus to prove Theorem 2, we simply need to bound the distance of the fqTB\ncode. For this purpose, deﬁne S as in (1), so that the underlying unfolded qTB code\n= CSS(C, C)\nhas C = ev(Fq[X]S ). The distance of ˜\nby deﬁnition equals the minimum over all codewords\nC\n(see Deﬁnition 14) in\nev(f )\nwhich f takes at least one nonzero value.\n**BLOCK**fs== 10.9**p== 13.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nC ⊥ of the number of distinct blocks\n**BLOCK**fs== 10.9**p== 13.0**b== 0.3**t== 0.5**l== 0.1**r== 0.1**\nAt a high level, we bound this minimum distance by considering two types of message poly-\nFq[X]S separately. For the ﬁrst type of message polynomial, we\nnomials f (X) =\nuse a similar argument as described in the proof sketch of Theorem 13 in Section 1.2.2. We are\nable to leverage the folding to replace the polynomial G(X) in (3) with another polynomial, which\nconsists of the composition of f with a determinant polynomial. This alternative choice of G(X)\ndetects roots of f more eﬃciently relative to its degree, and hence yields a better distance bound\n(see Claim 68). However, this method breaks down when the coeﬃcients fi of f are supported in\na small number of distinct values i (mod r), that is, when there are\nr distinct values i (mod r)\n= 0. The reason for the breakdown on these “bad” polynomials f stems from\namong all i with fi 6\nthe fact that we need G(X) to be a nonzero polynomial, which becomes more diﬃcult when f has\nfewer nonzero coeﬃcients.\n**BLOCK**fs== 10.9**p== 13.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nFortunately, we can consider such “bad” message polynomials f separately, and instead apply an\nuncertainty principle (Proposition 66) to bound the weight of the associated codeword (Claim 67).\nIntuitively, this uncertainty principle implies that if the coeﬃcients fi are zero for most values of i\n(mod r), then most of the evaluation points in ev(f ) must be nonzero, so ev(f ) has large weight.\nCombining our bounds from the two types of message polynomials described above, we obtain\n**BLOCK**fs== 10.9**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\na bound on the distance of the fqTB code\n**BLOCK**fs== 10.9**p== 13.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n, which yields Theorem 2.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\n1.3 Open Questions\n**BLOCK**fs== 10.9**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nOur work leads the the following open questions:\n**BLOCK**fs== 10.9**p== 14.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n• Can explicit qLRCs be constructed with a better rate-distance-locality tradeoﬀ than given\nby Theorem 2? Two approaches here are to improve our distance bound for fqTB codes in\nTheorem 2, or to introduce new constructions of qLRCs for which stronger bounds can be\nshown. In general, the goal is to close the gap to the Singleton-like bounds in Section 3.\n**BLOCK**fs== 10.9**p== 14.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n• How does the optimal rate-distance-locality tradeoﬀ of qLRCs diﬀer from that of qLDPC\ncodes? As described in Section 1.1.3, our bounds on qLRCs imply bounds on qLDPC codes,\nbut it is an interesting question whether the additional structure in qLDPC codes can be used\nto show stronger bounds. This question also points towards the more general line of inquiry\ninto relationships between notions of locality in quantum codes, of which local recoverability\nand LDPC are two examples of interest.\n**BLOCK**fs== 14.3**p== 14.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\n2 Preliminaries\n**BLOCK**fs== 10.9**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nIn this section, we introduce some notation, and then present preliminary deﬁnitions and results\npertaining to classical codes, quantum codes, and local recoverability.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\n2.1 Notation\n**BLOCK**fs== 10.9**p== 14.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\ny\nWe denote by\n**BLOCK**fs== 10.9**p== 14.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nN, we let [n] =\n**BLOCK**fs== 10.9**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\n.\n\n}\nFor a prime power q, let Fq denote the ﬁnite ﬁeld of order q. For n\ny =\nLet F∗q = Fq \\ {\n\n}\n**BLOCK**fs== 10.9**p== 14.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\n[n] xiyi denote the standard dot product.\n∈\n**BLOCK**fs== 10.9**p== 14.0**b== 0.5**t== 0.5**l== 0.3**r== 0.4**\ndenote the multiplicative group of Fq. For r\n**BLOCK**fs== 10.9**p== 14.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nF∗q denote a\n1), we let ωr ∈\nprimitive rth root of unity, and we let Ωr =\ndenote the group of all rth roots of\nunity. While the choice of ωr is not unique, we typically will think of ﬁxing some (q\n1)st root of\n1)/r\nunity ωq\n−\n\n−\n**BLOCK**fs== 10.9**p== 14.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nF∗q, and then let ωr = ω(q\n**BLOCK**fs== 10.9**p== 14.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nN and for x, y\n**BLOCK**fs== 10.9**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nFor a ﬁnite alphabet A, we denote the Hamming distance between two strings x, y\n**BLOCK**fs== 10.9**p== 14.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\ndis(x, y) =\n[n] : xi 6\ni\n|{\ndenoted dis(X, Y ) = minx\ndenote the Hamming weight of a string x\ndis(x, y) =\n**BLOCK**fs== 10.9**p== 14.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\n. For two sets X, Y\nY dis(x, y). If A is an abelian group (e.g. A = Fq, or A = Fs\n∈\n= dis(0, x) =\n**BLOCK**fs== 10.9**p== 14.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nAn by\nAn, the minimum Hamming distance is\nq) we\n, so that\n**BLOCK**fs== 10.9**p== 14.0**b== 0.2**t== 0.7**l== 0.1**r== 0.7**\nA quantum channel\n**BLOCK**fs== 10.9**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\na of the qudits will be clear from context. Thus ρ\noperator ρ : (Ca)⊗\n(Ca)⊗\ndenote the associated density matrix. For a density matrix ρ\nqudits, we denote the reduced density matrix ρB = TrA\n**BLOCK**fs== 10.9**p== 14.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\n(A) the set of density matrices on a set A of qudits, where the local dimension\n(A) if ρ is a positive semi-deﬁnite Hermitian\nA, we let ψ =\n(A)\nψ\nA is a subset of the\n**BLOCK**fs== 10.9**p== 14.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\nA of trace 1. For a pure state\n**BLOCK**fs== 10.9**p== 14.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\n∈ M\nfrom qudits A to qudits B is a completely positive, trace preserving map\n(B) that can be\n(Ca)⊗\n}ν, called\n**BLOCK**fs== 10.9**p== 14.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\n(A)\nK\nM\nKν : (Ca)⊗\n{\n**BLOCK**fs== 10.9**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nK\nexpressed in the form\n(ρ) =\nKraus operators, which satisfy\n**BLOCK**fs== 10.9**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\n(B). Equivalently, a quantum channel is a map\nν Kν ρK †ν for a set of operators\nν K †ν Kν = I.\nWe let the weight of a quantum channel\n**BLOCK**fs== 10.9**p== 14.0**b== 0.1**t== 0.8**l== 0.1**r== 0.4**\nqudits on which the channel acts nontrivially. Therefore if\nsubset W\nKν = K W\n**BLOCK**fs== 10.9**p== 14.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\n(A) refer to the number of distinct\n→ M\nhas weight w, then there exists a\nK\n= w such that each Kraus operator Kν of K can be decomposed as\n: (Ca)⊗\n**BLOCK**fs== 10.9**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nBelow we deﬁne the notion of a classical code.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nDeﬁnition 15. A classical code of block length n, dimension k, and alphabet size a is a\nsubset C\n**BLOCK**fs== 10.9**p== 15.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\n[a]n of size\n**BLOCK**fs== 10.9**p== 15.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nThe distance d of C is deﬁned as the minimum Hamming distance d = minc\nC.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nbetween any two distinct codewords c, c′ ∈\nFn\nWe say that C is linear if a = q is a prime power so that [a] ∼= Fq and C\nq is a linear subspace.\n⊆\n∼= Fsn\nSimilarly, C is Fq-linear if a = qs for some prime power q so that [a] ∼= Fs\n(Fs\nq and C\nq\n⊆\nis linear subspace over the ﬁeld Fq. The dual of a linear code is C ⊥ =\nFn\n.\nC\nc = 0\nq : c′ ·\nc′ ∈\n}\n∈\n{\nNonzero elements of the dual code C ⊥ are sometimes referred to as parity checks of C.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.7**t== 0.2**l== 0.8**r== 0.1**\nC dis(c, c′)\n∈\n**BLOCK**fs== 10.9**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nAll classical codes satisfy that following fundamental limitation on the tradeoﬀ between distance\n**BLOCK**fs== 10.9**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nand dimension, whose proof is a simple application of the pigeonhole principle.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nProposition 16 (Singleton bound). If C is a classical code of block length n, dimension k > 0,\nand distance d, then\n**BLOCK**fs== 10.9**p== 15.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n−\nFn\nA classical (linear) code can be expressed as the image of a (linear) encoding map Enc : Fk\nq\nthat maps messages to codewords encoding the messages. However, we will mostly consider the\nspace of codewords without reference to the encoding map.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nThroughout this paper we restrict attention to linear or Fq-linear codes, as will be clear from\ncontext. In particular, Fq-linear codes will arise from linear codes over Fq by “folding”, that is, by\ngrouping together symbols of the linear code into larger symbols.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nDeﬁnition 17. A classical locally recoverable code (cLRC) of locality r, block length n,\n[a]n together with a set of local recovery maps Reci\nand alphabet size a is a classical code C\nfor every i\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\n[n] satisfying the following properties:\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\n1. There exists a set Ii ⊆\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\n[n] of size\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nr with i\n**BLOCK**fs== 10.9**p== 15.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nIi such that Reci is a function Reci :\n**BLOCK**fs== 10.9**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\n2. It holds for every codeword c\n**BLOCK**fs== 10.9**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nWe specify that i\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nIi for notational convenience due to the following well known form of linear\ncLRCs. However, we emphasize that an LRC with locality r can recover any given codeword symbol\nfrom r\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\n1 other symbols.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nFn\nLemma 18 (Well known). If C\nsome parity check of Hamming weight\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.8**l== 0.4**r== 0.3**\nq is a linear code such that every i\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\n[n] lies in the support of\n**BLOCK**fs== 10.9**p== 15.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nr, then C is locally recoverable with locality r.\n**BLOCK**fs== 10.9**p== 15.0**b== 0.1**t== 0.8**l== 0.2**r== 0.6**\n[n], and let c′ ∈\n**BLOCK**fs== 10.9**p== 15.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\nC satisﬁes ci =\n**BLOCK**fs== 10.9**p== 15.0**b== 0.1**t== 0.8**l== 0.4**r== 0.4**\nC ⊥ be a parity check of weight\n**BLOCK**fs== 10.9**p== 15.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIi := supp(c′). Then by\n∈\n(c′j/c′i)cj, which gives the desired recovery function\n**BLOCK**fs== 10.9**p== 15.0**b== 0.1**t== 0.8**l== 0.6**r== 0.3**\nr with i\n**BLOCK**fs== 10.9**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nBelow we describe a particularly useful type of classical linear code given by evaluations of poly-\nnomials. Here we let Fq[X1, . . . , Xm] denote the ring of m-variate polynomials over Fq.\n**BLOCK**fs== 10.9**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nDeﬁnition 19. For a subset S\n**BLOCK**fs== 10.9**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n-dimensional subspace of Fq[X] consisting of polynomials with zero coeﬃcients for\ndenote the\nS\n|\n|\nall monomials X i with i /\n∈\n**BLOCK**fs== 10.9**p== 16.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\nS. Deﬁne the polynomial evaluation map\n**BLOCK**fs== 10.9**p== 16.0**b== 0.6**t== 0.3**l== 0.4**r== 0.5**\nev : Fq[X]S\n**BLOCK**fs== 10.9**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nq , so that ev(f ) outputs the list of evaluations of f at all points in F∗q. The\nby ev(f ) = (f (x))x\nF∗\nimage ev(Fq[X]S ) of ev is a linear code, called a polynomial evaluation code, with alphabet\nsize q, block length q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\n1, and dimension\n**BLOCK**fs== 10.9**p== 16.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nBelow, we present the well-known Reed-Solomon codes, along with their folded counterpart.\n**BLOCK**fs== 10.9**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nDeﬁnition 20. For a prime power q and an integer ℓ\nthe polynomial evaluation code C = ev(Fq[X][ℓ]).\nGiven an additional folding parameter s\n**BLOCK**fs== 10.9**p== 16.0**b== 0.4**t== 0.5**l== 0.2**r== 0.6**\n1 for F∗q, and then for every i\n**BLOCK**fs== 10.9**p== 16.0**b== 0.4**t== 0.5**l== 0.1**r== 0.4**\nthe Fq-linear code of alphabet size qs and block length (q\nωq\nof Fq) at positions\nωsi\nq\n{\n−\nq) of the folded code ˜C.\nFs\n**BLOCK**fs== 10.9**p== 16.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\n[q], the Reed-Solomon (RS) code is\n**BLOCK**fs== 10.9**p== 16.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n1), the folded Reed-Solomon (fRS) code ˜C is\n1)/s obtained as follows. Fix a generator\n1)/s], block together the s components (each an element\nin C into a single component (which is an element of\n**BLOCK**fs== 10.9**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nBy deﬁnition Reed-Solomon codes have block length q\n(q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nℓ.\n1, dimension ℓ, and distance d = q\nℓ because ever polynomial of degree < ℓ has\nℓ by the Singleton bound. Folded Reed-Solomon codes similarly have block\n**BLOCK**fs== 10.9**p== 16.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nSpeciﬁcally, it holds that d\n< ℓ roots, and d\nlength (q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.3**t== 0.6**l== 0.2**r== 0.5**\n1)/s, dimension ℓ/s, and distance (q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nOur decoding algorithm for the quantum LRCs we construct will rely on the eﬃcient list-\ndecodability of the (folded) Reed-Solomon codes, as stated in the known results below. However,\nwe ﬁrst must deﬁne list decoding.\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\nDeﬁnition 21. Let C be a code of block length n over alphabet A, and let δ\ndecoding algorithm for C is an algorithm that takes as input a corrupted codeword b\noutputs the list of every codeword c\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.8**l== 0.4**r== 0.4**\nC such that dis(b, c)\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.7**l== 0.8**r== 0.1**\n0. An e-list-\nAn, and\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nIn the statements below, recall that the RS code has block length q\n1).\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nwhile the fRS code has block length (q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\n1)/s and rate R = ℓ/(q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\n1 and rate R = ℓ/(q\n**BLOCK**fs== 10.9**p== 16.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nTheorem 22 ([GS98]). The RS code with parameters q, ℓ has an e-list-decoding algorithm that\nruns in time qO(1) for\n**BLOCK**fs== 10.9**p== 17.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nTheorem 23 ([GR08]). The fRS code with parameters q, ℓ, s has an e-list decoding algorithm that\nruns in time qO(√s), where\n**BLOCK**fs== 10.9**p== 17.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nassuming that s\n**BLOCK**fs== 10.9**p== 17.0**b== 0.8**t== 0.2**l== 0.4**r== 0.2**\nq0 = q0(s) for suﬃciently large constants s0, q0(s).\n**BLOCK**fs== 10.9**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nNote that the running times of the above algorithms implicitly give bounds on the lengths of\n**BLOCK**fs== 10.9**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nthe lists they output.\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n2.4 Quantum Codes\n**BLOCK**fs== 10.9**p== 17.0**b== 0.6**t== 0.3**l== 0.1**r== 0.3**\nIn this section, we describe relevant background on quantum codes.\n**BLOCK**fs== 10.9**p== 17.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nDeﬁnition 24. A quantum code of block length n, dimension k, and local dimension (that\nis, alphabet size) a is a ak-dimensional linear subspace\n**BLOCK**fs== 10.9**p== 17.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nThe deﬁnition above of a quantum code as a linear subspace of Hilbert space assumes a unitary\nencoding map, as we may express\nfor a unitary encoding map\ni ∈\nEnc : (Ca)⊗\nn. In this paper we restrict attention to codes with such unitary encodings\nunless explicitly stated otherwise. However, there are more general coding schemes with arbitrary\nchannel encodings; we leave it as an open question whether such non-unitary encodings could be\nbeneﬁcial for local recovery.\n**BLOCK**fs== 10.9**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nBelow we deﬁne the distance of a quantum code as one plus the maximum number of erasures\n**BLOCK**fs== 10.9**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nthat the code can correct.\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.5**l== 0.1**r== 0.3**\nDeﬁnition 25. Let\ncan decode from erasures in S if there exists a decoding channel DecS :\nthat satisﬁes\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.5**l== 0.3**r== 0.3**\nbe a quantum code of block length n. Given a subset S\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.5**l== 0.8**r== 0.1**\n[n], we say that\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nDecS(ψ[n]\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nfor every ψ\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nThe distance of\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\nis then deﬁned as the maximum value d\n**BLOCK**fs== 10.9**p== 17.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nerasures in every S\n**BLOCK**fs== 10.9**p== 17.0**b== 0.3**t== 0.6**l== 0.3**r== 0.6**\nC\n[n] of size\n⊆\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nN such that\n**BLOCK**fs== 10.9**p== 17.0**b== 0.4**t== 0.6**l== 0.8**r== 0.1**\ncan decode from\n**BLOCK**fs== 10.9**p== 17.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nThe well-known fact below (see e.g. Fact 2 of [AN22] for a proof) shows that for a quantum\ncode of distance d, any d\n1 codeword symbols contain no information about the encoded message.\nNote that there is no classical analogue to this fact, as classically every linear code has a systematic\nencoding, meaning that the ﬁrst k codword symbols equal the message.\n**BLOCK**fs== 10.9**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nLemma 26 (Local indistinguishability). If\nfrom erasures in some set S\n**BLOCK**fs== 10.9**p== 17.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nis a quantum code of block length n that can decode\n**BLOCK**fs== 10.9**p== 17.0**b== 0.2**t== 0.8**l== 0.4**r== 0.1**\n[n], then the reduced density matrix ψS is the same for all ψ\n**BLOCK**fs== 10.9**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nThe following well known quantum analogue of Proposition 16 presents a tradeoﬀ between\ndistance and dimension for quantum codes. See for instance Section 12.4.3 of [NC10] for a proof.\n**BLOCK**fs== 10.9**p== 17.0**b== 0.1**t== 0.8**l== 0.1**r== 0.6**\nProposition 27 (Singleton bound). If\nand distance d, then\n**BLOCK**fs== 10.9**p== 17.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nis a quanum code of block length n, dimension k > 0,\n**BLOCK**fs== 10.9**p== 18.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nWe next deﬁne stabilizer codes, a well-known class of quantum codes that are deﬁned as the\nsimultaneous +1 eigenspace of a set of Pauli operators, called stabilizers. We will ﬁrst need to\ndeﬁne the Pauli operators.\n**BLOCK**fs== 10.9**p== 18.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nDeﬁnition 28. Let Fq be a ﬁnite ﬁeld of characteristic p. For α\n∼= Cq\noperators X α, Z α\n×\n**BLOCK**fs== 10.9**p== 18.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nq so that for x\n**BLOCK**fs== 10.9**p== 18.0**b== 0.8**t== 0.2**l== 0.7**r== 0.1**\nFq, deﬁne the q-ary Pauli\n**BLOCK**fs== 8.0**p== 18.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\n=\ni\n= e(2πi/p) trFq /Fp (αx)\n**BLOCK**fs== 10.9**p== 18.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nObserve that Paulis always commute up to a phase, and speciﬁcally e(2πi/p) trFq /Fp (αβ)X αZ β =\nZ βX α.\n**BLOCK**fs== 10.9**p== 18.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nN, an n-qudit Pauli is an operator of the form X αZ β =\n∈\nn\nq denote the group of n-qudit Paulis modulo the global phase, so that\nP\nn\nq is deﬁned as the set i\n**BLOCK**fs== 10.9**p== 18.0**b== 0.6**t== 0.3**l== 0.7**r== 0.1**\nn\ni=1 X αiZ αi for α, β\nq ∼= F2n\nP\n**BLOCK**fs== 10.9**p== 18.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\nFn\nq .\n∈\nq . The\n[n] of qudits on which P\n. The Hamming weight of\n= (0, 0)\n}\n**BLOCK**fs== 10.9**p== 18.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nFor n\nWe take\nsupport supp(P ) of an n-qudit Pauli P\nacts nontrivially. That is, supp(X αZ β) =\n.\nsupp(P )\nP is\n|\nq is isomorphic to F2n\nn\nP\n**BLOCK**fs== 10.9**p== 18.0**b== 0.5**t== 0.4**l== 0.3**r== 0.3**\nq , it is a vector space where the action of γ\n**BLOCK**fs== 10.9**p== 18.0**b== 0.4**t== 0.4**l== 0.1**r== 0.1**\nFq on X αZ β\nn\nq gives\n∈ P\nn\nX γαZ γβ. We therefore let a subspace, or (by slight abuse of terminology) subgroup, of\nq be any\nP\nq ∼= F2n\nsubset that is a Fq-subspace under the isomorphism\nn\nq . Therefore in particular we require a\nP\nq to be closed under the action of Fq. Furthermore, although we deﬁned\nn\nn\nq to be\n“subgroup” of\nP\nn\nthe group of Paulis modulo a global phase, we abuse notation and call a subgroup of\nq abelian if\nall the operators in the subgroup commute with each other, taking into account the global phase.\ns\nWe also denote (\nq ;\nthis group will naturally arise when we consider folded stabilizer codes in Section 5.3.\n**BLOCK**fs== 10.9**p== 18.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nsn\nq , which we interpret as the group of length-n strings of elements in\n**BLOCK**fs== 10.9**p== 18.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nDeﬁnition 29. For a vector space Fs\nthe alphabet Fs\n+1 eigenspace of some abelian subgroup of (\ngroup of the code, and its elements are the code’s stabilizers.\n**BLOCK**fs== 10.9**p== 18.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\nq is a subgroup of the Hilbert space (CFs\n**BLOCK**fs== 10.9**p== 18.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\nq over a ﬁnite ﬁeld, a stabilizer code of block length n over\nn that is speciﬁed as the simultaneous\ns\nq )n. This abelian subgroup is called the stabilizer\n**BLOCK**fs== 10.9**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nWe will mostly be concerned with a speciﬁc type of stabilizer code called a CSS code, which is\n**BLOCK**fs== 10.9**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nspeciﬁed by two classical codes satisfying an orthogonality condition.\n**BLOCK**fs== 10.9**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nDeﬁnition 30. Given classical codes CX , CZ ⊆\ncode\n**BLOCK**fs== 10.9**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n= CSS(CX , CZ ) is given by\nis the stabilizer code with stabilizer group\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.7**l== 0.4**r== 0.3**\nq)n such that C ⊥X ⊆\nCZ } ⊆\n: x\n= span\nC⊥\ny\n∈\ni\nX |\n{\n∈\nX αZ β : α\n.\nC ⊥Z }\nC ⊥X, β\nP\n{\n**BLOCK**fs== 10.9**p== 18.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nCZ , the associated CSS\nn. Equivalently,\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nIt is well known that to decode a CSS code\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\ndecoders for CX and CZ, as stated below:\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n= CSS(CX, CZ ), it is suﬃcient to have classical\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nq of size a =\n**BLOCK**fs== 10.9**p== 18.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nProposition 31 (Well known). Let\n= CSS(CX , CZ ) be a CSS code of block length n over the\nalphabet A = Fs\n0 be an integer such that for each permutation (α, β) of\n(X, Z), there exists a (classical) decoding algorithm Decα that takes as input a (classical) corrupted\ncodeword c + b for some c\ne, and\noutputs some c′ ∈\n**BLOCK**fs== 10.9**p== 18.0**b== 0.1**t== 0.9**l== 0.4**r== 0.4**\nCα and some corruption b\n**BLOCK**fs== 10.9**p== 18.0**b== 0.1**t== 0.9**l== 0.6**r== 0.2**\nAn of Hamming weight\n**BLOCK**fs== 10.9**p== 18.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\nC\n. Let e\nA\n|\n|\n**BLOCK**fs== 10.9**p== 19.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nhas a decoding algorithm Dec that recovers from errors of weight e, so\n**BLOCK**fs== 10.9**p== 19.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nhas distance\n2e + 1. Furthermore, if each Decα has running time Tα(n, a), then Dec has running time\n**BLOCK**fs== 10.9**p== 19.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nd\nTX (n, a) + TZ (n, a) + O(n3 poly log a).\n**BLOCK**fs== 10.9**p== 19.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nacting on\n**BLOCK**fs== 10.9**p== 19.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\n(ψ) for a code state ψ\n**BLOCK**fs== 10.9**p== 19.0**b== 0.6**t== 0.2**l== 0.1**r== 0.1**\nProof sketch. The result is standard, so we just provide a brief outline. Let CX = ker HX and\nand an error channel\nCZ = ker HZ. Given a corrupted code state ρ =\nE\ne of the codeword qudits, the decoder Dec(ρ) ﬁrst performs syndrome measurements\nE\nfor HX, HZ to collapse ρ to EψE†, so that the error on ψ is collapsed to some Pauli E = X bX Z bZ\ne, where sX = HXbX and sZ = HZbZ are the outputs of the syndrome measurements.\nof weight\nThen for each permutation (α, β) of (X, Z), the decoder performs Gaussian elimination to ﬁnd some\nCα. The decoder\naα such that Hαaα = sα, so that aα = cα + bα for some (currently unknown) cα ∈\nC ⊥β . Letting b′α = aα −\nthen runs Decα(aα), which outputs cα + pα for some pα ∈\npα\n(cα + pα) = bα −\nand E′ = X b′\nZ , the decoder then applies E′† to output E′†EψE†E′ = ψ. This ﬁnal equality\nholds because by assumption X pX and Z pZ are stabilizers of\n**BLOCK**fs== 10.9**p== 19.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\n, so they preserve ψ.\n**BLOCK**fs== 10.9**p== 19.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nThe running time of Dec deﬁned above is TX(n, a) + TZ (n, a) + O(n3 poly log a) because outside\nof the calls to DecX and DecZ , all operations run in time O(n2 poly log a), except the Gaussian\nelimination which runs in time O(n3 poly log a).\n**BLOCK**fs== 10.9**p== 19.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nDeﬁnition 32. A quantum locally recoverable code (qLRC) of locality r, block length n,\nn together with a set of\nand local dimension (i.e. alphabet size) a is a quantum code\nlocal recovery channels Reci for every i\n**BLOCK**fs== 10.9**p== 19.0**b== 0.5**t== 0.5**l== 0.5**r== 0.2**\nC ⊆\n[n] satisfying the following properties:\n**BLOCK**fs== 10.9**p== 19.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\n1. There exists a set Ii ⊆\n)\ni\n(Ii \\ {\n→ M\n}\n2. It holds for every code state ψ\n**BLOCK**fs== 10.9**p== 19.0**b== 0.4**t== 0.5**l== 0.4**r== 0.1**\n∈\nIi| ≤\nIi such that Reci is a quantum channel\n[n] of size\n|\n∈\ni\n(Ii) with input qudits Ii \\ {\n}\nthat\n**BLOCK**fs== 10.9**p== 19.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nand output qudits Ii.\n**BLOCK**fs== 10.9**p== 19.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nr with i\n**BLOCK**fs== 10.9**p== 19.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nThat is, a qLRC permits local recovery against erasure of a single qudit, or equivalently, against\n**BLOCK**fs== 10.9**p== 19.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\na corruption in a single known location.\n**BLOCK**fs== 10.9**p== 19.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nBelow, we present a quantum analogue of Lemma 18 for stabilizer codes.\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nProposition 33. Let\ni\n(αi, βi) = (1, 0) and (γi, δi) = (0, 1). Then\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\n[n], there exist stabilizers P = X αZ β, Q = X γZ δ\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.3**r== 0.3**\nbe a stabilizer code with stabilizer group S\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n|\nis locally recoverable with locality r.\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\n⊆ P\nsupp(P )\n**BLOCK**fs== 10.9**p== 19.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nn\nq . Assume that for every\nr such that\n**BLOCK**fs== 10.9**p== 19.0**b== 0.1**t== 0.7**l== 0.1**r== 0.1**\nProof sketch. The result is a standard application of the well-known fact that a stabilizer code\ndetects any Pauli error that anticommutes with one of the code’s stabilizers. We will therefore just\nprovide a brief proof sketch. For any given i\nS be the Paulis\ngiven by the proposition statement, and let Ii = supp(P )\nsupp(Q). We will construct a recovery\nchannel to revert the action of an arbitrary error channel (such as a totally depolarizing channel)\nacting on qudit i. The recovery channel ﬁrst performs syndrome measurements for P and Q,\nspeciﬁcally by performing measurements on the corrupted code state for the operators P η and Qη\nFq. These measurements will collapse the error on qudit i to a simultaneous eigenspace\nfor all η\nFq, and the measurement outcomes (i.e. the syndrome) give\nof these operators P η and Qη for η\nthe eigenvalues of the projected state for each of these operators. That is, the error on qudit i is\n**BLOCK**fs== 10.9**p== 19.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\n[n], let P = X αZ β, Q = X γZ δ",
         ". . . . . . . . . . . . . . . . . . . . . . . 11 1.3 Open Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.1.1 Deﬁnition of Quantum Local Recoverability . . . . . . . . . . . . . . . . . . . 1.1.2 Explicit Construction of qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . . Singleton-Like Bound for qLRCs, with Implications for qLDCP Codes . . . . 1.1.3 1.1.4 Comparison to Basic Constructions . . . . . . . . . . . . . . . . . . . . . . . . 1.1.5 Eﬃcient Decoding Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . Impossibility of Quantum Locally Correctable Codes . . . . . . . . . . . . . . 1.1.6 1.2 Overview of (Folded) Quantum Tamo-Barg codes . . . . . . . . . . . . . . . . . . . . 1.2.1 Background and Classical Tamo-Barg Codes . . . . . . . . . . . . . . . . . . 1.2.2 Quantum Tamo-Barg codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2.3 Folded Quantum Tamo-Barg Codes 2.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2 Classical Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.3 Polynomial Evaluation Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.4 Quantum Codes 3 Singleton-Like Bounds for qLRCs 4.1 Random qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4.2 Explicit qLRCs from AEL Distance Ampliﬁcation . . . . . . . . . . . . . . . . . . . . 25 4.2.1 Review of AEL Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 4.2.2 Application to qLRCs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 5 Explicit Construction of qLRCs: Quantum Tamo-Barg Codes 5.1 Classical Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5.2 Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5.3 Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 6 Bounding the Distance . . . . . . . . . . . . . . . . . . . 34 6.1 Distance of Unfolded Quantum Tamo-Barg Codes 6.2 Distance of Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . 35 . . . . . . . . . . . . . . . . . . . . . . . . . . 41 7.1 Unfolded Quantum Tamo-Barg Codes 7.2 Folded Quantum Tamo-Barg Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 8 Impossibility of Quantum Locally Correctable Codes Classical locally recoverable codes (LRCs) provide one of the most important coding theoretic tools for distributed data storage. Such codes are deﬁned to permit highly eﬃcient recovery from common localized errors, as well as larger-scale recovery from rarer but more “catastrophic” global errors. In this paper, we initiate the study of quantum locally recoverable codes (qLRCs). In particular, we deﬁne qLRCs, present and analyze constructions, and also prove fundamental limitations on the achievable parameters and properties. While our constructions can be viewed as quantum generalizations of classical constructions, the analysis becomes surprisingly intricate, and requires new ideas that were not needed classically. Our results may also shed light on the study of locality in quantum coding theory, for instance as it pertains to quantum LDPC codes. Classically, the properties of a LRC are well suited for the needs of large datacenters, which can cost billions of dollars to build and maintain, and must often account for localized server failures while also handling occasional more global failures. Indeed, companies such as Microsoft [HSX+12] and Facebook [MLR+14] have implemented LRCs to obtain improved performance for data storage. Currently, experimental quantum computers remain at a vastly smaller scale than that of the classical datacenters in which LRCs are often used in practice. However, it is not implausible that quantum computing technology eventually follows its classical counterpart by growing to the scale where codes such as qLRCs become an integral part of quantum data storage. Furthermore, our study of qLRCs reveals the potential for more broad and near-term impli- cations as well. Indeed, locality properties in quantum codes, such as the ability to decode using local measurements (i.e. LDPC codes), are of particular importance for quantum error correction. Yet such locality is notoriously diﬃcult to achieve in the quantum setting. Indeed, the ﬁrst linear- distance quantum LDPC (qLDPC) codes were only recently constructed [PK22, LZ22, DHLV23], and good quantum codes with stronger properties such as local testability have yet to be con- structed. This diﬃculty of achieving locality is in contrast to the classical setting, where good LDPC codes have been known for decades (e.g. [SS96]), good locally testable codes were recently constructed [PK22, DEL+22], and other strong locality properties such as local correctability exist in linear-distance, albeit low-rate codes. From this perspective, our study of qLRCs provides a new angle to investigate locality properties in quantum codes. Indeed, classical local recoverability requires each code component to participate in one low-weight parity check, while quantum local recoverability requires each code component to participate in two low-weight stabilizers. Thus local recoverability can be viewed as a weaking of the LDPC property, in which each code component participates in many low-weight parity checks/stabilizers. Our study of qLRCs can therefore be viewed as progress towards understanding stronger locality properties possessed by qLDPC codes. One concrete example of this connection is provided in Section 3, where we show that qLRCs, and therefore also qLDPC codes, of constant locality r = O(1) must have relative distance bounded away from 1/2; to the best of our knowledge such a bound for qLDPC codes had not been previously shown. In this section we present the contributions of our paper. For details on notation or basic deﬁnitions, the reader is referred to Section 2. 1.1.1 Deﬁnition of Quantum Local Recoverability To begin, we deﬁne qLRCs. Recall that a classical LRC (cLRC) is a classical code C such that for C and every component i, the value of ci can be recovered by looking at the restriction every c of c to just r 1 other components. Deﬁnition 1 (Informal statement of Deﬁnition 32). A quantum locally recoverable code (qLRC) of locality r is a quantum code C is erased (i.e. it experiences a completely depolarizing channel), the original code state recovered by applying a recovery channel that accesses only r ψ such that if any single qudit of a code state i ∈ C | can be ψ i 1 other code state qudits. For intuition, recall that a classical linear code is a cLRC of locality r if each component takes part in a parity-check of weight = CSS(CX , CZ ) is a qLRC if both CX, CZ are cLRCs, so that every qudit takes part in a low weight X-parity-check and a low-weight Z-parity-check (see Corollary 34). r. Similarly, we show that a quantum CSS code We remark that classically, there is also a notion of message locally recoverable codes (mLRCs), which require that every message (instead of codeword) symbol can be recovered from r 1 code- word symbols. As any linear classical code has a systematic encoding, meaning that the ﬁrst k codeword symbols equal the message, classical mLRCs are strictly weaker than LRCs. However, the local indistinguishability property of quantum codes (see Lemma 26) implies that local queries to quantum codes cannot reveal anything about the message. Thus mLRCs do not exist quantumly, at least in the regime where the locality is less than the distance. 1.1.2 Explicit Construction of qLRCs One of our principal technical contributions is the following explicit construction of qLRCs. Theorem 2 (Folded quantum Tamo-Barg codes; informal statement of Corollary 64 combined with Lemma 56). For every prime number r and every 0 < R < 1, there exists an inﬁnite explicit family of qLRCs of locality r, rate R, relative distance and alphabet size nO(r2), where n denotes the block length. In Theorem 2 (and in future informal result statements in Section 1), for readability we state slightly looser bounds than the formal result statements. For instance, our actual distance bound in Corollary 64 is stronger than than stated in Theorem 2 for high rates, and in particular shows that δ Ω(1/r) for all R We remark that while the alphabet size nO(r2) may seem large, in the LRC literature one typically thinks of each code component as being a fairly large entity, so such a polynomial alphabet size is not unreasonable. Classically each code component could for instance be a hard drive, while quantumly each component would likely be itself a fault-tolerant quantum memeory. We prove Theorem 2 by introducing a quantum CSS version of the classical LRCs of Tamo and Barg [TB14], which achieve the optimal classical rate-distance-locality tradeoﬀ [GHSY12]. The classical Tamo-Barg (TB) codes are constructed as subcodes of Reed-Solomon codes by carefully inserting low-weight parity checks. Multiple complications arise when converting TB codes into CSS codes. Speciﬁcally, to ensure the CSS orthogonality relations are satisﬁed, we deﬁne a quantum Tamo-Barg (qTB) code to be a CSS code = CSS(C, C) consisting of two copies of a classical code C that contains a TB code as a subcode, but also contains some added low-weight codewords. These added low-weight codewords also lie in C ⊥, so they do not necessarily degrade the distance of , which equals the minimum C ⊥. However, these added low-weight codewords make the distance weight of an element of C analysis signiﬁcantly more challenging, and we are only able to show a “Johnson-like” bound on the distance of qTB codes: Theorem 3 (Quantum Tamo-Barg codes; informal statement of Theorem 62). For every prime number r and every 0 < R < 1, there exists an inﬁnite explicit family of qLRCs of locality r, rate R, relative distance and alphabet size n + 1, where n denotes the block length. To obtain the improved bound δ O(1/√r) in Theorem 2, we “fold” together code components, thereby reblocking the symbols into larger components. We then use a combination of algebraic techniques to bound the distance of these folded qTB (fqTB) codes; the two main tools are a root detection method involving a determinant polynomial, and an uncertainty principle over ﬁnite ﬁelds. In Section 1.2 below, we describe the formal construction of our (f)qTB codes, and outline the proofs of Theorem 3 and Theorem 2. A more detailed description of these codes is provided in Section 5, and the distance bounds are formally proven in Section 6. 1.1.3 Singleton-Like Bound for qLRCs, with Implications for qLDCP Codes Our fqTB codes in Theorem 2 achieve an optimal rate-distance tradeoﬀ as the locality r grows large. In particular, we prove the following fundamental limitation on any qLRC. Theorem 4 (Singleton-like bound; informal statement of Theorem 35). If r and rate R, then has relative distance is a qLRC of locality The reader is referred to Theorem 35 for the speciﬁc value of the constant hidden in the the Ω(1/r) term above. For comparison, recall that the ordinary quantum Singleton bound states that every quantum R)/2+O(1/n), where n denotes the block length. Thus code of rate R has relative distance δ for a ﬁxed rate, Theorem 4 shows that imposing local recoverability with locality r decreases the optimal relative distance of a quantum code by at least Ω(1/r). Meanwhile, our explicit construction in Theorem 64 has relative distance O(1/√r) below that of the Singleton bound. R + O(1/n), while for cLRCs of locality r this bound becomes δ Theorem 4 implies a fundamental diﬀerence between the classical and quantum cases for LRCs of low rate. Classically, the ordinary Singleton bound says that a code of rate R has relative distance δ 1) + O(1/n). The TB codes achieve this latter bound, proving its tightness. Therefore in particular, for ﬁxed 0, we see that there exist classical LRCs of relative distance locality r, by letting the rate R In contrast, whereas there exist quantum codes of relative distance approaching 1/2, δ Theorem 4 shows every qLRC has relative distance at most 1/2 Ω(1/r), which is bounded away from 1/2 for ﬁxed r. As we mentioned previously, because every (q)LRC is a by deﬁnition a (q)LDPC code, it follows that qLDPC codes of locality r have relative distance Ω(1/r) for arbitrarily large alphabets. To the best of our knowledge, such a bound has not been previously shown in the literature. This result is in again in contrast to the classical case, where for instance the q-ary Hadamard code is an LDPC code of locality 3 with relative distance approaching 1 as q grows large. The discussion above raises the interesting question as to how tight Theorem 4 is for qLDPC codes. That is, what is the additional cost to the optimal rate-distance tradeoﬀ of requiring a quantum code be LDPC, compared to just being an LRC? 1.1.4 Comparison to Basic Constructions While our explicit fqTB codes in Theorem 2 are O(1/√r) below the Singleton-like bound in The- orem 4, we show that a randomized construction improves this gap to O(1/r), at the cost of explicitness and eﬃciency. Proposition 5 (Random qLRCs; informal statement of Proposition 40). For every r 3 and δ > 0, there exists a randomized construction that with high probability gives a qLRC of locality r, rate R, relative distance and alphabet size 2O(r). The constant hidden in the O(1/r) term in Proposition 5 is larger than the constant in the Ω(1/r) term in Theorem 4, so our bound on the randomized construction is still O(1/r) below that of our Singleton-like bound. Thus the randomized construction in Proposition 40 achieves relative distance O(1/r) below our Singleton-like bound with has alphabet size 2O(r). These parameters improve upon our fqTB construction, which has relative distance O(1/√r) below the Singleton-like bound, and has alphabet size nO(r2). However, the main disadvantage of the randomized construction is its non-explicitness. As a result, we have no eﬃcient algorithm to certify that a randomly sampled qLRC has good distance, and we have no eﬃcient decoding algorithm for errors in unknown locations. In contrast, our fqTB codes are explicit, so their distance bound is guaranteed. Furthermore, we show that they have an eﬃcient decoding algorithm (see Section 1.1.5 below). One way of derandomizing the random qLRCs in Proposition 5 is to use them as in inner code in the concatenation and distance ampliﬁcation scheme of Alon, Edmunds, and Luby (AEL) [AEL95]. This technique has been used extensively in classical coding theory [GI01, GI02, GI03, GR08, HW18, KMRZS16, GKO+18, HRZW20], but has only recently been considered in the quantum setting [BGG22, WLH23]. We show that applying AEL using a random qLRC as an “inner code,” which is small enough to be found eﬃciently via brute force, yields the following result. Proposition 6 (qLRCs from AEL; informal statement of Proposition 49). For every ﬁxed 0 < N that there exists an inﬁnite family of eﬃciently R < 1, it holds for all suﬃciently large r constructable qLRCs of locality r, rate R, relative distance and alphabet size q = 2O(r), where the OR above hides a constant depending on R. As described in Remark 50, the codes in Proposition 6 are technically only eﬃciently con- structable by a randomized algorithm with high probability, but can be made truly explicit by using a slightly more complicated construction, with slightly worse parameters. Also, like our fqTB codes, we show that these codes from AEL have eﬃcient decoders from errors in unknown locations. The alphabet size q = 2O(r) in Proposition 6 is smaller than the q = nO(r2) of our fqTB codes in Theorem 2. However, qLRCs from AEL have worse rate-distance-locality tradeoﬀ, as their relative distance is OR(1/r1/4) below the Singleton-like bound, compared to only O(1/√r) for our fqTB codes. Our (f)qTB codes may have additional practical advantages over the qLRCs from AEL. For instance, our (f)qTB codes can achieve locality as small as r = 3, whereas the the minimum pos- sible locality in the qLRCs from AEL is r = 9. Furthermore, as one step in the AEL construction redistributes code symbols according to the edges of an expander graph, the resulting size-r sets of code components used for local recovery form an r-uniform hypergraph with a complex expanding structure. In contrast, the recovery sets of our (f)qTB codes form a partition of the code com- ponents, which is ideally suited for a physical implementation with good spatial locality. That is, our (f)qTB codes can easily be implemented in 1, 2, or 3-dimensional space such that each local recovery operation only involves code components that are close together; such a spatially local implementation would be much less feasible for a qLRC from AEL. This section presents our results on the decodability of our qLRCs. As we discussed previously, in the classical setting, LRCs are typically used for data storage where errors correspond to events such as server failures that are detectable. Such errors occur in known locations, so they can be treated as erasures. Because every linear code can be eﬃciently decoded from a number of erasures up to the distance using Gaussian elimination, the eﬃciency of decoding is often not a primary concern for cLRCs. Note that all of our qLRC constructions are stabilizer (and in fact CSS) codes, which can similarly be decoded eﬃciently from erasures. However, in the quantum setting there are additional potential applications of eﬃcient decoding from errors in unknown locations. Due to the inherently noisy nature of quantum states, even if a qLRC is used to store a large quantum state where each code component is itself stored in a fault-tolerant memory, these individual fault-tolerant memories may eventually accumulate errors. As such, it may be beneﬁcial to occasionally perform a global decoding procedure to reduce the overall error rate in the long term. Furthermore, as we have previously discussed, qLRCs can be viewed as a stepping stone towards better understanding stronger locality properties, such as the LDPC property, which are important for near-term quantum error correction. As eﬃcient decoding is critical for these error correction applications, it is desirable that the qLRCs we study are also eﬃciently decodable. Below we present a polynomial-time decoding algorithm for the fqTB codes in Theorem 2. Theorem 7 (Decoding fqTB codes; informal statement of Corollary 72). The fqTB codes in The- orem 2 of block length n, prime locality parameter r, and rate R can be decoded from errors acting on an unknown fraction of the code components in time nOr(1), provided the alphabet size is increased to some suﬃciently large q = nOr(1) with respect to r. Here Or(1) denotes a suﬃciently large constant depending only on r. Theorem 7 provides a decoding algorithm for the fqTB codes with decoding radius up to half our distance bound in Theorem 2, which is therefore optimal barring an improvement in the distance bound. While the algorithm runs in polynomial time nOr(1) for ﬁxed locality parameter r, this algorithm is ineﬃcient for growing r. We address this issue by providing the following decoding algorithm for unfolded qTB codes, which therefore also applies to folded qTB codes, and whose running time is a polynomial independent of r. Theorem 8 (Decoding (f)qTB codes; informal statement of Theorem 69). An (unfolded or folded) qTB code of block length n, prime locality parameter r, and rate R can be decoded from errors acting on an unknown − r fraction of the code components in time nO(1). The decoder in Theorem 8 simply performs r 1 calls to a classical Reed-Solomon (list) decoder, − and then performs some postprocessing on the resulting outputs (see Algorithm 1). Therefore this algorithm should be eﬃcient in practice, as Reed-Solomon decoders have been optimized for practical use. The decoding radius in Theorem 8 is half our distance bound in Theorem 3. Therefore this decoding radius is optimal among decoders for qTB codes, barring an improvement to our distance bound in Theorem 3. As the unfolded qTB codes achieve distance and decoding radius within roughly a factor of 2 of the optimal values as dictated by our Singleton-like bound in Theorem 4. = CSS(C, C) denote the qTB code. The decoding task for We prove both Theorem 8 and Theorem 7 using similar techniques as in the proof of Theorem 3. Speciﬁcally, let can be reduced to the following problem: given a corrupted codeword a of C, we want an eﬃcient algorithm the recovers some c C that is close to a in Hamming weight. For this purpose, we show how every C can be modiﬁed to obtain some c′ that is a codeword of a Reed-Solomon code. Applying c the same modiﬁcation to a, we obtain a corrupted Reed-Solomon codeword a′. We then apply a Reed-Solomon (list) decoder to recover c′, which we can then map back to the desired codeword c. To decode fqTB codes in Theorem 7, we use the same algorithm, except now we apply a folded Reed-Solomon list decoder [GR08] to recover c′ from a′. As folded Reed-Solomon codes have a larger list-decoding radius than ordinary Reed-Solomon codes, and our fqTB distance bound in Theorem 2 is better than our qTB distance bound in Theorem 3, we obtain a larger decoding radius in Theorem 7 than in Theorem 8. Impossibility of Quantum Locally Correctable Codes Our results on qLRCs described above indicate that while optimal local recoverability is more nuanced and diﬃcult to achieve quantumly than classically, there do exist constructions of qLRCs approaching the optimal parameters. It is therefore natural to consider quantum analogues of stronger forms of locality that exist classically. Local correctability and local decodability provide particularly notable examples of such prop- erties. Recall that an LRC of block length n and locality r has the property that any single code [n] is erased, the value of a codeword at that component can be recovered from component i 1 unerased components. A locally correctable code (LCC) has the stronger property that ≤ after a linear number Ω(n) of code components are erased, the value of a codeword at each erased component i can be recovered from 1 unerased components. − Equivalently, an LRC requires the value of a codeword at each component i erable from some recovery set of component i that can be used to recover the codeword’s value at i. [n] to have Ω(n) disjoint recovery sets, each of which contains [n] to be recov- 1 other components. In contrast, an LCC requires each 1 components Local decodable codes (LDCs) are deﬁned similarly, except they only need to support local The Hadamard and Reed-Muller codes provide examples of classical LCCs and LDCs. therefore natural to ask whether there are quantum versions of these types of codes. As local access to a quantum code of large distance cannot reveal any information about the message, local decodability seems to make little sense quantumly, at least in the regime of large distance and small locality. However, quantum local correctability may seem to be a reasonable strengthening of quantum local recoverability. We show below that quantum local correctability is impossible in a strong sense: if a quantum code has even two disjoint recovery sets for a single qudit, then that qudit is unentangled with the remainder of the code state, and contains no information about the message state. Recall that LCCs are typically required to have linearly many such disjoint recovery sets for each code component. Thus qLRCs, which have a single recovery set for each qudit, are in some sense the limit of what is possible for quantum local correctability. Theorem 9 (Impossibility of quantum LCCs; informal statement of Theorem 74). Let While we prove Theorem 9 for general quantum codes [n] quantum code of block length n such that for some qudit i ∈ satisfying I 1 such that the following holds for each b = 1, 2: if qudit i of a code state is erased (i.e. it experiences a completely depolarizing channel), the original code state ψ ψ can be recovered by applying a recovery channel that only accesses qudits in I b i . Then there exists a . 1-qudit state α such that every ψ can be decomposed as ψ = αi ⊗ (Cd)⊗ n, it is illustrative to consider i = CSS(CX, CZ ), a set Ii ∋ CSS or stabilizer codes. Recall from Section 1.1.1 that for a CSS code can be used to recover qudit i if both CX and CZ have parity checks whose support contains i and I 2 lies inside Ii. Thus if I 1 , then there i i = i ∩ } { I 2 i . But supp(c′Z ) are parity checks c′X ∈ ∈ = 0, which contradicts the orthogonality c′Z = (c′X )i(c′Z )i 6 then supp(c′X ) ∩ to be a well deﬁned CSS code. Thus Theorem 9 holds for CSS condition C ⊥X ⊆ codes. A similar proof holds for stabilizer codes; In Theorem 74 we prove the more general result for arbitrary quantum codes. i , I 2 C ⊥X and c′Z ∈ , so c′X · i supp(c′Z ) = } { CZ required for C i are both recovery sets for component i with I 1 I 1 i and i C ⊥Z such that i supp(c′X ) 1.2 Overview of (Folded) Quantum Tamo-Barg codes In this section, we provide more details on our (folded) quantum Tamo-Barg codes described in Section 1.1.2, and we overview the techniques we use to prove the distance bounds in Theorem 2 and Theorem 3. The construction and analysis of these codes comprise one of the main technical contributions of our paper. 1.2.1 Background and Classical Tamo-Barg Codes Our qTB codes are CSS codes whose associated classical codes are polynomial evaluation codes that are closely related to the classical LRCs of Tamo and Barg [TB14]. To describe these codes, we use the following notation. For a subset S denote the space of polynomials for which only monomials X i for i S can have nonzero coeﬃcients. q ∼= Fq Then let ev : Fq[X]S denote the evaluation map on nonzero points in Fq, so that ev(f ) = (f (x))x S aiX i : a ∈ 0, let Fq[X]S = With this notation, a classical Tamo-Barg (TB) code [TB14] speciﬁed by a prime power q, a locality parameter r 1), and an integer ℓ [q] is given by ev(Fq[X]S ) for [TB14] showed that this code has alphabet size q, block length q ℓ, and is locally recoverable with locality r. 1, dimension ℓ , distance ⌋ 1.2.2 Quantum Tamo-Barg codes In this section, we deﬁne our quantum analogue of TB codes, and give an overview of the analysis. For more details, the reader is referred to Section 5.2 and Section 6.1. As described in Section 1.1.2, to deﬁne a qTB code, we must ﬁrst modify the classical TB code by adding some low-weight codewords in order to construct a well-deﬁned associated quantum CSS code. These added low-weight codewords can be interpreted as piecewise linear functions, as described below. Deﬁnition 10 (Quantum Tamo-Barg codes; restatement of Deﬁnition 53). For a prime power q, a [q], we deﬁne the quantum Tamo-Barg 1) with r locality parameter r (qTB) code to be the CSS code 3, and an integer ℓ ∈ = CSS(C, C) with C = ev(Fq[X]S ) for . 1 (mod r) } By some basic algebraic manipulations (see Lemma 55), we show that C ⊥ ⊆ C C, so the qTB has 1. A straightforward calculation (see Lemma 56) shows that = CSS(C, C) is indeed a well-deﬁned quantum CSS code. Note that by construction code alphabet size q and block length q has dimension for some ǫ The code C in the deﬁnition above is by deﬁnition the sum of a classical TB code ev(Fq[X][ℓ] (1+rZ)). We call this latter code P the space of piecewise linear ∩ with the code1 P := ev(Fq[X][q functions due to the following lemma. Lemma 11 (Restatement of Lemma 57). Let Ωr = Then P = ev(Fq[X][q form f (x) = βxΩr · x for some β F∗q : xr = 1 denote the rth roots of unity. } (1+rZ)) consists of all functions f : F∗q → Fq that can be expressed in the Lemma 11 follows directly from the fact that the evaluation of a polynomial h(X) on inputs in xr) on such inputs. The lemma implies that every xΩr equals the evaluation of h(X) (mod X r function in P equals a linear function on the restriction to inputs in each coset xΩr. We show in Lemma 55 that P C ⊥, from which we obtain the local recoverability of Corollary 12 (Restatement of Corollary 58). The qTB code is locally recoverable with locality r. = CSS(C, C) given in Deﬁnition 10 F∗q, there exists some f Proof. As described in Section 1.1.1 and formalized in Corollary 34, it suﬃces to show that for each C ⊥ α ⊆ ∈ ∈ as described above, the piecewise linear function f : F∗q → αΩr and f (x) = 0 for x / ∈ | ≤ Fq given by f (x) = x for x αΩr satisﬁes these criteria, as desired. r. But because P C ⊥ such that α supp(f ) and It only remains to bound the distance of the qTB code following result, which directly implies Theorem 3. . For this purpose, we show the Theorem 13 (Restatement of Theorem 62). The qTB code parameter r has distance at least in Deﬁnition 10 with a prime locality As was mentioned in Section 1.1.2, this bound is reminiscent of the Johnson bound (see e.g. The- orem 7.3.1 of [GRS22]), which in particular implies that a classical code of dimension ℓ and block 1 whose distance approaches the Singleton bound is list-decodable from at least a fraction length q of errors approaching 1 1) as the alphabet size and block length grow large. It is unclear if there is a deeper reason for this similarity between the Johnson bound and Theorem 62. However, it is interesting that we are able to improve the distance beyond this Johnson-like bound by folding our qTB codes, just as [GR08] introduced folded RS codes to improve beyond the Johnson bound for the list-decoding radius of RS codes. Proof sketch of Theorem 13. Recall that the distance of C ⊥. As P of any element of C weight at least the value d given in (2). For this purpose, consider any ev(f ) C ⊥, it therefore suﬃces show that every element of C = CSS(C, C) equals the minimum weight P has P . At a high level, the proof will proceed as follows. C ∈ F∗q, G also has We deﬁne a polynomial G such that whenever f has multiple roots in a coset xΩr ⊆ many roots in that coset. We can then bound the number of roots of f by bounding the number of roots of G, which we in turn bound by the degree of G. By constructing G to have low degree relative to the number of roots of f , we obtain the desired result. We now formally deﬁne G. By deﬁnition we may decompose f (X) = g(X) + h(X), where (1+rZ) 1+rZ) evaluates to a nonzero classical TB codeword, and h(X) g(X) evaluates to a piecewise linear function. Deﬁne the polynomial G(X) By deﬁnition, the degree of G satisﬁes Meanwhile, we bound the number of roots of G as follows. For every x such that f (x) = 0 and f (ωi unity ωi rx) = 0, then F∗q and every rth root of r g(ωi i ω− r h(ωi i ω− where the second equality above holds because h is piecewise linear. Thus G has a root for every ordered pair (x, ωi r. Summing over all such pairs of roots of f (see Section 6.1 for details), we ﬁnd that the total number of roots of G is at least rx) of roots of f whose ratio is an rth root of unity ωi This expression must be bounded above by the RHS of (4); rearranging terms in the resulting inequality yields the desired bound d for d given in (2). As described in Section 1.1.2 and Section 1.2.2, we were only able to prove a “Johnson-like” bound on the distance of qTB codes, which does not approach our Singleton-like bounds for qLRCs described in Section 1.1.3. We address this issue by introducing a “folded” version of qTB codes, for which we show the distance does approach the Singleton bound for large localities r. The proof of this distance bound for folded qTB codes (Theorem 2) is quite involved, so in this section we simply provide a brief description of the main ideas involved. The reader is referred to Section 6.2 for the full proof. We deﬁne folded qTB codes by grouping together symbols of qTB codes as described below. Deﬁnition 14 (Restatement of Deﬁnition 59). As in Deﬁnition 10, let = CSS(C, C) be the qTB C 1)/r, we deﬁne the folded (q code with parameters q, r, ℓ. Given an additional folding parameter s − | quantum Tamo-Barg (fqTB) code ˜ to be the quantum code of alphabet size qs and block C 1 for F∗q, and then for every i length (q 1)/s],  1, ωsi+1 we block together the s components (each of alphabet size q) at positions q − into a single component (of alphabet size qs) of the folded code ˜ . in C 1)/s obtained as follows. Fix a generator ωq A folded qTB code by construction inherits the rate and local recoverability of the underlying unfolded qTB code. Thus to prove Theorem 2, we simply need to bound the distance of the fqTB code. For this purpose, deﬁne S as in (1), so that the underlying unfolded qTB code = CSS(C, C) has C = ev(Fq[X]S ). The distance of ˜ by deﬁnition equals the minimum over all codewords C (see Deﬁnition 14) in ev(f ) which f takes at least one nonzero value. C ⊥ of the number of distinct blocks At a high level, we bound this minimum distance by considering two types of message poly- Fq[X]S separately. For the ﬁrst type of message polynomial, we nomials f (X) = use a similar argument as described in the proof sketch of Theorem 13 in Section 1.2.2. We are able to leverage the folding to replace the polynomial G(X) in (3) with another polynomial, which consists of the composition of f with a determinant polynomial. This alternative choice of G(X) detects roots of f more eﬃciently relative to its degree, and hence yields a better distance bound (see Claim 68). However, this method breaks down when the coeﬃcients fi of f are supported in a small number of distinct values i (mod r), that is, when there are r distinct values i (mod r) = 0. The reason for the breakdown on these “bad” polynomials f stems from among all i with fi 6 the fact that we need G(X) to be a nonzero polynomial, which becomes more diﬃcult when f has fewer nonzero coeﬃcients. Fortunately, we can consider such “bad” message polynomials f separately, and instead apply an uncertainty principle (Proposition 66) to bound the weight of the associated codeword (Claim 67). Intuitively, this uncertainty principle implies that if the coeﬃcients fi are zero for most values of i (mod r), then most of the evaluation points in ev(f ) must be nonzero, so ev(f ) has large weight. Combining our bounds from the two types of message polynomials described above, we obtain a bound on the distance of the fqTB code , which yields Theorem 2. Our work leads the the following open questions: • Can explicit qLRCs be constructed with a better rate-distance-locality tradeoﬀ than given by Theorem 2? Two approaches here are to improve our distance bound for fqTB codes in Theorem 2, or to introduce new constructions of qLRCs for which stronger bounds can be shown. In general, the goal is to close the gap to the Singleton-like bounds in Section 3. • How does the optimal rate-distance-locality tradeoﬀ of qLRCs diﬀer from that of qLDPC codes? As described in Section 1.1.3, our bounds on qLRCs imply bounds on qLDPC codes, but it is an interesting question whether the additional structure in qLDPC codes can be used to show stronger bounds. This question also points towards the more general line of inquiry into relationships between notions of locality in quantum codes, of which local recoverability and LDPC are two examples of interest. In this section, we introduce some notation, and then present preliminary deﬁnitions and results pertaining to classical codes, quantum codes, and local recoverability. y We denote by N, we let [n] = .  } For a prime power q, let Fq denote the ﬁnite ﬁeld of order q. For n y = Let F∗q = Fq \\ {  } [n] xiyi denote the standard dot product. ∈ denote the multiplicative group of Fq. For r F∗q denote a 1), we let ωr ∈ primitive rth root of unity, and we let Ωr = denote the group of all rth roots of unity. While the choice of ωr is not unique, we typically will think of ﬁxing some (q 1)st root of 1)/r unity ωq −  − F∗q, and then let ωr = ω(q N and for x, y For a ﬁnite alphabet A, we denote the Hamming distance between two strings x, y dis(x, y) = [n] : xi 6 i |{ denoted dis(X, Y ) = minx denote the Hamming weight of a string x dis(x, y) = . For two sets X, Y Y dis(x, y). If A is an abelian group (e.g. A = Fq, or A = Fs ∈ = dis(0, x) = An by An, the minimum Hamming distance is q) we , so that A quantum channel a of the qudits will be clear from context. Thus ρ operator ρ : (Ca)⊗ (Ca)⊗ denote the associated density matrix. For a density matrix ρ qudits, we denote the reduced density matrix ρB = TrA (A) the set of density matrices on a set A of qudits, where the local dimension (A) if ρ is a positive semi-deﬁnite Hermitian A, we let ψ = (A) ψ A is a subset of the A of trace 1. For a pure state ∈ M from qudits A to qudits B is a completely positive, trace preserving map (B) that can be (Ca)⊗ }ν, called (A) K M Kν : (Ca)⊗ { K expressed in the form (ρ) = Kraus operators, which satisfy (B). Equivalently, a quantum channel is a map ν Kν ρK †ν for a set of operators ν K †ν Kν = I. We let the weight of a quantum channel qudits on which the channel acts nontrivially. Therefore if subset W Kν = K W (A) refer to the number of distinct → M has weight w, then there exists a K = w such that each Kraus operator Kν of K can be decomposed as : (Ca)⊗ Below we deﬁne the notion of a classical code. Deﬁnition 15. A classical code of block length n, dimension k, and alphabet size a is a subset C [a]n of size The distance d of C is deﬁned as the minimum Hamming distance d = minc C. between any two distinct codewords c, c′ ∈ Fn We say that C is linear if a = q is a prime power so that [a] ∼= Fq and C q is a linear subspace. ⊆ ∼= Fsn Similarly, C is Fq-linear if a = qs for some prime power q so that [a] ∼= Fs (Fs q and C q ⊆ is linear subspace over the ﬁeld Fq. The dual of a linear code is C ⊥ = Fn . C c = 0 q : c′ · c′ ∈ } ∈ { Nonzero elements of the dual code C ⊥ are sometimes referred to as parity checks of C. C dis(c, c′) ∈ All classical codes satisfy that following fundamental limitation on the tradeoﬀ between distance and dimension, whose proof is a simple application of the pigeonhole principle. Proposition 16 (Singleton bound). If C is a classical code of block length n, dimension k > 0, and distance d, then − Fn A classical (linear) code can be expressed as the image of a (linear) encoding map Enc : Fk q that maps messages to codewords encoding the messages. However, we will mostly consider the space of codewords without reference to the encoding map. Throughout this paper we restrict attention to linear or Fq-linear codes, as will be clear from context. In particular, Fq-linear codes will arise from linear codes over Fq by “folding”, that is, by grouping together symbols of the linear code into larger symbols. Deﬁnition 17. A classical locally recoverable code (cLRC) of locality r, block length n, [a]n together with a set of local recovery maps Reci and alphabet size a is a classical code C for every i [n] satisfying the following properties: 1. There exists a set Ii ⊆ [n] of size r with i Ii such that Reci is a function Reci : 2. It holds for every codeword c We specify that i Ii for notational convenience due to the following well known form of linear cLRCs. However, we emphasize that an LRC with locality r can recover any given codeword symbol from r 1 other symbols. Fn Lemma 18 (Well known). If C some parity check of Hamming weight q is a linear code such that every i [n] lies in the support of r, then C is locally recoverable with locality r. [n], and let c′ ∈ C satisﬁes ci = C ⊥ be a parity check of weight Ii := supp(c′). Then by ∈ (c′j/c′i)cj, which gives the desired recovery function r with i Below we describe a particularly useful type of classical linear code given by evaluations of poly- nomials. Here we let Fq[X1, . . . , Xm] denote the ring of m-variate polynomials over Fq. Deﬁnition 19. For a subset S -dimensional subspace of Fq[X] consisting of polynomials with zero coeﬃcients for denote the S | | all monomials X i with i / ∈ S. Deﬁne the polynomial evaluation map ev : Fq[X]S q , so that ev(f ) outputs the list of evaluations of f at all points in F∗q. The by ev(f ) = (f (x))x F∗ image ev(Fq[X]S ) of ev is a linear code, called a polynomial evaluation code, with alphabet size q, block length q 1, and dimension Below, we present the well-known Reed-Solomon codes, along with their folded counterpart. Deﬁnition 20. For a prime power q and an integer ℓ the polynomial evaluation code C = ev(Fq[X][ℓ]). Given an additional folding parameter s 1 for F∗q, and then for every i the Fq-linear code of alphabet size qs and block length (q ωq of Fq) at positions ωsi q { − q) of the folded code ˜C. Fs [q], the Reed-Solomon (RS) code is 1), the folded Reed-Solomon (fRS) code ˜C is 1)/s obtained as follows. Fix a generator 1)/s], block together the s components (each an element in C into a single component (which is an element of By deﬁnition Reed-Solomon codes have block length q (q ℓ. 1, dimension ℓ, and distance d = q ℓ because ever polynomial of degree < ℓ has ℓ by the Singleton bound. Folded Reed-Solomon codes similarly have block Speciﬁcally, it holds that d < ℓ roots, and d length (q 1)/s, dimension ℓ/s, and distance (q Our decoding algorithm for the quantum LRCs we construct will rely on the eﬃcient list- decodability of the (folded) Reed-Solomon codes, as stated in the known results below. However, we ﬁrst must deﬁne list decoding. Deﬁnition 21. Let C be a code of block length n over alphabet A, and let δ decoding algorithm for C is an algorithm that takes as input a corrupted codeword b outputs the list of every codeword c C such that dis(b, c) 0. An e-list- An, and In the statements below, recall that the RS code has block length q 1). while the fRS code has block length (q 1)/s and rate R = ℓ/(q 1 and rate R = ℓ/(q Theorem 22 ([GS98]). The RS code with parameters q, ℓ has an e-list-decoding algorithm that runs in time qO(1) for Theorem 23 ([GR08]). The fRS code with parameters q, ℓ, s has an e-list decoding algorithm that runs in time qO(√s), where assuming that s q0 = q0(s) for suﬃciently large constants s0, q0(s). Note that the running times of the above algorithms implicitly give bounds on the lengths of the lists they output. In this section, we describe relevant background on quantum codes. Deﬁnition 24. A quantum code of block length n, dimension k, and local dimension (that is, alphabet size) a is a ak-dimensional linear subspace The deﬁnition above of a quantum code as a linear subspace of Hilbert space assumes a unitary encoding map, as we may express for a unitary encoding map i ∈ Enc : (Ca)⊗ n. In this paper we restrict attention to codes with such unitary encodings unless explicitly stated otherwise. However, there are more general coding schemes with arbitrary channel encodings; we leave it as an open question whether such non-unitary encodings could be beneﬁcial for local recovery. Below we deﬁne the distance of a quantum code as one plus the maximum number of erasures that the code can correct. Deﬁnition 25. Let can decode from erasures in S if there exists a decoding channel DecS : that satisﬁes be a quantum code of block length n. Given a subset S [n], we say that for every ψ The distance of is then deﬁned as the maximum value d erasures in every S C [n] of size ⊆ N such that can decode from The well-known fact below (see e.g. Fact 2 of [AN22] for a proof) shows that for a quantum code of distance d, any d 1 codeword symbols contain no information about the encoded message. Note that there is no classical analogue to this fact, as classically every linear code has a systematic encoding, meaning that the ﬁrst k codword symbols equal the message. Lemma 26 (Local indistinguishability). If from erasures in some set S is a quantum code of block length n that can decode [n], then the reduced density matrix ψS is the same for all ψ The following well known quantum analogue of Proposition 16 presents a tradeoﬀ between distance and dimension for quantum codes. See for instance Section 12.4.3 of [NC10] for a proof. Proposition 27 (Singleton bound). If and distance d, then is a quanum code of block length n, dimension k > 0, We next deﬁne stabilizer codes, a well-known class of quantum codes that are deﬁned as the simultaneous +1 eigenspace of a set of Pauli operators, called stabilizers. We will ﬁrst need to deﬁne the Pauli operators. Deﬁnition 28. Let Fq be a ﬁnite ﬁeld of characteristic p. For α ∼= Cq operators X α, Z α × q so that for x Fq, deﬁne the q-ary Pauli Observe that Paulis always commute up to a phase, and speciﬁcally e(2πi/p) trFq /Fp (αβ)X αZ β = Z βX α. N, an n-qudit Pauli is an operator of the form X αZ β = ∈ n q denote the group of n-qudit Paulis modulo the global phase, so that P n q is deﬁned as the set i n i=1 X αiZ αi for α, β q ∼= F2n P Fn q . ∈ q . The [n] of qudits on which P . The Hamming weight of = (0, 0) } For n We take support supp(P ) of an n-qudit Pauli P acts nontrivially. That is, supp(X αZ β) = . supp(P ) P is | q is isomorphic to F2n n P q , it is a vector space where the action of γ Fq on X αZ β n q gives ∈ P n X γαZ γβ. We therefore let a subspace, or (by slight abuse of terminology) subgroup, of q be any P q ∼= F2n subset that is a Fq-subspace under the isomorphism n q . Therefore in particular we require a P q to be closed under the action of Fq. Furthermore, although we deﬁned n n q to be “subgroup” of P n the group of Paulis modulo a global phase, we abuse notation and call a subgroup of q abelian if all the operators in the subgroup commute with each other, taking into account the global phase. s We also denote ( q ; this group will naturally arise when we consider folded stabilizer codes in Section 5.3. sn q , which we interpret as the group of length-n strings of elements in Deﬁnition 29. For a vector space Fs the alphabet Fs +1 eigenspace of some abelian subgroup of ( group of the code, and its elements are the code’s stabilizers. q is a subgroup of the Hilbert space (CFs q over a ﬁnite ﬁeld, a stabilizer code of block length n over n that is speciﬁed as the simultaneous s q )n. This abelian subgroup is called the stabilizer We will mostly be concerned with a speciﬁc type of stabilizer code called a CSS code, which is speciﬁed by two classical codes satisfying an orthogonality condition. Deﬁnition 30. Given classical codes CX , CZ ⊆ code = CSS(CX , CZ ) is given by is the stabilizer code with stabilizer group q)n such that C ⊥X ⊆ CZ } ⊆ : x = span C⊥ y ∈ i X | { ∈ X αZ β : α . C ⊥Z } C ⊥X, β P { CZ , the associated CSS n. Equivalently, It is well known that to decode a CSS code decoders for CX and CZ, as stated below: = CSS(CX, CZ ), it is suﬃcient to have classical q of size a = Proposition 31 (Well known). Let = CSS(CX , CZ ) be a CSS code of block length n over the alphabet A = Fs 0 be an integer such that for each permutation (α, β) of (X, Z), there exists a (classical) decoding algorithm Decα that takes as input a (classical) corrupted codeword c + b for some c e, and outputs some c′ ∈ Cα and some corruption b An of Hamming weight has a decoding algorithm Dec that recovers from errors of weight e, so has distance 2e + 1. Furthermore, if each Decα has running time Tα(n, a), then Dec has running time d TX (n, a) + TZ (n, a) + O(n3 poly log a). acting on (ψ) for a code state ψ Proof sketch. The result is standard, so we just provide a brief outline. Let CX = ker HX and and an error channel CZ = ker HZ. Given a corrupted code state ρ = E e of the codeword qudits, the decoder Dec(ρ) ﬁrst performs syndrome measurements E for HX, HZ to collapse ρ to EψE†, so that the error on ψ is collapsed to some Pauli E = X bX Z bZ e, where sX = HXbX and sZ = HZbZ are the outputs of the syndrome measurements. of weight Then for each permutation (α, β) of (X, Z), the decoder performs Gaussian elimination to ﬁnd some Cα. The decoder aα such that Hαaα = sα, so that aα = cα + bα for some (currently unknown) cα ∈ C ⊥β . Letting b′α = aα − then runs Decα(aα), which outputs cα + pα for some pα ∈ pα (cα + pα) = bα − and E′ = X b′ Z , the decoder then applies E′† to output E′†EψE†E′ = ψ. This ﬁnal equality holds because by assumption X pX and Z pZ are stabilizers of , so they preserve ψ. The running time of Dec deﬁned above is TX(n, a) + TZ (n, a) + O(n3 poly log a) because outside of the calls to DecX and DecZ , all operations run in time O(n2 poly log a), except the Gaussian elimination which runs in time O(n3 poly log a). Deﬁnition 32. A quantum locally recoverable code (qLRC) of locality r, block length n, n together with a set of and local dimension (i.e. alphabet size) a is a quantum code local recovery channels Reci for every i C ⊆ [n] satisfying the following properties: 1. There exists a set Ii ⊆ ) i (Ii \\ { → M } 2. It holds for every code state ψ ∈ Ii| ≤ Ii such that Reci is a quantum channel [n] of size | ∈ i (Ii) with input qudits Ii \\ { } that and output qudits Ii. r with i That is, a qLRC permits local recovery against erasure of a single qudit, or equivalently, against a corruption in a single known location. Below, we present a quantum analogue of Lemma 18 for stabilizer codes. Proposition 33. Let i (αi, βi) = (1, 0) and (γi, δi) = (0, 1). Then [n], there exist stabilizers P = X αZ β, Q = X γZ δ be a stabilizer code with stabilizer group S | is locally recoverable with locality r. ⊆ P supp(P ) n q . Assume that for every r such that Proof sketch. The result is a standard application of the well-known fact that a stabilizer code detects any Pauli error that anticommutes with one of the code’s stabilizers. We will therefore just provide a brief proof sketch. For any given i S be the Paulis given by the proposition statement, and let Ii = supp(P ) supp(Q). We will construct a recovery channel to revert the action of an arbitrary error channel (such as a totally depolarizing channel) acting on qudit i. The recovery channel ﬁrst performs syndrome measurements for P and Q, speciﬁcally by performing measurements on the corrupted code state for the operators P η and Qη Fq. These measurements will collapse the error on qudit i to a simultaneous eigenspace for all η Fq, and the measurement outcomes (i.e. the syndrome) give of these operators P η and Qη for η the eigenvalues of the projected state for each of these operators. That is, the error on qudit i is [n], let P = X αZ β, Q = X γZ δ",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.08653v1.pdf",
         "extracted",
         "None",
         "",
         "Quantum Locally Recoverable Codes"
        ],
        [
         "2",
         "000a3e6667afb4ca8476ce15555b05244c3b458a",
         "Accurately extracting organs from medical images provides radiologist with more comprehensive evidences to clinical diagnose, which offers up a higher accuracy and efficiency. However, the key to achieving accurate segmentation lies in abundant clues for contour distinction, which has a high demand for the network architecture design and its practical training status. To this end, we design auxiliary and refined constraints to optimize the energy function by supplying additional guidance in training procedure, thus promoting model’s ability to capture information. Specifically, for the auxiliary constraint, a set of convolutional structures are involved into a conventional network to act as a discriminator, then adversarial network is established. Based on the obtained architecture, we further build adversarial mechanism by introducing a second discriminator into segmentor for refinement. The involvement of refined constraint contributes to ameliorate training situation, optimize model performance, and boost its ability of collecting information for segmentation. We evaluate the proposed framework on two public databases (NIH Pancreas-CT and MICCAI Sliver07). Experimental results show that the proposed network achieves comparable performance to current pancreas segmentation algorithms and outperforms most state-of-the-art liver segmentation methods. The obtained results on public datasets sufficiently demonstrate the effectiveness of the proposed model for organ segmentation.",
         "Fenghui Lian,Yingjie Sun,Meiyu Li",
         "\n**BLOCK**fs== 26.0**p== 0.0**b== 0.6**t== 0.2**l== 0.3**r== 0.1**\nExtracting organs of interest\nfrom medical images based on\nconvolutional neural network with\nauxiliary and refined constraints\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\nFenghui Lian1, Yingjie Sun1 & Meiyu Li2,3\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nAccurately extracting organs from medical images provides radiologist with more comprehensive\nevidences to clinical diagnose, which offers up a higher accuracy and efficiency. However, the key\nto achieving accurate segmentation lies in abundant clues for contour distinction, which has a high\ndemand for the network architecture design and its practical training status. To this end, we design\nauxiliary and refined constraints to optimize the energy function by supplying additional guidance\nin training procedure, thus promoting model’s ability to capture information. Specifically, for the\nauxiliary constraint, a set of convolutional structures are involved into a conventional network to\nact as a discriminator, then adversarial network is established. Based on the obtained architecture,\nwe further build adversarial mechanism by introducing a second discriminator into segmentor for\nrefinement. The involvement of refined constraint contributes to ameliorate training situation,\noptimize model performance, and boost its ability of collecting information for segmentation. We\nevaluate the proposed framework on two public databases (NIH Pancreas-CT and MICCAI Sliver07).\nExperimental results show that the proposed network achieves comparable performance to current\npancreas segmentation algorithms and outperforms most state-of-the-art liver segmentation\nmethods. The obtained results on public datasets sufficiently demonstrate the effectiveness of the\nproposed model for organ segmentation.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nKeywords  Organ segmentation, Convolutional neural network, Auxiliary constraint, Refined constraint\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.6**l== 0.3**r== 0.1**\nDistinguishing organs of interest from medical images is critical to synthesis disease diagnosis or state analysis\nin  the  field  of  medical  imaging  analysis.  However,  multiple  organs  (i.e.  target  area  and  non-target  area)  are\ncontained in a set of images, the boundaries between organ and background may exist indistinct phenomenon,\nand  the  tissues  in  morphology  and  outline  tend  to  be  variable.  All  these  factors  bring  challenge  to  accurate\norgan segmentation. In recent years, several medical imaging analysis methods based on neural networks are\nproposed for organ segmentation1–6. For example, Hu et al. firstly trained a three-dimensional convolutional\nneural network to predict the probability maps of target regions. Then, time-implicit multi-phase level-set is used\nto optimize current abdominal multi-organ segmentation model1. Chlebus et al. proposed an automatic liver\ntumor segmentation method based on a two-dimensional convolutional neural network, following an object-\nbased postprocessing to refine the segmentation results2. Liu et al. raised an automatic framework to achieve\norgan segmentation from CT scans, where simple linear iterative clustering and support vector machine are used\nto roughly classify pixels, and convolutional neural network is involved to achieve precise boundary3. Ren et al.\npresented an interleaved three-dimensional convolutional neural network to segment small tissues of head and\nneck from CT images. Multiscale patches are firstly collected for more image appearance information, then the\nindividual CNNs are interleaved to refine segmented tissues4. Huo et al. designed an automated liver attenuation\nestimation method, i.e., liver attenuation ROI-based measurement (ALARM). A previous deep convolutional\nneural network SS-Net is firstly used to segment liver. Based on liver segmentation results and morphological\noperations, several regions of interests are obtained to achieve attenuation estimation5.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nIn this paper, in order to preserve more details for segmentation, we design two sets of novel constraints\n(i.e. auxiliary constraintand refined constraint) on the basis of convolutional neural network to extract organs\n**BLOCK**fs== 8.5**p== 0.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\n1School of Aviation Operations and Services, Air Force Aviation University, Changchun 130000, China. 2Department\nof Rehabilitation Medicine, Tongren Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200336,\nChina.  3Yuanshen  Rehabilitation  Institute, Shanghai Jiao Tong University School  of  Medicine, Shanghai  200025,\nChina. email: limy022@sjtu.edu.cn\n**BLOCK**fs== 8.0**p== 0.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 0.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 1.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\nof  interest  from  medical  images.  To  obtain  auxiliary  constraint,  we  involve  convolutional  structure  into  the\nconventional segmentation model, and these two parts are trained in a manner of minmax two-player game,\nthen a novel adversarial mechanism is built. The conventional segmentation model acts as a generator while\nthe  convolutional  structure  acts  as  a  discriminator.  This  contributes  to  enhance  the  similarity  between  the\npredicted segmentation maps and their corresponding ground truths. Specifically, in each training iteration, the\noutput probability maps from generator (i.e. segmentation network) and the corresponding truths are sent into\ndiscriminator (i.e. convolutional structure). Then, the discriminator measures the nuance between the synthetic\nsample and the original image distributions, where auxiliary constraint is used as the performance measurement.\nIn  the  meantime,  the  generator  starts  training  according  to  the  obtained  feedback  from  discriminator,  with\nthe  purpose  of  synthesizing  so  authentic  samples  that  cannot  be  distinguished  from  original  images  by  the\ndiscriminator. This helps to improve the quality of the output segmentation maps.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nAs for the refined constraint, we further apply a set of convolutional structure into the segmentation model\nwith auxiliary constraint to build another group of adversarial mechanism, which contributes to preservation\nof detailed information for segmentation. Specifically, prior to training the adversarial network with auxiliary\nconstraint, we firstly locate the deconvolutional layer which produces the predicted maps in current network.\nThen,  we  further  involve  an  adversarial  mechanism  before  the  located  deconvolutional  layer.  That  is,  a  new\nconvolutional structure is introduced as a discriminator to establish the second adversarial mechanism. At this\nmoment, refined constraint is applied to measure the subtlety between the original and the synthetic distributions.\nThe procedure described above is equivalent to supply two constraints on conventional segmentation model,\ncontributing to preservation of details for segmentation. Figure 1 displays schematic illustration of the involved\nconstraints in our proposed network.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nMethods\nBasic segmentation architecture\nWe employ U-Net7 to initially construct basic segmentation architecture in this work, which is an upgraded\nversion of fully convolutional network (FCN). U-Net is primarily applied to medical image segmentation and\nmost segmentation models apply it as baseline frame8–11. Compared to FCN, the main improvements of U-Net\nare  the  combined  features  from  contracting  path  and  symmetric  expanding  path,  which  contributes  to  yield\nmore precise segmentation performance. The basic loss function is calculated as Eq. (1):\n**BLOCK**fs== 6.0**p== 1.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\nLBasic =\n**BLOCK**fs== 9.0**p== 1.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nYm  denotes  the  synthetic  samples  predicted  by  generator  while  Yg  denotes  the  corresponding  images  from\noriginal  dataset.  ω  is  the  total  number  of  volumes.  The  specific  diagram  of  basic  loss  is  displayed  in  Fig.  2.\nSpecifically, the predicted probability maps from the fifth deconvolutional layer in basic segmentation model and\ntheir corresponding ground truths are measured by dice function, and then the Lbasic is obtained.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFig. 1.  A schematic illustration of the proposed framework for extracting organs of interest from medical\nimages, which includes different energy functions: Basic loss (LBasic), Auxiliary constraint (LAuxiliary), and\nRefined constraint (LRefined). Model 1 and Model 2 represent basic segmentation architectures with five and\nfour deconvolutional layers, respectively. Structure 1 and Structure 2 represent the firstly and secondly involved\nconvolutional layers which are used as discriminators, respectively.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 1.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nFig. 2.  Illustration of model architectures: deconvolutional layers (a) and (b) in segmentation frameworks\nModel 1 and Model 2, adversarial networks (c) and (b) which are consisted of convolutional layers. Samples\nfrom top to bottom: predicted maps from Model 1, corresponding ground truths, predicted maps from Model\n2.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.3**t== 0.5**l== 0.3**r== 0.1**\nAuxiliary constraint for organ segmentation\nThe generative adversarial network proposed by Goodfellow et al.12 is capable of mastering the mapping rules\nbetween input and output samples, relying on its ability to capture spatial distributions knowledge of the training\nsamples. Generative adversarial network consists of two competing parts (i.e. generator and discriminator) and\nit obeys a minmax two-player game to train the network. When inputting noise z into generator, a set of fake\nsamples will be produced. And these samples and their corresponding ground truths are used as input images\nto  train  discriminator,  which  can  be  regarded  as  enlarging  the  training  datasets  for  the  discriminator.  Then\nback  propagation  algorithm  is  involved  to  further  update  the  parameters  of  generator.  The  above  procedure\nis  an  iterative  process.  In  this  process,  the  ultimate  goal  of  generator  is  to  produce  samples  which  are  so\nauthentic that the discriminator has difficulty distinguishing them from original images. The ultimate intention\nof discriminator is to accurately distinguish between synthetic samples and real images. The antagonistic and\ncompetitive relationship between generator and discriminator contributes to promote network performance of\neach other.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nIn  order  to  preserve  sufficient  clues  for  organ  segmentation,  we  introduce  an  auxiliary  constraint  into\nconventional U-Net7 to assist network training. Specifically, we involve three convolutional layers with kernels\n7 × 7, 5 × 5 and 4 × 4 into conventional segmentation network, and these two structures are trained in a manner\nof  minmax  two-player  game,  then  adversarial  mechanism  is  obtained.  The  constructed  adversarial  learning\nprovides  an  extra  constraint  for  basic  segmentation  model,  which  ensures  the  segmentor  training  under  the\nguidance of basic loss and the provided adversarial loss in each iteration process. This helps segmentor to obtain\na further training and reach a steady state more quickly, thus achieving better segmentation performance. In\nthis section, we defined the total energy function of segmentation model as auxiliary constraint. That is to say,\nthe auxiliary constraint here performs a regression task, which consists of two items and lower values represent\nbetter performance, as shown in Eq. (2):\n**BLOCK**fs== 6.0**p== 2.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\nLAuxiliary =\n**BLOCK**fs== 9.0**p== 2.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nPG(seg)log (1\n**BLOCK**fs== 9.0**p== 2.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nDθ D (Gθ G (Y m)))\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nG and D represent generator and discriminator, and θG and θD respectively represent the parameters of G and\nD. In concrete practice process, the parameters θG are fixed when training D, while the parameters θD are fixed\nwhen training G. PG(seg) denotes the spatial distributions of the produced samples. DθD(GθG(Ym)) expresses the\nprobability that the inputting images of D come from synthetic samples produced by G.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nAs  displayed  in  Fig.  2,  the  predicted  probability  maps  from  the  fifth  deconvolutional  layer  in  basic\nsegmentation  model  and  their  corresponding  ground  truths  are  sent  into  the  adversarial  network,  which\nare  served  as  inputting  images  for  discriminator.  Meanwhile,  the  discriminator  emits  an  extra  constraint  for\nsegmentation network and an adversarial regression function for itself. The basic loss from segmentation model\nand the extra constraint from discriminator form the novel auxiliary constraint, as displayed in Eq. (2). And the\nadversarial regression function for discriminator is displayed in Eq. (3):\n**BLOCK**fs== 8.0**p== 2.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 2.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nPG(seg)log (1\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nDθ D (Gθ G (Y m)))\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\n−\nPD(ground) denotes the spatial distributions of the original dataset. DθD(Yg) expresses the probability value that\nits inputting images are from original dataset.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nRefined constraint for organ segmentation\nA  second  set  of  convolutional  layers  are  involved  into  the  model  with  auxiliary  constraint,  to  further  refine\nnetwork  performance  for  more  precise  details.  Specifically,  based  on  the  model  with  auxiliary  constraint,\nanother discriminator is introduced to construct a new adversarial mechanism, which is set behind the fourth\ndeconvolutional  layer  in  segmentor.  In  current  segmentation  model,  the  energy  function  from  conventional\nnetwork rules supreme compared with the involved adversarial constraints. This scheme gives the flexibility to\nuse the specific competing relationship in GAN, which involves two constraints into segmentor to refine energy\nfunction, thus improve information preservation capacity to boost segmentation performance. The second set\nof convolutional layers in this part is identical to the discriminator in model with auxiliary constraint described\nin “Auxiliary constraint for organ segmentation”.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nAs shown in Fig.  2, on basis of the  model with auxiliary constraint, the predicted probability  maps from\nthe fourth deconvolutional layer in basic segmentation model and their ground truths are measured by dice\nfunction,  and  then  a  second  basic  loss  corresponding  to  current  segmentor  is  obtained.  Then,  the  predicted\nprobability maps from the fourth deconvolutional layer and their corresponding ground truths are used as the\ninputting images for an adversarial network. Thus, an extra constraint for current segmentation network and\na  new  adversarial  regression  function  for  this  adversarial  network  are  obtained.  The  refined  constraint  here\nperforms a regression task, and it consists of four items, as shown in Eq. (4):\n**BLOCK**fs== 6.0**p== 3.0**b== 0.5**t== 0.4**l== 0.4**r== 0.5**\nLRef ined = ω1 ·\n**BLOCK**fs== 6.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nPG1(seg) log (1\n**BLOCK**fs== 6.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\n\nPG2(seg) log (1\n\n**BLOCK**fs== 5.0**p== 3.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nDθD1 (GθG1 (Y m\n**BLOCK**fs== 5.0**p== 3.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nDθD2 (GθG2 (Y m\n**BLOCK**fs== 9.0**p== 3.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nAccording to the primary and secondary relations of various factors affecting segmentation performance, the\nitems of ω1, ω2, ω3, and ω4 in Eq. (4) are set to 1, 0.001, 0.1, and 0.0002, respectively.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.4**t== 0.6**l== 0.3**r== 0.2**\nThe regression functions for discriminators are respectively displayed in Eqs. (5) and (6):\n**BLOCK**fs== 6.0**p== 3.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nPD1(ground)log (Dθ D1 (Y g\nPD2(ground)log (Dθ D2 (Y g\n**BLOCK**fs== 6.0**p== 3.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nPG1(seg)log (1\n**BLOCK**fs== 6.0**p== 3.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nPG2(seg)log (1\n**BLOCK**fs== 5.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nDθ D1 (Gθ G1 (Y m\n**BLOCK**fs== 5.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nDθ D2 (Gθ G2 (Y m\n**BLOCK**fs== 9.0**p== 3.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nResults\nDataset and evaluation metrics\nWe involve two public datasets in this work to test model performance, including pancreas database collected\nby  National  Institutes  of  Health  Clinical  Center13,14  and  Sliver07  provided  by  MICCAI  liver  segmentation\ncompetition15. The pancreas dataset consists of 82 contrast-enhanced CT volumes, and the size of each slice is\n512 × 512. According to the training mode in16–20, we employ 4-fold cross validation to spit the dataset in this\nwork. The Sliver07 contains 20 contrast-enhanced volumes with standard truths, and the size of each slice is\n512 × 512.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nThere  are  two  groups  of  metrics  are  applied  for  segmentation  evaluation  in  this  work,  including  error\nmeasurement and similarity measurement. The error measurement consists of six indexes: Volumetric Overlap\nError (VOE), Relative Volume Difference (VD), Average Symmetric Surface Distance (ASD), Root Mean Square\nSymmetric Surface Distance (RMSD), Maximum Symmetric Surface Distance (MSD) and Root Mean Squared\nError (RMSE). The similarity measurement consists of four indexes: Dice similarity coefficient (DSC), Precision,\nRecall and Jaccard. All experiments are carried on PyTorch environment and run on an NVIDIA GeForce GTX\n1080Ti GPU of 11 GB memory.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nSegmentation results on NIH dataset\nFigure 3 shows error measurement distributions on NIH pancreas dataset from models with basic loss, auxiliary\nconstraint and refined constraint, including metrics VOE, VD, ASD, RMSD, MSD and RMSE. Whereas Fig. 4\nshows  similarity  measurement  distributions  of  DSC,  Precision,  Recall  and  Jaccard  from  these  three  models.\nFigures  3  and  4  intuitively  display  segmentation  result  distributions  from  different  models  on  NIH  pancreas\ndataset, and the specific values of these ten sets of metrics are correspondingly shown in Table 1. Furthermore,\nFig. 5 displays five groups of predicted maps from these three models to observe segmentation performance in\nan intuitive mode.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 3.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFig. 3.  Error measurement (VOE, VD, ASD, RMSD, MSD and RMSE) distributions on NIH pancreas dataset\nfrom different models with basic loss (first column), auxiliary constraint (second column), and refined\nconstraint (third column).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nSegmentation results on Sliver07 dataset\nFigure 6 presents boxplots of error measurement on Sliver07 dataset from segmentation models with basic loss,\nauxiliary  constraint  and  refined  constraint,  including  VOE,  VD,  ASD,  RMSD  and  RMSE.  And  the  similarity\nmeasurement distributions of DSC, Precision, Recall and Jaccard for these three models are displayed in Fig. 7.\nFigures 6 and 7 intuitively display boxplots from different models on Sliver07 dataset, and the specific values\n**BLOCK**fs== 8.0**p== 4.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 4.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFig. 4.  Similarity measurement (DSC, Precision, Recall and Jaccard) distributions on NIH pancreas dataset\nfrom different models with basic loss (first column), auxiliary constraint (second column), and refined\nconstraint (third column).\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nError measurement\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\nSimilarity Measurement\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.4**r== 0.3**\nASD (mm) RMSD (mm) MSD (mm) RMSE (mm) DSC (%)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nPrecision (%) Recall (%)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.9**r== 0.1**\nJaccard (%)\n**BLOCK**fs== 4.9**p== 5.0**b== 0.2**t== 0.7**l== 0.2**r== 0.7**\nLBasic\nLAuxiliary\nLRefined\n**BLOCK**fs== 9.0**p== 5.0**b== 0.2**t== 0.8**l== 0.3**r== 0.3**\nTable 1.  Evaluation indicators for pancreas segmentation on NIH Dataset.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nof  these  nine  sets  of  metrics  are  correspondingly  shown  in  Table  2.  In  order  to  intuitively  exhibit  the  liver\nsegmentation results, we display the output probability maps in Fig. 8.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.0**t== 0.9**l== 0.3**r== 0.1**\nDiscussion\nSegmentation results on NIH dataset\nFor error measurement, lower values equate to better segmentation performance in figures showing quantitative\ncomparisons. It is obvious from Fig. 3 that the obtained error measurement from model with refined constraint\nrepresent strongest convergence in each indicator, compared with models with basic loss and auxiliary constraint.\nThis indicates the involvement of refined constraint contributes to a more stable pancreas segmentation state. It\n**BLOCK**fs== 8.0**p== 5.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 5.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 6.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFig. 5.  Examples of pancreas segmentation results from models with different constraints. From left to right:\noriginal volumes from NIH dataset, the corresponding ground truths, predicted maps from model with basic\nloss, predicted maps from model with auxiliary constraint, and predicted maps from model with refined\nconstraint.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFig. 6.  Error measurement (VOE, VD, ASD, RMSD and RMSE) boxplots on Sliver07 dataset from model with\nbasic loss (a), model with auxiliary constraint (b), and model with refined constraint (c).\n**BLOCK**fs== 8.0**p== 6.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 6.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 7.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nFig. 7.  Similarity measurement (DSC, Precision, Recall and Jaccard) boxplots on Sliver07 dataset from (a)\nmodel with basic loss, (b) model with auxiliary constraint, and (c) model with refined constraint.\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nError Measurement\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nSimilarity Measurement\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\nRMSD\n(mm)\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nRMSE\n(mm)\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\nPrecision\n(%)\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\nRecall\n(%)\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.8**r== 0.2**\nJaccard\n(%)\n**BLOCK**fs== 4.9**p== 7.0**b== 0.5**t== 0.4**l== 0.3**r== 0.7**\nLBasic\nLAuxiliary\nLRefined\n**BLOCK**fs== 9.0**p== 7.0**b== 0.5**t== 0.5**l== 0.3**r== 0.3**\nTable 2.  Evaluation indicators for liver segmentation on sliver dataset.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nalso can be seen from Fig. 3 that the average level of each index corresponding to model with refined constraint\nshow optimal state. This illustrates the application of refined constraint improves the model performance, which\nalso effectively demonstrates its validity for pancreas segmentation.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nFor  similarity  measurement,  higher  values  equate  to  better  segmentation  performance.  As  displayed  in\nFig. 4, the obtained similarity measurement from model with refined constraint show strongest convergence\nthan another two models. This indicates the introduction of refined constraint improves the liver segmentation\nstability.  It  also  can  be  observed  from  Fig.  4  that  the  mean  values  of  each  measurement  corresponding  to\nmodel  with  refined  constraint  show  optimal  level. This  indicates  refined  constraint  effectively  improves  liver\nsegmentation performance, confirming the effectiveness of refined constraint for organ segmentation.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nAs  displayed  in  Table  1,  mean  and  standard  deviation  (std)  of  VOE  for  models  with  basic  loss,  auxiliary\nconstraint and refined constraint are 36.3 ± 9.5, 32.5 ± 8.6 and 29.0 ± 7.4, while mean and std of ASD for these\nthree models are 1.0 ± 0.8, 0.7 ± 0.5 and 0.5 ± 0.4. From these error measurement on pancreas dataset, we can\nconclude that the involvement of refined constraint achieves an optimized VOE of 7.3% and ASD of 0.5 mm,\nwhich  strongly  suggests  its  profit  for  boosting  segmentation  quality.  Furthermore,  the  depressed  std  values\nillustrates the model performance gradually stabilized. Besides, the obtained results of DSC and Precision are\n77.4 ± 7.6, 80.3 ± 6.4, 82.8 ± 5.3, 77.6 ± 9.7, 79.9 ± 9.6 and 83.1 ± 7.9, consecutively. This further demonstrates\nthe improved maps quality and stabilized model performance. It can be observed from Fig. 5 that the predicted\nprobability maps from basic model tend  to  represent  chunks of deviations,  and the involvement of auxiliary\nconstraint ameliorates the situation. After this, refined constraint further improves segmentation performance\neven in tiny positions which are difficult to segment.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nSegmentation results on Sliver07 dataset\nAs shown in Fig. 6, the mean level of each metric box uniformly progressively decreased from (a) model with\nbasic loss, (b) model with auxiliary constraint to (c) model with refined constraint. This declares the contribution\nof auxiliary constraint and refined constraint on promoting liver segmentation capability. Meanwhile, the mean\nlevel  of  each  box  in  Fig.  7  progressively  increased  from  (a)  basic  loss,  (b)  auxiliary  constraint  to  (c)  refined\nconstraint, which further verifies the effectiveness of the involved auxiliary and refined l constraints. Table 2\ndisplays mean and std of metrics for liver segmentation models with basic loss, auxiliary constraint and refined\nconstraint. Their corresponding VOE values are 19.6 ± 3.2, 12.3 ± 3.1 and 7.2 ± 2.2 while ASD values are 1.8 ±\n0.9, 0.7 ± 0.4 and 0.3 ± 0.2. Besides, the obtained liver segmentation results of DSC and Jaccard are 89.1 ± 2.0,\n93.4 ± 1.7, 96.3 ± 1.2, 80.4 ± 3.2, 87.7 ± 3.1 and 92.8 ± 2.2, consecutively. The predicted segmentation maps are\ndisplayed in Fig. 8, it is obvious that the output maps from model with auxiliary constraint can deal better with\nmain  frame  areas  than  basic  loss.  Furthermore,  the  employment  of  refined  constraint  helps  to  polish  minor\npositions which are challengeable to distinguish from background in other two models.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 7.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 8.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFig. 8.  Examples of liver segmentation results from models with different constraints. From left to right:\noriginal volumes from Sliver07 dataset, the corresponding ground truths, predicted maps from model with\nbasic loss, predicted maps from model with auxiliary constraint, and predicted maps from model with refined\nconstraint.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nComparison to state-of-the-art\nOur  proposed  model  is  compared  with  the-state-of-art  pancreas  segmentation  methods  to  test  its\nperformance6,17–24. As can be shown in Table 3, the model with refined constraint achieves improvements with\nDSC of 0.47% (82.8% vs. 82.33%), Precision of 0.98% (83.1% vs. 82.12%) and Jaccard of 4.45% (74.8% vs. 70.35%)\n**BLOCK**fs== 8.0**p== 8.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 8.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 7.0**p== 9.0**b== 0.7**t== 0.1**l== 0.3**r== 0.7**\nModels\nRoth et al.19\nZhou et al.18\nCai et al.22\nLi et al.21\nLiu et al.23\nCai et al.24\nYu et al.17\nMa et al.20\nFang et al.6\n**BLOCK**fs== 7.0**p== 9.0**b== 0.9**t== 0.1**l== 0.4**r== 0.5**\nPrecision (%) Recall (%)\n**BLOCK**fs== 7.0**p== 9.0**b== 0.9**t== 0.1**l== 0.6**r== 0.4**\nJaccard (%)\n**BLOCK**fs== 9.0**p== 9.0**b== 0.7**t== 0.3**l== 0.3**r== 0.2**\nTable 3.  Comparison with the state-of-the-arts models for pancreas segmentation.\n**BLOCK**fs== 7.0**p== 9.0**b== 0.5**t== 0.3**l== 0.3**r== 0.7**\nModels\nWang et al.28\nWu et al.26\nDou et al.25\nLiu et al.3\nLiao et al.29\nLi et al.30\nGauriau et al.27\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.3**r== 0.3**\nTable 4.  Comparison with the state-of-the-arts models for liver segmentation.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.5**l== 0.3**r== 0.1**\ncompared to Li et al.21. The mean DSC increases 1.53% (82.8% vs. 81.27%) and 0.4% (82.8% vs. 82.4%) compared\nto Roth et al.19 and Cai et al.22 and their Jaccard respectively increases 5.93% (74.8% vs. 68.87%) and 4.2% (74.8%\nvs. 70.6%). The DSC score of methods Liu et al.23 and Cai et al.24 are respectively 1.30% (82.8% vs. 84.10%) and\n0.90% (82.8% vs. 83.70%) higher than the proposed model with refined constraint. While its obtained Jaccard\noptimizes 1.94% and 2.50% compared to Liu et al.23 (74.8% vs. 72.86%) and Cai et al.24 (74.8% vs. 72.30%). It\ncan be observed that our proposed model exceeds most current technologies from different evaluation metrics.\nThe comparison in Table 4 shows our proposed model exceeds most liver segmentation methods3,25–30. The\nproposed model with refined constraint achieves the best liver segmentation performance with a mean DSC of\n96.3%. The obtained RMSD optimizes 0.2 mm and 0.3 mm respectively compared to Wu et al.26 (2.3 mm vs.\n2.5 mm) and Gauriau et al.27 (2.3 mm vs. 2.6 mm). The obtained ASD optimizes 0.93 mm, 0.99 mm and 1.00 mm\ncompared to Wang et al.28 (0.3 mm vs. 1.23 mm), Wu et al.26 (0.3 mm vs. 1.29 mm) and Gauriau et al.27 (0.3 mm\nvs. 1.3 mm). Meanwhile, the obtained VOE optimizes 0.37% and 0.67% compared to Wang et al.28 (7.2% vs.\n7.57%) and Wu et al.26 (7.2% vs. 7.87%). The DSC score of methods Liu et al.3 and Liao et al.29 are respectively\n1.13%  (96.3%  vs.  97.43%)  and  0.9%  (96.3%  vs.  97.2%)  higher  than  our  proposed  model.  While  its  obtained\nASD optimizes 1.18 mm and 0.8 mm compared to Liu et al.3 (0.3 mm vs. 1.48 mm) and Liao et al.29 (0.3 mm vs.\n1.1 mm).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nThough  the  proposed  model  achieves  desirable  results  on  both  pancreas  and  liver  datasets,  the  network\nimprovement of accuracy and application is still expected. Future research will fine-tune current architecture to\ncope better with pancreas and liver segmentation. Also, future work will apply the proposed model on multiple\ndatasets to explore the latent potential to solve different organ segmentation tasks. In addition, we intend to\nconduct  the  existing  model  on  medical  imaging  materials  collected  from  clinical  application,  to  explore  its\npotential ability of addressing the clinical scenario.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nConclusion\nThis paper designs a convolutional neural network with auxiliary and refined constraints to segment organs from\nmedical image. We introduce convolutional structure into basic segmentor, which is used as a discriminator, to\nconstruct adversarial mechanism for a higher segmentation quality. Auxiliary constraint at this moment is used\nto represent network regression condition. Furthermore, a new convolutional structure is involved into current\nframework to construct twofold adversarial mechanism. Aiming at collecting more sufficient information for\nsegmentation through imposing dual constraints on segmentor. Refined constraint at this moment is used to\nrepresent network regression condition. Experiments are conducted on two public datasets and the obtained\nresults  demonstrate  its  superior  performance  over  several  state-of-the-art  algorithms  on  pancreas  and  liver\nsegmentation tasks. This adequately indicates the proposed method is a powerful and promising tool for organ\nsegmentation.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 9.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nData availability\nThe Pancreas-CT and Sliver07 datasets are publicly available, and can be downloaded using the following links:\nPancreas-CT:  https:   //wi ki.cancerimagingarch ive .net/di spl ay/ Public/P ancreas-CTSliver07:   h t t p s : / / s l i v e r 0 7 . g r a n\nd - c h a l l e n g e . o r g /     .\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.4**\nReceived: 14 September 2024; Accepted: 8 January 2025\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nReferences\n1.  Hu, P. et al. Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets.\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.4**\nInt. J. Comput. Assist. Radiol. Surg. 12 (3), 399–411 (2017).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n2.  Chlebus,  G.  et  al.  Automatic  liver  tumor  segmentation  in  CT  with  fully  convolutional  neural  networks  and  object-based\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\npostprocessing. Sci. Rep. 8, 15497 (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n3.  Liu, X., Guo, S., Yang, B., Ma, S. & Yu, F. Automatic organ segmentation for CT scans based on Super-pixel and Convolutional\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.4**\nneural networks. J. Digit. Imaging. 31 (6), 748–760 (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n4.  Ren, X. et al. Interleaved 3D-CNNs for joint segmentation of small-volume structures in Head and Neck CT images. Med. Phys. 45\n**BLOCK**fs== 7.5**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n5.  Huo, Y. et al. Fully automatic liver attenuation estimation combing CNN segmentation and morphological operations. Med. Phys.\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\n6.  Fang,  C.,  Li,  G.,  Pan,  C.,  Li,  Y.  &  Yu,  Y.  Globally  guided  progressive  fusion  network  for  3D  pancreas  segmentation.  In  Paper\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.2**\npresented at: International Conference on Medical Image Computing and Computer-Assisted Intervention (2019).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\n7.  Ronneberger, O., Fischer, P., Brox, T. & U-Net convolutional networks for biomedical image segmentation. In Paper presented at:\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.2**\nInternational Conference on Medical Image Computing and Computer-Assisted Intervention (2015).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\n8.  Sundaresan, V., Zamboni, G., Rothwell, P. M., Jenkinson, M. & Griffanti, L. Triplanar ensemble U-Net model for white matter\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.3**\nhyperintensities segmentation on MR images. Med. Image. Anal. 73, 102184 (2021).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\n9.  Zeng, G., Xin, Y., Jing, L., Yu, L. & Zheng, G. 3D U-net with multi-level deep supervision: fully automatic segmentation of proximal\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.3**\nfemur in 3D MR images. In Paper presented at: Machine Learning in Medical Imaging (2017).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\n10.  Hao,  D.,  Yang,  G.,  Liu,  F.,  Mo,  Y.  &  Guo,  Y.  Automatic  brain  tumor  detection  and  segmentation  using  U-Net  based  fully\n**BLOCK**fs== 7.5**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.2**\nconvolutional networks. In Annual Conference on Medical Image Understanding and Analysis (2017).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\n11.  Balagopal, A., Kazemifar, S., Dan, N., Lin, M. H. & Jiang, S. B. Fully automated organ segmentation in male pelvic CT images. Phys.\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.5**\nMed. Biol. 63 (24), 245015 (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\n12.  Goodfellow, I. et al. Generative adversarial nets. In Paper presented at: Advances in Neural Information Processing Systems (2014).\n13.  Clark, K. et al. The Cancer Imaging Archive (TCIA): maintaining and operating a public information repository. J. Digit. Imaging.\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\n14.  Roth, H. R. et al. Data from Pancreas-CT. (2016). The cancer imaging archive.\n15.  Heimann, T., Ginneken, B. V., Styner, M. A., Arzhaeva, Y. & Wolf, I. Comparison and evaluation of methods for liver segmentation\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.4**\nfrom CT datasets. IEEE Trans. Med. Imaging. 28 (8), 1251–1265 (2009).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\n16.  Roth, H. R. et al. Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation. In Paper presented at:\n**BLOCK**fs== 7.5**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\nInternational Conference on Medical Image cComputing and Computer-Assisted Intervention (2015).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\n17.  Yu, Q. et al. Recurrent saliency transformation network: Incorporating multi-stage visual cues for small organ segmentation. In\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.2**\nPaper presented at: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\n18.  Zhou,  Y.  et  al.  A  fixed-point  model  for  pancreas  segmentation  in  abdominal  CT  scans.  In  Paper  presented  at:  International\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.3**\nConference on Medical Image Computing and Computer-Assisted Intervention (2017).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\n19.  Roth, H. R. et al. Spatial aggregation of holistically-nested convolutional neural networks for automated pancreas localization and\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\nsegmentation. Med. Image. Anal. 45, 94–107 (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\n20.  Ma,  J.,  Lin,  F.,  Wesarg,  S.  &  Erdt,  M.  A  novel  bayesian  model  incorporating  deep  neural  network  and  statistical  shape  model\nfor pancreas segmentation. In Paper presented at: International Conference on Medical Image Computing and Computer-Assisted\nIntervention (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\n21.  Li, M., Lian, F. & Guo, S. Pancreas segmentation based on an adversarial model under two-tier constraints. Phys. Med. Biol. 65 (22),\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\n22.  Cai, J., Lu, L., Xie, Y., Xing, F. & Yang, L. Improving Deep Pancreas Segmentation in CT and MRI Images Via Recurrent Neural\nContextual Learning and Direct Loss Function (Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\n23.  Liu, S. et al. Automatic pancreas segmentation via coarse location and ensemble learning. IEEE Access. 8, 2906–2914 (2020).\n24.  Cai,  J.,  Lu,  L.,  Xing,  F.  &  Yang,  L.  Pancreas  segmentation  in  CT  and  MRI  images  via  domain  specific  network  designing  and\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nrecurrent neural contextual learning. arXiv:180311303. (2018).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\n25.  Dou, Q. et al. 3D deeply supervised network for automatic liver segmentation from CT volumes. In International Conference on\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nMedical Image Computing and Computer-Assisted Intervention (2016).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\n26.  Wu, W., Zhou, Z., Wu, S. & Zhang, Y. Automatic liver segmentation on volumetric CT images using supervoxel-based graph cuts.\n**BLOCK**fs== 7.5**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.5**\nComput. Math. Methods Med. 2016, 9093721 (2016).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\n27.  Gauriau,  R.,  Cuingnet,  R.,  Prevost,  R.,  Mory,  B.  &  Bloch,  I.  A  generic,  robust  and  fully-automatic  workflow  for  3D  CT  liver\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nsegmentation. Comput. Clin. Appl. ABD-MICCAI. (2013).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\n28.  Wang, J., Cheng, Y., Guo, C., Wang, Y. & Tamura, S. Shape-intensity prior level set combining probabilistic atlas and probability\nmap constrains for automatic liver segmentation from abdominal CT images. Int. J. Comput. Assist. Radiol. Surg. 11 (5), 817–826\n(2016).\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\n29.  Liao, M. et al. Efficient liver segmentation in CT images based on graph cuts and bottleneck detection. Phys. Med. 32 (11), 1383–\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\n30.  Li, G. et al. Automatic Liver Segmentation based on shape constraints and deformable graph cut in CT images. IEEE Trans. Image\n**BLOCK**fs== 7.5**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\nProcess. 24 (12), 5315–5329 (2015).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nAuthor contributions\nL.F.H.:  Conceptualization,  methodology,  formal  analysis,  writing-original  draft.  S.Y.J.:  Software,  validation.\nL.M.Y.: Conceptualization, formal analysis, supervision, funding acquisition, project administration, writing-re-\nview and editing. All authors read and approved the final manuscript.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 10.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nEthics approval and consent to participate\nIn this paper, all methods were carried out in accordance with relevant guidelines and regulations. All cases\nwere used with the approval of the National Institutes of Health Clinical Center (NIH) and MICCAI liver\nsegmentation competition, and all participants provided informed consent.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.3**r== 0.5**\nCompeting interests\nThe authors declare no competing interests.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\nAdditional information\nCorrespondence and requests for materials should be addressed to M.L.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\nReprints and permissions information is available at www.nature.com/reprints.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nPublisher’s note  Springer Nature remains neutral with regard to jurisdictional claims in published maps and\ninstitutional affiliations.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nOpen Access   This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives\n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in\nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide\na link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have\npermission under this licence to share adapted material derived from this article or parts of it. The images or\nother third party material in this article are included in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence\nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o\nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n© The Author(s) 2025\n**BLOCK**fs== 8.0**p== 11.0**b== 0.0**t== 1.0**l== 0.1**r== 0.7**\nScientific Reports |         (2025) 15:2036\n**BLOCK**fs== 8.0**p== 11.0**b== 0.0**t== 1.0**l== 0.4**r== 0.4**\n| https://doi.org/10.1038/s41598-025-86087-8",
         "Extracting organs of interest from medical images based on convolutional neural network with auxiliary and refined constraints Fenghui Lian1, Yingjie Sun1 & Meiyu Li2,3 Accurately extracting organs from medical images provides radiologist with more comprehensive evidences to clinical diagnose, which offers up a higher accuracy and efficiency. However, the key to achieving accurate segmentation lies in abundant clues for contour distinction, which has a high demand for the network architecture design and its practical training status. To this end, we design auxiliary and refined constraints to optimize the energy function by supplying additional guidance in training procedure, thus promoting model’s ability to capture information. Specifically, for the auxiliary constraint, a set of convolutional structures are involved into a conventional network to act as a discriminator, then adversarial network is established. Based on the obtained architecture, we further build adversarial mechanism by introducing a second discriminator into segmentor for refinement. The involvement of refined constraint contributes to ameliorate training situation, optimize model performance, and boost its ability of collecting information for segmentation. We evaluate the proposed framework on two public databases (NIH Pancreas-CT and MICCAI Sliver07). Experimental results show that the proposed network achieves comparable performance to current pancreas segmentation algorithms and outperforms most state-of-the-art liver segmentation methods. The obtained results on public datasets sufficiently demonstrate the effectiveness of the proposed model for organ segmentation. Keywords  Organ segmentation, Convolutional neural network, Auxiliary constraint, Refined constraint Distinguishing organs of interest from medical images is critical to synthesis disease diagnosis or state analysis in  the  field  of  medical  imaging  analysis.  However,  multiple  organs  (i.e.  target  area  and  non-target  area)  are contained in a set of images, the boundaries between organ and background may exist indistinct phenomenon, and  the  tissues  in  morphology  and  outline  tend  to  be  variable.  All  these  factors  bring  challenge  to  accurate organ segmentation. In recent years, several medical imaging analysis methods based on neural networks are proposed for organ segmentation1–6. For example, Hu et al. firstly trained a three-dimensional convolutional neural network to predict the probability maps of target regions. Then, time-implicit multi-phase level-set is used to optimize current abdominal multi-organ segmentation model1. Chlebus et al. proposed an automatic liver tumor segmentation method based on a two-dimensional convolutional neural network, following an object- based postprocessing to refine the segmentation results2. Liu et al. raised an automatic framework to achieve organ segmentation from CT scans, where simple linear iterative clustering and support vector machine are used to roughly classify pixels, and convolutional neural network is involved to achieve precise boundary3. Ren et al. presented an interleaved three-dimensional convolutional neural network to segment small tissues of head and neck from CT images. Multiscale patches are firstly collected for more image appearance information, then the individual CNNs are interleaved to refine segmented tissues4. Huo et al. designed an automated liver attenuation estimation method, i.e., liver attenuation ROI-based measurement (ALARM). A previous deep convolutional neural network SS-Net is firstly used to segment liver. Based on liver segmentation results and morphological operations, several regions of interests are obtained to achieve attenuation estimation5. In this paper, in order to preserve more details for segmentation, we design two sets of novel constraints (i.e. auxiliary constraintand refined constraint) on the basis of convolutional neural network to extract organs of  interest  from  medical  images.  To  obtain  auxiliary  constraint,  we  involve  convolutional  structure  into  the conventional segmentation model, and these two parts are trained in a manner of minmax two-player game, then a novel adversarial mechanism is built. The conventional segmentation model acts as a generator while the  convolutional  structure  acts  as  a  discriminator.  This  contributes  to  enhance  the  similarity  between  the predicted segmentation maps and their corresponding ground truths. Specifically, in each training iteration, the output probability maps from generator (i.e. segmentation network) and the corresponding truths are sent into discriminator (i.e. convolutional structure). Then, the discriminator measures the nuance between the synthetic sample and the original image distributions, where auxiliary constraint is used as the performance measurement. In  the  meantime,  the  generator  starts  training  according  to  the  obtained  feedback  from  discriminator,  with the  purpose  of  synthesizing  so  authentic  samples  that  cannot  be  distinguished  from  original  images  by  the discriminator. This helps to improve the quality of the output segmentation maps. As for the refined constraint, we further apply a set of convolutional structure into the segmentation model with auxiliary constraint to build another group of adversarial mechanism, which contributes to preservation of detailed information for segmentation. Specifically, prior to training the adversarial network with auxiliary constraint, we firstly locate the deconvolutional layer which produces the predicted maps in current network. Then,  we  further  involve  an  adversarial  mechanism  before  the  located  deconvolutional  layer.  That  is,  a  new convolutional structure is introduced as a discriminator to establish the second adversarial mechanism. At this moment, refined constraint is applied to measure the subtlety between the original and the synthetic distributions. The procedure described above is equivalent to supply two constraints on conventional segmentation model, contributing to preservation of details for segmentation. Figure 1 displays schematic illustration of the involved constraints in our proposed network. Methods Basic segmentation architecture We employ U-Net7 to initially construct basic segmentation architecture in this work, which is an upgraded version of fully convolutional network (FCN). U-Net is primarily applied to medical image segmentation and most segmentation models apply it as baseline frame8–11. Compared to FCN, the main improvements of U-Net are  the  combined  features  from  contracting  path  and  symmetric  expanding  path,  which  contributes  to  yield more precise segmentation performance. The basic loss function is calculated as Eq. (1): Ym  denotes  the  synthetic  samples  predicted  by  generator  while  Yg  denotes  the  corresponding  images  from original  dataset.  ω  is  the  total  number  of  volumes.  The  specific  diagram  of  basic  loss  is  displayed  in  Fig.  2. Specifically, the predicted probability maps from the fifth deconvolutional layer in basic segmentation model and their corresponding ground truths are measured by dice function, and then the Lbasic is obtained. Fig. 1.  A schematic illustration of the proposed framework for extracting organs of interest from medical images, which includes different energy functions: Basic loss (LBasic), Auxiliary constraint (LAuxiliary), and Refined constraint (LRefined). Model 1 and Model 2 represent basic segmentation architectures with five and four deconvolutional layers, respectively. Structure 1 and Structure 2 represent the firstly and secondly involved convolutional layers which are used as discriminators, respectively. Fig. 2.  Illustration of model architectures: deconvolutional layers (a) and (b) in segmentation frameworks Model 1 and Model 2, adversarial networks (c) and (b) which are consisted of convolutional layers. Samples from top to bottom: predicted maps from Model 1, corresponding ground truths, predicted maps from Model 2. Auxiliary constraint for organ segmentation The generative adversarial network proposed by Goodfellow et al.12 is capable of mastering the mapping rules between input and output samples, relying on its ability to capture spatial distributions knowledge of the training samples. Generative adversarial network consists of two competing parts (i.e. generator and discriminator) and it obeys a minmax two-player game to train the network. When inputting noise z into generator, a set of fake samples will be produced. And these samples and their corresponding ground truths are used as input images to  train  discriminator,  which  can  be  regarded  as  enlarging  the  training  datasets  for  the  discriminator.  Then back  propagation  algorithm  is  involved  to  further  update  the  parameters  of  generator.  The  above  procedure is  an  iterative  process.  In  this  process,  the  ultimate  goal  of  generator  is  to  produce  samples  which  are  so authentic that the discriminator has difficulty distinguishing them from original images. The ultimate intention of discriminator is to accurately distinguish between synthetic samples and real images. The antagonistic and competitive relationship between generator and discriminator contributes to promote network performance of each other. In  order  to  preserve  sufficient  clues  for  organ  segmentation,  we  introduce  an  auxiliary  constraint  into conventional U-Net7 to assist network training. Specifically, we involve three convolutional layers with kernels 7 × 7, 5 × 5 and 4 × 4 into conventional segmentation network, and these two structures are trained in a manner of  minmax  two-player  game,  then  adversarial  mechanism  is  obtained.  The  constructed  adversarial  learning provides  an  extra  constraint  for  basic  segmentation  model,  which  ensures  the  segmentor  training  under  the guidance of basic loss and the provided adversarial loss in each iteration process. This helps segmentor to obtain a further training and reach a steady state more quickly, thus achieving better segmentation performance. In this section, we defined the total energy function of segmentation model as auxiliary constraint. That is to say, the auxiliary constraint here performs a regression task, which consists of two items and lower values represent better performance, as shown in Eq. (2): Dθ D (Gθ G (Y m))) G and D represent generator and discriminator, and θG and θD respectively represent the parameters of G and D. In concrete practice process, the parameters θG are fixed when training D, while the parameters θD are fixed when training G. PG(seg) denotes the spatial distributions of the produced samples. DθD(GθG(Ym)) expresses the probability that the inputting images of D come from synthetic samples produced by G. As  displayed  in  Fig.  2,  the  predicted  probability  maps  from  the  fifth  deconvolutional  layer  in  basic segmentation  model  and  their  corresponding  ground  truths  are  sent  into  the  adversarial  network,  which are  served  as  inputting  images  for  discriminator.  Meanwhile,  the  discriminator  emits  an  extra  constraint  for segmentation network and an adversarial regression function for itself. The basic loss from segmentation model and the extra constraint from discriminator form the novel auxiliary constraint, as displayed in Eq. (2). And the adversarial regression function for discriminator is displayed in Eq. (3): Dθ D (Gθ G (Y m))) − PD(ground) denotes the spatial distributions of the original dataset. DθD(Yg) expresses the probability value that its inputting images are from original dataset. Refined constraint for organ segmentation A  second  set  of  convolutional  layers  are  involved  into  the  model  with  auxiliary  constraint,  to  further  refine network  performance  for  more  precise  details.  Specifically,  based  on  the  model  with  auxiliary  constraint, another discriminator is introduced to construct a new adversarial mechanism, which is set behind the fourth deconvolutional  layer  in  segmentor.  In  current  segmentation  model,  the  energy  function  from  conventional network rules supreme compared with the involved adversarial constraints. This scheme gives the flexibility to use the specific competing relationship in GAN, which involves two constraints into segmentor to refine energy function, thus improve information preservation capacity to boost segmentation performance. The second set of convolutional layers in this part is identical to the discriminator in model with auxiliary constraint described in “Auxiliary constraint for organ segmentation”. As shown in Fig.  2, on basis of the  model with auxiliary constraint, the predicted probability  maps from the fourth deconvolutional layer in basic segmentation model and their ground truths are measured by dice function,  and  then  a  second  basic  loss  corresponding  to  current  segmentor  is  obtained.  Then,  the  predicted probability maps from the fourth deconvolutional layer and their corresponding ground truths are used as the inputting images for an adversarial network. Thus, an extra constraint for current segmentation network and a  new  adversarial  regression  function  for  this  adversarial  network  are  obtained.  The  refined  constraint  here performs a regression task, and it consists of four items, as shown in Eq. (4): According to the primary and secondary relations of various factors affecting segmentation performance, the items of ω1, ω2, ω3, and ω4 in Eq. (4) are set to 1, 0.001, 0.1, and 0.0002, respectively. The regression functions for discriminators are respectively displayed in Eqs. (5) and (6): Results Dataset and evaluation metrics We involve two public datasets in this work to test model performance, including pancreas database collected by  National  Institutes  of  Health  Clinical  Center13,14  and  Sliver07  provided  by  MICCAI  liver  segmentation competition15. The pancreas dataset consists of 82 contrast-enhanced CT volumes, and the size of each slice is 512 × 512. According to the training mode in16–20, we employ 4-fold cross validation to spit the dataset in this work. The Sliver07 contains 20 contrast-enhanced volumes with standard truths, and the size of each slice is 512 × 512. There  are  two  groups  of  metrics  are  applied  for  segmentation  evaluation  in  this  work,  including  error measurement and similarity measurement. The error measurement consists of six indexes: Volumetric Overlap Error (VOE), Relative Volume Difference (VD), Average Symmetric Surface Distance (ASD), Root Mean Square Symmetric Surface Distance (RMSD), Maximum Symmetric Surface Distance (MSD) and Root Mean Squared Error (RMSE). The similarity measurement consists of four indexes: Dice similarity coefficient (DSC), Precision, Recall and Jaccard. All experiments are carried on PyTorch environment and run on an NVIDIA GeForce GTX 1080Ti GPU of 11 GB memory. Segmentation results on NIH dataset Figure 3 shows error measurement distributions on NIH pancreas dataset from models with basic loss, auxiliary constraint and refined constraint, including metrics VOE, VD, ASD, RMSD, MSD and RMSE. Whereas Fig. 4 shows  similarity  measurement  distributions  of  DSC,  Precision,  Recall  and  Jaccard  from  these  three  models. Figures  3  and  4  intuitively  display  segmentation  result  distributions  from  different  models  on  NIH  pancreas dataset, and the specific values of these ten sets of metrics are correspondingly shown in Table 1. Furthermore, Fig. 5 displays five groups of predicted maps from these three models to observe segmentation performance in an intuitive mode. Fig. 3.  Error measurement (VOE, VD, ASD, RMSD, MSD and RMSE) distributions on NIH pancreas dataset from different models with basic loss (first column), auxiliary constraint (second column), and refined constraint (third column). Segmentation results on Sliver07 dataset Figure 6 presents boxplots of error measurement on Sliver07 dataset from segmentation models with basic loss, auxiliary  constraint  and  refined  constraint,  including  VOE,  VD,  ASD,  RMSD  and  RMSE.  And  the  similarity measurement distributions of DSC, Precision, Recall and Jaccard for these three models are displayed in Fig. 7. Figures 6 and 7 intuitively display boxplots from different models on Sliver07 dataset, and the specific values Fig. 4.  Similarity measurement (DSC, Precision, Recall and Jaccard) distributions on NIH pancreas dataset from different models with basic loss (first column), auxiliary constraint (second column), and refined constraint (third column). Table 1.  Evaluation indicators for pancreas segmentation on NIH Dataset. of  these  nine  sets  of  metrics  are  correspondingly  shown  in  Table  2.  In  order  to  intuitively  exhibit  the  liver segmentation results, we display the output probability maps in Fig. 8. Discussion Segmentation results on NIH dataset For error measurement, lower values equate to better segmentation performance in figures showing quantitative comparisons. It is obvious from Fig. 3 that the obtained error measurement from model with refined constraint represent strongest convergence in each indicator, compared with models with basic loss and auxiliary constraint. This indicates the involvement of refined constraint contributes to a more stable pancreas segmentation state. It Fig. 5.  Examples of pancreas segmentation results from models with different constraints. From left to right: original volumes from NIH dataset, the corresponding ground truths, predicted maps from model with basic loss, predicted maps from model with auxiliary constraint, and predicted maps from model with refined constraint. Fig. 6.  Error measurement (VOE, VD, ASD, RMSD and RMSE) boxplots on Sliver07 dataset from model with basic loss (a), model with auxiliary constraint (b), and model with refined constraint (c). Fig. 7.  Similarity measurement (DSC, Precision, Recall and Jaccard) boxplots on Sliver07 dataset from (a) model with basic loss, (b) model with auxiliary constraint, and (c) model with refined constraint. Table 2.  Evaluation indicators for liver segmentation on sliver dataset. also can be seen from Fig. 3 that the average level of each index corresponding to model with refined constraint show optimal state. This illustrates the application of refined constraint improves the model performance, which also effectively demonstrates its validity for pancreas segmentation. For  similarity  measurement,  higher  values  equate  to  better  segmentation  performance.  As  displayed  in Fig. 4, the obtained similarity measurement from model with refined constraint show strongest convergence than another two models. This indicates the introduction of refined constraint improves the liver segmentation stability.  It  also  can  be  observed  from  Fig.  4  that  the  mean  values  of  each  measurement  corresponding  to model  with  refined  constraint  show  optimal  level. This  indicates  refined  constraint  effectively  improves  liver segmentation performance, confirming the effectiveness of refined constraint for organ segmentation. As  displayed  in  Table  1,  mean  and  standard  deviation  (std)  of  VOE  for  models  with  basic  loss,  auxiliary constraint and refined constraint are 36.3 ± 9.5, 32.5 ± 8.6 and 29.0 ± 7.4, while mean and std of ASD for these three models are 1.0 ± 0.8, 0.7 ± 0.5 and 0.5 ± 0.4. From these error measurement on pancreas dataset, we can conclude that the involvement of refined constraint achieves an optimized VOE of 7.3% and ASD of 0.5 mm, which  strongly  suggests  its  profit  for  boosting  segmentation  quality.  Furthermore,  the  depressed  std  values illustrates the model performance gradually stabilized. Besides, the obtained results of DSC and Precision are 77.4 ± 7.6, 80.3 ± 6.4, 82.8 ± 5.3, 77.6 ± 9.7, 79.9 ± 9.6 and 83.1 ± 7.9, consecutively. This further demonstrates the improved maps quality and stabilized model performance. It can be observed from Fig. 5 that the predicted probability maps from basic model tend  to  represent  chunks of deviations,  and the involvement of auxiliary constraint ameliorates the situation. After this, refined constraint further improves segmentation performance even in tiny positions which are difficult to segment. Segmentation results on Sliver07 dataset As shown in Fig. 6, the mean level of each metric box uniformly progressively decreased from (a) model with basic loss, (b) model with auxiliary constraint to (c) model with refined constraint. This declares the contribution of auxiliary constraint and refined constraint on promoting liver segmentation capability. Meanwhile, the mean level  of  each  box  in  Fig.  7  progressively  increased  from  (a)  basic  loss,  (b)  auxiliary  constraint  to  (c)  refined constraint, which further verifies the effectiveness of the involved auxiliary and refined l constraints. Table 2 displays mean and std of metrics for liver segmentation models with basic loss, auxiliary constraint and refined constraint. Their corresponding VOE values are 19.6 ± 3.2, 12.3 ± 3.1 and 7.2 ± 2.2 while ASD values are 1.8 ± 0.9, 0.7 ± 0.4 and 0.3 ± 0.2. Besides, the obtained liver segmentation results of DSC and Jaccard are 89.1 ± 2.0, 93.4 ± 1.7, 96.3 ± 1.2, 80.4 ± 3.2, 87.7 ± 3.1 and 92.8 ± 2.2, consecutively. The predicted segmentation maps are displayed in Fig. 8, it is obvious that the output maps from model with auxiliary constraint can deal better with main  frame  areas  than  basic  loss.  Furthermore,  the  employment  of  refined  constraint  helps  to  polish  minor positions which are challengeable to distinguish from background in other two models. Fig. 8.  Examples of liver segmentation results from models with different constraints. From left to right: original volumes from Sliver07 dataset, the corresponding ground truths, predicted maps from model with basic loss, predicted maps from model with auxiliary constraint, and predicted maps from model with refined constraint. Comparison to state-of-the-art Our  proposed  model  is  compared  with  the-state-of-art  pancreas  segmentation  methods  to  test  its performance6,17–24. As can be shown in Table 3, the model with refined constraint achieves improvements with DSC of 0.47% (82.8% vs. 82.33%), Precision of 0.98% (83.1% vs. 82.12%) and Jaccard of 4.45% (74.8% vs. 70.35%) Table 3.  Comparison with the state-of-the-arts models for pancreas segmentation. Table 4.  Comparison with the state-of-the-arts models for liver segmentation. compared to Li et al.21. The mean DSC increases 1.53% (82.8% vs. 81.27%) and 0.4% (82.8% vs. 82.4%) compared to Roth et al.19 and Cai et al.22 and their Jaccard respectively increases 5.93% (74.8% vs. 68.87%) and 4.2% (74.8% vs. 70.6%). The DSC score of methods Liu et al.23 and Cai et al.24 are respectively 1.30% (82.8% vs. 84.10%) and 0.90% (82.8% vs. 83.70%) higher than the proposed model with refined constraint. While its obtained Jaccard optimizes 1.94% and 2.50% compared to Liu et al.23 (74.8% vs. 72.86%) and Cai et al.24 (74.8% vs. 72.30%). It can be observed that our proposed model exceeds most current technologies from different evaluation metrics. The comparison in Table 4 shows our proposed model exceeds most liver segmentation methods3,25–30. The proposed model with refined constraint achieves the best liver segmentation performance with a mean DSC of 96.3%. The obtained RMSD optimizes 0.2 mm and 0.3 mm respectively compared to Wu et al.26 (2.3 mm vs. 2.5 mm) and Gauriau et al.27 (2.3 mm vs. 2.6 mm). The obtained ASD optimizes 0.93 mm, 0.99 mm and 1.00 mm compared to Wang et al.28 (0.3 mm vs. 1.23 mm), Wu et al.26 (0.3 mm vs. 1.29 mm) and Gauriau et al.27 (0.3 mm vs. 1.3 mm). Meanwhile, the obtained VOE optimizes 0.37% and 0.67% compared to Wang et al.28 (7.2% vs. 7.57%) and Wu et al.26 (7.2% vs. 7.87%). The DSC score of methods Liu et al.3 and Liao et al.29 are respectively 1.13%  (96.3%  vs.  97.43%)  and  0.9%  (96.3%  vs.  97.2%)  higher  than  our  proposed  model.  While  its  obtained ASD optimizes 1.18 mm and 0.8 mm compared to Liu et al.3 (0.3 mm vs. 1.48 mm) and Liao et al.29 (0.3 mm vs. 1.1 mm). Though  the  proposed  model  achieves  desirable  results  on  both  pancreas  and  liver  datasets,  the  network improvement of accuracy and application is still expected. Future research will fine-tune current architecture to cope better with pancreas and liver segmentation. Also, future work will apply the proposed model on multiple datasets to explore the latent potential to solve different organ segmentation tasks. In addition, we intend to conduct  the  existing  model  on  medical  imaging  materials  collected  from  clinical  application,  to  explore  its potential ability of addressing the clinical scenario. Conclusion This paper designs a convolutional neural network with auxiliary and refined constraints to segment organs from medical image. We introduce convolutional structure into basic segmentor, which is used as a discriminator, to construct adversarial mechanism for a higher segmentation quality. Auxiliary constraint at this moment is used to represent network regression condition. Furthermore, a new convolutional structure is involved into current framework to construct twofold adversarial mechanism. Aiming at collecting more sufficient information for segmentation through imposing dual constraints on segmentor. Refined constraint at this moment is used to represent network regression condition. Experiments are conducted on two public datasets and the obtained results  demonstrate  its  superior  performance  over  several  state-of-the-art  algorithms  on  pancreas  and  liver segmentation tasks. This adequately indicates the proposed method is a powerful and promising tool for organ segmentation. Data availability The Pancreas-CT and Sliver07 datasets are publicly available, and can be downloaded using the following links: Pancreas-CT:  https:   //wi ki.cancerimagingarch ive .net/di spl ay/ Public/P ancreas-CTSliver07:   h t t p s : / / s l i v e r 0 7 . g r a n d - c h a l l e n g e . o r g /     . Author contributions L.F.H.:  Conceptualization,  methodology,  formal  analysis,  writing-original  draft.  S.Y.J.:  Software,  validation. L.M.Y.: Conceptualization, formal analysis, supervision, funding acquisition, project administration, writing-re- view and editing. All authors read and approved the final manuscript. Ethics approval and consent to participate In this paper, all methods were carried out in accordance with relevant guidelines and regulations. All cases were used with the approval of the National Institutes of Health Clinical Center (NIH) and MICCAI liver segmentation competition, and all participants provided informed consent. Competing interests The authors declare no competing interests. Additional information Correspondence and requests for materials should be addressed to M.L. Reprints and permissions information is available at www.nature.com/reprints. Publisher’s note  Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access   This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o n s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     . © The Author(s) 2025",
         "https://www.nature.com/articles/s41598-025-86087-8.pdf",
         "extracted",
         "None",
         "Pancreas segmentation based on an adversarial model under two-tier constraints;Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images;Globally Guided Progressive Fusion Network for 3D Pancreas Segmentation;Fully Automatic Liver Attenuation Estimation Combing CNN Segmentation and Morphological Operations;Automatic liver tumor segmentation in CT with fully convolutional neural networks and object-based postprocessing;A Novel Bayesian Model Incorporating Deep Neural Network and Statistical Shape Model for Pancreas Segmentation;Fully automated organ segmentation in male pelvic CT images;Interleaved 3D-CNNs for joint segmentation of small-volume structures in head and neck CT images.;Automatic Organ Segmentation for CT Scans Based on Super-Pixel and Convolutional Neural Networks;Recurrent Saliency Transformation Network: Incorporating Multi-stage Visual Cues for Small Organ Segmentation;3D U-net with Multi-level Deep Supervision: Fully Automatic Segmentation of Proximal Femur in 3D MR Images;Improving Deep Pancreas Segmentation in CT and MRI Images via Recurrent Neural Contextual Learning and Direct Loss Function;Automatic Brain Tumor Detection and Segmentation Using U-Net Based Fully Convolutional Networks;Spatial aggregation of holistically‐nested convolutional neural networks for automated pancreas localization and segmentation☆;A Fixed-Point Model for Pancreas Segmentation in Abdominal CT Scans;Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets;Efficient liver segmentation in CT images based on graph cuts and bottleneck detection.;3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes;Shape–intensity prior level set combining probabilistic atlas and probability map constrains for automatic liver segmentation from abdominal CT images;Automatic Liver Segmentation on Volumetric CT Images Using Supervoxel-Based Graph Cuts;Automatic Liver Segmentation Based on Shape Constraints and Deformable Graph Cut in CT Images;DeepOrgan: Multi-level Deep Convolutional Networks for Automated Pancreas Segmentation;U-Net: Convolutional Networks for Biomedical Image Segmentation;A Generic, Robust and Fully-Automatic Workflow for 3D CT Liver Segmentation;The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository;Comparison and Evaluation of Methods for Liver Segmentation From CT Datasets;Automatic Pancreas Segmentation via Coarse Location and Ensemble Learning;GENERATIVE ADVERSARIAL NETS;Data from Pancreas-CT",
         "Extracting organs of interest from medical images based on convolutional neural network with auxiliary and refined constraints"
        ],
        [
         "3",
         "000c965a4857c0da7d9df07065b48920a6a756c6",
         "None",
         "Sandeep Reddy,Sameer Shaikh",
         "None",
         "None",
         "https://eprints.qut.edu.au/252096/1/9284-PB1-6129-R1.pdf",
         "None",
         "None",
         "",
         "The long road ahead: navigating obstacles and building bridges for clinical integration of artificial intelligence technologies"
        ],
        [
         "4",
         "00139e24da15df3f2f4ef70a92a781ccf315ef47",
         "Repair of DNA damage is essential for genome integrity. DNA damage elicits a DNA damage response (DDR) that includes error-free and error-prone, i.e. mutagenic, repair. The SOS response is a widely conserved system in bacteria that regulates the DDR and depends on the recombinase RecA and the transcriptional repressor LexA. However, RecA/LexA-independent DDRs have been identified in several bacterial species. Here, using a whole-cell, label-free quantitative proteomics approach, we map the proteomic response in Myxococcus xanthus to mitomycin C treatment and the lack of LexA. In doing so, we confirm a LexA-independent DDR in M. xanthus. Using a candidate approach, we identify DdiA, a transcriptional regulator of the XRE family, and demonstrate that it regulates a subset of the LexA-independent DDR genes. ddiA is expressed heterogeneously in a subpopulation of cells in the absence of exogenous genotoxic stress and reversibly induced population-wide in response to such stress. DdiA, indirectly or directly, activates the expression of dnaE2, which encodes the DnaE2 error-prone DNA polymerase, and inhibits the expression of recX, which encodes RecX, a negative regulator of RecA. Accordingly, the ΔddiA mutant has a lower mutation frequency than the wild-type but also a fitness defect, suggesting that DdiA mediates a trade-off between fitness and mutagenesis. We speculate that the DdiA-dependent response is tailored to counter replication stress, thereby preventing the induction of the complete RecA/LexA-dependent DDR in the absence of exogenous genotoxic stress. Importance DNA damage repair is essential for genome integrity and depends on the DNA damage response (DDR). While the RecA/LexA-dependent SOS response is widely conserved in bacteria, there are also RecA/LexA-independent DDRs. Here, we identify the DNA damage-induced transcriptional regulator DdiA in Myxococcus xanthus and demonstrate that it regulates part of the RecA/LexA-independent DDR. DdiA activates the expression of dnaE2, which encodes the DnaE2 error-prone DNA polymerase, and inhibits the expression of recX, which encodes RecX, a negative regulator of RecA. Because the ΔddiA mutant has a lower mutation frequency than the wild-type but also a fitness defect, we suggest that DdiA mediates a trade-off between fitness and mutagenesis and that the DdiA-dependent DDR is specifically tailored to counter replication stress.",
         "Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaard‐Andersen",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2025/02/19/2025.02.19.639066.full.pdf",
         "None",
         "None",
         "",
         "DdiA, an XRE family transcriptional regulator, regulates a LexA-independent DNA damage response in Myxococcus xanthus"
        ],
        [
         "5",
         "0024c33a8cca7175b92880b8c47940deeb05e87c",
         "Breast cancer is the most common cancer among women and globally affects both genders. The disease arises due to abnormal growth of tissue formed of malignant cells. Early detection of breast cancer is crucial for enhancing the survival rate. Therefore, artificial intelligence has revolutionized healthcare and can serve as a promising tool for early diagnosis. The present study aims to develop a machine-learning model to classify breast cancer and to provide explanations for the model results. This could improve the understanding of the diagnosis and treatment of breast cancer by identifying the most important features of breast cancer tumors and the way they affect the classification task. The best-performing machine-learning model has achieved an accuracy of 97.7% using k-nearest neighbors and a precision of 98.2% based on the Wisconsin breast cancer dataset and an accuracy of 98.6% using the artificial neural network with 94.4% precision based on the Wisconsin diagnostic breast cancer dataset. Hence, this asserts the importance and effectiveness of the proposed approach. The present research explains the model behavior using model-agnostic methods, demonstrating that the bare nuclei feature in the Wisconsin breast cancer dataset and the area’s worst feature Wisconsin diagnostic breast cancer dataset are the most important factors in determining breast cancer malignancy. The work provides extensive insights into the particular characteristics of the diagnosis of breast cancer and suggests possible directions for expected investigation in the future into the fundamental biological mechanisms that underlie the disease’s onset. The findings underline the potential of machine learning to enhance breast cancer diagnosis and therapy planning while emphasizing the importance of interpretability and transparency in artificial intelligence-based healthcare systems.",
         "Tarek Khater,A. Hussain,R. Bendardaf,Iman M. Talaat,H. Tawfik,Sam Ansari,Soliman A. Mahmoud",
         "None",
         "None",
         "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10229149.pdf",
         "None",
         "None",
         "",
         "An Explainable Artificial Intelligence Model for the Classification of Breast Cancer"
        ],
        [
         "6",
         "0027ea27f5986f9c6ee9776e10289c7f2aa089ca",
         "None",
         "Robert Szafarczyk,S. Nabi,W. Vanderbauwhede",
         "\n**BLOCK**fs== 20.7**p== 0.0**b== 0.7**t== 0.1**l== 0.1**r== 0.1**\nCompiler Support for Speculation in Decoupled\nAccess/Execute Architectures\nSyed Waqar Nabi\nUniversity of Glasgow\nGlasgow, United Kingdom\nsyed.nabi@glasgow.ac.uk\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.6**\nRobert Szafarczyk\nUniversity of Glasgow\nGlasgow, United Kingdom\nrobert.szafarczyk@glasgow.ac.uk\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.7**r== 0.1**\nWim Vanderbauwhede\nUniversity of Glasgow\nGlasgow, United Kingdom\nwim.vanderbauwhede@glasgow.ac.uk\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nAbstract\nIrregular codes are bottlenecked by memory and communi-\ncation latency. Decoupled access/execute (DAE) is a common\ntechnique to tackle this problem. It relies on the compiler\nto separate memory address generation from the rest of the\nprogram, however, such a separation is not always possible\ndue to control and data dependencies between the access\nand execute slices, resulting in a loss of decoupling.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nIn this paper, we present compiler support for speculation\nin DAE architectures that preserves decoupling in the face\nof control dependencies. We speculate memory requests in\nthe access slice and poison mis-speculations in the execute\nslice without the need for replays or synchronization. Our\ntransformation works on arbitrary, reducible control flow\nand is proven to preserve sequential consistency. We show\nthat our approach applies to a wide range of architectural\nwork on CPU/GPU prefetchers, CGRAs, and accelerators,\nenabling DAE on a wider range of codes than before.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nCCS Concepts: • Hardware → Emerging languages and\ncompilers; • Software and its engineering → Compilers.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nKeywords: decoupled access/execute; compiler speculation\n**BLOCK**fs== 9.0**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nACM Reference Format:\nRobert Szafarczyk, Syed Waqar Nabi, and Wim Vanderbauwhede.\n2025. Compiler Support for Speculation in Decoupled Access/Ex-\necute Architectures. In Proceedings of the 34th ACM SIGPLAN In-\nternational Conference on Compiler Construction (CC ’25), March\n1–2, 2025, Las Vegas, NV, USA. ACM, New York, NY, USA, 13 pages.\nhttps://doi.org/10.1145/3708493.3712695\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n1 Introduction\nIrregular codes are characterized by data-dependent memory\naccesses and control flow, for example:\n**BLOCK**fs== 9.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nfor (int i = 0; i < N; ++i)\n**BLOCK**fs== 9.0**p== 0.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nA[idx[i]] = f(A[idx[i]]);\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThis work is licensed under a Creative Commons Attribution 4.0 Interna-\ntional License.\nCC ’25, Las Vegas, NV, USA\n© 2025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1407-8/25/03\nhttps://doi.org/10.1145/3708493.3712695\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n(a) An architecture with decoupled address generation, memory\naccess, and compute.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n(b) Loss-of-decoupling between address generation and mem-\nory access due to a dependency on the memory value.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n(c) Our contribution: compiler support for speculation removes\nloss-of-decoupling due to control dependencies.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nFigure 1. A decoupled access/execute architecture template.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThis code has unpredictable control flow that causes frequent\nbranch mis-predictions on CPUs and thread divergence on\nGPUs. Because of these limitations, and challenges with\nMoore’s Law and Dennard performance scaling, computer\narchitects are interested in adding CPU/GPU structures to\naccelerate such code patterns, or even to use accelerators\nspecialized for a given algorithm [26].\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nMany of the proposed architectures follow the decades-old\nidea of a Decoupled Access/Execute (DAE) architecture shown\nin Figure 1. In DAE, memory accesses are decoupled from\ncomputation to avoid stalls resulting from unpredictable\nloads [51]. The address generation unit (AGU) sends load\nand store requests to the data unit (DU), while the DU sends\nload values to and receives store values from the compute\nunit (CU). All communication is FIFO based and ideally the\nAGU to DU communication is one-directional, allowing the\n**BLOCK**fs== 9.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n(a) Pipeline of decoupled address generation from Figure 1a.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n(b) Pipeline of non-decoupled address generation from Figure 1b.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFigure 2. Comparison of a decoupled and non-decoupled\naddress generation. Non-decoupled address generation re-\nsults in a later arrival of the store address, which stalls the\nRAW check for the next load, lowering load throughput.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\naddress streams from the AGU to run ahead w.r.t the CU.\nFigure 1a shows an example of such a DAE architecture\nimplementing the earlier code snippet.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nDAE is a general technique applicable to many computa-\ntional models: it is used in specialized FPGA accelerators gen-\nerated from High-Level Synthesis (HLS) [11–13, 15, 16, 21, 54,\n55]; in Coarse Grain Reconfigurable Architectures (CGRAs)\n[20, 27, 37, 39, 43, 45, 46, 61]; and in CPU/GPU prefetchers\n[3, 5, 17, 18, 24, 38, 47, 59]. For example, NVIDIA introduced\nhardware-accelerated asynchronous memory copies [3]. The\nCUDA programmer can provide a “copy descriptor” of a ten-\nsor to copy and the hardware will run ahead and generate\nthe corresponding addresses in a Tensor Memory Unit.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nThe common denominator of all these works is that they\nrely on either the programmer or the compiler to decouple\naddress-generating instructions from the rest of the program.\nHowever, it has long been recognized that such a decoupling\nis not always possible [9, 57]. If any of the address-generating\ninstructions for array A depend on a value loaded from A,\nthen there is a loss-of-decoupling (LoD) [25]. Access patterns\nsuch as A[f(A[i])] are rare, but control dependencies that\ninvolve loads from A are common. For example, consider\nreplacing C[i] with A[i] in our running example:\n**BLOCK**fs== 9.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nfor (int i = 0; i < N; ++i)\n**BLOCK**fs== 9.0**p== 1.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nA[idx[i]] = f(A[idx[i]]);\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nHere, there is a LoD, because the A store is control-dependent\non a branch that loads from A. Whereas before the load from\nC could be prefetched, now the AGU/DU communication is\nsynchronized, because the AGU waits for A values from the\nDU before deciding if a store address should be generated,\nas shown in Figure 1b. In turn, the load waits for the store\naddress to ensure that there is no aliasing—the store address\nis needed for memory disambiguation. As a result, the AGU\ncannot run ahead of the CU anymore, resulting in decreased\npipeline parallelism, which Figure 2 illustrates.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nOne approach for restoring decoupling in this case is con-\ntrol speculation. As shown in Figure 1c, we can hoist the\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nstore request out of the if -condition in the AGU (specula-\ntion), and later poison the store in the CU on mis-speculation\n(store invalidation). However, it is unclear how the compiler\nshould coordinate the speculation and recovery transfor-\nmations across two distinct control-flow graphs. While the\nexample from Figure 1c is trivial, the task quickly becomes\ncomplicated with more speculated stores and nested control\nflow, as we demonstrate in the next section. The key chal-\nlenge here is to guarantee that the order of store requests\nsent from the AGU matches the order of store values or kill\nsignals sent from the CU on all control-flow paths.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nGeneral compiler support for speculated stores in DAE\narchitectures is an open question that we tackle in this paper,\nmaking the following contributions:\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\n• We give a formal description of the fundamental rea-\nsons why address generation cannot always be decou-\npled from the rest of the program (§4).\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.6**r== 0.1**\n• We describe compiler support for speculative memory\nin DAE architectures, solving the LoD problem due\nto control dependencies. We propose two algorithms:\none for speculating memory requests in the AGU, and\none for poisoning mis-speculations in the CU (§5).\n• We prove that our speculation approach preserves the\nsequential consistency of the original program and\ndoes not introduce deadlocks (§6).\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.6**r== 0.1**\n• We show that our work enables DAE on a wider class\nof codes than before, with applications in CPU/GPU\nprefetchers, CGRAs, and FPGA accelerators.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\n• We evaluate our DAE speculation approach on accel-\nerators generated from HLS implementing codes from\nthe graph and data analytics domain. We achieve an\naverage 1.9× (up to 3×) speedup over the baseline HLS\nimplementations. We show that our approach has no\nmis-speculation penalty and minimal code size impact\n(average accelerator area increase < 5%) (§8).\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n2 Motivating Example\nIn this brief section, we show why an obvious approach to\nspeculation in DAE architectures is incorrect.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThe FIFO-based nature of DAE requires that the order of\nmemory requests (speculative or not) generated in the AGU\nmatches exactly the order of load/store values (poisoned or\nnot) in the CU. The motivating example in Figure 1c contains\njust one speculative store and one path through the compute\nCFG where the speculation becomes unreachable, making\nthe problem of ordering trivial in that case.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nConsider the more complex code in Figure 3a with three\nstores 𝑠0, 𝑠1, and 𝑠2. Speculating all store requests in the AGU\nmight result in the store request order (𝑠2, 𝑠0, 𝑠1). In the CU,\nwe need to guarantee the same order of corresponding store\nvalues (poisoned or not) on every possible control-flow path\nthrough the loop. Unfortunately, the obvious approach that\nworked for the trivial example in Figure 1c does not work\n**BLOCK**fs== 9.0**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n(a) Code and control-flow graph of a loop with three control-\ndependent stores causing a loss-of-decoupling.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n(b) Depending on control flow, the order of store values can be:\n(𝑠2, 𝑠1, 𝑠0), (𝑠2, 𝑠0, 𝑠1), (𝑠0, 𝑠1, 𝑠2), but only (𝑠2, 𝑠0, 𝑠1) is correct.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFigure 3. Poisoning speculated stores immediately when\nthey become unreachable results in an ordering mismatch\nbetween AGU store requests from and CU store values.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nhere. If we poison values at points where the corresponding\nspeculation becomes unreachable, as illustrated in Figure 3b,\nthen we end up with three possible orderings of store values\ndepending on the CFG path in the CU, but only one of the\norderings is correct. This is why any previous implemen-\ntations of speculative stores in DAE architectures has only\nconsidered trivial triangle or diamond shaped CFGs [24], like\nthe one in Figure 1c. Generalized compiler support for store\nspeculation that guarantees the correct order of poisoning is\nthe key challenge that we solve in this paper.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n3 Background\nIn this section, we describe the architectural support needed\nto enable speculative DAE and some compiler preliminaries.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.7**\n3.1 Architectural Support\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nOur speculation technique requires architectural support for\npredicated stores and FIFOs. Store values are tagged with\na poison bit that, when set, causes the corresponding store\nrequest to be dropped in the DU without committing a store.\nWe say that a store request gets killed (or poisoned) if its\ncorresponding store value has the poison bit set. This is a\nlightweight form of speculation that does not require replays\nin the CU and does not result in out-of-bounds stores, be-\ncause mis-speculated stores are never committed. Speculative\nloads can be supported by simply discarding the value of a\nmis-speculated load.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nPredicated stores are easy to support in hardware since\nthe underlying memory protocol usually already uses a valid\nsignal. For example, the commonly used AXI4 interface\n[4] has a strobe signal to indicate which bytes are valid.\nArchitectural FIFOs (queues) are also commonly added in\nworks on CPU/GPU microarchitecture or can be relatively\ncheaply implemented in software. For example, works on\nDAE CPU/GPU prefetchers add architectural FIFOs and ex-\ntend the ISA with instructions for producing load/store ad-\ndresses and consuming/producing store values [3, 5, 17, 18,\n24, 38, 47].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThe prefetcher from [24] enables predicated stores with a\nstore_inv instruction, but the authors support only simple\ntriangle or diamond control flow patterns, calling for future\nwork on general speculation support. We discuss concrete ex-\namples of architectures that can benefit from our work in §7.\nWe evaluate our work on accelerators generated from HLS,\nwhere we have complete control of the memory interfaces.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\n3.2 Compiler Preliminaries\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nWe use an SSA-based compiler representation and associated\nanalyses [49]. In particular, we use the control-flow graph\nand dominator tree to calculate control dependencies [40],\nand we use the SSA def-use chain for data dependencies.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nWe use a canonical loop representation: loops have a sin-\ngle header block and a single loop backedge going from the\nloop latch to the loop header. Our transformation assumes re-\nducible control flow—CFG edges can be partitioned into two\ndisjoint sets, forward and back edges, such that the forward\nedges form a directed acyclic graph (DAG). Irreducible con-\ntrol flow can be made reducible with node splitting [7, 44].\nFor completeness, we briefly describe how our compiler\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nimplements a DAE architecture:\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.6**l== 0.6**r== 0.1**\n1. AGU: For each memory operation to be decoupled,\nwe change it to a send_ld_addr or a send_st_addr\nfunction that sends the memory address to the DU.\n2. CU: Dually, in the CU we change each decoupled mem-\nory operation to a consume_val or produce_val func-\ntion that receives or sends values to or from the DU.\n3. Dead Code Elimination: We run a standard DCE\npass in the CU to remove the now unnecessary address\ngeneration code. In the AGU, we delete all side effect\ninstructions that are not part of the address generation\ndef-use chains, and then also run a standard DCE pass.\nWe also use a control-flow simplification pass that\nremoves empty blocks potentially created by DCE.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nThe send_ld_addr, send_st_addr, consume_val, and\nproduce_val functions are implementation dependent. For\nexample, if we target CPU/GPU prefetchers, such as [17, 24],\nthen these would translate to instructions. For accelerators,\nthey would be translated to FIFO writes/reads.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\n4 Loss-of-Decoupling Analysis\nLoD events arise when the address generation for a given\nmemory access depends on a load that cannot be trivially\nprefetched, causing the AGU, DU, and CU communication\nto be synchronized. By non-trivially prefetched we mean\nloads that have a RAW hazards, i.e., the DU needs to receive\nall previous store addresses in program order to perform\nmemory disambiguation before executing the load.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nGiven a set of address-generating instructions 𝐺, and a set\nof memory load instructions 𝐴 using addresses generated by\ninstructions in 𝐺, there is a loss of decoupling if:\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nDefinition 4.1 (LoD Data Dependency). There exists a\npath in the def-use chain from 𝑎 ∈ 𝐴 to 𝑔 ∈ 𝐺. While en-\ncountering a 𝜙-node on the def-use chain leading to 𝑔, we\nalso trace the def-use paths of the terminator instructions 𝑇\nin the 𝜙-node incoming basic blocks to see if any terminator\ninstruction in 𝑇 depends on any 𝑎 ∈ 𝐴.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nDefinition 4.2 (LoD Control Dependency). There exists\nan instruction 𝑔 ∈ 𝐺 that is control-dependent on a branch\ninstruction 𝑏, and there is a path in the def-use chain from 𝑎 ∈\n𝐴 to 𝑏. We call the basic block that contains 𝑏 the LoD control\ndependency source. Note that the LoD control dependency\nsource need not be the immediate control dependency of 𝑔,\nand that 𝑔 might have multiple LoD control dependencies.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nDepending on the hardware context, the definition of the 𝐴\nset can be expanded or narrowed. For example, if the AGU is\nimplemented in hardware with limited control flow support,\nthen 𝐴 could include all branch instructions. On the other\nhand, given an address generating instruction, we could limit\n𝐴 to only include loads from the same array for which the\ngiven address is generated—this could be useful if we only\nwant to preserve decoupling for that array and do not care\nabout losing decoupling for other arrays. Our speculation\ntechnique applies equally well to all these definitions.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nAn example of a LoD data dependency is the A[f(A[i])]\naccess. Our speculation approach does not recover decou-\npling for such cases, but fortunately such accesses are rare.\nAn example of a more common LoD data dependency is the\ncode pattern if (A[i]) A[i++] = 1. In this case, the def-use\nchain leading to the definition of the store address contains\na 𝜙-node (i) whose value depends on loading from 𝐴. Such a\npattern is sometimes found in algorithms that operate on dy-\nnamically growing data structures, e.g. queues or stacks. Our\nspeculation technique does not work on such cases either,\nbut this is not a large limitation, since performance oriented\ncodes typically do not use dynamically growing structures,\ninstead opting for implementations with bounded space re-\nquirements that can be allocated statically [62].\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAn example of LoD due to a control dependency is shown\nin Figure 1b. This case is much more common than a direct\ndata dependency and is the focus of this paper.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nAlgorithm 1 Control-flow hoisting of AGU requests\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n1: Input: 𝑠𝑟𝑐𝐵𝑙𝑜𝑐𝑘𝑠 list of blocks that are the source of a\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\nLoD control dependency (defined in §4)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n2: Output: 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 { basic block: list of hoisted re-\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nquests to this block }\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.2**l== 0.5**r== 0.3**\n3:\n4: for 𝑠𝑟𝑐𝐵𝐵 ∈ 𝑠𝑟𝑐𝐵𝑙𝑜𝑐𝑘𝑠 do\n5:\n6:\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\n⊲ traverse the DAG from 𝑠𝑟𝑐𝐵𝐵 to the loop latch\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nfor 𝑓 𝑟𝑜𝑚𝐵𝐵 ∈ 𝑟𝑒𝑣𝑒𝑟𝑠𝑒𝑃𝑜𝑠𝑡𝑂𝑟𝑑𝑒𝑟 (𝑠𝑟𝑐𝐵𝐵) do\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nif 𝑓 𝑟𝑜𝑚𝐵𝐵 contains memory requests then\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nhoist 𝑓 𝑟𝑜𝑚𝐵𝐵 requests to the end of 𝑠𝑟𝑐𝐵𝐵\nadd requests to 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 [𝑠𝑟𝑐𝐵𝐵]\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n5 Compiler Support for Speculation\nWe now describe our dual transformations that enable spec-\nulation in the AGU and poison mis-speculations in the CU.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\n5.1 Speculating Memory Requests\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nAlgorithm 1 describes our approach to introducing specu-\nlation in the AGU. Given a LoD control dependency source\nblock 𝑠𝑟𝑐𝐵𝐵 we hoist all memory requests that are control de-\npendent on 𝑠𝑟𝑐𝐵𝐵 to the end of 𝑠𝑟𝑐𝐵𝐵. There can be multiple\nblocks with memory requests that have a LoD control depen-\ndency on 𝑠𝑟𝑐𝐵𝐵, which poses the question in which order\nshould they be hoisted to 𝑠𝑟𝑐𝐵𝐵. We use reverse post-order\nin Algorithm 1.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nAssuming reducible control flow, the CFG region from\n𝑠𝑟𝑐𝐵𝐵 to the loop latch is a DAG. The reverse post-order of\na DAG is its topological order. Topological ordering gives us\nthe useful property that given two distinct basic blocks 𝐴\nand 𝐵 in a given loop, if 𝐴 ≺ 𝐵 in any path through the loop\nthen 𝐴 ≺ 𝐵 in the topological ordering. Note that there can\nbe multiple topological orderings for a DAG, but it does not\nmatter which one is chosen in our algorithm.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nAlgorithm 1 traverses the CFG region from 𝑠𝑟𝑐𝐵𝐵 to the\nend of its loop (or to the end of the function if 𝑠𝑟𝑐𝐵𝐵 is\nnot in a loop). During the traversal, we ignore CFG edges\nleading to loop headers—we do not enter loops other than\nthe innermost loop containing 𝑠𝑟𝑐𝐵𝐵.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\n5.1.1 Example of Hoisting. Consider the CFG from Fig-\nure 4a. There are three LoD control dependency source\nblocks (2, 3, 5) and five blocks with memory requests (blocks\n2, 4, 5, 6, 7 with requests 𝑎, 𝑐, 𝑏, 𝑑, 𝑒, respectively). Assume that\neach block holds a single memory request—multiple memory\nrequests within the same block are treated in the same way\nby our algorithms. Figure 4c shows the topological order of\nthe loop (block 1 is omitted for brevity). Algorithm 1 will\nhoist 𝑏, 𝑒 to the end of block 2, and 𝑐, 𝑑, 𝑒 to the end of block\n3—the result is presented in Figure 4b. Note that the requests\n𝑏 and 𝑒 were hoisted to both block 2 and 3, because they are\nreachable from both blocks. Nothing is hoisted to block 1\nsince it is not a LoD control dependency source.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFigure 4. An example of introducing speculative memory requests in the AGU (§5.1); and poisoned stores in the CU (§5.2).\nBlock 6 in subfigure (d) kills stores c, b, then uses the allocation for store d, and then kills store e.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\n5.1.2 Nested LoD Control Dependencies. Block 5 in\nFigure 4b does not contain any speculative requests because\nit itself has a LoD control dependency on block 2 and 3.\nAlgorithm 1 considers only LoD control dependency source\nblocks that are not themselves the destination of another LoD\ncontrol dependency. Given a chain of nested LoD control\ndependencies, we only consider the chain head. For example,\nthe Figure 4a CFG has two LoD control dependency chains:\n2, 5 and 3, 5—Algorithm 1 considers only blocks 2 and 3.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nAlgorithm 2 Mapping Poison Stores to CFG Edges in CU\n1: Input: 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 { basic block: list of requests hoisted\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nto this block in Algorithm 1 }\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nfor 𝑝𝑎𝑡ℎ ∈ 𝑎𝑙𝑙𝑃𝑎𝑡ℎ𝑠𝑇𝑜𝐿𝑜𝑜𝑝𝐿𝑎𝑡𝑐ℎ(𝑠𝑝𝑒𝑐𝐵𝐵) do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n2:\n3: for 𝑠𝑝𝑒𝑐𝐵𝐵, 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 ∈ 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 do\n4:\n5:\n6:\n7:\n8:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.6**r== 0.2**\n𝑡𝑟𝑢𝑒𝐵𝐵 ← block where 𝑟 is true\n𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠.𝑖𝑛𝑠𝑒𝑟𝑡 (𝑡𝑟𝑢𝑒𝐵𝐵)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\n𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 ← ∅\nfor 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\n⊲ set keeps insertion order\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n5.1.3 Why Topological Order in Algorithm 1? Topo-\nlogical order is needed to make it possible to match the order\nof speculative requests made in the AGU with the order of\nvalues that will arrive from the CU on all its possible CFG\npaths. Consider, for example, the requests 𝑏 and 𝑐 in Fig-\nure 4a. We first want to hoist 𝑐 to block 3 before hoisting 𝑏,\nbecause there exists a CFG path where 𝑐 comes before 𝑏, but\nnot vice versa. If 𝑏 were hoisted before 𝑐, then the speculative\nrequests order would be 𝑏 ≺ 𝑐, which would be impossible\nto match with values in the CU on the CFG path 3, 5, 7.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nfor 𝑒𝑑𝑔𝑒 ∈ 𝑝𝑎𝑡ℎ do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\nfor 𝑡𝑟𝑢𝑒𝐵𝐵 ∈ 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 do\nif 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 = 𝑡𝑟𝑢𝑒𝐵𝐵 then\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.7**r== 0.1**\n𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠.𝑟𝑒𝑚𝑜𝑣𝑒 (𝑡𝑟𝑢𝑒𝐵𝐵)\nbreak\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.6**r== 0.1**\n⊲ to the next edge\nif 𝑡𝑟𝑢𝑒𝐵𝐵 not reachable from 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 then\n⊲ reachability ignores loop backedges\npoison 𝑡𝑟𝑢𝑒𝐵𝐵 requests on 𝑒𝑑𝑔𝑒 ⊲ Alg. 3\n𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠.𝑟𝑒𝑚𝑜𝑣𝑒 (𝑡𝑟𝑢𝑒𝐵𝐵)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.6**\n5.2 Poisoning Mis-speculated Stores\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nOur strategy for poisoning misspeculations in the CU is to\nfirst map a poison call to a CFG edge, and then to map that\nedge to a poison store call contained in an existing or newly\ncreated basic block.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nAlgorithm 2 describes the first step. Given block 𝑠𝑝𝑒𝑐𝐵𝐵\nthat contains speculative memory requests 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠, we\nconsider each path in the DAG from the 𝑠𝑝𝑒𝑐𝐵𝐵 to the loop\nlatch (or function exit) in the CU. We call the block where\na 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 becomes true the 𝑡𝑟𝑢𝑒𝐵𝐵 (for example,\nthe 𝑡𝑟𝑢𝑒𝐵𝐵 for request 𝑏 in Figure 4a is block 5). For each\nCFG path, we use the 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 list to keep track of which\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nrequests were already used or poisoned on the path—the list\ncontains the 𝑡𝑟𝑢𝑒𝐵𝐵 for each 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nGiven an edge in the traversal, the edge is skipped if the\nnext 𝑡𝑟𝑢𝑒𝐵𝐵 ∈ 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 is still reachable from 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 .\nThis guarantees that the order of speculative requests in the\nAGU matches the order of values in the CU, i.e., a speculative\nrequest for a given 𝑡𝑟𝑢𝑒𝐵𝐵 block is not poisoned immedi-\nately when 𝑡𝑟𝑢𝑒𝐵𝐵 becomes unreachable if there is an earlier\nspeculative request that can still be used.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n5.2.1 Example of Mapping Poison Stores to CFG Edges.\nFigure 4c shows which CFG edges are poisoned given the\noriginal CFG in Figure 4a and the AGU CFG in Figure 4b. For\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.6**\nAlgorithm 3 Poisoning Stores on Edges in CU\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n1: Input: store request 𝑟 ; CFG 𝑒𝑑𝑔𝑒; block 𝑠𝑝𝑒𝑐𝐵𝐵 where 𝑟\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nwas speculated; block 𝑡𝑟𝑢𝑒𝐵𝐵 where 𝑟 is true\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.3**r== 0.5**\n⊲ preserve set across calls\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.2**r== 0.5**\nget from 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒 if exists\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.1**r== 0.6**\n2:\n3: 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒 ← ∅\n4: if 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 is reachable from 𝑡𝑟𝑢𝑒𝐵𝐵 then\n5:\n6:\n7:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\n𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 ← create new block on 𝑒𝑑𝑔𝑒 or\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\nappend 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the end of 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵\n𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒.𝑖𝑛𝑠𝑒𝑟𝑡 (𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵)\n8:\n9: else if 𝑠𝑝𝑒𝑐𝐵𝐵 does not dominate 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 then\n𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 ← create new block on 𝑒𝑑𝑔𝑒\n10:\nappend 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the end of 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵\n11:\n12:\n13:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\ncreate 𝜙 (1, 𝑠𝑝𝑒𝑐𝐵𝐵) value in 𝑒𝑑𝑔𝑒𝑠𝑟𝑐\nbranch from 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 on 𝜙 = 1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\n⊲ create recursively on 𝑠𝑝𝑒𝑐𝐵𝐵 → 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 paths\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nappend 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the start of 𝑒𝑑𝑔𝑒𝑑𝑠𝑡\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nexample, the path 3 → 5 → 𝐿 will have: 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) on the\n3 → 5 edge; and 𝑝𝑜𝑖𝑠𝑜𝑛(𝑑), 𝑝𝑜𝑖𝑠𝑜𝑛(𝑒) on the 5 → 𝐿 edge\n(4th path from block 3 in Figure 4c).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n5.2.2 Mapping Poisoned Edges to Basic Blocks. Algo-\nrithm 3 shows how poisoned CFG edges are mapped to actual\npoison calls placed in a concrete basic block. Given a poi-\nsoned request 𝑟 on 𝑒𝑑𝑔𝑒 (from 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 block to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 block),\nthe 𝑠𝑝𝑒𝑐𝐵𝐵 block where 𝑟 was speculated in the AGU, and\n𝑡𝑟𝑢𝑒𝐵𝐵 where r becomes true there are three cases:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\n1. There exists a path from 𝑡𝑟𝑢𝑒𝐵𝐵 to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . In this\ncase, we cannot insert 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) in 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , because\nwe would end up with a CFG path where the store is\nboth true and poisoned. To avoid this, we create a new\n𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 block on 𝑒𝑑𝑔𝑒 and append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to it.\n2. There exists a path from the loop header to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡\nthat does not contain 𝑠𝑝𝑒𝑐𝐵𝐵. In this case, we cannot\ninsert 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) in 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , because we would end up\nwith a CFG path where 𝑟 was not speculated in the\nAGU, but was poisoned in the CU. To avoid this, we\ncreate a new block 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 on the edge and append\n𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to it. We also add steering instructions to the\npath from 𝑠𝑝𝑒𝑐𝐵𝐵 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 that will branch from\n𝑒𝑑𝑔𝑒𝑠𝑟𝑐 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 only if 𝑠𝑝𝑒𝑐𝐵𝐵 was encountered\non the current CFG path.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n3. Otherwise, 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) can safely be prepended to the\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nstart of 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 .\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAlgorithm 3 is executed only once per (𝑒𝑑𝑔𝑒, 𝑟 ) tuple—a\ngiven request is poisoned at most once on a given edge. Also,\npoison blocks created in case 1 in Algorithm 3 can be reused\nto poison other requests.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFigure 5. Basic blocks with the same list of poison stores\nand the same immediate successor can be merged in the CU.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n5.2.3 Example of Mapping Poison Edges to Blocks.\nConsider how the poisoned edges in Figure 4c are mapped\nto basic blocks in Figure 4d.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nCase 1: Store 𝑐 is poisoned on the 3 → 5 edge. Since\nthere is a path from the true block of 𝑐 (block 4) to the edge\ndestination block (block 5), we create a new block on the\n3 → 5 edge and append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) to it.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nCase 2: Store 𝑑 is poisoned on both the 5 → 7 and 5 → 𝐿\nedges. The 𝑠𝑝𝑒𝑐𝐵𝐵 for 𝑑 is block 3. Since there exists the path\n𝐻 → 1 → 2 → 5 that does not contain block 3, we create\na new block on the 5 → 7 edge with the 𝑝𝑜𝑖𝑠𝑜𝑛(𝑑) call. We\nadd steering instructions to the 3 → 5 and 3 → 4 → 5 paths\nthat will cause block 5 to branch to the new poison block\non the 5 → 7 edge only if block 5 was reached from a path\ncontaining block 3.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.6**r== 0.1**\nCase 3: Store 𝑐 is also poisoned on the 3 → 6 edge, but\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nhere it is safe to prepend 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) to the start of block 6.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\n5.3 Merging Poison Blocks\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nCase 1 and 2 of Algorithm 3 might create multiple poison\nblocks for the same store on different CFG edges. It is possible\nto merge two poison blocks into one if they contain the\nsame list of poison stores and if they have the same list of\nimmediate successors. When merging, we keep instructions\nfrom just one block. We apply such merging iteratively after\nAlgorithms 2 and 3. For example, Figure 5 contains a CFG sub-\nregion of our running example from Figure 4. Algorithm 3\ninserted poison blocks 10, 11, 12, 13 to poison stores 𝑑 and 𝑒.\nBlock pairs (11, 13) and (10, 12) can be merged.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\n5.4 Speculative Load Consumption\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nSpeculative loads are relatively easy to support. To match\nthe order of load_consume calls in the CU with the order\nof speculative send_load_addr calls in the AGU we can\nhoist the load_consume calls to the same block where the\ncorresponding send_load_addr were hoisted in the AGU.\nThen, the CU can either use the load value or discard it.\nAfter hoisting, we need to update all 𝜙 instructions that use\nthe load value, since the basic block containing the loaded\nvalue will have changed. Alternatively, we can transform 𝜙\ninstructions using the load value into select instructions.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\n6 Safety and Liveness\nWe prove that our transformations preserve the sequential\nconsistency of the original program and that they do not\nintroduce deadlock. Deadlock freedom is a corollary of se-\nquential consistency, so we focus only on the latter. We\nshow that on every CFG path the order of speculative store\nrequests in the AGU matches the order of store values in the\nCU, and that the non-poisoned store value sequence in the\nCU matches the store sequence of the original code.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nIn the following discussion, we assume blocks with a sin-\ngle store; the proof trivially extends to blocks with multi-\nple stores since all speculative stores in the same block are\ntreated the same. We also assume that all stores are specula-\ntive, since the relative order between non-speculative and\nspeculative stores is guaranteed by definition: given a a non-\nspeculative store 𝑠1 and a speculative store 𝑠2, Algorithm 1\nwill not change the relative program order of 𝑠1 and 𝑠2, i.e., if\n𝑠1 ≺ 𝑠2 in the original program order, then it is not possible\nto hoist 𝑠2 such that 𝑠2 ≺ 𝑠1. This follows from the con-\ntrol dependency definition (§4)—𝑠2 hoisting stops at its LoD\ncontrol dependency source 𝑠𝑟𝑐𝐵𝐵, which must come after\nthe block containing 𝑠1 in topological order. If 𝑠𝑟𝑐𝐵𝐵 would\ncome after 𝑠1 in topological order, then the block containing\n𝑠1 would also have a LoD control dependency on 𝑠𝑟𝑐𝐵𝐵 and\nwould have been hoisted, which is a contradiction since we\nassumed that 𝑠1 was non-speculative. A similar argument\ncan be made if 𝑠2 ≺ 𝑠1 in the original program.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nLemma 6.1 (Sequential Consistency). Given an ordered list\nof 𝑛 speculative store requests 𝐿𝑎 = {𝑎0, 𝑎1, ..., 𝑎𝑛−1} made\nin the AGU loop CFG on some fixed iteration 𝑘, Algorithms\n2 and 3 transform the CU CFG such that every possible\npath through its loop CFG on iteration 𝑘 produces an or-\ndered list of 𝑛 tagged store values 𝐿𝑣 = {(𝑣0, 𝑝0), (𝑣1, 𝑝1), ...,\n(𝑣𝑛−1, 𝑝𝑛−1)}, such that each (𝑎𝑖, 𝑣𝑖, 𝑝𝑖 ), 0 ≤ 𝑖 < 𝑛 triple cor-\nresponds to a 𝐴[𝑎𝑖 ] ← 𝑣𝑖 store in the original program CFG,\nand 𝑝𝑖 = 1 (poison bit) if that store is not executed on the\npath through the original loop CFG on iteration 𝑘.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nProof. We use a proof by induction on the transformed CFG.\nBase case: 𝐿𝑎 = ∅ (no speculated requests in the AGU).\nAlgorithm 2 does not change the CU CFG. Thus, the order\nof store addresses in the AGU and store values in the CU\ntrivially matches, 𝐿𝑎 = 𝐿𝑣 = ∅.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nInductive hypothesis: assume Lemma 6.1 holds at basic\nblock 𝐵𝑖 in the current CFG path. All store requests 𝑎 𝑗 ∈\n𝐿𝑎 contained in blocks reached before 𝐵𝑖 in the path were\nmatched with the correct store value call (𝑣 𝑗, 𝑝 𝑗 ) ∈ 𝐿𝑣, such\nthat 𝑝 𝑗 = 1 if 𝐴[𝑎 𝑗 ] ← 𝑣 𝑗 was not executed on the path in\nthe original loop CFG.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nInductive step: The next store address in the AGU 𝐿𝑎 se-\nquence is 𝑎 𝑗+1 ∈ 𝐿𝑎. The next store value in the CU CFG\npath should be (𝑣 𝑗+1, 𝑝 𝑗+1) ∈ 𝐿𝑣, where 𝑝 𝑗+1 = 1 iff the\nstore 𝐴[𝑎 𝑗+1] ← 𝑣 𝑗+1 is not reached on the current CFG\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\npath in the original program. Algorithm 2 considers the\n𝑒𝑑𝑔𝑒𝑠𝑟𝑐 → 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 next. There are three cases:\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\n1. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 = 𝑡𝑟𝑢𝑒𝐵𝐵, where 𝑡𝑟𝑢𝑒𝐵𝐵 is the block contain-\ning the store 𝐴[𝑎 𝑗+1] ← 𝑣 𝑗+1 in the original program\nCFG. In this case, Algorithm 2 will not poison this\nstore on this path through the CU CFG, i.e., the next\nitem in the 𝐿𝑣 sequence will be the correct (𝑣 𝑗, 0).\n2. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 ≠ 𝑡𝑟𝑢𝑒𝐵𝐵 and 𝑡𝑟𝑢𝑒𝐵𝐵 is not reachable from\n𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , in which case Algorithm 2 will insert a poison\nstore on this edge. Algorithm 3 will map this poison\nstore to a basic block, with the effect that taking the\n𝑒𝑑𝑔𝑒 will result in the poison call being executed and\ncontrol transferring to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . The next item in the\n𝐿𝑣 sequence will be the correct (𝑣 𝑗, 1).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\n3. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 ≠ 𝑡𝑟𝑢𝑒𝐵𝐵 and 𝑡𝑟𝑢𝑒𝐵𝐵 is reachable from 𝐵𝑙 , in\nwhich case Algorithm 2 will traverse the path until\nCase 1 or 2 is matched.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nSince Lemma 6.1 holds for the base case, for basic blocks\non the path up to 𝐵𝑖 , and for some successor block of 𝐵𝑖 , it\nmust hold at any block on the path. If it holds at any block\non the path, it holds for the whole path. Since a given store\nrequest 𝑟 is poisoned at most once on a given CFG edge\nand since, by definition of Algorithm 2, any given path will\ncontain at most one edge where 𝑟 is poisoned, we conclude\n□\nthat Lemma 6.1 holds for all paths.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\n7 Applications\nIn this section, we highlight three applications for our work:\nDAE-based prefetchers in CPUs/GPUs, CGRAs, and special-\nized accelerators generated from HLS. In the next section,\nwe choose HLS as an evaluation vehicle due to its simplicity\ncompared to CPU/GPU prefetchers where the evaluation\nresults can easily be polluted by other architectural factors\nlike cache behavior, branch prediction, etc. However, we em-\nphasize that our speculation support in DAE does not rely\non any HLS-specific features and can be applied wherever\nspeculation is combined with the DAE technique.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\n7.1 CPU/GPU Prefetchers\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nMost existing works on CPU/GPU prefetchers follow the\nDAE principle and rely on the compiler to decoupled address\ngeneration from compute [3, 5, 17, 18, 24, 38, 47]. All of these\nworks suffer from the control-dependency loss of decoupling\n(LoD) problem (§4). The work in [24] discusses adding spec-\nulation and predicated stores to the CPU microarchitecture\nto mitigate LoD, but their compiler only supports simple\ndiamond and triangle control flow shapes. In this paper, we\nhave demonstrated generalized compiler support for specu-\nlation in DAE, making these works viable for general control\nflow and thus applicable to a broader set of codes.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n7.1.1 Example. The CPU prefetcher proposed in [24] (on\nwhich most of the other work is based) separates address gen-\neration from compute and extends the ISA with store_addr,\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nload_produce, store_val, load_consume, and store_inv\ninstructions that can be directly targeted by our compiler.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n7.2 Coarse Grain Reconfigurable Architectures\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nA CGRA consists of an array of PEs, each with small memo-\nries, connected by a network. A CGRA compiler is typically\nco-designed with the hardware, as the PEs are typically stat-\nically scheduled. The job of the compiler is to map the Con-\ntrol/Data Flow Graph (CDFG) to the PEs, and many works\nfollow the DAE technique to tackle the memory wall prob-\nlem [20, 27, 37, 39, 43, 45, 46, 61]. Our work can help mitigate\nLoD events when mapping to CGRAs.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\n7.2.1 Example. The CGRA proposed in [39] is an example\nof a modern streaming dataflow CGRA. All communication\nin the CGRA is FIFO-based, and address generation is ex-\nplicitly decoupled at compile time into AGUs. The compiler\ngenerates commands to produce address streams, and to\nconsume or produce values. Control flow is handled with\npredication and there is a SD_Clean_Port command to throw\naway a value from an output port that can be used to imple-\nment predicated stores.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\n7.3 High-Level Synthesis\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nIn HLS, the CDFG of an algorithm is implemented directly\nin hardware following a spatial execution model with the\nfreedom to customize the memory system. This makes de-\ncoupling easier in HLS compared to the temporal CPU/GPU\nexecution model. HLS-generated accelerators can directly\nbenefit from our work today without any changes, and it is\nin this domain that we evaluate our implementation in the\nnext section.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nAlthough existing HLS compilers are successful in build-\ning non-trivial accelerators for regular code (e.g., [48]), their\nstatic scheduling techniques are sub-optimal for irregular\ncodes (for the same reason why traditional VLIW compilers\nwere sub-optimal for irregular codes). Many research works\nin academia and industry have exploited DAE in HLS to\nimprove the efficiency of HLS-generated accelerators for ir-\nregular codes [11–13, 15, 16, 21, 53–55]. By adding compiler\nspeculation support, DAE in HLS can be used on a broader\nset of codes, which we demonstrate in the next section.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.6**\n8 Evaluation\nIn this section, we answer the following questions:\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n• What is the performance benefit of using a DAE ar-\nchitecture (enabled by our speculation approach) to\naccelerate codes with LoD control dependencies?\n• What is the cost of mis-speculation in our approach?\n• What is the impact on code size (accelerator area usage)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nof our speculation approach?\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n• What is the scalability for nested control flow, which\nincreases the number of poison stores and blocks?\nWe make our work and evaluation publicly available [52].\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFigure 6. Performance of DAE, SPEC and ORACLE normalized\nto STA. SPEC achieves an average 1.9× (up to 3×) speedup.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\n8.1 Methodology\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nWe generate algorithm-specific accelerators using HLS tar-\ngeting an Intel Arria 10 FPGA. The C codes are taken directly\nfrom benchmark suites without adding any HLS-specific an-\nnotations (excluding dynamic structures, like queues, that\nwere replaced with HLS-specific libraries).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nWe use the LLVM-based Intel SYCL HLS compiler [29]\nand apply our standard DAE transformation (§3.2) and our\nproposed speculation transformation (§5) as LLVM passes.\nThe codes use deterministic dual-ported on-chip SRAM ca-\npable of 1 read and 1 write per cycle. To enable out-of-order\nloads, we use a load-store queue (LSQ) designed for HLS\n(load/store queue sizes of 4/32), which is commonly found\non accelerators for irregular codes [1, 24, 31, 53].\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nWe report cycle counts from ModelSim simulations. We\ndo not report circuit frequency since our approach does not\naffect the critical path (see [52] for such details). Area usage\nis obtained after place and route using Quartus 19.2.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n8.1.1 Baselines. For each benchmark, we synthesize the\nfollowing architectures which represent current state-of-the-\nart approaches to HLS :\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.6**r== 0.1**\n• STA: the default, industry-grade approach using static\nscheduling [29]. Loads that cannot be disambiguated\nat compile time execute in order.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\n• DAE: a DAE architecture without speculation. OoO\nloads are enabled by an LSQ. This is the state-of-the-\nart approach to irregular codes in academia [53], but\nit suffers from control-dependency LoDs.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\n• SPEC: the same as DAE, but with our speculation tech-\nnique which mitigates control-dependency LoDs.\n• ORACLE: the same as DAE, but all LoD control depen-\ndencies are removed manually from the input code.\nThe ORACLE results are wrong, but give a bound on the\nperformance of SPEC and show its area overhead.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n8.1.2 Benchmarks. DAE architectures optimize the la-\ntency between memory and compute and are most beneficial\nfor memory-bound codes [24], especially codes with an irreg-\nular memory access pattern that prevents static prefetching\n[18]. We evaluate nine such benchmarks from the graph\nand data analytics domain, using the GAP graph benchmark\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nTable 1. Absolute performance and area usage of STA [29], DAE [53], SPEC, and ORACLE accelerators. (*bc uses two LSQs).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nKernel\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nPoison\nBlocks Calls\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nbfs\nbc\nsssp\nhist\nthr\nmm\nfw\nsort\nspmv\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\nMis-spec.\nRate\n95%\n95%, 82% *\n95%\n2%\n97%\n31%\n85%\n49%\n32%\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\nHarmonic Mean:\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.5**r== 0.5**\nCycles\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nArea (ALMs [28])\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.5**r== 0.4**\nSPEC ORACLE\n27,561\n51,109\n51,227\n1,033\n1,052\n4,069\n3,433\n1,748\n8,028\n0.51\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.8**r== 0.1**\nSPEC ORACLE\n13,404\n16,582\n17,426\n3,117\n6,278\n7,813\n4,008\n5,260\n4,416\n1.42\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nsuite [8] and an HLS benchmark suite [14] of irregular pro-\ngrams. We select only codes that can benefit from our SPEC\napproach, i.e., codes with LoD control dependencies:\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n• bfs: breadth-first traversal through a graph.\n• bc: betweenness centrality of a single node in a graph.\n• sssp: single shortest path from a single node to all\nother nodes in a graph using Dijkstra’s algorithm.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n• hist: histogram, similar to Figure 1b (size 1000).\n• thr: zeroes RGB pixels above threshold (size 1000).\n• mm: maximal matching in a bipartite graph (2000 edges).\n• fw: Floyd-Warshall distance calculation of all node-to-\nnode pairs in a dense graph (10×10 distance matrix).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n• sort: using bitonic mergesort (size 64).\n• spvm: sparse vector matrix multiply (20×20 matrix).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nFor the graph codes (bfs, bc, sssp) we use a real-world graph\nemail-Eu-core with 1005 nodes and 25,571 edges.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\n8.2 Performance\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nFigure 6 reports normalized speedups of each technique over\nSTA. Our SPEC approach gives on average a 1.9× (and up\nto 3×) speedup over STA. This is within 5% of the ORACLE\nperformance. In contrast, DAE without speculation sees a\ndramatic performance degradation over STA, because the\nAGU, DU, CU communication is sequentialized.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\n8.2.1 Mis-speculation Cost. The SPEC and ORACLE per-\nformance gap is highest on the bfs and bc codes, because of\nits deep pipeline between the load and store that form a RAW\nhazard. The deep pipeline means that more store allocations\nneed to be held by the LSQ to guarantee perfect pipelining\n[34]. This, together with a high mis-speculation rate in these\nbenchmarks (Table 1), can cause the LSQ to fill with store\naddresses that are mis-speculated, potentially stalling later\nloads that have to wait for future store addresses to arrive.\nThis problem can be solved by increasing the store queue size\nin the LSQ. The increased number of requests and the need\nfor more buffering is one of the limitations of our approach.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nCodes with a shallower pipeline that do not need large LSQ\nsizes have no mis-speculation penalty.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nTo prove this, we choose three benchmarks where we\ncan instrument the input data so that we can vary the mis-\nspeculation rate. Table 2 shows how the mis-speculation\ncost changes as the mis-speculation rate increases. As can\nbe seen, there is no correlation between the mis-speculation\nrate and cost, with the slight variability in clock cycle counts\nattributable to the subtle difference in the number of true\nRAW hazards due to the varying data distribution.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nTable 2. SPEC cycle counts as mis-speculation rate changes.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nKernel\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nhist\nthr\nmm\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nMis-speculation rate\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\n8.3 Code Size\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nOur speculation approach can increase the number of blocks\nin the CU, especially for codes with deeply nested control\nflow. In HLS, an increased number of blocks can result in a\nhigher area usage due to larger scheduler complexity [50].\nTable 1 shows the absolute area usage of all accelerators.\nWe observe virtually no area overhead of SPEC over ORACLE\non the evaluated benchmarks. This is because most of the\ncodes have at most two control-flow nesting levels where\nnew poison blocks are inserted, and sometimes it is possible\nto reduce the number of blocks using our merging technique\n(e.g., two poison blocks in mm merged into one).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n8.3.1 Impact of Nested Control Flow on Area Usage.\nTo give a more meaningful measure of how nested control\nflow impacts the area overhead of our SPEC approach, we\ncreate a synthetic benchmark template where we can tune\nthe number of poison blocks generated by SPEC:\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nfor HLS with speculation support [23]. The speculation sup-\nport in this and other works requires costly recovery on\nmis-speculation [6, 22, 30, 35, 56, 60]. Efficiently squashing\nspeculative computation on the wrong paths in a spatial\ndataflow architecture is hard, because the architectural state\nis distributed [10]. Our speculative DAE sidesteps this issue,\nnot requiring any recovery: we speculate early (run ahead)\nin the AGU, and later handle mis-speculations in the CU by\ntaking an appropriate path in its CFG.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nControl-flow handling in GPUs is usually implemented\nvia predication. The algorithms used to calculate predicate\nmasks and re-convergence points resemble our work [32].\nThe SIMT stack approach in GPUs pushes predicate masks\nonto a stack when entering a control-flow nesting level, and\npops when exiting. Our Algorithm 1 implementing specula-\ntive requests can be seen as a pass through the CFG with only\npush operations, where the push is onto individual stacks of\ncontrol-dependency sources. Dually, our inserting of poison\ncalls in Algorithm 1 can be seen as a pass through the CFG\nwith only pop operations where the placement of the pops\nfollows a certain policy just like modern SIMT compilers fol-\nlow different policies to prevent SIMT deadlock and livelock,\nor to improve performance [19], instead of popping at the\nimmediate post-dominator.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\n10 Conclusion\nWe have presented general compiler support for specula-\ntive memory operations in DAE architectures that tackles\nthe LoD problem resulting from control dependencies. We\nhave proposed CFG transformations implementing specula-\ntion in the address generation slice, and poisoning of mis-\nspeculations in the compute slice, with a proof of correctness.\nWe have presented three applications where our work im-\nproves support for the efficient execution of irregular codes:\nDAE-based CPU/GPU prefetchers that require compiler sup-\nport, CGRA architectures, and HLS-generated specialized\naccelerators. We have evaluated our work on HLS-generated\naccelerators, showing an average 1.9× (up to 3×) speedup\nover non-DAE accelerators on a set of irregular benchmarks\nwhere DAE is not possible without our speculation. Our ap-\nproach has no mis-speculation cost and a small code size\nfootprint, scaling well to deeply nested control flow.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nFuture work could investigate vector-parallelism support\nby filling a vector of speculative requests in the AGU and\nproducing a store mask in the CU, similar to the recent work\non decoupled vector runahead prefetching in CPUs [36].\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nData-Availability Statement\nWe make our work and evaluation publicly available [52].\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nAcknowledgments\nWe thank Intel for access to FPGAs through their DevCloud.\nThis work was supported by a UK EPSRC PhD scholarship.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFigure 7. Change in area and performance overhead of SPEC\nover ORACLE as the number of poison blocks and calls grows.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nif 𝑥 > 0 then\n𝑠𝑡𝑜𝑟𝑒1\nif 𝑥 > 1 then\n𝑠𝑡𝑜𝑟𝑒2\nif 𝑥 > 2 then ...\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\npoison calls.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nEach nesting level in this template will result in one poison\nblock in the SPEC architecture. With 𝑛 stores, and assuming\none store per nesting level, there will be 𝑛 poison blocks and\n𝑛\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\n𝑖=1\nFigure 7 shows how the area and performance overhead of\nSPEC over ORACLE changes as more poison blocks are needed.\nThe performance overhead is close to 0% and does not change\nwith more poison blocks. The area overhead of the AGU unit\nis similarly close to 0%, because SPEC hoists stores out of\nthe if -conditions, causing the blocks to be deleted. The area\noverhead of the CU unit grows by a few percent (< 5%)\nwith each added poison block, but even for the pathological\ncase of eight nested if -conditions the overhead is below 25%.\nIn real codes, with more compute and lower control-flow\nnesting, the area overhead of SPEC should be minimal.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n9 Related Work\nProgram slicing is used beyond DAE architectures. Decoupled\nSoftware Pipelining (DSWP) [41] is a popular transforma-\ntion that decouples strongly connected components in the\nprogram dependence graph into separate pipeline stages\nmapped over multiple PEs communicating via FIFOs. The\nPEs can be CPU threads, or pipeline stages in an accelerator\ngenerated by HLS [33]. Control dependent pipeline stages in\nDSWP can also be executed speculatively, although stages\nwith memory operations require versioned memory [58].\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nControl speculation has its roots in compilers for VLIW ma-\nchines. Instruction scheduling in HLS is very similar to VLIW\nscheduling (no hardware support for speculation, static map-\nping to functional units, etc.), with many algorithms like\nmodulo-scheduling and if -conversion originally developed\nfor VLIW directly applicable to HLS [2, 42, 50]. Most recently,\npredicated execution in the form of gated SSA was proposed\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nReferences\n[1] Mythri Alle, Antoine Morvan, and Steven Derrien. 2013. Runtime\ndependency analysis for loop pipelining in High-Level Synthesis. In\n2013 50th ACM/EDAC/IEEE Design Automation Conference (DAC). 1–10.\ndoi:10.1145/2463209.2488796\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[2] J. R. Allen, Ken Kennedy, Carrie Porterfield, and Joe Warren. 1983.\nConversion of control dependence to data dependence. In Proceedings\nof the 10th ACM SIGACT-SIGPLAN Symposium on Principles of Program-\nming Languages (Austin, Texas) (POPL ’83). Association for Computing\nMachinery, New York, NY, USA, 177–189. doi:10.1145/567067.567085\n[3] Michael Andersch, Greg Palmer, Ronny Krashinsky, Nick Stam, Vishal\nMehta, Gonzalo Brito, and Sridhar Ramaswamy. 2022. NVIDIA Hop-\nper Architecture In-Depth. https://developer.nvidia.com/blog/nvidia-\nhopper-architecture-in-depth/\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n[4] ARM. 2024. AXI protocol overview.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nhttps://developer.arm.com/\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\ndocumentation/102202/0300/AXI-protocol-overview\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n[5] José-María Arnau, Joan-Manuel Parcerisa, and Polychronis Xekalakis.\n2012. Boosting mobile GPU performance with a decoupled access/exe-\ncute fragment processor. In Proceedings of the 39th Annual International\nSymposium on Computer Architecture (Portland, Oregon) (ISCA ’12).\nIEEE Computer Society, USA, 84–93.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[6] David I. August, Daniel A. Connors, Scott A. Mahlke, John W. Sias,\nKevin M. Crozier, Ben-Chung Cheng, Patrick R. Eaton, Qudus B. Olani-\nran, and Wen-mei W. Hwu. 1998. Integrated predicated and speculative\nexecution in the IMPACT EPIC architecture. SIGARCH Comput. Archit.\nNews 26, 3 (apr 1998), 227–237. doi:10.1145/279361.279391\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[7] Helge Bahmann, Nico Reissmann, Magnus Jahre, and Jan Christian\nMeyer. 2015. Perfect Reconstructability of Control Flow from Demand\nDependence Graphs. ACM Trans. Archit. Code Optim. 11, 4, Article 66\n(jan 2015), 25 pages. doi:10.1145/2693261\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[8] Scott Beamer, Krste Asanovic, and David A. Patterson. 2015. The\nGAP Benchmark Suite. CoRR abs/1508.03619 (2015). arXiv:1508.03619\nhttp://arxiv.org/abs/1508.03619\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n[9] Peter L. Bird, Alasdair Rawsthorne, and Nigel P. Topham. 1993. The\neffectiveness of decoupling. In Proceedings of the 7th International\nConference on Supercomputing (Tokyo, Japan) (ICS ’93). Association\nfor Computing Machinery, New York, NY, USA, 47–56. doi:10.1145/\n165939.165952\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[10] M. Budiu, P.V. Artigas, and S.C. Goldstein. 2005. Dataflow: A Comple-\nment to Superscalar. In IEEE International Symposium on Performance\nAnalysis of Systems and Software (ISPASS). doi:10.1109/ISPASS.2005.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[11] Tao Chen and G. Edward Suh. 2016. Efficient data supply for hardware\naccelerators with prefetching and access/execute decoupling. In 2016\n49th Annual IEEE/ACM International Symposium on Microarchitecture\n(MICRO). 1–12. doi:10.1109/MICRO.2016.7783749\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[12] Tao Chen and G Edward Suh. 2016. Efficient data supply for hardware\naccelerators with prefetching and access/execute decoupling. In 2016\n49th Annual IEEE/ACM International Symposium on Microarchitecture\n(MICRO). IEEE, 1–12.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n[13] Xinyu Chen, Hongshi Tan, Yao Chen, Bingsheng He, Weng-Fai Wong,\nand Deming Chen. 2021. ThunderGP: HLS-based Graph Processing\nFramework on FPGAs. In The 2021 ACM/SIGDA International Sympo-\nsium on Field-Programmable Gate Arrays (Virtual Event, USA) (FPGA\n’21). Association for Computing Machinery, New York, NY, USA, 69–80.\ndoi:10.1145/3431920.3439290\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[14] Jianyi Cheng. 2019. HLS_Benchmarks. doi:10.5281/zenodo.3561115\n[15] Shaoyi Cheng and John Wawrzynek. 2014. Architectural synthesis\nof computational pipelines with decoupled memory access. In 2014\nInternational Conference on Field-Programmable Technology (FPT). 83–\n90. doi:10.1109/FPT.2014.7082758\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[16] Eric Chung, Jeremy Fowers, Kalin Ovtcharov, Michael Papamichael,\nAdrian Caulfield, Todd Massengill, Ming Liu, Mahdi Ghandi, Daniel Lo,\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.1**l== 0.6**r== 0.1**\nSteve Reinhardt, Shlomi Alkalay, Hari Angepat, Derek Chiou, Alessan-\ndro Forin, Doug Burger, Lisa Woods, Gabriel Weisz, Michael Hasel-\nman, and Dan Zhang. 2018. Serving DNNs in Real Time at Datacen-\nter Scale with Project Brainwave.\nIEEE Micro 38 (March 2018), 8–\n20. https://www.microsoft.com/en-us/research/publication/serving-\ndnns-real-time-datacenter-scale-project-brainwave/\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\n[17] Neal C. Crago, Sana Damani, Karthikeyan Sankaralingam, and\nStephen W. Keckler. 2024. WASP: Exploiting GPU Pipeline Paral-\nlelism with Hardware-Accelerated Automatic Warp Specialization. In\n2024 IEEE International Symposium on High-Performance Computer\nArchitecture (HPCA). 1–16. doi:10.1109/HPCA57654.2024.00086\n[18] Neal Clayton Crago and Sanjay Jeram Patel. 2011. OUTRIDER: efficient\nmemory latency tolerance with decoupled strands. SIGARCH Comput.\nArchit. News 39, 3 (jun 2011), 117–128. doi:10.1145/2024723.2000079\n[19] Ahmed ElTantawy and Tor M. Aamodt. 2016. MIMD synchronization\non SIMT architectures. In The 49th Annual IEEE/ACM International\nSymposium on Microarchitecture (Taipei, Taiwan) (MICRO-49). IEEE\nPress, Article 11, 14 pages.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[20] Zhihua Fan, Wenming Li, Shengzhong Tang, Xuejun An, Xiaochun Ye,\nand Dongrui Fan. 2023. Improving utilization of dataflow architectures\nthrough software and hardware co-design. In European Conference on\nParallel Processing. Springer, 245–259.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[21] Shane T. Fleming and David B. Thomas. 2017. Using Runahead Ex-\necution to Hide Memory Latency in High Level Synthesis. In 2017\nInternational Symposium on Field-Programmable Custom Computing\nMachines (FCCM). 109–116. doi:10.1109/FCCM.2017.33\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[22] Hagen Gädke and Andreas Koch. 2008. Accelerating Speculative Exe-\ncution in High-Level Synthesis with Cancel Tokens. In Reconfigurable\nComputing: Architectures, Tools and Applications, Roger Woods, Kather-\nine Compton, Christos Bouganis, and Pedro C. Diniz (Eds.). Springer\nBerlin Heidelberg, Berlin, Heidelberg, 185–195.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[23] Jean-Michel Gorius, Simon Rokicki, and Steven Derrien. 2024. A\nUnified Memory Dependency Framework for Speculative High-Level\nSynthesis. In Proceedings of the 33rd ACM SIGPLAN International Con-\nference on Compiler Construction (Edinburgh, United Kingdom) (CC\n2024). Association for Computing Machinery, New York, NY, USA,\n13–25. doi:10.1145/3640537.3641581\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[24] Tae Jun Ham, Juan L. Aragón, and Margaret Martonosi. 2015. DeSC:\ndecoupled supply-compute communication management for hetero-\ngeneous architectures. In Proceedings of the 48th International Sym-\nposium on Microarchitecture (Waikiki, Hawaii) (MICRO-48). Asso-\nciation for Computing Machinery, New York, NY, USA, 191–203.\ndoi:10.1145/2830772.2830800\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\n[25] Tae Jun Ham, Juan L. Aragón, and Margaret Martonosi. 2017. Decou-\npling Data Supply from Computation for Latency-Tolerant Commu-\nnication in Heterogeneous Architectures. ACM Trans. Archit. Code\nOptim. 14, 2, Article 16 (jun 2017), 27 pages. doi:10.1145/3075620\n[26] John L. Hennessy and David A. Patterson. 2019. A New Golden Age for\nComputer Architecture. Commun. ACM (2019). doi:10.1145/3282307\n[27] Tu Hong, Ning Guan, Chen Yin, Qin Wang, Jianfei Jiang, Jing Jin,\nGuanghui He, and Naifeng Jing. 2020. Decoupling the multi-rate\ndataflow execution in coarse-grained reconfigurable array. In 2020\nIEEE International Symposium on Circuits and Systems (ISCAS). IEEE.\n[28] Mike Hutton, Jay Schleicher, David Lewis, Bruce Pedersen, Richard\nYuan, Sinan Kaptanoglu, Gregg Baeckler, Boris Ratchev, Ketan Padalia,\nMark Bourgeault, Andy Lee, Henry Kim, and Rahul Saini. 2004. Im-\nproving FPGA Performance and Area Using an Adaptive Logic Module.\nIn Field Programmable Logic and Application, Jürgen Becker, Marco\nPlatzner, and Serge Vernalde (Eds.). Springer Berlin Heidelberg, Berlin,\nHeidelberg, 135–144.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[29] Intel. [n. d.]. Intel/LLVM. https://github.com/intel/llvm/tree/sycl\n[30] Lana Josipovic, Andrea Guerrieri, and Paolo Ienne. 2019. Speculative\nDataflow Circuits. In Proceedings of the 2019 ACM/SIGDA International\nSymposium on Field-Programmable Gate Arrays. ACM, 162–171. doi:10.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[31] Lana Josipović, Andrea Guerrieri, and Paolo Ienne. 2022. From C/C++\nCode to High-Performance Dataflow Circuits. IEEE Transactions on\nComputer-Aided Design of Integrated Circuits and Systems (2022). doi:10.\n1109/TCAD.2021.3105574\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[32] Adam Levinthal and Thomas Porter. 1984. Chap - a SIMD graphics\nprocessor. In Proceedings of the 11th Annual Conference on Computer\nGraphics and Interactive Techniques (SIGGRAPH ’84). Association for\nComputing Machinery, New York, NY, USA, 77–82. doi:10.1145/800031.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[33] Feng Liu, Soumyadeep Ghosh, Nick P. Johnson, and David I. August.\n2014. CGPA: Coarse-Grained Pipelined Accelerators. In Proceedings\nof the 51st Annual Design Automation Conference (San Francisco, CA,\nUSA) (DAC ’14). Association for Computing Machinery, New York, NY,\nUSA, 1–6. doi:10.1145/2593069.2593105\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n[34] Jiantao Liu, Carmine Rizzi, and Lana Josipović. 2022. Load-Store\nQueue Sizing for Efficient Dataflow Circuits. In 2022 International\nConference on Field-Programmable Technology (ICFPT). 1–9. doi:10.\n1109/ICFPT56656.2022.9974425\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n[35] Scott A. Mahlke, William Y. Chen, Wen-mei W. Hwu, B. Ramakrishna\nRau, and Michael S. Schlansker. 1992. Sentinel scheduling for VLIW\nand superscalar processors. SIGPLAN Not. 27, 9 (sep 1992), 238–247.\ndoi:10.1145/143371.143529\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[36] Ajeya Naithani, Jaime Roelandts, Sam Ainsworth, Timothy M. Jones,\nand Lieven Eeckhout. 2023. Decoupled Vector Runahead. In Proceedings\nof the 56th Annual IEEE/ACM International Symposium on Microarchi-\ntecture (Toronto, ON, Canada) (MICRO ’23). Association for Computing\nMachinery, New York, NY, USA, 17–31. doi:10.1145/3613424.3614255\n[37] Quan M. Nguyen and Daniel Sanchez. 2021. Fifer: Practical Acceler-\nation of Irregular Applications on Reconfigurable Architectures. In\nMICRO-54: 54th Annual IEEE/ACM International Symposium on Mi-\ncroarchitecture (Virtual Event, Greece) (MICRO ’21). Association for\nComputing Machinery, New York, NY, USA, 1064–1077. doi:10.1145/\n3466752.3480048\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[38] Quan M. Nguyen and Daniel Sanchez. 2023. Phloem: Automatic Ac-\nceleration of Irregular Applications with Fine-Grain Pipeline Paral-\nlelism. In 2023 IEEE International Symposium on High-Performance\nComputer Architecture (HPCA). 1262–1274. doi:10.1109/HPCA56546.\n2023.10071026\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[39] Tony Nowatzki, Vinay Gangadhar, Newsha Ardalani, and Karthikeyan\nSankaralingam. 2017. Stream-dataflow acceleration. In Proceedings of\nthe 44th Annual International Symposium on Computer Architecture.\n416–429.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[40] Karl J. Ottenstein, Robert A. Ballance, and Arthur B. Maccabe. 1990.\nThe program dependence web: a representation supporting control-,\ndata-, and demand-driven interpretation of imperative languages. In\nPLDI ’90.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n[41] G. Ottoni, R. Rangan, A. Stoler, and D.I. August. 2005. Automatic\nthread extraction with decoupled software pipelining. In 38th Annual\nIEEE/ACM International Symposium on Microarchitecture (MICRO’05).\n12 pp.–118. doi:10.1109/MICRO.2005.13\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[42] Joseph CH Park and Mike Schlansker. 1991. On predicated execution.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nHewlett-Packard Laboratories Palo Alto, California.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[43] Michael Pellauer, Yakun Sophia Shao, Jason Clemons, Neal Crago,\nKartik Hegde, Rangharajan Venkatesan, Stephen W Keckler, Christo-\npher W Fletcher, and Joel Emer. 2019. Buffets: An efficient and com-\nposable storage idiom for explicit decoupled data orchestration. In\nProceedings of the Twenty-Fourth International Conference on Archi-\ntectural Support for Programming Languages and Operating Systems.\n137–151.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[44] W. W. Peterson, T. Kasami, and N. Tokura. 1973. On the capabilities of\nwhile, repeat, and exit statements. Commun. ACM 16, 8 (Aug. 1973),\n503–512. doi:10.1145/355609.362337\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.1**l== 0.5**r== 0.2**\n[45] Raghu Prabhakar and Sumti Jairath. 2021.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.1**l== 0.6**r== 0.1**\nSambaNova SN10\nRDU:Accelerating Software 2.0 with Dataflow. In 2021 IEEE Hot Chips.\n1–37. doi:10.1109/HCS52781.2021.9567250\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[46] Raghu Prabhakar, Yaqi Zhang, David Koeplinger, Matt Feldman, Tian\nZhao, Stefan Hadjis, Ardavan Pedram, Christos Kozyrakis, and Kunle\nOlukotun. 2017. Plasticine: A Reconfigurable Architecture For Parallel\nPaterns. In Proceedings of the 44th Annual International Symposium on\nComputer Architecture (Toronto, ON, Canada) (ISCA ’17). Association\nfor Computing Machinery, New York, NY, USA, 389–402. doi:10.1145/\n3079856.3080256\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[47] Shantian Qin, Wenming Li, Zhihua Fan, Zhen Wang, Tianyu Liu,\nHaibin Wu, Kunming Zhang, Xuejun An, Xiaochun Ye, and Dongrui\nFan. 2023. ROMA: A Reconfigurable On-chip Memory Architecture for\nMulti-core Accelerators. In 2023 IEEE International Conference on High\nPerformance Computing & Communications, Data Science & Systems,\nSmart City & Dependability in Sensor, Cloud & Big Data Systems &\nApplication. IEEE, 49–57.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[48] Parthasarathy Ranganathan, Daniel Stodolsky, Jeff Calow, Jeremy\nDorfman, Marisabel Guevara, Clinton Wills Smullen IV, Aki Kuusela,\nRaghu Balasubramanian, Sandeep Bhatia, Prakash Chauhan, et al. 2021.\nWarehouse-scale video acceleration: co-design and deployment in the\nwild. In Proceedings of the 26th ACM International Conference on Archi-\ntectural Support for Programming Languages and Operating Systems.\n600–615.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[49] Fabrice Rastello. 2016. SSA-based Compiler Design (1st ed.). Springer\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.4**l== 0.6**r== 0.2**\nPublishing Company, Incorporated.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[50] B. Ramakrishna Rau. 1994. Iterative modulo Scheduling: An Algorithm\nfor Software Pipelining Loops. In Proceedings of the 27th Annual Inter-\nnational Symposium on Microarchitecture. doi:10.1145/192724.192731\n[51] James E. Smith. 1982. Decoupled Access/Execute Computer Archi-\ntectures. In Proceedings of the 9th Annual Symposium on Computer\nArchitecture (Austin, Texas, USA) (ISCA ’82). IEEE Computer Society\nPress, Washington, DC, USA, 112–119.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[52] Robert Szafarczyk. 2025. Compiler Support for Speculation in Decoupled\nAccess/Execute Architectures - code & evaluation. doi:10.5281/zenodo.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[53] Robert Szafarczyk, Syed Waqar Nabi, and Wim Vanderbauwhede.\n2023. Compiler Discovered Dynamic Scheduling of Irregular Code in\nHigh-Level Synthesis. In 2023 33rd International Conference on Field-\nProgrammable Logic and Applications (FPL). 1–9. doi:10.1109/FPL60245.\n2023.00009\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[54] Robert Szafarczyk, Syed Waqar Nabi, and Wim Vanderbauwhede. 2023.\nA High-Frequency Load-Store Queue with Speculative Allocations\nfor High-Level Synthesis. In 2023 International Conference on Field\nProgrammable Technology (ICFPT). 115–124. doi:10.1109/ICFPT59805.\n2023.00018\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[55] Robert Szafarczyk, Syed Waqar Nabi, and Wim Vanderbauwhede. 2025.\nDynamic Loop Fusion in High-Level Synthesis. In Proceedings of the\n2025 ACM/SIGDA International Symposium on Field Programmable Gate\nArrays (Monterey, CA, USA) (FPGA ’25). Association for Computing\nMachinery, New York, NY, USA. doi:10.1145/3706628.3708871\n[56] Benjamin Thielmann, Jens Huthmann, and Andreas Koch. 2012.\nMemory Latency Hiding by Load Value Speculation for Reconfig-\nurable Computers. ACM Trans. Reconfigurable Technol. Syst. (2012).\ndoi:10.1145/2362374.2362377\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[57] N. Topham, A. Rawsthorne, C. McLean, M. Mewissen, and P. Bird.\n1995. Compiling and Optimizing for Decoupled Architectures. In\nSupercomputing ’95:Proceedings of the 1995 ACM/IEEE Conference on\nSupercomputing. 40–40. doi:10.1145/224170.224301\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[58] Neil Vachharajani, Ram Rangan, Easwaran Raman, Matthew J. Bridges,\nGuilherme Ottoni, and David I. August. 2007. Speculative Decou-\npled Software Pipelining. In 16th International Conference on Par-\nallel Architecture and Compilation Techniques (PACT 2007). 49–59.\ndoi:10.1109/PACT.2007.4336199\n**BLOCK**fs== 8.0**p== 12.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\n[59] Zhengrong Wang and Tony Nowatzki. 2019. Stream-based Memory Ac-\ncess Specialization for General Purpose Processors. In 2019 ACM/IEEE\n46th Annual International Symposium on Computer Architecture (ISCA).\n736–749.\n**BLOCK**fs== 8.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[60] Jian Weng, Sihao Liu, Vidushi Dadu, Zhengrong Wang, Preyas Shah,\nand Tony Nowatzki. 2020. DSAGEN: Synthesizing Programmable Spa-\ntial Accelerators. In 2020 ACM/IEEE 47th Annual International Sympo-\nsium on Computer Architecture (ISCA). 268–281. doi:10.1109/ISCA45697.\n2020.00032\n**BLOCK**fs== 8.0**p== 12.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[61] Dhananjaya Wijerathne, Zhaoying Li, Manupa Karunarathne, Anuj\nPathania, and Tulika Mitra. 2019. CASCADE: High Throughput Data\nStreaming via Decoupled Access-Execute CGRA. ACM Trans. Embed.\nComput. Syst. 18, 5s, Article 50 (Oct. 2019), 26 pages. doi:10.1145/\n**BLOCK**fs== 8.0**p== 12.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[62] Zeping Xue and David B. Thomas. 2016. SynADT: Dynamic Data\nStructures in High Level Synthesis. In 2016 IEEE 24th Annual Interna-\ntional Symposium on Field-Programmable Custom Computing Machines\n(FCCM). 64–71. doi:10.1109/FCCM.2016.26\n**BLOCK**fs== 9.0**p== 12.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nReceived 2024-11-12; accepted 2024-12-21",
         "Compiler Support for Speculation in Decoupled Access/Execute Architectures Syed Waqar Nabi University of Glasgow Glasgow, United Kingdom syed.nabi@glasgow.ac.uk Robert Szafarczyk University of Glasgow Glasgow, United Kingdom robert.szafarczyk@glasgow.ac.uk Wim Vanderbauwhede University of Glasgow Glasgow, United Kingdom wim.vanderbauwhede@glasgow.ac.uk Abstract Irregular codes are bottlenecked by memory and communi- cation latency. Decoupled access/execute (DAE) is a common technique to tackle this problem. It relies on the compiler to separate memory address generation from the rest of the program, however, such a separation is not always possible due to control and data dependencies between the access and execute slices, resulting in a loss of decoupling. In this paper, we present compiler support for speculation in DAE architectures that preserves decoupling in the face of control dependencies. We speculate memory requests in the access slice and poison mis-speculations in the execute slice without the need for replays or synchronization. Our transformation works on arbitrary, reducible control flow and is proven to preserve sequential consistency. We show that our approach applies to a wide range of architectural work on CPU/GPU prefetchers, CGRAs, and accelerators, enabling DAE on a wider range of codes than before. CCS Concepts: • Hardware → Emerging languages and compilers; • Software and its engineering → Compilers. Keywords: decoupled access/execute; compiler speculation 1 Introduction Irregular codes are characterized by data-dependent memory accesses and control flow, for example: Figure 1. A decoupled access/execute architecture template. This code has unpredictable control flow that causes frequent branch mis-predictions on CPUs and thread divergence on GPUs. Because of these limitations, and challenges with Moore’s Law and Dennard performance scaling, computer architects are interested in adding CPU/GPU structures to accelerate such code patterns, or even to use accelerators specialized for a given algorithm [26]. Many of the proposed architectures follow the decades-old idea of a Decoupled Access/Execute (DAE) architecture shown in Figure 1. In DAE, memory accesses are decoupled from computation to avoid stalls resulting from unpredictable loads [51]. The address generation unit (AGU) sends load and store requests to the data unit (DU), while the DU sends load values to and receives store values from the compute unit (CU). All communication is FIFO based and ideally the AGU to DU communication is one-directional, allowing the Figure 2. Comparison of a decoupled and non-decoupled address generation. Non-decoupled address generation re- sults in a later arrival of the store address, which stalls the RAW check for the next load, lowering load throughput. address streams from the AGU to run ahead w.r.t the CU. Figure 1a shows an example of such a DAE architecture implementing the earlier code snippet. DAE is a general technique applicable to many computa- tional models: it is used in specialized FPGA accelerators gen- erated from High-Level Synthesis (HLS) [11–13, 15, 16, 21, 54, 55]; in Coarse Grain Reconfigurable Architectures (CGRAs) [20, 27, 37, 39, 43, 45, 46, 61]; and in CPU/GPU prefetchers [3, 5, 17, 18, 24, 38, 47, 59]. For example, NVIDIA introduced hardware-accelerated asynchronous memory copies [3]. The CUDA programmer can provide a “copy descriptor” of a ten- sor to copy and the hardware will run ahead and generate the corresponding addresses in a Tensor Memory Unit. The common denominator of all these works is that they rely on either the programmer or the compiler to decouple address-generating instructions from the rest of the program. However, it has long been recognized that such a decoupling is not always possible [9, 57]. If any of the address-generating instructions for array A depend on a value loaded from A, then there is a loss-of-decoupling (LoD) [25]. Access patterns such as A[f(A[i])] are rare, but control dependencies that involve loads from A are common. For example, consider replacing C[i] with A[i] in our running example: Here, there is a LoD, because the A store is control-dependent on a branch that loads from A. Whereas before the load from C could be prefetched, now the AGU/DU communication is synchronized, because the AGU waits for A values from the DU before deciding if a store address should be generated, as shown in Figure 1b. In turn, the load waits for the store address to ensure that there is no aliasing—the store address is needed for memory disambiguation. As a result, the AGU cannot run ahead of the CU anymore, resulting in decreased pipeline parallelism, which Figure 2 illustrates. One approach for restoring decoupling in this case is con- trol speculation. As shown in Figure 1c, we can hoist the store request out of the if -condition in the AGU (specula- tion), and later poison the store in the CU on mis-speculation (store invalidation). However, it is unclear how the compiler should coordinate the speculation and recovery transfor- mations across two distinct control-flow graphs. While the example from Figure 1c is trivial, the task quickly becomes complicated with more speculated stores and nested control flow, as we demonstrate in the next section. The key chal- lenge here is to guarantee that the order of store requests sent from the AGU matches the order of store values or kill signals sent from the CU on all control-flow paths. General compiler support for speculated stores in DAE architectures is an open question that we tackle in this paper, making the following contributions: • We give a formal description of the fundamental rea- sons why address generation cannot always be decou- pled from the rest of the program (§4). • We describe compiler support for speculative memory in DAE architectures, solving the LoD problem due to control dependencies. We propose two algorithms: one for speculating memory requests in the AGU, and one for poisoning mis-speculations in the CU (§5). • We prove that our speculation approach preserves the sequential consistency of the original program and does not introduce deadlocks (§6). • We show that our work enables DAE on a wider class of codes than before, with applications in CPU/GPU prefetchers, CGRAs, and FPGA accelerators. • We evaluate our DAE speculation approach on accel- erators generated from HLS implementing codes from the graph and data analytics domain. We achieve an average 1.9× (up to 3×) speedup over the baseline HLS implementations. We show that our approach has no mis-speculation penalty and minimal code size impact (average accelerator area increase < 5%) (§8). 2 Motivating Example In this brief section, we show why an obvious approach to speculation in DAE architectures is incorrect. The FIFO-based nature of DAE requires that the order of memory requests (speculative or not) generated in the AGU matches exactly the order of load/store values (poisoned or not) in the CU. The motivating example in Figure 1c contains just one speculative store and one path through the compute CFG where the speculation becomes unreachable, making the problem of ordering trivial in that case. Consider the more complex code in Figure 3a with three stores 𝑠0, 𝑠1, and 𝑠2. Speculating all store requests in the AGU might result in the store request order (𝑠2, 𝑠0, 𝑠1). In the CU, we need to guarantee the same order of corresponding store values (poisoned or not) on every possible control-flow path through the loop. Unfortunately, the obvious approach that worked for the trivial example in Figure 1c does not work Figure 3. Poisoning speculated stores immediately when they become unreachable results in an ordering mismatch between AGU store requests from and CU store values. here. If we poison values at points where the corresponding speculation becomes unreachable, as illustrated in Figure 3b, then we end up with three possible orderings of store values depending on the CFG path in the CU, but only one of the orderings is correct. This is why any previous implemen- tations of speculative stores in DAE architectures has only considered trivial triangle or diamond shaped CFGs [24], like the one in Figure 1c. Generalized compiler support for store speculation that guarantees the correct order of poisoning is the key challenge that we solve in this paper. 3 Background In this section, we describe the architectural support needed to enable speculative DAE and some compiler preliminaries. Our speculation technique requires architectural support for predicated stores and FIFOs. Store values are tagged with a poison bit that, when set, causes the corresponding store request to be dropped in the DU without committing a store. We say that a store request gets killed (or poisoned) if its corresponding store value has the poison bit set. This is a lightweight form of speculation that does not require replays in the CU and does not result in out-of-bounds stores, be- cause mis-speculated stores are never committed. Speculative loads can be supported by simply discarding the value of a mis-speculated load. Predicated stores are easy to support in hardware since the underlying memory protocol usually already uses a valid signal. For example, the commonly used AXI4 interface [4] has a strobe signal to indicate which bytes are valid. Architectural FIFOs (queues) are also commonly added in works on CPU/GPU microarchitecture or can be relatively cheaply implemented in software. For example, works on DAE CPU/GPU prefetchers add architectural FIFOs and ex- tend the ISA with instructions for producing load/store ad- dresses and consuming/producing store values [3, 5, 17, 18, 24, 38, 47]. The prefetcher from [24] enables predicated stores with a store_inv instruction, but the authors support only simple triangle or diamond control flow patterns, calling for future work on general speculation support. We discuss concrete ex- amples of architectures that can benefit from our work in §7. We evaluate our work on accelerators generated from HLS, where we have complete control of the memory interfaces. We use an SSA-based compiler representation and associated analyses [49]. In particular, we use the control-flow graph and dominator tree to calculate control dependencies [40], and we use the SSA def-use chain for data dependencies. We use a canonical loop representation: loops have a sin- gle header block and a single loop backedge going from the loop latch to the loop header. Our transformation assumes re- ducible control flow—CFG edges can be partitioned into two disjoint sets, forward and back edges, such that the forward edges form a directed acyclic graph (DAG). Irreducible con- trol flow can be made reducible with node splitting [7, 44]. For completeness, we briefly describe how our compiler implements a DAE architecture: 1. AGU: For each memory operation to be decoupled, we change it to a send_ld_addr or a send_st_addr function that sends the memory address to the DU. 2. CU: Dually, in the CU we change each decoupled mem- ory operation to a consume_val or produce_val func- tion that receives or sends values to or from the DU. 3. Dead Code Elimination: We run a standard DCE pass in the CU to remove the now unnecessary address generation code. In the AGU, we delete all side effect instructions that are not part of the address generation def-use chains, and then also run a standard DCE pass. We also use a control-flow simplification pass that removes empty blocks potentially created by DCE. The send_ld_addr, send_st_addr, consume_val, and produce_val functions are implementation dependent. For example, if we target CPU/GPU prefetchers, such as [17, 24], then these would translate to instructions. For accelerators, they would be translated to FIFO writes/reads. 4 Loss-of-Decoupling Analysis LoD events arise when the address generation for a given memory access depends on a load that cannot be trivially prefetched, causing the AGU, DU, and CU communication to be synchronized. By non-trivially prefetched we mean loads that have a RAW hazards, i.e., the DU needs to receive all previous store addresses in program order to perform memory disambiguation before executing the load. Given a set of address-generating instructions 𝐺, and a set of memory load instructions 𝐴 using addresses generated by instructions in 𝐺, there is a loss of decoupling if: Definition 4.1 (LoD Data Dependency). There exists a path in the def-use chain from 𝑎 ∈ 𝐴 to 𝑔 ∈ 𝐺. While en- countering a 𝜙-node on the def-use chain leading to 𝑔, we also trace the def-use paths of the terminator instructions 𝑇 in the 𝜙-node incoming basic blocks to see if any terminator instruction in 𝑇 depends on any 𝑎 ∈ 𝐴. Definition 4.2 (LoD Control Dependency). There exists an instruction 𝑔 ∈ 𝐺 that is control-dependent on a branch instruction 𝑏, and there is a path in the def-use chain from 𝑎 ∈ 𝐴 to 𝑏. We call the basic block that contains 𝑏 the LoD control dependency source. Note that the LoD control dependency source need not be the immediate control dependency of 𝑔, and that 𝑔 might have multiple LoD control dependencies. Depending on the hardware context, the definition of the 𝐴 set can be expanded or narrowed. For example, if the AGU is implemented in hardware with limited control flow support, then 𝐴 could include all branch instructions. On the other hand, given an address generating instruction, we could limit 𝐴 to only include loads from the same array for which the given address is generated—this could be useful if we only want to preserve decoupling for that array and do not care about losing decoupling for other arrays. Our speculation technique applies equally well to all these definitions. An example of a LoD data dependency is the A[f(A[i])] access. Our speculation approach does not recover decou- pling for such cases, but fortunately such accesses are rare. An example of a more common LoD data dependency is the code pattern if (A[i]) A[i++] = 1. In this case, the def-use chain leading to the definition of the store address contains a 𝜙-node (i) whose value depends on loading from 𝐴. Such a pattern is sometimes found in algorithms that operate on dy- namically growing data structures, e.g. queues or stacks. Our speculation technique does not work on such cases either, but this is not a large limitation, since performance oriented codes typically do not use dynamically growing structures, instead opting for implementations with bounded space re- quirements that can be allocated statically [62]. An example of LoD due to a control dependency is shown in Figure 1b. This case is much more common than a direct data dependency and is the focus of this paper. Algorithm 1 Control-flow hoisting of AGU requests 1: Input: 𝑠𝑟𝑐𝐵𝑙𝑜𝑐𝑘𝑠 list of blocks that are the source of a LoD control dependency (defined in §4) 2: Output: 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 { basic block: list of hoisted re- quests to this block } 3: 4: for 𝑠𝑟𝑐𝐵𝐵 ∈ 𝑠𝑟𝑐𝐵𝑙𝑜𝑐𝑘𝑠 do 5: 6: ⊲ traverse the DAG from 𝑠𝑟𝑐𝐵𝐵 to the loop latch for 𝑓 𝑟𝑜𝑚𝐵𝐵 ∈ 𝑟𝑒𝑣𝑒𝑟𝑠𝑒𝑃𝑜𝑠𝑡𝑂𝑟𝑑𝑒𝑟 (𝑠𝑟𝑐𝐵𝐵) do if 𝑓 𝑟𝑜𝑚𝐵𝐵 contains memory requests then hoist 𝑓 𝑟𝑜𝑚𝐵𝐵 requests to the end of 𝑠𝑟𝑐𝐵𝐵 add requests to 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 [𝑠𝑟𝑐𝐵𝐵] 5 Compiler Support for Speculation We now describe our dual transformations that enable spec- ulation in the AGU and poison mis-speculations in the CU. Algorithm 1 describes our approach to introducing specu- lation in the AGU. Given a LoD control dependency source block 𝑠𝑟𝑐𝐵𝐵 we hoist all memory requests that are control de- pendent on 𝑠𝑟𝑐𝐵𝐵 to the end of 𝑠𝑟𝑐𝐵𝐵. There can be multiple blocks with memory requests that have a LoD control depen- dency on 𝑠𝑟𝑐𝐵𝐵, which poses the question in which order should they be hoisted to 𝑠𝑟𝑐𝐵𝐵. We use reverse post-order in Algorithm 1. Assuming reducible control flow, the CFG region from 𝑠𝑟𝑐𝐵𝐵 to the loop latch is a DAG. The reverse post-order of a DAG is its topological order. Topological ordering gives us the useful property that given two distinct basic blocks 𝐴 and 𝐵 in a given loop, if 𝐴 ≺ 𝐵 in any path through the loop then 𝐴 ≺ 𝐵 in the topological ordering. Note that there can be multiple topological orderings for a DAG, but it does not matter which one is chosen in our algorithm. Algorithm 1 traverses the CFG region from 𝑠𝑟𝑐𝐵𝐵 to the end of its loop (or to the end of the function if 𝑠𝑟𝑐𝐵𝐵 is not in a loop). During the traversal, we ignore CFG edges leading to loop headers—we do not enter loops other than the innermost loop containing 𝑠𝑟𝑐𝐵𝐵. 5.1.1 Example of Hoisting. Consider the CFG from Fig- ure 4a. There are three LoD control dependency source blocks (2, 3, 5) and five blocks with memory requests (blocks 2, 4, 5, 6, 7 with requests 𝑎, 𝑐, 𝑏, 𝑑, 𝑒, respectively). Assume that each block holds a single memory request—multiple memory requests within the same block are treated in the same way by our algorithms. Figure 4c shows the topological order of the loop (block 1 is omitted for brevity). Algorithm 1 will hoist 𝑏, 𝑒 to the end of block 2, and 𝑐, 𝑑, 𝑒 to the end of block 3—the result is presented in Figure 4b. Note that the requests 𝑏 and 𝑒 were hoisted to both block 2 and 3, because they are reachable from both blocks. Nothing is hoisted to block 1 since it is not a LoD control dependency source. Figure 4. An example of introducing speculative memory requests in the AGU (§5.1); and poisoned stores in the CU (§5.2). Block 6 in subfigure (d) kills stores c, b, then uses the allocation for store d, and then kills store e. 5.1.2 Nested LoD Control Dependencies. Block 5 in Figure 4b does not contain any speculative requests because it itself has a LoD control dependency on block 2 and 3. Algorithm 1 considers only LoD control dependency source blocks that are not themselves the destination of another LoD control dependency. Given a chain of nested LoD control dependencies, we only consider the chain head. For example, the Figure 4a CFG has two LoD control dependency chains: 2, 5 and 3, 5—Algorithm 1 considers only blocks 2 and 3. Algorithm 2 Mapping Poison Stores to CFG Edges in CU 1: Input: 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 { basic block: list of requests hoisted to this block in Algorithm 1 } for 𝑝𝑎𝑡ℎ ∈ 𝑎𝑙𝑙𝑃𝑎𝑡ℎ𝑠𝑇𝑜𝐿𝑜𝑜𝑝𝐿𝑎𝑡𝑐ℎ(𝑠𝑝𝑒𝑐𝐵𝐵) do 2: 3: for 𝑠𝑝𝑒𝑐𝐵𝐵, 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 ∈ 𝑆𝑝𝑒𝑐𝑅𝑒𝑞𝑀𝑎𝑝 do 4: 5: 6: 7: 8: 𝑡𝑟𝑢𝑒𝐵𝐵 ← block where 𝑟 is true 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠.𝑖𝑛𝑠𝑒𝑟𝑡 (𝑡𝑟𝑢𝑒𝐵𝐵) 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 ← ∅ for 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 do ⊲ set keeps insertion order 5.1.3 Why Topological Order in Algorithm 1? Topo- logical order is needed to make it possible to match the order of speculative requests made in the AGU with the order of values that will arrive from the CU on all its possible CFG paths. Consider, for example, the requests 𝑏 and 𝑐 in Fig- ure 4a. We first want to hoist 𝑐 to block 3 before hoisting 𝑏, because there exists a CFG path where 𝑐 comes before 𝑏, but not vice versa. If 𝑏 were hoisted before 𝑐, then the speculative requests order would be 𝑏 ≺ 𝑐, which would be impossible to match with values in the CU on the CFG path 3, 5, 7. for 𝑒𝑑𝑔𝑒 ∈ 𝑝𝑎𝑡ℎ do for 𝑡𝑟𝑢𝑒𝐵𝐵 ∈ 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 do if 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 = 𝑡𝑟𝑢𝑒𝐵𝐵 then ⊲ to the next edge if 𝑡𝑟𝑢𝑒𝐵𝐵 not reachable from 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 then ⊲ reachability ignores loop backedges poison 𝑡𝑟𝑢𝑒𝐵𝐵 requests on 𝑒𝑑𝑔𝑒 ⊲ Alg. 3 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠.𝑟𝑒𝑚𝑜𝑣𝑒 (𝑡𝑟𝑢𝑒𝐵𝐵) Our strategy for poisoning misspeculations in the CU is to first map a poison call to a CFG edge, and then to map that edge to a poison store call contained in an existing or newly created basic block. Algorithm 2 describes the first step. Given block 𝑠𝑝𝑒𝑐𝐵𝐵 that contains speculative memory requests 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠, we consider each path in the DAG from the 𝑠𝑝𝑒𝑐𝐵𝐵 to the loop latch (or function exit) in the CU. We call the block where a 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠 becomes true the 𝑡𝑟𝑢𝑒𝐵𝐵 (for example, the 𝑡𝑟𝑢𝑒𝐵𝐵 for request 𝑏 in Figure 4a is block 5). For each CFG path, we use the 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 list to keep track of which requests were already used or poisoned on the path—the list contains the 𝑡𝑟𝑢𝑒𝐵𝐵 for each 𝑟 ∈ 𝑠𝑝𝑒𝑐𝑅𝑒𝑞𝑢𝑒𝑠𝑡𝑠. Given an edge in the traversal, the edge is skipped if the next 𝑡𝑟𝑢𝑒𝐵𝐵 ∈ 𝑡𝑟𝑢𝑒𝐵𝑙𝑜𝑐𝑘𝑠 is still reachable from 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . This guarantees that the order of speculative requests in the AGU matches the order of values in the CU, i.e., a speculative request for a given 𝑡𝑟𝑢𝑒𝐵𝐵 block is not poisoned immedi- ately when 𝑡𝑟𝑢𝑒𝐵𝐵 becomes unreachable if there is an earlier speculative request that can still be used. 5.2.1 Example of Mapping Poison Stores to CFG Edges. Figure 4c shows which CFG edges are poisoned given the original CFG in Figure 4a and the AGU CFG in Figure 4b. For Algorithm 3 Poisoning Stores on Edges in CU 1: Input: store request 𝑟 ; CFG 𝑒𝑑𝑔𝑒; block 𝑠𝑝𝑒𝑐𝐵𝐵 where 𝑟 was speculated; block 𝑡𝑟𝑢𝑒𝐵𝐵 where 𝑟 is true ⊲ preserve set across calls get from 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒 if exists 2: 3: 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒 ← ∅ 4: if 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 is reachable from 𝑡𝑟𝑢𝑒𝐵𝐵 then 5: 6: 7: 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 ← create new block on 𝑒𝑑𝑔𝑒 or append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the end of 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝑙𝑜𝑐𝑘𝑅𝑒𝑢𝑠𝑒.𝑖𝑛𝑠𝑒𝑟𝑡 (𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵) 8: 9: else if 𝑠𝑝𝑒𝑐𝐵𝐵 does not dominate 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 then 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 ← create new block on 𝑒𝑑𝑔𝑒 10: append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the end of 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 11: 12: 13: create 𝜙 (1, 𝑠𝑝𝑒𝑐𝐵𝐵) value in 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 branch from 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 on 𝜙 = 1 ⊲ create recursively on 𝑠𝑝𝑒𝑐𝐵𝐵 → 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 paths append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to the start of 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 example, the path 3 → 5 → 𝐿 will have: 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) on the 3 → 5 edge; and 𝑝𝑜𝑖𝑠𝑜𝑛(𝑑), 𝑝𝑜𝑖𝑠𝑜𝑛(𝑒) on the 5 → 𝐿 edge (4th path from block 3 in Figure 4c). 5.2.2 Mapping Poisoned Edges to Basic Blocks. Algo- rithm 3 shows how poisoned CFG edges are mapped to actual poison calls placed in a concrete basic block. Given a poi- soned request 𝑟 on 𝑒𝑑𝑔𝑒 (from 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 block to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 block), the 𝑠𝑝𝑒𝑐𝐵𝐵 block where 𝑟 was speculated in the AGU, and 𝑡𝑟𝑢𝑒𝐵𝐵 where r becomes true there are three cases: 1. There exists a path from 𝑡𝑟𝑢𝑒𝐵𝐵 to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . In this case, we cannot insert 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) in 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , because we would end up with a CFG path where the store is both true and poisoned. To avoid this, we create a new 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 block on 𝑒𝑑𝑔𝑒 and append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to it. 2. There exists a path from the loop header to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 that does not contain 𝑠𝑝𝑒𝑐𝐵𝐵. In this case, we cannot insert 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) in 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , because we would end up with a CFG path where 𝑟 was not speculated in the AGU, but was poisoned in the CU. To avoid this, we create a new block 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 on the edge and append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) to it. We also add steering instructions to the path from 𝑠𝑝𝑒𝑐𝐵𝐵 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 that will branch from 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 to 𝑝𝑜𝑖𝑠𝑜𝑛𝐵𝐵 only if 𝑠𝑝𝑒𝑐𝐵𝐵 was encountered on the current CFG path. 3. Otherwise, 𝑝𝑜𝑖𝑠𝑜𝑛(𝑟 ) can safely be prepended to the start of 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . Algorithm 3 is executed only once per (𝑒𝑑𝑔𝑒, 𝑟 ) tuple—a given request is poisoned at most once on a given edge. Also, poison blocks created in case 1 in Algorithm 3 can be reused to poison other requests. Figure 5. Basic blocks with the same list of poison stores and the same immediate successor can be merged in the CU. 5.2.3 Example of Mapping Poison Edges to Blocks. Consider how the poisoned edges in Figure 4c are mapped to basic blocks in Figure 4d. Case 1: Store 𝑐 is poisoned on the 3 → 5 edge. Since there is a path from the true block of 𝑐 (block 4) to the edge destination block (block 5), we create a new block on the 3 → 5 edge and append 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) to it. Case 2: Store 𝑑 is poisoned on both the 5 → 7 and 5 → 𝐿 edges. The 𝑠𝑝𝑒𝑐𝐵𝐵 for 𝑑 is block 3. Since there exists the path 𝐻 → 1 → 2 → 5 that does not contain block 3, we create a new block on the 5 → 7 edge with the 𝑝𝑜𝑖𝑠𝑜𝑛(𝑑) call. We add steering instructions to the 3 → 5 and 3 → 4 → 5 paths that will cause block 5 to branch to the new poison block on the 5 → 7 edge only if block 5 was reached from a path containing block 3. Case 3: Store 𝑐 is also poisoned on the 3 → 6 edge, but here it is safe to prepend 𝑝𝑜𝑖𝑠𝑜𝑛(𝑐) to the start of block 6. Case 1 and 2 of Algorithm 3 might create multiple poison blocks for the same store on different CFG edges. It is possible to merge two poison blocks into one if they contain the same list of poison stores and if they have the same list of immediate successors. When merging, we keep instructions from just one block. We apply such merging iteratively after Algorithms 2 and 3. For example, Figure 5 contains a CFG sub- region of our running example from Figure 4. Algorithm 3 inserted poison blocks 10, 11, 12, 13 to poison stores 𝑑 and 𝑒. Block pairs (11, 13) and (10, 12) can be merged. Speculative loads are relatively easy to support. To match the order of load_consume calls in the CU with the order of speculative send_load_addr calls in the AGU we can hoist the load_consume calls to the same block where the corresponding send_load_addr were hoisted in the AGU. Then, the CU can either use the load value or discard it. After hoisting, we need to update all 𝜙 instructions that use the load value, since the basic block containing the loaded value will have changed. Alternatively, we can transform 𝜙 instructions using the load value into select instructions. 6 Safety and Liveness We prove that our transformations preserve the sequential consistency of the original program and that they do not introduce deadlock. Deadlock freedom is a corollary of se- quential consistency, so we focus only on the latter. We show that on every CFG path the order of speculative store requests in the AGU matches the order of store values in the CU, and that the non-poisoned store value sequence in the CU matches the store sequence of the original code. In the following discussion, we assume blocks with a sin- gle store; the proof trivially extends to blocks with multi- ple stores since all speculative stores in the same block are treated the same. We also assume that all stores are specula- tive, since the relative order between non-speculative and speculative stores is guaranteed by definition: given a a non- speculative store 𝑠1 and a speculative store 𝑠2, Algorithm 1 will not change the relative program order of 𝑠1 and 𝑠2, i.e., if 𝑠1 ≺ 𝑠2 in the original program order, then it is not possible to hoist 𝑠2 such that 𝑠2 ≺ 𝑠1. This follows from the con- trol dependency definition (§4)—𝑠2 hoisting stops at its LoD control dependency source 𝑠𝑟𝑐𝐵𝐵, which must come after the block containing 𝑠1 in topological order. If 𝑠𝑟𝑐𝐵𝐵 would come after 𝑠1 in topological order, then the block containing 𝑠1 would also have a LoD control dependency on 𝑠𝑟𝑐𝐵𝐵 and would have been hoisted, which is a contradiction since we assumed that 𝑠1 was non-speculative. A similar argument can be made if 𝑠2 ≺ 𝑠1 in the original program. Lemma 6.1 (Sequential Consistency). Given an ordered list of 𝑛 speculative store requests 𝐿𝑎 = {𝑎0, 𝑎1, ..., 𝑎𝑛−1} made in the AGU loop CFG on some fixed iteration 𝑘, Algorithms 2 and 3 transform the CU CFG such that every possible path through its loop CFG on iteration 𝑘 produces an or- dered list of 𝑛 tagged store values 𝐿𝑣 = {(𝑣0, 𝑝0), (𝑣1, 𝑝1), ..., (𝑣𝑛−1, 𝑝𝑛−1)}, such that each (𝑎𝑖, 𝑣𝑖, 𝑝𝑖 ), 0 ≤ 𝑖 < 𝑛 triple cor- responds to a 𝐴[𝑎𝑖 ] ← 𝑣𝑖 store in the original program CFG, and 𝑝𝑖 = 1 (poison bit) if that store is not executed on the path through the original loop CFG on iteration 𝑘. Proof. We use a proof by induction on the transformed CFG. Base case: 𝐿𝑎 = ∅ (no speculated requests in the AGU). Algorithm 2 does not change the CU CFG. Thus, the order of store addresses in the AGU and store values in the CU trivially matches, 𝐿𝑎 = 𝐿𝑣 = ∅. Inductive hypothesis: assume Lemma 6.1 holds at basic block 𝐵𝑖 in the current CFG path. All store requests 𝑎 𝑗 ∈ 𝐿𝑎 contained in blocks reached before 𝐵𝑖 in the path were matched with the correct store value call (𝑣 𝑗, 𝑝 𝑗 ) ∈ 𝐿𝑣, such that 𝑝 𝑗 = 1 if 𝐴[𝑎 𝑗 ] ← 𝑣 𝑗 was not executed on the path in the original loop CFG. Inductive step: The next store address in the AGU 𝐿𝑎 se- quence is 𝑎 𝑗+1 ∈ 𝐿𝑎. The next store value in the CU CFG path should be (𝑣 𝑗+1, 𝑝 𝑗+1) ∈ 𝐿𝑣, where 𝑝 𝑗+1 = 1 iff the store 𝐴[𝑎 𝑗+1] ← 𝑣 𝑗+1 is not reached on the current CFG path in the original program. Algorithm 2 considers the 𝑒𝑑𝑔𝑒𝑠𝑟𝑐 → 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 next. There are three cases: 1. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 = 𝑡𝑟𝑢𝑒𝐵𝐵, where 𝑡𝑟𝑢𝑒𝐵𝐵 is the block contain- ing the store 𝐴[𝑎 𝑗+1] ← 𝑣 𝑗+1 in the original program CFG. In this case, Algorithm 2 will not poison this store on this path through the CU CFG, i.e., the next item in the 𝐿𝑣 sequence will be the correct (𝑣 𝑗, 0). 2. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 ≠ 𝑡𝑟𝑢𝑒𝐵𝐵 and 𝑡𝑟𝑢𝑒𝐵𝐵 is not reachable from 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 , in which case Algorithm 2 will insert a poison store on this edge. Algorithm 3 will map this poison store to a basic block, with the effect that taking the 𝑒𝑑𝑔𝑒 will result in the poison call being executed and control transferring to 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 . The next item in the 𝐿𝑣 sequence will be the correct (𝑣 𝑗, 1). 3. 𝑒𝑑𝑔𝑒𝑑𝑠𝑡 ≠ 𝑡𝑟𝑢𝑒𝐵𝐵 and 𝑡𝑟𝑢𝑒𝐵𝐵 is reachable from 𝐵𝑙 , in which case Algorithm 2 will traverse the path until Case 1 or 2 is matched. Since Lemma 6.1 holds for the base case, for basic blocks on the path up to 𝐵𝑖 , and for some successor block of 𝐵𝑖 , it must hold at any block on the path. If it holds at any block on the path, it holds for the whole path. Since a given store request 𝑟 is poisoned at most once on a given CFG edge and since, by definition of Algorithm 2, any given path will contain at most one edge where 𝑟 is poisoned, we conclude □ that Lemma 6.1 holds for all paths. 7 Applications In this section, we highlight three applications for our work: DAE-based prefetchers in CPUs/GPUs, CGRAs, and special- ized accelerators generated from HLS. In the next section, we choose HLS as an evaluation vehicle due to its simplicity compared to CPU/GPU prefetchers where the evaluation results can easily be polluted by other architectural factors like cache behavior, branch prediction, etc. However, we em- phasize that our speculation support in DAE does not rely on any HLS-specific features and can be applied wherever speculation is combined with the DAE technique. Most existing works on CPU/GPU prefetchers follow the DAE principle and rely on the compiler to decoupled address generation from compute [3, 5, 17, 18, 24, 38, 47]. All of these works suffer from the control-dependency loss of decoupling (LoD) problem (§4). The work in [24] discusses adding spec- ulation and predicated stores to the CPU microarchitecture to mitigate LoD, but their compiler only supports simple diamond and triangle control flow shapes. In this paper, we have demonstrated generalized compiler support for specu- lation in DAE, making these works viable for general control flow and thus applicable to a broader set of codes. 7.1.1 Example. The CPU prefetcher proposed in [24] (on which most of the other work is based) separates address gen- eration from compute and extends the ISA with store_addr, load_produce, store_val, load_consume, and store_inv instructions that can be directly targeted by our compiler. A CGRA consists of an array of PEs, each with small memo- ries, connected by a network. A CGRA compiler is typically co-designed with the hardware, as the PEs are typically stat- ically scheduled. The job of the compiler is to map the Con- trol/Data Flow Graph (CDFG) to the PEs, and many works follow the DAE technique to tackle the memory wall prob- lem [20, 27, 37, 39, 43, 45, 46, 61]. Our work can help mitigate LoD events when mapping to CGRAs. 7.2.1 Example. The CGRA proposed in [39] is an example of a modern streaming dataflow CGRA. All communication in the CGRA is FIFO-based, and address generation is ex- plicitly decoupled at compile time into AGUs. The compiler generates commands to produce address streams, and to consume or produce values. Control flow is handled with predication and there is a SD_Clean_Port command to throw away a value from an output port that can be used to imple- ment predicated stores. In HLS, the CDFG of an algorithm is implemented directly in hardware following a spatial execution model with the freedom to customize the memory system. This makes de- coupling easier in HLS compared to the temporal CPU/GPU execution model. HLS-generated accelerators can directly benefit from our work today without any changes, and it is in this domain that we evaluate our implementation in the next section. Although existing HLS compilers are successful in build- ing non-trivial accelerators for regular code (e.g., [48]), their static scheduling techniques are sub-optimal for irregular codes (for the same reason why traditional VLIW compilers were sub-optimal for irregular codes). Many research works in academia and industry have exploited DAE in HLS to improve the efficiency of HLS-generated accelerators for ir- regular codes [11–13, 15, 16, 21, 53–55]. By adding compiler speculation support, DAE in HLS can be used on a broader set of codes, which we demonstrate in the next section. 8 Evaluation In this section, we answer the following questions: • What is the performance benefit of using a DAE ar- chitecture (enabled by our speculation approach) to accelerate codes with LoD control dependencies? • What is the cost of mis-speculation in our approach? • What is the impact on code size (accelerator area usage) of our speculation approach? • What is the scalability for nested control flow, which increases the number of poison stores and blocks? We make our work and evaluation publicly available [52]. Figure 6. Performance of DAE, SPEC and ORACLE normalized to STA. SPEC achieves an average 1.9× (up to 3×) speedup. We generate algorithm-specific accelerators using HLS tar- geting an Intel Arria 10 FPGA. The C codes are taken directly from benchmark suites without adding any HLS-specific an- notations (excluding dynamic structures, like queues, that were replaced with HLS-specific libraries). We use the LLVM-based Intel SYCL HLS compiler [29] and apply our standard DAE transformation (§3.2) and our proposed speculation transformation (§5) as LLVM passes. The codes use deterministic dual-ported on-chip SRAM ca- pable of 1 read and 1 write per cycle. To enable out-of-order loads, we use a load-store queue (LSQ) designed for HLS (load/store queue sizes of 4/32), which is commonly found on accelerators for irregular codes [1, 24, 31, 53]. We report cycle counts from ModelSim simulations. We do not report circuit frequency since our approach does not affect the critical path (see [52] for such details). Area usage is obtained after place and route using Quartus 19.2. 8.1.1 Baselines. For each benchmark, we synthesize the following architectures which represent current state-of-the- art approaches to HLS : • STA: the default, industry-grade approach using static scheduling [29]. Loads that cannot be disambiguated at compile time execute in order. • DAE: a DAE architecture without speculation. OoO loads are enabled by an LSQ. This is the state-of-the- art approach to irregular codes in academia [53], but it suffers from control-dependency LoDs. • SPEC: the same as DAE, but with our speculation tech- nique which mitigates control-dependency LoDs. • ORACLE: the same as DAE, but all LoD control depen- dencies are removed manually from the input code. The ORACLE results are wrong, but give a bound on the performance of SPEC and show its area overhead. 8.1.2 Benchmarks. DAE architectures optimize the la- tency between memory and compute and are most beneficial for memory-bound codes [24], especially codes with an irreg- ular memory access pattern that prevents static prefetching [18]. We evaluate nine such benchmarks from the graph and data analytics domain, using the GAP graph benchmark Table 1. Absolute performance and area usage of STA [29], DAE [53], SPEC, and ORACLE accelerators. (*bc uses two LSQs). bfs bc sssp hist thr mm fw sort spmv suite [8] and an HLS benchmark suite [14] of irregular pro- grams. We select only codes that can benefit from our SPEC approach, i.e., codes with LoD control dependencies: • bfs: breadth-first traversal through a graph. • bc: betweenness centrality of a single node in a graph. • sssp: single shortest path from a single node to all other nodes in a graph using Dijkstra’s algorithm. • hist: histogram, similar to Figure 1b (size 1000). • thr: zeroes RGB pixels above threshold (size 1000). • mm: maximal matching in a bipartite graph (2000 edges). • fw: Floyd-Warshall distance calculation of all node-to- node pairs in a dense graph (10×10 distance matrix). • sort: using bitonic mergesort (size 64). • spvm: sparse vector matrix multiply (20×20 matrix). For the graph codes (bfs, bc, sssp) we use a real-world graph email-Eu-core with 1005 nodes and 25,571 edges. Figure 6 reports normalized speedups of each technique over STA. Our SPEC approach gives on average a 1.9× (and up to 3×) speedup over STA. This is within 5% of the ORACLE performance. In contrast, DAE without speculation sees a dramatic performance degradation over STA, because the AGU, DU, CU communication is sequentialized. 8.2.1 Mis-speculation Cost. The SPEC and ORACLE per- formance gap is highest on the bfs and bc codes, because of its deep pipeline between the load and store that form a RAW hazard. The deep pipeline means that more store allocations need to be held by the LSQ to guarantee perfect pipelining [34]. This, together with a high mis-speculation rate in these benchmarks (Table 1), can cause the LSQ to fill with store addresses that are mis-speculated, potentially stalling later loads that have to wait for future store addresses to arrive. This problem can be solved by increasing the store queue size in the LSQ. The increased number of requests and the need for more buffering is one of the limitations of our approach. Codes with a shallower pipeline that do not need large LSQ sizes have no mis-speculation penalty. To prove this, we choose three benchmarks where we can instrument the input data so that we can vary the mis- speculation rate. Table 2 shows how the mis-speculation cost changes as the mis-speculation rate increases. As can be seen, there is no correlation between the mis-speculation rate and cost, with the slight variability in clock cycle counts attributable to the subtle difference in the number of true RAW hazards due to the varying data distribution. Table 2. SPEC cycle counts as mis-speculation rate changes. hist thr mm Mis-speculation rate Our speculation approach can increase the number of blocks in the CU, especially for codes with deeply nested control flow. In HLS, an increased number of blocks can result in a higher area usage due to larger scheduler complexity [50]. Table 1 shows the absolute area usage of all accelerators. We observe virtually no area overhead of SPEC over ORACLE on the evaluated benchmarks. This is because most of the codes have at most two control-flow nesting levels where new poison blocks are inserted, and sometimes it is possible to reduce the number of blocks using our merging technique (e.g., two poison blocks in mm merged into one). 8.3.1 Impact of Nested Control Flow on Area Usage. To give a more meaningful measure of how nested control flow impacts the area overhead of our SPEC approach, we create a synthetic benchmark template where we can tune the number of poison blocks generated by SPEC: for HLS with speculation support [23]. The speculation sup- port in this and other works requires costly recovery on mis-speculation [6, 22, 30, 35, 56, 60]. Efficiently squashing speculative computation on the wrong paths in a spatial dataflow architecture is hard, because the architectural state is distributed [10]. Our speculative DAE sidesteps this issue, not requiring any recovery: we speculate early (run ahead) in the AGU, and later handle mis-speculations in the CU by taking an appropriate path in its CFG. Control-flow handling in GPUs is usually implemented via predication. The algorithms used to calculate predicate masks and re-convergence points resemble our work [32]. The SIMT stack approach in GPUs pushes predicate masks onto a stack when entering a control-flow nesting level, and pops when exiting. Our Algorithm 1 implementing specula- tive requests can be seen as a pass through the CFG with only push operations, where the push is onto individual stacks of control-dependency sources. Dually, our inserting of poison calls in Algorithm 1 can be seen as a pass through the CFG with only pop operations where the placement of the pops follows a certain policy just like modern SIMT compilers fol- low different policies to prevent SIMT deadlock and livelock, or to improve performance [19], instead of popping at the immediate post-dominator. 10 Conclusion We have presented general compiler support for specula- tive memory operations in DAE architectures that tackles the LoD problem resulting from control dependencies. We have proposed CFG transformations implementing specula- tion in the address generation slice, and poisoning of mis- speculations in the compute slice, with a proof of correctness. We have presented three applications where our work im- proves support for the efficient execution of irregular codes: DAE-based CPU/GPU prefetchers that require compiler sup- port, CGRA architectures, and HLS-generated specialized accelerators. We have evaluated our work on HLS-generated accelerators, showing an average 1.9× (up to 3×) speedup over non-DAE accelerators on a set of irregular benchmarks where DAE is not possible without our speculation. Our ap- proach has no mis-speculation cost and a small code size footprint, scaling well to deeply nested control flow. Future work could investigate vector-parallelism support by filling a vector of speculative requests in the AGU and producing a store mask in the CU, similar to the recent work on decoupled vector runahead prefetching in CPUs [36]. Data-Availability Statement We make our work and evaluation publicly available [52]. Acknowledgments We thank Intel for access to FPGAs through their DevCloud. This work was supported by a UK EPSRC PhD scholarship. Figure 7. Change in area and performance overhead of SPEC over ORACLE as the number of poison blocks and calls grows. if 𝑥 > 0 then 𝑠𝑡𝑜𝑟𝑒1 if 𝑥 > 1 then 𝑠𝑡𝑜𝑟𝑒2 if 𝑥 > 2 then ... poison calls. Each nesting level in this template will result in one poison block in the SPEC architecture. With 𝑛 stores, and assuming one store per nesting level, there will be 𝑛 poison blocks and 𝑛 𝑖=1 Figure 7 shows how the area and performance overhead of SPEC over ORACLE changes as more poison blocks are needed. The performance overhead is close to 0% and does not change with more poison blocks. The area overhead of the AGU unit is similarly close to 0%, because SPEC hoists stores out of the if -conditions, causing the blocks to be deleted. The area overhead of the CU unit grows by a few percent (< 5%) with each added poison block, but even for the pathological case of eight nested if -conditions the overhead is below 25%. In real codes, with more compute and lower control-flow nesting, the area overhead of SPEC should be minimal. 9 Related Work Program slicing is used beyond DAE architectures. Decoupled Software Pipelining (DSWP) [41] is a popular transforma- tion that decouples strongly connected components in the program dependence graph into separate pipeline stages mapped over multiple PEs communicating via FIFOs. The PEs can be CPU threads, or pipeline stages in an accelerator generated by HLS [33]. Control dependent pipeline stages in DSWP can also be executed speculatively, although stages with memory operations require versioned memory [58]. Control speculation has its roots in compilers for VLIW ma- chines. Instruction scheduling in HLS is very similar to VLIW scheduling (no hardware support for speculation, static map- ping to functional units, etc.), with many algorithms like modulo-scheduling and if -conversion originally developed for VLIW directly applicable to HLS [2, 42, 50]. Most recently, predicated execution in the form of gated SSA was proposed",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.13553v1.pdf",
         "extracted",
         "None",
         "",
         "Compiler Support for Speculation in Decoupled Access/Execute Architectures"
        ],
        [
         "7",
         "00291c982d2d9e69d8fe8c89a7db1fbb25f15687",
         "G protein-coupled receptors (GPCRs) are integral membrane proteins which closely interact with their plasma membrane lipid microenvironment. Cholesterol is a lipid enriched at the plasma membrane with pivotal roles in the control of membrane fluidity and maintenance of membrane microarchitecture, directly impacting on GPCR stability, dynamics and function. Cholesterol extraction from pancreatic beta cells has previously been shown to disrupt the internalisation, clustering and cAMP responses of the glucagon-like peptide-1 receptor (GLP-1R), a class B1 GPCR with key roles in the control of blood glucose levels via the potentiation of insulin secretion in beta cells and weight reduction via the modulation of brain appetite control centres. Here, we unveil the detrimental effect of a high cholesterol diet on GLP-1R-dependent glucoregulation in vivo, and the improvement in GLP-1R function that a reduction in cholesterol synthesis using simvastatin exerts in pancreatic islets. We next identify and map sites of cholesterol high occupancy and residence time on active versus inactive GLP-1Rs using coarse-grained molecular dynamics (cgMD) simulations, followed by a screen of key residues selected from these sites and detailed analyses of the effects of mutating one of these residues, Val229, to alanine on GLP-1R interactions with cholesterol, plasma membrane behaviours, clustering, trafficking and signalling in pancreatic beta cells and primary islets, unveiling an improved insulin secretion profile for the V229A mutant receptor. This study 1) highlights the role of cholesterol in regulating GLP-1R responses in vivo; 2) provides a detailed map of GLP-1R - cholesterol binding sites in model membranes; 3) validates their functional relevance in beta cells; and 4) highlights their potential as locations for the rational design of novel allosteric modulators with the capacity to fine-tune GLP-1R responses.",
         "Affiong I. Oqua,Kin Chao,Liliane El Eid,Lisa Casteller,Billy P Baxter,Alba Miguéns-Gómez,Sebastian Barg,Ben Jones,Jorge Bernadino de la Serna,Sarah L Rouse,Alejandra Tomas",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/06/25/2024.06.22.600087.full.pdf",
         "None",
         "None",
         "GLP-1R associates with VAPB and SPHKAP at ERMCSs to regulate β-cell mitochondrial remodelling and function;Missense3D-TM: Predicting the Effect of Missense Variants in Helical Transmembrane Protein Regions Using 3D Protein Structures;Newer pharmacological interventions directed at gut hormones for obesity;Martini 3 Coarse-Grained Force Field for Cholesterol.;Statins and risk of type 2 diabetes: mechanism and clinical implications;An updated patent review of GLP-1 receptor agonists (2020-present);Divergent acute versus prolonged pharmacological GLP-1R responses in adult β cell–specific β-arrestin 2 knockout mice;The expanding incretin universe: from basic biology to clinical translation;Enhanced Endosomal Signaling and Desensitization of GLP-1R vs GIPR in Pancreatic Beta Cells;Fluorescent Probes for Lipid Membranes: From the Cell Surface to Organelles.;Interactions of cholesterol molecules with GPCRs in different states: A comparative analysis of GPCRs' structures.;Martinize2 and Vermouth: Unified Framework for Topology Generation;Exenatide prevents statin-related LDL receptor increase and improves insulin secretion in pancreatic beta cells (1.1E7) in a protein kinase A-dependent manner.;GPCRdb in 2023: state-specific structure models using AlphaFold2 and new ligand resources;Cholesterol-Dependent Dynamics of the Serotonin1A Receptor Utilizing Single Particle Tracking: Analysis of Diffusion Modes.;Biased Agonism and Polymorphic Variation at the GLP-1 Receptor: Implications for the Development of Personalised Therapeutics.;1457-P: Cholesterol Accumulation in Islets Increases Steroidogenic Acute Regulatory (StAR) Protein Expression and Decreases Islet Cell Viability and ß-Cell Function;Cholesterol Dependent Activity of the Adenosine A2A Receptor Is Modulated via the Cholesterol Consensus Motif;The role of the lipid environment in the activity of G protein coupled receptors.;Cholesterol-dependent endocytosis of GPCRs: implications in pathophysiology and therapeutics;Spatial arrangement of proteins in planar and curved membranes by PPM 3.0;Brain GLP‐1 and the regulation of food intake: GLP‐1 action in the brain and its implications for GLP‐1 receptor agonists in obesity treatment;Super-Resolution Microscopy Using a Bioorthogonal-Based Cholesterol Probe Provides Unprecedented Capabilities for Imaging Nanoscale Lipid Heterogeneity in Living Cells.;Acylation of the Incretin Peptide Exendin-4 Directly Impacts Glucagon-Like Peptide-1 Receptor Signaling and Trafficking;PyLipID: A Python Package for Analysis of Protein–Lipid Interactions from Molecular Dynamics Simulations;Contribution of Mitochondria to Insulin Secretion by Various Secretagogues;Improved Parameterization of Phosphatidylinositide Lipid Headgroups for the Martini 3 Coarse-Grain Force Field.;Molecular insights into ago-allosteric modulation of the human glucagon-like peptide-1 receptor;The Interplay of Glucagon-Like Peptide-1 Receptor Trafficking and Signalling in Pancreatic Beta Cells;The therapeutic potential of GLP‐1 receptor biased agonism;Martini 3: a general purpose force field for coarse-grained molecular dynamics;Multi-dimensional and spatiotemporal correlative imaging at the plasma membrane of live cells to determine the continuum nano-to-micro scale lipid adaptation and collective motion;LAURDAN since Weber: The Quest for Visualizing Membrane Heterogeneity.;Predictable cholesterol binding sites in GPCRs lack consensus motifs.;Allosteric Modulation of GPCRs of Class A by Cholesterol;Evolving cryo-EM structural approaches for GPCR drug discovery;Adaptive Lipid Immiscibility and Membrane Remodeling Are Active Functional Determinants of Primary Ciliogenesis.;Genetic and biased agonist-mediated reductions in β-arrestin recruitment prolong cAMP signaling at glucagon family receptors;Incretin Hormones and Type 2 Diabetes—Mechanistic Insights and Therapeutic Approaches;Imperial;Ligand-Specific Factors Influencing GLP-1 Receptor Post-Endocytic Trafficking and Degradation in Pancreatic Beta Cells;Structure and Dynamics of GPCRs in Lipid Membranes: Physical Principles and Experimental Approaches;Differential GLP-1R binding and activation by peptide and non-peptide agonists;Lipid-Protein Interactions Are a Unique Property and Defining Feature of G Protein-Coupled Receptors.;Full-length human GLP-1 receptor structure without orthosteric ligands;Signalling, trafficking and glucoregulatory properties of glucagon‐like peptide‐1 receptor agonists exendin‐4 and lixisenatide;ER-lysosome contacts enable cholesterol sensing by mTORC1 and drive aberrant growth signaling in Niemann-Pick type C;Agonist-induced membrane nanodomain clustering drives GLP-1 receptor responses in pancreatic beta cells;2125-P: Increased StAR (Steroidogenic Acute Regulatory Protein) Is Detrimental to ß Cells and Promotes Mitochondrial Dysfunction;An Overview, Advantages and Therapeutic Potential of Nonpeptide Positive Allosteric Modulators of Glucagon‐Like Peptide‐1 Receptor;RNA-seq-based identification of Star upregulation by islet amyloid formation.;State-dependent Lipid Interactions with the A2a Receptor Revealed by MD Simulations Using In Vivo-Mimetic Membranes;Targeting GLP-1 receptor trafficking to improve agonist efficacy;Cholesterol metabolism—physiological regulation and pathophysiological deregulation by the endoplasmic reticulum;Phase-plate cryo-EM structure of a biased agonist-bound human GLP-1 receptor–Gs complex;Dissecting single–cell molecular spatiotemporal mobility and clustering at Focal Adhesions in polarised cells by fluorescence fluctuation spectroscopy methods;Membrane lipids and cell signaling;Cryo-EM structure of the activated GLP-1 receptor in complex with G protein;The New Biology and Pharmacology of Glucagon.;The mystery of membrane organization: composition, regulation and roles of lipid rafts;Lipid–Protein Interactions Are Unique Fingerprints for Membrane Proteins;Glucagon-Like Peptide-1 and Its Class B G Protein–Coupled Receptors: A Long March to Therapeutic Successes;There Is No Simple Model of the Plasma Membrane Organization;Use of CRISPR/Cas9-engineered INS-1 pancreatic β cells to define the pharmacology of dual GIPR/GLP-1R agonists.;Restoring Mitochondrial Function: A Small Molecule-mediated Approach to Enhance Glucose Stimulated Insulin Secretion in Cholesterol Accumulated Pancreatic beta cells;Simvastatin Impairs Insulin Secretion by Multiple Mechanisms in MIN6 Cells;GROMACS: High performance molecular simulations through multi-level parallelism from laptops to supercomputers;CHARMM-GUI Martini Maker for Coarse-Grained Simulations with the Martini Force Field.;Glucagon-Like Peptide-1 Increases Mitochondrial Biogenesis and Function in INS-1 Rat Insulinoma Cells;Computational Lipidomics with insane: A Versatile Tool for Generating Custom Membranes for Molecular Simulations.;The class B G-protein-coupled GLP-1 receptor: an important target for the treatment of type-2 diabetes mellitus.;Structure of Class B GPCRs: new horizons for drug discovery;Physiology and pharmacology of the enteroendocrine hormone glucagon-like peptide-2.;Nutrition and L and K-enteroendocrine cells;Identification of cholesterol recognition amino acid consensus (CRAC) motif in G-protein coupled receptors.;Syntaxin clusters assemble reversibly at sites of secretory granules in live cells;Raster image correlation spectroscopy in live cells;Multiphoton excitation fluorescence microscopy in planar membrane systems.;Combining an Elastic Network With a Coarse-Grained Molecular Force Field: Structure, Dynamics, and Intermolecular Recognition.;A specific cholesterol binding site is established by the 2.8 A structure of the human beta2-adrenergic receptor.;Cholesterol homeostasis in T cells. Methyl-beta-cyclodextrin treatment results in equal loss of cholesterol from Triton X-100 soluble and insoluble fractions.;The physiology of glucagon-like peptide 1.;Canonical sampling through velocity rescaling.;Caveolin-1 regulates cellular trafficking and function of the glucagon-like Peptide 1 receptor.;Comparative Protein Structure Modeling Using Modeller;Simvastatin: a review;The 3-hydroxy-3-methylglutaryl coenzyme-A (HMG-CoA) reductases;Isolation of INS-1-derived cell lines with robust ATP-sensitive K+ channel-dependent and -independent glucose-stimulated insulin secretion.;VMD: visual molecular dynamics.;Simvastatin. A reappraisal of its pharmacology and therapeutic efficacy in hypercholesterolaemia.;Polymorphic transitions in single crystals: A new molecular dynamics method;Zhang X;29 of 31 Frontiers;Röhrl C;Role of the steroidogenic acute regulatory protein in health and disease",
         "Molecular mapping and functional validation of GLP-1R cholesterol binding sites in pancreatic beta cells"
        ],
        [
         "8",
         "00317a3206df00f0c3c91595a349bc81b7118929",
         "None",
         "Yeping Wang,M. Gleicher",
         "\n**BLOCK**fs== 17.9**p== 0.0**b== 0.8**t== 0.1**l== 0.4**r== 0.4**\n– Preprint –\n**BLOCK**fs== 17.9**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nAnytime Planning for End-Effector Trajectory Tracking\n**BLOCK**fs== 11.0**p== 0.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\nYeping Wang and Michael Gleicher\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nAbstract—End-effector trajectory tracking algorithms find\njoint motions that drive robot manipulators to track reference\ntrajectories. In practical scenarios, anytime algorithms are pre-\nferred for their ability to quickly generate initial motions and\ncontinuously refine them over time. In this paper, we present\nan algorithmic framework that adapts common graph-based\ntrajectory tracking algorithms to be anytime and enhances their\nefficiency and effectiveness. Our key insight is to identify guide\npaths that approximately track the reference trajectory and\nstrategically bias sampling toward the guide paths. We demon-\nstrate the effectiveness of the proposed framework by restruc-\nturing two existing graph-based trajectory tracking algorithms\nand evaluating the updated algorithms in three experiments.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nIndex Terms—Constrained Motion Planning, Motion and Path\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.9**\nPlanning\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.4**l== 0.2**r== 0.6**\nI. INTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nM ANY applications require a robot manipulator to accu-\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.5**l== 0.1**r== 0.5**\nrately and smoothly move its end-effector along a spe-\ncific trajectory. These applications involve welding, sanding,\npolishing, painting, and additive manufacturing. For redundant\nmanipulators or applications with tolerances, there exist in-\nfinitely many possible motions to track a reference end-effector\ntrajectory. Thus, planning algorithms seek to find optimal\nmotions among these possibilities based on criteria such as\nminimal joint movement [1], minimal end-effector error [1],\n[2], minimal maximum joint velocity [3], or minimal number\nof reconfigurations, i.e., instances where the robot pauses task\nexecution and restarts from another joint configuration [4], [5].\nTo track an end-effector trajectory based on some optimality\ncriteria, common graph-based approaches [1], [3], [4], [6],\n[7] first sample inverse kinematics (IK) solutions for each\nwaypoint on the reference trajectory. These IK solutions serve\nas vertices to construct a layered graph, where each layer\ncorresponds to a waypoint. Edges are added to link IK solu-\ntions in adjacent layers, and these edges’ weights are defined\naccording to the optimality criteria. Finally, a graph search\nmethod is utilized to find the optimal motion. The success of\nthis approach relies heavily on the density of the sampling\nto sufficiently discretize the solution space. Existing graph-\nbased trajectory tracking approaches often rely on uniformly\ndense IK sampling, which leads to long delays in finding initial\nsolutions. In practical scenarios with limited computational\nresources, anytime algorithms are preferred because they can\ngenerate feasible solutions quickly and progressively refine\nthem over time. This flexibility allows anytime algorithms to\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nThis work was supported in part by National Science Foundation under\nAward 2007436 and in part by the Los Alamos National Laboratory and the\nDepartment of Energy.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nBoth authors are with the Department of Computer Sciences, Univer-\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nsity of Wisconsin-Madison, Madison, WI 53706, USA\n[yeping|gleicher]@cs.wisc.edu\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nbe stopped at any time, enabling trade-offs between solution\nquality and computation time.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.3**l== 0.5**r== 0.1**\nIn this work, we present an anytime algorithmic framework\nthat enhances existing approaches to efficiently and effec-\ntively generate robot motions to track reference end-effector\ntrajectories. Our framework enhances existing methods by\nincorporating a heuristic to prioritize samples that are likely\nto lead to good solutions. Our key insight is to identify guide\npaths that approximately track the reference trajectory and\nstrategically bias sampling toward the guide paths, which\nprogressively densifies the graph. This approach enables fre-\nquent identification of effective solutions within a significantly\nreduced timeframe. Over time, the graph converges towards\nthe dense graph used in conventional algorithms. We show\nthat, in the worst case, our anytime framework converges to\nthe conventional framework, although in practice its ability\nto sample strategically usually leads to better results in less\ntime. The algorithmic framework is independent of specific\nIK sampling algorithms, optimality criteria, or graph searching\nalgorithms. We provide an open-source implementation of our\nframework 1.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nThe central contribution of this work is a guided anytime\nalgorithmic framework (Sections III-D and IV). To explain\nour approach, we first describe the conventional sequential\nframework and a naïve anytime framework as baselines (Sec-\ntions III-B and III-C). We evaluated our framework through\nthree experiments (§V). First, we applied it to two end-effector\ntrajectory tracking algorithms, Stampede [1] and IKLink [4],\noriginally based on the conventional framework. Our results\nshow that our framework accelerates both algorithms, gener-\nating solutions with less computation time than the conven-\ntional and naïve frameworks, while matching or exceeding\ntheir solution quality. Additionally, we applied it to semi-\nconstrained trajectory tracking, which expands the solution\nspace by allowing tolerances and requiring more IK samplings.\nUnlike baseline frameworks, which are inefficient due to naïve\nsampling, our framework enhances IKLink’s efficiency and\neffectiveness for this task.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nA. End-Effector Trajectory Tracking\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nII. RELATED WORK\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nThe end-effector trajectory tracking problem, also known\nas path-wise inverse kinematics [1], task-space non-revisiting\ntracking [5], or task-constrained motion planning [8], involves\nvarious approaches based on input type. Specifically, trajectory\ntracking methods [1], [2], [4], [5], [6] take a timestamped\ntrajectory as input, whereas path tracking methods [3], [7]\ntrack a sequence of coordinates without timing.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n1Open-sourced code https://github.com/uwgraphics/IKLink/tree/anytime\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.1**l== 0.1**r== 0.5**\nEnd-effector trajectory tracking methods can be broadly\ncategorized into two groups: trajectory optimization and graph-\nbased approaches. Trajectory optimization directly optimizes\na joint-space trajectory while satisfying constraints. For exam-\nple, Holladay et al. [9] utilize TrajOpt [10], a trajectory opti-\nmization method, to minimize the Fréchet distances between\ncurrent solutions and a given reference trajectory. Instead of\nFréchet distances, Torm [11] minimizes the summed Euclidean\ndistance between corresponding waypoints on the current and\nreference trajectories. These optimization methods require an\ninitial trajectory as a starting point, are sensitive to this initial\ntrajectory [12], and are prone to be stuck in local minima\n[9]. Meanwhile, graph-based approaches [1], [3], [4], [6], [7]\nconstruct a hierarchical graph where vertices represent inverse\nkinematics (IK) solutions. A path within the graph defines a\nrobot motion by sequentially connecting the IK solutions. We\nwill review these approaches in §III-B as part of the discussion\non the conventional algorithmic framework. Below, we discuss\nIK sampling strategies in graph-based approaches.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nB. IK Sampling in Graph-based Trajectory Tracking\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.4**l== 0.1**r== 0.5**\nIn graph-based end-effector trajectory tracking, the majority\nof the computation time is consumed by sampling inverse kine-\nmatics (IK) solutions and establishing connections between\nthem [13]. Some prior work [1], [4], [6], [7] exhaustively\nsamples IK solutions before searching for a path, resulting\nin long computation time before obtaining initial solutions.\n[2], [13]. Meanwhile, other approaches use incremental sam-\npling to accelerate the procedure. For example, CppFlow\n[3] leverages a generative IK solver, IKFlow [14], which\nrapidly produces a diverse set of IK solutions by learning the\ndistribution of uniformly sampled IK solutions. If the graph\nsearch algorithm fails to find a viable motion, the algorithm\nincrementally samples additional IK solutions to density the\ngraph. In contrast to uniform sampling, Malhan et al. [13] use\ncontinuity in Cartesian space as a heuristic for IK selection\nduring incremental graph construction. However, the heuristic\nis applicable solely to non-redundant robotic arms. Holladay\net al. [2] presents strategies to balance uniform sampling\nwith targeted sampling around certain areas. However, their\napproach is designed specifically to minimize the Fréchet dis-\ntance in Cartesian space, and it remains unclear how to adapt\ntheir strategies to address objectives such as minimizing joint\nmovements. Our method, like Holladay et al. [2], balances\nuniform and targeted sampling, but differs by sampling around\na guide path that roughly tracks the reference trajectory.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nIn certain trajectory tracking scenarios, precise end-effector\nmovements in all six degrees of freedom are not necessary,\ni.e., allowing for certain tolerances in Cartesian space. For\ninstance, in a drawing task, the robot may be permitted to\ntilt or rotate the pen as long as the pen tip position remains\nprecise and the motion remains collision-free. This problem is\ncalled semi-constrained end-effector trajectory tracking. Due\nto tolerances, the solution space expands, requiring more IK\nsolutions to cover the solution space. Graph-based approaches\nwith uniform sampling, e.g., Descartes [6], have a significant\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nincrease in computational load when using redundant robots\nor having tolerances on multiple degrees of freedom [15].\nTherefore, developing a more efficient algorithm is essential\nfor semi-constrained end-effector tracking. In this work, we\npresent a guided anytime algorithmic framework to accelerate\ngraph-based trajectory tracking approaches. We show how this\nframework can efficiently and effectively compute motions to\ntrack semi-constrained end-effector trajectory in §V.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nIII. TECHNICAL OVERVIEW\nIn this section, we first formalize our problem statement\nand describe the conventional algorithmic framework. We then\ndescribe a naïve anytime framework and why it is ineffective.\nFinally, we give an overview of our guided anytime framework\nand its advantages over previous approaches.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.3**l== 0.5**r== 0.3**\nA. Problem Statement\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nConsider a k degree of freedom robot manipulator whose\njoint configuration and end-effector pose are denoted by q∈Rk\nand p∈SE(3), respectively. End-effector trajectory tracking\nrefers to the problem of computing a joint space trajectory\nξ:[0, Tχ]→Rk that drives the robot’s end-effector along a\ndesired trajectory χ:[0, Tχ]→SE(3), where Tχ represents the\ntotal time duration of the end-effector trajectory. In practice,\nthe target end-effector trajectory χ is often represented in a\ndiscrete form {(t1, p1), ..., (tn, pn)}, where pi\nis the end-\neffector pose at timestamp ti. We assume that the waypoints\nare sufficiently dense to accurately approximate χ.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\nin a short\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\ntime interval τ >0, all\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nIn general, there are some requirements for joint space\ncontinuity, e.g.,\njoint\nmovements are within their velocity limits, vmin≤[ξ(t+τ )j\n−ξ(t)j]/τ ≤vmax, ∀j∈{1, ..., k}, ∀t∈[0, Tχ−τ ]. However,\nin\ntrajectory is complex and can\nscenarios where the input\nnot be tracked as a single, continuous path, exceptions to\nthis requirement may be permissible if the task allows for\ninterruptions. In such instances, joint discontinuities may be\nintroduced deliberately. Each joint discontinuity requires the\nrobot to perform an arm reconfiguration, in which the robot\npauses the task execution, relocates itself in the joint space,\nand resumes task execution from another configuration.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThis work focuses on the cases where the robot manipulator\nhas some redundancy; it is either a redundant arm (k > 6) or\na non-redundant arm performing semi-constrained trajectory\ntracking, where certain tolerances are permitted on the end-\nthe trajectory can\neffector poses. Due to the redundancy,\nbe tracked by infinitely many possible motions, requiring\noptimization criteria to select the best solution.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nGraph-based trajectory tracking algorithms maintain a lay-\nered graph G=(V, E), where each layer corresponds to a\nwaypoint on the reference trajectory. V and E denote vertices\nand edges in the graph, respectively. The notation V [x] denotes\nall vertices in the layer corresponding to the x-th waypoint.\nV [x][y] represents the y-th IK solution that aligns the end-\neffector with the x-th waypoint.\n|V [x]| denotes the total\nnumber of vertices in V [x].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nB. Baseline 1: Conventional Algorithmic Framework\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nMany existing graph-based trajectory tracking algorithms\nuse a sequential framework. As shown in Figure 1-A, these\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nconstruct the robot motion. Hence, we seek ways to improve\nthe sampling process, i.e., biasing sampling towards areas with\na high probability of being selected. Additionally, the number\nof IK solutions decides the number of edges in the graph; a\nsmall set of IK solutions can reduce the time for connectivity\nchecking and graph search.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nC. Baseline 2: Naïve Anytime Algorithmic Framework\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.2**l== 0.5**r== 0.1**\nThe aforementioned conventional framework does not pro-\nvide a solution until completion. In contrast, an anytime algo-\nrithm provides an initial solution and then iteratively refines\nit, enabling the process to be stopped at any time and allowing\nfor tradeoffs between solution quality and computation time.\nAs shown in Figure 1-B, a naïve anytime framework uses the\nsame random sampling process to initially sample a smaller\nset of IK solutions, from which a layered graph is constructed.\nA graph search is then conducted to identify an initial solution.\nThe solution is iteratively refined by sampling additional IK\nsolutions, expanding the graph, and performing further graph\nsearches to find new solutions. The solutions are always at\nleast as good as, if not better than, the previous ones because\nthe graph incorporates all vertices and edges from its previous\nversion. The algorithm continues until it reaches a predefined\nthreshold, such as running time or the number of iterations.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nAnalysis: The naïve anytime framework has the advantage\nof generating an initial solution quickly and refining it over\ntime. However, it requires some heuristic to find an effective\ninitial solution. In our implementation, we use an optimization-\nbased IK solver to find IK solutions that are close to those of\nthe previous waypoints, which helps ensure smooth motion.\nThis heuristic is similar to GreedyIK in Wang et al. [4].\nDespite this, the naïve framework often converges slowly,\nbecause the samples are added in a random order. This\neffect is demonstrated in the experiments in §V. Meanwhile,\nour proposed algorithmic framework uses heuristics to bias\nsampling such that initial solutions are likely to be effective,\nand the additional sampling focuses on adding samples likely\nto improve the solution.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nD. Overview of Guided Anytime Algorithmic Framework\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\nSimilar to the aforementioned approaches,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nthe proposed\nframework maintains a layered graph, in which a layer corre-\nsponds to a waypoint on the reference trajectory and a vertex\nrepresents an IK solution. The key idea of our method is to\nbias sampling toward guide paths. A guide path is a sequence\nof vertices that approximately tracks the reference trajectory. It\ntypically includes sparse edges that connect vertices that are\na few layers apart. Upon refinement, guide paths are likely\nto be good solutions. A solution is a path through the graph\nwith a vertex at every time step, thus accurately tracking the\ntrajectory. During refinement, sparse edges within guide paths\nare potentially replaced by dense edges which connect vertices\nwith adjacent timestamps, thereby gradually converting guide\npaths to solutions.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nAs shown in Figure 2, our algorithm starts by constructing a\ngraph in which IK solutions are sampled for certain waypoints\nand connected using sparse edges. An initial guide path is\nidentified by searching over these sparse edges. The guide\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFig. 1. Three algorithmic frameworks described and evaluated in this paper\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\napproaches sample inverse kinematics (IK) solutions for each\nwaypoint on the end-effector trajectory, use these IK solutions\nas graph vertices, and search for a solution in the graph.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n1) IK Sampling: The two primary goals of IK sampling\nare to find IK solutions that are diverse enough to cover the\nentire solution space and dense enough to construct a smooth\nmotion. In order to generate diverse IK solutions, one common\napproach is to randomly sample starting configurations in a\nrobot’s joint space and find IK solutions that are closest to the\nstarting configurations using an optimization-based IK solver,\nsuch as Trac-IK [16] or RelaxedIK [17], or an iterative IK\nsolver, such as Orocos KDL or the damped least squares IK\nalgorithm [18]. Another approach [3] uses a learned generative\nIK solver, IKFlow [14], which learns the distribution of\nuniformly sampled IK solutions and efficiently generates a\ndiverse set of IK solutions.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\nTo ensure sufficient density of IK solutions, many previous\napproaches specify a fixed number of IK solutions for each\nwaypoint, represented by m. For example, Stampede [1] sets\nm=250, IKLink [4] sets m=300, and CppFlow [3] sets\nm=175. We note that these numbers are used for a 7-DoF\nrobotic arm to track a fully constrained end-effector trajectory.\nFor scenarios involving a more redundant robot (DoF>7)\nor a semi-constrained trajectory, more IK solutions may be\nnecessary. This is because the solution space is larger and\nrequires more IK solutions to densely cover the entire space.\n2) Graph Construction: The sampled IK solutions are used\nas vertices to construct a layered graph where each layer\ncorresponds to a waypoint on the end-effector trajectory. Edges\nconnect vertices in consecutive layers if the robot can move\nbetween the two IK solutions within the time budget specified\nby the reference trajectory. Edge weights are defined based on\nvarious problem formulations such as total joint movement [1]\nor maximum joint movement [3].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n3) Graph Search: Once the graph is constructed, any\npaths within the graph represent possible robot motions by\nconnecting the IK solutions. The shortest path from the first\nlayer to the last layer corresponds to a high-quality motion\nthat tracks the trajectory. Different methods are utilized to\nsearch for the shortest path. For example, Descartes [6] uses\nDijkstra’s algorithm, Niyaz et al. [7] uses lifelong planning\nA∗, Stampede [1] uses value iteration, and IKLink [4] uses a\ndynamic programming method with two objectives.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAnalysis: Although multiple IK solutions are sampled for\na waypoint, ultimately, only one IK solution is selected to\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nFig. 2. An illustration of the guided anytime algorithmic framework. In the 1st iteration, A a limited set of IK solutions are sampled for specific waypoints.\nB The IK solutions construct a graph with sparse edges (dashed lines) and a guide path (red) is identified by searching in the graph. C Additional IK\nsolutions are sampled with a bias toward the guide path. D Dense edges (solid lines) are added to connect vertices in adjacent layers and an initial solution\n(red) is identified by searching through the dense edges. In the 2nd iteration, E additional sparse edges are added to connect the newly added vertices, and a\nnew guide path (red) is found by searching through both sparse and dense edges. F More vertices are sampled, biasing toward the new guide path. G After\nadditional dense edges are added, a new solution (red) is identified in the new graph. In subsequent iterations, the algorithm continues to densify the graph\nand refine the solutions.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\npath is refined by adding vertices near it and connecting them\nwith dense edges. An initial solution is found by searching\nover the dense edges. The process is repeated by identifying\nnew guide paths, performing further sampling around them,\nand finding new solutions.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nStages: Our framework contains six stages, briefly described\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nhere. The details of the stages are outlined in §IV.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n1) Sparse Vertex Sampling: In contrast to the conventional\nframework which samples IK solutions for every waypoint,\nthis stage samples a limited number of IK solutions for a subset\nof waypoints spaced apart. We sample at every s waypoint,\nwhere the sparse step size s is a hyperparameter.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n2) Sparse Edge Addition: This stage adds sparse edges to\nthe graph, connecting vertices that are s layers apart. While\nsparse edges still correspond to feasible motion segments,\nthey typically do not accurately track the reference trajectory\nbecause intermediate waypoints are omitted.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n3) Guide Path Search: This stage identifies a guide path\nby finding the shortest path from the first to the last layer,\nusing both dense and sparse edges. Guide paths correspond\nto motions that approximately track the reference end-effector\ntrajectory. The heuristic assumes that high-quality solutions\nare likely to be found near guide paths.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n4) Additional Vertex Sampling: This stage adds vertices\nto the graph through a combination of random sampling\nand targeted sampling around a guide path. The underlying\nassumption is that IK solutions near the guide path are more\nlikely to yield high-quality solutions. In addition, we also\nrandomly sample an equivalent number of IK solutions. This\nhelps avoid local minima where guide paths are misleading\nand ensures that the algorithm converges to the same worst-\ncase expected performance as the conventional approach.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\ncertain sparse edges are superseded by the dense edges.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n6) Solution Search: This stage identifies a solution by\nfinding the shortest path from the first to the last layer using\nonly dense edges. The solution, containing only dense edges,\nprecisely tracks the reference trajectory.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nIncremental Improvement: As shown in Algorithm 1, after\ngenerating a solution, the algorithm repeats the process, which\ninvolves identifying a new guide path, sampling additional\nvertices with a bias toward this new guide path, adding dense\nedges to connect the new vertices, and finding a new solution\nin the new graph. Because each new graph contains vertices\nand dense edges from its predecessor, each new solution is at\nleast as good as, if not better than, the solution before, thus\nensuring incremental improvement. The algorithm terminates\nupon reaching a predefined threshold, such as maximum\nrunning time or sampling capacity.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nAnalysis: The proposed framework involves random sam-\npling IK solutions, which mimics the process of the baseline\napproaches. Therefore, given sufficient time, our method will\ngenerate the same (probabilistic) sample set as the baseline\napproaches. With finite time and sampling budget, even the\nbaseline approaches cannot provide guarantees of optimality,\nalthough Holladay [2] has proven that a similar algorithm con-\nverges towards optimality as the sampling density grows. Most\nprior works [1], [4], [3] empirically show the effectiveness of\ntheir algorithms. Similarly, we empirically demonstrate that\nour sampling strategy often more quickly finds solutions with\nbetter or equal quality in §V.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIV. TECHNICAL DETAILS\nIn §III-D, we gave an overview of our anytime algorithmic\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nframework; this section details its stages.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n5) Dense Edge Addition: This stage adds dense edges to\nthe graph to connect vertices in adjacent layers. In addition,\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n1) Sparse Vertex Sampling: This stage involves sampling\nm0 IK solutions for every s waypoint, starting from index\n**BLOCK**fs== 8.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nAlgorithm 1: Guided Algorithmic Framework\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.5**r== 0.3**\nthe need for a sparse edge.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.1**l== 0.2**r== 0.5**\n: an end-effector trajectory χ={(t1, p1), ..., (tn, pn)}\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ninput\noutput : a joint space trajectory p, which is refined over iteration\nhparam: initial number of IK solutions for each waypoint m0,\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nsparse step size s, max number of iterations imax\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.2**l== 0.1**r== 0.7**\n1 V ← SparseSample(χ, s, m0)\n2 E ← ∅, i ← 0\n3 while i < imax do\ni ← i + 1\n\nE ← AddSparseEdges(V, E, χ)\nG ← (V, E)\nξ′ ← SearchHybrid (G)\nV ← AdditionalSample(V, χ, ξ′)\nE ← AddDenseEdges(V, E, χ)\nG ← (V, E)\nξ ← SearchDense (G)\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\n▷ Sparse vertex sampling\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\n▷ Sparse edge addition\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.2**l== 0.4**r== 0.5**\n▷ Guide path search\n▷ Sample more vertices\n▷ Dense edge addition\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\n▷ Solution search\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nSparseSampling(χ, s, m0) randomly samples m0 IK solutions for every\ns waypoints along the reference trajectory χ. Specific sampling methods are\ndiscussed in §III-B1.\nSearchHybrid(G) finds the shortest path from the first layer to the last\nlayer in G, using both dense and sparse edges. Specific search methods are\ndiscussed in §III-B3.\nSearchDense(G) finds the shortest path from the first layer to the last layer\nin G, using only dense edges.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nAlgorithm 2: AddSparseEdges\n: vertices V , edges E\nan end-effector trajectory χ={(t1, p1), ..., (tn, pn)}\n: updated edges E\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.6**\noutput\nhparam : sparse step size s, scaling factor η\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n1 for x = s+1 to n do\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nfor y1 = 1 to |V [x−s]| do\nfor y2 = 1 to |V [x]| do\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nif Linkable(V [x−s][y1], V [x][y2], tx−tx−s) and\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nCost(V [x−s][y1], V [x][y2])∗η <\nCostDense(V [x−s][y1], V [x][y2]) then\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.5**l== 0.2**r== 0.6**\ne ← (V [x−s][y1], V [x][y2])\ne.weight = Cost(V [x−s][y1], V [x][y2])\ne.is_sparse = True\nE ← E ∪ {e}\n**BLOCK**fs== 8.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nLinkable(V1, V2, ∆t) returns true if the robot can move between the two\ngiven joint configurations within the time duration, without exceeding joint\nvelocity limits.\nCost(V1, V2) returns the cost to move directly between the two joint config-\nurations. As discussed in §III-B2, the cost depends on problem formulation.\nCostDense(V1, V2) returns the lowest cost that moves between the two\njoint configurations using dense edges. The lowest cost can be computed\nusing graph search methods. If the two joint configurations are not connected\nby dense edges, return infinity.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n1 and including index n. A total of ⌈n/s + 1⌉ × m0 IK\nsolutions are sampled, where n is the number of waypoints\non the reference trajectory and ⌈·⌉ is a ceiling function that\nrounds a real number up to the nearest integer. The specific\nsampling methods described in §III-B1 can be used to sample\nIK solutions. This stage generates the initial set of vertices in\nthe graph, which are used to find an initial guide path.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n2) Sparse Edge Addition: This stage adds sparse edges\nto the graph. Algorithm 2 outlines the AddSparseEdges\nfunction. In order to add a sparse edge between vertices that\nare s layers away, the Linkable function checks if the robot\ncan move between the configurations within the time budget.\nIn our implementation, Linkable assumes linear movements\nin joint space and checks if a linear movement is within the\nrobot’s joint velocity limit. In addition, the algorithm checks\nwhether the two vertices are already connected by dense edges.\nIf a path composed of dense edges connects the two vertices\nand its cost is similar to the cost of the sparse edge, it suggests\nthat the area has already been sufficiently sampled, eliminating\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n3) Guide Path Search: A guide path is identified by finding\nthe lowest cost path from the first to the last layer of the graph,\nusing both dense and sparse edges. Specific graph search\nalgorithms discussed in §III-B3 can be used to find the path\nwith the lowest cost.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n4) Additional Vertex Sampling: This stage takes a guide\npath as input and biases sampling toward it. As shown in\nAlgorithm 3, this stage first samples around every sparse edge\nwithin the guide path, then randomly samples an equivalent\namount of IK solutions. Sampling around the sparse edges\nallows them to be replaced by dense edges.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nIn order to sample around a sparse edge, we linearly inter-\npolate joint configurations on the sparse edge (LinInterp),\napply some random disturbance (AddRandDelta), and use\nit as starting configurations of an IK solver. The IK solver\nfinds IK solutions near the starting configuration. We use\nRelaxedIK [17] in our implementation, but any other IK\nsolvers mentioned in §III-B1 are also compatible.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nIn order to randomly sample IK solutions across the entire\ntrajectory, we first randomly select waypoints using Softmax,\nwhich assigns higher selection probabilities to waypoints with\nfewer randomly sampled IK solutions.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nexp(−|Vr[x]|)\ni=0 exp(−|Vr[i]|)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nwhere x is the waypoint index, and |Vr[x]| is the number of\nexisting randomly sampled IK solutions for waypoint x. After\nselecting a waypoint, we generate a random IK solution by\ninitiating an IK solver’s starting configuration at a random\nlocation (RandConfig) in the robot’s joint space.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\n5) Dense Edge Addition: This stage adds dense edges to the\ngraph, which connect vertices in adjacent layers. As detailed\nin Algorithm 4, the procedure involves iterating over all pairs\nof vertices located on adjacent layers. The algorithm uses\nthe Linkable function to check the feasibility of each pair.\nAfter adding dense edges, the algorithm identifies and removes\nthe sparse edges that have been superseded by dense edges.\nSpecifically, if there exists a path composed of dense edges\nthat connects the two endpoint vertices of a sparse edge, and\nthe path’s cost is similar to the sparse edge’s cost, maintaining\nthe sparse edge becomes unnecessary. Our approach shares a\nsimilar idea with lazy planning [19], [20], which delays the\nevaluation of edges until they are necessary for the solution.\nIn our approach, sparse edges serve as estimators and a more\naccurate cost is computed when replacing sparse edges with\ndense edges.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n6) Solution Search: This stage identifies a solution by\nfinding the lowest cost path from the first to the last layer,\nusing only dense edges. Specific graph search approaches\ndescribed in §III-B3 can be used to find the shortest path.\nThe identified solution corresponds to a motion that accurately\ntracks every waypoint on the reference trajectory.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nV. EXPERIMENTS\nIn this section, we compare our proposed algorithm frame-\nwork with the two baseline approaches described in §III:\nthe conventional sequential framework and the naïve anytime\nframework. We conducted three independent experiments in\n**BLOCK**fs== 8.0**p== 5.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nAlgorithm 3: AdditionalSample\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.1**l== 0.2**r== 0.5**\n: vertices V , a guide path ξ′,\nan end-effector trajectory χ={(t1, p1), ..., (tn, pn)}\n: updated vertices V\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\noutput\nhparam : number of new IK solutions per waypoint md\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nperturbation bound δ\n▷ Sample around the guide path\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\n1 foreach edge in ξ′ do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nif edge.is_sparse then\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nfor x= e.start_idx to e.end_idx do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.2**l== 0.2**r== 0.6**\nr = (x−e.start_idx)/(e.end_idx−e.start_idx)\nq = LinInterp(e.start_vertex, e.end_vertex, r)\nfor i = 1 to md do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nq = AddRandDelta(q, δ)\nv = IK(px, q)\nV = V ∪ {v}\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\n▷ Randomly Sample\n10 Pr = CompProb(V )\n11 for i = 1 to |V | do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nx ← SampleIndex(p)\nv = IK(px, RandConfig())\nV = V ∪ {v}\nPr = CompProb(V )\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nLinInterp(V1, V2, r) returns a joint configuration along the straight line\nbetween V1 and V2 based on a specified ratio r.\nAddRandDelta(q, δ) adds random disturbance rand(−δ, δ) to each joint\nvalue qj , ∀j ∈ {1, ..., k}, and clips q to the valid joint range.\nIK(p, qs) returns an IK solution that moves the end-effector to p. The IK\nsolution is regularized to be near the starting configuration qs.\nCompProb(V ) returns the probability of selecting a waypoint using Eq. 1.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nAlgorithm 4: AddDenseEdges\n: vertics V , edges E,\nan end-effector trajectory χ={(t1, p1), ..., (tn, pn)}\n: updated Edges E\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\noutput\nhparam : scaling factor η\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\n1 for x = 2 to n do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.7**\nfor y2 = 1 to |V [x]| do\n▷ Add dense edges\nfor y1 = 1 to |V [x−1]| do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\ne ← {(V [x−1][y1], V [x][y2])}\nif Linkable(V [x−1][y1], V [x][y2], tx−tx−1) then\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\ne.weight = Cost(V [x−1][y1], V [x][y2])\ne.is_sparse = False\nE ← E ∪ {e}\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\n▷ Remove sparse edges\nif x > s then\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nfor y1 = 1 to |V [x−s]| do\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\ne ← {(V [x−s][y1], V [x][y2])}\nif e ∈ E and Cost(V [x−s][y1], V [x][y2])∗η <\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nCostDense(V [x−s][y1], V [x][y2]) then\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nsimulation, each involves two testbeds. The first testbed tracks\n10 randomly generated trajectories, comparing our frame-\nwork with various parameter settings (step size s=3, 5, or 10)\nagainst the baselines. The second testbed tracks a trajectory 10\ntimes and we report the average, best, and worst motions gen-\nerated by each method to provide a comprehensive overview\nof the performance variations.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.0**t== 0.9**l== 0.1**r== 0.5**\nOur implementation is based on the open source IKLink\nlibrary in Rust. We note that the Rust implementation per-\nforms faster than the implementation evaluated in the original\npaper [4]. Our framework used md=5, δ=0.2, η=1.1 (across\nall experiments), m0=50 (Experiments A&B) and m0=500\n(Experiment C). All evaluations were performed on a laptop\nwith an Intel i7-11800H 2.30 GHz CPU and 16 GB of RAM.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nWe apply our framework to the Stampede algorithm [1]\nto find robot motions that track end-effector trajectories with\nminimal joint movements. As proposed in the original pa-\nper, Stampede used the conventional sequential framework.\nStampede samples IK solutions by initiating an optimization-\nbased IK solver, RelaxedIK [17], with starting configurations\nsampled from a uniform distribution. Additionally,\nit uses\nvalue iteration for graph search. Since our objective is to\nminimize joint movements, we define the edge weights within\nthe graph as the Euclidean distances in joint space between\ntwo joint configurations.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThis experiment uses a 7-degrees-of-freedom KUKA LBR\niiwa robot. The first testbed tracks 10 random cumulative\ncubic Bézier curves [22] for smooth position and orientation\nchanges. These trajectories have an average length of 1.26 m,\nan average angular displacement of 5.13 rad, and an average of\n379.4 waypoints. The second testbed replicates a writing task\nfrom prior work [3], [11], where the robot traces a “hello”\ntrajectory. The trajectory is rescaled to fit iiwa’s workspace.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nAs shown in the left column of Figure 3, while all three\napproaches generated motions with similar joint movements,\nour framework achieved initial solutions 2× faster. The results\nshow that our heuristic is effective for simple trajectories and\nenables fast identification of effective motions.\nB. Experiment B - Tracking with Minimal Reconfigurations\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nWe apply our framework to the IKLink algorithm [4]\nwhich utilizes the conventional sequential framework to track\nthe end-effector trajectory of any complexity. If a reference\ntrajectory is too complex to be tracked as a single, continuous\npath, IKLink generates motions with minimal reconfigurations.\nIn addition, IKLink has a secondary objective of minimizing\njoint movements. Similar to Stampede, IKLink uses RelaxedIK\n[17] to uniformly sample IK solutions. It also leverages\nRelaxedIK’s velocity regularization to find IK solutions close\nto those in the previous layer,\nthereby generating smooth\nmotions. Moreover, similar IK solutions are merged using\na clustering method. IKLink finds motions using dynamic\nprogramming, which incorporates both the number of recon-\nfigurations and joint movements as objectives.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThis experiment uses a 7-DoF Franka Panda robot. The\nfirst testbed tracks random trajectories that consist of two con-\nsecutive cubic cumulative Bézier curves [22]. The trajectories\naverage 2.26 m in length, 12.07 rad in angular displacement,\nand 677.6 waypoints. The second testbed involves a 3D\nscanning task, in which a robot accurately moves a sensor\nalong a predefined trajectory, ensuring the sensor consistently\npoints at the object.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nAs shown in Figure 3, our framework was more efficient\nand converged to motions with fewer or equal configurations,\ncompared to both the conventional framework (baseline 1) and\nthe naïve anytime framework (baseline 2).\nC. Experiment C - Tracking Trajectories with Tolerances\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIn this experiment, we show how our framework ex-\ntends IKLink’s capability [4] to track semi-constrained end-\neffector trajectories. IKLink was originally designed for fully-\nconstrained trajectory tracking, which requires all 6 DoF of\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFig. 3. Results of our three experiments, each on two testbeds. For random trajectory tracking (top row), the results are averaged over 10 randomly generated\ntrajectories. For specific tasks (bottom row), the results are averaged over 10 repetitions of the same trajectory, with colored regions indicating the range\nbetween the maximum and minimum values within these repetitions. In the line charts, the initial point of a line encodes the average computation time to get\ninitial solutions. Left column: our framework enabled Stampede to find initial effective solutions faster than the baselines. Middle column: IKLink with our\nframework converged faster than with the naïve framework. Right column: for trajectories with tolerances, our framework enabled IKLink to find motion\nwith fewer reconfigurations than the baseline frameworks. The robot visualizations were generated using Motion Comparator [21]3.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.5**t== 0.4**l== 0.4**r== 0.4**\nTABLE I\nEXPERIMENT RESULTS\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.8**\nMethod\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\nBaseline 1\nBaseline 2\nOurs (s=5)\nOurs (s=3)\nOurs (s=10)\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\nTestbed 1\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\nTestbed 2\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\nTestbed 1\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.6**r== 0.4**\nTestbed 2\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.7**r== 0.3**\nTestbed 1\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nTestbed 2\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n†: Average computation time to achieve the same performance of Baseline 1 (the conventional framework)\n‡: Average performance achieved within Baseline 1’s computation time (JM=Joint Movement, # RC=Number of Reconfigurations)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nthe end-effector to be accurate. This requirement becomes\noverly restrictive in applications such as welding, where\nthe torch may rotate around its principal axis. In contrast,\nsemi-constrained trajectory tracking allows the end-effector\nto move within certain tolerances. Semi-constrained tracking\nposes a greater challenge to graph-based approaches because\nthe solution space is larger and requires more samplings to\nsufficiently cover the solution space. We demonstrate that the\nIKLink using the conventional framework struggles to quickly\nfind plausible motions, and the proposed anytime framework\nenables IKLinks to efficiently and effectively track trajectory\nwith tolerances. We use RangedIK [23] as the IK solver, which\nis an extension of RelaxedIK that generates IK solutions that\nmove the end-effector within specified tolerances.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThe first testbed randomly generates 10 welding trajectories\nfor a Franka Panda robot. Each trajectory is composed of\nfour cumulative cubic Bézier curves [22]. The trajectories\naverage 1.29 m in length, 22.70 rad in angular displacement,\nand 646.8 waypoints. Compared to the random trajectories\nin Experiments A and B,\nthese trajectories involve more\nrotational movements. In the welding task, the tolerance is\nalong the torch’s principal axis, i.e., the robot is allowed to\nfreely rotate its end-effector along the principal axis (z-axis).\nAs shown in Figure 3, the principal axis is angled 45 degrees\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nfrom the robot’s last axis. The robot must coordinate the\nmovement of all its joints to exploit the tolerance, in contrast to\njust rotating the last joint when the principal axis aligns with\nthe last axis. In the second testbed, a 7-degrees-of-freedom\nRethink Robotics Sawyer robot performs a sanding task by\ntracking a spiral trajectory. The robot can freely rotate the\nsanding tool around its principal axis, which is oriented 90\ndegrees from the robot’s last axis.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nAs shown in Figure 3, our framework enabled IKLink to\nquickly find motions with fewer reconfigurations than the\nbaseline frameworks, while IKLink with both the conventional\nand naïve anytime frameworks struggled to find optimal solu-\ntions for trajectories with tolerances.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nSummary: Across all experiments, our anytime framework\nrequires less computation time to achieve motions of the same\nquality and reaches equal or better motion quality within\nthe same time frame compared to both the conventional and\nnaïve anytime frameworks. Figure 3 shows that our framework\nconsistently outperforms the baselines (our lines are consis-\ntently below or overlapping with the baselines), while Table I\npresents the corresponding quantitative results.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nExperiments A and B show that our framework accelerates\nthe performance of both Stampede and IKLink, enabling\n3Visualization tool: https://github.com/uwgraphics/MotionComparator\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nthem to find motions of higher or equal quality in less time,\nin comparison to both the conventional and naïve anytime\nframeworks. Experiment C shows that our framework extends\nIKLink’s ability to efficiently generate motions for tracking\nsemi-constrained trajectories.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nOur results also show the effects of the hyperparameter\nstep size s, which defines the length of sparse edges. A\nsmaller s increases the number of IK samples in Stage 1,\nsparse vertex sampling, thereby raising computation time for\nobtaining initial solutions. Meanwhile, a larger s reduces the\naccuracy of guide paths as cost estimators, leading to slower\nalgorithm convergence. In our experiments, we observe a\nsweetspot at s=5.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nVI. DISCUSSION\nThis section summarizes the limitations, implications, and\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nconclusions of our work.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nLimitations: Our work has several limitations that suggest\nfuture research directions. First, our algorithm lacks a quality-\nbased stopping threshold; users can specify the maximum\nnumber of iterations, running time, or sampling budget, but\nthe algorithm does not automatically stop upon convergence.\nFuture work should explore the effects of adaptive stopping\nthresholds such as when the guide path no longer updates with\niterations. Second, our method uses a heuristic to bias sam-\npling in graph-based approaches. While we provide empirical\nevidence to demonstrate its ability to efficiently produce high-\nquality solutions, we cannot guarantee consistent performance\nacross all scenarios. In certain scenarios, the heuristic may\nbe misleading, causing the method to be slower than the\nnaive anytime framework. Future work may provide a more\nrigorous understanding of the heuristic’s effectiveness. Third,\nwhile we expect that our framework generalizes across many\ngraph-based tracking algorithms, we have only demonstrated\nit on two. Finally, the present work does not consider dynamic\nconstraints, focusing solely on the velocity constraints of robot\njoints. Future work should consider incorporating acceleration\nconstraints and the inertia of the robot to improve the quality\nof generated motions.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nImplications: The guided anytime framework presented in\nthis work enables graph-based approaches to efficiently and\neffectively find motions that accurately move a manipulator’s\nend-effector along reference trajectories. It quickly generates\ninitial solutions and continues to refine them as needed. We\nhave demonstrated that it accelerates and improves solutions\nover prior methods and enables solving problems that a prior\nmethod cannot. The proposed framework is particularly bene-\nficial for scenarios where end-effector trajectories are complex\nor have specific tolerances.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nConclusion: This paper presented an anytime framework\nthat enables graph-based trajectory tracking algorithms to\nefficiently and effectively find robot motions. Our framework\ngenerates trajectories of equal or better quality in less time\nthan previous approaches.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nREFERENCES\n**BLOCK**fs== 8.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[1] D. Rakita, B. Mutlu, and M. Gleicher, “Stampede: A discrete-\noptimization method for solving pathwise-inverse kinematics,” in IEEE\nInt. Conf. on Robotics and Automation.\nIEEE, 2019, pp. 3507–3513.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[2] R. Holladay, O. Salzman, and S. Srinivasa, “Minimizing task-space\nfrechet error via efficient incremental graph search,” IEEE Robotics and\nAutomation Letters, vol. 4, no. 2, pp. 1999–2006, 2019.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[3] J. Morgan, D. Millard, and G. S. Sukhatme, “Cppflow: Generative\ninverse kinematics for efficient and robust cartesian path planning,” in\nInt. Conf. on Robotics and Automation.\nIEEE, 2024, pp. 12 279–12 785.\n[4] Y. Wang, C. Sifferman, and M. Gleicher, “Iklink: End-effector trajectory\ntracking with minimal reconfigurations,” in IEEE Int. Conf. on Robotics\nand Automation (ICRA).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.7**r== 0.1**\nIEEE, 2024, pp. 12 165–12 171.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[5] T. Yang, J. V. Miro, Y. Wang, and R. Xiong, “Optimal task-space\ntracking with minimum manipulator reconfiguration,” IEEE Robotics\nand Automation Letters, vol. 7, no. 2, pp. 5079–5086, 2022.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[6] ROS-I. (2015) Descartes—a ros-industrial project for performing path-\nplanning on under-defined cartesian trajectories. [Online]. Available:\nhttp://wiki.ros.org/descartes\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[7] S. Niyaz, A. Kuntz, O. Salzman, R. Alterovitz, and S. Srinivasa,\n“Following surgical trajectories with concentric tube robots via nearest-\nneighbor graphs,” in Proceedings of the 2018 International Symposium\non Experimental Robotics. Springer, 2020, pp. 3–13.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[8] M. Cefalo, G. Oriolo, and M. Vendittelli, “Task-constrained motion\nplanning with moving obstacles,” in 2013 IEEE/RSJ Int. Conf. on\nIntelligent Robots and Systems.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.1**\nIEEE, 2013, pp. 5758–5763.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[9] R. M. Holladay and S. S. Srinivasa, “Distance metrics and algorithms\nfor task space path optimization,” in IEEE/RSJ Int. Conf. on Intelligent\nRobots and Systems (IROS).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.1**\nIEEE, 2016, pp. 5533–5540.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[10] J. Schulman, Y. Duan, J. Ho, A. Lee, I. Awwal, H. Bradlow, J. Pan,\nS. Patil, K. Goldberg, and P. Abbeel, “Motion planning with sequential\nconvex optimization and convex collision checking,” The International\nJournal of Robotics Research, vol. 33, no. 9, pp. 1251–1270, 2014.\n[11] M. Kang, H. Shin, D. Kim, and S.-E. Yoon, “Torm: Fast and accurate\ntrajectory optimization of redundant manipulator given an end-effector\npath,” in 2020 IEEE/RSJ International Conference on Intelligent Robots\nand Systems (IROS).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nIEEE, 2020, pp. 9417–9424.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[12] M. Yoon, M. Kang, D. Park, and S.-E. Yoon, “Learning-based initializa-\ntion of trajectory optimization for path-following problems of redundant\nmanipulators,” in IEEE Int. Conf. on Robotics and Automation (ICRA).\nIEEE, 2023, pp. 9686–9692.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[13] R. K. Malhan, S. Thakar, A. M. Kabir, P. Rajendran, P. M. Bhatt,\nand S. K. Gupta, “Generation of configuration space trajectories over\nsemi-constrained cartesian paths for robotic manipulators,” IEEE Trans.\nAutomation Sci. and Eng., vol. 20, no. 1, pp. 193–205, 2022.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[14] B. Ames, J. Morgan, and G. Konidaris, “Ikflow: Generating diverse\ninverse kinematics solutions,” IEEE Robotics and Automation Letters,\nvol. 7, no. 3, pp. 7177–7184, 2022.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[15] J. De Maeyer, B. Moyaers, and E. Demeester, “Cartesian path planning\nfor arc welding robots: Evaluation of the descartes algorithm,” in 2017\n22nd IEEE International conference on emerging technologies and\nfactory automation (ETFA).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nIEEE, 2017, pp. 1–8.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[16] P. Beeson and B. Ames, “Trac-ik: An open-source library for improved\nsolving of generic inverse kinematics,” in 2015 International Conf. on\nHumanoid Robots (Humanoids).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nIEEE, 2015, pp. 928–935.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[17] D. Rakita, B. Mutlu, and M. Gleicher, “Relaxedik: Real-time synthesis\nof accurate and feasible robot arm motion.” in Robotics: Science and\nSystems, vol. 14. Pittsburgh, PA, 2018, pp. 26–30.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[18] C. W. Wampler, “Manipulator inverse kinematic solutions based on\nvector formulations and damped least-squares methods,” IEEE Trans.\non Systems, Man, and Cybernetics, vol. 16, no. 1, pp. 93–101, 1986.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[19] R. Bohlin and L. E. Kavraki, “Path planning using lazy prm,” in ICRA.\nMillennium conference. IEEE Int. Conf. on Robotics and Automation.\nSymposia proceedings, vol. 1.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\nIEEE, 2000, pp. 521–528.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[20] N. Haghtalab, S. Mackenzie, A. Procaccia, O. Salzman, and S. Srinivasa,\n“The provable virtue of laziness in motion planning,” in Int. Conf. on\nAutomated Planning and Scheduling, vol. 28, 2018, pp. 106–113.\n[21] Y. Wang, A. Peseckis, Z. Jiang, and M. Gleicher, “Motion comparator:\nVisual comparison of robot motions,” IEEE Robotics and Automation\nLetters, vol. 9, no. 9, pp. 7699–7706, 2024.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[22] M.-J. Kim, M.-S. Kim, and S. Y. Shin, “A general construction scheme\nfor unit quaternion curves with simple high order derivatives,” in 22nd\nAnnual Conf. on Computer Graphics and Interactive Technologies, 1995,\npp. 369–376.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[23] Y. Wang, P. Praveena, D. Rakita, and M. Gleicher, “Rangedik: An\noptimization-based robot motion generation method for ranged-goal\ntasks,” in IEEE Int. Conf. on Robotics and Automation (ICRA).\nIEEE,\n2023, pp. 8090–8096.",
         "– Preprint – Anytime Planning for End-Effector Trajectory Tracking Yeping Wang and Michael Gleicher M ANY applications require a robot manipulator to accu- rately and smoothly move its end-effector along a spe- cific trajectory. These applications involve welding, sanding, polishing, painting, and additive manufacturing. For redundant manipulators or applications with tolerances, there exist in- finitely many possible motions to track a reference end-effector trajectory. Thus, planning algorithms seek to find optimal motions among these possibilities based on criteria such as minimal joint movement [1], minimal end-effector error [1], [2], minimal maximum joint velocity [3], or minimal number of reconfigurations, i.e., instances where the robot pauses task execution and restarts from another joint configuration [4], [5]. To track an end-effector trajectory based on some optimality criteria, common graph-based approaches [1], [3], [4], [6], [7] first sample inverse kinematics (IK) solutions for each waypoint on the reference trajectory. These IK solutions serve as vertices to construct a layered graph, where each layer corresponds to a waypoint. Edges are added to link IK solu- tions in adjacent layers, and these edges’ weights are defined according to the optimality criteria. Finally, a graph search method is utilized to find the optimal motion. The success of this approach relies heavily on the density of the sampling to sufficiently discretize the solution space. Existing graph- based trajectory tracking approaches often rely on uniformly dense IK sampling, which leads to long delays in finding initial solutions. In practical scenarios with limited computational resources, anytime algorithms are preferred because they can generate feasible solutions quickly and progressively refine them over time. This flexibility allows anytime algorithms to be stopped at any time, enabling trade-offs between solution quality and computation time. In this work, we present an anytime algorithmic framework that enhances existing approaches to efficiently and effec- tively generate robot motions to track reference end-effector trajectories. Our framework enhances existing methods by incorporating a heuristic to prioritize samples that are likely to lead to good solutions. Our key insight is to identify guide paths that approximately track the reference trajectory and strategically bias sampling toward the guide paths, which progressively densifies the graph. This approach enables fre- quent identification of effective solutions within a significantly reduced timeframe. Over time, the graph converges towards the dense graph used in conventional algorithms. We show that, in the worst case, our anytime framework converges to the conventional framework, although in practice its ability to sample strategically usually leads to better results in less time. The algorithmic framework is independent of specific IK sampling algorithms, optimality criteria, or graph searching algorithms. We provide an open-source implementation of our framework 1. The central contribution of this work is a guided anytime algorithmic framework (Sections III-D and IV). To explain our approach, we first describe the conventional sequential framework and a naïve anytime framework as baselines (Sec- tions III-B and III-C). We evaluated our framework through three experiments (§V). First, we applied it to two end-effector trajectory tracking algorithms, Stampede [1] and IKLink [4], originally based on the conventional framework. Our results show that our framework accelerates both algorithms, gener- ating solutions with less computation time than the conven- tional and naïve frameworks, while matching or exceeding their solution quality. Additionally, we applied it to semi- constrained trajectory tracking, which expands the solution space by allowing tolerances and requiring more IK samplings. Unlike baseline frameworks, which are inefficient due to naïve sampling, our framework enhances IKLink’s efficiency and effectiveness for this task. The end-effector trajectory tracking problem, also known as path-wise inverse kinematics [1], task-space non-revisiting tracking [5], or task-constrained motion planning [8], involves various approaches based on input type. Specifically, trajectory tracking methods [1], [2], [4], [5], [6] take a timestamped trajectory as input, whereas path tracking methods [3], [7] track a sequence of coordinates without timing. End-effector trajectory tracking methods can be broadly categorized into two groups: trajectory optimization and graph- based approaches. Trajectory optimization directly optimizes a joint-space trajectory while satisfying constraints. For exam- ple, Holladay et al. [9] utilize TrajOpt [10], a trajectory opti- mization method, to minimize the Fréchet distances between current solutions and a given reference trajectory. Instead of Fréchet distances, Torm [11] minimizes the summed Euclidean distance between corresponding waypoints on the current and reference trajectories. These optimization methods require an initial trajectory as a starting point, are sensitive to this initial trajectory [12], and are prone to be stuck in local minima [9]. Meanwhile, graph-based approaches [1], [3], [4], [6], [7] construct a hierarchical graph where vertices represent inverse kinematics (IK) solutions. A path within the graph defines a robot motion by sequentially connecting the IK solutions. We will review these approaches in §III-B as part of the discussion on the conventional algorithmic framework. Below, we discuss IK sampling strategies in graph-based approaches. B. IK Sampling in Graph-based Trajectory Tracking In graph-based end-effector trajectory tracking, the majority of the computation time is consumed by sampling inverse kine- matics (IK) solutions and establishing connections between them [13]. Some prior work [1], [4], [6], [7] exhaustively samples IK solutions before searching for a path, resulting in long computation time before obtaining initial solutions. [2], [13]. Meanwhile, other approaches use incremental sam- pling to accelerate the procedure. For example, CppFlow [3] leverages a generative IK solver, IKFlow [14], which rapidly produces a diverse set of IK solutions by learning the distribution of uniformly sampled IK solutions. If the graph search algorithm fails to find a viable motion, the algorithm incrementally samples additional IK solutions to density the graph. In contrast to uniform sampling, Malhan et al. [13] use continuity in Cartesian space as a heuristic for IK selection during incremental graph construction. However, the heuristic is applicable solely to non-redundant robotic arms. Holladay et al. [2] presents strategies to balance uniform sampling with targeted sampling around certain areas. However, their approach is designed specifically to minimize the Fréchet dis- tance in Cartesian space, and it remains unclear how to adapt their strategies to address objectives such as minimizing joint movements. Our method, like Holladay et al. [2], balances uniform and targeted sampling, but differs by sampling around a guide path that roughly tracks the reference trajectory. In certain trajectory tracking scenarios, precise end-effector movements in all six degrees of freedom are not necessary, i.e., allowing for certain tolerances in Cartesian space. For instance, in a drawing task, the robot may be permitted to tilt or rotate the pen as long as the pen tip position remains precise and the motion remains collision-free. This problem is called semi-constrained end-effector trajectory tracking. Due to tolerances, the solution space expands, requiring more IK solutions to cover the solution space. Graph-based approaches with uniform sampling, e.g., Descartes [6], have a significant increase in computational load when using redundant robots or having tolerances on multiple degrees of freedom [15]. Therefore, developing a more efficient algorithm is essential for semi-constrained end-effector tracking. In this work, we present a guided anytime algorithmic framework to accelerate graph-based trajectory tracking approaches. We show how this framework can efficiently and effectively compute motions to track semi-constrained end-effector trajectory in §V. III. TECHNICAL OVERVIEW In this section, we first formalize our problem statement and describe the conventional algorithmic framework. We then describe a naïve anytime framework and why it is ineffective. Finally, we give an overview of our guided anytime framework and its advantages over previous approaches. Consider a k degree of freedom robot manipulator whose joint configuration and end-effector pose are denoted by q∈Rk and p∈SE(3), respectively. End-effector trajectory tracking refers to the problem of computing a joint space trajectory ξ:[0, Tχ]→Rk that drives the robot’s end-effector along a desired trajectory χ:[0, Tχ]→SE(3), where Tχ represents the total time duration of the end-effector trajectory. In practice, the target end-effector trajectory χ is often represented in a discrete form {(t1, p1), ..., (tn, pn)}, where pi is the end- effector pose at timestamp ti. We assume that the waypoints are sufficiently dense to accurately approximate χ. in a short time interval τ >0, all In general, there are some requirements for joint space continuity, e.g., joint movements are within their velocity limits, vmin≤[ξ(t+τ )j −ξ(t)j]/τ ≤vmax, ∀j∈{1, ..., k}, ∀t∈[0, Tχ−τ ]. However, in trajectory is complex and can scenarios where the input not be tracked as a single, continuous path, exceptions to this requirement may be permissible if the task allows for interruptions. In such instances, joint discontinuities may be introduced deliberately. Each joint discontinuity requires the robot to perform an arm reconfiguration, in which the robot pauses the task execution, relocates itself in the joint space, and resumes task execution from another configuration. This work focuses on the cases where the robot manipulator has some redundancy; it is either a redundant arm (k > 6) or a non-redundant arm performing semi-constrained trajectory tracking, where certain tolerances are permitted on the end- the trajectory can effector poses. Due to the redundancy, be tracked by infinitely many possible motions, requiring optimization criteria to select the best solution. Graph-based trajectory tracking algorithms maintain a lay- ered graph G=(V, E), where each layer corresponds to a waypoint on the reference trajectory. V and E denote vertices and edges in the graph, respectively. The notation V [x] denotes all vertices in the layer corresponding to the x-th waypoint. V [x][y] represents the y-th IK solution that aligns the end- effector with the x-th waypoint. |V [x]| denotes the total number of vertices in V [x]. Many existing graph-based trajectory tracking algorithms use a sequential framework. As shown in Figure 1-A, these construct the robot motion. Hence, we seek ways to improve the sampling process, i.e., biasing sampling towards areas with a high probability of being selected. Additionally, the number of IK solutions decides the number of edges in the graph; a small set of IK solutions can reduce the time for connectivity checking and graph search. The aforementioned conventional framework does not pro- vide a solution until completion. In contrast, an anytime algo- rithm provides an initial solution and then iteratively refines it, enabling the process to be stopped at any time and allowing for tradeoffs between solution quality and computation time. As shown in Figure 1-B, a naïve anytime framework uses the same random sampling process to initially sample a smaller set of IK solutions, from which a layered graph is constructed. A graph search is then conducted to identify an initial solution. The solution is iteratively refined by sampling additional IK solutions, expanding the graph, and performing further graph searches to find new solutions. The solutions are always at least as good as, if not better than, the previous ones because the graph incorporates all vertices and edges from its previous version. The algorithm continues until it reaches a predefined threshold, such as running time or the number of iterations. Analysis: The naïve anytime framework has the advantage of generating an initial solution quickly and refining it over time. However, it requires some heuristic to find an effective initial solution. In our implementation, we use an optimization- based IK solver to find IK solutions that are close to those of the previous waypoints, which helps ensure smooth motion. This heuristic is similar to GreedyIK in Wang et al. [4]. Despite this, the naïve framework often converges slowly, because the samples are added in a random order. This effect is demonstrated in the experiments in §V. Meanwhile, our proposed algorithmic framework uses heuristics to bias sampling such that initial solutions are likely to be effective, and the additional sampling focuses on adding samples likely to improve the solution. D. Overview of Guided Anytime Algorithmic Framework Similar to the aforementioned approaches, the proposed framework maintains a layered graph, in which a layer corre- sponds to a waypoint on the reference trajectory and a vertex represents an IK solution. The key idea of our method is to bias sampling toward guide paths. A guide path is a sequence of vertices that approximately tracks the reference trajectory. It typically includes sparse edges that connect vertices that are a few layers apart. Upon refinement, guide paths are likely to be good solutions. A solution is a path through the graph with a vertex at every time step, thus accurately tracking the trajectory. During refinement, sparse edges within guide paths are potentially replaced by dense edges which connect vertices with adjacent timestamps, thereby gradually converting guide paths to solutions. As shown in Figure 2, our algorithm starts by constructing a graph in which IK solutions are sampled for certain waypoints and connected using sparse edges. An initial guide path is identified by searching over these sparse edges. The guide approaches sample inverse kinematics (IK) solutions for each waypoint on the end-effector trajectory, use these IK solutions as graph vertices, and search for a solution in the graph. 1) IK Sampling: The two primary goals of IK sampling are to find IK solutions that are diverse enough to cover the entire solution space and dense enough to construct a smooth motion. In order to generate diverse IK solutions, one common approach is to randomly sample starting configurations in a robot’s joint space and find IK solutions that are closest to the starting configurations using an optimization-based IK solver, such as Trac-IK [16] or RelaxedIK [17], or an iterative IK solver, such as Orocos KDL or the damped least squares IK algorithm [18]. Another approach [3] uses a learned generative IK solver, IKFlow [14], which learns the distribution of uniformly sampled IK solutions and efficiently generates a diverse set of IK solutions. To ensure sufficient density of IK solutions, many previous approaches specify a fixed number of IK solutions for each waypoint, represented by m. For example, Stampede [1] sets m=250, IKLink [4] sets m=300, and CppFlow [3] sets m=175. We note that these numbers are used for a 7-DoF robotic arm to track a fully constrained end-effector trajectory. For scenarios involving a more redundant robot (DoF>7) or a semi-constrained trajectory, more IK solutions may be necessary. This is because the solution space is larger and requires more IK solutions to densely cover the entire space. 2) Graph Construction: The sampled IK solutions are used as vertices to construct a layered graph where each layer corresponds to a waypoint on the end-effector trajectory. Edges connect vertices in consecutive layers if the robot can move between the two IK solutions within the time budget specified by the reference trajectory. Edge weights are defined based on various problem formulations such as total joint movement [1] or maximum joint movement [3]. 3) Graph Search: Once the graph is constructed, any paths within the graph represent possible robot motions by connecting the IK solutions. The shortest path from the first layer to the last layer corresponds to a high-quality motion that tracks the trajectory. Different methods are utilized to search for the shortest path. For example, Descartes [6] uses Dijkstra’s algorithm, Niyaz et al. [7] uses lifelong planning A∗, Stampede [1] uses value iteration, and IKLink [4] uses a dynamic programming method with two objectives. Analysis: Although multiple IK solutions are sampled for a waypoint, ultimately, only one IK solution is selected to path is refined by adding vertices near it and connecting them with dense edges. An initial solution is found by searching over the dense edges. The process is repeated by identifying new guide paths, performing further sampling around them, and finding new solutions. Stages: Our framework contains six stages, briefly described here. The details of the stages are outlined in §IV. 1) Sparse Vertex Sampling: In contrast to the conventional framework which samples IK solutions for every waypoint, this stage samples a limited number of IK solutions for a subset of waypoints spaced apart. We sample at every s waypoint, where the sparse step size s is a hyperparameter. 2) Sparse Edge Addition: This stage adds sparse edges to the graph, connecting vertices that are s layers apart. While sparse edges still correspond to feasible motion segments, they typically do not accurately track the reference trajectory because intermediate waypoints are omitted. 3) Guide Path Search: This stage identifies a guide path by finding the shortest path from the first to the last layer, using both dense and sparse edges. Guide paths correspond to motions that approximately track the reference end-effector trajectory. The heuristic assumes that high-quality solutions are likely to be found near guide paths. 4) Additional Vertex Sampling: This stage adds vertices to the graph through a combination of random sampling and targeted sampling around a guide path. The underlying assumption is that IK solutions near the guide path are more likely to yield high-quality solutions. In addition, we also randomly sample an equivalent number of IK solutions. This helps avoid local minima where guide paths are misleading and ensures that the algorithm converges to the same worst- case expected performance as the conventional approach. certain sparse edges are superseded by the dense edges. 6) Solution Search: This stage identifies a solution by finding the shortest path from the first to the last layer using only dense edges. The solution, containing only dense edges, precisely tracks the reference trajectory. Incremental Improvement: As shown in Algorithm 1, after generating a solution, the algorithm repeats the process, which involves identifying a new guide path, sampling additional vertices with a bias toward this new guide path, adding dense edges to connect the new vertices, and finding a new solution in the new graph. Because each new graph contains vertices and dense edges from its predecessor, each new solution is at least as good as, if not better than, the solution before, thus ensuring incremental improvement. The algorithm terminates upon reaching a predefined threshold, such as maximum running time or sampling capacity. Analysis: The proposed framework involves random sam- pling IK solutions, which mimics the process of the baseline approaches. Therefore, given sufficient time, our method will generate the same (probabilistic) sample set as the baseline approaches. With finite time and sampling budget, even the baseline approaches cannot provide guarantees of optimality, although Holladay [2] has proven that a similar algorithm con- verges towards optimality as the sampling density grows. Most prior works [1], [4], [3] empirically show the effectiveness of their algorithms. Similarly, we empirically demonstrate that our sampling strategy often more quickly finds solutions with better or equal quality in §V. IV. TECHNICAL DETAILS In §III-D, we gave an overview of our anytime algorithmic framework; this section details its stages. 5) Dense Edge Addition: This stage adds dense edges to the graph to connect vertices in adjacent layers. In addition, 1) Sparse Vertex Sampling: This stage involves sampling m0 IK solutions for every s waypoint, starting from index the need for a sparse edge. 1 and including index n. A total of ⌈n/s + 1⌉ × m0 IK solutions are sampled, where n is the number of waypoints on the reference trajectory and ⌈·⌉ is a ceiling function that rounds a real number up to the nearest integer. The specific sampling methods described in §III-B1 can be used to sample IK solutions. This stage generates the initial set of vertices in the graph, which are used to find an initial guide path. 2) Sparse Edge Addition: This stage adds sparse edges to the graph. Algorithm 2 outlines the AddSparseEdges function. In order to add a sparse edge between vertices that are s layers away, the Linkable function checks if the robot can move between the configurations within the time budget. In our implementation, Linkable assumes linear movements in joint space and checks if a linear movement is within the robot’s joint velocity limit. In addition, the algorithm checks whether the two vertices are already connected by dense edges. If a path composed of dense edges connects the two vertices and its cost is similar to the cost of the sparse edge, it suggests that the area has already been sufficiently sampled, eliminating 3) Guide Path Search: A guide path is identified by finding the lowest cost path from the first to the last layer of the graph, using both dense and sparse edges. Specific graph search algorithms discussed in §III-B3 can be used to find the path with the lowest cost. 4) Additional Vertex Sampling: This stage takes a guide path as input and biases sampling toward it. As shown in Algorithm 3, this stage first samples around every sparse edge within the guide path, then randomly samples an equivalent amount of IK solutions. Sampling around the sparse edges allows them to be replaced by dense edges. In order to sample around a sparse edge, we linearly inter- polate joint configurations on the sparse edge (LinInterp), apply some random disturbance (AddRandDelta), and use it as starting configurations of an IK solver. The IK solver finds IK solutions near the starting configuration. We use RelaxedIK [17] in our implementation, but any other IK solvers mentioned in §III-B1 are also compatible. In order to randomly sample IK solutions across the entire trajectory, we first randomly select waypoints using Softmax, which assigns higher selection probabilities to waypoints with fewer randomly sampled IK solutions. where x is the waypoint index, and |Vr[x]| is the number of existing randomly sampled IK solutions for waypoint x. After selecting a waypoint, we generate a random IK solution by initiating an IK solver’s starting configuration at a random location (RandConfig) in the robot’s joint space. 5) Dense Edge Addition: This stage adds dense edges to the graph, which connect vertices in adjacent layers. As detailed in Algorithm 4, the procedure involves iterating over all pairs of vertices located on adjacent layers. The algorithm uses the Linkable function to check the feasibility of each pair. After adding dense edges, the algorithm identifies and removes the sparse edges that have been superseded by dense edges. Specifically, if there exists a path composed of dense edges that connects the two endpoint vertices of a sparse edge, and the path’s cost is similar to the sparse edge’s cost, maintaining the sparse edge becomes unnecessary. Our approach shares a similar idea with lazy planning [19], [20], which delays the evaluation of edges until they are necessary for the solution. In our approach, sparse edges serve as estimators and a more accurate cost is computed when replacing sparse edges with dense edges. 6) Solution Search: This stage identifies a solution by finding the lowest cost path from the first to the last layer, using only dense edges. Specific graph search approaches described in §III-B3 can be used to find the shortest path. The identified solution corresponds to a motion that accurately tracks every waypoint on the reference trajectory. V. EXPERIMENTS In this section, we compare our proposed algorithm frame- work with the two baseline approaches described in §III: the conventional sequential framework and the naïve anytime framework. We conducted three independent experiments in simulation, each involves two testbeds. The first testbed tracks 10 randomly generated trajectories, comparing our frame- work with various parameter settings (step size s=3, 5, or 10) against the baselines. The second testbed tracks a trajectory 10 times and we report the average, best, and worst motions gen- erated by each method to provide a comprehensive overview of the performance variations. Our implementation is based on the open source IKLink library in Rust. We note that the Rust implementation per- forms faster than the implementation evaluated in the original paper [4]. Our framework used md=5, δ=0.2, η=1.1 (across all experiments), m0=50 (Experiments A&B) and m0=500 (Experiment C). All evaluations were performed on a laptop with an Intel i7-11800H 2.30 GHz CPU and 16 GB of RAM. We apply our framework to the Stampede algorithm [1] to find robot motions that track end-effector trajectories with minimal joint movements. As proposed in the original pa- per, Stampede used the conventional sequential framework. Stampede samples IK solutions by initiating an optimization- based IK solver, RelaxedIK [17], with starting configurations sampled from a uniform distribution. Additionally, it uses value iteration for graph search. Since our objective is to minimize joint movements, we define the edge weights within the graph as the Euclidean distances in joint space between two joint configurations. This experiment uses a 7-degrees-of-freedom KUKA LBR iiwa robot. The first testbed tracks 10 random cumulative cubic Bézier curves [22] for smooth position and orientation changes. These trajectories have an average length of 1.26 m, an average angular displacement of 5.13 rad, and an average of 379.4 waypoints. The second testbed replicates a writing task from prior work [3], [11], where the robot traces a “hello” trajectory. The trajectory is rescaled to fit iiwa’s workspace. As shown in the left column of Figure 3, while all three approaches generated motions with similar joint movements, our framework achieved initial solutions 2× faster. The results show that our heuristic is effective for simple trajectories and enables fast identification of effective motions. B. Experiment B - Tracking with Minimal Reconfigurations We apply our framework to the IKLink algorithm [4] which utilizes the conventional sequential framework to track the end-effector trajectory of any complexity. If a reference trajectory is too complex to be tracked as a single, continuous path, IKLink generates motions with minimal reconfigurations. In addition, IKLink has a secondary objective of minimizing joint movements. Similar to Stampede, IKLink uses RelaxedIK [17] to uniformly sample IK solutions. It also leverages RelaxedIK’s velocity regularization to find IK solutions close to those in the previous layer, thereby generating smooth motions. Moreover, similar IK solutions are merged using a clustering method. IKLink finds motions using dynamic programming, which incorporates both the number of recon- figurations and joint movements as objectives. This experiment uses a 7-DoF Franka Panda robot. The first testbed tracks random trajectories that consist of two con- secutive cubic cumulative Bézier curves [22]. The trajectories average 2.26 m in length, 12.07 rad in angular displacement, and 677.6 waypoints. The second testbed involves a 3D scanning task, in which a robot accurately moves a sensor along a predefined trajectory, ensuring the sensor consistently points at the object. As shown in Figure 3, our framework was more efficient and converged to motions with fewer or equal configurations, compared to both the conventional framework (baseline 1) and the naïve anytime framework (baseline 2). C. Experiment C - Tracking Trajectories with Tolerances In this experiment, we show how our framework ex- tends IKLink’s capability [4] to track semi-constrained end- effector trajectories. IKLink was originally designed for fully- constrained trajectory tracking, which requires all 6 DoF of the end-effector to be accurate. This requirement becomes overly restrictive in applications such as welding, where the torch may rotate around its principal axis. In contrast, semi-constrained trajectory tracking allows the end-effector to move within certain tolerances. Semi-constrained tracking poses a greater challenge to graph-based approaches because the solution space is larger and requires more samplings to sufficiently cover the solution space. We demonstrate that the IKLink using the conventional framework struggles to quickly find plausible motions, and the proposed anytime framework enables IKLinks to efficiently and effectively track trajectory with tolerances. We use RangedIK [23] as the IK solver, which is an extension of RelaxedIK that generates IK solutions that move the end-effector within specified tolerances. The first testbed randomly generates 10 welding trajectories for a Franka Panda robot. Each trajectory is composed of four cumulative cubic Bézier curves [22]. The trajectories average 1.29 m in length, 22.70 rad in angular displacement, and 646.8 waypoints. Compared to the random trajectories in Experiments A and B, these trajectories involve more rotational movements. In the welding task, the tolerance is along the torch’s principal axis, i.e., the robot is allowed to freely rotate its end-effector along the principal axis (z-axis). As shown in Figure 3, the principal axis is angled 45 degrees from the robot’s last axis. The robot must coordinate the movement of all its joints to exploit the tolerance, in contrast to just rotating the last joint when the principal axis aligns with the last axis. In the second testbed, a 7-degrees-of-freedom Rethink Robotics Sawyer robot performs a sanding task by tracking a spiral trajectory. The robot can freely rotate the sanding tool around its principal axis, which is oriented 90 degrees from the robot’s last axis. As shown in Figure 3, our framework enabled IKLink to quickly find motions with fewer reconfigurations than the baseline frameworks, while IKLink with both the conventional and naïve anytime frameworks struggled to find optimal solu- tions for trajectories with tolerances. Summary: Across all experiments, our anytime framework requires less computation time to achieve motions of the same quality and reaches equal or better motion quality within the same time frame compared to both the conventional and naïve anytime frameworks. Figure 3 shows that our framework consistently outperforms the baselines (our lines are consis- tently below or overlapping with the baselines), while Table I presents the corresponding quantitative results. them to find motions of higher or equal quality in less time, in comparison to both the conventional and naïve anytime frameworks. Experiment C shows that our framework extends IKLink’s ability to efficiently generate motions for tracking semi-constrained trajectories. Our results also show the effects of the hyperparameter step size s, which defines the length of sparse edges. A smaller s increases the number of IK samples in Stage 1, sparse vertex sampling, thereby raising computation time for obtaining initial solutions. Meanwhile, a larger s reduces the accuracy of guide paths as cost estimators, leading to slower algorithm convergence. In our experiments, we observe a sweetspot at s=5. VI. DISCUSSION This section summarizes the limitations, implications, and conclusions of our work. Limitations: Our work has several limitations that suggest future research directions. First, our algorithm lacks a quality- based stopping threshold; users can specify the maximum number of iterations, running time, or sampling budget, but the algorithm does not automatically stop upon convergence. Future work should explore the effects of adaptive stopping thresholds such as when the guide path no longer updates with iterations. Second, our method uses a heuristic to bias sam- pling in graph-based approaches. While we provide empirical evidence to demonstrate its ability to efficiently produce high- quality solutions, we cannot guarantee consistent performance across all scenarios. In certain scenarios, the heuristic may be misleading, causing the method to be slower than the naive anytime framework. Future work may provide a more rigorous understanding of the heuristic’s effectiveness. Third, while we expect that our framework generalizes across many graph-based tracking algorithms, we have only demonstrated it on two. Finally, the present work does not consider dynamic constraints, focusing solely on the velocity constraints of robot joints. Future work should consider incorporating acceleration constraints and the inertia of the robot to improve the quality of generated motions. Implications: The guided anytime framework presented in this work enables graph-based approaches to efficiently and effectively find motions that accurately move a manipulator’s end-effector along reference trajectories. It quickly generates initial solutions and continues to refine them as needed. We have demonstrated that it accelerates and improves solutions over prior methods and enables solving problems that a prior method cannot. The proposed framework is particularly bene- ficial for scenarios where end-effector trajectories are complex or have specific tolerances. Conclusion: This paper presented an anytime framework that enables graph-based trajectory tracking algorithms to efficiently and effectively find robot motions. Our framework generates trajectories of equal or better quality in less time than previous approaches.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2502/2502.03676v1.pdf",
         "extracted",
         "None",
         "",
         "Anytime Planning for End-Effector Trajectory Tracking"
        ],
        [
         "9",
         "0034e238be40924c815d89333e50afeb8fde846e",
         "None",
         "Meghan M. Moran,Jun Li,Quan Shen,Sheona P. Drummond,C. Milner,Anthony J. Day,A. Naqib,D. R. Sumner,Anna Plaas",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/10/17/2024.10.17.618923.full.pdf",
         "None",
         "None",
         "",
         "Evidence of an Allostatic Response by Intestinal Tissues Following Induction of Joint Inflammation"
        ],
        [
         "10",
         "003c35a5bdd27f7089275036709cde1785dcf8d3",
         "Standard ANNs lack flexibility when handling corrupted input due to their fixed structure. In this paper, a spiking neural network utilizes biological temporal coding features in the form of noise-induced stochastic resonance and dynamical synapses to increase the model’s performance when its parameters are not optimized for a given input. Using the analog XOR task as a simplified convolutional neural network model, this paper demonstrates two key results: (1) SNNs solve the problem that is linearly inseparable in ANN with fewer neurons, and (2) in leaky SNNs, the addition of noise and dynamical synapses compensate for non-optimal parameters, achieving near-optimal results for weaker inputs.",
         "Yana Garipova,Shogo Yonekura,Yasuo Kuniyoshi",
         "\n**BLOCK**fs== 10.0**p== 0.0**b== 0.8**t== 0.2**l== 0.3**r== 0.5**\nand Yasuo Kuniyoshi\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.2**l== 0.3**r== 0.2**\nLaboratory for Intelligent Systems and Informatics, University of Tokyo, Tokyo 113-0033, Japan;\nyonekura@isi.imi.i.u-tokyo.ac.jp (S.Y.); kuniyosh@isi.imi.i.u-tokyo.ac.jp (Y.K.)\n* Correspondence: garipova@isi.imi.i.u-tokyo.ac.jp\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nAbstract: Standard ANNs lack flexibility when handling corrupted input due to their\nfixed structure. In this paper, a spiking neural network utilizes biological temporal coding\nfeatures in the form of noise-induced stochastic resonance and dynamical synapses to\nincrease the model’s performance when its parameters are not optimized for a given\ninput. Using the analog XOR task as a simplified convolutional neural network model,\nthis paper demonstrates two key results: (1) SNNs solve the problem that is linearly\ninseparable in ANN with fewer neurons, and (2) in leaky SNNs, the addition of noise\nand dynamical synapses compensate for non-optimal parameters, achieving near-optimal\nresults for weaker inputs.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nKeywords: spiking neural networks; adaptability; noise; stochastic resonance; dynamical\nsynapse; leaky integrate-and-fire neuron\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n1. Introduction\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nAI training and inference servers’ power consumption is kept at bay with tensor\nprocessing units (TPUs), shortening the circuit paths and processing data locally rather\nthan spending energy on transit [1]. However, we are at the limit of how small computer\nchips can be in order to work reliably, continuing to depend on longer wait times and\npower draws. Exploring alternative solutions, researchers have shown that spiking neural\nnetworks (SNNs) outperform conventional static artificial neural networks (ANNs) [2] in\nenergy efficiency when running models on neuromorphic chips [3], offering a remarkable\nreduction in energy consumption from 100 times [4] to 280 times [5].\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nSpiking networks have also shown the ability to self-optimize to changing probability\ndistributions, such as the likelihood of a reward [6] and the adaptability of a dynamic motor\ncontrol system to a changing environment [7]. This paper shows that noise sensitivity in\nSNNs with dynamical synapses leads to surprisingly better performance than ANNs when\nparameters are not fully optimized.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nUnlike ANNs, training the synaptic weights of SNNs is challenging due to the instanta-\nneous spiking activity and dynamic synaptic characteristics that hinder gradient computation.\nSeveral methods exist to achieve trained SNNs. One method is to obtain synaptic weights\nby ANN backpropagation and directly apply them to SNN [8]. SNNs can also be trained\ndirectly with supervised learning error-based methods , resulting in faster convergence and\nmany possible solutions [9]. Examples include SNN backpropagation [10], hybrid learning\nof STDP-based unsupervised pre-training and supervised fine-tuning [11], and an approxi-\nmation of backpropagation with dendritic cortical microcircuits [12]. Other approaches for\nsupervised learning in SNNs are the target propagation methods, which result in a constrained\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.8**\nAcademic Editor: António Lopes\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nReceived: 21 January 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nRevised: 10 February 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nPublished: 21 February 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nCitation: Garipova, Y.; Yonekura, S.;\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nKuniyoshi, Y. Noise and Dynamical\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nSynapses as Optimization Tools for\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nSpiking Neural Networks. Entropy\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\n2025, 27, 219. https://doi.org/\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nCopyright: © 2025 by the authors.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nLicensee MDPI, Basel, Switzerland.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.8**\nThis article is an open access article\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\ndistributed under the terms and\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nconditions of the Creative Commons\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\n(https://creativecommons.org/\n**BLOCK**fs== 10.0**p== 1.0**b== 0.9**t== 0.1**l== 0.3**r== 0.1**\nsolution [9]. For example, there is a method of target propagation based on the Gauss–Newton\noptimization [13] and a gradient-free training method for SNN [14].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nIn order to compare the adaptability of ANN and SNN models, we create two similarly\nstructured networks designed to run the analog XOR function. The goal of the analog XOR\ntask is to check if the inputs are within a certain range of each other; if they are, then the\noutput is low; otherwise, it is high.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nThe analog XOR task is a non-linear operation and a fundamental building block in\nneural networks. It is a simple way to analyze the internal processes of networks that can\nbe generalized to aspects of convolutional neural networks, audio processing, and sensor\nsystems [15,16]. Specifically, in both CNN kernels [16] and biological visual processing [17],\nXOR, in conjunction with logical negation NOT or inhibitory mechanisms, such as lateral\ninhibition and feedback loops, can approximate functions such as feature extraction and\ncontrast enhancement.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nUnlike pioneering ANN-to-SNN network translation research [4,8], our spiking net-\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nwork utilizes temporal coding features: the presence of noise and dynamical synapses.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nNoise plays an important role in biological networks, improving the adaptability of a\nnetwork [18]; it stimulates the effect of stochastic resonance by boosting the near-threshold\nvoltage and generating a spike [19]. Noise also influences the synchronization of inputs and\ninhibition, which is crucial because the synchronous input is propagated more strongly [19,20].\nNoise in biological networks can be attributed to individual neurons and the behavior of a\nnetwork as a whole. Neuron-specific additive noise is independent of input strength and\nincludes thermal noise and fluctuations in neural membrane conductivity [18,19]. These can\nbe modeled by fluctuating the spike threshold (escape noise), fluctuating any parameter (slow\nnoise), or as an added current (diffusive Gaussian white noise) [19].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nThe multiplicative noise is proportional to the input and is attributed to the whole\nnetwork rather than an individual neuron. This noise originates from synaptic transmission\nfailures [19] and is modeled in this work as input-scaled Gaussian white noise. Other\narchitecture-attributed fluctuations originate in fixed random connectivity of neurons [19].\nIn this work, we compare the effect of additive white noise, additive Ornstein–Uhlenbeck\n(OU) colored noise [21], and multiplicative white noise on the adaptability of the SNN.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nThe dynamical synapses regulate the neural connection strength depending on the\nrecent activity: the connection strength increases with recent stimulation and depresses\nwhen not activated. In biological networks, dynamical synapses are crucial in implementing\nplasticity, adaptation, and learning. They enable the detection of temporal patterns, filter\nhigh-frequency noise, and drive neural synchronization [19].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nThe main parameter of the dynamical synapse is the synaptic time constant, τsyn.\nA higher synaptic time constant means the synapse integrates information over a longer\nperiod; a lower τsyn gives more rapid dynamics. In this work, we look at different values of\nτsyn. Although parameter tuning (signal gain, τsyn) challenges the convertibility of dynami-\ncal synapse network models, we show that the inherent robustness of our spiking network\nmitigates the need for extensive optimization. The intrinsic adaptability of our spiking\nnetwork allows it to maintain functionality even with suboptimal parameter configurations.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\n2. Materials and Methods\n2.1. The Analog XOR Task\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nWe define the analog XOR task for SNNs using the analog input signal (x0, x1) ∈ [0, 1]\nand the analog spike count CT within the time frame T of the output spiking neuron (N5) as\nfollows:\nCT\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nN5 will exceed the firing threshold h when exactly one of the inputs (x0, x1) is greater\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.3**r== 0.3**\nthan or equal to a boundary value b (see the algorithm Table 1).\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.8**r== 0.1**\nNormalized CT\nN5\n<h (LOW)\n≥h (HIGH)\n≥h (HIGH)\n<h (LOW)\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.4**\nThe final values of the output neuron CT\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nN5 are normalized such that h ∈ (0.00, 1.00).\nThe normalization of the final output is used to compare the models, since ANN activations\nand the SNN spike count are not guaranteed to be proportionally aligned, which depends\non other gain and the synaptic time-constant parameters.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nThe accuracy of the XOR task for an SNN circuit is calculated using the digitized\nN5) − h), where Θ is the Heaviside\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.3**r== 0.2**\nvariables (Θ(x0 − b), Θ(x1 − b)) and (Θ(normalized(CT\nstep function, and Θ(i) = 1 and 0 for i > 0, and i ≤ 0, respectively.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nWe find the boundaries (b, h) and parameters with a grid search. First, we searched\nfor the gain parameters with a fixed boundary on ANN and then tuned the boundary with\nanother grid search of (b, h). One of the best-found boundaries in ANN is (b, h) = (0.46,\n0.3) with an 83.74% accuracy. Due to the structure in the output activations of the ANN\nXOR circuit, many boundaries yield similar accuracy. The same gain parameters did not\nwork for the SNN with τsyn = 1 ms, and we applied another grid search for parameters\ngiven the boundary (b, h) = (0.46, 0.3). The gain parameters that worked best for SNN\nwith τsyn = 1 are (input gain, weight gain) = (5, 110) or (6, 111). Due to the steps in the grid\nsearch and the bias gain parameter set to 1, the returned setting is not guaranteed to be the\nmost optimal.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nAfter finding the optimal boundaries, we observed how the circuit performed with\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.3**r== 0.4**\nnoise added for suboptimal boundaries.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.3**r== 0.5**\n2.2. The Circuits’ Structure\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nThe ANN and SNN circuits have two input neurons, two hidden-layer neurons,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\nand one output neuron (Figure 1).\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFigure 1. XOR circuit diagrams with initial connection strengths. (left): ANN XOR circuit. (right):\nSNN XOR circuit.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nThe input and connection weights of the circuits are scaled by the input gain and\nweight gain; the bias gain is set to 1. The ReLU activation in the ANN circuit is chosen\nbased on previous research of the ANN-to-SNN translation method: ReLU neurons are a\ngood approximation of discrete spikes and are efficient during training [8].\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.3**r== 0.4**\n2.3. Implementation of Noisy Spiking Neurons\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nThe spiking circuit is simulated with NEST 2.20.1 [22], consisting of leaky integrate-\nand-fire iaf_psc_exp neurons with a dynamical synapse model tsodyks_synapse [23] and the\nparameters listed in Table 2.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nTable 2. iaf_psc_exp neuron, tsodyks_synapse dynamical synapse, and simulation parameters.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nCode Variable\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\nDescription, Units\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nV_reset\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nrefractory_input\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\ntau_fac\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.3**r== 0.7**\ntau_rec\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.3**r== 0.7**\ntau_syn\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.3**l== 0.5**r== 0.3**\nMembrane capacitance, pF\nMembrane time constant,\nms\nResting membrane\npotential, mV\nInitial membrane potential,\nmV\nReset potential of the\nmembrane, mV\nLowest value for the\nmembrane potential\nDiscard input during\nrefractory period\nConstant input current, pA\nSpike threshold, mV\nSynapse facilitation time\nconstant, ms\nSynapse recovery time\nconstant, ms\nSynaptic time constant\n(τsyn), ms\nSimulation resolution, ms\nSimulation time, s\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nWe selected the leaky model for this work due to its biological plausibility [19] and\nhigher susceptibility to stochastic resonance compared to a non-leaky neuron. We have\ntested the firing rate of the non-leaky neuron with static synapse at different noise levels\n(see Figure S2). Unlike leaky SNN, static non-leaky SNN produced ANN-like output with\nhigher noise intensity. The non-leaky SNN is simulated in C++ with the same parameters.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.3**r== 0.3**\nThe leaky neurons’ membrane potential is defined by\n**BLOCK**fs== 10.4**p== 3.0**b== 0.2**t== 0.8**l== 0.4**r== 0.2**\n= −Vm(t) + Ibias + I(t) + I(t)ξmul(t) + ξ add(t) + z(t),\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nIbias is the base current (18 pA) plus the biases set by the network architecture;\nI(t) is the postsynaptic input current;\nξmul and ξ add is Gaussian white noise generated from the probability density function\nf (x) of normal distribution with 0 mean and standard deviation D:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.3**r== 0.1**\nz(t) is the colored noise implemented with the Orstein–Uhlenbeck process [21]. z(t) is\ndefined with Gaussian noise ξ(t) and the damping term a as\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nThe white noise is implemented with the numpy.random.default_rng().normal function.\nIt can be applied directly as additive noise (ξ add), or it can be scaled by input values to\nmimic synaptic multiplicative noise (I(t)ξmul), that is, accumulated voltage that did not\ngenerate a spike [19]. Although different types of noise are introduced together in the same\nEquation (1), in the experiments they were applied individually for comparison.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nUnlike unpredictable white noise, the colored noise of the Orstein–Uhlenbeck (OU)\nprocess [21] has a non-uniform power spectral density: its values depend on the pre-\nvious values. The OU process is implemented with the discrete-time approximation of\nEquation (3) with the damping term (mean-reversion rate) θ = a/τ_z. The mean-reversion\nrate describes how fast the process converges to the selected mean 0. A lower θ increases\nthe autocorrelation of the process. See Figure S1 for sample noise patterns.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\nNoise is applied only to the input neurons. This noise can be common (identical)\nacross both inputs or independent (different noise values drawn from the same distribu-\ntion). A new noise value is sampled every 0.1 ms, which is the temporal resolution of\nthe simulation.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nThere are fundamental differences in how noise affects the two networks. In the SNN,\nnoise continuously interacts with the network’s dynamics, influencing synchronization\nand inhibition before the final spike number is counted. However, in the ANN, negative\nactivations are suppressed by the ReLU activation function, and the effect of the noise is\nmitigated by averaging the output.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\n3. Results\n3.1. Networks Output Comparison: Non-Linear Separability with Fewer Neurons\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nThe ANN of the given circuit structure returns the linear separation of the solution\nfield (Figure 2), while the SNN produces a non-linear solution with the same number\nof neurons.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFigure 2. Output example without noise. Parameters: input gain = 6, weight gain = 111. (left):\nNormalized output values in ANN XOR (with ReLU activations). (right): Normalized firing frequency\nin SNN XOR with dynamical synapse τsyn = 1 ms.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nThe SNN XOR can give high-accuracy results at 95% or more with only five neurons.\nHowever, this success would only apply to a couple of specific decision boundaries. For ex-\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nample, in Figure 2 (right), we have 95.5% for (b, h) = (0.36, 0.5). The optimal boundary in\nSNN would greatly depend on the preset parameters: input gain, weight gain, synaptic\ntime constant of a dynamical synapse, and noise level. The linearity of the ANN circuit\nsolution peaks at 83.74% and produces low variability in accuracy for most boundaries.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nIt is possible to achieve high accuracy (up to 100%) in an ANN circuit for the analog\nXOR task with a sigmoidal activation function rather than ReLU by applying another layer\nwith a steep sigmoid function to the inputs, which would digitize the analog signal xi to\n0 or 1. Insofar as xi is an analog signal between [0, 1], and the ANN structure consists of\nfive neurons as in Figure 1, the ANN XOR recognition accuracy remains low regardless of\nthe activation function. However, the SNN of the similar minimal structure is sufficient for\nthe analog XOR task.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nFigure 3 shows the accuracy changes with common noise for some selected boundaries.\nFour boundaries are shown in both graphs: the yellow (b, h) = (0.46, 0.3) is optimal in ANN;\nthe magenta (b, h) = (0.4, 0.5) is the most optimal in SNN; the red (b, h) = (0.42, 0.4) is an\nexample of reaching optimal accuracy with some noise; the dark blue (b, h) = (0.46, 0.2) is a\nrandom sample.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 3. Comparing average accuracy of ANN and SNN circuits for some boundaries across\ndifferent levels of common multiplicative noise. Tested with input gain = 5, weight gain = 110. (left):\nNon-spiking XOR. (right): Spiking XOR with dynamical synapses τsyn = 1 ms.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nBoth charts show an average accuracy over 20 runs, where noise values are generated\nwith a new seed every run. In the non-spiking circuit of Figure 3 left, each input is tested\nwith 20,000 different noise components drawn from the same distribution, and then all\n20,000 trials are averaged for a single output. The same operation is repeated 20 times for\neach noise level D to have more samples for the average accuracy result. The spiking circuit\n(Figure 3 right) is simulated for 20 s per input, with a new noise component added every\n0.1 ms (NEST resolution setting), with a total of 200,000 noise components per input. This\nis repeated 20 times for each noise level D. Since the accuracy is measured on normalized\ndata, the standard deviation of the average accuracy is low.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFigure 3 shows that the current implementation of the circuits gives (1) some improved\naccuracy for certain boundaries due to the non-linear separation of the output (Figure 2),\n(2) the noise effect is more dramatic in the SNN than in the ANN, and (3) some boundaries\ncan have the accuracy improved with noise.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.9**t== 0.1**l== 0.3**r== 0.2**\n3.2. Dynamical Synapses in Leaky SNN and Their Effect on Stochastic Resonance\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nDifferent from static synapses that have a fixed connection strength, dynamical\nsynapses regulate their conductance based on the previous activity. Increasing the synaptic\ntime constant τsyn extends the amount of time it takes to decay the synapse strength back\nto its resting state after a presynaptic spike [23], thus allowing the circuit to integrate input\nover a longer period.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nWhen τsyn is high, as in Figure 4 center, the output neuron has a high contrast firing\nfrequency, compared to the lower τsyn = 1 ms in Figure 2 right and τsyn = 5 ms in Figure 4 left.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nFigure 4. Firing frequency in SNN XOR with different synapse settings. Low intensity D = 0.1\ncommon multiplicative noise is applied. (left): Dynamical synapse with τsyn = 5 ms. (center):\nDynamical synapse with τsyn = 20 ms. (right): Static synapse.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nFigure 5 shows the effect of strong common multiplicative noise on the output firing\nfrequency in the SNN with dynamical and static synapses. All synapse configurations show\nmoderate stochastic resonance with a shift in sensitivity to lower boundaries; however,\nthe dynamical synapse with a high synaptic time constant maintains sharper contrast in\nthe firing rates, which would allow it to perform more reliably even at high-intensity noise.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFigure 5. Firing frequency in noisy SNN XOR with different synapse settings. High intensity\nD = 5 common multiplicative noise is applied. (left): Dynamical synapse with τsyn = 5 ms (center):\nDynamical synapse with τsyn = 20 ms. (right): Static synapse.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nFigure 6 follows the accuracy for some boundaries that are found to be the best at\neach noise level. Although the static synapse network still exhibits up to 3% improve-\nment attributed to noise for the suboptimal boundaries, the dynamical synapse shows\na more measurable and predictable pattern in improving the accuracy for suboptimal\nboundaries with stronger noise. With dynamical synapses, we have 7% improvement for\nthe more optimal boundary (orange) and 17% improved accuracy for the least optimal\nboundary (purple).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\nFigure 6. Accuracy of the SNN XOR circuit for best-found boundaries at different common mul-\ntiplicative noise levels. (left): Static synapse, input gain = 5, weight gain = 5. (right): Dynamical\nsynapse, input gain = 5, weight gain = 110, τsyn = 20 ms.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\n3.3. Improving Accuracy for Sub-Optimal Boundaries in Leaky Dynamic SNN with Noise-Induced\nStochastic Resonance\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nThe noise component can be common between both inputs or independent. With com-\nmon noise, a single value is pulled from the normal distribution and applied to both inputs.\nIndependent noise implies pulling two different noise values from the distribution, one for\neach input.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nThe noise component can also be additive or multiplicative. While both additive and\nmultiplicative noise are technically “added” as a fluctuating current, multiplicative noise is\nscaled by the original inputs and the input gain values; the additive noise is not scaled by\ngain and is applied uniformly. The multiplicative noise is stronger than the additive noise\nby a factor of the input gain value in high inputs (which are closer to 1), but the inputs that\nare closer to 0 generate low noise.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 7 shows the firing rates in networks with different types of strong independent\nnoise. Each noise raises the firing rates in the circuit but at a different rate. Given the same\nparameters (0 mean, D standard deviation), the OU-colored noise is the most powerful\nand should be applied at a lower intensity. The multiplicative noise has a stronger shift\nin sensitivity to the weaker input than the additive noise while maintaining clear non-\nlinear separation.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nFigure 8 follows the boundaries that were found to be the most accurate at each\nintensity of additive (Figure 8 left) and colored noise (Figure 8 right). Both white and colored\nnoise drastically improve the accuracy for the suboptimal boundaries due to stochastic\nresonance. Although additive noise shows slow improvement with high intensity, colored\nnoise has a much stronger effect with the same standard deviation D, and the accuracy\ndegrades faster after peaking.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nFigure 7. Firing frequency in dynamic SNN XOR with additive and multiplicative noise. Other\nparameters: input gain = 5, weight gain = 25, τsyn = 20 ms, noise intensity D = 5. (left): Additive\nindependent noise (not scaled by input). (center): Multiplicative independent white noise (scaled by\ninput and gain). (right): Additive independent OU colored noise, θ = 1.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nFigure 8. Accuracy of the XOR circuit for some boundaries with different types of noise. Parameters:\ninput gain = 5, weight gain = 25, τsyn = 20 ms. (left): SNN XOR accuracy with independent additive\nwhite noise. (right): SNN XOR accuracy with additive independent OU colored noise, θ = 1.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 9 right (solid line) follows the same boundaries but with the addition of only\nmultiplicative noise. Both additive and multiplicative noise have a similar effect on the\ncurrent network. However, compared to additive and colored noise, multiplicative noise\nreaches near-optimal scores with lower noise and produces higher accuracies per node\noverall. For example, at D = 5 of multiplicative noise (Figure 9 right), the suboptimal\nboundaries reach between 92–95% accuracy, the additive noise requires a higher D for\nsimilar results, and the colored noise accuracy peaks at 87–93%.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nFigure 9 compares the effects of common and independent noise on suboptimal\nboundaries. The chart shows some boundaries found to be most accurate at each noise level\nand follows changes in their accuracy. Independent noise gives slightly more improvement\nthan common noise at first, but the trend reverses for less optimal boundaries with high\nnoise intensity (Figure 9 left). Strong common noise is more effective than the independent\nnoise for the boundaries where the model is not optimized, for example, the black boundary\n(b, h) = (0.36, 0.4).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nThe accuracy gap between the common and independent noisy networks increases\nwith a higher D as a result of more variation among the individual noise components. This\ngap is minimal with a high synaptic time constant in Figure 9 right.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nFigure 9. Comparing accuracy of spiking circuit across different levels of common and independent\nmultiplicative noise. The solid line is independent noise, and the dashed line is common noise. (left):\nParameters: τsyn = 1 ms, input gain = 5, weight gain = 110. (right): Parameters: τsyn = 20 ms, input\ngain = 5, weight gain = 25.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nEven though the different types of noise have nuances in their effect, we have shown\nthat noise makes the dynamical spiking network more sensitive to weaker input due to\nstochastic resonance, thus boosting the untuned dynamical spiking network’s performance\nto near-optimal levels.\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n4. Discussion\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.5**l== 0.3**r== 0.1**\nIn artificial networks, the ability to adapt is another way (besides neuromorphic\nhardware) to reduce the power consumption during a model’s training and inference.\nIn biological networks, the ability to adapt to changing or missing input is embedded in the\nbrain’s regime of stable propagation of synchronous neural activity among asynchronous\nglobal activity [20,24], a combination of rate and temporal coding [25]. The physical\nproperties that contribute to temporal coding are inhibitory connections (feedback) [17],\nthe presence of noise [26], and the short-term plasticity of dynamical synapses [23,27].\nThese properties are usually omitted from the standard conversion method based on the\nANN-to-SNN rate coding [4,8,28]. This work implemented temporal features in the XOR\nnetwork in the form of multiplicative synaptic noise and dynamical synapses to discuss\ntheir effects on adaptation.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nThe implementation of temporal features in the SNN introduces notable network\ntranslation challenges, especially if we seek to apply these results to “convert” existing well-\nperforming ANNs to SNN. The gain parameters for SNN have to be re-selected depending\non the synaptic time constant of the dynamical synapse. To make the circuits equivalent\nand convertible, firing frequency/activations have to be aligned, the ANN activations’\noutput has to have a similar shape to that of an SNN (non-linear separation), implying an\narchitectural change; a parameter selection rule has to be established, such that the same\nboundary is returned as the most optimal.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nAlthough ANN models can benefit from noisy training [29], the current set-up showed\na minimal noise-induced stochastic resonance effect in ANN. In SNN, noise interacts with\nneurons’ internal dynamics, and we have more measurable changes with stronger noise\nwhen the network is not optimally tuned. We have also shown that the spiking network\nwith multiplicative noise has increased sensitivity to sub-optimal inputs, which can be\napplied as an adaptation.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nThe noise types applied in this work show a similar effect, which is likely to be more\nvaried in a larger network. The noisy SNN stochastic resonance presented in this work\nimplies that only the suboptimal boundaries that can be helped by amplifying the firing\nfrequency will be improved. This poses a question for implementing noise with inverse\neffects that would weaken the firing frequency in stronger inputs and adjust the circuit for\nhigher boundaries instead.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nThe functionality of a noisy SNN XOR could also be expanded to other functions by\nimplementing other temporal characteristics in the form of inhibitory neuron pools [30],\nfeedback loops, or taking into account the synchronization index [25].\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nSupplementary Materials: The following supporting information can be downloaded at https:\n//www.mdpi.com/article/10.3390/e27030219/s1, Figure S1: Sample noise values for one hundred\ntime intervals; Figure S2: Relative firing rate in non-leaky SNN XOR at different intensity levels of\ncommon multiplicative white noise.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nAuthor Contributions: Conceptualization, Y.G., S.Y. and Y.K.; methodology, Y.G.; software, Y.G.\nand S.Y.; validation, S.Y. and Y.K.; resources, Y.G. and S.Y.; writing—original draft preparation, Y.G.;\nwriting—review and editing, Y.G. and S.Y.; supervision, S.Y. and Y.K. All authors have read and\nagreed to the published version of the manuscript.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\nFunding: This research received no external funding.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\nInstitutional Review Board Statement: Not applicable.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\nInformed Consent Statement: Not applicable.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nData Availability Statement: The raw data supporting the conclusions of this article will be made\navailable by the authors on request.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.3**\nConflicts of Interest: The authors declare no conflicts of interest.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nReferences\n1. Mead, C. Neuromorphic Engineering: In Memory of Misha Mahowald. Neural Comput. 2023, 35, 343–383. [CrossRef] [PubMed]\nBrilliant.org. Available online: https://brilliant.org/wiki/feedforward-neural-networks/ (accessed on 12 December 2024).\n2.\n3.\nStöckl, C.; Maass, W. Optimized spiking neurons classify images with high accuracy through temporal coding with two spikes.\narXiv 2021, arXiv:2002.00860. [CrossRef]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n4. Cao, Y.; Chen, Y.; Khosla, D. Spiking deep convolutional neural networks for energy-efficient object recognition. Int. J. Comput.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nVis. 2015, 113, 54–66. [CrossRef]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n5. Kim, S.; Park, S.; Na, B.; Yoon, S. Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection. Proc. Aaai Conf.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nArtif. Intell. 2020, 34, 11270–11277. [CrossRef]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n6. Legenstein, R.; Maass, W. Ensembles of spiking neurons with noise support optimal probabilistic inference in a dynamically\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nchanging environment. PLoS Comput Biol. 2014, 10, e1003859. [CrossRef]\nFavier, K.; Yonekura, S.; Kuniyoshi, Y. Spiking neurons ensemble for movement generation in dynamically changing environments.\nIn Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vegas, NV, USA, 24–29 October\n2020; pp. 3789–3794.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n8. Rueckauer, B.; Lungu, I.A.; Hu, Y.; Pfeiffer, M.; Liu, S.C. Conversion of continuous-valued deep networks to efficient event-driven\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nnetworks for image classification. Front. Neurosci. 2017, 11, 682. [CrossRef]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n9. Capone, C.; Muratore, P.; Paolucci, P.S. Error-based or target-based? A unified framework for learning in recurrent spiking\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nnetworks. PLoS Comput. Biol. 2022, 18, e1010221. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n10. Lee, J.H.; Delbruck, T.; Pfeiffer, M. Training deep spiking neural networks using backpropagation. Front. Neurosci. 2016, 10, 508.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\n[CrossRef]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n11. Lee, C.; Panda, P.; Srinivasan, G.; Roy, K. Training deep spiking convolutional neural networks with stdp-based unsupervised\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\npre-training followed by supervised fine-tuning. Front. Neurosci. 2018, 12, 435. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n12. Sacramento, J.; Costa, R.P.; Bengio, Y.; Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In\nProceedings of the Thirty-Second Annual Conference on Neural Information Processing Systems (NIPS), Montreal, QC, Canada,\n2–8 December 2018.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n13. Meulemans, A.; Carzaniga, F.S.; Suykens, J.A.K.; Sacramento, J.; Grewe, B.F. A Theoretical Framework for Target Propagation.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\narXiv 2020, arXiv:2006.14331.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n14. Nakajima, M.; Inoue, K.; Tanaka, K.; Kuniyoshi, Y.; Hashimoto, T.; Nakajima, K. Physical deep learning with biologically inspired\n**BLOCK**fs== 9.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\ntraining method: Gradient-free approach for physical hardware. Nat Commun. 2022, 13, 7847. [CrossRef]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n15. Bertalmío, M.; Gomez-Villa, A.; Martín, A.; Vazquez-Corral, J.; Kane, D.; Malo, J. Evidence for the intrinsically nonlinear nature of\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.4**\nreceptive fields in vision. Sci. Rep. 2020, 10, 16277. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n16. Sun, Z.H. Binary Outer Product Expansion of Convolutional Kernels IEEE J.-STSP 2020, 14, 871–883.\n17. Liang, H.; Gong, X.; Chen, M.; Yan, Y.; Li, W.; Gilbert, C.D. Interactions between feedback and lateral connections in the primary\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.4**\nvisual cortex. Proc Natl. Acad. Sci. USA 2017, 114, 8637–8642. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n18. Faisal, A.A.; Selen, L.P.; Wolpert, D.M. Noise in the nervous system. Nat Rev. Neurosci. 2008, 9, 292–303. [CrossRef] [PubMed]\n19. Gerstner, W.; Kistler, W.M. Spiking Neuron Models: Single Neurons, Populations, Plasticity; Cambridge University Press: Cambridge,\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n20. Fries, P. A mechanism for cognitive dynamics: Neuronal communication through neuronal coherence. TiCS 2005, 9, 474–480.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\n[CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n21. Hanggi, P.; Jung, P. Colored noise in dynamical system. Adv. Chem. Phys. 1995, 89 , 239–326.\n22. Gewaltig, M.O.; Diesmann, M. NEST (NEural Simulation Tool). Scholarpedia 2007, 2, 1430. [CrossRef]\n23. Tsodyks, M.; Uziel, A.; Markram, H. Synchrony generation in recurrent networks with frequency-dependent synapses. J. Neurosci.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\n2000, 20, RC50. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n24. Aviel, Y.; Horn, D.; Abeles, M. Synfire waves in small balanced networks. Neurocomputing 2004, 58–60, 123–127. [CrossRef]\n25. Reichert, D.P.; Serre, T. Neuronal synchrony in complex-valued deep networks. arXiv 2013, arXiv:1312.6115.\n26. Sutherland, C.; Doiron, B.; Longtin, A. Feedback-induced gain control in stochastic spiking networks. Biol. Cybern. 2009, 100,\n**BLOCK**fs== 9.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\n475–489. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n27. Tsodyks, M.; Wu, S. Short-term synaptic plasticity. Scholarpedia 2013, 8, 3153. [CrossRef]\n28. Diehl, P.U.; Neil, D.; Binas, J.; Cook, M.; Liu, S.C.; Pfeiffer, M. Fast-classifying, high-accuracy spiking deep networks through\nweight and threshold balancing. In Proceedings of the 2015 International Joint Conference on Neural Networks (IJCNN), Killarney,\nIreland, 12–17 July 2015; pp. 1–8.\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n29. Ventura, E.; Benedetti, M. Training neural networks with structured noise improves classification and generalization. arXiv 2023,\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n30. Abeles, M.; Hayon, G.; Lehmann, D. Modeling compositionality by dynamic binding of synfire chains. J. Comput. Neurosci. 2004,\n**BLOCK**fs== 9.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\n17, 179–201. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.",
         "and Yasuo Kuniyoshi Abstract: Standard ANNs lack flexibility when handling corrupted input due to their fixed structure. In this paper, a spiking neural network utilizes biological temporal coding features in the form of noise-induced stochastic resonance and dynamical synapses to increase the model’s performance when its parameters are not optimized for a given input. Using the analog XOR task as a simplified convolutional neural network model, this paper demonstrates two key results: (1) SNNs solve the problem that is linearly inseparable in ANN with fewer neurons, and (2) in leaky SNNs, the addition of noise and dynamical synapses compensate for non-optimal parameters, achieving near-optimal results for weaker inputs. Keywords: spiking neural networks; adaptability; noise; stochastic resonance; dynamical synapse; leaky integrate-and-fire neuron AI training and inference servers’ power consumption is kept at bay with tensor processing units (TPUs), shortening the circuit paths and processing data locally rather than spending energy on transit [1]. However, we are at the limit of how small computer chips can be in order to work reliably, continuing to depend on longer wait times and power draws. Exploring alternative solutions, researchers have shown that spiking neural networks (SNNs) outperform conventional static artificial neural networks (ANNs) [2] in energy efficiency when running models on neuromorphic chips [3], offering a remarkable reduction in energy consumption from 100 times [4] to 280 times [5]. Spiking networks have also shown the ability to self-optimize to changing probability distributions, such as the likelihood of a reward [6] and the adaptability of a dynamic motor control system to a changing environment [7]. This paper shows that noise sensitivity in SNNs with dynamical synapses leads to surprisingly better performance than ANNs when parameters are not fully optimized. Unlike ANNs, training the synaptic weights of SNNs is challenging due to the instanta- neous spiking activity and dynamic synaptic characteristics that hinder gradient computation. Several methods exist to achieve trained SNNs. One method is to obtain synaptic weights by ANN backpropagation and directly apply them to SNN [8]. SNNs can also be trained directly with supervised learning error-based methods , resulting in faster convergence and many possible solutions [9]. Examples include SNN backpropagation [10], hybrid learning of STDP-based unsupervised pre-training and supervised fine-tuning [11], and an approxi- mation of backpropagation with dendritic cortical microcircuits [12]. Other approaches for supervised learning in SNNs are the target propagation methods, which result in a constrained solution [9]. For example, there is a method of target propagation based on the Gauss–Newton optimization [13] and a gradient-free training method for SNN [14]. In order to compare the adaptability of ANN and SNN models, we create two similarly structured networks designed to run the analog XOR function. The goal of the analog XOR task is to check if the inputs are within a certain range of each other; if they are, then the output is low; otherwise, it is high. The analog XOR task is a non-linear operation and a fundamental building block in neural networks. It is a simple way to analyze the internal processes of networks that can be generalized to aspects of convolutional neural networks, audio processing, and sensor systems [15,16]. Specifically, in both CNN kernels [16] and biological visual processing [17], XOR, in conjunction with logical negation NOT or inhibitory mechanisms, such as lateral inhibition and feedback loops, can approximate functions such as feature extraction and contrast enhancement. Unlike pioneering ANN-to-SNN network translation research [4,8], our spiking net- work utilizes temporal coding features: the presence of noise and dynamical synapses. Noise plays an important role in biological networks, improving the adaptability of a network [18]; it stimulates the effect of stochastic resonance by boosting the near-threshold voltage and generating a spike [19]. Noise also influences the synchronization of inputs and inhibition, which is crucial because the synchronous input is propagated more strongly [19,20]. Noise in biological networks can be attributed to individual neurons and the behavior of a network as a whole. Neuron-specific additive noise is independent of input strength and includes thermal noise and fluctuations in neural membrane conductivity [18,19]. These can be modeled by fluctuating the spike threshold (escape noise), fluctuating any parameter (slow noise), or as an added current (diffusive Gaussian white noise) [19]. The multiplicative noise is proportional to the input and is attributed to the whole network rather than an individual neuron. This noise originates from synaptic transmission failures [19] and is modeled in this work as input-scaled Gaussian white noise. Other architecture-attributed fluctuations originate in fixed random connectivity of neurons [19]. In this work, we compare the effect of additive white noise, additive Ornstein–Uhlenbeck (OU) colored noise [21], and multiplicative white noise on the adaptability of the SNN. The dynamical synapses regulate the neural connection strength depending on the recent activity: the connection strength increases with recent stimulation and depresses when not activated. In biological networks, dynamical synapses are crucial in implementing plasticity, adaptation, and learning. They enable the detection of temporal patterns, filter high-frequency noise, and drive neural synchronization [19]. The main parameter of the dynamical synapse is the synaptic time constant, τsyn. A higher synaptic time constant means the synapse integrates information over a longer period; a lower τsyn gives more rapid dynamics. In this work, we look at different values of τsyn. Although parameter tuning (signal gain, τsyn) challenges the convertibility of dynami- cal synapse network models, we show that the inherent robustness of our spiking network mitigates the need for extensive optimization. The intrinsic adaptability of our spiking network allows it to maintain functionality even with suboptimal parameter configurations. 2. Materials and Methods 2.1. The Analog XOR Task We define the analog XOR task for SNNs using the analog input signal (x0, x1) ∈ [0, 1] and the analog spike count CT within the time frame T of the output spiking neuron (N5) as follows: CT N5 will exceed the firing threshold h when exactly one of the inputs (x0, x1) is greater than or equal to a boundary value b (see the algorithm Table 1). The final values of the output neuron CT N5 are normalized such that h ∈ (0.00, 1.00). The normalization of the final output is used to compare the models, since ANN activations and the SNN spike count are not guaranteed to be proportionally aligned, which depends on other gain and the synaptic time-constant parameters. The accuracy of the XOR task for an SNN circuit is calculated using the digitized N5) − h), where Θ is the Heaviside variables (Θ(x0 − b), Θ(x1 − b)) and (Θ(normalized(CT step function, and Θ(i) = 1 and 0 for i > 0, and i ≤ 0, respectively. We find the boundaries (b, h) and parameters with a grid search. First, we searched for the gain parameters with a fixed boundary on ANN and then tuned the boundary with another grid search of (b, h). One of the best-found boundaries in ANN is (b, h) = (0.46, 0.3) with an 83.74% accuracy. Due to the structure in the output activations of the ANN XOR circuit, many boundaries yield similar accuracy. The same gain parameters did not work for the SNN with τsyn = 1 ms, and we applied another grid search for parameters given the boundary (b, h) = (0.46, 0.3). The gain parameters that worked best for SNN with τsyn = 1 are (input gain, weight gain) = (5, 110) or (6, 111). Due to the steps in the grid search and the bias gain parameter set to 1, the returned setting is not guaranteed to be the most optimal. After finding the optimal boundaries, we observed how the circuit performed with noise added for suboptimal boundaries. The ANN and SNN circuits have two input neurons, two hidden-layer neurons, and one output neuron (Figure 1). The input and connection weights of the circuits are scaled by the input gain and weight gain; the bias gain is set to 1. The ReLU activation in the ANN circuit is chosen based on previous research of the ANN-to-SNN translation method: ReLU neurons are a good approximation of discrete spikes and are efficient during training [8]. 2.3. Implementation of Noisy Spiking Neurons The spiking circuit is simulated with NEST 2.20.1 [22], consisting of leaky integrate- and-fire iaf_psc_exp neurons with a dynamical synapse model tsodyks_synapse [23] and the parameters listed in Table 2. refractory_input tau_fac tau_rec tau_syn Membrane capacitance, pF Membrane time constant, ms Resting membrane potential, mV Initial membrane potential, mV Reset potential of the membrane, mV Lowest value for the membrane potential Discard input during refractory period Constant input current, pA Spike threshold, mV Synapse facilitation time constant, ms Synapse recovery time constant, ms Synaptic time constant (τsyn), ms Simulation resolution, ms Simulation time, s We selected the leaky model for this work due to its biological plausibility [19] and higher susceptibility to stochastic resonance compared to a non-leaky neuron. We have tested the firing rate of the non-leaky neuron with static synapse at different noise levels (see Figure S2). Unlike leaky SNN, static non-leaky SNN produced ANN-like output with higher noise intensity. The non-leaky SNN is simulated in C++ with the same parameters. The leaky neurons’ membrane potential is defined by = −Vm(t) + Ibias + I(t) + I(t)ξmul(t) + ξ add(t) + z(t), Ibias is the base current (18 pA) plus the biases set by the network architecture; I(t) is the postsynaptic input current; ξmul and ξ add is Gaussian white noise generated from the probability density function f (x) of normal distribution with 0 mean and standard deviation D: z(t) is the colored noise implemented with the Orstein–Uhlenbeck process [21]. z(t) is defined with Gaussian noise ξ(t) and the damping term a as The white noise is implemented with the numpy.random.default_rng().normal function. It can be applied directly as additive noise (ξ add), or it can be scaled by input values to mimic synaptic multiplicative noise (I(t)ξmul), that is, accumulated voltage that did not generate a spike [19]. Although different types of noise are introduced together in the same Equation (1), in the experiments they were applied individually for comparison. Unlike unpredictable white noise, the colored noise of the Orstein–Uhlenbeck (OU) process [21] has a non-uniform power spectral density: its values depend on the pre- vious values. The OU process is implemented with the discrete-time approximation of Equation (3) with the damping term (mean-reversion rate) θ = a/τ_z. The mean-reversion rate describes how fast the process converges to the selected mean 0. A lower θ increases the autocorrelation of the process. See Figure S1 for sample noise patterns. Noise is applied only to the input neurons. This noise can be common (identical) across both inputs or independent (different noise values drawn from the same distribu- tion). A new noise value is sampled every 0.1 ms, which is the temporal resolution of the simulation. There are fundamental differences in how noise affects the two networks. In the SNN, noise continuously interacts with the network’s dynamics, influencing synchronization and inhibition before the final spike number is counted. However, in the ANN, negative activations are suppressed by the ReLU activation function, and the effect of the noise is mitigated by averaging the output. 3. Results 3.1. Networks Output Comparison: Non-Linear Separability with Fewer Neurons The ANN of the given circuit structure returns the linear separation of the solution field (Figure 2), while the SNN produces a non-linear solution with the same number of neurons. The SNN XOR can give high-accuracy results at 95% or more with only five neurons. However, this success would only apply to a couple of specific decision boundaries. For ex- ample, in Figure 2 (right), we have 95.5% for (b, h) = (0.36, 0.5). The optimal boundary in SNN would greatly depend on the preset parameters: input gain, weight gain, synaptic time constant of a dynamical synapse, and noise level. The linearity of the ANN circuit solution peaks at 83.74% and produces low variability in accuracy for most boundaries. It is possible to achieve high accuracy (up to 100%) in an ANN circuit for the analog XOR task with a sigmoidal activation function rather than ReLU by applying another layer with a steep sigmoid function to the inputs, which would digitize the analog signal xi to 0 or 1. Insofar as xi is an analog signal between [0, 1], and the ANN structure consists of five neurons as in Figure 1, the ANN XOR recognition accuracy remains low regardless of the activation function. However, the SNN of the similar minimal structure is sufficient for the analog XOR task. Figure 3 shows the accuracy changes with common noise for some selected boundaries. Four boundaries are shown in both graphs: the yellow (b, h) = (0.46, 0.3) is optimal in ANN; the magenta (b, h) = (0.4, 0.5) is the most optimal in SNN; the red (b, h) = (0.42, 0.4) is an example of reaching optimal accuracy with some noise; the dark blue (b, h) = (0.46, 0.2) is a random sample. Both charts show an average accuracy over 20 runs, where noise values are generated with a new seed every run. In the non-spiking circuit of Figure 3 left, each input is tested with 20,000 different noise components drawn from the same distribution, and then all 20,000 trials are averaged for a single output. The same operation is repeated 20 times for each noise level D to have more samples for the average accuracy result. The spiking circuit (Figure 3 right) is simulated for 20 s per input, with a new noise component added every 0.1 ms (NEST resolution setting), with a total of 200,000 noise components per input. This is repeated 20 times for each noise level D. Since the accuracy is measured on normalized data, the standard deviation of the average accuracy is low. Figure 3 shows that the current implementation of the circuits gives (1) some improved accuracy for certain boundaries due to the non-linear separation of the output (Figure 2), (2) the noise effect is more dramatic in the SNN than in the ANN, and (3) some boundaries can have the accuracy improved with noise. 3.2. Dynamical Synapses in Leaky SNN and Their Effect on Stochastic Resonance Different from static synapses that have a fixed connection strength, dynamical synapses regulate their conductance based on the previous activity. Increasing the synaptic time constant τsyn extends the amount of time it takes to decay the synapse strength back to its resting state after a presynaptic spike [23], thus allowing the circuit to integrate input over a longer period. When τsyn is high, as in Figure 4 center, the output neuron has a high contrast firing frequency, compared to the lower τsyn = 1 ms in Figure 2 right and τsyn = 5 ms in Figure 4 left. Figure 5 shows the effect of strong common multiplicative noise on the output firing frequency in the SNN with dynamical and static synapses. All synapse configurations show moderate stochastic resonance with a shift in sensitivity to lower boundaries; however, the dynamical synapse with a high synaptic time constant maintains sharper contrast in the firing rates, which would allow it to perform more reliably even at high-intensity noise. Figure 6 follows the accuracy for some boundaries that are found to be the best at each noise level. Although the static synapse network still exhibits up to 3% improve- ment attributed to noise for the suboptimal boundaries, the dynamical synapse shows a more measurable and predictable pattern in improving the accuracy for suboptimal boundaries with stronger noise. With dynamical synapses, we have 7% improvement for the more optimal boundary (orange) and 17% improved accuracy for the least optimal boundary (purple). 3.3. Improving Accuracy for Sub-Optimal Boundaries in Leaky Dynamic SNN with Noise-Induced Stochastic Resonance The noise component can be common between both inputs or independent. With com- mon noise, a single value is pulled from the normal distribution and applied to both inputs. Independent noise implies pulling two different noise values from the distribution, one for each input. The noise component can also be additive or multiplicative. While both additive and multiplicative noise are technically “added” as a fluctuating current, multiplicative noise is scaled by the original inputs and the input gain values; the additive noise is not scaled by gain and is applied uniformly. The multiplicative noise is stronger than the additive noise by a factor of the input gain value in high inputs (which are closer to 1), but the inputs that are closer to 0 generate low noise. Figure 7 shows the firing rates in networks with different types of strong independent noise. Each noise raises the firing rates in the circuit but at a different rate. Given the same parameters (0 mean, D standard deviation), the OU-colored noise is the most powerful and should be applied at a lower intensity. The multiplicative noise has a stronger shift in sensitivity to the weaker input than the additive noise while maintaining clear non- linear separation. Figure 8 follows the boundaries that were found to be the most accurate at each intensity of additive (Figure 8 left) and colored noise (Figure 8 right). Both white and colored noise drastically improve the accuracy for the suboptimal boundaries due to stochastic resonance. Although additive noise shows slow improvement with high intensity, colored noise has a much stronger effect with the same standard deviation D, and the accuracy degrades faster after peaking. Figure 9 right (solid line) follows the same boundaries but with the addition of only multiplicative noise. Both additive and multiplicative noise have a similar effect on the current network. However, compared to additive and colored noise, multiplicative noise reaches near-optimal scores with lower noise and produces higher accuracies per node overall. For example, at D = 5 of multiplicative noise (Figure 9 right), the suboptimal boundaries reach between 92–95% accuracy, the additive noise requires a higher D for similar results, and the colored noise accuracy peaks at 87–93%. Figure 9 compares the effects of common and independent noise on suboptimal boundaries. The chart shows some boundaries found to be most accurate at each noise level and follows changes in their accuracy. Independent noise gives slightly more improvement than common noise at first, but the trend reverses for less optimal boundaries with high noise intensity (Figure 9 left). Strong common noise is more effective than the independent noise for the boundaries where the model is not optimized, for example, the black boundary (b, h) = (0.36, 0.4). The accuracy gap between the common and independent noisy networks increases with a higher D as a result of more variation among the individual noise components. This gap is minimal with a high synaptic time constant in Figure 9 right. Even though the different types of noise have nuances in their effect, we have shown that noise makes the dynamical spiking network more sensitive to weaker input due to stochastic resonance, thus boosting the untuned dynamical spiking network’s performance to near-optimal levels. In artificial networks, the ability to adapt is another way (besides neuromorphic hardware) to reduce the power consumption during a model’s training and inference. In biological networks, the ability to adapt to changing or missing input is embedded in the brain’s regime of stable propagation of synchronous neural activity among asynchronous global activity [20,24], a combination of rate and temporal coding [25]. The physical properties that contribute to temporal coding are inhibitory connections (feedback) [17], the presence of noise [26], and the short-term plasticity of dynamical synapses [23,27]. These properties are usually omitted from the standard conversion method based on the ANN-to-SNN rate coding [4,8,28]. This work implemented temporal features in the XOR network in the form of multiplicative synaptic noise and dynamical synapses to discuss their effects on adaptation. The implementation of temporal features in the SNN introduces notable network translation challenges, especially if we seek to apply these results to “convert” existing well- performing ANNs to SNN. The gain parameters for SNN have to be re-selected depending on the synaptic time constant of the dynamical synapse. To make the circuits equivalent and convertible, firing frequency/activations have to be aligned, the ANN activations’ output has to have a similar shape to that of an SNN (non-linear separation), implying an architectural change; a parameter selection rule has to be established, such that the same boundary is returned as the most optimal. Although ANN models can benefit from noisy training [29], the current set-up showed a minimal noise-induced stochastic resonance effect in ANN. In SNN, noise interacts with neurons’ internal dynamics, and we have more measurable changes with stronger noise when the network is not optimally tuned. We have also shown that the spiking network with multiplicative noise has increased sensitivity to sub-optimal inputs, which can be applied as an adaptation. The noise types applied in this work show a similar effect, which is likely to be more varied in a larger network. The noisy SNN stochastic resonance presented in this work implies that only the suboptimal boundaries that can be helped by amplifying the firing frequency will be improved. This poses a question for implementing noise with inverse effects that would weaken the firing frequency in stronger inputs and adjust the circuit for higher boundaries instead. The functionality of a noisy SNN XOR could also be expanded to other functions by implementing other temporal characteristics in the form of inhibitory neuron pools [30], feedback loops, or taking into account the synchronization index [25].",
         "https://www.mdpi.com/1099-4300/27/3/219/pdf?version=1740123018",
         "extracted",
         "None",
         "",
         "Noise and Dynamical Synapses as Optimization Tools for Spiking Neural Networks"
        ],
        [
         "11",
         "00466e50bb0d57aaf1949c4f295bd6203236a42a",
         "Stress is a physiological and psychological response triggered by internal or external stressors that challenge the body's homeostasis. Cortisol, a glucocorticoid hormone released by the adrenal glands in response to stress, plays a pivotal role in modulating this response. Its primary function is to mobilize energy, regulate inflammation, and enhance cognitive processes during acute stress. While cortisol facilitates adaptation by suppressing overactive immune responses and ensuring resource availability, its prolonged elevation can lead to detrimental effects, including metabolic disorders, cardiovascular diseases, and cognitive impairments. Conversely, inadequate cortisol production disrupts the bodyâ€™s ability to manage stress, resulting in conditions like fatigue, hypotension, and impaired recovery. This study explores the dynamic relationship between stress and cortisol, emphasizing how balanced cortisol levels contribute to stress resolution and homeostasis restoration. Understanding cortisolâ€™s dual role provides insights into its potential therapeutic applications for managing stress-related disorders.",
         "Anliana,Henry Panguhutan Sitorus,Melva Silitonga",
         "\n**BLOCK**fs== 11.0**p== 0.0**b== 0.9**t== 0.1**l== 0.4**r== 0.3**\nInternational Journal of Ecophysiology\nJournal homepage: https://talenta.usu.ac.id/ijoep\n**BLOCK**fs== 11.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\nAnliana1*, Henry Pangihutan Sitorus1, Melva Silitonga2\n1Biology Education, Medan, 20221, State University of Medan\n2Biology Education, Lecturer, Medan, 20221, State University of Medan\n*Corresponding Author: anliana1982@gmail.com\nARTICLE   INFO\nArticle history:\nReceived 8 December 2024\nRevised 10 January 2025\nAccepted 28 February 2025\n**BLOCK**fs== 11.0**p== 0.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nABSTRACT\n**BLOCK**fs== 11.0**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.6**\nE-ISSN: 2656-0674\nHow to cite:\nAnliana, Henry Pangihutan Sitorus,\nMelva  Silitonga  (2025),  “The  Role\nof  cortisol  in  the  stress  response”.\nInternational\nof\nJournal\nEcophysiology, (7)1, 48-58.\n**BLOCK**fs== 11.0**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.6**\nThis work is licensed under a\nCreative Commons Attribution-\nShareAlike 4.0 International.\nHttp://doi.org/10.32734/ijoep.v7i1.19118\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.3**l== 0.4**r== 0.1**\nStress  is  a  physiological  and  psychological  response  triggered  by\ninternal  or  external  stressors  that  challenge  the  body's  homeostasis.\nCortisol,  a  glucocorticoid  hormone  released  by  the  adrenal  glands  in\nresponse to stress, plays a pivotal role in modulating this response. Its\nprimary  function  is  to  mobilize  energy,  regulate  inflammation,  and\nenhance  cognitive  processes  during  acute  stress.  While  cortisol\nfacilitates adaptation by suppressing overactive immune responses and\nensuring  resource  availability,  its  prolonged  elevation  can  lead  to\ndetrimental  effects,  including  metabolic  disorders,  cardiovascular\ndiseases,  and  cognitive  impairments.  Conversely,  inadequate  cortisol\nproduction  disrupts  the  body’s  ability  to  manage  stress,  resulting  in\nconditions like fatigue, hypotension, and impaired recovery. This study\nthe  dynamic  relationship  between  stress  and  cortisol,\nexplores\nemphasizing how balanced cortisol levels contribute to stress resolution\nand homeostasis restoration. Understanding cortisol’s dual role provides\ninsights into its potential therapeutic applications for managing stress-\nrelated disorders.\nKeyword:  stress,  cortisol,  the  role of  cortisol,  mechanism  of  cortisol,\ncortisol and stress hormone\nABSTRAK\nStres adalah respons fisiologis dan psikologis yang dipicu oleh stresor\ninternal  atau  eksternal  yang  menantang  homeostasis  tubuh.  Kortisol,\nhormon glukokortikoid yang dilepaskan oleh kelenjar adrenal sebagai\nrespons  terhadap  stres,  memegang  peran  penting  dalam  memodulasi\nrespons  ini.  Fungsi  utamanya  adalah  untuk  memobilisasi  energi,\nmengatur peradangan, dan meningkatkan proses kognitif selama stres\nakut.  Sementara  kortisol  memfasilitasi  adaptasi  dengan  menekan\nrespons  imun  yang  terlalu  aktif  dan  memastikan  ketersediaan  sumber\ndaya,  peningkatan  jangka  panjangnya  dapat  menyebabkan  efek\nmerugikan,  termasuk  gangguan  metabolik,  penyakit  kardiovaskular,\ndan  gangguan  kognitif.  Sebaliknya,  produksi  kortisol  yang  tidak\nmemadai mengganggu kemampuan tubuh untuk mengelola stres, yang\nmengakibatkan  kondisi  seperti  kelelahan,  hipotensi,  dan  pemulihan\nyang  terganggu.  Studi  ini  mengeksplorasi  hubungan  dinamis  antara\nstres  dan  kortisol,  menekankan  bagaimana  kadar  kortisol  yang\nseimbang berkontribusi pada resolusi stres dan pemulihan homeostasis.\nMemahami peran ganda kortisol memberikan wawasan tentang potensi\naplikasi terapeutiknya untuk mengelola gangguan terkait stres.\n.\nKata kunci: stres, kortisol, peran kortisol, mekanisme kortisol, kortisol\ndan hormon stres\n**BLOCK**fs== 11.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nIntroduction\n**BLOCK**fs== 11.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nStress is an inevitable aspect of life, influencing both physical and mental well-being. Defined as the\nbody’s response to any challenge that disrupts homeostasis, stress can manifest acutely or chronically, with\n**BLOCK**fs== 10.6**p== 1.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   49\n**BLOCK**fs== 11.0**p== 1.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nvarying impacts depending on its intensity and duration. The hypothalamic pituitary adrenal (HPA) axis is\ncentral to the stress response, with cortisol as its primary effector hormone [1].\n**BLOCK**fs== 11.0**p== 1.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nCortisol,  often  referred  to  as  the  \"stress  hormone,\"  orchestrates  several  adaptive  responses  aimed  at\nhelping the body cope with and recover from stress. In the short term, cortisol mobilizes energy reserves by\nincreasing glucose availability, suppresses excessive immune activity, and enhances cognitive functions such\nas focus and decision-making. These effects are essential for acute stress adaptation, often described as the\n\"fight-or-flight\" response [2].\n**BLOCK**fs== 11.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nHowever,  the  balance  of  cortisol  levels  is  critical.  Chronic  stress,  which  leads  to  prolonged  cortisol\nelevation, is associated with negative outcomes such as metabolic syndrome, hypertension, and neurocognitive\ndecline.  On  the  other  hand,  insufficient  cortisol  production,  as  seen  in  conditions  like  Addison’s  disease,\nimpairs  the  body's  ability  to  handle  stress,  leading  to  fatigue,  hypotension,  and  increased  vulnerability  to\nexternal stressors [3].\n**BLOCK**fs== 11.0**p== 1.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nThis article delves into the intricate relationship between stress and cortisol, examining how cortisol\ncontributes to stress resolution and discussing the consequences of dysregulated cortisol levels. By exploring\nthese  dynamics,  the  study  highlights  cortisol’s  potential  as  a  therapeutic  target  in  managing  stress-related\ndisorders and promoting overall resilience.\n**BLOCK**fs== 11.0**p== 1.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nThis systematic review was performed by online searches of PubMed Google Scholar, Sciencedirect\nand Mendeley databases. The descriptors “cortisol and stres response”, “stres hormone”, “stress and stressor\n“the role of cortisol”.  The inclusion criteria were research articles on role of cortisol to stres response. The\nsearch  returned  185  articles  and  the  preselection  was  made  by  reading  the  abstracts  and  fulltext  research\npublications,  while  excluding  reviews.  The  preferred  reporting  items  for  systematic  and  meta-analysis\n(PRISMA) framework used data collection for this review is shown in Figure 1.\n**BLOCK**fs== 11.0**p== 1.0**b== 0.1**t== 0.9**l== 0.3**r== 0.2**\nFigure 1. PRISMA flowchart for the review methodology.\n**BLOCK**fs== 10.6**p== 2.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   50\n**BLOCK**fs== 11.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nResult and discussion\n**BLOCK**fs== 11.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nStudies that have been selected in this review demonstrate that role of cortisol in the stress response that\n**BLOCK**fs== 11.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.4**\nused to systematic literature review by using PRISMA at Table 1.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nReference\n**BLOCK**fs== 11.0**p== 2.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nHighlight Result\n**BLOCK**fs== 11.0**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.6**\nSapolsky, R. M. (2020). Cortisol’s Role\nin Acute and Chronic Stress Responses.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nFunder, J. W., et al. (2020). The\nPhysiology of Cortisol Secretion\n**BLOCK**fs== 11.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nThau, L., Gandhi, J., & Sharma, S.\n(2021). Physiology, Cortisol\n**BLOCK**fs== 11.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nMcEwen, B. S. (2021). Acute Stress\nResponses in Humans.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nHerman, J. P., et al. (2021). CRH and\nthe HPA Axis in Stress Regulation\n**BLOCK**fs== 11.0**p== 2.0**b== 0.7**t== 0.2**l== 0.4**r== 0.1**\nThe  crucial  role  of  cortisol,  a  key  stress  hormone,  in  how  we\nrespond to stress, both in the short term and over the long run.\nSapolsky explains that cortisol helps the body handle acute stress\nby mobilizing  energy  and boosting  the fight-or-flight  response,\nallowing people to deal with immediate threats. However, when\nstress becomes chronic, sustained high levels of cortisol can have\nharmful effects on various bodily systems, such as the immune,\ncardiovascular, and nervous systems.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.6**t== 0.3**l== 0.4**r== 0.1**\nThe  article  offers  an  in-depth  explanation  of  how  cortisol\nsecretion is regulated and its physiological functions in the body.\nIt  describes  how  cortisol,  a  crucial  glucocorticoid  hormone\nproduced by the adrenal glands, is released in reaction to stress\nvia  the  hypothalamic-pituitary-adrenal  (HPA)  axis.  The  article\nalso  highlights  the  various  impacts  of  cortisol  on  metabolism,\nimmune function, and the body's ability to adapt to stress.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.5**t== 0.4**l== 0.4**r== 0.1**\nCortisol levels follow a diurnal pattern, typically peaking in the\nmorning shortly after waking and declining throughout the day. It\nis  regulated  by  the  hypothalamic-pituitary-adrenal  (HPA)  axis,\nwhere\nreleases  corticotropin-releasing\nhormone  (CRH),  stimulating  the  pituitary  gland  to  release\nadrenocorticotropic  hormone  (ACTH),  which  then  stimulates\ncortisol production in the adrenal glands.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nthe  hypothalamus\n**BLOCK**fs== 11.0**p== 2.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\nThe acute stress response is a critical biological process that helps\nthe body react to immediate threats by activating the sympathetic\nnervous system and the HPA axis. This response is beneficial in\nthe short term, as it boosts alertness and energy to help us survive\nstressful situations.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.2**t== 0.6**l== 0.4**r== 0.1**\nThe key role of the CRH and HPA axis in both the physical and\nmental  reactions  to  stress.  CRH,  which  is  produced  in  the\nhypothalamus,  is  essential  for  initiating  the  body’s  stress\nresponse.\nrelease  of\nadrenocorticotropic hormone (ACTH), which in turn prompts the\nadrenal glands to produce cortisol. This hormonal cascade is vital\nfor mobilizing energy and regulating the body’s functions during\ntimes of stress.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.3**t== 0.7**l== 0.7**r== 0.3**\ntriggering\n**BLOCK**fs== 11.0**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\nIt  does\n**BLOCK**fs== 11.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.6**\nZefferino, R., Di Gioia, S., & Conese,\nM. (2021). Molecular links between\nendocrine, nervous and immune system\nduring chronic stress\n**BLOCK**fs== 11.0**p== 2.0**b== 0.1**t== 0.8**l== 0.4**r== 0.1**\nThe  intricate  and  interdependent  functions  of  the  endocrine,\nnervous,  and  immune  systems  in  how  the  body  responds  to\nchronic  stress,  both  physiologically  and  at  the  molecular  level.\nFrom  the  context,  it  seems  the  authors  suggest  that  prolonged\nstress  can  cause  major  changes  in  these  systems,  triggering  a\nseries of biological reactions that ultimately affect overall health.\n**BLOCK**fs== 10.6**p== 3.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   51\n**BLOCK**fs== 11.0**p== 3.0**b== 0.9**t== 0.1**l== 0.1**r== 0.8**\nReference\n**BLOCK**fs== 11.0**p== 3.0**b== 0.9**t== 0.1**l== 0.6**r== 0.3**\nHighlight Result\n**BLOCK**fs== 11.0**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.6**\nDziurkowska, E., & Wesolowski, M.\n(2021). Cortisol as a Biomarker of\nMental Disorder Severity\n**BLOCK**fs== 11.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\nIqbal, T., Elahi, A., Wijns, W., &\nShahzad, A. (2023). Cortisol\ndetection methods for stress\nmonitoring in connected health\n**BLOCK**fs== 11.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.6**\nJames, K. A., Stromin, J. I., Steenkamp,\nN., & Combrinck, M. I. (2023).\nUnderstanding the relationships\nbetween physiological and\npsychosocial stress, cortisol and\ncognition.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\nKnezevic, E., Nenic, K., Milanovic, V.,\n& Knezevic, N. N. (2023). The Role of\nCortisol in Chronic Stress,\nNeurodegenerative Diseases, and\nPsychological Disorders.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.8**t== 0.1**l== 0.4**r== 0.1**\nConsequences  of  abnormal  cortisol  secretion.  Disorders  in\ncortisol  secretion  (particularly  hypercortisolemia)  may  cause\nmental disorders and can be one of the many hormonal disorders\naccompanying these conditions,\nfor  example  depression.  Increased  secretion  of  cortisol  in  a\nstressful  situation  has  consequences  for  the  functioning  and\ncondition of our brain.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.7**t== 0.2**l== 0.4**r== 0.1**\nThe article delves into different methods for detecting cortisol, a\nkey stress biomarker, within the framework of connected health\nsystems. It examines various techniques, with a particular focus\non  their  suitability  for  real-time  stress  monitoring  and  their\npotential  for  integration  into  wearable  devices  designed  for\ncontinuous health tracking\n**BLOCK**fs== 11.0**p== 3.0**b== 0.5**t== 0.3**l== 0.4**r== 0.1**\nThe study finds that both physiological and psychosocial stress\nhave a considerable impact on cortisol production, which, in turn,\naffects  cognitive  functions.  However,  the  link  between  cortisol\nand  cognition  is  complex,  as  the  effects  of  increased  cortisol\nlevels depend on factors like the type and duration of stress, as\nwell  as  individual  differences.  Chronic  stress  and  prolonged\nelevated  cortisol  can  negatively  affect  cognitive  abilities,\nin  memory,  attention,  and  decision-making.\nparticularly\nConversely,  short-term  stress  might  temporarily  boost  certain\ncognitive functions due to the body's adaptive responses.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.4**t== 0.5**l== 0.4**r== 0.1**\nChronic stress can lead to sustained high levels of cortisol, which\nmay  impair  neuroplasticity,  disrupt  the  hippocampus  (a  region\ncritical for memory and emotional regulation), and contribute to\ncognitive  decline.  This  can  be  particularly  evident  in  disorders\nlike Alzheimer's disease, depression, and anxiety disorders. The\nstudy emphasizes that cortisol dysregulation can be a contributing\nfactor  to  the  pathophysiology  of  these  conditions,  potentially\nleading to changes in brain structure and function.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nStress is a physiological and psychological response to external or internal demands, often referred to\nas  stressors.  These  demands  challenge  an  individual's  ability  to  cope  and  adapt.  Stress  is  not  inherently\nnegative;  it  can  be  categorized  as  positive  (eustress)  or  negative  (distress)  depending  on  its  effects  on  an\nindividual.  Stress arises  when there is  a mismatch between  the  demands  placed  on an individual  and  their\nresources to cope with those demands [4].\n**BLOCK**fs== 11.0**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nStress can be classified into three primary types:\n**BLOCK**fs== 11.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n1.  Acute Stress is short term stress that occurs in response to immediate threats or challenges. Examples\nnarrowly avoiding an accident, preparing for a presentation. Generally manageable and sometimes\nbeneficial in motivating individuals to perform well [5].\n**BLOCK**fs== 11.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n2.  Chronic Stress is long term stress resulting from ongoing demands or challenges that do not resolve\nquickly.  The  examples  is  financial  difficulties,  ongoing  workplace  conflicts.  It  can  lead  to  serious\nhealth issues like cardiovascular disease, depression, and weakened immunity [6].\n**BLOCK**fs== 11.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n3.  Episodic Acute Stress is recurring episodes of acute stress often associated with patterns of worry and\novercommitment.Examples  are  requently  missing  deadlines,  consistently  feeling  overwhelmed  by\nresponsibilities. It may lead to tension headaches, migraines, and hypertension [7].\n**BLOCK**fs== 11.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n4.  Eustress and Distress. Eustress is positive stress that enhances performance and motivation. Distress\n**BLOCK**fs== 11.0**p== 3.0**b== 0.1**t== 0.9**l== 0.2**r== 0.3**\nis negative stress that overwhelms coping abilities and impairs functioning [8].\n**BLOCK**fs== 10.6**p== 4.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   52\n**BLOCK**fs== 11.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nStressors are the stimuli or events that trigger a stress response. They can be classified into:\n**BLOCK**fs== 11.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n1.  Physical Stressors are Environmental factors that cause physical strain on the body for the examples\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.1**l== 0.2**r== 0.4**\nare noise, temperature extremes, physical injuries [9].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n2.  Psychological  Stressors  are  internal  factors,  such  as  thoughts  or  feelings,  that  lead  to  stress.  The\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nexamples are fear of failure, negative self-talk, and anxiety about the future [10].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n3.  Social Stressors is stress originating from interpersonal relationships or social situations such as are\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.3**\nconflicts with friends or family, social isolation, workplace harassment [11].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n4.  Daily hassles are minor, recurring stressors in everyday life. Such as are traffic jams, losing keys, or\n**BLOCK**fs== 11.0**p== 4.0**b== 0.7**t== 0.2**l== 0.2**r== 0.5**\ndealing with minor workplace issues [12].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nHormones play a pivotal role in regulating the body's response to stress  through the activation of the\nhypothalamic-pituitary-adrenal  (HPA)  axis  and  the  sympathetic-adrenal-medullary  (SAM)  system.  These\nsystems coordinate the release of key hormones to help the body cope with and adapt to stress. Below are the\nmain hormones involved in the stress response and their effects:\n**BLOCK**fs== 11.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n1.  Cortisol (The Primary Stress Hormone). Cortisol is released by the adrenal cortex, is central to the\nHPA axis and helps the body manage acute and chronic stress.The effects are metabolic regulation is\nstimulates  gluconeogenesis  in  the  liver  to  increase  blood  glucose  levels,  immune  modulationcis\nsuppresses  pro  inflammatory  cytokines  and  adaptive  immune  responses  to  prevent  excessive\ninflammation, cardiovascular support is increases blood pressure and cardiac output by enhancing the\nresponsiveness of blood vessels to catecholamines and cognitive enhancement  mproves memory and\nfocus during acute stress. Prolonged cortisol elevation can lead to metabolic syndrome, hypertension,\nimmune suppression, and cognitive decline [13].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\n2.  Adrenaline and Noradrenaline (Catecholamines). These hormones, secreted by the adrenal medulla,\nare  part  of  the  SAM system,  which mediates the  \"fight-or-flight\"  response.  The  effects are  energy\nmobilization  increases  heart  rate  and  respiration  to  deliver  oxygen  and  glucose  to  muscles,\nvasoconstriction is redirects blood flow to vital organs (heart, brain, muscles) by constricting blood\nvessels in less  critical areas.  Enhanced  alertness.  Activates the amygdala  and  prefrontal  cortex for\nquick  decision-making  and  persistent  elevation  can  cause  cardiovascular  strain  and  contribute  to\nanxiety disorders [14].\n**BLOCK**fs== 11.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n3.  Corticotropin-Releasing  Hormone  (CRH).  CRH  is  released  by  the  hypothalamus  to  activate  the\nHPA axis and stimulate the production of adrenocorticotropic hormone (ACTH). The effects are HPA\naxis  activation.  Facilitates  cortisol  release  from  the  adrenal  glands.  Appetite  Suppression  can\nmodulates hunger during stress by interacting with the hypothalamic feeding centers. Chronic Effects\nare prolonged CRH activity can lead to dysregulated HPA axis responses and mood disorders.\n**BLOCK**fs== 11.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nCortisol (C21H30O5), is a steroid hormone with a molecular weight of 362.46 g/mol. Cortisol is a well-\nknown biomarker of psychological and physiological stress. The level of cortisol plays an important part in\nregulating blood pressure, carbohydrate metabolism and glucose levels. It also contributes to the homeostasis\nof  cardiovascular,  renal,  immune,  endocrine  and  skeletal  systems.  Abnormally  increased  levels  of  cortisol\ninterfere  with  blood  amino  acid  and  fatty  acid  levels,  resulting  in  depression  of  the  immune  system  and\ninflammation. Severely increased levels of cortisol contribute to the development of symptoms of  obesity,\nbone fragility, and fatigue, while decreased levels of cortisol lead to Addison’s disease manifested by arterial\nhypotension, weight loss and darkened scars/skinfolds. The most dominating effects of cortisol are indicative\nof emotional or psychological stress and that is why cortisol is also called the ‘stress hormone [19].\n**BLOCK**fs== 10.6**p== 5.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   53\n**BLOCK**fs== 11.0**p== 5.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nFigure 2. Molecular and 3D structure of Cortisol (C21H30O5). In (a) C is for Carbon, H is for Hydrogen and O\nis for Oxygen molecule. In (b) Black shows Carbon, grey shows Hydrogen and Red shows Oxygen\nmolecule.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nNormal Cortisol Levels\nCortisol levels are typically measured in the blood, saliva, or urine. The levels vary depending on\nthe time of day, as they peak in the early morning and decline throughout the day.\n1.  Normal Blood Cortisol Levels [20]:\n**BLOCK**fs== 11.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\n•  Morning (6:00 AM - 8:00 AM): 10-20 µg/dL (275-555 nmol/L)\n•  Afternoon (4:00 PM - 6:00 PM): 3-10 µg/dL (80-275 nmol/L)\n**BLOCK**fs== 11.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n•  Morning: 0.15-0.6 µg/dL (4.14-16.56 nmol/L)\n•  Afternoon: 0.05-0.2 µg/dL (1.38-5.52 nmol/L)\n**BLOCK**fs== 11.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\n•  10-100 µg/day (28-276 nmol/day)\n**BLOCK**fs== 11.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nCortisol Levels During Stress\nDuring acute or chronic stress, cortisol levels may rise significantly above normal.\n1.  Acute Stress. Blood cortisol levels can increase to  20-40 µg/dL (555-1110 nmol/L) during acute stress\n**BLOCK**fs== 11.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\nevents [23].\n**BLOCK**fs== 11.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n2.  Chronic Stress. Chronic exposure to stressors can elevate cortisol levels persistently or disrupt the diurnal\nrhythm, leading to flattened curves (e.g., higher evening levels). Urinary free cortisol levels may exceed\n100 µg/day in cases of chronic stress. [24]\n**BLOCK**fs== 11.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n3.  Pathological Cortisol Levels. Cushing’s Syndrome: Cortisol >50 µg/dL (1380 nmol/L) and Addison’s\n**BLOCK**fs== 11.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nDisease (Low Cortisol): Cortisol <5 µg/dL (138 nmol/L) [25]\n**BLOCK**fs== 11.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nCortisol  levels  are  typically  measured  in  blood,  saliva,  urine,  or  hair  using  various  analytical\ntechniques. These methods vary in sensitivity, specificity, and practicality depending on the research or clinical\ncontext.\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nSample type\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.7**l== 0.4**r== 0.3**\nTable 2. method for identifying cortisollevels.\nspecificity\nsensitivity\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nEase of use\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nSaliva, Blood\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\nModerate\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\nModerate\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nBlood, Urine\n**BLOCK**fs== 11.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nModerate\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.8**l== 0.2**r== 0.7**\nBlood, Saliva,\nUrine\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\nVery High\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.4**\nVery High\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\nComplex\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nSaliva\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\nModerate\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.4**\nModerate\n**BLOCK**fs== 11.0**p== 5.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\nVery Easy\n**BLOCK**fs== 10.6**p== 6.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   54\n**BLOCK**fs== 11.0**p== 6.0**b== 0.9**t== 0.1**l== 0.6**r== 0.3**\nModerate\n**BLOCK**fs== 11.0**p== 6.0**b== 0.9**t== 0.1**l== 0.6**r== 0.3**\nModerate\n**BLOCK**fs== 11.0**p== 6.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nChronic stress\nassessment [30]\nAdrenal disorder\ndiagnosis [31]\n**BLOCK**fs== 11.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nCortisol,  the  primary  glucocorticoid  hormone,  is  released  in  response  to  stress  as  part  of  the\nhypothalamic-pituitary-adrenal (HPA) axis activation. Its increase during stress serves adaptive purposes to\nhelp the body cope with and respond to external or internal challenges.\n**BLOCK**fs== 11.0**p== 6.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nFunction\n**BLOCK**fs== 11.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nEnergy Mobilization\nImmune Modulation\nCardiovascular Support\nCognitive and Behavioral\nAdaptation\n**BLOCK**fs== 11.0**p== 6.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\nTable 3. The aim of cortisol increase during stress\n**BLOCK**fs== 11.0**p== 6.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nPurpose\n**BLOCK**fs== 11.0**p== 6.0**b== 0.7**t== 0.3**l== 0.4**r== 0.1**\nProvides energy to vital organs during stress [32]\nPrevents overactive immune responses and reduces inflammation [33]\nEnhances blood pressure and circulation [34]\n**BLOCK**fs== 11.0**p== 6.0**b== 0.6**t== 0.4**l== 0.4**r== 0.1**\nImproves focus, memory, and decision-making during stress [35]\n**BLOCK**fs== 11.0**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nStress Recovery and Termination\n**BLOCK**fs== 11.0**p== 6.0**b== 0.6**t== 0.4**l== 0.4**r== 0.2**\nSelf-regulates the stress response through negative feedback\nmechanisms [36]\n**BLOCK**fs== 11.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nCortisol,  often  called  the  \"stress  hormone,\"  plays  a  dual  role  in  stress  regulation.  While  prolonged\ncortisol elevation is associated with negative effects, short term cortisol release is essential for managing and\nresolving stress. Cortisol helps the body adapt to stress by regulating various physiological and psychological\nprocesses.\n**BLOCK**fs== 11.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n1.  Regulation  of  the  Hypothalamic-Pituitary-Adrenal  (HPA)  Axis.  The  HPA  axis  governs  cortisol\nproduction. During stress, the hypothalamus signals the pituitary gland to stimulate cortisol release from\nthe adrenal glands. Cortisol, in turn, exerts a negative feedback effect on the HPA axis, reducing the\nrelease  of  corticotropin-releasing  hormone  (CRH)  and  adrenocorticotropic  hormone  (ACTH).  This\nfeedback loop prevents excessive cortisol secretion and helps restore homeostasis [37].\n**BLOCK**fs== 11.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n2.  Modulation of Inflammation. Cortisol suppresses the immune response by inhibiting pro-inflammatory\ncytokines such as IL-6 and TNF-α. This reduces inflammation, which is often elevated during chronic\nstress.  By  dampening  inflammatory  pathways,  cortisol  alleviates  physiological  stress  and  prevents\nstress-related damage to tissues [38].\n**BLOCK**fs== 11.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n3.  Energy  Mobilization  and  Recovery.  Cortisol  facilitates  the  mobilization  of  glucose,  fats,  and  amino\nacids, providing energy to cope with immediate stressors. After the stressor is resolved, cortisol helps\nin energy restoration, promoting recovery and repair processes [39].\n**BLOCK**fs== 11.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n4.  Regulation of Mood and Emotional Responses. Cortisol interacts with brain regions like the amygdala\nand  prefrontal  cortex,  modulating  emotional  responses  to  stress.  By  reducing  excessive  emotional\nreactivity, cortisol contributes to psychological resilience and stress recovery [40].\n**BLOCK**fs== 11.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n5.  Sleep-Wake Regulation. Cortisol levels follow a diurnal rhythm, peaking in the morning and declining\nat night. This rhythm supports stress recovery by facilitating restorative sleep and preparing the body\nfor daily challenges. Improved sleep, in turn, reduces stress perception and enhances overall resilience\n[41].\n**BLOCK**fs== 11.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nCortisol, a vital glucocorticoid hormone, plays a crucial role in maintaining homeostasis during stress.\nHowever,  abnormal  increases  or  decreases  in  cortisol  levels  can  have  significant  physiological  and\npsychological effects. The effect of cortisol is shown in Table 4.\n**BLOCK**fs== 10.6**p== 7.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   55\n**BLOCK**fs== 11.0**p== 7.0**b== 0.9**t== 0.1**l== 0.4**r== 0.4**\nTable 4. Effect of cortisol\n**BLOCK**fs== 11.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nCortisol Level\nIncreased\n(High)\nDecreased\n(Low)\n**BLOCK**fs== 11.0**p== 7.0**b== 0.9**t== 0.1**l== 0.3**r== 0.5**\nShort-Term Effects\n**BLOCK**fs== 11.0**p== 7.0**b== 0.8**t== 0.1**l== 0.2**r== 0.4**\nMobilized energy, suppressed inflammation,\nheightened focus\nHypoglycemia, hypotension, impaired stress\nresponse\n**BLOCK**fs== 11.0**p== 7.0**b== 0.8**t== 0.1**l== 0.6**r== 0.1**\nLong-Term Effects\nInsulin resistance, hypertension, cognitive\ndecline\nFatigue, excessive inflammation,\ndepression\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nAbnormal cortisol levels, whether excessively high or low, can lead to specific diseases and\ndisorders  that  significantly  affect  the  body's  physiological  and  psychological  functions.  Diseases\nrelated to abnoemal coertisol levels are shown in Table 5.\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.3**\nTable 5. Disease related to abnormal cortisol levels\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nCortisol Level\nIncreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\nIncreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\nIncreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nDecreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nDecreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nDecreased\n**BLOCK**fs== 11.0**p== 7.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nSymptoms\nObesity, hypertension, hyperglycemia, depression [44].\nObesity, insulin resistance, dyslipidemia, hypertension\n[45].\nMood disturbances, cognitive decline, sleep issues[46].\nFatigue, hypotension, hyperpigmentation, weight loss\n[47].\nSimilar to Addison's disease without pigmentation or\nsevere electrolyte imbalance [48].\nSevere  hypotension,  abdominal  pain,  confusion,  life-\nthreatening shock [49].\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.8**\nCondition\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nCushing’s Syndrome\n**BLOCK**fs== 11.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nMetabolic Syndrome\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nAnxiety/Depression\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nAddison’s Disease\n**BLOCK**fs== 11.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nSecondary Adrenal\nInsufficiency\n**BLOCK**fs== 11.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nAdrenal Crisis\n**BLOCK**fs== 11.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nConclusion\n**BLOCK**fs== 11.0**p== 7.0**b== 0.3**t== 0.5**l== 0.1**r== 0.1**\nCortisol  is  crucial  in  how  the  body  reacts  to  stress,  serving  as  a  key  element  in  the  hypothalamic-\npituitary-adrenal (HPA) axis. When the body detects a threat, the HPA axis is triggered, leading to a rise in\ncortisol levels. This hormone helps release energy reserves, slows down non-essential functions like digestion\nand  immune  activity,  and primes  the  body  for  quick action,  often  known  as  the  \"fight  or  flight\"  response.\nCortisol  is  typically  elevated  during  stressful  situations,  aiding  the  body  in  dealing  with  short-term  stress.\nHowever, when stress becomes chronic or long-lasting, it can disrupt cortisol production, potentially leading\nto negative health effects such as immune suppression, memory issues, and an increased risk of conditions like\nheart  disease  and  depression.  The  body’s  cortisol  levels  fluctuate,  rising  sharply  during  acute  stress  and\ngradually decreasing once the stressor is gone or resolved. While normal cortisol responses are beneficial and\nadaptive,  prolonged  or  excessive  cortisol  exposure  due  to  ongoing  stress  can  be  harmful,  highlighting  the\nimportance of managing stress for overall well-being.\n**BLOCK**fs== 11.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nRecommendation\nBased on the results of this study to better manage stress and its impact on cortisol levels, individuals\nshould adopt stress reduction techniques such as mindfulness, regular physical activity, and adequate sleep.\nPsychological  interventions,  like  cognitive-behavioral  therapy,  can  help  reduce  chronic  stress  and  regulate\ncortisol  production.  Additionally,  healthcare  professionals  should  consider  monitoring  cortisol  levels  in\npatients with chronic stress, as early intervention may help prevent long-term health issues. Further research\nis also needed to explore the most effective strategies for cortisol regulation in stress-related conditions.\n**BLOCK**fs== 11.0**p== 7.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nAcknowledgements\nThe authors wish to thank all to Prof. Dr. Melva Silitonga and my friend that have supported the work\n**BLOCK**fs== 10.6**p== 8.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   56\n**BLOCK**fs== 11.0**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nConflict of Interest\nThe authors declare that  there is no conflict of interest regarding the publication of this paper. All\nresearch was conducted in the absence of any commercial or financial relationships that could be construed as\na potential conflict of interest.\n**BLOCK**fs== 11.0**p== 8.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nUlrich-Lai,  Y.  M.,  &  Herman,  J.  P.  (2009).  Neural  regulation  of  endocrine  and  autonomic  stress\nresponses. Nature reviews. Neuroscience, 10(6), 397–409. https://doi.org/10.1038/nrn2647\nSapolsky,  R.  M.,  Romero,  L.  M.,  &  Munck,  A.  U.  (2000).  How  do  glucocorticoids  influence  stress\nresponses?  Integrating  permissive,  suppressive,  stimulatory,  and  preparative  actions. Endocrine\nreviews, 21(1), 55–89. https://doi.org/10.1210/edrv.21.1.0389\nChrousos G. P. (2009). Stress and disorders of the stress system. Nature reviews. Endocrinology, 5(7),\n374–381. https://doi.org/10.1038/nrendo.2009.106\n**BLOCK**fs== 11.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[4]  Lazarus, R. S., & Folkman, S. (1984). Stress, Appraisal, and Coping. Springer Publishing.\n[5]  McEwen, B. S. (2021). \"Acute Stress Responses in Humans.\" Nature Reviews Neuroscience, 22(2), 120-\n**BLOCK**fs== 11.0**p== 8.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n135. DOI: 10.1038/s41583-020-00415-4\nSapolsky, R. M. (2020). \"The Impact of Chronic Stress on Health.\" Annual Review of Psychology, 71,\n621-642. DOI: 10.1146/annurev-psych-122118-101544\n**BLOCK**fs== 11.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[7]  American Psychological Association (2022). \"Stress and Health: Episodic Acute Stress.\"  APA Stress\n**BLOCK**fs== 11.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[8]  Goyal,  K.,  &  Sharma,  A.  (2022).  \"Eustress  and  Distress:  Impacts  on  Performance.\"  Psychological\n**BLOCK**fs== 11.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nBulletin. DOI: 10.1037/bul0000345\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n[9]  Cohen, S., Janicki-Deverts, D., & Miller, G. E. (2021). \"Physical Stressors and the HPA Axis.\" Journal\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nof Environmental Psychology, 75, 101645. DOI: 10.1016/j.jenvp.2020.101645\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[10]  Folkman, S. (2021). \"Psychological Stressors and Coping Mechanisms.\" Annual Review of Psychology,\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\n72, 45-67. DOI: 10.1146/annurev-psych-010919-124644\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[11]  Taylor, S. E. (2020). \"Social Stress and Its Impact on Health.\" Health Psychology, 39(5), 345-356. DOI:\n**BLOCK**fs== 11.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[12]  Lazarus,  R.  S.,  &  DeLongis,  A.  (2021).  \"Daily  Hassles  as  Predictors  of  Chronic  Stress.\"  Journal  of\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nBehavioral Medicine.\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[13]  Sapolsky, R. M. (2020). \"Cortisol’s Role in Acute and Chronic Stress Responses.\" Annual Review of\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nPhysiology, 82, 639-661. DOI: 10.1146/annurev-physiol-020518-114406\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[14]  McEwen, B. S., & Morrison, J. H. (2022). \"Catecholamines in Stress and Adaptive Responses.\" Nature\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nReviews Neuroscience, 23(4), 220-233. DOI: 10.1038/s41583-022-00512-y\n**BLOCK**fs== 11.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[15]  Herman, J. P., et al. (2021). \"CRH and the HPA Axis in Stress Regulation.\" Frontiers in Neuroscience,\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n15, 645012. DOI: 10.3389/fnins.2021.645012\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[16]  Carter,  C.  S.,  &  Porges,  S.  W.  (2020).  \"Oxytocin  and  the  Biopsychosocial  Model  of  Stress.\"\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nPsychoneuroendocrinology, 125, 105097. DOI: 10.1016/j.psyneuen.2020.105097\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[17]  Freeman,  M.  E.,  et  al.  (2021).  \"Prolactin  in  Stress  and  Immune  Responses.\"  Frontiers  in\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\nNeuroendocrinology, 50, 1-15. DOI: 10.1016/j.yfrne.2020.100874\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[18]  Bahn,  R.  S.  (2022).  \"Stress  and  Thyroid  Hormone  Dysregulation.\"  Thyroid,  32(7),  789-795.  DOI:\n**BLOCK**fs== 11.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[10.1089/thy.2021.0610](https://doi.org/10.1089/thy\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n[19]  Iqbal, T., Elahi, A., Wijns, W., & Shahzad, A. (2023). Cortisol detection methods for stress  monitoring\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nin connected health. Health Sciences Review, 6, 100079. https://doi.org/10.1016/j.hsr.2023.100079\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[20]  Funder, J. W., et al. (2020). \"The Physiology of Cortisol Secretion.\" Journal of Endocrinology, 245(1),\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\n1-12. DOI: 10.1530/JOE-20-0112\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[21]  Kirschbaum, C., & Hellhammer, D. H. (2021). \"Measuring Salivary Cortisol for Stress Assessment.\"\n**BLOCK**fs== 11.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nPsychoneuroendocrinology, 131, 105291. DOI: 10.1016/j.psyneuen.2020.105291\n**BLOCK**fs== 11.0**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n[22]  Nicolaides, N. C., et al. (2022). \"Cortisol in Urine and Stress Response.\"  Endocrine Reviews, 43(4),\n**BLOCK**fs== 11.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\n639-662. DOI: 10.1210/endrev/bnab034\n**BLOCK**fs== 11.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[23]  Kudielka,  B.  M.,  &  Wüst,  S.  (2020).  \"Acute  Stress-Induced  Cortisol  Responses.\"  Trends  in\n**BLOCK**fs== 11.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.3**\nEndocrinology & Metabolism, 31(7), 634-645. DOI: 10.1016/j.tem.2020.05.001\n**BLOCK**fs== 10.6**p== 9.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   57\n**BLOCK**fs== 11.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n[24]  McEwen,  B.  S.,  &  Sapolsky,  R.  M.  (2021).  \"Chronic  Stress,  HPA  Axis  Dysregulation,  and  Health\nOutcomes.\"  Annual  Review  of  Neuroscience,  44,  267-290.  DOI:  10.1146/annurev-neuro-102020-\n**BLOCK**fs== 11.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n[25]  Nieman, L. K., et al. (2022). \"Disorders of Cortisol Secretion.\" The Lancet Diabetes & Endocrinology,\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n[26]  Kirschbaum, C., & Hellhammer, D. H. (2021). \"Salivary Cortisol as a Biomarker for Stress Research.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nPsychoneuroendocrinology, 131, 105291. DOI: 10.1016/j.psyneuen.2020.105291\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[27]  Bäck, S. E., et al. (2022). \"The Historical and Modern Use of Radioimmunoassay in Endocrinology.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nTrends in Endocrinology & Metabolism, 33(5), 383-391. DOI: 10.1016/j.tem.2021.12.009\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[28]  Taylor,  R.  L.,  et  al.  (2021).  \"LC-MS/MS  for  Cortisol  Measurement:  A  Gold  Standard  Approach.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nJournal of Chromatography B, 1185, 123456. DOI: 10.1016/j.jchromb.2021.123456\n**BLOCK**fs== 11.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[29]  Hellhammer, J., et al. (2020). \"The Role of Salivary Cortisol in Psychophysiological Stress Research.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\nNeuropsychobiology, 79(3), 243-252. DOI: 10.1159/000505620\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[30]  Meyer, J., et al. (2021). \"Hair Cortisol: A Biomarker of Chronic Stress?\" Psychoneuroendocrinology,\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n125, 105097. DOI: 10.1016/j.psyneuen.2021.105097\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[31]  Nieman, L. K. (2022). \"Urinary Free Cortisol Testing in Endocrine Disorders.\" The Lancet Diabetes &\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.3**\nEndocrinology, 10(4), 301-314. DOI: 10.1016/S2213-8587(21)00373-7\n**BLOCK**fs== 11.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[32]  Sapolsky,  R.  M.  (2020).  \"Cortisol  and  Energy  Regulation  During  Acute  Stress.\"  Annual  Review  of\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.3**\nPhysiology, 82, 639-661. DOI: 10.1146/annurev-physiol-020518-114406\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[33]  Miller,  G.  E.,  &  Cohen,  S.  (2020).  \"Cortisol's  Role  in  Modulating  Inflammation  During  Stress.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nPsychosomatic Medicine, 82(2), 124-131. DOI: 10.1097/PSY.0000000000000788\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[34]  Kudielka, B. M., & Wüst, S. (2020). \"Acute Stress and Cortisol's Cardiovascular Effects.\" Trends in\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\nEndocrinology & Metabolism, 31(7), 634-645. DOI: 10.1016/j.tem.2020.05.001\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[35]  McEwen,  B.  S.  (2022).  \"Cortisol's  Cognitive  and  Behavioral  Roles  in  Stress  Adaptation.\"  Nature\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\nReviews Neuroscience, 23(4), 220-233. DOI: 10.1038/s41583-022-00512-y\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n[36]  Herman, J. P., et al. (2021). \"Negative Feedback of the HPA Axis in Stress Regulation.\" Frontiers in\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nNeuroscience, 15, 645012. DOI: 10.3389/fnins.2021.645012\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[37]  Herman, J. P., et al. (2021). \"Feedback Regulation of the HPA Axis in Stress Resilience.\" Frontiers in\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nNeuroscience, 15, 645012. DOI: 10.3389/fnins.2021.645012\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[38]  Miller,  G.  E.,  &  Cohen,  S.  (2020).  \"Cortisol  and  Inflammatory  Processes  in  Stress  Regulation.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nPsychosomatic Medicine, 82(2), 124-131. DOI: 10.1097/PSY.0000000000000788\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[39]  Sapolsky, R. M. (2020). \"The Adaptive Role of Cortisol in Energy Regulation During Stress.\" Annual\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nReview of Physiology, 82, 639-661. DOI: 10.1146/annurev-physiol-020518-114406\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[40]  McEwen, B. S., & Morrison, J. H. (2022). \"Cortisol and Brain Plasticity in Stress Management.\" Nature\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nReviews Neuroscience, 23(4), 220-233. DOI: 10.1038/s41583-022-00512-y\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[41]  Nicolaides,  N.  C.,  et  al.  (2021).  \"Cortisol  Rhythms  and  Their  Role  in  Sleep  and  Stress  Recovery.\"\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nEndocrine Reviews, 42(4), 725-748. DOI: 10.1210/endrev/bnab032\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[42]  Chrousos,  G.  P.  (2020).  \"Stress  Management  Interventions  and  Cortisol  Regulation.\"  Journal  of\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.6**l== 0.1**r== 0.3**\nPsychotherapy and Psychosomatics, 89(5), 261-273. DOI: 10.1159/000509643\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[43]  Pariante,  C.  M.,  et  al.  (2021).  \"Dietary  Interventions  and  Stress  Hormone  Regulation.\"  Nutritional\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nNeuroscience, 24(8), 551-562. DOI: 10.1080/1028415X.2020.1761728\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[44]  Nieman,  L.  K.,  et  al.  (2022).  \"Cushing's  Syndrome:  Pathophysiology  and  Diagnosis.\"  The  Lancet\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nDiabetes & Endocrinology, 10(4), 301-314. DOI: 10.1016/S2213-8587(21)00373-7\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[45]  Boden, G. (2021). \"Chronic Cortisol and Metabolic Syndrome.\" Endocrine Reviews, 42(3), 307-320.\n**BLOCK**fs== 11.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nDOI: 10.1210/endrev/bnab020\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n[46]  McEwen, B. S. (2022). \"Cortisol and Psychiatric Disorders.\" Nature Reviews Neuroscience, 23(4), 220-\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[47]  Arlt, W., et al. (2021). \"Primary Adrenal Insufficiency: Causes and Consequences.\" Endocrine Reviews,\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n42(3), 623-635. DOI: 10.1210/endrev/bnab030\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[48]  Nicolaides, N. C., et al. (2021). \"Adrenal Crisis and Cortisol Deficiency.\" Endocrine Reviews, 42(4),\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\n725-748. DOI: 10.1210/endrev/bnab032\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[49]  Iqbal, T., Elahi, A., Wijns, W., & Shahzad, A. (2023). Cortisol detection methods for stress monitoring\n**BLOCK**fs== 11.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nin connected health. Health Sciences Review, 6, 100079. https://doi.org/10.1016/j.hsr.2023.100079\n**BLOCK**fs== 11.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[50]  James, K. A., Stromin, J. I., Steenkamp, N., & Combrinck, M. I. (2023). Understanding the relationships\nbetween physiological and psychosocial stress, cortisol and cognition. Frontiers in Endocrinology, 14.\nhttps://doi.org/10.3389/fendo.2023.1085950\n**BLOCK**fs== 10.6**p== 10.0**b== 1.0**t== 0.0**l== 0.3**r== 0.1**\nInternational Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   58\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n[51]  Zefferino,  R.,  Di  Gioia,  S.,  &  Conese,  M.  (2021).  Molecular  links  between  endocrine,  nervous  and\ne01960.\nstress.\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.7**r== 0.3**\nbehavior,\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.4**r== 0.6**\nchronic\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nimmune\nhttps://doi.org/10.1002/brb3.1960\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.2**r== 0.7**\nsystem\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\nduring\n**BLOCK**fs== 11.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n[52]  Knezevic, E., Nenic, K., Milanovic, V., & Knezevic, N. N. (2023). The Role of Cortisol in Chronic\nStress,  Neurodegenerative  Diseases,  and  Psychological  Disorders.  Cells,  12(23),  2726.\nhttps://doi.org/10.3390/cells12232726",
         "International Journal of Ecophysiology Journal homepage: https://talenta.usu.ac.id/ijoep Anliana1*, Henry Pangihutan Sitorus1, Melva Silitonga2 1Biology Education, Medan, 20221, State University of Medan 2Biology Education, Lecturer, Medan, 20221, State University of Medan *Corresponding Author: anliana1982@gmail.com ARTICLE   INFO Article history: Received 8 December 2024 Revised 10 January 2025 Accepted 28 February 2025 E-ISSN: 2656-0674 How to cite: Anliana, Henry Pangihutan Sitorus, Melva  Silitonga  (2025),  “The  Role of  cortisol  in  the  stress  response”. International of Journal Ecophysiology, (7)1, 48-58. This work is licensed under a Creative Commons Attribution- ShareAlike 4.0 International. Http://doi.org/10.32734/ijoep.v7i1.19118 Stress is an inevitable aspect of life, influencing both physical and mental well-being. Defined as the body’s response to any challenge that disrupts homeostasis, stress can manifest acutely or chronically, with International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   49 varying impacts depending on its intensity and duration. The hypothalamic pituitary adrenal (HPA) axis is central to the stress response, with cortisol as its primary effector hormone [1]. Cortisol,  often  referred  to  as  the  \"stress  hormone,\"  orchestrates  several  adaptive  responses  aimed  at helping the body cope with and recover from stress. In the short term, cortisol mobilizes energy reserves by increasing glucose availability, suppresses excessive immune activity, and enhances cognitive functions such as focus and decision-making. These effects are essential for acute stress adaptation, often described as the \"fight-or-flight\" response [2]. However,  the  balance  of  cortisol  levels  is  critical.  Chronic  stress,  which  leads  to  prolonged  cortisol elevation, is associated with negative outcomes such as metabolic syndrome, hypertension, and neurocognitive decline.  On  the  other  hand,  insufficient  cortisol  production,  as  seen  in  conditions  like  Addison’s  disease, impairs  the  body's  ability  to  handle  stress,  leading  to  fatigue,  hypotension,  and  increased  vulnerability  to external stressors [3]. This article delves into the intricate relationship between stress and cortisol, examining how cortisol contributes to stress resolution and discussing the consequences of dysregulated cortisol levels. By exploring these  dynamics,  the  study  highlights  cortisol’s  potential  as  a  therapeutic  target  in  managing  stress-related disorders and promoting overall resilience. This systematic review was performed by online searches of PubMed Google Scholar, Sciencedirect and Mendeley databases. The descriptors “cortisol and stres response”, “stres hormone”, “stress and stressor “the role of cortisol”.  The inclusion criteria were research articles on role of cortisol to stres response. The search  returned  185  articles  and  the  preselection  was  made  by  reading  the  abstracts  and  fulltext  research publications,  while  excluding  reviews.  The  preferred  reporting  items  for  systematic  and  meta-analysis (PRISMA) framework used data collection for this review is shown in Figure 1. Figure 1. PRISMA flowchart for the review methodology. International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   50 Result and discussion Studies that have been selected in this review demonstrate that role of cortisol in the stress response that used to systematic literature review by using PRISMA at Table 1. Sapolsky, R. M. (2020). Cortisol’s Role in Acute and Chronic Stress Responses. Funder, J. W., et al. (2020). The Physiology of Cortisol Secretion Thau, L., Gandhi, J., & Sharma, S. (2021). Physiology, Cortisol McEwen, B. S. (2021). Acute Stress Responses in Humans. Herman, J. P., et al. (2021). CRH and the HPA Axis in Stress Regulation The  crucial  role  of  cortisol,  a  key  stress  hormone,  in  how  we respond to stress, both in the short term and over the long run. Sapolsky explains that cortisol helps the body handle acute stress by mobilizing  energy  and boosting  the fight-or-flight  response, allowing people to deal with immediate threats. However, when stress becomes chronic, sustained high levels of cortisol can have harmful effects on various bodily systems, such as the immune, cardiovascular, and nervous systems. The  article  offers  an  in-depth  explanation  of  how  cortisol secretion is regulated and its physiological functions in the body. It  describes  how  cortisol,  a  crucial  glucocorticoid  hormone produced by the adrenal glands, is released in reaction to stress via  the  hypothalamic-pituitary-adrenal  (HPA)  axis.  The  article also  highlights  the  various  impacts  of  cortisol  on  metabolism, immune function, and the body's ability to adapt to stress. Cortisol levels follow a diurnal pattern, typically peaking in the morning shortly after waking and declining throughout the day. It is  regulated  by  the  hypothalamic-pituitary-adrenal  (HPA)  axis, where releases  corticotropin-releasing hormone  (CRH),  stimulating  the  pituitary  gland  to  release adrenocorticotropic  hormone  (ACTH),  which  then  stimulates cortisol production in the adrenal glands. the  hypothalamus The acute stress response is a critical biological process that helps the body react to immediate threats by activating the sympathetic nervous system and the HPA axis. This response is beneficial in the short term, as it boosts alertness and energy to help us survive stressful situations. The key role of the CRH and HPA axis in both the physical and mental  reactions  to  stress.  CRH,  which  is  produced  in  the hypothalamus,  is  essential  for  initiating  the  body’s  stress response. release  of adrenocorticotropic hormone (ACTH), which in turn prompts the adrenal glands to produce cortisol. This hormonal cascade is vital for mobilizing energy and regulating the body’s functions during times of stress. triggering It  does Zefferino, R., Di Gioia, S., & Conese, M. (2021). Molecular links between endocrine, nervous and immune system during chronic stress The  intricate  and  interdependent  functions  of  the  endocrine, nervous,  and  immune  systems  in  how  the  body  responds  to chronic  stress,  both  physiologically  and  at  the  molecular  level. From  the  context,  it  seems  the  authors  suggest  that  prolonged stress  can  cause  major  changes  in  these  systems,  triggering  a series of biological reactions that ultimately affect overall health. International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   51 Dziurkowska, E., & Wesolowski, M. (2021). Cortisol as a Biomarker of Mental Disorder Severity Iqbal, T., Elahi, A., Wijns, W., & Shahzad, A. (2023). Cortisol detection methods for stress monitoring in connected health James, K. A., Stromin, J. I., Steenkamp, N., & Combrinck, M. I. (2023). Understanding the relationships between physiological and psychosocial stress, cortisol and cognition. Knezevic, E., Nenic, K., Milanovic, V., & Knezevic, N. N. (2023). The Role of Cortisol in Chronic Stress, Neurodegenerative Diseases, and Psychological Disorders. Consequences  of  abnormal  cortisol  secretion.  Disorders  in cortisol  secretion  (particularly  hypercortisolemia)  may  cause mental disorders and can be one of the many hormonal disorders accompanying these conditions, for  example  depression.  Increased  secretion  of  cortisol  in  a stressful  situation  has  consequences  for  the  functioning  and condition of our brain. The article delves into different methods for detecting cortisol, a key stress biomarker, within the framework of connected health systems. It examines various techniques, with a particular focus on  their  suitability  for  real-time  stress  monitoring  and  their potential  for  integration  into  wearable  devices  designed  for continuous health tracking The study finds that both physiological and psychosocial stress have a considerable impact on cortisol production, which, in turn, affects  cognitive  functions.  However,  the  link  between  cortisol and  cognition  is  complex,  as  the  effects  of  increased  cortisol levels depend on factors like the type and duration of stress, as well  as  individual  differences.  Chronic  stress  and  prolonged elevated  cortisol  can  negatively  affect  cognitive  abilities, in  memory,  attention,  and  decision-making. particularly Conversely,  short-term  stress  might  temporarily  boost  certain cognitive functions due to the body's adaptive responses. Chronic stress can lead to sustained high levels of cortisol, which may  impair  neuroplasticity,  disrupt  the  hippocampus  (a  region critical for memory and emotional regulation), and contribute to cognitive  decline.  This  can  be  particularly  evident  in  disorders like Alzheimer's disease, depression, and anxiety disorders. The study emphasizes that cortisol dysregulation can be a contributing factor  to  the  pathophysiology  of  these  conditions,  potentially leading to changes in brain structure and function. Stress is a physiological and psychological response to external or internal demands, often referred to as  stressors.  These  demands  challenge  an  individual's  ability  to  cope  and  adapt.  Stress  is  not  inherently negative;  it  can  be  categorized  as  positive  (eustress)  or  negative  (distress)  depending  on  its  effects  on  an individual.  Stress arises  when there is  a mismatch between  the  demands  placed  on an individual  and  their resources to cope with those demands [4]. Stress can be classified into three primary types: 1.  Acute Stress is short term stress that occurs in response to immediate threats or challenges. Examples narrowly avoiding an accident, preparing for a presentation. Generally manageable and sometimes beneficial in motivating individuals to perform well [5]. 2.  Chronic Stress is long term stress resulting from ongoing demands or challenges that do not resolve quickly.  The  examples  is  financial  difficulties,  ongoing  workplace  conflicts.  It  can  lead  to  serious health issues like cardiovascular disease, depression, and weakened immunity [6]. 3.  Episodic Acute Stress is recurring episodes of acute stress often associated with patterns of worry and overcommitment.Examples  are  requently  missing  deadlines,  consistently  feeling  overwhelmed  by responsibilities. It may lead to tension headaches, migraines, and hypertension [7]. 4.  Eustress and Distress. Eustress is positive stress that enhances performance and motivation. Distress is negative stress that overwhelms coping abilities and impairs functioning [8]. International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   52 Stressors are the stimuli or events that trigger a stress response. They can be classified into: 1.  Physical Stressors are Environmental factors that cause physical strain on the body for the examples are noise, temperature extremes, physical injuries [9]. 2.  Psychological  Stressors  are  internal  factors,  such  as  thoughts  or  feelings,  that  lead  to  stress.  The examples are fear of failure, negative self-talk, and anxiety about the future [10]. 3.  Social Stressors is stress originating from interpersonal relationships or social situations such as are conflicts with friends or family, social isolation, workplace harassment [11]. 4.  Daily hassles are minor, recurring stressors in everyday life. Such as are traffic jams, losing keys, or dealing with minor workplace issues [12]. Hormones play a pivotal role in regulating the body's response to stress  through the activation of the hypothalamic-pituitary-adrenal  (HPA)  axis  and  the  sympathetic-adrenal-medullary  (SAM)  system.  These systems coordinate the release of key hormones to help the body cope with and adapt to stress. Below are the main hormones involved in the stress response and their effects: 1.  Cortisol (The Primary Stress Hormone). Cortisol is released by the adrenal cortex, is central to the HPA axis and helps the body manage acute and chronic stress.The effects are metabolic regulation is stimulates  gluconeogenesis  in  the  liver  to  increase  blood  glucose  levels,  immune  modulationcis suppresses  pro  inflammatory  cytokines  and  adaptive  immune  responses  to  prevent  excessive inflammation, cardiovascular support is increases blood pressure and cardiac output by enhancing the responsiveness of blood vessels to catecholamines and cognitive enhancement  mproves memory and focus during acute stress. Prolonged cortisol elevation can lead to metabolic syndrome, hypertension, immune suppression, and cognitive decline [13]. 2.  Adrenaline and Noradrenaline (Catecholamines). These hormones, secreted by the adrenal medulla, are  part  of  the  SAM system,  which mediates the  \"fight-or-flight\"  response.  The  effects are  energy mobilization  increases  heart  rate  and  respiration  to  deliver  oxygen  and  glucose  to  muscles, vasoconstriction is redirects blood flow to vital organs (heart, brain, muscles) by constricting blood vessels in less  critical areas.  Enhanced  alertness.  Activates the amygdala  and  prefrontal  cortex for quick  decision-making  and  persistent  elevation  can  cause  cardiovascular  strain  and  contribute  to anxiety disorders [14]. 3.  Corticotropin-Releasing  Hormone  (CRH).  CRH  is  released  by  the  hypothalamus  to  activate  the HPA axis and stimulate the production of adrenocorticotropic hormone (ACTH). The effects are HPA axis  activation.  Facilitates  cortisol  release  from  the  adrenal  glands.  Appetite  Suppression  can modulates hunger during stress by interacting with the hypothalamic feeding centers. Chronic Effects are prolonged CRH activity can lead to dysregulated HPA axis responses and mood disorders. Cortisol (C21H30O5), is a steroid hormone with a molecular weight of 362.46 g/mol. Cortisol is a well- known biomarker of psychological and physiological stress. The level of cortisol plays an important part in regulating blood pressure, carbohydrate metabolism and glucose levels. It also contributes to the homeostasis of  cardiovascular,  renal,  immune,  endocrine  and  skeletal  systems.  Abnormally  increased  levels  of  cortisol interfere  with  blood  amino  acid  and  fatty  acid  levels,  resulting  in  depression  of  the  immune  system  and inflammation. Severely increased levels of cortisol contribute to the development of symptoms of  obesity, bone fragility, and fatigue, while decreased levels of cortisol lead to Addison’s disease manifested by arterial hypotension, weight loss and darkened scars/skinfolds. The most dominating effects of cortisol are indicative of emotional or psychological stress and that is why cortisol is also called the ‘stress hormone [19]. International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   53 Figure 2. Molecular and 3D structure of Cortisol (C21H30O5). In (a) C is for Carbon, H is for Hydrogen and O is for Oxygen molecule. In (b) Black shows Carbon, grey shows Hydrogen and Red shows Oxygen molecule. Normal Cortisol Levels Cortisol levels are typically measured in the blood, saliva, or urine. The levels vary depending on the time of day, as they peak in the early morning and decline throughout the day. 1.  Normal Blood Cortisol Levels [20]: •  Morning (6:00 AM - 8:00 AM): 10-20 µg/dL (275-555 nmol/L) •  Afternoon (4:00 PM - 6:00 PM): 3-10 µg/dL (80-275 nmol/L) •  Morning: 0.15-0.6 µg/dL (4.14-16.56 nmol/L) •  Afternoon: 0.05-0.2 µg/dL (1.38-5.52 nmol/L) •  10-100 µg/day (28-276 nmol/day) Cortisol Levels During Stress During acute or chronic stress, cortisol levels may rise significantly above normal. 1.  Acute Stress. Blood cortisol levels can increase to  20-40 µg/dL (555-1110 nmol/L) during acute stress events [23]. 2.  Chronic Stress. Chronic exposure to stressors can elevate cortisol levels persistently or disrupt the diurnal rhythm, leading to flattened curves (e.g., higher evening levels). Urinary free cortisol levels may exceed 100 µg/day in cases of chronic stress. [24] 3.  Pathological Cortisol Levels. Cushing’s Syndrome: Cortisol >50 µg/dL (1380 nmol/L) and Addison’s Cortisol  levels  are  typically  measured  in  blood,  saliva,  urine,  or  hair  using  various  analytical techniques. These methods vary in sensitivity, specificity, and practicality depending on the research or clinical context. Sample type Table 2. method for identifying cortisollevels. specificity sensitivity Ease of use International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   54 Chronic stress assessment [30] Adrenal disorder diagnosis [31] Cortisol,  the  primary  glucocorticoid  hormone,  is  released  in  response  to  stress  as  part  of  the hypothalamic-pituitary-adrenal (HPA) axis activation. Its increase during stress serves adaptive purposes to help the body cope with and respond to external or internal challenges. Energy Mobilization Immune Modulation Cardiovascular Support Cognitive and Behavioral Adaptation Table 3. The aim of cortisol increase during stress Provides energy to vital organs during stress [32] Prevents overactive immune responses and reduces inflammation [33] Enhances blood pressure and circulation [34] Improves focus, memory, and decision-making during stress [35] Stress Recovery and Termination Self-regulates the stress response through negative feedback mechanisms [36] Cortisol,  often  called  the  \"stress  hormone,\"  plays  a  dual  role  in  stress  regulation.  While  prolonged cortisol elevation is associated with negative effects, short term cortisol release is essential for managing and resolving stress. Cortisol helps the body adapt to stress by regulating various physiological and psychological processes. 1.  Regulation  of  the  Hypothalamic-Pituitary-Adrenal  (HPA)  Axis.  The  HPA  axis  governs  cortisol production. During stress, the hypothalamus signals the pituitary gland to stimulate cortisol release from the adrenal glands. Cortisol, in turn, exerts a negative feedback effect on the HPA axis, reducing the release  of  corticotropin-releasing  hormone  (CRH)  and  adrenocorticotropic  hormone  (ACTH).  This feedback loop prevents excessive cortisol secretion and helps restore homeostasis [37]. 2.  Modulation of Inflammation. Cortisol suppresses the immune response by inhibiting pro-inflammatory cytokines such as IL-6 and TNF-α. This reduces inflammation, which is often elevated during chronic stress.  By  dampening  inflammatory  pathways,  cortisol  alleviates  physiological  stress  and  prevents stress-related damage to tissues [38]. 3.  Energy  Mobilization  and  Recovery.  Cortisol  facilitates  the  mobilization  of  glucose,  fats,  and  amino acids, providing energy to cope with immediate stressors. After the stressor is resolved, cortisol helps in energy restoration, promoting recovery and repair processes [39]. 4.  Regulation of Mood and Emotional Responses. Cortisol interacts with brain regions like the amygdala and  prefrontal  cortex,  modulating  emotional  responses  to  stress.  By  reducing  excessive  emotional reactivity, cortisol contributes to psychological resilience and stress recovery [40]. 5.  Sleep-Wake Regulation. Cortisol levels follow a diurnal rhythm, peaking in the morning and declining at night. This rhythm supports stress recovery by facilitating restorative sleep and preparing the body for daily challenges. Improved sleep, in turn, reduces stress perception and enhances overall resilience [41]. Cortisol, a vital glucocorticoid hormone, plays a crucial role in maintaining homeostasis during stress. However,  abnormal  increases  or  decreases  in  cortisol  levels  can  have  significant  physiological  and psychological effects. The effect of cortisol is shown in Table 4. International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   55 Table 4. Effect of cortisol Mobilized energy, suppressed inflammation, heightened focus Hypoglycemia, hypotension, impaired stress response Long-Term Effects Insulin resistance, hypertension, cognitive decline Fatigue, excessive inflammation, depression Abnormal cortisol levels, whether excessively high or low, can lead to specific diseases and disorders  that  significantly  affect  the  body's  physiological  and  psychological  functions.  Diseases related to abnoemal coertisol levels are shown in Table 5. Table 5. Disease related to abnormal cortisol levels Symptoms Obesity, hypertension, hyperglycemia, depression [44]. Obesity, insulin resistance, dyslipidemia, hypertension [45]. Mood disturbances, cognitive decline, sleep issues[46]. Fatigue, hypotension, hyperpigmentation, weight loss [47]. Similar to Addison's disease without pigmentation or severe electrolyte imbalance [48]. Severe  hypotension,  abdominal  pain,  confusion,  life- threatening shock [49]. Cortisol  is  crucial  in  how  the  body  reacts  to  stress,  serving  as  a  key  element  in  the  hypothalamic- pituitary-adrenal (HPA) axis. When the body detects a threat, the HPA axis is triggered, leading to a rise in cortisol levels. This hormone helps release energy reserves, slows down non-essential functions like digestion and  immune  activity,  and primes  the  body  for  quick action,  often  known  as  the  \"fight  or  flight\"  response. Cortisol  is  typically  elevated  during  stressful  situations,  aiding  the  body  in  dealing  with  short-term  stress. However, when stress becomes chronic or long-lasting, it can disrupt cortisol production, potentially leading to negative health effects such as immune suppression, memory issues, and an increased risk of conditions like heart  disease  and  depression.  The  body’s  cortisol  levels  fluctuate,  rising  sharply  during  acute  stress  and gradually decreasing once the stressor is gone or resolved. While normal cortisol responses are beneficial and adaptive,  prolonged  or  excessive  cortisol  exposure  due  to  ongoing  stress  can  be  harmful,  highlighting  the importance of managing stress for overall well-being. Recommendation Based on the results of this study to better manage stress and its impact on cortisol levels, individuals should adopt stress reduction techniques such as mindfulness, regular physical activity, and adequate sleep. Psychological  interventions,  like  cognitive-behavioral  therapy,  can  help  reduce  chronic  stress  and  regulate cortisol  production.  Additionally,  healthcare  professionals  should  consider  monitoring  cortisol  levels  in patients with chronic stress, as early intervention may help prevent long-term health issues. Further research is also needed to explore the most effective strategies for cortisol regulation in stress-related conditions. Acknowledgements The authors wish to thank all to Prof. Dr. Melva Silitonga and my friend that have supported the work International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   56 Conflict of Interest The authors declare that  there is no conflict of interest regarding the publication of this paper. All research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Ulrich-Lai,  Y.  M.,  &  Herman,  J.  P.  (2009).  Neural  regulation  of  endocrine  and  autonomic  stress responses. Nature reviews. Neuroscience, 10(6), 397–409. https://doi.org/10.1038/nrn2647 Sapolsky,  R.  M.,  Romero,  L.  M.,  &  Munck,  A.  U.  (2000).  How  do  glucocorticoids  influence  stress responses?  Integrating  permissive,  suppressive,  stimulatory,  and  preparative  actions. Endocrine reviews, 21(1), 55–89. https://doi.org/10.1210/edrv.21.1.0389 Chrousos G. P. (2009). Stress and disorders of the stress system. Nature reviews. Endocrinology, 5(7), 374–381. https://doi.org/10.1038/nrendo.2009.106 [4]  Lazarus, R. S., & Folkman, S. (1984). Stress, Appraisal, and Coping. Springer Publishing. [5]  McEwen, B. S. (2021). \"Acute Stress Responses in Humans.\" Nature Reviews Neuroscience, 22(2), 120- 135. DOI: 10.1038/s41583-020-00415-4 Sapolsky, R. M. (2020). \"The Impact of Chronic Stress on Health.\" Annual Review of Psychology, 71, 621-642. DOI: 10.1146/annurev-psych-122118-101544 [7]  American Psychological Association (2022). \"Stress and Health: Episodic Acute Stress.\"  APA Stress [8]  Goyal,  K.,  &  Sharma,  A.  (2022).  \"Eustress  and  Distress:  Impacts  on  Performance.\"  Psychological [9]  Cohen, S., Janicki-Deverts, D., & Miller, G. E. (2021). \"Physical Stressors and the HPA Axis.\" Journal of Environmental Psychology, 75, 101645. DOI: 10.1016/j.jenvp.2020.101645 [10]  Folkman, S. (2021). \"Psychological Stressors and Coping Mechanisms.\" Annual Review of Psychology, [11]  Taylor, S. E. (2020). \"Social Stress and Its Impact on Health.\" Health Psychology, 39(5), 345-356. DOI: [12]  Lazarus,  R.  S.,  &  DeLongis,  A.  (2021).  \"Daily  Hassles  as  Predictors  of  Chronic  Stress.\"  Journal  of [13]  Sapolsky, R. M. (2020). \"Cortisol’s Role in Acute and Chronic Stress Responses.\" Annual Review of [14]  McEwen, B. S., & Morrison, J. H. (2022). \"Catecholamines in Stress and Adaptive Responses.\" Nature [15]  Herman, J. P., et al. (2021). \"CRH and the HPA Axis in Stress Regulation.\" Frontiers in Neuroscience, [16]  Carter,  C.  S.,  &  Porges,  S.  W.  (2020).  \"Oxytocin  and  the  Biopsychosocial  Model  of  Stress.\" [17]  Freeman,  M.  E.,  et  al.  (2021).  \"Prolactin  in  Stress  and  Immune  Responses.\"  Frontiers  in [18]  Bahn,  R.  S.  (2022).  \"Stress  and  Thyroid  Hormone  Dysregulation.\"  Thyroid,  32(7),  789-795.  DOI: [19]  Iqbal, T., Elahi, A., Wijns, W., & Shahzad, A. (2023). Cortisol detection methods for stress  monitoring in connected health. Health Sciences Review, 6, 100079. https://doi.org/10.1016/j.hsr.2023.100079 [20]  Funder, J. W., et al. (2020). \"The Physiology of Cortisol Secretion.\" Journal of Endocrinology, 245(1), [21]  Kirschbaum, C., & Hellhammer, D. H. (2021). \"Measuring Salivary Cortisol for Stress Assessment.\" [22]  Nicolaides, N. C., et al. (2022). \"Cortisol in Urine and Stress Response.\"  Endocrine Reviews, 43(4), [23]  Kudielka,  B.  M.,  &  Wüst,  S.  (2020).  \"Acute  Stress-Induced  Cortisol  Responses.\"  Trends  in Endocrinology & Metabolism, 31(7), 634-645. DOI: 10.1016/j.tem.2020.05.001 International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   57 [24]  McEwen,  B.  S.,  &  Sapolsky,  R.  M.  (2021).  \"Chronic  Stress,  HPA  Axis  Dysregulation,  and  Health Outcomes.\"  Annual  Review  of  Neuroscience,  44,  267-290.  DOI:  10.1146/annurev-neuro-102020- [25]  Nieman, L. K., et al. (2022). \"Disorders of Cortisol Secretion.\" The Lancet Diabetes & Endocrinology, [26]  Kirschbaum, C., & Hellhammer, D. H. (2021). \"Salivary Cortisol as a Biomarker for Stress Research.\" [27]  Bäck, S. E., et al. (2022). \"The Historical and Modern Use of Radioimmunoassay in Endocrinology.\" Trends in Endocrinology & Metabolism, 33(5), 383-391. DOI: 10.1016/j.tem.2021.12.009 [28]  Taylor,  R.  L.,  et  al.  (2021).  \"LC-MS/MS  for  Cortisol  Measurement:  A  Gold  Standard  Approach.\" Journal of Chromatography B, 1185, 123456. DOI: 10.1016/j.jchromb.2021.123456 [29]  Hellhammer, J., et al. (2020). \"The Role of Salivary Cortisol in Psychophysiological Stress Research.\" [30]  Meyer, J., et al. (2021). \"Hair Cortisol: A Biomarker of Chronic Stress?\" Psychoneuroendocrinology, [31]  Nieman, L. K. (2022). \"Urinary Free Cortisol Testing in Endocrine Disorders.\" The Lancet Diabetes & [32]  Sapolsky,  R.  M.  (2020).  \"Cortisol  and  Energy  Regulation  During  Acute  Stress.\"  Annual  Review  of [33]  Miller,  G.  E.,  &  Cohen,  S.  (2020).  \"Cortisol's  Role  in  Modulating  Inflammation  During  Stress.\" [34]  Kudielka, B. M., & Wüst, S. (2020). \"Acute Stress and Cortisol's Cardiovascular Effects.\" Trends in Endocrinology & Metabolism, 31(7), 634-645. DOI: 10.1016/j.tem.2020.05.001 [35]  McEwen,  B.  S.  (2022).  \"Cortisol's  Cognitive  and  Behavioral  Roles  in  Stress  Adaptation.\"  Nature [36]  Herman, J. P., et al. (2021). \"Negative Feedback of the HPA Axis in Stress Regulation.\" Frontiers in [37]  Herman, J. P., et al. (2021). \"Feedback Regulation of the HPA Axis in Stress Resilience.\" Frontiers in [38]  Miller,  G.  E.,  &  Cohen,  S.  (2020).  \"Cortisol  and  Inflammatory  Processes  in  Stress  Regulation.\" [39]  Sapolsky, R. M. (2020). \"The Adaptive Role of Cortisol in Energy Regulation During Stress.\" Annual Review of Physiology, 82, 639-661. DOI: 10.1146/annurev-physiol-020518-114406 [40]  McEwen, B. S., & Morrison, J. H. (2022). \"Cortisol and Brain Plasticity in Stress Management.\" Nature [41]  Nicolaides,  N.  C.,  et  al.  (2021).  \"Cortisol  Rhythms  and  Their  Role  in  Sleep  and  Stress  Recovery.\" [42]  Chrousos,  G.  P.  (2020).  \"Stress  Management  Interventions  and  Cortisol  Regulation.\"  Journal  of Psychotherapy and Psychosomatics, 89(5), 261-273. DOI: 10.1159/000509643 [43]  Pariante,  C.  M.,  et  al.  (2021).  \"Dietary  Interventions  and  Stress  Hormone  Regulation.\"  Nutritional [44]  Nieman,  L.  K.,  et  al.  (2022).  \"Cushing's  Syndrome:  Pathophysiology  and  Diagnosis.\"  The  Lancet Diabetes & Endocrinology, 10(4), 301-314. DOI: 10.1016/S2213-8587(21)00373-7 [45]  Boden, G. (2021). \"Chronic Cortisol and Metabolic Syndrome.\" Endocrine Reviews, 42(3), 307-320. [46]  McEwen, B. S. (2022). \"Cortisol and Psychiatric Disorders.\" Nature Reviews Neuroscience, 23(4), 220- [47]  Arlt, W., et al. (2021). \"Primary Adrenal Insufficiency: Causes and Consequences.\" Endocrine Reviews, [48]  Nicolaides, N. C., et al. (2021). \"Adrenal Crisis and Cortisol Deficiency.\" Endocrine Reviews, 42(4), [49]  Iqbal, T., Elahi, A., Wijns, W., & Shahzad, A. (2023). Cortisol detection methods for stress monitoring in connected health. Health Sciences Review, 6, 100079. https://doi.org/10.1016/j.hsr.2023.100079 [50]  James, K. A., Stromin, J. I., Steenkamp, N., & Combrinck, M. I. (2023). Understanding the relationships between physiological and psychosocial stress, cortisol and cognition. Frontiers in Endocrinology, 14. https://doi.org/10.3389/fendo.2023.1085950 International Journal of Ecophysiology Vol.07, No.01 (2025) 48-58                                   58 [51]  Zefferino,  R.,  Di  Gioia,  S.,  &  Conese,  M.  (2021).  Molecular  links  between  endocrine,  nervous  and e01960. stress. behavior, chronic system during [52]  Knezevic, E., Nenic, K., Milanovic, V., & Knezevic, N. N. (2023). The Role of Cortisol in Chronic Stress,  Neurodegenerative  Diseases,  and  Psychological  Disorders.  Cells,  12(23),  2726. https://doi.org/10.3390/cells12232726",
         "https://talenta.usu.ac.id/ijoep/article/download/19118/8494",
         "extracted",
         "None",
         "",
         "The Role of cortisol in the stress response"
        ],
        [
         "12",
         "0053ae5c37112efe02b3a9990bfd51510a567637",
         "None",
         "Jun Ma,Yanfeng Yue,Yuanhao Ren,Liu Cao,Haishan Wang,Yan Chen,Wenqi Zhuo,Zhou Wang,Tingting Dang,Xueyi Wang,Pan Chen,Xingrong Hou,Hai Huang,Keji Jiang,Tingting Lin",
         "\n**BLOCK**fs== 16.0**p== 0.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nGenetic Diversity Analysis of Wild Population Based on SNP Developed from\nTranscriptome Sequencing of Spot-Fin Porcupine Fish (Diodon hystrix)\n**BLOCK**fs== 8.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.2**l== 0.0**r== 0.9**\nshoujia jiang\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nSun Yat-Sen University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.0**r== 0.9**\nliu cao\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.0**r== 0.9**\nhaihsan wang\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.0**r== 0.9**\nwenqi zhuo\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\nzhou wang\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\ntingting dang\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\nxueyi wang\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.0**r== 0.9**\npan chen\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.0**r== 0.9**\nxingrong hou\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nHainan Tropical Ocean University\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.0**r== 0.9**\nxinxin you\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nBGI-Shenzhen: BGI Group\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.0**r== 0.7**\nhai huang  (  huanghai74@126.com )\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nHainan Tropical Ocean University  https://orcid.org/0000-0001-9841-1147\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nResearch Article\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.5**\nKeywords: Spot-\u0000n porcupine \u0000sh, Diodon hystrix, SNPs, RNA-Seq Diversity\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.8**\nPosted Date: May 18th, 2022\n**BLOCK**fs== 8.0**p== 0.0**b== 0.3**t== 0.7**l== 0.0**r== 0.7**\nDOI: https://doi.org/10.21203/rs.3.rs-352287/v1\n**BLOCK**fs== 8.0**p== 0.0**b== 0.3**t== 0.7**l== 0.0**r== 0.2**\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.   Read Full License\n**BLOCK**fs== 8.0**p== 1.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nDiodon hystrix is widely distributed in the tropical and subtropical ocean. Due to delicious taste and unique body shape, the catch of this \u0000sh in the South\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nChina Sea has been increasing year by year. It is urgent to evaluate the population status of D. hystrix in the South China Sea. Molecular markers are often\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nused to evaluate the population status, but it has been a lack of relevant molecular markers for D. hystrix. In this study, we utilized the Illumina sequencing\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nplatform to generate transcriptome data to identify SNPs in D. hystrix muscle tissue. A total of 7.2 Mb clean reads with 94.92% Q20 bases were obtained, and\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\n4,179 putative SNPs distributed among 22,618 genes were identi\u0000ed and con\u0000rmed. Randomly selected SNPs were validated, and 19 true SNPs (39.58%) were\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nscreened. We used these true SNP loci to verify the genetic diversity and population structure of a wild population of D. hystrix. The results showed that 18\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nSNP loci were polymorphic. The average PIC, Ne, Ho and He were 0.3354, 1.7893, 0.4963 and 0.4391, respectively. 14 SNP loci were consistent with Hardy-\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nWeinberg equilibrium (HWE), which revealed that the population was in a genetically stable state. The haplotype network concluded that the population may\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nbe composed of two different clades. In conclusion, the transcriptomic sequencing can quickly obtain the SNP loci as molecular markers which can be used\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nfor population genetic diversity and population structure analysis. It provides necessary help for the conservation biology and resource evaluation of D. hystrix.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.3**l== 0.0**r== 0.8**\nIntroduction\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nDiodon hystrix, the spot-\u0000n porcupine \u0000sh, is a member of the Diodontidae family and is widely distributed in tropical and subtropical marine environments\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\n(Leis JM, 2006). D. hystrix has the same easily recognizable biological characteristics as puffer\u0000sh (Takifugu sp., Tetraodontidae family), such as an in\u0000ated\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nbody and spiny skin. Some countries and regions catch the porcupine \u0000sh for making dry crafts to sell to tourists, or showing in private and public aquariums.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nAlthough some reports indicate that porcupine \u0000sh are toxic, its meat is eaten by people living along the coast of the South China Sea. Until now, D. hystrix has\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nbeen listed as a species of least concern (LC) in the red list of threaded animals (IUCN 2015), but in fact, the biomass of this \u0000sh in the South China Sea has\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nbeen rapidly decreasing.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nRecently, signi\u0000cant technical advancements have provided innovative molecular genetic tools for studying aquaculture species (Hauser L, 2008; Milano I,\n2011). Single nucleotide polymorphisms (SNPs) are widely used in genetic diversity research, genetic linkage map construction, quantitative trait loci (QTL)\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nmapping, genome-wide association study (GWAS), and genomic selection (GS) because of their abundance and stability in genomes and transcriptomes (You\nX, 2020). Generally, when considering the marker density and genome coverage of SNP markers, the distribution of SNPs among unigenes is crucial, especially\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nwhen they are used for genetic mapping. Meanwhile, large sets of SNPs have also been reported in some aquaculture species, such as in the genus\nAustrolebias (García G, 2019), and the species Litopenaeus vannamei (Lu X, 2018), Hyriopsis cumingii (Zhang A, 2016), the Eastern oyster (Quilang J, 2007),\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nCtenopharyngodon idella (Liao Z, 2017), and Acipenser schrenckii (Li S, 2018) and some Takifugu species (Cui J, 2014; Jin W, 2015). These reported SNPs are\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nmainly centered on economic traits, including tolerance to various environmental stressors, disease resistance, sexual determination, and growth rate (Xiao S,\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.5**l== 0.0**r== 0.4**\n2015; Yu H, 2016; Wang X, 2019). Nevertheless, the SNPs of D. hystrix has not yet been reported.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.4**t== 0.5**l== 0.0**r== 0.1**\nThe large-scale discovery of molecular markers of D. hystrix is the basic work for reserving germplasm resources, constructing genetic analysis, and\n**BLOCK**fs== 8.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\ndeveloping molecular genetic breeding technology. In view the conservation status and the intention of improving the breeding of this species, we describe a\n**BLOCK**fs== 8.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nlarge set of SNPs obtained by the transcriptome sequencing of D. hystrix in this study. These SNPs should re\u0000ect information concerning economically\n**BLOCK**fs== 8.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.6**\nrelevant traits for future molecular-assisted breeding.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.7**\nMaterials And Methods\n**BLOCK**fs== 14.0**p== 1.0**b== 0.3**t== 0.6**l== 0.0**r== 0.6**\nSample collection and RNA isolation\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nThe spot-\u0000n porcupine \u0000sh (length 20 cm) was captured from the South China Sea in Sanya, Hainan province, China. Later, the muscle tissues were collected,\nfrozen in liquid nitrogen, and then stored at -80˚C before RNA isolation. Total RNA was extracted from muscle tissues using the TRIzol reagent (Simms D,\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\n1993) and further puri\u0000ed using the RNeasy Mini kit according to the manufacturer’s protocol (Beltrame C, 2015). The quantity and quality of total RNA were\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nmeasured and recorded using an Agilent 2100 Bioanalyzer (Panaro NJ, 2000). All treatment procedures for \u0000sh during this study were conducted in\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.7**l== 0.0**r== 0.1**\naccordance with the guidelines of the Animal Ethics Committee and were approved by the review committee of BGI bioethics and biosafety.\nTranscriptome Sequencing and Reads Collection\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nUsing the criteria of paired-end 150 bp reads, the transcriptome libraries were sequenced on an Illumina HiSeqTM 2000 platform (San Diego, CA, USA). To\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\nbetter assemble the whole transcriptome de novo, a paired end (PE) sequencing strategy was used. Subsequently, the clean reads from D. hystrix\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\ntranscriptome were de novo assembled using Trinity package and the assembled sequence from the transcriptome data was used as reference in this study.\nFirstly, the obtained raw reads from D. hystrix were treated using SOAPdenovo (https://github.com/BGI-\u0000exlab/SOAP) to remove the junk reads with adapters,\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nreads with more than 5% unknown nucleotides, and low-quality scores (Q20). The clean reads were then de novo assembled into contigs and unigenes using\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nthe Trinity package, with the parameters set to “min_contig_length 150 --min_kmer_cov 3 --min_glue 3 --b\u0000y_opts '-V 5 --edge-thr = 0.1 –stderr”. Then, the clean\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.1**\nsequences were then mapped back to contigs. Ultimately, we obtained unigenes (more than 150 nucleotides), which were clustered using TGICL (default\nparameters) (Pertea G, 2003) to reduce redundancy.\nSNP Detection\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nPotential SNP variations were predicted by combining two tools, BWA for mapping and GATK for variant calling. Short reads of the D. hystrix transcriptome\nwas mapped to the reference using BWA version 0.5.9 (http://bio-bwa.sourceforge.net/) by the default settings except for no gap tolerance. There are many\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\navailable calling software programs, GATK and SAMtools are currently the most popular SNP discovery tools. In this study, raw vcf \u0000les were \u0000ltered using\n**BLOCK**fs== 8.0**p== 1.0**b== 0.0**t== 1.0**l== 0.0**r== 0.1**\nGATK version 3.4 with the parameter settings “stand_call_conf 20.0 -stand_emit_conf 20.0 -window 35 -cluster 3 -FS > 30.0 QD < 5.0” except for no gap\n**BLOCK**fs== 8.0**p== 2.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\ntolerance (De Summa S, 2017). The high-quality SNPs were required to meet the requirements of quality score greater than 20 and read depth measured over\n10. Since the prediction accuracy of SNPs depends on sequence coverage, both SNPs and indels were considered to be true polymorphisms, when each allele\n**BLOCK**fs== 14.0**p== 2.0**b== 0.8**t== 0.1**l== 0.0**r== 0.4**\nwas observed at least three times.\nAnalysis of genetic diversity and population structure\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nTo validate the SNPs from RNA-Seq, we used the software Primer 3 (http://primer3.ut.ee/) to design a number of primers which could amplify the \u0000anking\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nsequence of randomly selected SNP loci. The genome DNA of D. hystrix was used to detect these SNP loci, and the positive PCR was as basis for preliminary\nscreening of SNP loci. A true SNP locus usually has nucleotide transversion or transition. So, a wild group of D. hystrix (30 individuals) was used as templates\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.0**r== 0.2**\nfor validating these screened SNP loci. The positive PCR products on these screened SNP loci were sequenced by BGI-Guangzhou.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nIn sequencing peak map, the homozygous SNP loci are single peaks, whereas heterozygous SNP loci are double peaks. Homozygotes were recorded as AA\nand BB respectively, and heterozygotes were recorded as AB. The effective number of alleles (Ne), expected heterozygosity (He), observed heterozygosity (Ho),\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nand minimum allele frequency (MAF) were analyzed by Arlequin (version 3.5.2.2) software (Exco\u0000er L, 2010). In addition, the Arlequin software was also used\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nto analyze the linkage disequilibrium among different SNP loci. The PIC_CALC (version 0.6, https://github.com/luansheng/PIC_CALC) was used to calculate\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nthe polymorphism information content (PIC) of SNPs. The Genepop (version 4.5.1) (François Rousset, 2008) was used to test the Hardy-Weinberg equilibrium\n(HWE).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nThe genotypes of different SNP loci of each individual were used to compose the SNP feature sequences. These SNP feature sequences were used to\n**BLOCK**fs== 8.0**p== 2.0**b== 0.6**t== 0.4**l== 0.0**r== 0.2**\nconstruct the haplotype networkby DNASP (version 6) and NETWORK (version 10.2) (Rozas J, 2017; Tobias Polzin, 2003).\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\nResults\n**BLOCK**fs== 14.0**p== 2.0**b== 0.6**t== 0.4**l== 0.0**r== 0.4**\nTranscriptome sequencing and de novo assembly\n**BLOCK**fs== 8.0**p== 2.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nA total of 7.74 Mb paired-end raw reads were generated from the D. hystrix muscle. Raw reads of separated individuals were deposited in the ENA (European\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nNucleotide Archive) public database (Accession: PRJEB47595). After removing the adapter sequences and low-complexity reads, a total of 7.2 Mb of clean\nreads was obtained. The Q20 and Q30 values were 94.9% and 88.7%, respectively (Table 1). The GC percentage of the transcriptome was 47.0%. The high-\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nquality reads were then assembled into 29,272 contigs from the short reads. These redundant contigs were further clustered into 22,618 unigenes with the N50\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.0**r== 0.4**\nsize of 975 bp (Table 2). The length distributions of these assembled unigenes are shown in Fig. 1.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\nTable 1\nThe information of RNA-Seq reads\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.5**l== 0.3**r== 0.6**\nInsert Size (bp)\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.5**l== 0.4**r== 0.5**\nTotal Reads (Mb)\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.5**l== 0.5**r== 0.4**\nTotal Bases (Gb)\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nRaw data\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nClean data\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.6**l== 0.4**r== 0.4**\nTable 2\nThe information of assembled unigenes\n**BLOCK**fs== 8.0**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nTotal Number\n**BLOCK**fs== 8.0**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nTotal Length (bp) Mean Length (bp)\n**BLOCK**fs== 14.0**p== 2.0**b== 0.3**t== 0.7**l== 0.0**r== 0.8**\nSNP Detection\n**BLOCK**fs== 8.0**p== 2.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nThe alignment \u0000le was used for SNP detection by using GATK. To obtain more reliable SNPs, high-quality SNPs were de\u0000ned as those with a quality score over\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\n20 and a read depth over 10. As predicted from the muscle transcriptome, there are 4,179 high-quality SNPs. Among the detected SNPs, the transition sites are\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\n2856 (68.34%), while the transversion sites are 1323 (31.66%). The ratio of transition to transversion is 2.16. In these transition sites, the highest proportions\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nare G/A (752, 17.99%) and C/T (737, 17.64%). In these transversion sites, the highest proportions are A/C (185, 4.43%) and C/A (181, 4.33%), while the C/G\n(145, 3.47%) is the lowest proportion (Table 3). SNP distribution among unigenes signi\u0000cantly matters in the consideration of the marker density and genome\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\ncoverage with the usage of SNP markers, especially when SNPs are used for linkage map construction. In this study, we found that all the SNPs were\ndistributed in 2,270 unigenes (10.04% of the total number of unigenes). The unigenes with a single SNP were common (occupied 34.0% of all SNPs), and\n**BLOCK**fs== 8.0**p== 2.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nthose with no more than 10 SNPs occupied 95.14% of all SNPs. A total of 19 unigenes containing over 10 SNPs were observed. The detailed SNP distribution\namong those unigenes is indicated in Fig. 2.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.9**t== 0.1**l== 0.2**r== 0.8**\nSNP type\n**BLOCK**fs== 8.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.7**\nTransition\n**BLOCK**fs== 8.0**p== 3.0**b== 0.9**t== 0.1**l== 0.5**r== 0.4**\nTransversion\n**BLOCK**fs== 8.0**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nNumber\n**BLOCK**fs== 8.0**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nPercentage%\n**BLOCK**fs== 14.0**p== 3.0**b== 0.7**t== 0.2**l== 0.0**r== 0.8**\nSNP screening\n**BLOCK**fs== 8.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nAs the SNPs reported in the present study were identi\u0000ed through RNA-Seq analysis, the SNPs needed further validation. A total of 103 SNP loci were randomly\nselected from 4,179 predicted SNPs, and the primers were obtained under the default stringency conditions of the Primer3 software. By optimizing the PCR\nreaction conditions, 48 pairs of primers could amplify the target sequences. Within these ampli\u0000ed sequences, 19 SNP loci (682, 698, 1569, 5491, 5649, 5921,\n**BLOCK**fs== 8.0**p== 3.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\n7808, 10659, 12102, 12374, 12683, 14194, 14788, 15840, 18877, 19192, CL351, CL439, and CL552) were effectively screened (these primers were listed in the\nTable S1). The estimated prediction accuracy of SNPs reached 39.58%.\nPolymorphism analysis of SNP\n**BLOCK**fs== 8.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nThe genomic DNA from 30 wild individuals of D. hystrix was detected by these primers of 19 SNP loci. The results showed that one locus (5649) contained\n**BLOCK**fs== 8.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nthree alleles (A, T, and G) in each sample did not conform to the feature of diploid, and the remaining 18 SNP loci contained two alleles (see Table 4). Expected\nheterozygosity (He) is often used to measure the genetic diversity of populations. In this wild population, average observed heterozygosity (Ho) was 0.4963,\nand average expected heterozygosity (He) was 0.4391; Minor allele frequency (MAF) is actually the second most frequent allele in the population, which is\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nmainly used to distinguish whether an allele is a common polymorphism or a rare variation. The distribution range of MAF of 18 SNP loci was 0.1167-0.5000,\nwhich was greater than 0.05, indicating that these loci belong to common polymorphisms. Polymorphism information content (PIC) is used to indicate the\ndegree of polymorphism at a certain locus in a population. The average PIC of this wild population was 0.3354, one locus (12102) belonged to low\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\npolymorphism (PIC < 0.25), and others belonged to moderate polymorphism (0.25 < PIC < 0.5). Hardy-Weinberg equilibrium test showed that 4 loci (5921,\n15840, 18877, and CL351) did not accord with HWE (P < 0.05), and 2 loci (15840 and CL351) seriously did not accord with HWE (P < 0.01). These results of\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.2**\npolymorphism analysis showed that 18 SNP loci (excepted 5649) could be used for the genetic analysis of Diodon hystrix.\nLinkage disequilibrium analysis of SNP\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nLinkage disequilibrium (LD) is used to evaluate the phenomenon that the alleles at different loci appearing on the same chromosome is frequently higher than\nthat of random association. In this study, it was found that locus 12102 was linked to 12374, 14194 and 15840, respectively (p < 0.05), locus 12102 and\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\n14194 were signi\u0000cant linkage (p = 0.0059); SNP locus 5921 was linked to 15840 and CL351, respectively (P < 0.05); In addition, there was a very signi\u0000cant\nlinkage between locus 15840 and CL351 (p = 0.0000, see Table 5).\nSNP for population genetic structure analysis\n**BLOCK**fs== 8.0**p== 3.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nThe loci deviating from HWE are not suitable to investigate the genetic stability of the population. Therefore, we recombined the SNP feature sequences by\nusing the genotypes of 14 SNP loci conforming to HWE. 30 individuals were formed 30 haplotypes. Haplotype network analysis divided these 30 haplotypes\n**BLOCK**fs== 8.0**p== 3.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\ninto two clades. One small clade contained 8 haplotypes (m15, m19, m21, m23-025, m28 and m29), and the other big clade contained 22 haplotypes (m1-14,\nm16-18, m20, m22, m26-27 and m30). The big clade included four small branches, which respectively composed by 6 (m2, m6, m10, m13, m16 and m20), 5\n**BLOCK**fs== 8.0**p== 3.0**b== 0.3**t== 0.7**l== 0.0**r== 0.3**\n(m3, m7, m11, m12 and m18), 6 (m1, m5, m8, m17, m27 and m30), 3 (m4, m14 and m26) haplotypes (Fig. 4).\n**BLOCK**fs== 8.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.8**\nUnigene ID\n**BLOCK**fs== 8.0**p== 4.0**b== 0.9**t== 0.1**l== 0.5**r== 0.5**\nFrequency\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUnigene682_Control_1_74\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUnigene698_Control_1_613\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUnigene1569_Control_1_272\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUnigene5491_Control_1_445\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUnigene5649_Control_1_411\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUnigene5921_Control_1_120\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUnigene7808_Control_1_197\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUnigene10659_Control_1_2585\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUnigene12102_Control_1_559\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUnigene12374_Control_1_331\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nUnigene12683_Control_1_275\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nUnigene14194_Control_1_317\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nUnigene14788_Control_1_551\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nUnigene15840_Control_1_289\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nUnigene18877_Control_1_246\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nUnigene19192_Control_1_347\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nCL351.Contig1_Control_1_802\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nCL439.Contig1_Control_1_588\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nCL552.Contig2_Control_1_560\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\nAverage\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nTransition frequency\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nTransversion frequency\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nTheta_S\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nSubstitution frequency\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\ns.d. Theta_S\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nIndel frequency\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\na: The SNP locus predicted from transcriptome is complementary with the validation results from genomic\n**BLOCK**fs== 8.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nb: Abnormal SNP locus\n**BLOCK**fs== 8.0**p== 5.0**b== 0.9**t== 0.1**l== 0.4**r== 0.3**\nTable 5\nThe linkage disequilibrium analysis of SNP loci\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nThe signi\u0000cance level of linkage disequilibrium is 0.05\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.5**l== 0.0**r== 0.9**\nDiscussion\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nIn terms of novel species, NGS technology is a powerful tool for examining their genetic blueprint. Whole-genome sequencing (WGS) and RNA-Seq can be\nused to study individual differences, gene function, and evolutionary history (Werner T, 2010; Martin JA, 2011). However, WGS is more costly in terms of\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nexpense and computing resources than RNA-Seq, and it cannot directly obtain the comprehensive information included in transcriptomes through functional\nprediction (Chou C-H, 2018). A more effective strategy is to use RNA-seq \u0000rst to clarify the molecular bases of biological functions. Owing to the economic\nimportance of many aquatic species, it is necessary to establish a complete transcriptome resource database, and this can be done despite the lack of\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\ngenomes for non-model species. In addition, RNA-Seq is also an e\u0000cient and cost-effective method to comprehensively identify SNPs from transcribed\nregions in the genomes of aquaculture species. In this study, the transcriptome was generated using the Illumina HiSeq platform to identify SNPs in D. hystrix.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nA total of 4,179 putative SNPs distributed among 2,270 unigenes were identi\u0000ed. Among these, the number of transition SNP loci (A/G and C/T) was\nsigni\u0000cantly greater than that of transversion SNP loci (A/T, A/C, G/T, and C/G; Table 3), which is similar to the \u0000ndings of other studies such as in Acipenser\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nschrenckii (Li S, 2018), Litopenaeus vannamei (Lu X, 2018), and Piaractus mesopotamicus (Mastrochirico-Filho VA, 2016). These large sets of SNPs were\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nobtained from the D. hystrix transcriptome sequencing, and then 19 available SNP loci were screened from 48 ampli\u0000ed loci, and the predicted accuracy of\nSNP loci was 39.58%. It indicated that tissue-speci\u0000c transcriptome sequencing was one of the important ways to e\u0000ciently screen available SNP loci.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nPolymorphism is the genetic diversity among different populations within a species or among different individuals within a population. It is the foundation for\nmaintaining the evolution of species, and is also closely related to the formation, disappearance and development of biodiversity. In this study, we used 18\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\navailable SNP loci (excluding 5649 locus) to analyze the polymorphism of wild population of D. hystrix. Expected heterozygosity (He) indicated the genetic\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\ndiversity of this population was at a moderately low level, which may be caused by the inhomogeneous distribution of individual loci (such as 12102 and\nCL552) in the population. In addition, the average PIC of 18 SNP loci was generally low, which was consistent with the result of He. Remarkably, SNP locus\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\n(5649) often appeared the triploid in population (each individual contained three alleles, such as A, T, or G). We have not eliminated this phenomenon by\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nimproving experimental methods, eliminating sample pollution and improving primer speci\u0000city. Therefore, we speculate that there are two possibilities on this\nlocus: (1) the gene of this locus is a multi-copy gene in this species; (2) the chromosome of this species has a doubling phenomenon in the evolution. These\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.9**l== 0.0**r== 0.7**\ninferences need to be veri\u0000ed in the future.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nIn a stable population, the frequency of alleles and genes are balanced in generation heredity. The results of HWE showed that four loci (5921, 15840, 18877\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nand CL351) signi\u0000cantly deviated from the balance, while other loci (except 5649) were well to comply with Mendel's law of inheritance. It indicated that the\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\npopulation of D. hystrix in the South China Sea was still in a relatively stable state under high \u0000shing intensity. Interestingly, the other three loci (5921, 15840\nand CL351) deviated from HWE have linkage disequilibrium. These linkage disequilibrium loci lead to a serious difference between the actual frequency and\n**BLOCK**fs== 8.0**p== 6.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nexpected frequency of two genes at different loci, which indicated that the genes corresponding to these loci may be located on the same chromosome or\nclose to each other. This suggested that we should be more attention to the effect of linkage disequilibrium genes on HWE in the population diversity analysis.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nWe also analyzed the population structure of this wild population of D. hystrixHaplotype analysis divided this wild population into 30 haplotypes, which may\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\nbe attributed to too many SNP loci or insu\u0000cient number of samples. However, it does not affect the construction of haplotype network for this wild\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\npopulation. Haplotype network analysis revealed that the wild population of D. hystrix in the South China Sea may be composed of two different clades.\nClade1 had more haplotypes and branches, it suggested that the clade1 was higher polymorphism than clade2. Theoretically, these haplotypes in clade1 have\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.0**r== 0.4**\nstronger adaptability, but it still needs to be further veri\u0000ed by increasing the number of samples.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.0**r== 0.9**\nConclusion\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nIn this study, the high-throughput sequencing reads from muscle tissue transcriptomes of D. hystrix were used to detect SNPs. A total of 4,179 high-quality\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nSNPs were predicted. Within 48 ampli\u0000ed SNP loci, about half could be veri\u0000ed. The available SNP loci were used to analyze the genetic diversity and\npopulation structure of the wild population of D. hystrix in the South China Sea. The genetic diversity of the wild population was at moderately low level. The\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nwild population may be composed of two relatively independent clades, and the diversity of one clade was signi\u0000cantly higher than that of the other. It\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nsuggested that the genetic status of the wild population of D. hystrix in the South China Sea was still relatively stable, but its` population resources need to be\nattention to at all times. Overall, the SNPs predicted in this study will play a role in genetic diversity research and molecular-assisted breeding of D. hystrix.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nDeclarations\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\nEthics approval\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nAll applicable international, national, and/or institutional guidelines for the care and use of animals were followed by the authors. The use of animal was\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.0**r== 0.4**\napproved by the Institutional Animal Care and Use Committee of Hainan Tropical Ocean University.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.0**r== 0.7**\nConsent to Publish and Participate\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.0**r== 0.5**\nWritten informed consent for publication was obtained from all participants.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.0**r== 0.9**\nData Availability\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nAll data generated or analyzed during this study are included in this article. The information of SNPs is provided as online supplementary material.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.0**r== 0.8**\nCompeting Interests\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.6**\nThe authors have declared that no competing interests exist.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.8**\nAuthor contribution\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nH.H. and X.Y. contributed study design, J.M., Y.C., P.C., X.H., and L.C. contributed to the sample preparation, W.Z., T.D. and Z.W. contributed the experimental\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nveri\u0000cation; J.M., H.W. and X.W. contributed the genetic analysis; S.J., and X.Y. performed the bioinformatics analysis; S.J., and J.M. wrote the paper. All\nauthors read and approved the \u0000nal manuscript.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.7**l== 0.0**r== 0.9**\nFunding Info\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nThis research was funded by the Key R & D Program Project of Hainan Province (No. ZDYF2018225), Ministry of Agriculture and Rural Affairs Project for\nConservation of Species Resources (No. 17200352).\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.0**r== 0.9**\nReferences\n**BLOCK**fs== 8.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n1. Beltrame C, Côrtes M, Bandeira P. Optimization of the RNeasy Mini Kit to obtain high-quality total RNA from sessile cells of Staphylococcus aureus.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nBrazilian Journal of Medical and Biological Research. 2015, 48(12):1071–1076.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.0**\n2. Chou C-H, Huang H-Y, Huang W-C. The aquatic animals` transcriptome resource for comparative functional analysis. BMC genomics. 2018, 19(2):161–\n**BLOCK**fs== 8.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.0**\n3. Cui J, Wang H, Liu S. Transcriptome analysis of the gill of Takifugu rubripes using Illumina sequencing for discovery of SNPs. Comparative Biochemistry\n**BLOCK**fs== 8.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nand Physiology Part D: Genomics and Proteomics. 2014, 10:44–51.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.0**\n4. De Summa S, Malerba G, Pinto R. GATK hard \u0000ltering: tunable parameters to improve variant calling for next generation sequencing targeted gene panel\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\ndata. BMC bioinformatics. 2017, 18(5):119.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n5. Exco\u0000er L, Lischer H. Arlequin suite ver 3.5: a new series of programs to perform population genetics analyses under Linux and Windows[J]. Molecular\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nEcology Resources, 2010, 10(3):564–567.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n\u0000. François Rousset. genepop’007: a complete re-implementation of the genepop software for Windows and Linux. Molucular ecology resources. 2008, 8(1):\n**BLOCK**fs== 8.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n7. García G, Ríos N, Gutiérrez V. Transcriptome-Based SNP Discovery and Validation in the Hybrid Zone of the Neotropical Annual Fish Genus Austrolebias.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.0**\n\u0000. Hauser L, Carvalho GR. Paradigm shifts in marine \u0000sheries genetics: ugly hypotheses slain by beautiful facts. Fish and Fisheries. 2008, 9(4):333 − 62.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.0**\n9. Jin W, Wen H, Du X. Transcriptome analysis reveals the potential mechanism of the albino skin development in puffer\u0000sh Takifugu obscurus. In Vitro\n**BLOCK**fs== 8.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nCellular & Developmental Biology-Animal. 2015, 51(6):572–577.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\n10. Leis JM. Nomenclature and distribution of the species of the porcupine\u0000sh family Diodontidae (Pisces, Teleostei). Memoirs of Museum Victoria. 2006,\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\n11. Li S, Wang D, Cao Y, et al. Transcriptome pro\u0000le of Amur sturgeon (Acipenser schrenckii) liver provides insights into immune modulation in response to\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nYersinia ruckeri infection. Aquaculture. 2018, 492:137 − 46.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\n12. Liao Z, Wan Q, Shang X, et al. Large-scale SNP screenings identify markers linked with GCRV resistant traits through transcriptomes of individuals and\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\ncell lines in Ctenopharyngodon idella. Scienti\u0000c reports. 2017, 7(1):1–12.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.0**\n13. Lu X, Kong J, Meng X, et al. Identi\u0000cation of SNP markers associated with tolerance to ammonia toxicity by selective genotyping from de novo assembled\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\ntranscriptome in Litopenaeus vannamei. Fish & shell\u0000sh immunology. 2018, 73:158 − 66.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.3**\n14. Martin JA, Wang Z. Next-generation transcriptome assembly. Nature Reviews Genetics. 2011, 12(10):671–682.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n15. Mastrochirico-Filho VA, Hata ME, Sato LS, et al. SNP discovery from liver transcriptome in the \u0000sh Piaractus mesopotamicus. Conservation genetics\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nresources. 2016, 8(2):109–114.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n1\u0000. Milano I, Babbucci M, Panitz F, et al. Novel tools for conservation genomics: comparing two high-throughput approaches for SNP discovery in the\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\ntranscriptome of the European hake. PLoS One. 2011, 6(11):e28008.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n17. Panaro NJ, Yuen PKi, Sakazume T, et al. Evaluation of DNA fragment sizing and quanti\u0000cation by the agilent 2100 bioanalyzer. Clinical chemistry. 2000,\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n1\u0000. Pertea G, Huang X, Liang F, et al. TIGR Gene Indices clustering tools (TGICL): a software system for fast clustering of large EST datasets. Bioinformatics.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n19. Quilang J, Wang S, Li P, et al. Generation and analysis of ESTs from the eastern oyster, Crassostrea virginica Gmelin and identi\u0000cation of microsatellite\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nand SNP markers. BMC genomics. 2007, 8(1):157.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n20. Rozas J, Ferrer-Mata A, Sánchez-DelBarrio JC, et al. DnaSP 6: DNA Sequence Polymorphism Analysis of Large Datasets. Mol. Biol. Evol.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n21. Simms D, Cizdziel PE, Chomczynski P. TRIzol: A new reagent for optimal single-step isolation of RNA. Focus. 1993, 15(4):532–535.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n22. Tobias Polzin, Siavash Vahdati Daneshmand. On Steiner trees and minimum spanning trees in hypergraphs, Operations Research Letters, 2003,\n**BLOCK**fs== 8.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\n23. Wang X, Jiang S, Zheng L, et al. An SNP-Based Genetic Map and QTL Mapping for Growth Traits in the Red-Spotted Grouper (Epinephelus akaara). Genes.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\n24. Werner T. Next generation sequencing in functional genomics. Brie\u0000ngs in bioinformatics. 2010, 11(5):499–511.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.0**\n25. Xiao S, Wang P, Zhang Y, et al. Gene map of large yellow croaker (Larimichthys crocea) provides insights into teleost genome evolution and conserved\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nregions associated with growth. Scienti\u0000c reports. 2015, 5:18661.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n2\u0000. You X, Shan X, Shi Q. Research advances in the genomics and applications for molecular breeding of aquaculture animals. Aquaculture. 2020,\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n27. Yu H, You X, Li J, et al. Genome-wide mapping of growth-related quantitative trait loci in orange-spotted grouper (Epinephelus coioides) using double\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\ndigest restriction-site associated DNA sequencing (ddRADseq). International journal of molecular sciences. 2016, 17(4):501.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.0**\n2\u0000. Zhang A, Liu S, Zhu J, et al. Transcriptome analysis of the freshwater pearl mussel, Hyriopsis cumingii (Lea) using illumina paired-end sequencing to\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\nidentify genes and markers. Iranian Journal of Fisheries Sciences. 2016, 15(1):479–496.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.7**l== 0.0**r== 0.9**\nFigures\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigure 1\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.6**l== 0.0**r== 0.2**\nLength distribution of unigenes. The X-axis represents the length of unigenes, and the Y-axis stands for the number of unigenes.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigure 2\n**BLOCK**fs== 8.0**p== 9.0**b== 0.4**t== 0.6**l== 0.0**r== 0.5**\nSingle nucleotide polymorphisms (SNPs) distribution among unigenes.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigure 3\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.0**r== 0.7**\nThe haplotype network based on 14 SNP loci\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.0**r== 0.3**\nThe yellow circle represents the haplotype of individuals, and the red circle represents the median vector\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.7**l== 0.0**r== 0.8**\nSupplementary Files\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.0**r== 0.5**\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nSNPsmuscleDiodonhystrix.xls",
         "Genetic Diversity Analysis of Wild Population Based on SNP Developed from Transcriptome Sequencing of Spot-Fin Porcupine Fish (Diodon hystrix) shoujia jiang liu cao haihsan wang wenqi zhuo zhou wang tingting dang xueyi wang pan chen xingrong hou xinxin you hai huang  (  huanghai74@126.com ) Hainan Tropical Ocean University  https://orcid.org/0000-0001-9841-1147 Keywords: Spot-\u0000n porcupine \u0000sh, Diodon hystrix, SNPs, RNA-Seq Diversity License:   This work is licensed under a Creative Commons Attribution 4.0 International License.   Read Full License Diodon hystrix is widely distributed in the tropical and subtropical ocean. Due to delicious taste and unique body shape, the catch of this \u0000sh in the South China Sea has been increasing year by year. It is urgent to evaluate the population status of D. hystrix in the South China Sea. Molecular markers are often used to evaluate the population status, but it has been a lack of relevant molecular markers for D. hystrix. In this study, we utilized the Illumina sequencing platform to generate transcriptome data to identify SNPs in D. hystrix muscle tissue. A total of 7.2 Mb clean reads with 94.92% Q20 bases were obtained, and 4,179 putative SNPs distributed among 22,618 genes were identi\u0000ed and con\u0000rmed. Randomly selected SNPs were validated, and 19 true SNPs (39.58%) were screened. We used these true SNP loci to verify the genetic diversity and population structure of a wild population of D. hystrix. The results showed that 18 SNP loci were polymorphic. The average PIC, Ne, Ho and He were 0.3354, 1.7893, 0.4963 and 0.4391, respectively. 14 SNP loci were consistent with Hardy- Weinberg equilibrium (HWE), which revealed that the population was in a genetically stable state. The haplotype network concluded that the population may be composed of two different clades. In conclusion, the transcriptomic sequencing can quickly obtain the SNP loci as molecular markers which can be used for population genetic diversity and population structure analysis. It provides necessary help for the conservation biology and resource evaluation of D. hystrix. Diodon hystrix, the spot-\u0000n porcupine \u0000sh, is a member of the Diodontidae family and is widely distributed in tropical and subtropical marine environments (Leis JM, 2006). D. hystrix has the same easily recognizable biological characteristics as puffer\u0000sh (Takifugu sp., Tetraodontidae family), such as an in\u0000ated body and spiny skin. Some countries and regions catch the porcupine \u0000sh for making dry crafts to sell to tourists, or showing in private and public aquariums. Although some reports indicate that porcupine \u0000sh are toxic, its meat is eaten by people living along the coast of the South China Sea. Until now, D. hystrix has been listed as a species of least concern (LC) in the red list of threaded animals (IUCN 2015), but in fact, the biomass of this \u0000sh in the South China Sea has been rapidly decreasing. Recently, signi\u0000cant technical advancements have provided innovative molecular genetic tools for studying aquaculture species (Hauser L, 2008; Milano I, 2011). Single nucleotide polymorphisms (SNPs) are widely used in genetic diversity research, genetic linkage map construction, quantitative trait loci (QTL) mapping, genome-wide association study (GWAS), and genomic selection (GS) because of their abundance and stability in genomes and transcriptomes (You X, 2020). Generally, when considering the marker density and genome coverage of SNP markers, the distribution of SNPs among unigenes is crucial, especially when they are used for genetic mapping. Meanwhile, large sets of SNPs have also been reported in some aquaculture species, such as in the genus Austrolebias (García G, 2019), and the species Litopenaeus vannamei (Lu X, 2018), Hyriopsis cumingii (Zhang A, 2016), the Eastern oyster (Quilang J, 2007), Ctenopharyngodon idella (Liao Z, 2017), and Acipenser schrenckii (Li S, 2018) and some Takifugu species (Cui J, 2014; Jin W, 2015). These reported SNPs are mainly centered on economic traits, including tolerance to various environmental stressors, disease resistance, sexual determination, and growth rate (Xiao S, 2015; Yu H, 2016; Wang X, 2019). Nevertheless, the SNPs of D. hystrix has not yet been reported. The large-scale discovery of molecular markers of D. hystrix is the basic work for reserving germplasm resources, constructing genetic analysis, and developing molecular genetic breeding technology. In view the conservation status and the intention of improving the breeding of this species, we describe a large set of SNPs obtained by the transcriptome sequencing of D. hystrix in this study. These SNPs should re\u0000ect information concerning economically relevant traits for future molecular-assisted breeding. Sample collection and RNA isolation The spot-\u0000n porcupine \u0000sh (length 20 cm) was captured from the South China Sea in Sanya, Hainan province, China. Later, the muscle tissues were collected, frozen in liquid nitrogen, and then stored at -80˚C before RNA isolation. Total RNA was extracted from muscle tissues using the TRIzol reagent (Simms D, 1993) and further puri\u0000ed using the RNeasy Mini kit according to the manufacturer’s protocol (Beltrame C, 2015). The quantity and quality of total RNA were measured and recorded using an Agilent 2100 Bioanalyzer (Panaro NJ, 2000). All treatment procedures for \u0000sh during this study were conducted in accordance with the guidelines of the Animal Ethics Committee and were approved by the review committee of BGI bioethics and biosafety. Transcriptome Sequencing and Reads Collection Using the criteria of paired-end 150 bp reads, the transcriptome libraries were sequenced on an Illumina HiSeqTM 2000 platform (San Diego, CA, USA). To better assemble the whole transcriptome de novo, a paired end (PE) sequencing strategy was used. Subsequently, the clean reads from D. hystrix transcriptome were de novo assembled using Trinity package and the assembled sequence from the transcriptome data was used as reference in this study. Firstly, the obtained raw reads from D. hystrix were treated using SOAPdenovo (https://github.com/BGI-\u0000exlab/SOAP) to remove the junk reads with adapters, reads with more than 5% unknown nucleotides, and low-quality scores (Q20). The clean reads were then de novo assembled into contigs and unigenes using the Trinity package, with the parameters set to “min_contig_length 150 --min_kmer_cov 3 --min_glue 3 --b\u0000y_opts '-V 5 --edge-thr = 0.1 –stderr”. Then, the clean sequences were then mapped back to contigs. Ultimately, we obtained unigenes (more than 150 nucleotides), which were clustered using TGICL (default parameters) (Pertea G, 2003) to reduce redundancy. SNP Detection Potential SNP variations were predicted by combining two tools, BWA for mapping and GATK for variant calling. Short reads of the D. hystrix transcriptome was mapped to the reference using BWA version 0.5.9 (http://bio-bwa.sourceforge.net/) by the default settings except for no gap tolerance. There are many available calling software programs, GATK and SAMtools are currently the most popular SNP discovery tools. In this study, raw vcf \u0000les were \u0000ltered using GATK version 3.4 with the parameter settings “stand_call_conf 20.0 -stand_emit_conf 20.0 -window 35 -cluster 3 -FS > 30.0 QD < 5.0” except for no gap tolerance (De Summa S, 2017). The high-quality SNPs were required to meet the requirements of quality score greater than 20 and read depth measured over 10. Since the prediction accuracy of SNPs depends on sequence coverage, both SNPs and indels were considered to be true polymorphisms, when each allele was observed at least three times. Analysis of genetic diversity and population structure To validate the SNPs from RNA-Seq, we used the software Primer 3 (http://primer3.ut.ee/) to design a number of primers which could amplify the \u0000anking sequence of randomly selected SNP loci. The genome DNA of D. hystrix was used to detect these SNP loci, and the positive PCR was as basis for preliminary screening of SNP loci. A true SNP locus usually has nucleotide transversion or transition. So, a wild group of D. hystrix (30 individuals) was used as templates for validating these screened SNP loci. The positive PCR products on these screened SNP loci were sequenced by BGI-Guangzhou. In sequencing peak map, the homozygous SNP loci are single peaks, whereas heterozygous SNP loci are double peaks. Homozygotes were recorded as AA and BB respectively, and heterozygotes were recorded as AB. The effective number of alleles (Ne), expected heterozygosity (He), observed heterozygosity (Ho), and minimum allele frequency (MAF) were analyzed by Arlequin (version 3.5.2.2) software (Exco\u0000er L, 2010). In addition, the Arlequin software was also used to analyze the linkage disequilibrium among different SNP loci. The PIC_CALC (version 0.6, https://github.com/luansheng/PIC_CALC) was used to calculate the polymorphism information content (PIC) of SNPs. The Genepop (version 4.5.1) (François Rousset, 2008) was used to test the Hardy-Weinberg equilibrium (HWE). The genotypes of different SNP loci of each individual were used to compose the SNP feature sequences. These SNP feature sequences were used to construct the haplotype networkby DNASP (version 6) and NETWORK (version 10.2) (Rozas J, 2017; Tobias Polzin, 2003). Transcriptome sequencing and de novo assembly A total of 7.74 Mb paired-end raw reads were generated from the D. hystrix muscle. Raw reads of separated individuals were deposited in the ENA (European Nucleotide Archive) public database (Accession: PRJEB47595). After removing the adapter sequences and low-complexity reads, a total of 7.2 Mb of clean reads was obtained. The Q20 and Q30 values were 94.9% and 88.7%, respectively (Table 1). The GC percentage of the transcriptome was 47.0%. The high- quality reads were then assembled into 29,272 contigs from the short reads. These redundant contigs were further clustered into 22,618 unigenes with the N50 size of 975 bp (Table 2). The length distributions of these assembled unigenes are shown in Fig. 1. Table 1 The information of RNA-Seq reads Insert Size (bp) Raw data Clean data Table 2 The information of assembled unigenes Total Length (bp) Mean Length (bp) The alignment \u0000le was used for SNP detection by using GATK. To obtain more reliable SNPs, high-quality SNPs were de\u0000ned as those with a quality score over 20 and a read depth over 10. As predicted from the muscle transcriptome, there are 4,179 high-quality SNPs. Among the detected SNPs, the transition sites are 2856 (68.34%), while the transversion sites are 1323 (31.66%). The ratio of transition to transversion is 2.16. In these transition sites, the highest proportions are G/A (752, 17.99%) and C/T (737, 17.64%). In these transversion sites, the highest proportions are A/C (185, 4.43%) and C/A (181, 4.33%), while the C/G (145, 3.47%) is the lowest proportion (Table 3). SNP distribution among unigenes signi\u0000cantly matters in the consideration of the marker density and genome coverage with the usage of SNP markers, especially when SNPs are used for linkage map construction. In this study, we found that all the SNPs were distributed in 2,270 unigenes (10.04% of the total number of unigenes). The unigenes with a single SNP were common (occupied 34.0% of all SNPs), and those with no more than 10 SNPs occupied 95.14% of all SNPs. A total of 19 unigenes containing over 10 SNPs were observed. The detailed SNP distribution among those unigenes is indicated in Fig. 2. SNP type SNP screening As the SNPs reported in the present study were identi\u0000ed through RNA-Seq analysis, the SNPs needed further validation. A total of 103 SNP loci were randomly selected from 4,179 predicted SNPs, and the primers were obtained under the default stringency conditions of the Primer3 software. By optimizing the PCR reaction conditions, 48 pairs of primers could amplify the target sequences. Within these ampli\u0000ed sequences, 19 SNP loci (682, 698, 1569, 5491, 5649, 5921, 7808, 10659, 12102, 12374, 12683, 14194, 14788, 15840, 18877, 19192, CL351, CL439, and CL552) were effectively screened (these primers were listed in the Table S1). The estimated prediction accuracy of SNPs reached 39.58%. Polymorphism analysis of SNP The genomic DNA from 30 wild individuals of D. hystrix was detected by these primers of 19 SNP loci. The results showed that one locus (5649) contained three alleles (A, T, and G) in each sample did not conform to the feature of diploid, and the remaining 18 SNP loci contained two alleles (see Table 4). Expected heterozygosity (He) is often used to measure the genetic diversity of populations. In this wild population, average observed heterozygosity (Ho) was 0.4963, and average expected heterozygosity (He) was 0.4391; Minor allele frequency (MAF) is actually the second most frequent allele in the population, which is mainly used to distinguish whether an allele is a common polymorphism or a rare variation. The distribution range of MAF of 18 SNP loci was 0.1167-0.5000, which was greater than 0.05, indicating that these loci belong to common polymorphisms. Polymorphism information content (PIC) is used to indicate the degree of polymorphism at a certain locus in a population. The average PIC of this wild population was 0.3354, one locus (12102) belonged to low polymorphism (PIC < 0.25), and others belonged to moderate polymorphism (0.25 < PIC < 0.5). Hardy-Weinberg equilibrium test showed that 4 loci (5921, 15840, 18877, and CL351) did not accord with HWE (P < 0.05), and 2 loci (15840 and CL351) seriously did not accord with HWE (P < 0.01). These results of polymorphism analysis showed that 18 SNP loci (excepted 5649) could be used for the genetic analysis of Diodon hystrix. Linkage disequilibrium analysis of SNP Linkage disequilibrium (LD) is used to evaluate the phenomenon that the alleles at different loci appearing on the same chromosome is frequently higher than that of random association. In this study, it was found that locus 12102 was linked to 12374, 14194 and 15840, respectively (p < 0.05), locus 12102 and 14194 were signi\u0000cant linkage (p = 0.0059); SNP locus 5921 was linked to 15840 and CL351, respectively (P < 0.05); In addition, there was a very signi\u0000cant linkage between locus 15840 and CL351 (p = 0.0000, see Table 5). SNP for population genetic structure analysis The loci deviating from HWE are not suitable to investigate the genetic stability of the population. Therefore, we recombined the SNP feature sequences by using the genotypes of 14 SNP loci conforming to HWE. 30 individuals were formed 30 haplotypes. Haplotype network analysis divided these 30 haplotypes into two clades. One small clade contained 8 haplotypes (m15, m19, m21, m23-025, m28 and m29), and the other big clade contained 22 haplotypes (m1-14, m16-18, m20, m22, m26-27 and m30). The big clade included four small branches, which respectively composed by 6 (m2, m6, m10, m13, m16 and m20), 5 (m3, m7, m11, m12 and m18), 6 (m1, m5, m8, m17, m27 and m30), 3 (m4, m14 and m26) haplotypes (Fig. 4). Transition frequency Transversion frequency Substitution frequency s.d. Theta_S Indel frequency a: The SNP locus predicted from transcriptome is complementary with the validation results from genomic b: Abnormal SNP locus Table 5 The linkage disequilibrium analysis of SNP loci The signi\u0000cance level of linkage disequilibrium is 0.05 In terms of novel species, NGS technology is a powerful tool for examining their genetic blueprint. Whole-genome sequencing (WGS) and RNA-Seq can be used to study individual differences, gene function, and evolutionary history (Werner T, 2010; Martin JA, 2011). However, WGS is more costly in terms of expense and computing resources than RNA-Seq, and it cannot directly obtain the comprehensive information included in transcriptomes through functional prediction (Chou C-H, 2018). A more effective strategy is to use RNA-seq \u0000rst to clarify the molecular bases of biological functions. Owing to the economic importance of many aquatic species, it is necessary to establish a complete transcriptome resource database, and this can be done despite the lack of genomes for non-model species. In addition, RNA-Seq is also an e\u0000cient and cost-effective method to comprehensively identify SNPs from transcribed regions in the genomes of aquaculture species. In this study, the transcriptome was generated using the Illumina HiSeq platform to identify SNPs in D. hystrix. A total of 4,179 putative SNPs distributed among 2,270 unigenes were identi\u0000ed. Among these, the number of transition SNP loci (A/G and C/T) was signi\u0000cantly greater than that of transversion SNP loci (A/T, A/C, G/T, and C/G; Table 3), which is similar to the \u0000ndings of other studies such as in Acipenser schrenckii (Li S, 2018), Litopenaeus vannamei (Lu X, 2018), and Piaractus mesopotamicus (Mastrochirico-Filho VA, 2016). These large sets of SNPs were obtained from the D. hystrix transcriptome sequencing, and then 19 available SNP loci were screened from 48 ampli\u0000ed loci, and the predicted accuracy of SNP loci was 39.58%. It indicated that tissue-speci\u0000c transcriptome sequencing was one of the important ways to e\u0000ciently screen available SNP loci. Polymorphism is the genetic diversity among different populations within a species or among different individuals within a population. It is the foundation for maintaining the evolution of species, and is also closely related to the formation, disappearance and development of biodiversity. In this study, we used 18 available SNP loci (excluding 5649 locus) to analyze the polymorphism of wild population of D. hystrix. Expected heterozygosity (He) indicated the genetic diversity of this population was at a moderately low level, which may be caused by the inhomogeneous distribution of individual loci (such as 12102 and CL552) in the population. In addition, the average PIC of 18 SNP loci was generally low, which was consistent with the result of He. Remarkably, SNP locus (5649) often appeared the triploid in population (each individual contained three alleles, such as A, T, or G). We have not eliminated this phenomenon by improving experimental methods, eliminating sample pollution and improving primer speci\u0000city. Therefore, we speculate that there are two possibilities on this locus: (1) the gene of this locus is a multi-copy gene in this species; (2) the chromosome of this species has a doubling phenomenon in the evolution. These inferences need to be veri\u0000ed in the future. In a stable population, the frequency of alleles and genes are balanced in generation heredity. The results of HWE showed that four loci (5921, 15840, 18877 and CL351) signi\u0000cantly deviated from the balance, while other loci (except 5649) were well to comply with Mendel's law of inheritance. It indicated that the population of D. hystrix in the South China Sea was still in a relatively stable state under high \u0000shing intensity. Interestingly, the other three loci (5921, 15840 and CL351) deviated from HWE have linkage disequilibrium. These linkage disequilibrium loci lead to a serious difference between the actual frequency and expected frequency of two genes at different loci, which indicated that the genes corresponding to these loci may be located on the same chromosome or close to each other. This suggested that we should be more attention to the effect of linkage disequilibrium genes on HWE in the population diversity analysis. We also analyzed the population structure of this wild population of D. hystrixHaplotype analysis divided this wild population into 30 haplotypes, which may be attributed to too many SNP loci or insu\u0000cient number of samples. However, it does not affect the construction of haplotype network for this wild population. Haplotype network analysis revealed that the wild population of D. hystrix in the South China Sea may be composed of two different clades. Clade1 had more haplotypes and branches, it suggested that the clade1 was higher polymorphism than clade2. Theoretically, these haplotypes in clade1 have stronger adaptability, but it still needs to be further veri\u0000ed by increasing the number of samples. In this study, the high-throughput sequencing reads from muscle tissue transcriptomes of D. hystrix were used to detect SNPs. A total of 4,179 high-quality SNPs were predicted. Within 48 ampli\u0000ed SNP loci, about half could be veri\u0000ed. The available SNP loci were used to analyze the genetic diversity and population structure of the wild population of D. hystrix in the South China Sea. The genetic diversity of the wild population was at moderately low level. The wild population may be composed of two relatively independent clades, and the diversity of one clade was signi\u0000cantly higher than that of the other. It suggested that the genetic status of the wild population of D. hystrix in the South China Sea was still relatively stable, but its` population resources need to be attention to at all times. Overall, the SNPs predicted in this study will play a role in genetic diversity research and molecular-assisted breeding of D. hystrix. Ethics approval All applicable international, national, and/or institutional guidelines for the care and use of animals were followed by the authors. The use of animal was approved by the Institutional Animal Care and Use Committee of Hainan Tropical Ocean University. Consent to Publish and Participate Written informed consent for publication was obtained from all participants. All data generated or analyzed during this study are included in this article. The information of SNPs is provided as online supplementary material. The authors have declared that no competing interests exist. Author contribution H.H. and X.Y. contributed study design, J.M., Y.C., P.C., X.H., and L.C. contributed to the sample preparation, W.Z., T.D. and Z.W. contributed the experimental veri\u0000cation; J.M., H.W. and X.W. contributed the genetic analysis; S.J., and X.Y. performed the bioinformatics analysis; S.J., and J.M. wrote the paper. All authors read and approved the \u0000nal manuscript. This research was funded by the Key R & D Program Project of Hainan Province (No. ZDYF2018225), Ministry of Agriculture and Rural Affairs Project for Conservation of Species Resources (No. 17200352). 1. Beltrame C, Côrtes M, Bandeira P. Optimization of the RNeasy Mini Kit to obtain high-quality total RNA from sessile cells of Staphylococcus aureus. Brazilian Journal of Medical and Biological Research. 2015, 48(12):1071–1076. 2. Chou C-H, Huang H-Y, Huang W-C. The aquatic animals` transcriptome resource for comparative functional analysis. BMC genomics. 2018, 19(2):161– 3. Cui J, Wang H, Liu S. Transcriptome analysis of the gill of Takifugu rubripes using Illumina sequencing for discovery of SNPs. Comparative Biochemistry and Physiology Part D: Genomics and Proteomics. 2014, 10:44–51. 4. De Summa S, Malerba G, Pinto R. GATK hard \u0000ltering: tunable parameters to improve variant calling for next generation sequencing targeted gene panel data. BMC bioinformatics. 2017, 18(5):119. 5. Exco\u0000er L, Lischer H. Arlequin suite ver 3.5: a new series of programs to perform population genetics analyses under Linux and Windows[J]. Molecular \u0000. François Rousset. genepop’007: a complete re-implementation of the genepop software for Windows and Linux. Molucular ecology resources. 2008, 8(1): 7. García G, Ríos N, Gutiérrez V. Transcriptome-Based SNP Discovery and Validation in the Hybrid Zone of the Neotropical Annual Fish Genus Austrolebias. \u0000. Hauser L, Carvalho GR. Paradigm shifts in marine \u0000sheries genetics: ugly hypotheses slain by beautiful facts. Fish and Fisheries. 2008, 9(4):333 − 62. 9. Jin W, Wen H, Du X. Transcriptome analysis reveals the potential mechanism of the albino skin development in puffer\u0000sh Takifugu obscurus. In Vitro Cellular & Developmental Biology-Animal. 2015, 51(6):572–577. 10. Leis JM. Nomenclature and distribution of the species of the porcupine\u0000sh family Diodontidae (Pisces, Teleostei). Memoirs of Museum Victoria. 2006, 11. Li S, Wang D, Cao Y, et al. Transcriptome pro\u0000le of Amur sturgeon (Acipenser schrenckii) liver provides insights into immune modulation in response to Yersinia ruckeri infection. Aquaculture. 2018, 492:137 − 46. 12. Liao Z, Wan Q, Shang X, et al. Large-scale SNP screenings identify markers linked with GCRV resistant traits through transcriptomes of individuals and cell lines in Ctenopharyngodon idella. Scienti\u0000c reports. 2017, 7(1):1–12. 13. Lu X, Kong J, Meng X, et al. Identi\u0000cation of SNP markers associated with tolerance to ammonia toxicity by selective genotyping from de novo assembled transcriptome in Litopenaeus vannamei. Fish & shell\u0000sh immunology. 2018, 73:158 − 66. 14. Martin JA, Wang Z. Next-generation transcriptome assembly. Nature Reviews Genetics. 2011, 12(10):671–682. 15. Mastrochirico-Filho VA, Hata ME, Sato LS, et al. SNP discovery from liver transcriptome in the \u0000sh Piaractus mesopotamicus. Conservation genetics resources. 2016, 8(2):109–114. 1\u0000. Milano I, Babbucci M, Panitz F, et al. Novel tools for conservation genomics: comparing two high-throughput approaches for SNP discovery in the transcriptome of the European hake. PLoS One. 2011, 6(11):e28008. 17. Panaro NJ, Yuen PKi, Sakazume T, et al. Evaluation of DNA fragment sizing and quanti\u0000cation by the agilent 2100 bioanalyzer. Clinical chemistry. 2000, 1\u0000. Pertea G, Huang X, Liang F, et al. TIGR Gene Indices clustering tools (TGICL): a software system for fast clustering of large EST datasets. Bioinformatics. 19. Quilang J, Wang S, Li P, et al. Generation and analysis of ESTs from the eastern oyster, Crassostrea virginica Gmelin and identi\u0000cation of microsatellite and SNP markers. BMC genomics. 2007, 8(1):157. 20. Rozas J, Ferrer-Mata A, Sánchez-DelBarrio JC, et al. DnaSP 6: DNA Sequence Polymorphism Analysis of Large Datasets. Mol. Biol. Evol. 21. Simms D, Cizdziel PE, Chomczynski P. TRIzol: A new reagent for optimal single-step isolation of RNA. Focus. 1993, 15(4):532–535. 22. Tobias Polzin, Siavash Vahdati Daneshmand. On Steiner trees and minimum spanning trees in hypergraphs, Operations Research Letters, 2003, 23. Wang X, Jiang S, Zheng L, et al. An SNP-Based Genetic Map and QTL Mapping for Growth Traits in the Red-Spotted Grouper (Epinephelus akaara). Genes. 24. Werner T. Next generation sequencing in functional genomics. Brie\u0000ngs in bioinformatics. 2010, 11(5):499–511. 25. Xiao S, Wang P, Zhang Y, et al. Gene map of large yellow croaker (Larimichthys crocea) provides insights into teleost genome evolution and conserved regions associated with growth. Scienti\u0000c reports. 2015, 5:18661. 2\u0000. You X, Shan X, Shi Q. Research advances in the genomics and applications for molecular breeding of aquaculture animals. Aquaculture. 2020, 27. Yu H, You X, Li J, et al. Genome-wide mapping of growth-related quantitative trait loci in orange-spotted grouper (Epinephelus coioides) using double digest restriction-site associated DNA sequencing (ddRADseq). International journal of molecular sciences. 2016, 17(4):501. 2\u0000. Zhang A, Liu S, Zhu J, et al. Transcriptome analysis of the freshwater pearl mussel, Hyriopsis cumingii (Lea) using illumina paired-end sequencing to identify genes and markers. Iranian Journal of Fisheries Sciences. 2016, 15(1):479–496. Length distribution of unigenes. The X-axis represents the length of unigenes, and the Y-axis stands for the number of unigenes. Single nucleotide polymorphisms (SNPs) distribution among unigenes. The haplotype network based on 14 SNP loci The yellow circle represents the haplotype of individuals, and the red circle represents the median vector This is a list of supplementary \u0000les associated with this preprint. Click to download.",
         "https://www.researchsquare.com/article/rs-352287/latest.pdf",
         "extracted",
         "None",
         "",
         "Genetic diversity analysis of wild population based on SNP developed from transcriptome sequencing of spot-fin porcupine fish (Diodon hystrix)"
        ],
        [
         "13",
         "0054da67677e57ad0e4329f204539db27329c1d8",
         "None",
         "Donghua Wang,Wenyan Yao,Tingsong Jiang,Chao Li",
         "\n**BLOCK**fs== 23.9**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nUniversal Multi-view Black-box Attack against\nObject Detectors via Layout Optimization\n**BLOCK**fs== 11.0**p== 0.0**b== 0.8**t== 0.2**l== 0.3**r== 0.2**\nDonghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.3**l== 0.1**r== 0.5**\nAbstract—Object detectors have demonstrated vulnerability\nto adversarial examples crafted by small perturbations that\ncan deceive the object detector. Existing adversarial attacks\nmainly focus on white-box attacks and are merely valid at\na specific viewpoint, while the universal multi-view black-box\nattack is less explored, limiting their generalization in practice.\nIn this paper, we propose a novel universal multi-view black-\nbox attack against object detectors, which optimizes a universal\nadversarial UV texture constructed by multiple image stickers\nfor a 3D object via the designed layout optimization algorithm.\nSpecifically, we treat the placement of image stickers on the UV\ntexture as a circle-based layout optimization problem, whose\nobjective is to find the optimal circle layout filled with image\nstickers so that it can deceive the object detector under the\nmulti-view scenario. To ensure reasonable placement of image\nstickers, two constraints are elaborately devised. To optimize\nthe layout, we adopt the random search algorithm enhanced by\nthe devised important-aware selection strategy to find the most\nappropriate image sticker for each circle from the image sticker\npools. Extensive experiments conducted on four common object\ndetectors suggested that the detection performance decreases by\na large magnitude of 74.29% on average in multi-view scenarios.\nAdditionally, a novel evaluation tool based on the photo-realistic\nsimulator is designed to assess the texture-based attack fairly.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nIndex Terms—Adversarial examples, multi-view black-box at-\ntack, universal attack, physical adversarial attack, object detec-\ntion.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nI. INTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nDeep learning, with the core of deep neural networks\n(DNNs), has profoundly impacted many research areas, such\nas computer vision, speech recognition, and natural language\nprocesses. However, DNNs have been demonstrated to be\nvulnerable to adversarial examples, which are crafted by\nsmall noises that are invisible to human observers but can\ndeceive DNN models [1]. Therefore, adversarial examples\nimpose potential security risk for the physically deployed\nDNN-based systems, especially in security-sensitive scenarios,\nsuch as autonomous driving and medical image diagnosing. An\nexhaustive exploration of such adversarial attacks-caused risk\nin advance is necessary to reduce the potential loss.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nCurrently, a line of studies on adversarial examples has\nemerged [2], [3], [4], [5], [6], and these works can be divided\ninto white-box attacks and black-box attacks in terms of\nthe adversarial’s knowledge. White-box attacks assume the\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nDonghua Wang is with the College of Computer Science and Technol-\nogy, Zhejiang University, Hangzhou, China. Wen Yao, Tingsong Jiang and\nXiaoqian Chen is with the Defense Innovation Institute, Chinese Academy\nof Military Science and Intelligent Game and Decision Laboratory, Beijing,\nChina. Chao Li is with the school of automation and electrical engineering,\nZhongyuan University of Technology, Zhengzhou, China. (Corresponding\nauthor: Wen Yao and Tingsong Jiang.)\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nis impractical\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nadversary can access full knowledge about the target model,\nsuch as architecture, training data, parameters, and so on.\nWhite-box attacks allow the adversary to leverage the model’s\ngradient to optimize the adversarial example [2], [7], [8],\nin the real world as the attacker\nwhile it\ncan not access the deployed model’s gradient. In contrast,\nblack-box attacks prohibit the adversary from accessing the\ninformation about the model yet only allow them to query\nthe model, which makes them match the physical scenario\nmore practical. Nonetheless, current black-box attacks mainly\nfocus on generating imperceptible [4], [5] and image-specific\nadversarial perturbation [6], [9] for each input image, whose\nflexibility is poor as it necessitates engender new perturbation\nfor each input samples. Although some universal adversarial\nattack methods[28], [30], [32] can address the issue, these\nmethods can not be physically deployed.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.5**l== 0.5**r== 0.1**\nPhysical deployable adversarial attacks are characteristic of\nthe generated adversarial perturbation that can be manufac-\ntured and placed on the target cover object (e.g., pedestrian)\nin the physical world, which imposes practical security risks.\nExisting physical adversarial attacks can be roughly divided\ninto the following two-fold in terms of the deployment of\nphysical perturbation: sticker (patch)-based and camouflage-\nbased physical attacks. The former performs physical attacks\nby sticking the sticker on a specific object area (e.g., the\nfront side of the pedestrian [10], [11]), but the attack will\nfail when the detector captures the image from the viewpoint\nwhere the adversarial sticker does not appear. In contrast,\ncamouflage-based attacks [12], [13], [14], [15] generate the\nadversarial UV texture to modify the appearance of the 3D\nobject by wrapping the texture over the surface of the 3D\nobject, enabling them to maintain the attack effect on multi-\nview angles. However, most camouflage-based attacks belong\nto white-box attacks, limiting their usefulness. Although Wu et\nal.[16] proposed a black-box attack by leveraging the discrete\nsearch algorithm, which first optimizes the small image patch\nand then performs the enlarge-repeat process to construct the\nfinal adversarial texture. Nonetheless, the mosaic-like pattern\nof generated textures is conspicuous and easily attracts the\nattention of human observers.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nSome approaches attempt to improve the inconspicuous of\nphysical adversarial attacks, such as Liu et al.[17] exploited\nthe generative model to generate the natural image, which is\ntreated as the adversarial patch that is pasted on the sample\nto deceive the model. Doan et al.[18] proposed a two-stage\nmethod to optimize the natural adversarial image patch against\nthe classification model, in which the generator is trained to\ngenerate natural flower images at the first stage, and the input\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nFig. 1. Example of vehicle graffiti in the real world.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nlatent variable of the generator is optimized via the adversarial\nloss to ensure aggressive of the generated image. Wei et\nal.[19] demonstrated that natural stickers can deceive the\nfacial recognition system, where the paste location of stickers\nis found by their proposed search algorithm. Despite their\nsuccess on the recognition task, adversarial attacks against the\ndetection task proved more difficult than the recognition task\n[20]. Moreover, these methods are valid at specific viewpoints,\nlimiting their effectiveness in the physical world.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.3**l== 0.1**r== 0.5**\nUnlike optimizing the adversarial pattern of a single sticker\nfor the object at the specific viewpoint, we optimize the layout\nof multiple sticker images in the UV texture of the object to\nperform universal adversarial attacks on multiple viewpoints.\nNote that the sticker can be arbitrary natural images, which\nrenders the attack more inconspicuous as it looks like the vehi-\ncle with the graffiti, which is normal in the real world and can\nnot attract human alert, as illustrated in Figure 1. In this paper,\nwe propose a novel universal multi-view black-box attack on\nobject detectors, which optimizes a universal adversarial UV\ntexture for a 3D object via the designed layout optimization\nalgorithm, rendering the generated image to deceive the object\ndetector. More specifically, we treat the optimization problem\nof adversarial UV texture as a circle layout optimization\nproblem, in which the rectangle is the container for image\nstickers randomly sampled from the preprepared image pool.\nThe optimization objective is to find a universal adversarial\nUV texture wrapped over the 3D object to deceive the object\ndetector from different viewpoints, and two layout constraint\nstrategies are proposed to ensure the reasonable placement\nof image stickers. To obtain the optimal adversarial layout\nsolution, we adopt the random search algorithm enhanced\nby the devised important-aware selection strategy. The op-\ntimization variable is the circle number, radius, and center,\nsimplifying the constraint strategy. Additionally, we developed\na novel evaluation tool based on the photo-realistic simulator\n(i.e., Unreal Engine) to assess the texture-based adversarial\nattack fairly. Finally, we conduct extensive experiments in\nboth digital and simulated environments, showing the proposed\nmethod outperforms the comparison method significantly.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nOur main contributions are listed as follows.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• We propose a novel universal multi-view black-box attack\nagainst object detectors via layout optimization, which\nengenders a universal adversarial UV texture that is valid\nin the multi-view scenario.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n• We formulate a circle layout optimization problem to\nobtain the optimal adversarial UV texture, which is\nsolved by the random search algorithm enhanced by the\ndesigned important-aware selection strategy. Two layout\nconstraints are designed to enable the reason for the\nplacement of image stickers.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n• We devised a novel evaluation tool based on the photo-\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nrealistic simulator (i.e., Unreal Engine) to assess the\nattack performance of adversarial sticker attacks fairly.\n• Extensive experiments on both digital and simulated\nenvironments under different tasks show the effectiveness\nand extensibility of the proposed method. Moreover, we\ndemonstrate that 3D objects with natural image graffiti\ncan deceive object detectors in surround view.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nThe rest of this paper is arranged as follows. The related\nworks are briefly reviewed in Section II. Then, we formulate\nthe problem statement in Section III. The proposed method\nis exhaustly introduced in Section IV. The evaluation tool is\ndescribed in Section V. Experiment and result analysis are\ndiscussed in Section VI. The conclusion is given in Section\nVIII.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.3**l== 0.7**r== 0.2**\nII. RELATE WORKS\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nIn this section, we briefly review digital adversarial attacks\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nand physical adversarial attacks.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nA. Digital Adversarial attacks\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.4**l== 0.5**r== 0.1**\nExisting digital adversarial attacks can be categorized into\nwhite-box and black-box attacks in terms of whether the\nadversary can access the target model. The former assumes\nthe adversary can access the full knowledge about the target\nmodel, which allows the adversary to exploit the gradient\nof the target model to develop adversarial attacks. Thus, the\nmethod used the gradient with respect to the model is re-\ngarded as the white-box attack. The most represented gradient-\nbased approach is FGSM [7], which crafts the adversarial\nexample along with the gradient ascend direction of task-\nspecific loss with respect to the input in a single step. Since\nthen, a line of variants of FGSM have emerged, such as\nmultiple iterative steps (BIM) [8], random initialization (PGD)\n[2], combined with momentum terms (MIM) [3] to improve\nthe transferability, and input augmentation [21]. In contrast,\nblack-box attacks prohibit the attacker from accessing the\ntarget model and only allow them to query the target model.\nThus, a promising method to perform black-box attacks is\nthe evolutionary algorithm, such as genetic algorithm [22],\ndifferential evolution (DE) [23], and particle swarm opti-\nmization (PSO) [24]. Despite obtaining certain success, their\noptimization involved amount of variables, because they were\nrequired to find the pixel-wise adversarial perturbation with\nthe shape of the input image, which is time-consuming in\npractice. To reduce the optimization variables, Yang et al.\n[25] optimized a small perturbation size and then interpolated\nit\nleading to a dramatic reduction in\noptimization variables. Rather than directly optimizing the\npixel of perturbation, Andriushchenko et al. [26] utilized the\nrandom search algorithm to yield square-based perturbation,\nwherein the optimization variable is the position, side length,\nand fill color of the square. Li et al. [4] proposed to exploit\nneighborhood samples around the input image to estimate\nthe gradient, which is used to guide the update direction\nof adversarial examples. In their algorithm, the optimization\nvariables solved by DE are the weights used to fusion the\nneighborhoods. Later, Li et al. [5] proposed to perturb partial\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\nto the input shape,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\npixels of input, which are determined by CAM [27] that\nhighlights the important pixel for model decision.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nAnother type of adversarial attack are universal attacks,\nwhich engender a single universal perturbation for the dataset.\nMoosavi et al.[28] first proposed an iterate update method to\naccumulate the perturbation for each image samples, where\nthe final perturbation is called the universal adversarial pertur-\nbation. Concurrent, Mopuri et al.[29] devised a feature loss\nfunction to render the universal adversarial perturbation to\ndisrupt the intermediate feature distributions. After that, a line\nof universal perturbation attack methods is proposed, such as\nreducing the requirement of large-scale labeled training sam-\nples [30], [31], improving the transferability across different\nmodels [32].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.3**l== 0.1**r== 0.5**\nUnlike optimizing the adversarial perturbation, some re-\nsearchers attempt to search the sensitive location where the\nmodel is most vulnerable. Yang et al. [25] extracted the class-\nspecific textures by clustering Gram matrix of intermediate\nlayers, which are used to paste on the image for realizing\nadversarial attack, in which the paste location is obtained by\nperforming reinforcement learning. Dong et al. [33] observed\nthat natural objects under specific viewpoints in the real\nworld are easily misrecognition by the model. To find such\nadversarial viewpoints, the author optimized the camera trans-\nformation (i.e., location and orientation) that made the model\nmisclassification, then used the neural radiance field (NeRF) to\ngenerate realistic images based on that camera transformation.\nHowever, the above black-box attacks need to optimize the\nadversarial perturbation for each input, which is impractical.\nTo generate universal adversarial perturbation, Ghosh et al.\n[34] proposed a novel black-box method to craft the universal\nadversarial perturbation against image classification tasks, but\ntheir method can not be physically deployed. The universal\nadversarial perturbation against the object detector under the\nblack-box setting remains unexplored.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nB. Physical adversarial attacks\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nThe physical adversarial attacks can be divided into sticker\n(patch)-based or camouflage-based [35]. Sticker-based attack\nmethods are designed to optimize an image sticker with the\nadversarial pattern, which will be manufactured (e.g., printed)\nand then deployed (e.g., hung [10] or pasted [36], [37], [18])\non the object in the physical world. Thys et al.[10] developed\na patch-based attack against the pedestrian detector. Huang\net al. [11] proposed to optimize a universal adversarial patch\nwith the initial natural image (i.e., dog), which is then printed\nout and pasted on the object repeatedly. Hu et al.[37] used\na generative model to engender a natural adversarial patch to\nattack the pedestrian detector. Wei et al. [19] demonstrated\nthe facial recognition model is susceptible to natural stickers.\nThe sticker-based attacks show their limitation in multi-view\nangles. In contrast, camouflage-based attack methods were\ndevised to optimize the UV texture of the 3D object directly,\nwhich is then wrapped over the surface of the 3D object,\nachieving better multi-view angle attack performance. Zhang\net al. [38] devised a clone network to mimic the render-\ndetection process as the physical render is not differentiable,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.1**l== 0.5**r== 0.1**\nthen optimized the UV texture of the 3D object via white-\nbox attacks. Wang et al. [12] exploited the neural renderer\nand optimized the partial adversarial camouflage (i.e., vehicle’s\nhood, roof, and side) by the devised attention suppress loss.\nWang et al. [13] took a step further than [12] and proposed a\nfull coverage adversarial camouflage for the complex environ-\nment conditions (e.g., occlusion, multi-view) by maximizing\nthe detector loss. Suryanto et al.[15] proposed an approximate\nrenderer model to wrap the adversarial UV texture over the\nvehicle, which was optimized via gradient descent. Concurrent\nto [15], Duan et al.[14] optimized the UV texture of the\n3D object by maximizing the prediction score of the target\nclass. Most approaches discussed above are white-box attacks\nthat allow the adversary to utilize the target model’s gradient\nto optimize the adversarial perturbation, while the black-box\nattacks are less explored. This work focuses on developing a\nuniversal multi-view black-box attack against object detection\nvia layout optimization.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nIII. PROBLEM STATEMENT\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nIn this section, we first\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nintroduce the general problem\nstatement of adversarial attack against object detection, and\nthen we come up with the problem that this works to solve.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.2**\nA. Adversarial attack against object detection\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\ninclude the coordinate of the center point,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nLet F indicate the trained object detection model to be\nattacked: F : X → Y, where X ∈ RC×H×W (C, H, W are\nthe channel, height, and width of the image) and Y ∈ Rd,\nwhere d=6 for object detection, includes x, y, w, h, F cls, F obj,\nthe former four terms describes the predicted bounding box\nthe width\nthat\nand height of the object, F cls and F obj are the predicted\ncategory and confident score of the object, respectively. In\nobject detection, only the predicted F obj of the object larger\nthan the assigned confident threshold τ is regarded as detected;\notherwise, the object is regarded as undetected. We follow the\nprevious work [12], [13] set the confident threshold τ to 0.5.\nThe goal of adversarial attacks is to optimize a perturbation δ\nthat decreases the F obj until beneath the predefined threshold\nτ , while the perturbation does not arouse the attention of the\nhuman observer. Mathematically, the optimization of pertur-\nbation can be expressed as:\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.2**\ns.t. F obj(x + δ) < τ,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nwhere || · ||p indicates the Lp-norm, which confines δ to the\nLp-norm sphere with radius of ϵ for ensuring the imperceptible\nof the adversarial examples.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\nB. Universal multi-view attack\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nThe perturbation δ form defined in Equation 1 is crucial for\nits physical deployment, such as when δ is the adversarial\npatch,\nis unable to achieve multi-view attacks as they\nreplace the partial pixel of the image with the adversarial\npatch (see Figure 2(a)), ignore the non-plane characteristic of\nthe 3D object. In contrast, we take non-plane characteristics\ninto account and exploit the physical render to implement\n**BLOCK**fs== 8.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nFig. 2. Illustration of sticker-based (a) and render-based (b-e) methods. From\n(b)-(e): (a) texture modified with the character; (b) right side position; (c)\nfront position; (d) left side position. As we can see, only modifying a specific\narea (e.g., “A”) will fail to attack the rendered image (d).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nreasonable placement of image stickers. We wrap the adver-\nsarial UV texture constructed by multiple stickers over the\n3D object via a physical renderer, changing the appearance\nof the 3D object. However, the 3D object has a different\nappearance observed from a different perspective, making a\nsingle adversarial sticker that can not work in multi-view\nconditions, as shown in Figure 2(b)-(e). In this work, we\naim to find a universal adversarial UV texture via the layout\noptimization algorithm, where the adversarial UV texture can\nbe wrapped on the 3D object via the physical renderer and\nfool the object detector under a multi-view scenario.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nFormally, given image stickers δs, which are pasted on\nthe UV texture T of a 3D object with category ygt using\nan applier function A, engender an adversarial UV texture\nTadv (i.e., Tadv = A(T, δs)), which is then wrapped to the\n3D object’s mesh M by a physical renderer R, and output\nmultiple adversarial examples xadv by using different camera\ntransformations θ ∼ Θ, θ contain x, y, z; pitch, yall, roll,\ni.e., xadv = R(M, Tadv; θ). Finally, the optimization object is\nto find appropriate image sticker δs to reduce the objectness\nscore of the object detector for the specific 3D object under\nmulti-view conditions, which can be expressed as\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nEθ∼ΘF obj(R(M, A(T, δs); θ); ygt).\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nIV. METHODOLOGY\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nIn this section, we describe how we model the universal\nadversarial UV texture optimization problem as a circle-\nbased layout optimization problem. Then, we elaborate on the\nproposed random search algorithm.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nRather than optimize the pixel of adversarial stickers, we\nfollow [19] to use the nature image as the adversarial sticker\nand optimize their number, size, and paste position on the UV\ntexture, which can be regarded as the rectangle-based layout\noptimization problem. However, placing multiple rectangle\nstickers in UV texture inevitably causes overlaps, while the\noverlap control of the rectangle image is complexity. To\naddress this issue, we formulate the problem as a circle-\nbased layout optimization, which simplifies the overlap control\nduring optimization. Moreover, the circle-based model can\nreduce the optimization variable, such as three variables (i.e.,\ncenter position and radius) to determine the size and position\nof a sticker, but four variables (i.e., center position, width, and\nlength) are required for the original rectangle-based model.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nBased on the aforementioned discussion, adversarial stickers\nδs can be determined by the center position p(px, py) and\nradius r. For multi-view attacks, we use n stickers to modify\nthe UV texture, ensuring each side of the vehicle’s appearance\nis modified. We use L to indicate the sticker layout represented\nby n sticker. Thus, A(T, δs) is reformulated as A(T, n, p, r),\nindicating that place n stickers with radius r at location p on\nthe UV texture T . Note that we aim to find the optimal sticker\nlayout L to construct the universal adversarial UV texture\nTadv, so adversarial stickers and Tadv refer to the same thing,\nand we adopt Tadv as following for simplicity. Finally, the\nlayout optimization problem is expressed as follows.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\nfind Tadv\nmin Eθ∼ΘF obj(R(M, A(T, n, p, r); θ); ygt)\ns.t. nmin ≤ n ≤ nmax\nrmin ≤ r ≤ rmax\np ∈ Ω\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nwhere nmin, nmax are the minimum and maximum allowable\nnumber of stickers in the UV texture, rmin and rmax are the\nlower and upper bound of the radius, which is determined by\nthe area ratio of the sticker to UV texture; Ω refers to the\nregion that allows for painting circles realized by constraints.\nMoreover, modificating the interior part of UV textures can\nnot alter the 3D object’s appearance (see Figure 4(b)). For the\nselection of stickers, not only the natural image can be the\nsticker, but also the pure color block(namely base elements).\nFigure 3 describes the pipeline of the proposed method. To\naddress the layout optimization problem, we adopt the random\nsearch algorithm to find the optimal Tadv, which will be\nintroduced as follows.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nB. Random Search for Universal Adversarial Texture\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nIn this section, we elaborate on how we use the random\nsearch algorithm to find the universal adversarial\ntexture\nfor multi-view attacks represented by a circle-based layout\noptimization problem defined in Equation (3), including layout\ninitialization and layout optimization.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\n1) Layout initialization: We treat the construction of ad-\nversarial UV texture via adversarial stickers as the layout\ninitialization, where the layout element is the sticker (e.g.,\nsticker image or pure color image). More specifically, we first\nrandomly sample the circle number n from the [nmin, nmax].\nFor each circle, we obtain the circle radius r determined by the\npredefined allowable modification area, followed by randomly\nsampling the circle’s center (x, y). Concretely, we bound the\nupper bound of the circle’s area by exploiting the ratio a of the\ncircle’s area to the UV texture’s area A, such that we can get\nA ∗ a where the a should not exceed 10\nthe circle radius by\npercent. In the placement stage represented in A, each circle\nshould satisfy the overlap and mask constraint to make the\nplacement coincidence with physical deployment, which will\nbe discussed below.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nOverlap constraint. Overlap caused by multiple stickers\ncan be easily solved by the circle-based layout. Specifically,\nwe control the overlap by ensuring each spawn circle satisfies\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFig. 3. Overview of the proposed method. The layout of adversarial patches in UV texture is optimized by choosing from the base elements (e.g., colored\ncircle or square) or image sticker pool through layout constraints. With a physical renderer R, the adversarial texture Tadv is wrapped over the mesh M of\nthe 3D object and rendered to adversarial images xadv, which are fed into the object detector F for calculating fitness.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nAlgorithm 1 Layout checkout\nInput:current circle lcur, recorded circle L, texture mask Ω,\nallowable overlap threshold γ\nOutput: Boolean\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n(a) Overlap control\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n(b) Mask constraint\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFig. 4. Layout constraints. From left to right: (a) Overlap control: avoid the\noverlap of the circle; (b) Mask constraint: confine the circle in the appearance\nregion of the 3D object.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nthe following rule: the Euclidean distance of the circle’s center\nbetween the new circle (xi, yi) and all recorded circles (x, y)\nis larger than the sum of their radius, which can be formulated\nas follows.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n(xi − xj)2 + (yi − yj)2 ≥ γ(ri + rj), ∀j ∈ {1, .., |x|} ,\n(4)\nwhere |x| denotes the number of recorded circles, and the γ\ncontrols the overlap magnitude of two circles, which is set to\n1. Figure 4 (a) provides the visualization explanation.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nMask constraint. Given the fact that some region in UV\ntexture does not appear on the surface of the 3D object, such\nas vehicle interiors. To avoid the invalid search, we make a\nbinary mask Ω to separate whether the region can appear on\nthe appearance, where 1 in Ω denotes the region that allows\nbeing painted the circle (represented in white), while 0 does\nnot (represented in black), Figure 4 (b) illustrates the mask\nconstraint.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nTo obtain the n circle to construct\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nthe adversarial UV\ntexture, we record the circle whose center is located in the\nmask Ω until sufficient circles are obtained. Meanwhile, every\ncircle has to satisfy the overlap constraints. Algorithm 1\ndescribes the process of layout constraints. Once the circle\nlayout L constructed, we replace each circle with the image\nto obtain the final adversarial UV texture. In this stage, we\nrandomly select an image from the image pool for each circle.\nThen, we adopt the following strategy to place them on the\nUV texture: the size of the image is adjusted in terms of\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.5**r== 0.3**\n1: xi, yi, ri ← lcur\n2: if Ω(x, y) = 0\nreturn false\n3:\n4: for l in L do\n5:\n6:\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.5**l== 0.5**r== 0.4**\n7:\n8:\n9:\n10: end for\n11: return true\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.6**r== 0.2**\nxj, yj, rj ← l\ndr = ri + rj\ndc = (xi − xj)2 + (yi − yj)2\nif dc ≤ dr ∗ γ\nreturn false\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nAlgorithm 2 Circle layout initialization\nInput: texture area A, texture mask Ω, allowable number\nof patch [nmin, nmax] and overlap threshold γ, are ratio\n[amin, amax]\nOutput: circle layout L\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n1: Randomly sample n from [nmin, nmax]\n2: Initial circle layout L\n3: for itr = i, ..., n do\n4:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\nRandomly sample ratio a from [amin, amax], where\namin, amax are the lower and upper bound of area ratio\n√\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nCalculate the radius r by\nRandomly sample circle center coordinates (x, y)\nif Layout check(x, y, r, L, Ω, γ)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\n▷ Algorithm 1\n**BLOCK**fs== 8.0**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.4**\n8:\n9:\n10:\n11: end for\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nResample\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nthe size of the circle’s largest inscribed square, where the\n√\n2r, as illustrated in Figure 5.\nside length is determined by\nMoreover, we adjust the image’s orientation for a reasonable\npurpose. For example, the rendered image without adjusting\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nAlgorithm 4 Important-aware layout optimization\nInput: circle layout L, texture T , image pool S\nOutput: texture Tadv\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\n1: Tadv ← T\n2: for l\n3:\n4:\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.2**l== 0.5**r== 0.4**\n5:\n6:\n7:\n8: end for\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nx, y, r ← l\nSl ← G(sl) = f (Tadv) − f (sl ∪ Tadv), sl ∈ S\nif p ≤ 0.5\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\n▷ Random transformation\nRotate s by randomly select angle from [−30◦, 30◦]\nReplace the circle with image s at the coordinate (x, y)\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThere are two termination conditions: either achieving the\nmax iteration number or the Tadv can fool the object detector\nF on all camera transformations Θ. Algorithm 3 describes the\noptimization of the adversarial UV texture.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nC. Important-aware selection strategy\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nIn Section IV-B, we adopt a randomly selected strategy\nto choose an image from the image pool, which may ignore\nthe optimal image for the specific position, making it fails to\nobtain the best attack performance. To address this issue, we\nintroduce an important-aware layout strategy. Specifically, we\nsearch for the best image from the image pool for each circle\nin the layout. With the important-aware selection strategy, we\ncan find a better layout of the image sticker and obtain a higher\nattack performance. Mathematically, given the image sticker\npool S, the best adversarial texture Tadv can be obtained by\nsolving the following problem.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nG(si) = f (Tadv) − f (si ∪ Tadv), si ∈ S\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nwhere G(si) is the gain function, we use f (Tadv) to de-\nnotes the fitness score of the adversarial texture Tadv, and\nf (si∪Tadv) is the fitness score of adversarial texture Tadv with\nthe natural image si. By maximizing G(si) for each layout\nposition, we can obtain the optimal layout that could drop the\nfitness score the most.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nMoreover, before painting the image sticker on the texture,\nwe introduce a random transform to improve the diversification\nby randomly rotating the image sticker within [−30◦, 30◦]. Al-\ngorithm 4 describes the generation method of the naturalistic-\naware adversarial texture.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nV. PHOTO-REALISTIC EVALUATION TOOL\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nCurrently, in physical adversarial attacks against object de-\ntectors, the lack of a uniform platform to assess the attack per-\nformance makes it hard to reproduce the existing approach due\nto the actual environmental discrepancy between the method\nand their follower who want to reproduce the physical attack.\nMoreover, the researcher usually evaluates physical attacks\non the specific environment, while it is hard to reproduce by\nothers. To address this issue, we presented a novel evaluation\ntool based on the photo-realistic simulator (i.e., Unreal Engine)\nto evaluate the attack performance of different attacks. Based\non the simulator, we provide several evaluated backgrounds\nbased on the scene (e.g., Landscape) provided by the simulator.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nFig. 5. Illustration of replacing the circle with other elements (e.g., rectangle\nand nature image) in layout optimization. From left to right: left: circle and\nthe largest inscribed square; middle: pure circle layout; right: natural image\nlayout.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nAlgorithm 3 Adversarial UV texture optimization\nInput: object detector F , physical renderer R, camera trans-\nformation distribution Θ, the 3D object of category yt com-\nprise of mesh M and texture T , mask constraint Ω, maximum\niterative step ItrM AX\nOutput: adversarial texture T ∗\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nI(Fcls(R(M, T ; θ)) = yt)\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\n1: Tadv ← T , Lbest ← []\n2: fbest ← \nθ∈Θ\n3: for itr = 1, ..., ItrM AX do\n4:\n5:\n6:\n7:\n8:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nObtain circle layout L with Algorithm 2\nUpdate adversarial texture Tadv with circle layout L\ncalculate fcur ← \nI(F cls(R(M, Tadv; θ)) = yt)\nif fcur ≤ fbest\nfbest ← fcur\nT ∗\nadv ← Tadv\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n9:\n10:\n11:\n12: end for\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nif fbest = 0\nbreak\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nthe image sticker is odd (inverted image) in the real world\n(see Figure 2 (c)). Therefore, we designed a criterion to adjust\nthe orientation of the sticker. Specifically, the sticker image\nrendered on the left side of the vehicle will be rotated 90\ndegrees clockwise, while the right side will be rotated 90\ndegrees counterclockwise. In summary, the whole process of\nlayout initialization is described in Algorithm 2.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n2) Layout Optimization: Recall that our goal is to find a\nuniversal adversarial texture Tadv, which is wrapped over the\n3D object and rendered into adversarial examples xadv via\nphysical renderer R under different camera positions Θ. At\nthe same time, the objectness score of object detector F on\nthe generated adversarial examples beneath the threshold τ .\nTherefore, we minimize the objectness score over rendered\nadversarial examples from different perspectives by optimizing\nthe adversarial UV texture. Specifically, we devise the fitness\nscore function f as follows.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\nI(F obj(R(M, A(Tadv, n, p, r); θ); yt) ≤ τ ),\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nwhere F obj(·) denotes the objectness score of the category yt\nthe object detector F ; I(·) = 1 if true, and I(·) = 0 if false.\nFor the selection of Θ, we sample the image per 2◦ over 360◦\nand keep other settings fixed, collecting 176 images, which\nmeans that the universal adversarial UV texture Tadv should\nmaintain aggression on these images.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\n3) Evaluation Metric: To quantify the performance of the\nproposed method, we follow the prior works [38], [16], [12]\nto adopt the P@0.5 as the measurement metric for vehicle\ndetection and warplane detection. P@0.5 refers to the ratio of\nimages correctly detected after attacks to the total test number\nwhen the confidence threshold is set to 0.5, which indicates the\nlower P@0.5, the stronger the attack. For TSR, we adopt the\nattack success rate (ASR) as the evaluation metric to represent\nthe proposed method against the TSR model, indicating the\nhigher the ASR, the better.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n4) Implementation Details: The physical renderer is the\ncrucial component of the proposed method, which wraps\nthe optimized adversarial UV texture over the 3D object.\nIn this paper, we adopt the widely used physical renderer\nopen3d library [47] as the physical renderer. Unless otherwise\nspecified, we adopt the following default parameters for all\nexperiments, nmin and nmax are set to 5 and 15 for vehicle\nand warplane tasks, and 3 and 8 are for the traffic sign\nrecognition task. a is uniformly sampled from 0.001 and 0.1\nfor all tasks. The image numbers of the image pool are set to\n30. The maximum iteration number ItrM AX set to 10000.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.5**r== 0.3**\nB. Comparison result\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.5**l== 0.5**r== 0.1**\nTo investigate the effectiveness of the proposed method, we\nperform the attack by wrapping the adversarial texture stuck\nwith the optimized image sticker layout on the vehicle. For\ncomparison, we get inspiration from RP2 [48] and SquareAt-\ntack [26] and then modify them as the baseline method. RP2\n[48] stuck the white or black image patch on the 2D traffic sign\nimage for deceiving TSR model. In contrast, SquareAttack\n[26] is designed to optimize the invisible square adversarial\nperturbation by adding the pure color square block to fool the\nimage classifier. Although these works achieve certain success\nin the original task, they are hardly applied to our tasks involv-\ning 2D to 3D transformation. Therefore, we combine the pro-\nposed method with their elements (e.g., square and white-block\npatch) to optimize the adversarial texture, and we treat these\ntwo methods as baseline approaches. Specifically, in our work,\nwe replace the circle area with their image patch to mimic their\nmethods, called BlackWhite [48] and SquareAttack [26]. We\nalso compare the proposed method with existing adversarial\nattacks against object detectors, which include CAMOU [38],\nUPC [11], ER [16], DAS [12], FCA [13], CAC [14], and DTA\n[15]. Note that these methods are white-box attacks, so we\nonly use their generated adversarial pattern or camouflage to\nconstruct the adversarial texture to perform black-box attacks\nfor comparison. We treat\nthe pure circle element as our\nbaseline, and we select the adversarial texture generated by\nthe proposed method using natural images (i.e., AdvPatch,\nAnimal, and Cartoon) with the best attack performance for\nevaluation. For the adversarial texture constructed by natural\nimages, we utilize the adversarial patch generated by the\nexisting approaches, which may still be aggressive based on\nadversarial perturbation with transferability. In addition, we\nalso adopt two public available image categories containing\ncartoon images and animal images. With a physical renderer,\nwe wrap the optimal adversarial texture over the vehicle and\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nFig. 6. The pipeline of the proposed evaluation tool. The tool requires the\n3D object and the corresponding UV texture to generate multi-view simulated\nimages.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nFor each background, we construct a camera rail around the\ntarget 3D object wrapped with adversarial texture, and then a\ncamera is bound to the camera rail and towards the target\nobject. Finally, a video sequence is recorded to construct\nthe multi-view images, which are then used to assess the\nattack performance. The generated adversarial (UV) texture\nand the 3D object model are required to use the tool. With\nthe proposed tool, anyone could reimplement other methods\nand make comparisons fairly. Figure 6 describes the basic\npipeline to use the evaluation tool. Therefore, we treat the\nsimulated adversarial attack as the physical adversarial attack\nin this work.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nVI. EXPERIMENTS\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nIn this section, we first introduce the experiment settings.\nThen, we evaluate the proposed method on different object\ndetectors under digital and physical conditions. We followed\nby conducting the ablation study on the influence of the image\nnumber of the seed image pool and the important-aware layout\noptimization. Finally, we extend our method to the warplane\ndetection and traffic sign recognition (TSR) task.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nA. Settings\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\n1) Target models: We evaluate the proposed method of\nvehicle detection and warplane detection on the following\nfour object detectors: two one-stage (i.e., YOLOv5x [39], and\nRetinaNet [40]) and two-stage detectors(i.e., Faster RCNN\n[41], and Mask RCNN [42]), provided by PyTorch [43]. These\ndetectors are trained on the MS COCO dataset [44], which\ncontains 80 categories. Moreover, We further evaluate the\nperformance of the proposed method on two widely used TSR\nmodels: GTSRB CNN and LISA CNN. We follow [17] to\nresize the image resolution from 28 × 28 to 128 × 128 when\ntraining two models on GTSRB [45] and LISA [46] datasets,\nwhich obtain 95.06% and 100% accuracy on the test data,\nrespectively. The reason for adjusting the resolution is that\nthe naturalistic image will be severely distorted when resizing\nhigh-resolution images to low-resolution images, which makes\nit hard to achieve higher attack performance.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n2) Evaluation Dataset: We collect 176 images for the\nvehicle detection task with sampling per 2◦ until covered\n360◦, where 160 images for the warplane detection task.\nRegarding the TSR task, we randomly select 100 naturally-\nlooking “STOP” sign images from the corresponding dataset.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.2**l== 0.1**r== 0.5**\nThe experiment results are listed in Table I. As we can ob-\nserve, on the one hand, the proposed method (i.e., Circle) out-\nperforms the baseline method BlackWhite and SquareAttack\nby 16.76% and 4.54% in terms of the average degradation of\nP@0.5. At the same time, the pure color elements are unable to\nobtain better attack performance. On the other hand, AdvPatch\noutperforms all comparison methods, achieving a maximum\ndecrease of 74.29% in terms of the average P@0.5 over four\ndetectors. Besides AdvPatch, although Cartoon falls behind\nthe CAC, the discrepancy is small (i.e., 6.25%). The reason\nmay be attributed to CAC being designed to generate the full\ncoverage adversarial texture under the white-box attack setting.\nHowever, the adversarial texture generated by Cartoon is more\nstealthiness than CAC. Moreover, we observe that approaches\ndevised to generate full coverage adversarial texture (i.e., FCA\nand CAC) exhibit better transferability than other methods\n(except for AdvPatch), particularly for attacking two-stage\ndetectors (i.e., Faster RCNN and Mask RCNN), where the\naverage degradation caused by FCA and CAC are 55.12% and\n54.26% in terms of P@0.5, surpass other methods in a large\nmargin. Such observation indicates the advantage of the full\ncoverage adversarial attack method in multiview conditions.\nAdditionally, we find an interesting phenomenon that some\nadversarial textures would boost the detection performance of\nthe detector, such as ER boosting the detect performance by\n0.57% for Faster RCNN and DAS and DTA enhancing the\ndetect performance by 5.68% for RetinaNet.\nRegarding the image-based adversarial\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\nthe Ad-\nvPatch obtains the best attack performance, achieving the\nmaximum degradation on P@0.5 on RetinaNet by 88.07%.\nThe possible reason is that AdvPatch naturally contains adver-\nsarially due to the transferability characteristic of adversarial\nperturbation, despite not being trained on the used target\ndetector. Although Animal performs better than the baseline\nmethods on average, it’s falling behind the AdvPatch and\nCartoon, which indicates that the content of the images has\nalso impacted the attack performance. On the other hand,\nwe observe the robustness discrepancy of different detectors\nvarying. One-stage detectors display weaker than two-stage\ndetectors under the proposed attack. Specifically, the average\nP@0.5 degradation of YOLOv5x and RetinaNet are 57.01%\nand 60.8%, while Faster RCNN and Mask RCNN are 40.72%\nand 21.88%, respectively.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.4**r== 0.6**\ntexture,\n**BLOCK**fs== 8.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFig. 7. Attack performance changes with direction. Zoom in for details.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nTABLE I\nCOMPARISON RESULTS OF VARIOUS digital attacks IN TERMS OF P@0.5\n(%). BOLD ITEM HIGHLIGHTS THE BEST RESULT, WHERE THE ITEM IN\nTHE BRACKET DENOTES THE GAIN OF P@0.5.\n**BLOCK**fs== 7.0**p== 7.0**b== 0.5**t== 0.4**l== 0.5**r== 0.4**\nRaw\nBlackWhite [48]\nSquareAttack [26]\nCAMOU [38]\nUPC [11]\nER[16]\nDAS [12]\nFCA [13]\nCAC [14]\nDTA [15]\nCircle\nAdvPatch\nAnimal\nCartoon\n**BLOCK**fs== 7.0**p== 7.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\nYOLOv5x\n87.50\n61.93(↓25.57)\n41.48(↓46.02)\n3.98(↓83.52)\n27.84(↓59.66)\n5.68(↓81.82)\n17.05(↓70.45)\n45.45(↓42.05)\n10.23(↓77.27)\n17.05(↓70.45)\n26.7(↓60.8)\n2.84(↓84.66)\n23.86(↓63.64)\n5.11(↓82.39)\n**BLOCK**fs== 7.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.1**\nFaster RCNN Mask RCNN\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nWe also provide some adversarial examples rendered by\ndifferent viewpoints in Figure 8. As we can see, the adver-\nsarial examples generated by the proposed method can fool\nthe detector into making the wrong detection in most cases\n(11/12). In contrast, comparison methods fail to deceive the\ndetector. More importantly, compared with the mosaic-like\nadversarial texture generated by comparison methods [38],\n[16], the proposed method displays a better naturalness and\nstealthiness, which increases the risk of the proposed method\nwhen applied to the real world as people tend to ignore\nthe security risk of scrawl painting, and result in significant\naccidents.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.5**r== 0.3**\nC. Simulated adversarial attack\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nTo analyze the influence of rendered viewpoints on attack\nperformance, we regroup the rendered image into eight groups\nin terms of the rendered vehicle’s heading,\nthen statistics\nthe change of P@0.5. Figure 7 illustrates the evaluation\nresults. We can observe that adversarial examples in the\nwest, southeast, and southwest groups exhibit worse attack\nperformance, where the P@0.5 are 29.88%, 47.31%, and\n39.62%, respectively. In contrast, the P@0.5 of the other five\ngroups is less than 20%. One possible reason is that the images\nin the west, southeast, and southwest display the strong vehicle\ncontour characteristic. By contrast, the adversarial examples\nin the northeast group display the best attack performance,\nresulting in 91.54% degradation of detection performance.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIn this part, we conduct the simulated adversarial attack\nexperiment for vehicle object detection with the decided\nevaluated tool mentioned in Section V. Specifically, we record\na ten-second video with frame per second (FPS) 30 and extract\n300 images for evaluation. Table II lists the quantitative result\nof different adversarial textures for vehicle detection. As we\ncan observe, the AdvPatch obtains superior attack performance\nexcept for CAC on the average decrease of P@0.5 by 30.83%\non four detectors. The possible reason is that CAC optimized\nthe adversarial texture by exploiting the information of target\nmodels on a large-scale dataset. In contrast, the proposed\nblack-box method is optimized on fewer images. On the other\nhand, the attack performance of our method (i.e., Circle and\n**BLOCK**fs== 8.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nFig. 8. Visualization of various adversarial textured vehicles (“truck”). The detection results are given by YOLOv5x. Zoom in for details.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nFig. 9. Visualization of various adversarial textured vehicles (“truck”) in a simulated environment. The detection results are given by YOLOv5x. Zoom in\nfor details.\n**BLOCK**fs== 6.4**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nTABLE II\nCOMPARISON RESULTS OF simulated attacks IN TERMS OF P@0.5 (%).\nBOLD ITEM HIGHLIGHTS THE BEST RESULT FOR COMPARISON METHODS\nAND PROPOSED METHOD RESPECTIVELY, WHERE THE ITEM IN THE\nBRACKET DENOTES THE DEROGATION OF P@0.5.\n**BLOCK**fs== 7.0**p== 8.0**b== 0.2**t== 0.6**l== 0.1**r== 0.8**\nRAW\nBlackWhite [48]\nSquareAttack [26]\nCAMOU [38]\nUPC [11]\nER[16]\nDAS [12]\nFCA [13]\nCAC [14]\nDTA [15]\nCircle\nAdvPatch\nAnimals\nCartoon\n**BLOCK**fs== 7.0**p== 8.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nFaster RCNN Mask RCNN\n**BLOCK**fs== 7.0**p== 8.0**b== 0.2**t== 0.6**l== 0.4**r== 0.5**\nRetinaNet\n87.33\n81.33(↓ 6.00)\n74.00(↓13.33)\n64.33(↓23.00)\n68.67(↓18.66)\n71.33(↓16.00)\n66.67(↓20.66)\n45.00(↓42.33)\n14.00(↓73.33)\n76.00(↓11.33)\n63.33(↓24.00)\n47.67(↓39.66)\n64.00(↓23.33)\n66.33(↓21.00)\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nCartoon) is on par with the existing approaches, indicating the\nproposed method’s effectiveness.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nAdditionally, the YOLOv5x shows vulnerable to adversarial\ntexture attacks than other methods. Specifically, the average\nP@0.5 under various attack methods of YOLOv5x is 38.64%,\nwhile Faster RCNN, Mask RCNN, and RetinaNet are 80.55%,\n84.42%, and 63.26%, respectively. Such findings indicate the\nrobustness discrepancy across the detector, which can help\npeople design more robust architecture. Figure 9 illustrated\nthe simulated adversarial examples.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nFig. 10. Effectiveness of local search on attack performance.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.7**l== 0.5**r== 0.4**\nD. Ablation study\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nIn this part, we exhaustively investigate the influence of the\nfollowing factors on the attack performance: important-aware\nselection strategy, the number of image pools, and the devised\nconstraints composed of masking and overlap control.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nto seek the best\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n1) Important-aware selection strategy: The random search\nmay fail\nimage patch for the specificity\nposition, while the important-aware strategy is used to solve\nthis problem. To study the effectiveness of the important-aware\nstrategy, we perform experiments using the image pool of 20\nimages (i.e., |S| = 20). Figure 10 depicts the comparison\nresults. We can conclude that the local search can boost the\nattack performance of the proposed method. Specifically, we\nobtain the average gains of model performance degradation by\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.1**l== 0.5**r== 0.1**\nexperiment settings under the following constraints composed:\nwithout (w/o) Mask&Overlap, w/o Overlap, and the complete\nmethod. Quantitative and qualitative results are illustrated in\nFigure 12. As we can observe, on the one hand, the complete\nmethod not only convergences fast and obtains the best attack\nperformance at the same iteration number. Specifically, the\ncomplete method degrades the detector’s performance by\n67.05% at the 18-th iteration, while w/o Mask&Overlap or\nw/o Overlap degrades by 57.95% and 55.11%, respectively.\nMoreover,\nthe complete method deteriorates the detector’s\nperformance by 80.68% at the 500-th iteration, while the other\ntwo are 57.95% and 72.73%. On the other hand, the w/o Over-\nlap&Mask place the image patch on the non-appearance region\nof texture, and w/o Overlap results in overlap phenomena. By\ncontrast, the complete method obtains the rational layout of\nimage patches.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nVII. EXTENSION OF THE PROPOSED METHOD\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nIn this section, we investigate the flexibility of the proposed\nmethod. Specifically, we perform two additional experiments,\ni.e., the warplane detection task and the traffic sign recognition\ntask. The former is used to investigate whether the proposed\nmethod can be applied to find the optimal adversarial UV\ntexture to the 3D model that has no explicit UV texture, while\nthe latter is used to investigate whether the proposed method\ncan be applied to find the optimal adversarial layout of image\nsticker on 2D images.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.2**\nA. Extend to warplane detection task\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nTo investigate the extensibility of the proposed method, we\noptimize the adversarial texture for no UV texture 3D model.\nSpecifically, we first construct a base UV texture initialized\nwith pure color. Then, we optimize the optimal layout of the\nelements on the base UV for adversarially. We discard the\nmask constraint as the 3D model has no UV texture. In this\npart, we collect 160 images sampled from different viewpoints\nas the test set, and the number of the image pool is 40. The\nevaluation results are listed in Table III, as we can observe,\non the one hand, the AdvPatch achieves the best result against\nall models (i.e., YOLOv5x, Faster RCNN, Mask RCNN, and\nRetinaNet), obtaining the maximum drop in terms of P@0.5\nby 83.75%, 82.5%, 78.75%, and 82.5%, respectively. On the\nother hand, the average decrease in terms of P@0.5 of four\ndetectors exceeds 50%, i.e., 54.53% and 54.69% for Circle\nand Cartoon. The experiment result shows the effectiveness of\nthe proposed method in generating the adversarial texture for\nthe none-UV texture 3D model.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nFurthermore, we also conduct\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nthe simulated adversarial\nattack. Specifically, we use the evaluated tool to collect 301\nimages for evaluation. The evaluation results are illustrated in\nTable IV. As we can see, AdvPatch achieves the best attack\nperformance on four detectors, where the average decrease of\nP@0.5 is 90.28%. Moreover, the adversarial texture optimized\non the pure color displays superior attack performance (i.e.,\nthe average drop of P@0.5 is 16.53% and 19.52% for Square\nand Circle) than Animal (0.42%) or Cartoon (13.29%). The\npossible reason is that the warplane model has no UV texture,\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFig. 11. Effectiveness of varying image count of image pools on attack\nperformance.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nw/o Overlap & Mask w/o Overlap\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nOverlap & Mask\n**BLOCK**fs== 8.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFig. 12. Effectiveness of proposed variable constraints on attack performance.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n10%. Meanwhile, we also observe that the important-aware\nstrategy has minimum impact on BlackWhite, and Circle,\nwhich can be attributed to the pure color no content. However,\nthe important-aware strategy obtains the attack improvement\nwith the search time cost. Therefore, we can trade off both by\nswitching to the important-aware strategy or not.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\n2) Number of image pools: Intuitively, enlarging the search\nspace (i.e., diversity of the image pool) could benefit\nin\nobtaining a better solution. To verify this conjecture, we\ninvestigate the influence of different\nimage numbers (i.e.,\n20, 30, 40, 50) in the image pool on attack performance.\nFigure 11 describe the evaluation results. We can observe no\nobvious discrepancies when adopting the different number of\nimages pool. For example, the standard deviation of YOLOv5\non AdvPatch, Animal, and Cartoon on the different image\nnumbers of image pools is 3.88, 3.76, and 2.46, respectively,\nwhich indicates that increasing the image number of the image\npool can not bring significant improvement. Besides, we find\nan interesting phenomenon that the one-stage detectors are\nmore fragile than the two-stage detectors under the proposed\nattack, which encourage people to pay more attention to the\nrobustness of the one-stage detector.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n3) Effectiveness of the proposed constraint conditions:\nThe effectiveness and efficiency of the proposed method have\nbeen influenced by the search space, which is constrained by\nthe proposed two constraint conditions. Thus, we optimize\nthe adversarial texture against the YOLOv5 with the default\n**BLOCK**fs== 6.4**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nTABLE III\nEVALUATION RESULTS OF VARIOUS digital attacks IN TERMS OF P@0.5\n(%) FOR warplane. BOLD ITEM HIGHLIGHTS THE BEST RESULT, WHERE\nTHE ITEM IN THE BRACKET DENOTES THE GAIN OF P@0.5.\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nRAW\nBlackWhite [48]\nSquareAttack [26]\nCircle\nAdvPatch\nAnimal\nCartoon\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.2**l== 0.2**r== 0.7**\nYOLOv5x\n95.00\n81.25(↓13.75)\n48.75(↓46.25)\n40.63(↓54.37)\n11.25(↓83.75)\n61.88(↓33.12)\n33.13(↓61.87)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.2**l== 0.3**r== 0.7**\nFasterRCNN\n91.25\n57.50 (↓33.75)\n24.38(↓66.87)\n31.88(↓59.37)\n8.75 (↓82.50)\n49.38(↓41.87)\n40.63(↓50.62)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.2**l== 0.4**r== 0.6**\nMaskRCNN\n88.75\n50.63(↓38.12)\n31.25(↓57.5)\n31.88(↓56.87)\n10.00 (↓78.75)\n50.63(↓38.12)\n46.88(↓41.87)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.2**l== 0.4**r== 0.5**\nRetinaNet\n86.88\n39.38(↓47.50)\n33.13(↓53.75)\n39.38(↓47.50)\n4.38 (↓82.50)\n48.75(↓38.13)\n22.50(↓64.38)\n**BLOCK**fs== 6.4**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nTABLE IV\nEVALUATION RESULTS OF VARIOUS simulated attacks IN TERMS OF P@0.5\n(%) FOR warplane. BOLD ITEM HIGHLIGHTS THE BEST RESULT, WHERE\nTHE ITEM IN THE BRACKET DENOTES THE GAIN OF P@0.5.\n**BLOCK**fs== 7.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.8**\nRAW\nBlackWhite [48]\nSquareAttack [26]\nCircle\nAdvPatch\nAnimal\nCartoon\n**BLOCK**fs== 7.0**p== 10.0**b== 0.6**t== 0.3**l== 0.2**r== 0.7**\nYOLOv5x\n100.0\n98.34(↓1.66)\n58.80(↓41.20)\n61.13(↓38.87)\n11.96(↓88.04)\n97.34(↓ 2.66)\n76.08(↓23.92)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.6**t== 0.3**l== 0.3**r== 0.7**\nFasterRCNN\n100.0\n99.00(↓33.75)\n22.26(↓77.74)\n32.56(↓67.44)\n9.63 (↓90.37)\n99.67(↓ 0.33)\n86.71(↓13.29)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.6**t== 0.3**l== 0.4**r== 0.6**\nMaskRCNN\n100.0\n99.67(↓ 0.33)\n69.10(↓30.90)\n79.40(↓20.60)\n4.32 (↓95.68)\n100.0(↓38.12)\n88.04(↓11.96)\n**BLOCK**fs== 7.0**p== 10.0**b== 0.6**t== 0.3**l== 0.4**r== 0.5**\nRetinaNet\n100.0\n99.67(↓ 0.33)\n82.06(↓17.94)\n83.06(↓16.94)\n12.96 (↓87.04)\n99.00(↓ 1.00)\n96.01(↓ 3.99)\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFig. 13. Examples generated by different adversarial textures in a simulated\nenvironment against YOLOv5x.\n**BLOCK**fs== 6.4**p== 10.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nTABLE V\nEVALUATION RESULTS OF OUR METHOD ON TRAFFIC SIGN RECOGNITION\nIN TERMS OF MODEL’S ASR.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nGTSRB CNN\nLISA CNN\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nresulting in severe distortion of the natural\nimage during\npasting on the customed texture. In contrast, the adversarial\ntexture optimized by the pure color exhibits better attack\nperformance due to its small image distortion. Additionally,\nFigure 13 provides some simulated examples.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nB. Extend to traffic sign recognition\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nWe extend our method to attack the traffic sign recognition\n(TSR) model to demonstrate not only the proposed method\ncan seek the optimal adversarial layout of UV texture for the\n3D objects but is also applicable to 2D images. Specifically,\nwe first train two widely used TSR models consisting of\nLISA CNN and GTSRB CNN. Note that, we only focus\non the “STOP” sign category. Our goal is to optimize the\nuniversal adversarial image patch layout for the “STOP” sign\nto mislead the TSR model to output the wrong result, namely\nthe untargeted attack. We select 100 visually recognizable\n“STOP” sign images from the test dataset for evaluation.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nThe evaluation results are reported in Table V regarding\nattack success rate (ASR). As we can see, the pure color\nbaselines outperform the image-based methods, where the\nformer achieves the average ASR of 94.5%, and the latter is\n75.33%. We speculate the discrepancy between the TSR model\nand the vehicle detection model in model architecture and task\nspecificity leads to the gap in attack performance. Moreover,\nthe pure color baselines have bigger search space than the\nimage-based method, which is effective when attacking the\nTSR model. Additionally, we also observe that the AdvPatch\nperforms worse than other methods, which can be attributed\nto the AdvPatch being originally designed to attack object\ndetectors, while TSR is a classification task.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.2**r== 0.6**\nVIII. CONCLUSION\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nIn this paper, we proposed a novel universal multi-view\nblack-box attack against the object detector. Specifically, we\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\ninstead optimize the adversarial layout constructed by multiple\nstickers for a 3D object’s texture, whose rendered images\ncan deceive the object detector from the multi-view scenario.\nMoreover, the image sticker can be arbitrary images, which\nrenders our attack more inconspicuous. To find the adversarial\nlayout, we first model the above problem as a circle-based\nlayout optimization problem and then exploit\nthe random\nsearch algorithm enhanced by the proposed important-aware\nselection strategy to find the optimal sticker layout. Addition-\nally, we proposed a photo-realistic simulator-based evaluation\ntool to assess the UV texture-based attack approaches. Exten-\nsive digital and simulated experiments, as well as extended\nexperiments, suggested the effectiveness and extensibility of\nthe proposed method.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.6**l== 0.7**r== 0.2**\nREFERENCES\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[1] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J.\nGoodfellow, and R. Fergus, “Intriguing properties of neural networks,”\nin 2nd International Conference on Learning Representations, ICLR\n2014, Banff, AB, Canada, April 14-16, 2014, Conference Track\nProceedings, 2014. [Online]. Available: http://arxiv.org/abs/1312.6199\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[2] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards\ndeep learning models resistant to adversarial attacks,” in 6th Interna-\ntional Conference on Learning Representations, ICLR 2018, Vancouver,\nBC, Canada, April 30 - May 3, 2018, Conference Track Proceedings.\nOpenReview.net, 2018.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[3] Y. Dong, F. Liao, T. Pang, H. Su, J. Zhu, X. Hu, and J. Li, “Boosting\nadversarial attacks with momentum,” 2018 IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, pp. 9185–9193, 2018.\n[4] C. Li, H. Wang, J. Zhang, W. Yao, and T. Jiang, “An approximated gra-\ndient sign method using differential evolution for black-box adversarial\nattack,” IEEE Transactions on Evolutionary Computation, pp. 1–1, 2022.\n[5] C. Li, W. Yao, H. Wang, and T. Jiang, “Adaptive momentum variance\nfor attention-guided sparse adversarial attacks,” Pattern Recognition, vol.\n133, p. 108979, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[6] D. Wang, W. Yao, T. Jiang, C. Li, and X. Chen, “Rfla: A stealthy\nreflected light adversarial attack in the physical world,” in Proceedings\nof the IEEE/CVF International Conference on Computer Vision, 2023,\npp. 4455–4465.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[7] I. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing\nadversarial examples,” in International Conference on Learning\nRepresentations, 2015. [Online]. Available: http://arxiv.org/abs/1412.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\n[8] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial machine learning\n**BLOCK**fs== 8.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nat scale,” arXiv preprint arXiv:1611.01236, 2016.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[9] G. Tang, W. Yao, T. Jiang, W. Zhou, Y. Yang, and D. Wang, “Natural\nweather-style black-box adversarial attacks against optical aerial detec-\ntors,” IEEE Transactions on Geoscience and Remote Sensing, vol. 61,\npp. 1–11, 2023.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[10] S. Thys, W. Van Ranst, and T. Goedem´e, “Fooling automated surveil-\nlance cameras: adversarial patches to attack person detection,” in Pro-\nceedings of the IEEE/CVF conference on computer vision and pattern\nrecognition workshops, 2019, pp. 0–0.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[11] L. Huang, C. Gao, Y. Zhou, C. Xie, A. L. Yuille, C. Zou, and\nN. Liu, “Universal physical camouflage attacks on object detectors,”\nin Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2020, pp. 720–729.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[12] J. Wang, A. Liu, Z. Yin, S. Liu, S. Tang, and X. Liu, “Dual attention\nsuppression attack: Generate adversarial camouflage in physical world,”\nin Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2021, pp. 8565–8574.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n[13] D. Wang, T. Jiang, J. Sun, W. Zhou, Z. Gong, X. Zhang, W. Yao,\nand X. Chen, “Fca: Learning a 3d full-coverage vehicle camouflage\nfor multi-view physical adversarial attack,” in Proceedings of the AAAI\nConference on Artificial Intelligence, vol. 36, no. 2, 2022, pp. 2414–\n2422.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n[14] Y. Duan, J. Chen, X. Zhou, J. Zou, Z. He, J. Zhang, W. Zhang, and\nZ. Pan, “Learning coated adversarial camouflages for object detectors,”\nin Proceedings of the Thirty-First International Joint Conference on\nArtificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022,\nL. D. Raedt, Ed., 2022, pp. 891–897.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[15] N. Suryanto, Y. Kim, H. Kang, H. T. Larasati, Y. Yun, T.-T.-H. Le,\nH. Yang, S.-Y. Oh, and H. Kim, “Dta: Physical camouflage attacks using\ndifferentiable transformation network,” in Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition, 2022, pp.\n15 305–15 314.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[16] T. Wu, X. Ning, W. Li, R. Huang, H. Yang, and Y. Wang, “Physical\nadversarial attack on vehicle detector in the carla simulator,” arXiv\npreprint arXiv:2007.16118, 2020.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n[17] A. Liu, X. Liu, J. Fan, Y. Ma, A. Zhang, H. Xie, and D. Tao, “Perceptual-\nsensitive gan for generating adversarial patches,” in Proceedings of the\nAAAI conference on artificial intelligence, vol. 33, no. 01, 2019, pp.\n1028–1035.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[18] B. G. Doan, M. Xue, S. Ma, E. Abbasnejad, and D. C. Ranasinghe, “Tnt\nattacks! universal naturalistic adversarial patches against deep neural\nnetwork systems,” IEEE Transactions on Information Forensics and\nSecurity, 2022.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[19] X. Wei, Y. Guo, and J. Yu, “Adversarial sticker: A stealthy attack method\nin the physical world,” IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 2022.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[20] S.-T. Chen, C. Cornelius, J. Martin, and D. H. P. Chau, “Shapeshifter:\nRobust physical adversarial attack on faster r-cnn object detector,”\nin Joint European Conference on Machine Learning and Knowledge\nDiscovery in Databases. Springer, 2018, pp. 52–68.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[21] P. Xie, L. Wang, R. Qin, K. Qiao, S. Shi, G. Hu, and B. Yan, “Improving\nthe transferability of adversarial examples with new iteration framework\nand input dropout,” arXiv preprint arXiv:2106.01617, 2021.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n[22] M. Alzantot, Y. Sharma, S. Chakraborty, H. Zhang, C.-J. Hsieh, and\nM. B. Srivastava, “Genattack: Practical black-box attacks with gradient-\nfree optimization,” in Proceedings of the Genetic and Evolutionary\nComputation Conference, 2019, pp. 1111–1119.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[23] J. Lin, L. Xu, Y. Liu, and X. Zhang, “Black-box adversarial sample\ngeneration based on differential evolution,” Journal of Systems and\nSoftware, vol. 170, p. 110767, 2020.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[24] Q. Zhang, K. Wang, W. Zhang, and J. Hu, “Attacking black-box image\nclassifiers with particle swarm optimization,” IEEE Access, vol. 7, pp.\n158 051–158 063, 2019.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[25] C. Yang, A. Kortylewski, C. Xie, Y. Cao, and A. Yuille, “Patchattack:\nA black-box texture-based attack with reinforcement learning,” in Eu-\nropean Conference on Computer Vision. Springer, 2020, pp. 681–698.\n[26] M. Andriushchenko, F. Croce, N. Flammarion, and M. Hein, “Square\nattack: a query-efficient black-box adversarial attack via random search,”\nin European Conference on Computer Vision. Springer, 2020, pp. 484–\n501.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[27] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning\ndeep features for discriminative localization,” in Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2016, pp. 2921–\n2929.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[28] S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Univer-\nsal adversarial perturbations,” in Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, 2017, pp. 1765–1773.\n[29] K. R. Mopuri, U. Garg, and R. V. Babu, “Fast feature fool: A data inde-\npendent approach to universal adversarial perturbations,” in Proceedings\nof the British Machine Vision Conference (BMVC), 2017.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[30] K. R. Mopuri, A. Ganeshan, and R. V. Babu, “Generalizable data-\nfree objective for crafting universal adversarial perturbations,” IEEE\ntransactions on pattern analysis and machine intelligence, vol. 41,\nno. 10, pp. 2452–2465, 2018.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[31] K. R. Mopuri, P. K. Uppala, and R. V. Babu, “Ask, acquire, and attack:\nData-free uap generation using class impressions,” in Proceedings of the\nEuropean Conference on Computer Vision (ECCV), 2018, pp. 19–34.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[32] D. Wang, W. Yao, T. Jiang, and X. Chen, “Improving transferability\nof universal adversarial perturbation with feature disruption,” IEEE\nTransactions on Image Processing, 2023.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[33] Y. Dong, S. Ruan, H. Su, C. Kang, X. Wei, and J. Zhu, “Viewfool:\nEvaluating the robustness of visual recognition to adversarial view-\npoints,” in Advances in Neural Information Processing Systems, A. H.\nOh, A. Agarwal, D. Belgrave, and K. Cho, Eds., 2022.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[34] A. Ghosh, S. S. Mullick, S. Datta, S. Das, A. K. Das, and R. Mallipeddi,\n“A black-box adversarial attack strategy with adjustable sparsity and\ngeneralizability for deep image classifiers,” Pattern Recognition, vol.\n122, p. 108279, 2022.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[35] D. Wang, W. Yao, T. Jiang, G. Tang, and X. Chen, “A survey on physical\nadversarial attack in computer vision,” arXiv preprint arXiv:2209.14262,\n2022.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[36] J. Tan, N. Ji, H. Xie, and X. Xiang, “Legitimate adversarial patches:\nEvading human eyes and detection models in the physical world,” in\nProceedings of the 29th ACM International Conference on Multimedia,\n2021, pp. 5307–5315.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[37] Y.-C.-T. Hu, B.-H. Kung, D. S. Tan, J.-C. Chen, K.-L. Hua, and W.-H.\nCheng, “Naturalistic physical adversarial patch for object detectors,” in\nProceedings of the IEEE/CVF International Conference on Computer\nVision, 2021, pp. 7848–7857.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[38] Y. Zhang, P. H. Foroosh, and B. Gong, “Camou: Learning a vehicle\ncamouflage for physical adversarial attack on object detections in the\nwild,” ICLR, 2019.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[39] G. J. et. al., “ultralytics/yolov5: v6.0 - YOLOv5n ’Nano’ models,\nRoboflow integration, TensorFlow export, OpenCV DNN support,”\n2021. [Online]. Available: https://doi.org/10.5281/zenodo.5563715\n[40] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll´ar, “Focal loss\nfor dense object detection,” in Proceedings of the IEEE international\nconference on computer vision, 2017, pp. 2980–2988.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[41] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time\nobject detection with region proposal networks,” Advances in neural\ninformation processing systems, vol. 28, pp. 91–99, 2015.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[42] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick, “Mask r-cnn,” in\nProceedings of the IEEE international conference on computer vision,\n2017, pp. 2961–2969.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[43] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,\nT. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An\nimperative style, high-performance deep learning library,” Advances in\nneural information processing systems, vol. 32, 2019.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[44] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,\nP. Doll´ar, and C. L. Zitnick, “Microsoft coco: Common objects in\ncontext,” in European conference on computer vision. Springer, 2014,\npp. 740–755.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[45] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel, “The german traffic\nsign recognition benchmark: a multi-class classification competition,” in\nThe 2011 international joint conference on neural networks.\nIEEE,\n2011, pp. 1453–1460.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[46] A. Mogelmose, M. M. Trivedi, and T. B. Moeslund, “Vision-based traffic\nsign detection and analysis for intelligent driver assistance systems: Per-\nspectives and survey,” IEEE Transactions on Intelligent Transportation\nSystems, vol. 13, no. 4, pp. 1484–1497, 2012.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[47] Q.-Y. Zhou, J. Park, and V. Koltun, “Open3d: A modern library for 3d\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.8**l== 0.6**r== 0.2**\ndata processing,” arXiv:1801.09847, 2018.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[48] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao,\nA. Prakash, T. Kohno, and D. Song, “Robust physical-world attacks\non deep learning visual classification,” in Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2018, pp. 1625–\n1634.",
         "Universal Multi-view Black-box Attack against Object Detectors via Layout Optimization Deep learning, with the core of deep neural networks (DNNs), has profoundly impacted many research areas, such as computer vision, speech recognition, and natural language processes. However, DNNs have been demonstrated to be vulnerable to adversarial examples, which are crafted by small noises that are invisible to human observers but can deceive DNN models [1]. Therefore, adversarial examples impose potential security risk for the physically deployed DNN-based systems, especially in security-sensitive scenarios, such as autonomous driving and medical image diagnosing. An exhaustive exploration of such adversarial attacks-caused risk in advance is necessary to reduce the potential loss. Currently, a line of studies on adversarial examples has emerged [2], [3], [4], [5], [6], and these works can be divided into white-box attacks and black-box attacks in terms of the adversarial’s knowledge. White-box attacks assume the is impractical adversary can access full knowledge about the target model, such as architecture, training data, parameters, and so on. White-box attacks allow the adversary to leverage the model’s gradient to optimize the adversarial example [2], [7], [8], in the real world as the attacker while it can not access the deployed model’s gradient. In contrast, black-box attacks prohibit the adversary from accessing the information about the model yet only allow them to query the model, which makes them match the physical scenario more practical. Nonetheless, current black-box attacks mainly focus on generating imperceptible [4], [5] and image-specific adversarial perturbation [6], [9] for each input image, whose flexibility is poor as it necessitates engender new perturbation for each input samples. Although some universal adversarial attack methods[28], [30], [32] can address the issue, these methods can not be physically deployed. Physical deployable adversarial attacks are characteristic of the generated adversarial perturbation that can be manufac- tured and placed on the target cover object (e.g., pedestrian) in the physical world, which imposes practical security risks. Existing physical adversarial attacks can be roughly divided into the following two-fold in terms of the deployment of physical perturbation: sticker (patch)-based and camouflage- based physical attacks. The former performs physical attacks by sticking the sticker on a specific object area (e.g., the front side of the pedestrian [10], [11]), but the attack will fail when the detector captures the image from the viewpoint where the adversarial sticker does not appear. In contrast, camouflage-based attacks [12], [13], [14], [15] generate the adversarial UV texture to modify the appearance of the 3D object by wrapping the texture over the surface of the 3D object, enabling them to maintain the attack effect on multi- view angles. However, most camouflage-based attacks belong to white-box attacks, limiting their usefulness. Although Wu et al.[16] proposed a black-box attack by leveraging the discrete search algorithm, which first optimizes the small image patch and then performs the enlarge-repeat process to construct the final adversarial texture. Nonetheless, the mosaic-like pattern of generated textures is conspicuous and easily attracts the attention of human observers. Some approaches attempt to improve the inconspicuous of physical adversarial attacks, such as Liu et al.[17] exploited the generative model to generate the natural image, which is treated as the adversarial patch that is pasted on the sample to deceive the model. Doan et al.[18] proposed a two-stage method to optimize the natural adversarial image patch against the classification model, in which the generator is trained to generate natural flower images at the first stage, and the input latent variable of the generator is optimized via the adversarial loss to ensure aggressive of the generated image. Wei et al.[19] demonstrated that natural stickers can deceive the facial recognition system, where the paste location of stickers is found by their proposed search algorithm. Despite their success on the recognition task, adversarial attacks against the detection task proved more difficult than the recognition task [20]. Moreover, these methods are valid at specific viewpoints, limiting their effectiveness in the physical world. Unlike optimizing the adversarial pattern of a single sticker for the object at the specific viewpoint, we optimize the layout of multiple sticker images in the UV texture of the object to perform universal adversarial attacks on multiple viewpoints. Note that the sticker can be arbitrary natural images, which renders the attack more inconspicuous as it looks like the vehi- cle with the graffiti, which is normal in the real world and can not attract human alert, as illustrated in Figure 1. In this paper, we propose a novel universal multi-view black-box attack on object detectors, which optimizes a universal adversarial UV texture for a 3D object via the designed layout optimization algorithm, rendering the generated image to deceive the object detector. More specifically, we treat the optimization problem of adversarial UV texture as a circle layout optimization problem, in which the rectangle is the container for image stickers randomly sampled from the preprepared image pool. The optimization objective is to find a universal adversarial UV texture wrapped over the 3D object to deceive the object detector from different viewpoints, and two layout constraint strategies are proposed to ensure the reasonable placement of image stickers. To obtain the optimal adversarial layout solution, we adopt the random search algorithm enhanced by the devised important-aware selection strategy. The op- timization variable is the circle number, radius, and center, simplifying the constraint strategy. Additionally, we developed a novel evaluation tool based on the photo-realistic simulator (i.e., Unreal Engine) to assess the texture-based adversarial attack fairly. Finally, we conduct extensive experiments in both digital and simulated environments, showing the proposed method outperforms the comparison method significantly. Our main contributions are listed as follows. • We propose a novel universal multi-view black-box attack against object detectors via layout optimization, which engenders a universal adversarial UV texture that is valid in the multi-view scenario. • We formulate a circle layout optimization problem to obtain the optimal adversarial UV texture, which is solved by the random search algorithm enhanced by the designed important-aware selection strategy. Two layout constraints are designed to enable the reason for the placement of image stickers. • We devised a novel evaluation tool based on the photo- realistic simulator (i.e., Unreal Engine) to assess the attack performance of adversarial sticker attacks fairly. • Extensive experiments on both digital and simulated environments under different tasks show the effectiveness and extensibility of the proposed method. Moreover, we demonstrate that 3D objects with natural image graffiti can deceive object detectors in surround view. The rest of this paper is arranged as follows. The related works are briefly reviewed in Section II. Then, we formulate the problem statement in Section III. The proposed method is exhaustly introduced in Section IV. The evaluation tool is described in Section V. Experiment and result analysis are discussed in Section VI. The conclusion is given in Section VIII. In this section, we briefly review digital adversarial attacks and physical adversarial attacks. A. Digital Adversarial attacks Existing digital adversarial attacks can be categorized into white-box and black-box attacks in terms of whether the adversary can access the target model. The former assumes the adversary can access the full knowledge about the target model, which allows the adversary to exploit the gradient of the target model to develop adversarial attacks. Thus, the method used the gradient with respect to the model is re- garded as the white-box attack. The most represented gradient- based approach is FGSM [7], which crafts the adversarial example along with the gradient ascend direction of task- specific loss with respect to the input in a single step. Since then, a line of variants of FGSM have emerged, such as multiple iterative steps (BIM) [8], random initialization (PGD) [2], combined with momentum terms (MIM) [3] to improve the transferability, and input augmentation [21]. In contrast, black-box attacks prohibit the attacker from accessing the target model and only allow them to query the target model. Thus, a promising method to perform black-box attacks is the evolutionary algorithm, such as genetic algorithm [22], differential evolution (DE) [23], and particle swarm opti- mization (PSO) [24]. Despite obtaining certain success, their optimization involved amount of variables, because they were required to find the pixel-wise adversarial perturbation with the shape of the input image, which is time-consuming in practice. To reduce the optimization variables, Yang et al. [25] optimized a small perturbation size and then interpolated it leading to a dramatic reduction in optimization variables. Rather than directly optimizing the pixel of perturbation, Andriushchenko et al. [26] utilized the random search algorithm to yield square-based perturbation, wherein the optimization variable is the position, side length, and fill color of the square. Li et al. [4] proposed to exploit neighborhood samples around the input image to estimate the gradient, which is used to guide the update direction of adversarial examples. In their algorithm, the optimization variables solved by DE are the weights used to fusion the neighborhoods. Later, Li et al. [5] proposed to perturb partial to the input shape, pixels of input, which are determined by CAM [27] that highlights the important pixel for model decision. Another type of adversarial attack are universal attacks, which engender a single universal perturbation for the dataset. Moosavi et al.[28] first proposed an iterate update method to accumulate the perturbation for each image samples, where the final perturbation is called the universal adversarial pertur- bation. Concurrent, Mopuri et al.[29] devised a feature loss function to render the universal adversarial perturbation to disrupt the intermediate feature distributions. After that, a line of universal perturbation attack methods is proposed, such as reducing the requirement of large-scale labeled training sam- ples [30], [31], improving the transferability across different models [32]. Unlike optimizing the adversarial perturbation, some re- searchers attempt to search the sensitive location where the model is most vulnerable. Yang et al. [25] extracted the class- specific textures by clustering Gram matrix of intermediate layers, which are used to paste on the image for realizing adversarial attack, in which the paste location is obtained by performing reinforcement learning. Dong et al. [33] observed that natural objects under specific viewpoints in the real world are easily misrecognition by the model. To find such adversarial viewpoints, the author optimized the camera trans- formation (i.e., location and orientation) that made the model misclassification, then used the neural radiance field (NeRF) to generate realistic images based on that camera transformation. However, the above black-box attacks need to optimize the adversarial perturbation for each input, which is impractical. To generate universal adversarial perturbation, Ghosh et al. [34] proposed a novel black-box method to craft the universal adversarial perturbation against image classification tasks, but their method can not be physically deployed. The universal adversarial perturbation against the object detector under the black-box setting remains unexplored. B. Physical adversarial attacks The physical adversarial attacks can be divided into sticker (patch)-based or camouflage-based [35]. Sticker-based attack methods are designed to optimize an image sticker with the adversarial pattern, which will be manufactured (e.g., printed) and then deployed (e.g., hung [10] or pasted [36], [37], [18]) on the object in the physical world. Thys et al.[10] developed a patch-based attack against the pedestrian detector. Huang et al. [11] proposed to optimize a universal adversarial patch with the initial natural image (i.e., dog), which is then printed out and pasted on the object repeatedly. Hu et al.[37] used a generative model to engender a natural adversarial patch to attack the pedestrian detector. Wei et al. [19] demonstrated the facial recognition model is susceptible to natural stickers. The sticker-based attacks show their limitation in multi-view angles. In contrast, camouflage-based attack methods were devised to optimize the UV texture of the 3D object directly, which is then wrapped over the surface of the 3D object, achieving better multi-view angle attack performance. Zhang et al. [38] devised a clone network to mimic the render- detection process as the physical render is not differentiable, then optimized the UV texture of the 3D object via white- box attacks. Wang et al. [12] exploited the neural renderer and optimized the partial adversarial camouflage (i.e., vehicle’s hood, roof, and side) by the devised attention suppress loss. Wang et al. [13] took a step further than [12] and proposed a full coverage adversarial camouflage for the complex environ- ment conditions (e.g., occlusion, multi-view) by maximizing the detector loss. Suryanto et al.[15] proposed an approximate renderer model to wrap the adversarial UV texture over the vehicle, which was optimized via gradient descent. Concurrent to [15], Duan et al.[14] optimized the UV texture of the 3D object by maximizing the prediction score of the target class. Most approaches discussed above are white-box attacks that allow the adversary to utilize the target model’s gradient to optimize the adversarial perturbation, while the black-box attacks are less explored. This work focuses on developing a universal multi-view black-box attack against object detection via layout optimization. In this section, we first introduce the general problem statement of adversarial attack against object detection, and then we come up with the problem that this works to solve. A. Adversarial attack against object detection include the coordinate of the center point, Let F indicate the trained object detection model to be attacked: F : X → Y, where X ∈ RC×H×W (C, H, W are the channel, height, and width of the image) and Y ∈ Rd, where d=6 for object detection, includes x, y, w, h, F cls, F obj, the former four terms describes the predicted bounding box the width that and height of the object, F cls and F obj are the predicted category and confident score of the object, respectively. In object detection, only the predicted F obj of the object larger than the assigned confident threshold τ is regarded as detected; otherwise, the object is regarded as undetected. We follow the previous work [12], [13] set the confident threshold τ to 0.5. The goal of adversarial attacks is to optimize a perturbation δ that decreases the F obj until beneath the predefined threshold τ , while the perturbation does not arouse the attention of the human observer. Mathematically, the optimization of pertur- bation can be expressed as: s.t. F obj(x + δ) < τ, where || · ||p indicates the Lp-norm, which confines δ to the Lp-norm sphere with radius of ϵ for ensuring the imperceptible of the adversarial examples. B. Universal multi-view attack The perturbation δ form defined in Equation 1 is crucial for its physical deployment, such as when δ is the adversarial patch, is unable to achieve multi-view attacks as they replace the partial pixel of the image with the adversarial patch (see Figure 2(a)), ignore the non-plane characteristic of the 3D object. In contrast, we take non-plane characteristics into account and exploit the physical render to implement reasonable placement of image stickers. We wrap the adver- sarial UV texture constructed by multiple stickers over the 3D object via a physical renderer, changing the appearance of the 3D object. However, the 3D object has a different appearance observed from a different perspective, making a single adversarial sticker that can not work in multi-view conditions, as shown in Figure 2(b)-(e). In this work, we aim to find a universal adversarial UV texture via the layout optimization algorithm, where the adversarial UV texture can be wrapped on the 3D object via the physical renderer and fool the object detector under a multi-view scenario. Formally, given image stickers δs, which are pasted on the UV texture T of a 3D object with category ygt using an applier function A, engender an adversarial UV texture Tadv (i.e., Tadv = A(T, δs)), which is then wrapped to the 3D object’s mesh M by a physical renderer R, and output multiple adversarial examples xadv by using different camera transformations θ ∼ Θ, θ contain x, y, z; pitch, yall, roll, i.e., xadv = R(M, Tadv; θ). Finally, the optimization object is to find appropriate image sticker δs to reduce the objectness score of the object detector for the specific 3D object under multi-view conditions, which can be expressed as Eθ∼ΘF obj(R(M, A(T, δs); θ); ygt). In this section, we describe how we model the universal adversarial UV texture optimization problem as a circle- based layout optimization problem. Then, we elaborate on the proposed random search algorithm. Rather than optimize the pixel of adversarial stickers, we follow [19] to use the nature image as the adversarial sticker and optimize their number, size, and paste position on the UV texture, which can be regarded as the rectangle-based layout optimization problem. However, placing multiple rectangle stickers in UV texture inevitably causes overlaps, while the overlap control of the rectangle image is complexity. To address this issue, we formulate the problem as a circle- based layout optimization, which simplifies the overlap control during optimization. Moreover, the circle-based model can reduce the optimization variable, such as three variables (i.e., center position and radius) to determine the size and position of a sticker, but four variables (i.e., center position, width, and length) are required for the original rectangle-based model. Based on the aforementioned discussion, adversarial stickers δs can be determined by the center position p(px, py) and radius r. For multi-view attacks, we use n stickers to modify the UV texture, ensuring each side of the vehicle’s appearance is modified. We use L to indicate the sticker layout represented by n sticker. Thus, A(T, δs) is reformulated as A(T, n, p, r), indicating that place n stickers with radius r at location p on the UV texture T . Note that we aim to find the optimal sticker layout L to construct the universal adversarial UV texture Tadv, so adversarial stickers and Tadv refer to the same thing, and we adopt Tadv as following for simplicity. Finally, the layout optimization problem is expressed as follows. find Tadv min Eθ∼ΘF obj(R(M, A(T, n, p, r); θ); ygt) s.t. nmin ≤ n ≤ nmax rmin ≤ r ≤ rmax p ∈ Ω where nmin, nmax are the minimum and maximum allowable number of stickers in the UV texture, rmin and rmax are the lower and upper bound of the radius, which is determined by the area ratio of the sticker to UV texture; Ω refers to the region that allows for painting circles realized by constraints. Moreover, modificating the interior part of UV textures can not alter the 3D object’s appearance (see Figure 4(b)). For the selection of stickers, not only the natural image can be the sticker, but also the pure color block(namely base elements). Figure 3 describes the pipeline of the proposed method. To address the layout optimization problem, we adopt the random search algorithm to find the optimal Tadv, which will be introduced as follows. B. Random Search for Universal Adversarial Texture In this section, we elaborate on how we use the random search algorithm to find the universal adversarial texture for multi-view attacks represented by a circle-based layout optimization problem defined in Equation (3), including layout initialization and layout optimization. 1) Layout initialization: We treat the construction of ad- versarial UV texture via adversarial stickers as the layout initialization, where the layout element is the sticker (e.g., sticker image or pure color image). More specifically, we first randomly sample the circle number n from the [nmin, nmax]. For each circle, we obtain the circle radius r determined by the predefined allowable modification area, followed by randomly sampling the circle’s center (x, y). Concretely, we bound the upper bound of the circle’s area by exploiting the ratio a of the circle’s area to the UV texture’s area A, such that we can get A ∗ a where the a should not exceed 10 the circle radius by percent. In the placement stage represented in A, each circle should satisfy the overlap and mask constraint to make the placement coincidence with physical deployment, which will be discussed below. Overlap constraint. Overlap caused by multiple stickers can be easily solved by the circle-based layout. Specifically, we control the overlap by ensuring each spawn circle satisfies Algorithm 1 Layout checkout Input:current circle lcur, recorded circle L, texture mask Ω, allowable overlap threshold γ Output: Boolean the following rule: the Euclidean distance of the circle’s center between the new circle (xi, yi) and all recorded circles (x, y) is larger than the sum of their radius, which can be formulated as follows. (xi − xj)2 + (yi − yj)2 ≥ γ(ri + rj), ∀j ∈ {1, .., |x|} , (4) where |x| denotes the number of recorded circles, and the γ controls the overlap magnitude of two circles, which is set to 1. Figure 4 (a) provides the visualization explanation. Mask constraint. Given the fact that some region in UV texture does not appear on the surface of the 3D object, such as vehicle interiors. To avoid the invalid search, we make a binary mask Ω to separate whether the region can appear on the appearance, where 1 in Ω denotes the region that allows being painted the circle (represented in white), while 0 does not (represented in black), Figure 4 (b) illustrates the mask constraint. To obtain the n circle to construct the adversarial UV texture, we record the circle whose center is located in the mask Ω until sufficient circles are obtained. Meanwhile, every circle has to satisfy the overlap constraints. Algorithm 1 describes the process of layout constraints. Once the circle layout L constructed, we replace each circle with the image to obtain the final adversarial UV texture. In this stage, we randomly select an image from the image pool for each circle. Then, we adopt the following strategy to place them on the UV texture: the size of the image is adjusted in terms of 1: xi, yi, ri ← lcur 2: if Ω(x, y) = 0 return false 3: 4: for l in L do 5: 6: xj, yj, rj ← l dr = ri + rj dc = (xi − xj)2 + (yi − yj)2 if dc ≤ dr ∗ γ return false Algorithm 2 Circle layout initialization Input: texture area A, texture mask Ω, allowable number of patch [nmin, nmax] and overlap threshold γ, are ratio [amin, amax] Output: circle layout L 1: Randomly sample n from [nmin, nmax] 2: Initial circle layout L 3: for itr = i, ..., n do 4: Randomly sample ratio a from [amin, amax], where amin, amax are the lower and upper bound of area ratio √ Calculate the radius r by Randomly sample circle center coordinates (x, y) if Layout check(x, y, r, L, Ω, γ) ▷ Algorithm 1 the size of the circle’s largest inscribed square, where the √ 2r, as illustrated in Figure 5. side length is determined by Moreover, we adjust the image’s orientation for a reasonable purpose. For example, the rendered image without adjusting Algorithm 4 Important-aware layout optimization Input: circle layout L, texture T , image pool S Output: texture Tadv x, y, r ← l Sl ← G(sl) = f (Tadv) − f (sl ∪ Tadv), sl ∈ S if p ≤ 0.5 ▷ Random transformation Rotate s by randomly select angle from [−30◦, 30◦] Replace the circle with image s at the coordinate (x, y) There are two termination conditions: either achieving the max iteration number or the Tadv can fool the object detector F on all camera transformations Θ. Algorithm 3 describes the optimization of the adversarial UV texture. C. Important-aware selection strategy In Section IV-B, we adopt a randomly selected strategy to choose an image from the image pool, which may ignore the optimal image for the specific position, making it fails to obtain the best attack performance. To address this issue, we introduce an important-aware layout strategy. Specifically, we search for the best image from the image pool for each circle in the layout. With the important-aware selection strategy, we can find a better layout of the image sticker and obtain a higher attack performance. Mathematically, given the image sticker pool S, the best adversarial texture Tadv can be obtained by solving the following problem. G(si) = f (Tadv) − f (si ∪ Tadv), si ∈ S where G(si) is the gain function, we use f (Tadv) to de- notes the fitness score of the adversarial texture Tadv, and f (si∪Tadv) is the fitness score of adversarial texture Tadv with the natural image si. By maximizing G(si) for each layout position, we can obtain the optimal layout that could drop the fitness score the most. Moreover, before painting the image sticker on the texture, we introduce a random transform to improve the diversification by randomly rotating the image sticker within [−30◦, 30◦]. Al- gorithm 4 describes the generation method of the naturalistic- aware adversarial texture. Currently, in physical adversarial attacks against object de- tectors, the lack of a uniform platform to assess the attack per- formance makes it hard to reproduce the existing approach due to the actual environmental discrepancy between the method and their follower who want to reproduce the physical attack. Moreover, the researcher usually evaluates physical attacks on the specific environment, while it is hard to reproduce by others. To address this issue, we presented a novel evaluation tool based on the photo-realistic simulator (i.e., Unreal Engine) to evaluate the attack performance of different attacks. Based on the simulator, we provide several evaluated backgrounds based on the scene (e.g., Landscape) provided by the simulator. Algorithm 3 Adversarial UV texture optimization Input: object detector F , physical renderer R, camera trans- formation distribution Θ, the 3D object of category yt com- prise of mesh M and texture T , mask constraint Ω, maximum iterative step ItrM AX Output: adversarial texture T ∗ I(Fcls(R(M, T ; θ)) = yt) 1: Tadv ← T , Lbest ← [] 2: fbest ←  θ∈Θ 3: for itr = 1, ..., ItrM AX do 4: 5: 6: 7: 8: Obtain circle layout L with Algorithm 2 Update adversarial texture Tadv with circle layout L calculate fcur ←  I(F cls(R(M, Tadv; θ)) = yt) if fcur ≤ fbest fbest ← fcur T ∗ adv ← Tadv if fbest = 0 break the image sticker is odd (inverted image) in the real world (see Figure 2 (c)). Therefore, we designed a criterion to adjust the orientation of the sticker. Specifically, the sticker image rendered on the left side of the vehicle will be rotated 90 degrees clockwise, while the right side will be rotated 90 degrees counterclockwise. In summary, the whole process of layout initialization is described in Algorithm 2. 2) Layout Optimization: Recall that our goal is to find a universal adversarial texture Tadv, which is wrapped over the 3D object and rendered into adversarial examples xadv via physical renderer R under different camera positions Θ. At the same time, the objectness score of object detector F on the generated adversarial examples beneath the threshold τ . Therefore, we minimize the objectness score over rendered adversarial examples from different perspectives by optimizing the adversarial UV texture. Specifically, we devise the fitness score function f as follows. I(F obj(R(M, A(Tadv, n, p, r); θ); yt) ≤ τ ), where F obj(·) denotes the objectness score of the category yt the object detector F ; I(·) = 1 if true, and I(·) = 0 if false. For the selection of Θ, we sample the image per 2◦ over 360◦ and keep other settings fixed, collecting 176 images, which means that the universal adversarial UV texture Tadv should maintain aggression on these images. 3) Evaluation Metric: To quantify the performance of the proposed method, we follow the prior works [38], [16], [12] to adopt the P@0.5 as the measurement metric for vehicle detection and warplane detection. P@0.5 refers to the ratio of images correctly detected after attacks to the total test number when the confidence threshold is set to 0.5, which indicates the lower P@0.5, the stronger the attack. For TSR, we adopt the attack success rate (ASR) as the evaluation metric to represent the proposed method against the TSR model, indicating the higher the ASR, the better. 4) Implementation Details: The physical renderer is the crucial component of the proposed method, which wraps the optimized adversarial UV texture over the 3D object. In this paper, we adopt the widely used physical renderer open3d library [47] as the physical renderer. Unless otherwise specified, we adopt the following default parameters for all experiments, nmin and nmax are set to 5 and 15 for vehicle and warplane tasks, and 3 and 8 are for the traffic sign recognition task. a is uniformly sampled from 0.001 and 0.1 for all tasks. The image numbers of the image pool are set to 30. The maximum iteration number ItrM AX set to 10000. B. Comparison result To investigate the effectiveness of the proposed method, we perform the attack by wrapping the adversarial texture stuck with the optimized image sticker layout on the vehicle. For comparison, we get inspiration from RP2 [48] and SquareAt- tack [26] and then modify them as the baseline method. RP2 [48] stuck the white or black image patch on the 2D traffic sign image for deceiving TSR model. In contrast, SquareAttack [26] is designed to optimize the invisible square adversarial perturbation by adding the pure color square block to fool the image classifier. Although these works achieve certain success in the original task, they are hardly applied to our tasks involv- ing 2D to 3D transformation. Therefore, we combine the pro- posed method with their elements (e.g., square and white-block patch) to optimize the adversarial texture, and we treat these two methods as baseline approaches. Specifically, in our work, we replace the circle area with their image patch to mimic their methods, called BlackWhite [48] and SquareAttack [26]. We also compare the proposed method with existing adversarial attacks against object detectors, which include CAMOU [38], UPC [11], ER [16], DAS [12], FCA [13], CAC [14], and DTA [15]. Note that these methods are white-box attacks, so we only use their generated adversarial pattern or camouflage to construct the adversarial texture to perform black-box attacks for comparison. We treat the pure circle element as our baseline, and we select the adversarial texture generated by the proposed method using natural images (i.e., AdvPatch, Animal, and Cartoon) with the best attack performance for evaluation. For the adversarial texture constructed by natural images, we utilize the adversarial patch generated by the existing approaches, which may still be aggressive based on adversarial perturbation with transferability. In addition, we also adopt two public available image categories containing cartoon images and animal images. With a physical renderer, we wrap the optimal adversarial texture over the vehicle and For each background, we construct a camera rail around the target 3D object wrapped with adversarial texture, and then a camera is bound to the camera rail and towards the target object. Finally, a video sequence is recorded to construct the multi-view images, which are then used to assess the attack performance. The generated adversarial (UV) texture and the 3D object model are required to use the tool. With the proposed tool, anyone could reimplement other methods and make comparisons fairly. Figure 6 describes the basic pipeline to use the evaluation tool. Therefore, we treat the simulated adversarial attack as the physical adversarial attack in this work. In this section, we first introduce the experiment settings. Then, we evaluate the proposed method on different object detectors under digital and physical conditions. We followed by conducting the ablation study on the influence of the image number of the seed image pool and the important-aware layout optimization. Finally, we extend our method to the warplane detection and traffic sign recognition (TSR) task. 1) Target models: We evaluate the proposed method of vehicle detection and warplane detection on the following four object detectors: two one-stage (i.e., YOLOv5x [39], and RetinaNet [40]) and two-stage detectors(i.e., Faster RCNN [41], and Mask RCNN [42]), provided by PyTorch [43]. These detectors are trained on the MS COCO dataset [44], which contains 80 categories. Moreover, We further evaluate the performance of the proposed method on two widely used TSR models: GTSRB CNN and LISA CNN. We follow [17] to resize the image resolution from 28 × 28 to 128 × 128 when training two models on GTSRB [45] and LISA [46] datasets, which obtain 95.06% and 100% accuracy on the test data, respectively. The reason for adjusting the resolution is that the naturalistic image will be severely distorted when resizing high-resolution images to low-resolution images, which makes it hard to achieve higher attack performance. 2) Evaluation Dataset: We collect 176 images for the vehicle detection task with sampling per 2◦ until covered 360◦, where 160 images for the warplane detection task. Regarding the TSR task, we randomly select 100 naturally- looking “STOP” sign images from the corresponding dataset. The experiment results are listed in Table I. As we can ob- serve, on the one hand, the proposed method (i.e., Circle) out- performs the baseline method BlackWhite and SquareAttack by 16.76% and 4.54% in terms of the average degradation of P@0.5. At the same time, the pure color elements are unable to obtain better attack performance. On the other hand, AdvPatch outperforms all comparison methods, achieving a maximum decrease of 74.29% in terms of the average P@0.5 over four detectors. Besides AdvPatch, although Cartoon falls behind the CAC, the discrepancy is small (i.e., 6.25%). The reason may be attributed to CAC being designed to generate the full coverage adversarial texture under the white-box attack setting. However, the adversarial texture generated by Cartoon is more stealthiness than CAC. Moreover, we observe that approaches devised to generate full coverage adversarial texture (i.e., FCA and CAC) exhibit better transferability than other methods (except for AdvPatch), particularly for attacking two-stage detectors (i.e., Faster RCNN and Mask RCNN), where the average degradation caused by FCA and CAC are 55.12% and 54.26% in terms of P@0.5, surpass other methods in a large margin. Such observation indicates the advantage of the full coverage adversarial attack method in multiview conditions. Additionally, we find an interesting phenomenon that some adversarial textures would boost the detection performance of the detector, such as ER boosting the detect performance by 0.57% for Faster RCNN and DAS and DTA enhancing the detect performance by 5.68% for RetinaNet. Regarding the image-based adversarial the Ad- vPatch obtains the best attack performance, achieving the maximum degradation on P@0.5 on RetinaNet by 88.07%. The possible reason is that AdvPatch naturally contains adver- sarially due to the transferability characteristic of adversarial perturbation, despite not being trained on the used target detector. Although Animal performs better than the baseline methods on average, it’s falling behind the AdvPatch and Cartoon, which indicates that the content of the images has also impacted the attack performance. On the other hand, we observe the robustness discrepancy of different detectors varying. One-stage detectors display weaker than two-stage detectors under the proposed attack. Specifically, the average P@0.5 degradation of YOLOv5x and RetinaNet are 57.01% and 60.8%, while Faster RCNN and Mask RCNN are 40.72% and 21.88%, respectively. texture, We also provide some adversarial examples rendered by different viewpoints in Figure 8. As we can see, the adver- sarial examples generated by the proposed method can fool the detector into making the wrong detection in most cases (11/12). In contrast, comparison methods fail to deceive the detector. More importantly, compared with the mosaic-like adversarial texture generated by comparison methods [38], [16], the proposed method displays a better naturalness and stealthiness, which increases the risk of the proposed method when applied to the real world as people tend to ignore the security risk of scrawl painting, and result in significant accidents. C. Simulated adversarial attack To analyze the influence of rendered viewpoints on attack performance, we regroup the rendered image into eight groups in terms of the rendered vehicle’s heading, then statistics the change of P@0.5. Figure 7 illustrates the evaluation results. We can observe that adversarial examples in the west, southeast, and southwest groups exhibit worse attack performance, where the P@0.5 are 29.88%, 47.31%, and 39.62%, respectively. In contrast, the P@0.5 of the other five groups is less than 20%. One possible reason is that the images in the west, southeast, and southwest display the strong vehicle contour characteristic. By contrast, the adversarial examples in the northeast group display the best attack performance, resulting in 91.54% degradation of detection performance. In this part, we conduct the simulated adversarial attack experiment for vehicle object detection with the decided evaluated tool mentioned in Section V. Specifically, we record a ten-second video with frame per second (FPS) 30 and extract 300 images for evaluation. Table II lists the quantitative result of different adversarial textures for vehicle detection. As we can observe, the AdvPatch obtains superior attack performance except for CAC on the average decrease of P@0.5 by 30.83% on four detectors. The possible reason is that CAC optimized the adversarial texture by exploiting the information of target models on a large-scale dataset. In contrast, the proposed black-box method is optimized on fewer images. On the other hand, the attack performance of our method (i.e., Circle and Cartoon) is on par with the existing approaches, indicating the proposed method’s effectiveness. Additionally, the YOLOv5x shows vulnerable to adversarial texture attacks than other methods. Specifically, the average P@0.5 under various attack methods of YOLOv5x is 38.64%, while Faster RCNN, Mask RCNN, and RetinaNet are 80.55%, 84.42%, and 63.26%, respectively. Such findings indicate the robustness discrepancy across the detector, which can help people design more robust architecture. Figure 9 illustrated the simulated adversarial examples. D. Ablation study In this part, we exhaustively investigate the influence of the following factors on the attack performance: important-aware selection strategy, the number of image pools, and the devised constraints composed of masking and overlap control. to seek the best 1) Important-aware selection strategy: The random search may fail image patch for the specificity position, while the important-aware strategy is used to solve this problem. To study the effectiveness of the important-aware strategy, we perform experiments using the image pool of 20 images (i.e., |S| = 20). Figure 10 depicts the comparison results. We can conclude that the local search can boost the attack performance of the proposed method. Specifically, we obtain the average gains of model performance degradation by experiment settings under the following constraints composed: without (w/o) Mask&Overlap, w/o Overlap, and the complete method. Quantitative and qualitative results are illustrated in Figure 12. As we can observe, on the one hand, the complete method not only convergences fast and obtains the best attack performance at the same iteration number. Specifically, the complete method degrades the detector’s performance by 67.05% at the 18-th iteration, while w/o Mask&Overlap or w/o Overlap degrades by 57.95% and 55.11%, respectively. Moreover, the complete method deteriorates the detector’s performance by 80.68% at the 500-th iteration, while the other two are 57.95% and 72.73%. On the other hand, the w/o Over- lap&Mask place the image patch on the non-appearance region of texture, and w/o Overlap results in overlap phenomena. By contrast, the complete method obtains the rational layout of image patches. In this section, we investigate the flexibility of the proposed method. Specifically, we perform two additional experiments, i.e., the warplane detection task and the traffic sign recognition task. The former is used to investigate whether the proposed method can be applied to find the optimal adversarial UV texture to the 3D model that has no explicit UV texture, while the latter is used to investigate whether the proposed method can be applied to find the optimal adversarial layout of image sticker on 2D images. A. Extend to warplane detection task To investigate the extensibility of the proposed method, we optimize the adversarial texture for no UV texture 3D model. Specifically, we first construct a base UV texture initialized with pure color. Then, we optimize the optimal layout of the elements on the base UV for adversarially. We discard the mask constraint as the 3D model has no UV texture. In this part, we collect 160 images sampled from different viewpoints as the test set, and the number of the image pool is 40. The evaluation results are listed in Table III, as we can observe, on the one hand, the AdvPatch achieves the best result against all models (i.e., YOLOv5x, Faster RCNN, Mask RCNN, and RetinaNet), obtaining the maximum drop in terms of P@0.5 by 83.75%, 82.5%, 78.75%, and 82.5%, respectively. On the other hand, the average decrease in terms of P@0.5 of four detectors exceeds 50%, i.e., 54.53% and 54.69% for Circle and Cartoon. The experiment result shows the effectiveness of the proposed method in generating the adversarial texture for the none-UV texture 3D model. Furthermore, we also conduct the simulated adversarial attack. Specifically, we use the evaluated tool to collect 301 images for evaluation. The evaluation results are illustrated in Table IV. As we can see, AdvPatch achieves the best attack performance on four detectors, where the average decrease of P@0.5 is 90.28%. Moreover, the adversarial texture optimized on the pure color displays superior attack performance (i.e., the average drop of P@0.5 is 16.53% and 19.52% for Square and Circle) than Animal (0.42%) or Cartoon (13.29%). The possible reason is that the warplane model has no UV texture, 10%. Meanwhile, we also observe that the important-aware strategy has minimum impact on BlackWhite, and Circle, which can be attributed to the pure color no content. However, the important-aware strategy obtains the attack improvement with the search time cost. Therefore, we can trade off both by switching to the important-aware strategy or not. 2) Number of image pools: Intuitively, enlarging the search space (i.e., diversity of the image pool) could benefit in obtaining a better solution. To verify this conjecture, we investigate the influence of different image numbers (i.e., 20, 30, 40, 50) in the image pool on attack performance. Figure 11 describe the evaluation results. We can observe no obvious discrepancies when adopting the different number of images pool. For example, the standard deviation of YOLOv5 on AdvPatch, Animal, and Cartoon on the different image numbers of image pools is 3.88, 3.76, and 2.46, respectively, which indicates that increasing the image number of the image pool can not bring significant improvement. Besides, we find an interesting phenomenon that the one-stage detectors are more fragile than the two-stage detectors under the proposed attack, which encourage people to pay more attention to the robustness of the one-stage detector. 3) Effectiveness of the proposed constraint conditions: The effectiveness and efficiency of the proposed method have been influenced by the search space, which is constrained by the proposed two constraint conditions. Thus, we optimize the adversarial texture against the YOLOv5 with the default resulting in severe distortion of the natural image during pasting on the customed texture. In contrast, the adversarial texture optimized by the pure color exhibits better attack performance due to its small image distortion. Additionally, Figure 13 provides some simulated examples. B. Extend to traffic sign recognition We extend our method to attack the traffic sign recognition (TSR) model to demonstrate not only the proposed method can seek the optimal adversarial layout of UV texture for the 3D objects but is also applicable to 2D images. Specifically, we first train two widely used TSR models consisting of LISA CNN and GTSRB CNN. Note that, we only focus on the “STOP” sign category. Our goal is to optimize the universal adversarial image patch layout for the “STOP” sign to mislead the TSR model to output the wrong result, namely the untargeted attack. We select 100 visually recognizable “STOP” sign images from the test dataset for evaluation. The evaluation results are reported in Table V regarding attack success rate (ASR). As we can see, the pure color baselines outperform the image-based methods, where the former achieves the average ASR of 94.5%, and the latter is 75.33%. We speculate the discrepancy between the TSR model and the vehicle detection model in model architecture and task specificity leads to the gap in attack performance. Moreover, the pure color baselines have bigger search space than the image-based method, which is effective when attacking the TSR model. Additionally, we also observe that the AdvPatch performs worse than other methods, which can be attributed to the AdvPatch being originally designed to attack object detectors, while TSR is a classification task. In this paper, we proposed a novel universal multi-view black-box attack against the object detector. Specifically, we instead optimize the adversarial layout constructed by multiple stickers for a 3D object’s texture, whose rendered images can deceive the object detector from the multi-view scenario. Moreover, the image sticker can be arbitrary images, which renders our attack more inconspicuous. To find the adversarial layout, we first model the above problem as a circle-based layout optimization problem and then exploit the random search algorithm enhanced by the proposed important-aware selection strategy to find the optimal sticker layout. Addition- ally, we proposed a photo-realistic simulator-based evaluation tool to assess the UV texture-based attack approaches. Exten- sive digital and simulated experiments, as well as extended experiments, suggested the effectiveness and extensibility of the proposed method.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2407/2407.06688v1.pdf",
         "extracted",
         "None",
         "",
         "Universal Multi-view Black-box Attack against Object Detectors via Layout Optimization"
        ],
        [
         "14",
         "006409cdca137cfc222cee85ad960caace21b7d5",
         "None",
         "Soumak Biswas,Maheshanand Bhaintwal",
         "None",
         "None",
         "https://www.aimsciences.org/data/article/export-pdf?id=658400c292d3ad47ddca22bd",
         "None",
         "None",
         "Quasi-Cyclic Constructions of Quantum Codes;Structure and performance of generalized quasi-cyclic codes;On ℤprℤps-additive codes;On ℤ2ℤ2[u]-additive codes;On cyclic self-orthogonal codes over Z2m;On double cyclic codes over Z4;Z2\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$${{\\mathbb {Z}}}_2$$\\end{document}-double cyclic codes;On quasi-cyclic codes over $${\\mathbb{Z}_q}$$;$${{{\\mathbb Z}_2}{{\\mathbb Z}_4}}$$ -linear codes: generator matrices and duality;On the algebraic structure of quasi-cyclic codes I: Finite fields;Cyclic Codes over the Integers Modulopm;On ℤprℤps-additive cyclic codes",
         "On some characterizations of generalized quasi-cyclic codes over $ \\mathbb{Z}_q $"
        ],
        [
         "15",
         "006b512306cc252e48b8999f5e52acf05b115889",
         "None",
         "Luuk Poort,Lars A.L. Janssen,B. Besselink,Rob H. B. Fey,N. Wouw",
         "\n**BLOCK**fs== 16.9**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nAbstracted Model Reduction:\nA General Framework for Efficient Interconnected System Reduction\n**BLOCK**fs== 11.0**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nLuuk Poort, Lars A.L. Janssen, Bart Besselink, Rob H.B. Fey, Nathan van de Wouw\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nAbstract—This paper introduces the concept of abstracted\nmodel reduction: a framework to improve the tractability of\nstructure-preserving methods for the complexity reduction of\ninterconnected system models. To effectively reduce high-order,\ninterconnected models, it is usually not sufficient to consider the\nsubsystems separately. Instead, structure-preserving reduction\nmethods should be employed, which consider the interconnected\ndynamics to select which subsystem dynamics to retain in\nreduction. However, structure-preserving methods are often not\ncomputationally tractable. To overcome this issue, we propose to\nconnect each subsystem model to a low-order abstraction of its\nenvironment to reduce it both effectively and efficiently. By means\nof a high-fidelity structural-dynamics model from the lithography\nindustry, we show, on the one hand, significantly increased\naccuracy with respect to standard subsystem reduction and, on\nthe other hand, similar accuracy to direct application of expen-\nsive structure-preserving methods, while significantly reducing\ncomputational cost. Furthermore, we formulate a systematic\napproach to automatically determine sufficient abstraction and\nreduction orders to preserve stability and guarantee a given\nfrequency-dependent error specification. We apply this approach\nthe\nto the lithography equipment use case and show that\nenvironment model can indeed be reduced by over 80% without\nsignificant loss in the accuracy of the reduced interconnected\nmodel.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nIndex Terms—Model Reduction, Interconnected Systems, Sta-\nbility Preservation, Accuracy Guarantee, Structural Dynamics\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nI. INTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nComplex dynamical systems are often composed of in-\nterconnected subsystems, such as plant-controller feedback\nloops, multi-physical systems, networked cyber-physical sys-\ntems, or assemblies of components in high-tech equipment.\nThe collective of all subsystem models constitutes the model\nof the interconnected system, as schematically visualized in\nFigure 1a. Often, this interconnected system model is of such\nhigh order that dynamical analysis becomes computationally\ninfeasible and model order reduction methods are required to\napproximate the high-order model by a low-order surrogate\nmodel. An illustrative scenario where this problem arises can\nbe found in structural dynamics, such as in the design and\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nManuscript created November, 2024; This work is funded by Holland\nHigh Tech | TKI HSTM via the PPS allowance scheme for public-private\npartnerships and ASML.\nThe authors Luuk Poort, Lars Janssen, Rob Fey and Nathan van de Wouw\nare with the Department of Mechanical Engineering, in the Dynamics &\nControl group, Eindhoven University of Technology, 5600 MB Eindhoven,\nthe Netherlands (e-mail: l.poort@tue.nl; l.a.l.janssen@tue.nl; r.h.b.fey@tue.nl;\nn.v.d.wouw@tue.nl).\nBart Besselink is with the Bernoulli Institute for Mathematics, Computer\nScience and Artificial Intelligence, University of Groningen, 9700 AK,\nGroningen, the Netherlands (e-mail: b.besselink@rug.nl).\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nanalysis of lithography machines [1], which serves as the\nprimary motivating case study for this research.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nWhen reducing a model of interconnected subsystems, it\nis preferable to retain the interconnection structure to keep\nthe modelling approach modular. In other words, the reduced\ninterconnected system model should be constructed from re-\nduced subsystem models. This modular reduction approach\naligns with the typical design process in industry, where each\nsubsystem is largely developed separately [2]. The combi-\nnation of such modular design and model reduction allows\nfor greater flexibility of individual design teams, preservation\nof the essential structure of the interconnected system and\nincreased interpretability of the reduced system model.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nThe most direct and resource-efficient approach to modu-\nlar reduction involves individually reducing each subsystem\nmodel [3], i.e., in an “open-loop” sense, for which many\nstandard reduction methods exist [4–6]. This approach is\nparticularly practical because the computational cost of model\nreduction scales with the model order and the individual\nsubsystem models are clearly of lower order than the intercon-\nnected model as a whole. Even though one has to reduce mul-\ntiple lower-order subsystem models, this is usually still much\ncheaper than the reduction of one high-order interconnected\nsystem model. However, individual reduction of the separate\nsubsystem models might not retain the dynamics required\nfor the reduced, interconnected system model to accurately\napproximate its full-order model counterpart [3, 7].\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nTo improve the accuracy of the reduced interconnected sys-\ntem model, a variety of methods [8–14] have been developed\nto reduce the interconnected system model while preserving\nits interconnection structure. These methods effectively reduce\nthe individual subsystem models in a “closed-loop” sense by\nconsidering the interconnected dynamics. Consequently, such\nstructure-preserving reduction methods successfully reduce\nthe subsystem models to lower-order models that collectively\nconstitute a low-order, interconnected model that accurately\napproximates the original, high-order model.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nUnfortunately, for many complex engineering systems the\ninterconnected system model is of such a high order, that many\nstructure-preserving reduction methods become computation-\nally infeasible. In such cases, only computationally highly\nefficient reduction methods remain viable.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.7**r== 0.1**\niterative methods. For instance,\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nOne approach to address these computational constraints\nin\nis to use approximate,\n[15], the Gramians of the interconnected system model are\napproximated to reduce each subsystem model. However, as\navailable structure-preserving reduction methods evaluate the\ninterconnected model differently, i.e., not all use Gramians\n[3, 13, 14], there is no single iterative method that provides a\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nTo address this challenge, we introduce the framework\nof abstracted model reduction, illustrated in Figure 2c, as\nour first main contribution. The core idea is to use a low-\norder abstraction of the environment model, rather than the\noriginal, high-order environment model, to identify the sys-\ntem dynamics most relevant to the interconnected system.\nThe framework serves as a versatile solution to improve\nthe efficiency of structure-preserving reduction methods for\ninterconnected systems.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nAs a second contribution, we employ techniques from robust\nperformance theory, which have recently been applied in the\ncontext of reducing interconnected systems [17], to quanti-\ntatively assess how relying solely on an abstraction of the\nenvironment influences the resulting accuracy of the reduced\ninterconnected system model. This allows us to establish a\npriori requirements on the accuracy of both the abstracted\nenvironment model and the reduced system model, based on\nuser-defined, frequency-dependent or H∞-based specifications\non the model accuracy of the interconnected system as a\nwhole. These specifications are then leveraged to extend the\nframework of abstracted model reduction (abstracted reduction\nfor brevity) to the framework of robust abstracted reduction.\nThis latter framework automatically generates a reduced-order\nsystem model which guarantees stability of the reduced inter-\nconnected system model and guarantees the satisfaction of its\nprescribed accuracy specification.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nFinally, we evaluate the abstracted model reduction frame-\nwork by an industrial case study, where we reduce a structural\ndynamics model of lithography equipment of the semiconduc-\ntor industry, consisting of several interconnected subsystem\nmodels. Through application of abstracted model reduction in\ncombination with closed-loop balanced reduction [18, 19], we\nshow that a low-order abstraction of a subsystem’s environ-\nment is sufficient to ensure the relevance of the reduced sub-\nsystem model and the accuracy of the reduced interconnected\nsystem model.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.6**l== 0.5**r== 0.1**\nThe remainder of this paper is organized as follows. In\nSection II, the system-environment representation is presented\nand the problem is formally defined. Then, the framework of\nabstracted reduction is introduced in Section III. In this frame-\nwork, an error source is introduced both for the abstraction of\nthe environment and for the reduction of the subsystem. In\nSection IV, we relate both error sources to the resulting error\non the level of the interconnected system and use robust per-\nformance techniques to relate the different error specifications.\nThis relation is subsequently leveraged to present a systematic\napproach to abstracted reduction in Section V. Subsequently,\nin Section VI, both the general abstracted reduction framework\nand its robust extension are evaluated and compared to other\nreduction approaches from literature by means of an industrial\ncase study. Finally, Section VII presents conclusions on the\nproposed approach.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nNotation: In this paper, sets are generally indicated by\nblackboard-bold symbols, such as R, R>0 and C, which denote\nthe set of real, positive real and complex numbers, respectively.\nRm×p and Cm×p indicate matrices of real and complex\nnumbers, respectively, with m rows and p columns. Given\na complex matrix A, A⊤ and AH denote its transpose and\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nFig. 1. The interconnected system as a) an interconnection of three subsys-\ntems, and b) an interconnection of a single system and its environment.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nFig. 2. Three modular approaches for the reduction of a system within a\ndynamic environment: a) Open-loop (independent) reduction of the system\nmodel, b) Closed-loop (structure-preserving) reduction of the interconnection\nof the system and its environment, and c) Abstracted model reduction, where\nthe system is reduced in connection to an abstracted environment model.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nuniversally applicable solution to computational limitations. In\naddition, it is often unclear how the use of such approximate\nsolutions impacts the accuracy of the resulting reduced-order\ninterconnected system model.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nAlternatively, in case of sparsely interconnected systems,\nLeung et al. [16] perform the structure-preserving reduction\nof a subsystem using only information on its immediate\nneighbors. As a result, the reduced subsystem model is relevant\nwith respect to the considered cluster of subsystem models. For\neach subsystem, its immediate neighbouring subsystems there-\nfore act as a lower-order surrogate for its full environment,\nconsisting of all other subsystem models. By iterating over all\nsubsystems, all reduced subsystem model retain their relevance\nwith respect to their own clusters, theoretically resulting in a\n(more) accurate reduced, interconnected model.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nIn this paper, we introduce a novel, different perspective. Let\nus focus on a single subsystem, which we then denote as the\nsystem, which is embedded within an environment consisting\nof the remaining subsystems, as visualized schematically in\nFigure 1. A model for this environment is straightforwardly\nattained by the interconnection of all remaining subsystem\nmodels. Using this general system-environment model descrip-\ntion, including any system within a dynamic environment,\nwe can schematically visualize the open-loop and closed-\nloop reduction methods by Figures 2a and 2b, respectively.\nObserving the structure-preserving reduction as in Figure 2b,\nthe environment determines what essential system dynamics\nto retain (in the light of the interconnected system dynamics).\nHowever, this model for the environment is often unnecessarily\ncomplex (high order), thereby inducing computation infeasi-\nbility.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nIn the setting of interconnected systems, E(s) typically rep-\nresents several (interconnected) subsystems such that its order\nis typically large, particularly nE > nΣ. This motivates the\ncurrent work, where the evaluation of Σ(s) is computationally\ntractable, but the evaluation of Fl(E, Σ) is not.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.5**r== 0.2**\nB. Structure-preserving model reduction\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\nThe high-level objective is to find a transfer function matrix\nˆΣ(s) of order rΣ < nΣ such that Fl(E, ˆΣ), as depicted in\nFigure 3b, is well-posed, stable and accurately approximates\nFl(E, Σ) in terms of input-output behaviour, i.e., such that the\napproximation error, being the output of the error dynamics:\nΛC := Fl(E, ˆΣ) − Fl(E, Σ),\nis small in a suitable sense. Structure-preserving reduction\nmethods as discussed in [7, 9, 10, 21] aim to find an accurate\nreduced-order model Fl(E, ˆΣ). However, they are often only\napplicable to interconnected systems of limited order. In\naddition, most methods either do not guarantee stability of\nFl(E, ˆΣ), e.g. [7, 9], or require additional system properties\nsuch as passivity [10, 21].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nA further, intrinsic limitation of structure-preserving reduc-\ntion methods is the need for environment model E(s). In a\nmodular, model-based design process of complex engineering\nsystems, where subsystems are designed in parallel, the envi-\nronment model E(s) is typically not available or only a rough\nestimate ˆE(s) is available.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\nC. Problem statement\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nOur goal is to address the limitations of existing structure-\npreserving model reduction methods. Particularly, given a\nsystem Σ(s) and environment E(s), possibly both of large\norder, we aim to reduce Σ(s) to ˆΣ(s) such that\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n1) stability is preserved, i.e., Fl(E, ˆΣ) is well-posed, inter-\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\nnally stable, and Fl(E, ˆΣ) ∈ RH∞,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n2) the approximation is accurate in the sense that the ap-\nproximation error dynamics ΛC := Fl(E, ˆΣ)−Fl(E, Σ)\nis small.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nSpecifically, we consider the case where the order of E(s) is\nhigh, such that the application of existing structure-preserving\nreduction methods to Fl(E, Σ) is not feasible (or comes at\ntoo large computational cost).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\nIII. ABSTRACTED REDUCTION FRAMEWORK\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nWe will initially neglect giving guarantees on the accuracy\nand stability of the reduced model (such guarantees will be\ntreated in Sections IV-B and V) and focus on addressing\nthe computational limitations of structure-preserving reduction\nmethods. To this end, we propose the abstracted reduction\nframework in Section III-A. The computational benefits of\nthis approach and some applicability considerations are sub-\nsequently discussed in Section III-B.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nA. The abstracted reduction algorithm\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nTo facilitate efficient and accurate model reduction, we\npresent our framework of abstracted reduction, which is also\nillustrated in Figure 4, consisting of the following steps.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n(a) Lower LFT of E(s) and Σ(s), constituting the interconnected\nFig. 3.\nmodel Fl(E, Σ) and (b) lower LFT of E(s) and ˆΣ(s), constituting the\nreduced, interconnected model Fl(E, ˆΣ).\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nconjugate transpose, respectively, ∥A∥ denotes its 2-induced\nnorm, A ≻ 0 and A ⪰ 0 denote that A is positive definite\nand positive semi-definite, respectively, and A = diag(A1, A2)\ndenotes a block-diagonal matrix of submatrices A1 and A2.\nThe zero matrix and identity matrix are denoted by O and I,\nrespectively, while In denotes an identity matrix of size n.\nGiven a transfer function matrix Σ(s), where s is the Laplace\nvariable, ∥Σ∥∞ denotes its H∞-norm. The set of all proper,\nreal rational stable transfer matrices is denoted by RH∞.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nII. PROBLEM SETTING\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nThe system and its environment, as schematically visualized\nin Figure 1b, are modeled by the proper, real rational transfer\nfunction matrices Σ(s) and E(s), respectively, such that the\ninterconnected system model can be described by the block-\ndiagram shown in Figure 3a. The system model Σ(s) has\ninputs u ∈ Rm, outputs y ∈ Rp and McMillan degree (order)\nnΣ and the environment model E(s) has inputs w ∈ RmC and\ny ∈ Rp, outputs z ∈ RpC and u ∈ Rm and order nE, such\nthat\nE11 E12\nE21 E22\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nThe system and environment are interconnected by means of a\nlower linear fractional transformation (LFT), as defined below.\n P11(s) P12(s)\nP21(s) P22(s)\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n\nDefinition 1. Let P (s) =\n, Ml(s) and Mu(s) be\nproper, real rational transfer function matrices of dimensions\n(p1 + p2) × (m1 + m2), m2 × p2 and m1 × p1, respectively.\nThen, we define the lower and upper LFTs, respectively, as\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nFl(P, Ml) = P12Ml(I − P22Ml)−1P21 + P11,\nFu(P, Mu) = P21Mu(I − P11Mu)−1P12 + P22,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nwhich are said to be well-posed if I − P22Ml and I −\nP11Mu have a proper real rational inverse, respectively [20,\nDef. 9.2, Lem. 5.1].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nUsing this definition, the interconnection of system Σ and\nenvironment E as in Figure 3a can be written as Fl(E, Σ).\nWe make the following assumption to ensure that Fl(E, Σ) is\nwell-defined and internally stable (see [20, Chapter 5]).\nAssumption 1. We have Σ(s) ∈ RH∞, E(s) ∈ RH∞\nand the interconnection Fl(E, Σ) is well-posed and internally\nstable, i.e., Σ(I − E22Σ)−1 ∈ RH∞. Particularly, we have\nFl(E, Σ) ∈ RH∞.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nreduction methods to evaluate the approximate, coupled input-\noutput behaviour (via Fl( ˆF , Σ)), thereby significantly reduc-\ning computational costs. In an ideal world, without compu-\ntational limitations, one would like to do direct, structure-\npreserving reduction of Fl(E, Σ). However, this is not always\nfeasible or it is computationally very expensive. Hence, we\nsuggest abstracted reduction as a framework to enable an\napproximate structure-preserving reduction, where the direct\nstructure-preserving reduction of Fl(E, Σ) is not feasible or\ntoo computationally expensive.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nThe augmentation with the weighting matrices Gu and\nGy in Algorithm 1 serves two main purposes: (i) to control\nthe accuracy distribution over ˆΣ and Fl(E, ˆΣ), and (ii) to\nfacilitate error analysis in Section IV. Regarding the first\npurpose, increasing the magnitudes of Gu and Gy amplifies\nthe contribution of Σ’s input-output behaviour in Fl( ˆF , Σ).\nWhen using an input-output approximating reduction method,\nhigh-magnitude Gu and Gy thus improve ˆΣ’s approximation\nof Σ at the cost of the accuracy of Fl( ˆF , ˆΣ). This trade-off\nis discussed further in Section V-C. Regarding the second-\npurpose, it turns out that extending the number inputs and\noutputs Fl( ˆE, Σ) to Fl( ˆF , Σ), by augmentation of ˆE(s) to\nˆF (s), is often essential for deriving the error relations in the\nabstracted reduction algorithm, as detailed in Section IV.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.2**\nB. Computational benefits and applicability\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nTo compare the computational cost of abstracted reduction\nto direct structure-preserving reduction of Fl(E, Σ), recall that\nthe model orders of E(s), ˆE(s), Σ(s) and ˆΣ(s) are denoted as\nnE, rE, nΣ and rΣ, respectively. Structure-preserving reduc-\ntion methods based on balancing, such as [9, 10], usually scale\ncubically with the order of Fl(E, Σ) [23], while structure-\npreserving methods based on LMI’s, such as [14, 24], scale\neven more steeply. Hence, our abstracted approach replaces\na cost (nE + nΣ)c with (rE + nΣ)c for c ≥ 3, i.e., the en-\nvironment is replaced by a low-order abstraction, which yields\na significant reduction in computational cost when nE is large\nand rE is small, and when nE is large compared to nΣ.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nThe low-order abstraction ˆE can be obtained by an inexpen-\nsive reduction method, which does not preserve structure, such\nas [25, 26], as its accuracy is not so important for the accuracy\nof the reduced, interconnected system Fl(E, ˆΣ); it merely acts\nas a weight in the reduction of Σ to ˆΣ. In such a case, the\ncomputational cost of the reduction of Σ to ˆΣ is dominant.\nThis makes abstracted reduction mostly beneficial to systems\nwhere nE > nΣ and when rE is selected as rE ≪ nE, as\nshown in Figure 5.\nRemark 1. Sometimes, Σ(s) needs to be reduced while having\nincomplete knowledge of E(s). This is a common occurrence\nin modular design processes, where several subsystems are\ndesigned simultaneously. However, these design processes are\ntypically iterative, such that we generally possess subsystem\nmodels from a previous iteration. In our abstracted approach,\nwe suggest to use ˆE(s), an approximation of E(s), to ef-\nfectively indicate which dynamics of Σ(s) are relevant to\nFl(E, Σ). Therefore, an ˆE(s) of a previous design iteration\nor even an ˆE(s) based on a basic, preliminary environment\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nFig. 4. Schematic representation of the steps of abstracted reduction.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nAlgorithm 1. Abstracted reduction\nInput: p × m transfer matrix Σ(s) and (pC + m) × (mC + p)\ntransfer matrix E(s), of orders nΣ, nE, respectively, abstrac-\ntion order rE ≤ nE and reduction order rΣ < nΣ and\nweighting matrices Gy ∈ Cp×p and Gu ∈ Cm×m.\nOutput: Surrogate model ˆΣ(s) of reduced order rΣ, such that\nFl(E, ˆΣ) approximates Fl(E, Σ).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n1) Abstraction of E(s). Abstract E(s) to ˆE(s) in open\nloop, i.e., disconnected from Σ(s), by means of, e.g.,\nreduction or another form of surrogate modelling.\n2) Augmentation of ˆE(s). Augment the set of external\ninputs and outputs of Fl( ˆE, Σ) by incorporating Σ’s\n(weighted) inputs u and outputs y. This is equivalent to\nreplacing ˆE(s) with ˆF (s), resulting in Fl( ˆF , Σ), where\n\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nˆE12\nO Gy\nˆE22\nwhere ˆE is partitioned the same as E, see (1).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nˆE11 O\nO\nˆE21 Gu\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n3) Reduction of Σ(s). Use a structure-preserving reduction\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nmethod to reduce Fl( ˆF , Σ) to Fl( ˆF , ˆΣ).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n4) Substitution of E(s). Substitute the original environ-\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nment E(s) to obtain Fl(E, ˆΣ).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nTo interpret the concept of abstracted reduction, let us first\ndisregard the augmentation step by selecting Gu(s) = Om×m,\nGy(s) = Op×p and assume the use of reduction methods\nthat approximate a model’s input-output behaviour, such as\nbalancing methods [19, 22]. Then, abstracted reduction can\nbe interpreted as follows: whereas an open-loop reduction\napproach evaluates the input-output behaviour of the sys-\ntem (Σ) itself and structure-preserving reduction approach\nevaluates the coupled input-output behaviour (of Fl(E, Σ)),\nthe abstracted reduction approach uses structure-preserving\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nWe emphasize that we work with the error system ΛF (s) rather\nthan with ˆΣ(s) − Σ(s), for the following two reasons:\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\n• Structure-preserving reduction methods reduce subsys-\ntems based on the coupled dynamics, such that any\navailable error bounds are typically bounds on ΛF (s).\n• As we aim to (accurately) approximate the coupled\ndynamics, the magnitude of ˆΣ − Σ cannot be expected to\nbe a good indication of the quality of reduction. Alterna-\ntively, ΛF typically gives a much better indication of the\nquality of the overall reduction, as long as ΛE is small.\nNote that if ΛE = 0, Gu = Om×m and Gy = Op×p,\nindeed ΛF = Fl(E, ˆΣ) − Fl(E, Σ). Therefore,\nif a\nspecification on the accuracy of Fl(E, ˆΣ) is translated\nto bounds on ΛE and ΛF , these bounds are expected to\nbe less conservative than similar bounds on ˆΣ − Σ.\nThe abstraction and reduction steps, characterized through\nthe errors in (6) and (7), respectively, ultimately lead to the\nreduction error ΛC of the interconnected system, as previously\nintroduced in (4) and repeated here for completeness as\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\nE(s), ˆΣ(s) − Fl\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nOur main goal in this section is to relate ΛC to the error\nsystems ΛE and ΛF . As a first step in this direction, we\nexpress the reduced-order system ˆΣ in terms of the reduction\nerror system ΛF .\nLemma 2. Let Σ(s), ˆΣ(s) be transfer function matrices and\nlet ˆF (s) be as in (5) with square, invertible matrices Gu and\nGy, such that Fl( ˆF , Σ) and Fl( ˆF , ˆΣ) are well-posed with a\ndifference ΛF (s) as in (7). Then\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\n, Σ(I − ˆE22Σ)−1 + G−1\n**BLOCK**fs== 7.0**p== 4.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\n  O Gy\nGu ˆE22\n**BLOCK**fs== 7.0**p== 4.0**b== 0.4**t== 0.6**l== 0.8**r== 0.2**\n  O Gy\nGu ˆE22\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nis the 22-partition of ΛF as in (7), representing the transfer\nmatrix from the augmented inputs to the augmented outputs\nof Fl( ˆF , Σ).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\nProof. Let us first define P :=\ncan be rewritten as\n**BLOCK**fs== 7.0**p== 4.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\n O Gy\nGu ˆE22\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.8**r== 0.1**\nand note that (10)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nP, ˆΣ = GyΣ(I − ˆE22Σ)−1Gu + ΛF,22.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nGiven the fact that Gu and Gy are square and invertible, we\ncan then use the inversion formula of [28, Lemma 10.4] to\nextract ˆΣ from Fl(P, ˆΣ) as\n\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nP −1, Fl(P, ˆΣ)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nA substitution of (11) and (13) into (12) gives an expression\nsimilar to (9). Using the definition of the upper LFT in (3), we\nP, ˆΣ\nfinally move the G−1\nu\nto attain the expression for ˆΣ as in (9).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.7**r== 0.1**\nterms from P −1 to Fl\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFig. 5. Computational cost reduction per the amount of reduction of E(s),\nassuming negligible abstraction cost and cubic scaling of the reduction’s cost.\nThe results are given for three different relative orders of E(s) and Σ(s).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nmodel might improve the accuracy of Fl(E, ˆΣ) beyond what\ncan be achieved through (open-loop) reduction of Σ. However,\nin case a preliminary model ˆE is used without knowledge of its\naccuracy (i.e., without knowing E), the formal error analysis\nof Section IV can not be applied.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nIV. ERROR ANALYSIS AND THE RELATION OF BOUNDS\nThe reduction goal, as specified in Section II, is to achieve\na low-order surrogate model ˆΣ(s) such that\nthe reduced,\ninterconnected model Fl(E, ˆΣ) is well-posed, stable and (ac-\ncurately) approximates Fl(E, Σ). To this end, we first assume\nthe reduction/abstraction errors to be known transfer functions\nand determine the relation between introduced reduction and\nabstraction errors and the error of the interconnected system\nin Section IV-A. Subsequently, building on the approach\nintroduced in [27], we relate bounds on these errors in Sec-\ntion IV-B.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nA. Error relations\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nWe start by defining the errors introduced by the abstracted\nreduction procedure described by Algorithm 1 in Section III-A.\nFirst, the abstraction of the environment E(s) to its low-order\napproximation ˆE(s) leads to the error system\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nΛE(s) := ˆE(s) − E(s).\nWe recall from step 2 of Algorithm 1 that the resulting system\nFl( ˆE, Σ) is subsequently augmented to obtain the system\nFl( ˆF , Σ). Augmentation does not affect the well-posedness\nand stability of the interconnection, as stated next.\nLemma 1. Consider the p × m transfer matrix Σ(s) and\n(pC +m)×(mC +p) transfer matrix ˆE(s), such that Fl( ˆE, Σ)\nis well-posed and internally stable. Then, for any ˆF (s) in\n(5), with weighting matrices Gy ∈ Cp×p and Gu ∈ Cm×m,\nFl( ˆF , Σ) is well-posed and internally stable.\nProof. Following Definition 1 and [20, Corollary 5.2],\nFl( ˆF , Σ) is well-posed and internally stable if I − ˆE22Σ has\na proper real rational inverse and Σ(I − ˆE22Σ)−1 ∈ RH∞,\nrespectively. Both notions follow directly from the well-\nposedness and internal stability of Fl( ˆE, Σ).\n■\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nthe application of structure-preserving reduction\nmethods to Fl( ˆF , Σ) (reduction step at the bottom of Figure 4)\nleads to a reduced-order system ˆΣ and error system\n ˆF (s), Σ(s).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFig. 6. Schematic representation of the coupled error system ΛC (s) :=\nFl(E, ˆΣ) − Fl(E, Σ), where ˆΣ is given as in (9).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFig. 7. The coupled error dynamics ΛC (s) of (15), expressed as an upper\nLFT of the nominal model N (s) and error terms ΛE,22 and ˜ΛF .\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nRemark 2. The inversion formula of [28, Lemma 10.4] used\nin the proof of Lemma 2 motivates the augmentation of\nE with Gu and Gy. Note, however, that we used only the\naugmented inputs and outputs to express ˆΣ. This augmentation\nis excessive as we can also express ˆΣ in terms of ΛF instead\nof ΛF,22. When using ΛF , P = ˆF in the proof, and the\ninversion requires ˆF21 and ˆF12 to be full column and row\nrank, respectively. In this general case, ˆΣ can be expressed by\n(9), with G−1\n21, where (.)†\ndenotes the Moore-Penrose pseudoinverse. Augmentation of\nE with square and invertible Gu and Gy, however, gives the\nmost convenient expression for ˆΣ, because this prevents the\ninversion of (unknown) transfer function matrices ˆF21 and ˆF12.\nUsing the lower LFT definition in (2), the expression for the\ntotal reduction error system ΛC, as in (8), can be rewritten to\n ˆΣ(I − E22 ˆΣ)−1 − Σ(I − E22Σ)−1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nreplaced by ˆF †\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nSubstitution of ˆΣ(s) as in (9) gives an expression of ΛC in\nterms of the error system ΛF,22, as depicted schematically in\nFigure 6, where the expression for ˆΣ(s) is highlighted. This\nblock diagram facilitates an intuitive interpretation. Firstly, if\nΛF,22 = 0, the two feedback-loops with ˆE(s) cancel and\nˆΣ(s) = Σ(s). This represents the inverse relation between the\nabstraction and substitution steps of the abstracted reduction\nif ˆE22(s) = E22(s),\napproach. Also,\nthe feedback-loops\nindicated by a ∗ in Figure 6 cancel and the approach simplifies\nto standard structure-preserving reduction.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThe observed dependency of ΛC on ˆE22 in Figure 6\nsuggests that ˆE11, ˆE12 and ˆE21 do not influence ΛC. Note,\nhowever, that ˆE determines Fl( ˆF , Σ) through the definition\nof ˆF in (5). ΛF,22 thus implicitly depends on ˆE. We will\nnot consider this implicit dependency in the remainder of this\npaper and treat ΛF,22 as a independent error source.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nMotivated by Figure 6, we obtain a characterization of\nΛC that allows us to isolate the influence of abstraction\nand reduction errors on the error ΛC on the reduced-order\ninterconnected system.\nTheorem 1. Let Σ(s), ˆΣ(s) be transfer function matrices and\nlet ˆF (s) be as in (5), satisfying Assumption 1. Let ΛC(s) and\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nΛF,22(s) be as in (8) and (10), respectively, and let ΛE,22 :=\nˆE22 − E22 and ˜ΛF := G−1\ny ΛF,22G−1\nΛC = Fu(N, diag(ΛE,22, ˜ΛF , ΛE,22))\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.6**r== 0.2**\nI\nO\nO\nE12M E12 E12M\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\nM E21\nE21\nM E21\nO\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nM (s) = Σ(s)(I − E22(s)Σ(s))−1,\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nsuch that N (s) ∈ RH∞ due to Assumption 1.\nProof. Substitution of ˆE22 = E22 + ΛE,22, ˜ΛF (s)\nG−1\ngives\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.7**r== 0.1**\n:=\nand (9) into ΛC := Fl(E, ˆΣ) − Fl(E, Σ)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\ny ΛF,22(s)G−1\nu\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nΛC = −Fl(E, Σ) + Fl\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.6**r== 0.1**\n ,\n −E22−ΛE,22 I\nO\nI\n\nΣ(I − (E22 + ΛE,22)Σ)−1 + ˜ΛF\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nTo extract the error terms of ΛE,22 and ˜ΛF , we note that\n , Σ = Σ(I − (E22 + ΛE,22)Σ)−1,\n**BLOCK**fs== 5.0**p== 5.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\n  E22+ΛE,22 I\nO\nI\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nwith M as in (17), such that (18) can be rewritten as\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nΛC = −Fl(E, Σ) + Fl (E, Fu ([ K K\n**BLOCK**fs== 7.0**p== 5.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\nM M ] , ΛE,22) + ˜ΛF\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nFinally, these nested LFT’s can be expressed as the LFT of\n■\n(15), making repeated use of [28, Lemma 10.3].\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nThe expression of ΛC as in (15) can be verified intuitively\nby its graphical representation in Figure 7. Starting from\nFigure 6, which represents the definition of ΛC in (8), we\nexpress ˆE22 as a parallel connection of E22 and ΛE,22 and\n“pull out” the error terms ΛE,22 and ˜ΛF , resulting in Figure 7.\nThis shows that, indeed, (15) expresses ΛC as in (8).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nFurthermore, we introduce scaling matrices Dℓ and Dr,\nfor any ∆ of the form (26)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nwhich satisfy D1/2\n[29, Theorem 3.8], by requiring (Dℓ, Dr) ∈ D, with\n\n**BLOCK**fs== 9.0**p== 6.0**b== 0.7**t== 0.2**l== 0.7**r== 0.2**\nS11Ip\nO\nS21Ip\nO\nS11Im\nO\nS21Im\nO\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.2**l== 0.8**r== 0.2**\nO\ndF Im\nO\nO\n**BLOCK**fs== 9.0**p== 6.0**b== 0.7**t== 0.2**l== 0.8**r== 0.2**\nO\ndF Ip\nO\nO\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.2**l== 0.8**r== 0.2**\nS12Ip\nO\nS22Ip\nO\n**BLOCK**fs== 9.0**p== 6.0**b== 0.7**t== 0.2**l== 0.8**r== 0.1**\nO\nO\nO\nImC\nS12Im O\nO\nS22Im O\nIpC\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.7**r== 0.1**\ndF ∈ R>0, S ∈ C2×2, S = SH ≻ 0\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nWe can then use the approach of [27] to formulate the\nfollowing guarantee on the boundedness of ΛC(s).\nTheorem 2. Consider the transfer functions Σ(s), E(s) and\nFl(E, Σ) satisfying Assumption 1 and error dynamics (15).\nLet W (s) and V (s) be bistable and biproper weighting\nF and\nfunctions as given in (26) and let the sets\nC be as given in (25). If there exist some scaling matrices\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n(Dℓ, Dr) ∈ D, with D as given in (27), such that\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.6**r== 0.1**\nN (iω)DrN H (iω) ⪯ Dℓ ∀ ω ∈ R,\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nwith N = V N W and N as in (16), then it follows that if\nΛE,22 ∈ E,22 and ˜ΛF ∈ ˜\nFl(E, ˆΣ) is well-posed and internally stable and the coupled\nerror dynamics satisfies\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nProof. We first note that N ∈ RH∞ due to Assumption 1 and\nN ∈ RH∞ due to the weighting functions V, W ∈ RH∞.\nThen, according to [27, Theorem 3.2], for any ΛE,22, ˜ΛF ∈\nRH∞ satisfying (29), the coupled error dynamics (15) are\nwell-posed, internally stable and satisfies (30) if and only if\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nwhere µ denotes the structured singular value [29, Defini-\ntion 3.1]. Instead of µ , we use its upper bound\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\nFollowing\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nwhich can be tightened by optimizing over Dℓ and Dr [29].\nrequirement\nTheorem 3.5],\n¯σ(D−1/2\n) < 1 can be equivalently stated as\nN (iω)DrN H (iω) ⪯ Dℓ. Therefore, (28) implies (31) and\nthus ΛC ∈ RH∞ satisfies (30). Due to the definition of ΛC\nin (8) and Assumption 1, this also guarantees the internal\nstability and well-posedness of Fl(E, ˆΣ).\n■\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nRemark 3. The approach of µ-analysis, as exploited in Theo-\nrem 2, typically requires Dℓ, Dr to only satisfy D1/2\nr ∆ =\n∆D1/2\n. However, we impose additional constraints on the\nℓ\npositive definiteness and Hermitian form of Dℓ, Dr in (27).\nThese restrictions simplify further computation, while they do\nnot increase the conservatism of (32) [29].\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFig. 8. Robust performance framework, with the nominal model N and the\nweighted uncertainties pulled out.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nB. A robust performance perspective\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nNext, we will use the formulation of the overall error dy-\nnamics as in Theorem 1 (and Figure 7) to relate requirements\non bounds on this error dynamics to the errors made in\nthe underlying abstraction and (structure-preserving) reduction\nstep. We will assume a prescribed, weighted bound on the\nerror ΛC(s) and aim to translate this to bounds on ΛE,22(s)\nand ˜ΛF (s). Specifically, we prescribe weighting matrices\nVC(s) ∈ RH∞ and WC(s) ∈ RH∞ and formulate the\nrequirement as\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\n∆C(s) = VC(s) ΛC(s) WC(s),\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nfor some ∆C(s) ∈ RH∞ satisfying ∥∆C∥∞ ≤ 1.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nThe abstraction and reduction errors ΛE,22(s), ˜ΛF (s) are\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nexpressed similarly as\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nΛE,22(s) = WE(s) ∆E,22(s) VE(s),\n˜ΛF (s) = WF (s) ˜∆F (s) VF (s),\nfor bistable weighting matrices VE, WE, VF , WF ∈ RH∞,\nimplying that V −1\nE , V −1\nF ∈ RH∞, and some\n∆E,22, ˜∆F ∈ RH∞ satisfying\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nThe requirements of (22) and (23) can be stated equivalently\nby restricting ΛE,22, ˜ΛF and ΛC to the sets of transfer\nfunctions E,22, ˜\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nF and C, respectively, given as\nE ∥∞ ≤ 1,\nE,22 := ΛE,22\nE ΛE,22V −1\n\nF := ˜ΛF\n˜\n˜ΛF V −1\n ∥W −1\nF\n\nC := ΛC\n ∥VCΛCWC∥∞ < 1.\nWe can now formulate the goal of this section explicitly\nas: given the sets E,22, ˜\nF and C, determine whether the\ncoupled error dynamics are guaranteed to satisfy ΛC ∈ C\nfor any ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nTo determine the relation between E,22, ˜\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nF and C, we\nwill use tools from robust performance analysis. By combining\nexpression (15) for the coupled error dynamics ΛC with (22)\nand (23), we attain the framework of robust performance\ntheory, as visualized in Figure 8. Then, the uncertainties and\nweights are combined in the block-diagonal transfer functions\n**BLOCK**fs== 10.0**p== 6.0**b== 0.0**t== 0.9**l== 0.1**r== 0.5**\n∆(s) := diag(∆E,22(s), ˜∆F (s), ∆E,22(s), ∆C(s)),\nV (s) := diag(VE(s), VF (s), VE(s), VC(s)),\nW (s) := diag(WE(s), WF (s), WE(s), WC(s)).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nBesides the relation of weighted H∞-norm set defini-\ntions, as in Theorem 2, similar methods from robust per-\nformance are also applicable to relate frequency-dependent\nerror bounds. To this end, with slight abuse of notation, we\nformulate frequency-dependent error set definitions by restrict-\ning ΛE,22(iω), ˜ΛF (iω) and ΛC(iω) to E,22(ω), ˜\nF (ω) and\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nC(ω) at frequency point ω ∈ R, where\n\nΛE,22(iω) \n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nabstraction and reduction errors. This result is subsequently\nused to formulate the robust abstracted reduction framework,\nto efficiently reduce Fl(E, Σ) to Fl(E, ˆΣ), such that Fl(E, ˆΣ)\nis well-posed and internally stable and ΛC ∈ C.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nAdditionally, we formulate a frequency-dependent variant\nof the above-mentioned optimization problem in Section V-B,\nusing Corollary 1, which is more flexible, but provides no\nstability guarantees. We then conclude in Section V-C with\nsome notes on the properties of the proposed methods.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\n\nWE(iω)−1\n\n˜ΛF (iω) \n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nΛE,22(iω)VE(iω)−1\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nA. The robust abstracted reduction framework for stability and\naccuracy guarantees\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nWF (iω)−1 ˜ΛF (iω)VF (iω)−1\n\n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nC(ω) := ΛC(iω) \n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\n ∥VC(iω)ΛC(iω)WC(iω)∥ < 1.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nUsing the set definitions of (33), we formulate a guarantee\nsimilar to Theorem 2 on the boundedness of ΛC(iω) at a\nspecific frequency point ω ∈ R.\nCorollary 1. Consider the transfer functions Σ(s) and E(s),\nsuch that Fl(E, Σ) is well-posed and stable. Let W (s) and\nV (s) be weighting functions as in (26). Let ω ∈ R and let\nthe sets E,22(ω), ˜\nF (ω) and C(ω) be given as in (33). If\nthere exist (Dℓ, Dr) ∈ D, with D as given in (27), such that\nN (iω)DrN H (iω) ≤ Dℓ,\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nwith N (iω) = V (iω)N (iω)W (iω) and N as in (16), then it\nfollows that if\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\nΛE,22(iω) ∈ E,22(ω) and ˜ΛF (iω) ∈ ˜\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nthe coupled error dynamics ΛC, evaluated at ω, satisfies\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nΛC(iω) ∈ C(ω).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nProof. The proof closely follows [27, Theorem 3.4], consid-\nering µ per frequency point, and is largely equivalent to\n■\nTheorem 2.\n**BLOCK**fs== 8.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nV. A PRIORI SPECIFICATIONS FOR ABSTRACTED\nREDUCTION\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nIn this section, we will leverage the relation between the\nintroduced errors, as determined in Section IV, to guide the\nabstraction of E and reduction of Σ. This allows us to guaran-\ntee that the resulting coupled error ΛC satisfies a user-defined,\npossibly frequency-dependent specification. Specifically, we\nwill answer the question: How should ˆE(s) and ˆΣ(s) be\nselected, such that Fl(E, ˆΣ) is stable and meets a prescribed\naccuracy specification?\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\nthe perspective in which\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nE,22,\nTo this end, we adopt\n˜\nF and C represent specifications on ΛE,22, ˜ΛF and ΛC,\nrespectively. Explicitly, an error, such as ΛC, satisfies its\nspecification, C, if ΛC ∈ C. Theorem 2 and Corollary 1\nthen allow us to relate such specifications. In particular, we\nC is given and we mean to find\nfocus on the case where\nspecifications E,22 and ˜\nF that guarantee ΛC ∈ C.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nFirst, in Section V-A, we formulate an optimization problem\nF , as in (25), are\nwhere\ndetermined as the least conservative specifications on the\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nC is given and\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nTo guarantee the stability and accuracy of Fl(E, ˆΣ), cap-\nC, we will use Theorem 2 to provide suitable\ntured in\nspecifications E,22 and ˜\nF . This can be interpreted as a dis-\ntribution of the coupled error budget C over the abstraction\nerror budget E,22 and the structure-preserving reduction error\nbudget ˜\nF . To maximize the reduction of E and Σ, we aim\nfor lenient specifications (large error budgets) E,22 and ˜\nF ,\nas in (33). To this end, we prescribe the weighting matrices\nW (s), as in (26), and ¯V (s), defined as\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.6**r== 0.1**\n¯V (s) := diag( ¯VE(s), ¯VF (s), ¯VE(s), ¯VC(s)),\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nwhere ¯ε = diag(¯εEIp, ¯εF Im, ¯εEIp, Imc) and V is given in\n(26). Particularly, ¯εE, ¯εF ∈ R>0 represent H∞-bounds on the\nweighted errors as\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.7**r== 0.2**\n\nE ΛE,22 ¯V −1\n∞ ≤ ¯εE,\nE\n\n˜ΛF ¯V −1\n∞ ≤ ¯εF\nF\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.8**r== 0.2**\nthere exist\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.7**r== 0.3**\nto note that\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nand we aim to maximize ¯εE and ¯εF . Then, for a given W (s)\nand ¯V (s), E,22 and ˜\nF are defined by W (s) and V (s) =\n¯ε ¯V (s), as in (33).\nis important\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\ninfinitely many\ncombinations of ¯εE and ¯εF that guarantee ΛC ∈ C. To\nselect which unique combination is the “optimal” one, we\nintroduce an additional scalar parameter β to weigh the relative\nimportance of ˜\nF over E,22. This results in the following\noptimization problem.\nTheorem 3. Consider the transfer functions Σ(s), E(s) and\nFl(E, Σ) satisfying Assumption 1 and error dynamics (15).\nLet the requirements E,22, ˜\nF and C be given as in (25)\nand let ¯V (s) and W (s) be prescribed bistable and biproper\nweighting functions as in (37) and (26), respectively. Consider\nnow the optimization problem where β ∈ R>0 is a given\ntuning variable:\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\ngiven ¯V (s), W (s)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.6**r== 0.1**\nmaximize ¯ε2\nsubject to ¯ε2 N (iω)DrN H (iω) ⪯ Dℓ ∀ ω ∈ R,\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nwhere N = ¯V N W , N is given in (16) and D in (27).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIf ¯εE, ¯εF is a feasible solution to (39), then for any ΛE,22 ∈\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nRH∞ and ˜ΛF ∈ RH∞ that satisfy\n**BLOCK**fs== 7.0**p== 7.0**b== 0.1**t== 0.9**l== 0.6**r== 0.2**\nΛE,22 ∈ E,22 and ˜ΛF ∈ ˜\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nthe reduced, interconnected system Fl(E, ˆΣ) ∈ RH∞ and the\nerror system satisfies ΛC ∈ C.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nProof. The proof follows from Theorem 2, where only V (s)\nis replaced by ¯ε ¯V (s). Substitution of V = ¯ε ¯V into (28) gives\n■\nthe constraint of (39).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nRemark 4. The matrix inequality of the optimization problem\nin Theorem 3 is not linear in its unknowns, but can be solved\nefficiently by iteratively solving for ¯ε and Dr, as shown in\n[17].\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nThe solution to the optimization problem of Theorem 3 de-\ntermines the maximum weighted H∞-bounds ¯εE and ¯εF , that\ndefine E,22 and ˜\nF . However, to make sure these accuracy\nspecifications can be satisfied by significantly reduced models\nˆE and ˆΣ, the weighting functions ¯V and W should reflect\nthe expected trend of the error system’s frequency response.\nFor example, if the reduction method for abstracting the envi-\nronment is known to particularly approximate low-frequency\ndynamics, ¯VE and WE could be prescribed as low-pass filters\nto ensure a more uniform response of W −1\nE . This\nresults in a less conservative H∞-bound and a lower-order\nabstraction of E.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nTo systematically reduce an interconnected system, we\npresent the robust abstracted reduction framework: an ex-\ntension of Algorithm 1 with the optimization problem of\nTheorem 3. Using this framework in combination with ap-\npropriate (structure-preserving) reduction methods, Fl(E, Σ)\nis efficiently reduced to Fl(E, ˆΣ), such that Fl(E, ˆΣ) is well-\nposed, internally stable and ΛC ∈ C (i.e., the reduced-order\ninterconnected system satisfies a given error specification).\nAlgorithm 2. Robust Abstracted Reduction\nInput: Transfer functions Σ(s), E(s) and Fl(E, Σ) satisfying\nAssumption 1, bistable and biproper ¯V and W as in (37) and\n(26), scalar β ∈ R≥0 and full-rank weighting matrices Gu ∈\nCm×m and Gy ∈ Cp×p.\nOutput: Surrogate model ˆΣ(s) of reduced order rΣ, such that\nFl(E, ˆΣ) is well-posed, internally stable and ΛC ∈ C.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n1) Optimization Solve the optimization problem given in\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nTheorem 3 to attain specifications ˜\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n2) Abstraction of E. Reduce E to ˆE of the lowest order\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nrE, such that ΛE,22 ∈ E,22.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n3) Augmentation of ˆE. Augment the inputs and outputs\nof Fl( ˆE, Σ), resulting in Fl( ˆF , Σ), with ˆF as in (5).\n4) Reduction of Σ(s). Reduce Σ(s) to ˆΣ(s) of the lowest\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\norder rΣ, such that ˜ΛF ∈ ˜\n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\nF , where\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n5) Substitution of E. Substitute the original environment\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nE to obtain Fl(E, ˆΣ).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nB. Frequency-based robust abstracted reduction\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAlgorithm 2 fully addresses the problem statement of\nSection II-C by providing a systematic and efficient way\nto reduce Fl(E, Σ). However, the algorithm requires several\ninputs, among which the bistable weighting functions ¯V (s)\nand W (s). In Section V-A, we advise ¯V (s) and W (s) to\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nreflect the expected trend error system’s response, but this\nmight be unknown or very irregular over the frequency range\nof interest. To avoid providing these weighting functions, we\nwill formulate an alternative approach, based on Corollary 1,\nto relate the error specifications E,22(ω), ˜\nF (ω) and C(ω),\nas in (33), for a specific discrete frequency grid ω ∈ .\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nTo simplify computation, we restrict V (s) and W (s), eval-\nuated at ω, to satisfy V (iω) ∈ V and W (iω) ∈ W, with V\nand W given as\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\ndiag(VE, VF , VE, VC )\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nVE = diag(vE,1, ..., vE,p) ∈ Rp×p\n>0 ,\nVF = diag(vF,1, ..., vF,m) ∈ Rm×m\nVC = diag(vC,1, ..., vC,mC ) ∈ RmC ×mC\n\n**BLOCK**fs== 9.0**p== 8.0**b== 0.6**t== 0.3**l== 0.6**r== 0.2**\ndiag(WE, WF , WE, WC )\n**BLOCK**fs== 9.0**p== 8.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nWE = diag(wE,1, ..., wE,m) ∈ Rm×m\n>0\nWF = diag(wF,1, ..., wF,p) ∈ Rp×p\n>0 ,\nWC = diag(wC,1, ..., wC,pC ) ∈ RpC ×pC\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nThis results in the following optimization problem.\nTheorem 4. Consider the transfer functions Σ(s) and E(s),\nsuch that Fl(E, Σ) is well-posed and stable. Let N (s), D, V\nand W, as given in (16), (27), (42) and (43), respectively, and\nlet the sets E,22(ω), ˜\nF (ω) and C(ω) be given as in (33).\nConsider now the optimization problem at the frequency point\nω ∈ R where VC(iω) and WC(iω) are prescribed weighting\nmatrices and β ∈ R>0 is a given tuning variable:\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.6**r== 0.3**\ngiven VC(iω), WC(iω)\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nminimize tr(XV V −2(iω)) + tr(XW W −2(iω))\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.6**r== 0.4**\nsubject to\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nW −2(iω)D−1\nr\nN (iω)\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.8**r== 0.2**\nN H (iω)\nV −2(iω)Dℓ\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nV (iω) ∈ V, W (iω) ∈ W, (Dℓ, Dr) ∈ D,\nXW = diag(Im, βIp, Im, IpC ),\nXV = diag(Ip, βIm, Ip, ImC ).\nIf V (iω), W (iω) is a feasible solution to (44), then for any\nF (ω), it is ensured\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\nΛE,22(iω) ∈ E,22(ω) and ˜ΛF (iω) ∈ ˜\nthat ΛC(iω) ∈ C(ω).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nProof. In [17, Theorem 1] the inequality of (44) is shown to\nbe equivalent to (34) when V (iω) ∈ V and W (iω) ∈ W. The\n■\nrest of the proof follows directly from Corollary 1.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nRemark 5. The matrix inequality of the optimization problem\nin Theorem 4 is not linear in its unknowns, but can be solved\nefficiently by iteratively solving for V −2(ω), W −2(ω) and\nDℓ, Dr as shown in [17].\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nC(ω) for a specific frequency ω. In addition,\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nCompared to Theorem 3, which required the bistable trans-\nfer matrices ¯V (s) and W (s), Theorem 4 only needs to be\nsupplied with the required coupled accuracy specification\nC(ω) can\nbe selected more freely, as the weighting matrices V (iω) and\nW (iω) do not even need to represent actual transfer functions.\nHowever, this comes at the loss of any guarantees on well-\nposedness, stability or on an error bound for other frequency\npoints.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nRemark 6. A third abstracted reduction algorithm could be\nformulated based on Theorem 4, using frequency-dependent\nbounds as in (33). However, as this algorithm would be nearly\nequivalent to Algorithm 2, it is omitted for brevity.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nC. Computational considerations and tuning parameters\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nThe main drawback of the systematic approach of Algo-\nrithm 2 is the increase of computational cost with respect to\nstandard abstracted reduction as in Algorithm 1. The additional\ncost, however, heavily depends on the system under consid-\neration. The computational cost of the optimization problems\nas presented in Theorem 3 and Theorem 4, scales with the\nnumber of inputs and outputs of the nominal model N (s)\n[27]. Therefore,\nthe robust approach is best applicable to\nsystems where the number of inputs and outputs, m and p, are\nsmall (e.g., less than 10). Furthermore, in the frequency-based\napproach, optimization is typically conducted for a discrete\nfrequency grid ω ∈ . To expedite this process, parallel com-\nputation can be employed, simultaneously addressing multiple\nfrequency points.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nBesides the additional computational cost of optimization in\nstep 1) of Algorithm 2, the robust approach also complicates\nthe reduction of E and Fl( ˆF , Σ) in step 2) and 4). Namely, the\nmodels should be reduced as much as possible, while satisfy-\ning ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜\nF , which typically results in\nan iterative procedure. In case of standard, projection-based\nreduction methods, this too can be implemented efficiently\nby iteratively increasing the order of the projection matrix.\nTo check efficiently whether ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜\nF\nat each iteration, the H∞-norm can be calculated using the\ninstead, frequency-based bounds are\napproach of [30]. If,\n ˆF (iω), Σ(iω) can\nused, as in Theorem 4, E22(iω) and Fl\nbe determined beforehand, such that ΛE,22(iω) and ˜ΛF (iω)\ncan be determined rapidly by only calculating ˆE22(iω) and\nFl( ˆF (iω), ˆΣ(iω). Particular reduction methods also permit a\npriori lower or upper error bounds [31, 32], which may be\nused to select an initial rE, rΣ for faster convergence.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nIn Algorithm 2, β, Gy and Gu are tuning parameters to\nbe supplied by the user. Although any selection of these\nparameters guarantees ΛC to be in C, they greatly influence\nthe resulting reduced-order model ˆΣ(s) and the required com-\nputational cost. Their specific influence is discussed below:\nOptimization parameter β\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\nF at the cost of a smaller set size of\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nParameter β is used to choose how to allocate the total\nF in the\nC between\nallowed reduction error\noptimization of Theorem 4. A larger β therefore increases the\nset size of ˜\nE,22,\nsuch that Σ(s) can be reduced further and E(s) can be\nreduced less. Vice versa, a smaller β allows more reduction\nof E(s) and lesser reduction of Σ(s). Thus, β gives a trade-\noff between the computational cost of the structure-preserving\nreduction (smaller ˆE(s) reduces cost) and the amount of\neffective reduction of Σ(s).\nRemark 7. While β allows the user to increase the size of ˜\nF ,\nthere exists an upper bound to ˜\nF for which E,22 is an empty\nset, i.e., ΛE,22 = O. At this point, the reduction converts\nto the expensive structure-preserving reduction of Fl(E, Σ),\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.8**r== 0.1**\nE,22 however, ˜\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nwhich we aim to avoid with abstracted reduction (see also\nSection IV-A). For a sufficiently small\nF\napproximates this upper bound and further increasing β does\nnot allow further reduction of ˆΣ(s). This value of β is in\nsome sense optimal, as ˆΣ(s) is reduced as far as possible\nusing Algorithm 2, and further increasing β only results in an\nincreased order of ˆE(s) and thus in an increased computational\ncost of the reduction. This value is however only attainable\nthrough iterative evaluation of the resulting rΣ and rE for\nvariable β, which is very costly itself.\nAugmented weighting Gu and Gy\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nWeighting matrices Gu and Gy scale the magnitude of\nthe augmented outputs. Intuitively, increasing their magnitude\ntherefore increases the importance of the augmented outputs,\ni.e., the 22-partition of Fl( ˆF , Σ) as in (10), with respect to\nthe external inputs and outputs of Fl( ˆE, Σ). Large Gu and\nGy would therefore improve the approximation Fl( ˆF , Σ)22,\nsuch that fewer states are required to achieve ˜ΛF ∈ ˜\nF ,\nwhereas small Gu and Gy would improve the approximation\nFl( ˆF , Σ)11 = Fl(E, Σ). Thus, the magnitudes of Gu and\nGy give a trade-off between accuracy of Fl(E, ˆΣ) and the\namount of reduction. This means that for smaller Gu and\nGy, ΛC becomes smaller, i.e., the reduction becomes more\nconservative with respect to the specified\nC, because 1)\nthere is more focus on the accuracy of Fl( ˆE, Σ) compared\nto Fl( ˆF , Σ)22 and 2) rΣ is increased.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nIn addition to the simple scaling of magnitudes, Gu and Gy\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\ncan also be related to VF (s) and WF (s), for instance, as\nGu,ij = α (∥VF,ij∥2)−2 , Gy,ij = α (∥WF,ij∥2)−2 ,\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nwhere (.)ij denotes the i,j’th element of the transfer matrix,\nα is a scalar R>0 and ∥(.)∥2 denotes the H2-norm. By the\ninverse relation of (45), the reduction can be steered to focus\nmost on the input-output pairs for which the bounds are tight,\nallowing further reduction. Additional frequency dependencies\ncan also be reflected by augmentation with transfer matrices\nGu(s) and Gy(s), which should be bistable and biproper to\nallow Lemma 2. This is considered out of the scope of this\npaper.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nVI. REDUCTION OF AN INTERCONNECTED,\nSTRUCTURAL-DYNAMICS MODEL\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nTo evaluate the framework of abstracted reduction, we\nconsider a structural-dynamics model for equipment in the\nlithography industry. The system, as shown schematically\nin Figure 9, represents a simplified, scaled-down frame of\na lithography machine, consisting of several interconnected\ncomponents. The system is a typical example of an intercon-\nnected structural dynamics system encountered in industry.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nThe interconnected system is about 25×42×40 cm (x×y×z)\nand is made of 5 aluminium components (or subsystems), as\nshown in Figure 9: two plates of different thickness, a frame\nfor the support of optical equipment, a bridge-like frame and a\nframe of beams connecting all components. The two plates are\nconnected to the ground with three translational springs with\na stiffness of 1010 N/m each and three rotational springs with\na stiffness of 105 Nm/rad each in two locations per plate, see\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\n2) In Section VI-B, we evaluate the frequency-based robust\nabstracted reduction framework of Section V-B, where\nwe input C(ω) and reduce the thin plate to an order rΣ,\nsuch that the resulting ΛC(s) ∈ C(ω), for all ω ∈ .\nThe abstracted environment ˆE(s) is obtained by the\nHintz-Herting (HH) component mode synthesis method [34],\nwhereas the reduction of Σ(s) (a component model) is per-\nformed using Closed-Loop Balanced Reduction (CLBR), as\nintroduced by Ceton and Wortelboer et al. [18, 19]. Specifi-\ncally, the reduction of Σ(s) is performed using residualization\n(also called singular perturbation), which retains the steady\nstate transfer. See [6] for more details.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\nA. Fixed-order reduction\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nFor this evaluation, all 5 subsystems are reduced to a\nlower order rΣ, as indicated in Table I, using the abstracted\nreduction approach introduced in this paper. To this end,\nwe first formulate an environment model Ej, for each j ∈\n{1, . . . , 5}, as the interconnection of all remaining subsystems\nΣl, l ∈ {1, . . . , 5}\\{j}, and then perform Algorithm 1 once\nfor each subsystem Σj.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.4**l== 0.5**r== 0.1**\nTo properly evaluate the reduction of all Σj in the abstracted\nreduction framework, three balanced reduction methods are\nused: subsystem balanced reduction (ssBR), without taking\nthe environment into account (see Figure 2a and [22]), in-\nterconnected systems balanced reduction (ISBR), taking its\nfull environment into account (see Figure 2b and [9]), and\nabstracted reduction using CLBR (aCLBR), taking only an\nabstraction of the environment into account (see Figure 2c,\nAlgorithm 1 and [19]). The three resulting reduction methods\nare then compared in terms of computational cost and the\naccuracy of the resulting reduced-order, interconnected model.\nThe ISBR approach, as introduced by Vandendorpe and Van\nDooren [9], is a generalization of CLBR. Whereas CLBR is\nonly defined for 2 interconnected subsystems, ISBR reduces\nall k ≥ 2 subsystems to retain their relevance with respect to\nthe interconnected system. For aCLBR, we use Gy = Gu =\nOm×m, i.e., no augmentation, to focus solely on the accuracy\nof Fl(E, ˆΣ).\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThe accuracy of the reduced-order, interconnected models\nis measured by visually comparing their frequency response\nfunctions (FRFs) with the FRFs of the unreduced intercon-\nnected model, the FRFs of their error ΛC(s) and the bounded\nL2-norm of ΛC(s) [20] (on the frequency-domain of 10 to\n106 Hz, relevant for this application) given by\n 2π×106\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\ntrace[ΛH\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\nC (jω)ΛC(jω)]dω.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nTable II compares the computational cost of the reduc-\ntion methods1 and the obtained accuracy. Clearly, and as\nexpected, ssBR is the most computationally efficient, as only\nthe dynamics of the individual subsystem models are evaluated\nupon their reduction. ISBR, on the other hand, considers\nthe full interconnected model dynamics, which results in a\nconsiderable increase in computational cost with a factor 12.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n1All computation is performed on a HP Z-book Studio G5 with a Intel(R)\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nCore(TM) i7-9750H CPU and 16 GB of RAM.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nFig. 9. Schematic drawing of the benchmark system, where\na spring connection to the ground, • indicates an interface point and\nindicates a collocated external input/output pair.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\nindicates\n**BLOCK**fs== 6.4**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nTABLE I\nMODEL ORDERS nΣ, NUMBER OF INPUTS AND OUTPUTS m = p, ORDER\nOF THE CORRESPONDING ABSTRACTED ENVIRONMENT rE , AND ORDER\nrΣ AFTER REDUCTION.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nThin plate\n\nThick plate\n\nBeam frame\n\nBridge\nOptics frame\n\nInterconnected system 2136\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nFigure 9. The components are connected to each other with\nlinear springs with a stiffness of 108 N/m per spring in x-,\ny- and z-directions at the interface points shown in Figure 9.\nEach component has a modal damping factor [33] of 5% for\neach eigenmode. As a result, the interconnected model has no\nrigid-body modes and is asymptotically stable.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nAll components are modeled by high-order transfer function\nmatrices with forces as their inputs and collocated displace-\nments as outputs, such that\nthe spring interconnection is\nrepresented by a static interconnection matrix [17]. The model\norder and the number of inputs and outputs per component\nmodel are indicated in Table I. The interconnected system has\ntwo external, collocated, force inputs and displacement outputs\n(mC = pC = 2): one at the interface between the thin plate\nand the beam frame in y-direction and one at the interface\nbetween the bridge and the beam frame in x-direction, as\nindicated in Figure 9.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThe original interconnected system model, with an order\nof 2136, is too computationally costly for various industrial\napplications, such as real-time simulation, (low-order) con-\ntroller synthesis, online monitoring, and sensitivity analysis.\nTherefore, in this section, we will reduce the interconnected\nsystem model to a lower order. Specifically, we will perform\ntwo evaluations:\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n1) In Section VI-A, we evaluate the abstracted reduction\nframework of Algorithm 1, where we select\nthe re-\nduction orders rE and rΣ beforehand, as indicated in\nTable I, and reduce all subsystems.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nFig. 10. The collocated FRFs of the benchmark model at the interface on the bridge (a) and the thin plate (b), and the FRFs of the corresponding error entries\nfrom ΛC in (c) and (d), respectively. The full-order model (FOM,\n) .\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\n) is compared to the models reduced by ssBR (\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\n) and aCLBR (\n**BLOCK**fs== 6.4**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nTABLE II\nCOMPUTATION TIME AND ACCURACY OF THE REDUCTION METHODS.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.9**\nMethod\n**BLOCK**fs== 6.0**p== 11.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\n∥ΛC ∥2\n∥Fl(E,Σ)∥2\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.6**l== 0.1**r== 0.8**\nssBR\nFull ISBR\nAbstracted CLBR\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nBy taking only an abstraction into account, aCLBR reduces\nthis cost by a factor 6 to only twice the cost of ssBR.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nRemark 8. When Σ(s) represents the beam frame, the order\nof Fl( ˆF , Σ) is 1128, which remains relatively high. This high\norder can be attributed to the disparity in order between the\nbeam frame and the other subsystems. Recall that aCLBR\ndemonstrates its greatest efficiency improvement when the\nenvironment\nis substantially larger than the subsystem, as\nillustrated in Figure 5. If all subsystems would be of similar\nsize, the computational cost of aCLBR would approach the\ncost of ssBR.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAs mentioned before, Table II also indicates the accuracy\nof the various reduced-order models (ROMs) by means of the\n(relative) L2-norm of the corresponding error systems. While\nall relative L2-norms are quite large due to the significant\norder reduction, a clear distinction in accuracy is observable.\nFirst of all, the ssBR-ROM results in a significantly higher\nL2 error norm than the other two ROMs. This is as expected,\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nas ssBR considers only the separate subsystems. Furthermore,\nthe accuracy of the ISBR-ROM, in terms of its L2 error norm,\nshows a slight superiority with respect to the accuracy of the\naCLBR-ROM. This small sacrifice in accuracy is a logical\nresult from the introduced abstraction error with aCLBR. We\ncan conclude that aCLBR is capable of achieving an accuracy\nlevel comparable to ISBR, while requiring computational cost\nalmost competitive wth ssBR.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nThe magnitudes of the two collocated FRFs of the full-order\nmodel (FOM) of the interconnected system are visualized\ntogether with the FRFs of the three corresponding reduced-\norder models (ROMs) in Figures 10a and 10b. The FRFs of\nthe collocated errors from ΛC(s), i.e., the differences between\nthe FRFs of ROMs and of the FOM, are visualized underneath\nin Figures 10c and 10d. These error plots reflect in more detail\nthe observations made above regarding the L2 error norms.\nNamely, the ssBR-ROM displays a clearly inferior accuracy\nwith respect to the other two, whereas the accuracy of the\nISBR- and aCLBR-ROMs seems similar.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nSummarizing, we have evaluated (open-loop) subsystem\nreduction (ssBR), structure-preserving reduction (ISBR) and\nan abstract implementation (aCLBR), as presented in Algo-\nrithm 1, by means of a benchmark system from the field of\nstructural dynamics. For this example, the proposed abstracted\nreduction approach achieves similar accuracy to the accurate\nbut expensive ISBR method, while having a computational\ncost similar to the cheap but inaccurate ssBR method.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nIn this example, we will focus on the reduction of the\nthin plate, denoted Σ(s), such that the remaining (connected)\ncomponents/subsystem models form the environment model\nE(s) with an order of nE = 1756, p + mC = 11 inputs and\nm + pC = 11 outputs. Our goal is to reduce Σ(s) to ˆΣ(s)\nwith abstracted reduction, such that ΛC(iω) ∈ C(ω) for all\nω ∈ , where ΛC := Fl(E, ˆΣ) − Fl(E, Σ).\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.7**\nWe first select the frequency grid\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nas 250 logarithmically\nequidistantly spaced points between 5 Hz and 2 kHz. We then\nvisualize the FRF matrices of Fl(E, Σ), E22(s) and Fl( ˆF , Σ),\n, as\nby means of their spectral norm per frequency in\nthe black lines in Figure 11a, Figure 11b and Figure 11c,\nrespectively.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nTo simplify interpretation of the accuracy specifications, we\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\nrestrict the scaling matrices to be of the form\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nVE(iω) = εE(ω)Ip,\nWE(iω) = εE(ω)Im,\nVF (iω) = εF (ω)Im,\nWF (iω) = εF (ω)Ip,\nWC(iω) = εC(ω)IpC , VC(iω) = εC(ω)ImC ,\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nfor nonnegative, real scalars εE(ω), εF (ω), εC(ω). The error\nspecifications can then be simplified to\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nE,22(ω) = {ΛE,22(iω) | ∥ΛE,22(iω)∥ < εE(ω)},\n˜\nF (ω) = {˜ΛF (iω) | ∥˜ΛF (iω)∥ < εF (ω)},\nC(ω) = {ΛC(iω) | ∥ΛC(iω)∥ < εC(ω)}.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nWe specify the allowed coupled inaccuracy\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nC(ω) by\nsetting εC(ω) = 10−7, for all ω ∈ . The coupled inaccuracy\nspecification C(ω) is visualized accordingly in Figure 11a as\nthe blue area. This rather simple choice of εC(ω) emphasizes\nthe accurate prediction of the resonance peaks, which might\nbe relevant in, for example, a structural health monitoring\nuse case where structural wear or damage may result in a\nfrequency shift of the resonance peaks. The specifications\nF (ω) are subsequently determined using The-\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\norem 4 for a range of β.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nThe influence of β on the bounds εF and εE is visualized\nin Figure 12a. As explained in Section V-C, β influences the\nC(ω). Specifically, a\ndistribution of the total error budget\nlarge β increases the bound εF (ω) at the cost of a smaller\nbound εE(ω). For β → ∞, only εF (ω) is maximized,\nregardless of εE(ω), i.e., εF (ω) is the bound on ˜ΛF (ω) if\nthe full E(s) is considered instead of ˆE(s). For β = 0, the\nopposite occurs, and εE(ω) is maximized, regardless of εF (ω).\nHowever, the latter optimization problem is ill-posed as the\nF , because\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nE,22 is theoretically unbounded for an empty set ˜\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nfor ˜ΛF = O, ˆΣ(s) = Σ(s) regardless of ˆE(s).\n**BLOCK**fs== 10.0**p== 12.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nNaturally, a larger allowed error bound can be satisfied more\neasily by a reduced model, so that the model’s order can be\ndecreased further. Therefore, varying β also allows a trade-\noff between rΣ and rE. Assuming Gy = Ip, Gu = Im,\nwe can visualize this trade-off in Figure 12b. Note that we\nwant to reduce Σ(s) as far as possible, i.e, nΣ − rΣ should\nbe large, while nE − rE should only be sufficiently small\nto reduce the computational complexity of the reduction ap-\nproach. Figure 12b indicates that E(s) can be reduced by over\n**BLOCK**fs== 8.0**p== 12.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nFig. 11. Spectral norms of the MIMO transfer functions Fl(E, Σ) (a), E22\n(b) and Fl( ˆF , Σ)22 (c), their reduced counterparts and corresponding bounds\nεC (ω), εE (ω) and εF (ω), respectively. The full-order models are given in\nblack (—), whereas the reduced models are given in red (– –) and the error\nbounds in blue (\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n80% without significantly influencing the allowed reduction of\nΣ(s). This exemplifies the motivation of using environment\nabstraction for effective reduction of coupled systems.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nIn addition to the influence of β on\n**BLOCK**fs== 10.0**p== 12.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nF ,\nweighting matrices Gy and Gu determine ˆF (s), enabling to\nchange the importance of the augmented outputs compared to\nthe interconnected system outputs in the structure-preserving\nreduction of Fl( ˆF , Σ) (see Section V-C). To evaluate the influ-\nence of these weighting matrices, we determine the maximum\norder reduction with weighting Gy = αIp, Gu = αIm for\nα = 0.01, 1, and 100, as visualized in Figure 13. As explained\nin Section V-C, a high value α favors the accuracy of the\naugmented outputs, such that, for a large α, ˜ΛF (s) would\nbe relatively small, whereas ΛC(s) would be relatively large.\nThis implies that for a given rE, a smaller rΣ would be\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.1**l== 0.5**r== 0.1**\nand rΣ = 63 (nE = 1756, nΣ = 380). The FRFs of ˆE22\nand Fl( ˆF , ˆΣ)22 and their errors are visualized by red dashed\nlines in Figure 11b and Figure 11c, respectively, which are,\nby definition, fully included in the blue area. Interconnection\nof ˆΣ(s) with E(s) gives the reduced interconnected model\nFl(E, ˆΣ), whose FRF and error are visualized by red dashed\nlines in Figure 11a, which are also well within the specification\nof C(ω).\nRemark 9. The full execution of the robust abstracted re-\nduction framework of Algorithm 2 using these settings takes\napproximately 450 s, of which most time is required to solve\nthe optimization problem of Theorem 4. The computation time\ndepends on the number of inputs and outputs of Σ (which\ndetermine the dimensions of N ) and the efficiency of the\nused numerical method. Currently, V −2(iω), W −2(iω) and\nDℓ, Dr are solved iteratively using MOSEK [35]. However,\nthere exist much more efficient methods to calculate bounds\non µ∆(V N W ) (as used in Theorem 3) [36]. Incorporating\nsuch methods could potentially speed up the determination\nof E,22 and ˜\nF significantly. This is, however, outside the\nscope of this paper and is left for further research.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nThe robust abstracted reduction framework allocates an\nerror budget, εE(ω), to the reduction of E and, εF (ω), to\nthe reduction of Σ. To reduce E and Σ as far as possible,\nwe should aim to use as much of these budgets as pos-\nsible. However, the chosen reduction methods do not take\nthese error budgets into account, resulting in considerable\nconservatism. This is especially apparent for the abstraction,\nwhere ∥ΛE,22(iω)∥ ≪ εE(ω) for most frequencies, as shown\nin Figure 11b. In addition, even when ∥ΛE,22(iω)∥ ≈ εE(ω),\nusually only one input-output pair restricts further reduction,\nwhile other input-output pairs are well within specification.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nThese two sources of conservatism result\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nin significant\nconservatism of the eventual reduced, interconnected model\nFl(E, ˆΣ), as shown by difference of a factor 100 between\nactual error and allowed error. In addition, the reduced orders\nof rE = 184 and rΣ = 63 remain quite large. Through iterative\nreduction and evaluation of ΛC(s), a process that is far from\nC(ω),\nstraightforward, we found that the specification of\nwith εC(ω) = 10−7, for all ω ∈ , is achievable by aCLBR\nwith rE = 20 and rΣ = 8 and by ssBR with rΣ = 22.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\nSummarizing,\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nthe above analysis gives insight\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\ninto the\nsensitivity of the resulting error ΛC(s) to inaccuracies of the\nenvironment model. Namely, the environment model can be\nreduced significantly without seriously impacting the resulting\naccuracy of the reduced interconnected system model. This\nobservation therefore also strengthens the case for using the\ngeneral abstracted reduction framework of Algorithm 1.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nC. Key insights from numerical evaluation\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nFor the considered use case, abstracted model reduction,\nas introduced in Section III and evaluated in Section VI-A,\nyielded an accuracy of the reduced interconnected system\nsimilar to the expensive structure-preserving method, while\nhaving a computational cost similar to the cheap subsystem\nreduction method. In other words, the framework of abstracted\nmodel reduction can significantly improve the computational\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n(a) Euclidean norms of the error bounds εE (ω) and εF (ω) as\nFig. 12.\ndetermined from Theorem 4, for different values of β, and (b) the maximum\nreduction allowed for the environment model E(s) and thin plate model Σ\nto satisfy these bounds, respectively, using Gy = Im, Gu = Ip.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nFig. 13. Maximum reduction allowed for the environment model E(s)\nand thin plate model Σ to satisfy E,22(ω) and ˜\nF (ω), respectively, for\ndifferent weighting matrices Gu = αIp and Gy = αIm.\nrequired for ˜ΛF ∈ ˜\nF if α is large. However, the results\nshown in Figure 13 are not consistent with this, as a larger α\noften allows less reduction of Σ(s), given a certain given rE.\nIn addition, we observe a rather nonlinear relation between\nerror bounds and reduction order, which makes it difficult to\nset proper α and β that result in the maximum reduction of\nE(s) and Σ(s). This inconsistency between the theory and\nthe results of Figure 13 is attributed to the presented use\ncase (where the dynamics of Σ relevant to the input-output\nbehaviour of Σ and Fl(E, Σ) seems to align) and the non-\noptimality of CLBR (or weighted CLBR [8]). Further study is\nrequired to asses the influence of Gy and Gu in alternate use\ncases using other reduction methods.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nBecause the above evaluation of β and α to find ‘optimal’\nvalues is usually too time-consuming (±1 hour for this use\ncase), it is typically wise to select β > 1, which puts emphasis\non reduction of Σ(s), accepting a higher order ˆE(s), resulting\nin a slightly higher computational cost (see Section V-C). For\nthe remainder of the evaluation in this section, we will use β =\n100. As CLBR does not respond intuitively to the weighting\nof Gy and Gu, we simply select Gy = Ip, Gu = Im.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nThe frequency-dependent accuracy specifications E,22(ω)\nand ˜\nF (ω) for these choices of β, Gy and Gu are visualized\nby the blue areas in Figure 11b and Figure 11c, respectively.\nThe environment model E(s) and augmented, abstracted sys-\ntem Fl( ˆF , Σ) are subsequently reduced as far as possible\nsubject to ΛE,22(iω) ∈ E,22(ω), ˜ΛF (iω) ∈ ˜\nF (ω), for\nall ω ∈\nusing Hintz-Herting reduction for the environment\nand CLBR for the thin plate model, resulting in rE = 184\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ntractability of structure preserving methods while retaining\nsimilar accuracy. This indicates that the low-order abstractions\nof the environment models are sufficient to indicate what\nsubsystem dynamics needs to be retained to attain an accurate\nreduced-order interconnected system model.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\nThis observation regarding the sufficiency of low-order\nabstractions is reaffirmed in the assessment of the robust\nabstracted reduction framework, as introduced in Section V\nand evaluated in Section VI-B, which showed that reducing\nthe environment up to 80% does not significantly impact\nthe reduced system. Although the evaluation in Section VI-B\nindicates that robust abstracted reduction tends to be conserva-\ntive, this tendency might significantly mitigated by utilization\nof alternative reduction methods. In addition,\nthe stability\nguarantee, given by the robust abstracted reduction framework,\nremains valuable even in cases of conservatism.\n**BLOCK**fs== 8.0**p== 14.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nVII. CONCLUSION\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.4**l== 0.1**r== 0.5**\nWe have introduced the framework of abstracted reduction\nto improve the tractability of the structure-preserving reduction\nof interconnected systems. In this framework, the structure-\npreserving reduction method is not applied to the full inter-\nconnected system model, but to a single subsystem model con-\nnected to a low-order abstraction of its environment. By thus\napplying structure-preserving reduction to a much lower-order\nmodel, the computational cost of this reduction is significantly\nreduced. Leveraging techniques from robust performance, we\nintroduced a second approach to also automatically determine\n(environment) abstraction and (subsystem) reduction orders\nthat guarantee the reduced interconnected system model to be\nstable and to satisfy a prescribed H∞-accuracy specification.\nBy means of a high-dimensional model representing an\ninterconnected lithography machine frame, we have illustrated\nthat employing a structure-preserving reduction method within\nthe abstracted reduction framework can significantly decrease\nthe reduction’s computational cost without significant loss of\naccuracy. Although the robust performance-based approach\ntends to yield a conservative reduced-order model of the inter-\nconnected system, it effectively illustrates the relation between\nthe introduced error budgets. It is important to emphasize that\nthe introduced abstracted reduction framework is versatile,\ni.e., it is compatible with any structure-preserving reduction\nmethod. This versatility suggests the potential for numerous al-\nternative implementations that offer enhanced accuracy, greater\norder reduction, and less conservatism compared to the current\nimplementation.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nVIII. ACKNOWLEDGEMENTS\nThe authors would like to thank Dr. Victor Dolk and Thijs\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nVerhees, M.Sc., for valuable discussions.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nREFERENCES\n[1] M. Dorosti, R. H. B. Fey, M. F. Heertjes, M. M. J. van de Wal,\nand H. Nijmeijer, “Finite Element Model Reduction and Model\nUpdating of structures for Control,” IFAC Proceedings Volumes,\nvol. 47, no. 3, pp. 4517–4522, 2014.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[2] C. Y. Baldwin and K. B. Clark, “Modularity in the Design\nof Complex Engineering Systems,” in Complex Engineered\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.1**l== 0.6**r== 0.1**\nSystems. Understanding Complex Systems, D. Braha, A. Minai,\nand Y. Bar-Yam, Eds. Springer, Berlin, Heidelberg, 2006, ch. 9,\npp. 175–205.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[3] T. Reis and T. Stykel, “A Survey on Model Reduction of Cou-\npled Systems,” in Model Order Reduction: Theory, Research\nAspects and Applications, W. H. A. Schilders, H. A. van der\nVorst, and J. Rommes, Eds. Berlin, Heidelberg: Springer Berlin\nHeidelberg, 2008, pp. 133–155.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[4] B. Besselink, U. Tabak, A. Lutowska, N. Van De Wouw,\nH. Nijmeijer, D. J. Rixen, M. E. Hochstenbach, and W. H.\nSchilders, “A comparison of model reduction techniques from\nstructural dynamics, numerical mathematics and systems and\ncontrol,” Journal of Sound and Vibration, vol. 332, no. 19, pp.\n4403–4422, 2013.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[5] D. De Klerk, D. J. Rixen, and S. N. Voormeeren, “General\nframework for dynamic substructuring: History, review, and\nclassification of techniques,” AIAA Journal, vol. 46, no. 5, pp.\n1169–1181, 2008.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[6] A. C. Antoulas, Approximation of Large-Scale Dynamical Sys-\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\ntems, R. C. Smith, Ed. Philadelphia: SIAM, 1 2005.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[7] H. Sandberg and R. M. Murray, “Model reduction of inter-\nconnected linear systems,” Optimal Control Applications and\nMethods, vol. 30, no. 3, pp. 225–245, 5 2009.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[8] P. M. Wortelboer and O. H. Bosgra, “Frequency weighted\nclosed-loop order reduction in the control design configuration,”\nProceedings of the IEEE Conference on Decision and Control,\nvol. 3, no. December, pp. 2714–2719, 1994.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[9] A. Vandendorpe and P. Van Dooren, “Model Reduction of\nInterconnected Systems,” in Model Order Reduction: Theory,\nResearch Aspects and Applications, 2008, pp. 305–321.\n[10] L. Poort, B. Besselink, R. H. B. Fey, and N. v. d. Wouw,\n“Balancing-Based Reduction for Interconnected Passive Sys-\ntems,” IEEE Transactions on Control Systems Technology,\nvol. 32, no. 5, pp. 1817–1826, 2024.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[11] B. M. Kessels, M. L. J. Verhees, A. M. Steenhoek, R. H. B.\nFey, and N. van de Wouw, “Sensitivity-Based Substructure\nError Propagation for Efficient Assembly Model Reduction,”\nin Dynamic Substructures, Volume 4, Conference Proceedings\nof the Society for Experimental Mechanics Series, M. Allen,\nW. D’Ambrogio, and D. Roettgen, Eds.\nSpringer, 2022, pp.\n1–11.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[12] S. M. Kim, J. G. Kim, K. C. Park, and S. W. Chae, “A compo-\nnent mode selection method based on a consistent perturbation\nexpansion of interface displacement,” Computer Methods in\nApplied Mechanics and Engineering, vol. 330, pp. 578–597,\n2018.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[13] R.-C. Li and Z. Bai, “Structure-Preserving Model Reduction\nUsing a Krylov Subspace Projection Formulation,” Communi-\ncations in Mathematical Sciences, vol. 3, no. 2, pp. 179–199,\n2005.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[14] L. Li and F. Paganini, “Structured coprime factor model reduc-\ntion based on LMIs,” Automatica, vol. 41, no. 1, pp. 145–151,\n2005.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[15] J. Fern´andez Villena, W. Schilders, and L. Silveira, Block\noriented model order reduction of interconnected systems, ser.\nCASA-report. Technische Universiteit Eindhoven, 2009, vol.\n0901.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[16] J. Leung, M. Kinnaert, J. C. Maun, and F. Villella, “Model\nreduction in power systems using a structure-preserving bal-\nanced truncation approach,” Electric Power Systems Research,\nvol. 177, no. May, p. 106002, 2019.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[17] L. A. L. Janssen, B. Besselink, R. H. B. Fey, and N. van de\nWouw, “Modular Model Reduction of Interconnected Systems:\nA Top-Down Approach,” IFAC-PapersOnLine, vol. 56, no. 2,\npp. 4246–4251, 2023.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[18] C. Ceton, P. M. R. Wortelboer, and O. H. Bosgra, “Frequency\nweighted closed loop balanced reduction,” Proceedings of the\n2nd European Control Conference, pp. 697–701, 1993.\n[19] P. M. Wortelboer, “Frequency-weighted balanced reduction of\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nclosed-loop mechanical servo-systems: theory and tools,” Ph.D.\ndissertation, Delft University of Technology, 1994.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[20] K. Zhou and J. C. Doyle, Essentials of Robust Control, 1st ed.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nPrentice Hall, 1998.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[21] X. Cheng, J. M. Scherpen, and B. Besselink, “Balanced trun-\ncation of networked linear passive systems,” Automatica, vol.\n104, pp. 17–25, 2019.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[22] B. C. Moore, “Principal Component Analysis in Linear Sys-\ntems: Controllability, Observability, and Model Reduction,”\nIEEE Transactions on Automatic Control, vol. 26, no. 1, pp.\n17–32, 1981.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[23] A. C. Antoulas, “An overview of approximation methods for\nlarge-scale dynamical systems,” Annual Reviews in Control,\nvol. 29, no. 2, pp. 181–190, 2005.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[24] C. L. Beck, J. C. Doyle, and K. Glover, “Model reduction of\nMultiDimensional and Uncertain Systems,” IEEE Transactions\non Automatic Control, vol. 41, no. 10, pp. 1466–1477, 1996.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n[25] S. Gugercin, A. C. Antoulas, and C. Beattie, “H2 Model\nReduction for Large-Scale Linear Dynamical Systems,” SIAM\nJournal on Matrix Analysis and Applications, vol. 30, no. 2, pp.\n609–638, 1 2008.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n[26] R. Craig, “Component-Mode Synthesis,” in Structural dynam-\nics—an introduction to computer methods. New York, NY:\nWiley, 1981, ch. 17, pp. 531–575.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[27] L. A. L. Janssen, B. Besselink, R. H. B. Fey, and N. van de\nWouw, “Modular model reduction of interconnected systems: A\nrobust performance analysis perspective,” Automatica, vol. 160,\n2024.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[28] K. Zhou and J. C. Doyle, Robust and Optimal Control. Prentice\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nHall, 1996, vol. 4.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[29] A. Packard and J. C. Doyle, “The Complex Structured Singular\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nValue,” Automatica, vol. 29, no. 1, pp. 71–109, 1993.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[30] N. A. Bruinsma and M. Steinbuch, “A fast algorithm to compute\nthe H∞-norm of a transfer function matrix,” Systems and\nControl Letters, vol. 14, no. 4, pp. 287–293, 1990.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n[31] K. Glover, “All optimal Hankel-norm approximations of linear\nmultivariable systems and their L,∞-error bounds†,” Interna-\ntional Journal of Control, vol. 39, no. 6, pp. 1115–1193, 1984.\n[32] Y. Liu and B. D. Anderson, “Singular perturbation approxi-\nmation of balanced systems,” International Journal of Control,\nvol. 50, no. 4, pp. 1379–1405, 1989.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[33] W. K. Gawronski, Advanced Structural Dynamics and Active\n**BLOCK**fs== 9.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nControl of Structures. Springer-Verlag, 2004.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[34] D. N. Herting, “A general purpose, multi-stage, component\nmodal synthesis method,” Finite Elements in Analysis and\nDesign, vol. 1, no. 2, pp. 153–164, 1985.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[35] M. ApS, MOSEK Optimization Toolbox for MATLAB 10.1.,\n**BLOCK**fs== 9.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[36] P. M. Young, “Robustness with Parametric and Dynamic Un-\ncertainty,” Ph.D. dissertation, California Institute of Technology,\n1993.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.1**t== 0.8**l== 0.2**r== 0.5**\nLuuk Poort received his M.Sc.-degree (cum laude)\nin Mechanical Engineering at the Eindhoven Uni-\nversity of Technology in 2020. He now works as\na doctoral candidate on the derivation of modular\nmodel reduction techniques and their application\nto industrial-scale, structural dynamics models. His\nresearch interests include model reduction, structural\ndynamics and system theory. He is recipient of the\nbest presentation award of the 42nd Benelux meeting\non Systems and Control (2023).\n**BLOCK**fs== 8.0**p== 15.0**b== 0.8**t== 0.1**l== 0.7**r== 0.1**\nLars A.L. Janssen was born in Nijmegen,\nthe\nNetherlands, in 1996. He received his M.Sc.-degree\n(cum laude) in Mechanical Engineering from the\nEindhoven University of Technology, Eindhoven, the\nNetherlands in 2019. Currently, he is a Doctoral\nCandidate at the Dynamics and Control (DC) group\nof the Mechanical Engineering Department at Eind-\nhoven University of Technology (TU/e). His current\nresearch interest are large-scale interconnected sys-\ntems, modelling of complex systems and structures,\nmodel reduction, and systems engineering.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nBart Besselink (M’17) received the M.Sc. (cum\nlaude) degree in mechanical engineering in 2008 and\nthe Ph.D. degree in 2012, both from Eindhoven Uni-\nversity of Technology, Eindhoven, The Netherlands.\nSince 2016, he has been an Assistant Professor with\nthe Bernoulli Institute for Mathematics, Computer\nScience and Artificial Intelligence, University of\nGroningen, Groningen, The Netherlands. He was a\nshort-term Visiting Researcher with the Tokyo Insti-\ntute of Technology, Tokyo, Japan, in 2012. Between\n2012 and 2016, he was a Postdoctoral Researcher\nwith the ACCESS Linnaeus Centre and Department of Automatic Control,\nKTH Royal Institute of Technology, Stockholm, Sweden. His main research\ninterests are on mathematical systems theory for largescale interconnected\nsystems, with emphasis on contract-based design and control, compositional\nanalysis, model reduction, and applications in intelligent transportation sys-\ntems and neuromorphic computing. He is a recipient (with Xiaodong Cheng\nand Jacquelien Scherpen) of the 2020 Automatica Paper Prize.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nRob H. B. Fey received his M.Sc. degree (cum\nlaude) in Mechanical Engineering and his Ph.D.\ndegree from Eindhoven University of Technology\nin the Netherlands, in 1987 and 1992, respectively.\nHe was a recipient of the Shell Study Prize for his\nPh.D. thesis. From 1992 to 2002, he was a Senior\nScientist with the Structural Dynamics Group of the\nNetherlands Organization for Applied Scientific Re-\nsearch (TNO) in Delft, the Netherlands. Since 2002,\nhe has been with the Dynamics & Control Group,\nDepartment of Mechanical Engineering, Eindhoven\nUniversity of Technology, where he currently is an Associate Professor of\nStructural Dynamics. He is (co-)author of many refereed journal papers,\nchapters in books, and conference papers. His general research interests\ninclude the modeling, analysis, and validation of the dynamic behavior of\ncomplex structures and (multiphysics) systems. Current focus is on data- and\nAI-based model updating techniques and model reduction of interconnected\nsystems. His main applications are currently in the fields of High-Tech\nSystems, Mechatronic Systems and Micro-ElectroMechanical Systems. He is\nmember of the Editorial Board of the Journal of Vibration and Control and\nthe Technical Committee for Vibrations of IFToMM. He was guest editor of\nthe journal Nonlinear Dynamics.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.1**t== 0.8**l== 0.7**r== 0.1**\nNathan van de Wouw obtained his M.Sc.-degree\n(with honors) and Ph.D.-degree in Mechanical En-\ngineering from the Eindhoven University of Technol-\nogy, Eindhoven, the Netherlands, in 1994 and 1999,\nrespectively. He currently holds a full professor\nposition at the Mechanical Engineering Department\nof the Eindhoven University of Technology,\nthe\nNetherlands. His current research interests are the\nmodeling, model reduction, analysis and control of\nnonlinear/hybrid and delay systems, with applica-\ntions to vehicular platooning, high-tech systems,\n**BLOCK**fs== 8.0**p== 15.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nresource exploration, smart energy systems and networked control systems.",
         "Abstracted Model Reduction: A General Framework for Efficient Interconnected System Reduction Luuk Poort, Lars A.L. Janssen, Bart Besselink, Rob H.B. Fey, Nathan van de Wouw Complex dynamical systems are often composed of in- terconnected subsystems, such as plant-controller feedback loops, multi-physical systems, networked cyber-physical sys- tems, or assemblies of components in high-tech equipment. The collective of all subsystem models constitutes the model of the interconnected system, as schematically visualized in Figure 1a. Often, this interconnected system model is of such high order that dynamical analysis becomes computationally infeasible and model order reduction methods are required to approximate the high-order model by a low-order surrogate model. An illustrative scenario where this problem arises can be found in structural dynamics, such as in the design and analysis of lithography machines [1], which serves as the primary motivating case study for this research. When reducing a model of interconnected subsystems, it is preferable to retain the interconnection structure to keep the modelling approach modular. In other words, the reduced interconnected system model should be constructed from re- duced subsystem models. This modular reduction approach aligns with the typical design process in industry, where each subsystem is largely developed separately [2]. The combi- nation of such modular design and model reduction allows for greater flexibility of individual design teams, preservation of the essential structure of the interconnected system and increased interpretability of the reduced system model. The most direct and resource-efficient approach to modu- lar reduction involves individually reducing each subsystem model [3], i.e., in an “open-loop” sense, for which many standard reduction methods exist [4–6]. This approach is particularly practical because the computational cost of model reduction scales with the model order and the individual subsystem models are clearly of lower order than the intercon- nected model as a whole. Even though one has to reduce mul- tiple lower-order subsystem models, this is usually still much cheaper than the reduction of one high-order interconnected system model. However, individual reduction of the separate subsystem models might not retain the dynamics required for the reduced, interconnected system model to accurately approximate its full-order model counterpart [3, 7]. To improve the accuracy of the reduced interconnected sys- tem model, a variety of methods [8–14] have been developed to reduce the interconnected system model while preserving its interconnection structure. These methods effectively reduce the individual subsystem models in a “closed-loop” sense by considering the interconnected dynamics. Consequently, such structure-preserving reduction methods successfully reduce the subsystem models to lower-order models that collectively constitute a low-order, interconnected model that accurately approximates the original, high-order model. Unfortunately, for many complex engineering systems the interconnected system model is of such a high order, that many structure-preserving reduction methods become computation- ally infeasible. In such cases, only computationally highly efficient reduction methods remain viable. iterative methods. For instance, One approach to address these computational constraints in is to use approximate, [15], the Gramians of the interconnected system model are approximated to reduce each subsystem model. However, as available structure-preserving reduction methods evaluate the interconnected model differently, i.e., not all use Gramians [3, 13, 14], there is no single iterative method that provides a To address this challenge, we introduce the framework of abstracted model reduction, illustrated in Figure 2c, as our first main contribution. The core idea is to use a low- order abstraction of the environment model, rather than the original, high-order environment model, to identify the sys- tem dynamics most relevant to the interconnected system. The framework serves as a versatile solution to improve the efficiency of structure-preserving reduction methods for interconnected systems. As a second contribution, we employ techniques from robust performance theory, which have recently been applied in the context of reducing interconnected systems [17], to quanti- tatively assess how relying solely on an abstraction of the environment influences the resulting accuracy of the reduced interconnected system model. This allows us to establish a priori requirements on the accuracy of both the abstracted environment model and the reduced system model, based on user-defined, frequency-dependent or H∞-based specifications on the model accuracy of the interconnected system as a whole. These specifications are then leveraged to extend the framework of abstracted model reduction (abstracted reduction for brevity) to the framework of robust abstracted reduction. This latter framework automatically generates a reduced-order system model which guarantees stability of the reduced inter- connected system model and guarantees the satisfaction of its prescribed accuracy specification. Finally, we evaluate the abstracted model reduction frame- work by an industrial case study, where we reduce a structural dynamics model of lithography equipment of the semiconduc- tor industry, consisting of several interconnected subsystem models. Through application of abstracted model reduction in combination with closed-loop balanced reduction [18, 19], we show that a low-order abstraction of a subsystem’s environ- ment is sufficient to ensure the relevance of the reduced sub- system model and the accuracy of the reduced interconnected system model. The remainder of this paper is organized as follows. In Section II, the system-environment representation is presented and the problem is formally defined. Then, the framework of abstracted reduction is introduced in Section III. In this frame- work, an error source is introduced both for the abstraction of the environment and for the reduction of the subsystem. In Section IV, we relate both error sources to the resulting error on the level of the interconnected system and use robust per- formance techniques to relate the different error specifications. This relation is subsequently leveraged to present a systematic approach to abstracted reduction in Section V. Subsequently, in Section VI, both the general abstracted reduction framework and its robust extension are evaluated and compared to other reduction approaches from literature by means of an industrial case study. Finally, Section VII presents conclusions on the proposed approach. Notation: In this paper, sets are generally indicated by blackboard-bold symbols, such as R, R>0 and C, which denote the set of real, positive real and complex numbers, respectively. Rm×p and Cm×p indicate matrices of real and complex numbers, respectively, with m rows and p columns. Given a complex matrix A, A⊤ and AH denote its transpose and universally applicable solution to computational limitations. In addition, it is often unclear how the use of such approximate solutions impacts the accuracy of the resulting reduced-order interconnected system model. Alternatively, in case of sparsely interconnected systems, Leung et al. [16] perform the structure-preserving reduction of a subsystem using only information on its immediate neighbors. As a result, the reduced subsystem model is relevant with respect to the considered cluster of subsystem models. For each subsystem, its immediate neighbouring subsystems there- fore act as a lower-order surrogate for its full environment, consisting of all other subsystem models. By iterating over all subsystems, all reduced subsystem model retain their relevance with respect to their own clusters, theoretically resulting in a (more) accurate reduced, interconnected model. In this paper, we introduce a novel, different perspective. Let us focus on a single subsystem, which we then denote as the system, which is embedded within an environment consisting of the remaining subsystems, as visualized schematically in Figure 1. A model for this environment is straightforwardly attained by the interconnection of all remaining subsystem models. Using this general system-environment model descrip- tion, including any system within a dynamic environment, we can schematically visualize the open-loop and closed- loop reduction methods by Figures 2a and 2b, respectively. Observing the structure-preserving reduction as in Figure 2b, the environment determines what essential system dynamics to retain (in the light of the interconnected system dynamics). However, this model for the environment is often unnecessarily complex (high order), thereby inducing computation infeasi- bility. In the setting of interconnected systems, E(s) typically rep- resents several (interconnected) subsystems such that its order is typically large, particularly nE > nΣ. This motivates the current work, where the evaluation of Σ(s) is computationally tractable, but the evaluation of Fl(E, Σ) is not. B. Structure-preserving model reduction The high-level objective is to find a transfer function matrix ˆΣ(s) of order rΣ < nΣ such that Fl(E, ˆΣ), as depicted in Figure 3b, is well-posed, stable and accurately approximates Fl(E, Σ) in terms of input-output behaviour, i.e., such that the approximation error, being the output of the error dynamics: ΛC := Fl(E, ˆΣ) − Fl(E, Σ), is small in a suitable sense. Structure-preserving reduction methods as discussed in [7, 9, 10, 21] aim to find an accurate reduced-order model Fl(E, ˆΣ). However, they are often only applicable to interconnected systems of limited order. In addition, most methods either do not guarantee stability of Fl(E, ˆΣ), e.g. [7, 9], or require additional system properties such as passivity [10, 21]. A further, intrinsic limitation of structure-preserving reduc- tion methods is the need for environment model E(s). In a modular, model-based design process of complex engineering systems, where subsystems are designed in parallel, the envi- ronment model E(s) is typically not available or only a rough estimate ˆE(s) is available. C. Problem statement Our goal is to address the limitations of existing structure- preserving model reduction methods. Particularly, given a system Σ(s) and environment E(s), possibly both of large order, we aim to reduce Σ(s) to ˆΣ(s) such that 1) stability is preserved, i.e., Fl(E, ˆΣ) is well-posed, inter- nally stable, and Fl(E, ˆΣ) ∈ RH∞, 2) the approximation is accurate in the sense that the ap- proximation error dynamics ΛC := Fl(E, ˆΣ)−Fl(E, Σ) is small. Specifically, we consider the case where the order of E(s) is high, such that the application of existing structure-preserving reduction methods to Fl(E, Σ) is not feasible (or comes at too large computational cost). We will initially neglect giving guarantees on the accuracy and stability of the reduced model (such guarantees will be treated in Sections IV-B and V) and focus on addressing the computational limitations of structure-preserving reduction methods. To this end, we propose the abstracted reduction framework in Section III-A. The computational benefits of this approach and some applicability considerations are sub- sequently discussed in Section III-B. A. The abstracted reduction algorithm To facilitate efficient and accurate model reduction, we present our framework of abstracted reduction, which is also illustrated in Figure 4, consisting of the following steps. conjugate transpose, respectively, ∥A∥ denotes its 2-induced norm, A ≻ 0 and A ⪰ 0 denote that A is positive definite and positive semi-definite, respectively, and A = diag(A1, A2) denotes a block-diagonal matrix of submatrices A1 and A2. The zero matrix and identity matrix are denoted by O and I, respectively, while In denotes an identity matrix of size n. Given a transfer function matrix Σ(s), where s is the Laplace variable, ∥Σ∥∞ denotes its H∞-norm. The set of all proper, real rational stable transfer matrices is denoted by RH∞. The system and its environment, as schematically visualized in Figure 1b, are modeled by the proper, real rational transfer function matrices Σ(s) and E(s), respectively, such that the interconnected system model can be described by the block- diagram shown in Figure 3a. The system model Σ(s) has inputs u ∈ Rm, outputs y ∈ Rp and McMillan degree (order) nΣ and the environment model E(s) has inputs w ∈ RmC and y ∈ Rp, outputs z ∈ RpC and u ∈ Rm and order nE, such that E11 E12 E21 E22 The system and environment are interconnected by means of a lower linear fractional transformation (LFT), as defined below.  P11(s) P12(s) P21(s) P22(s) Definition 1. Let P (s) = , Ml(s) and Mu(s) be proper, real rational transfer function matrices of dimensions (p1 + p2) × (m1 + m2), m2 × p2 and m1 × p1, respectively. Then, we define the lower and upper LFTs, respectively, as Fl(P, Ml) = P12Ml(I − P22Ml)−1P21 + P11, Fu(P, Mu) = P21Mu(I − P11Mu)−1P12 + P22, which are said to be well-posed if I − P22Ml and I − P11Mu have a proper real rational inverse, respectively [20, Def. 9.2, Lem. 5.1]. Using this definition, the interconnection of system Σ and environment E as in Figure 3a can be written as Fl(E, Σ). We make the following assumption to ensure that Fl(E, Σ) is well-defined and internally stable (see [20, Chapter 5]). Assumption 1. We have Σ(s) ∈ RH∞, E(s) ∈ RH∞ and the interconnection Fl(E, Σ) is well-posed and internally stable, i.e., Σ(I − E22Σ)−1 ∈ RH∞. Particularly, we have Fl(E, Σ) ∈ RH∞. reduction methods to evaluate the approximate, coupled input- output behaviour (via Fl( ˆF , Σ)), thereby significantly reduc- ing computational costs. In an ideal world, without compu- tational limitations, one would like to do direct, structure- preserving reduction of Fl(E, Σ). However, this is not always feasible or it is computationally very expensive. Hence, we suggest abstracted reduction as a framework to enable an approximate structure-preserving reduction, where the direct structure-preserving reduction of Fl(E, Σ) is not feasible or too computationally expensive. The augmentation with the weighting matrices Gu and Gy in Algorithm 1 serves two main purposes: (i) to control the accuracy distribution over ˆΣ and Fl(E, ˆΣ), and (ii) to facilitate error analysis in Section IV. Regarding the first purpose, increasing the magnitudes of Gu and Gy amplifies the contribution of Σ’s input-output behaviour in Fl( ˆF , Σ). When using an input-output approximating reduction method, high-magnitude Gu and Gy thus improve ˆΣ’s approximation of Σ at the cost of the accuracy of Fl( ˆF , ˆΣ). This trade-off is discussed further in Section V-C. Regarding the second- purpose, it turns out that extending the number inputs and outputs Fl( ˆE, Σ) to Fl( ˆF , Σ), by augmentation of ˆE(s) to ˆF (s), is often essential for deriving the error relations in the abstracted reduction algorithm, as detailed in Section IV. B. Computational benefits and applicability To compare the computational cost of abstracted reduction to direct structure-preserving reduction of Fl(E, Σ), recall that the model orders of E(s), ˆE(s), Σ(s) and ˆΣ(s) are denoted as nE, rE, nΣ and rΣ, respectively. Structure-preserving reduc- tion methods based on balancing, such as [9, 10], usually scale cubically with the order of Fl(E, Σ) [23], while structure- preserving methods based on LMI’s, such as [14, 24], scale even more steeply. Hence, our abstracted approach replaces a cost (nE + nΣ)c with (rE + nΣ)c for c ≥ 3, i.e., the en- vironment is replaced by a low-order abstraction, which yields a significant reduction in computational cost when nE is large and rE is small, and when nE is large compared to nΣ. The low-order abstraction ˆE can be obtained by an inexpen- sive reduction method, which does not preserve structure, such as [25, 26], as its accuracy is not so important for the accuracy of the reduced, interconnected system Fl(E, ˆΣ); it merely acts as a weight in the reduction of Σ to ˆΣ. In such a case, the computational cost of the reduction of Σ to ˆΣ is dominant. This makes abstracted reduction mostly beneficial to systems where nE > nΣ and when rE is selected as rE ≪ nE, as shown in Figure 5. Remark 1. Sometimes, Σ(s) needs to be reduced while having incomplete knowledge of E(s). This is a common occurrence in modular design processes, where several subsystems are designed simultaneously. However, these design processes are typically iterative, such that we generally possess subsystem models from a previous iteration. In our abstracted approach, we suggest to use ˆE(s), an approximation of E(s), to ef- fectively indicate which dynamics of Σ(s) are relevant to Fl(E, Σ). Therefore, an ˆE(s) of a previous design iteration or even an ˆE(s) based on a basic, preliminary environment Algorithm 1. Abstracted reduction Input: p × m transfer matrix Σ(s) and (pC + m) × (mC + p) transfer matrix E(s), of orders nΣ, nE, respectively, abstrac- tion order rE ≤ nE and reduction order rΣ < nΣ and weighting matrices Gy ∈ Cp×p and Gu ∈ Cm×m. Output: Surrogate model ˆΣ(s) of reduced order rΣ, such that Fl(E, ˆΣ) approximates Fl(E, Σ). 1) Abstraction of E(s). Abstract E(s) to ˆE(s) in open loop, i.e., disconnected from Σ(s), by means of, e.g., reduction or another form of surrogate modelling. 2) Augmentation of ˆE(s). Augment the set of external inputs and outputs of Fl( ˆE, Σ) by incorporating Σ’s (weighted) inputs u and outputs y. This is equivalent to replacing ˆE(s) with ˆF (s), resulting in Fl( ˆF , Σ), where  ˆE12 O Gy ˆE22 where ˆE is partitioned the same as E, see (1). 3) Reduction of Σ(s). Use a structure-preserving reduction method to reduce Fl( ˆF , Σ) to Fl( ˆF , ˆΣ). 4) Substitution of E(s). Substitute the original environ- ment E(s) to obtain Fl(E, ˆΣ). To interpret the concept of abstracted reduction, let us first disregard the augmentation step by selecting Gu(s) = Om×m, Gy(s) = Op×p and assume the use of reduction methods that approximate a model’s input-output behaviour, such as balancing methods [19, 22]. Then, abstracted reduction can be interpreted as follows: whereas an open-loop reduction approach evaluates the input-output behaviour of the sys- tem (Σ) itself and structure-preserving reduction approach evaluates the coupled input-output behaviour (of Fl(E, Σ)), the abstracted reduction approach uses structure-preserving We emphasize that we work with the error system ΛF (s) rather than with ˆΣ(s) − Σ(s), for the following two reasons: • Structure-preserving reduction methods reduce subsys- tems based on the coupled dynamics, such that any available error bounds are typically bounds on ΛF (s). • As we aim to (accurately) approximate the coupled dynamics, the magnitude of ˆΣ − Σ cannot be expected to be a good indication of the quality of reduction. Alterna- tively, ΛF typically gives a much better indication of the quality of the overall reduction, as long as ΛE is small. Note that if ΛE = 0, Gu = Om×m and Gy = Op×p, indeed ΛF = Fl(E, ˆΣ) − Fl(E, Σ). Therefore, if a specification on the accuracy of Fl(E, ˆΣ) is translated to bounds on ΛE and ΛF , these bounds are expected to be less conservative than similar bounds on ˆΣ − Σ. The abstraction and reduction steps, characterized through the errors in (6) and (7), respectively, ultimately lead to the reduction error ΛC of the interconnected system, as previously introduced in (4) and repeated here for completeness as E(s), ˆΣ(s) − Fl Our main goal in this section is to relate ΛC to the error systems ΛE and ΛF . As a first step in this direction, we express the reduced-order system ˆΣ in terms of the reduction error system ΛF . Lemma 2. Let Σ(s), ˆΣ(s) be transfer function matrices and let ˆF (s) be as in (5) with square, invertible matrices Gu and Gy, such that Fl( ˆF , Σ) and Fl( ˆF , ˆΣ) are well-posed with a difference ΛF (s) as in (7). Then , Σ(I − ˆE22Σ)−1 + G−1 is the 22-partition of ΛF as in (7), representing the transfer matrix from the augmented inputs to the augmented outputs of Fl( ˆF , Σ). Proof. Let us first define P := can be rewritten as and note that (10) P, ˆΣ = GyΣ(I − ˆE22Σ)−1Gu + ΛF,22. Given the fact that Gu and Gy are square and invertible, we can then use the inversion formula of [28, Lemma 10.4] to extract ˆΣ from Fl(P, ˆΣ) as A substitution of (11) and (13) into (12) gives an expression similar to (9). Using the definition of the upper LFT in (3), we P, ˆΣ finally move the G−1 u to attain the expression for ˆΣ as in (9). terms from P −1 to Fl model might improve the accuracy of Fl(E, ˆΣ) beyond what can be achieved through (open-loop) reduction of Σ. However, in case a preliminary model ˆE is used without knowledge of its accuracy (i.e., without knowing E), the formal error analysis of Section IV can not be applied. IV. ERROR ANALYSIS AND THE RELATION OF BOUNDS The reduction goal, as specified in Section II, is to achieve a low-order surrogate model ˆΣ(s) such that the reduced, interconnected model Fl(E, ˆΣ) is well-posed, stable and (ac- curately) approximates Fl(E, Σ). To this end, we first assume the reduction/abstraction errors to be known transfer functions and determine the relation between introduced reduction and abstraction errors and the error of the interconnected system in Section IV-A. Subsequently, building on the approach introduced in [27], we relate bounds on these errors in Sec- tion IV-B. A. Error relations We start by defining the errors introduced by the abstracted reduction procedure described by Algorithm 1 in Section III-A. First, the abstraction of the environment E(s) to its low-order approximation ˆE(s) leads to the error system ΛE(s) := ˆE(s) − E(s). We recall from step 2 of Algorithm 1 that the resulting system Fl( ˆE, Σ) is subsequently augmented to obtain the system Fl( ˆF , Σ). Augmentation does not affect the well-posedness and stability of the interconnection, as stated next. Lemma 1. Consider the p × m transfer matrix Σ(s) and (pC +m)×(mC +p) transfer matrix ˆE(s), such that Fl( ˆE, Σ) is well-posed and internally stable. Then, for any ˆF (s) in (5), with weighting matrices Gy ∈ Cp×p and Gu ∈ Cm×m, Fl( ˆF , Σ) is well-posed and internally stable. Proof. Following Definition 1 and [20, Corollary 5.2], Fl( ˆF , Σ) is well-posed and internally stable if I − ˆE22Σ has a proper real rational inverse and Σ(I − ˆE22Σ)−1 ∈ RH∞, respectively. Both notions follow directly from the well- posedness and internal stability of Fl( ˆE, Σ). ■ the application of structure-preserving reduction methods to Fl( ˆF , Σ) (reduction step at the bottom of Figure 4) leads to a reduced-order system ˆΣ and error system  ˆF (s), Σ(s). Remark 2. The inversion formula of [28, Lemma 10.4] used in the proof of Lemma 2 motivates the augmentation of E with Gu and Gy. Note, however, that we used only the augmented inputs and outputs to express ˆΣ. This augmentation is excessive as we can also express ˆΣ in terms of ΛF instead of ΛF,22. When using ΛF , P = ˆF in the proof, and the inversion requires ˆF21 and ˆF12 to be full column and row rank, respectively. In this general case, ˆΣ can be expressed by (9), with G−1 21, where (.)† denotes the Moore-Penrose pseudoinverse. Augmentation of E with square and invertible Gu and Gy, however, gives the most convenient expression for ˆΣ, because this prevents the inversion of (unknown) transfer function matrices ˆF21 and ˆF12. Using the lower LFT definition in (2), the expression for the total reduction error system ΛC, as in (8), can be rewritten to  ˆΣ(I − E22 ˆΣ)−1 − Σ(I − E22Σ)−1 replaced by ˆF † Substitution of ˆΣ(s) as in (9) gives an expression of ΛC in terms of the error system ΛF,22, as depicted schematically in Figure 6, where the expression for ˆΣ(s) is highlighted. This block diagram facilitates an intuitive interpretation. Firstly, if ΛF,22 = 0, the two feedback-loops with ˆE(s) cancel and ˆΣ(s) = Σ(s). This represents the inverse relation between the abstraction and substitution steps of the abstracted reduction if ˆE22(s) = E22(s), approach. Also, the feedback-loops indicated by a ∗ in Figure 6 cancel and the approach simplifies to standard structure-preserving reduction. The observed dependency of ΛC on ˆE22 in Figure 6 suggests that ˆE11, ˆE12 and ˆE21 do not influence ΛC. Note, however, that ˆE determines Fl( ˆF , Σ) through the definition of ˆF in (5). ΛF,22 thus implicitly depends on ˆE. We will not consider this implicit dependency in the remainder of this paper and treat ΛF,22 as a independent error source. Motivated by Figure 6, we obtain a characterization of ΛC that allows us to isolate the influence of abstraction and reduction errors on the error ΛC on the reduced-order interconnected system. Theorem 1. Let Σ(s), ˆΣ(s) be transfer function matrices and let ˆF (s) be as in (5), satisfying Assumption 1. Let ΛC(s) and ΛF,22(s) be as in (8) and (10), respectively, and let ΛE,22 := ˆE22 − E22 and ˜ΛF := G−1 y ΛF,22G−1 ΛC = Fu(N, diag(ΛE,22, ˜ΛF , ΛE,22)) M (s) = Σ(s)(I − E22(s)Σ(s))−1, such that N (s) ∈ RH∞ due to Assumption 1. Proof. Substitution of ˆE22 = E22 + ΛE,22, ˜ΛF (s) G−1 gives := and (9) into ΛC := Fl(E, ˆΣ) − Fl(E, Σ) ΛC = −Fl(E, Σ) + Fl ,  −E22−ΛE,22 I O I  Σ(I − (E22 + ΛE,22)Σ)−1 + ˜ΛF To extract the error terms of ΛE,22 and ˜ΛF , we note that  , Σ = Σ(I − (E22 + ΛE,22)Σ)−1, with M as in (17), such that (18) can be rewritten as ΛC = −Fl(E, Σ) + Fl (E, Fu ([ K K Finally, these nested LFT’s can be expressed as the LFT of ■ (15), making repeated use of [28, Lemma 10.3]. The expression of ΛC as in (15) can be verified intuitively by its graphical representation in Figure 7. Starting from Figure 6, which represents the definition of ΛC in (8), we express ˆE22 as a parallel connection of E22 and ΛE,22 and “pull out” the error terms ΛE,22 and ˜ΛF , resulting in Figure 7. This shows that, indeed, (15) expresses ΛC as in (8). Furthermore, we introduce scaling matrices Dℓ and Dr, for any ∆ of the form (26) which satisfy D1/2 [29, Theorem 3.8], by requiring (Dℓ, Dr) ∈ D, with  dF ∈ R>0, S ∈ C2×2, S = SH ≻ 0 We can then use the approach of [27] to formulate the following guarantee on the boundedness of ΛC(s). Theorem 2. Consider the transfer functions Σ(s), E(s) and Fl(E, Σ) satisfying Assumption 1 and error dynamics (15). Let W (s) and V (s) be bistable and biproper weighting F and functions as given in (26) and let the sets C be as given in (25). If there exist some scaling matrices (Dℓ, Dr) ∈ D, with D as given in (27), such that N (iω)DrN H (iω) ⪯ Dℓ ∀ ω ∈ R, with N = V N W and N as in (16), then it follows that if ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜ Fl(E, ˆΣ) is well-posed and internally stable and the coupled error dynamics satisfies Proof. We first note that N ∈ RH∞ due to Assumption 1 and N ∈ RH∞ due to the weighting functions V, W ∈ RH∞. Then, according to [27, Theorem 3.2], for any ΛE,22, ˜ΛF ∈ RH∞ satisfying (29), the coupled error dynamics (15) are well-posed, internally stable and satisfies (30) if and only if where µ denotes the structured singular value [29, Defini- tion 3.1]. Instead of µ , we use its upper bound which can be tightened by optimizing over Dℓ and Dr [29]. requirement Theorem 3.5], ¯σ(D−1/2 ) < 1 can be equivalently stated as N (iω)DrN H (iω) ⪯ Dℓ. Therefore, (28) implies (31) and thus ΛC ∈ RH∞ satisfies (30). Due to the definition of ΛC in (8) and Assumption 1, this also guarantees the internal stability and well-posedness of Fl(E, ˆΣ). ■ Remark 3. The approach of µ-analysis, as exploited in Theo- rem 2, typically requires Dℓ, Dr to only satisfy D1/2 r ∆ = ∆D1/2 . However, we impose additional constraints on the ℓ positive definiteness and Hermitian form of Dℓ, Dr in (27). These restrictions simplify further computation, while they do not increase the conservatism of (32) [29]. B. A robust performance perspective Next, we will use the formulation of the overall error dy- namics as in Theorem 1 (and Figure 7) to relate requirements on bounds on this error dynamics to the errors made in the underlying abstraction and (structure-preserving) reduction step. We will assume a prescribed, weighted bound on the error ΛC(s) and aim to translate this to bounds on ΛE,22(s) and ˜ΛF (s). Specifically, we prescribe weighting matrices VC(s) ∈ RH∞ and WC(s) ∈ RH∞ and formulate the requirement as ∆C(s) = VC(s) ΛC(s) WC(s), for some ∆C(s) ∈ RH∞ satisfying ∥∆C∥∞ ≤ 1. The abstraction and reduction errors ΛE,22(s), ˜ΛF (s) are expressed similarly as ΛE,22(s) = WE(s) ∆E,22(s) VE(s), ˜ΛF (s) = WF (s) ˜∆F (s) VF (s), for bistable weighting matrices VE, WE, VF , WF ∈ RH∞, implying that V −1 E , V −1 F ∈ RH∞, and some ∆E,22, ˜∆F ∈ RH∞ satisfying The requirements of (22) and (23) can be stated equivalently by restricting ΛE,22, ˜ΛF and ΛC to the sets of transfer functions E,22, ˜ F and C, respectively, given as E ∥∞ ≤ 1, E,22 := ΛE,22 E ΛE,22V −1  F := ˜ΛF ˜ ˜ΛF V −1  ∥W −1 F  C := ΛC  ∥VCΛCWC∥∞ < 1. We can now formulate the goal of this section explicitly as: given the sets E,22, ˜ F and C, determine whether the coupled error dynamics are guaranteed to satisfy ΛC ∈ C for any ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜ To determine the relation between E,22, ˜ F and C, we will use tools from robust performance analysis. By combining expression (15) for the coupled error dynamics ΛC with (22) and (23), we attain the framework of robust performance theory, as visualized in Figure 8. Then, the uncertainties and weights are combined in the block-diagonal transfer functions ∆(s) := diag(∆E,22(s), ˜∆F (s), ∆E,22(s), ∆C(s)), V (s) := diag(VE(s), VF (s), VE(s), VC(s)), W (s) := diag(WE(s), WF (s), WE(s), WC(s)). Besides the relation of weighted H∞-norm set defini- tions, as in Theorem 2, similar methods from robust per- formance are also applicable to relate frequency-dependent error bounds. To this end, with slight abuse of notation, we formulate frequency-dependent error set definitions by restrict- ing ΛE,22(iω), ˜ΛF (iω) and ΛC(iω) to E,22(ω), ˜ F (ω) and C(ω) at frequency point ω ∈ R, where  ΛE,22(iω) abstraction and reduction errors. This result is subsequently used to formulate the robust abstracted reduction framework, to efficiently reduce Fl(E, Σ) to Fl(E, ˆΣ), such that Fl(E, ˆΣ) is well-posed and internally stable and ΛC ∈ C. Additionally, we formulate a frequency-dependent variant of the above-mentioned optimization problem in Section V-B, using Corollary 1, which is more flexible, but provides no stability guarantees. We then conclude in Section V-C with some notes on the properties of the proposed methods. WE(iω)−1  ˜ΛF (iω) A. The robust abstracted reduction framework for stability and accuracy guarantees C(ω) := ΛC(iω) ∥VC(iω)ΛC(iω)WC(iω)∥ < 1. Using the set definitions of (33), we formulate a guarantee similar to Theorem 2 on the boundedness of ΛC(iω) at a specific frequency point ω ∈ R. Corollary 1. Consider the transfer functions Σ(s) and E(s), such that Fl(E, Σ) is well-posed and stable. Let W (s) and V (s) be weighting functions as in (26). Let ω ∈ R and let the sets E,22(ω), ˜ F (ω) and C(ω) be given as in (33). If there exist (Dℓ, Dr) ∈ D, with D as given in (27), such that N (iω)DrN H (iω) ≤ Dℓ, with N (iω) = V (iω)N (iω)W (iω) and N as in (16), then it follows that if ΛE,22(iω) ∈ E,22(ω) and ˜ΛF (iω) ∈ ˜ the coupled error dynamics ΛC, evaluated at ω, satisfies ΛC(iω) ∈ C(ω). Proof. The proof closely follows [27, Theorem 3.4], consid- ering µ per frequency point, and is largely equivalent to ■ Theorem 2. In this section, we will leverage the relation between the introduced errors, as determined in Section IV, to guide the abstraction of E and reduction of Σ. This allows us to guaran- tee that the resulting coupled error ΛC satisfies a user-defined, possibly frequency-dependent specification. Specifically, we will answer the question: How should ˆE(s) and ˆΣ(s) be selected, such that Fl(E, ˆΣ) is stable and meets a prescribed accuracy specification? the perspective in which E,22, To this end, we adopt ˜ F and C represent specifications on ΛE,22, ˜ΛF and ΛC, respectively. Explicitly, an error, such as ΛC, satisfies its specification, C, if ΛC ∈ C. Theorem 2 and Corollary 1 then allow us to relate such specifications. In particular, we C is given and we mean to find focus on the case where specifications E,22 and ˜ F that guarantee ΛC ∈ C. First, in Section V-A, we formulate an optimization problem F , as in (25), are where determined as the least conservative specifications on the C is given and To guarantee the stability and accuracy of Fl(E, ˆΣ), cap- C, we will use Theorem 2 to provide suitable tured in specifications E,22 and ˜ F . This can be interpreted as a dis- tribution of the coupled error budget C over the abstraction error budget E,22 and the structure-preserving reduction error budget ˜ F . To maximize the reduction of E and Σ, we aim for lenient specifications (large error budgets) E,22 and ˜ F , as in (33). To this end, we prescribe the weighting matrices W (s), as in (26), and ¯V (s), defined as ¯V (s) := diag( ¯VE(s), ¯VF (s), ¯VE(s), ¯VC(s)), where ¯ε = diag(¯εEIp, ¯εF Im, ¯εEIp, Imc) and V is given in (26). Particularly, ¯εE, ¯εF ∈ R>0 represent H∞-bounds on the weighted errors as E ΛE,22 ¯V −1 ∞ ≤ ¯εE, E  ˜ΛF ¯V −1 ∞ ≤ ¯εF F there exist to note that and we aim to maximize ¯εE and ¯εF . Then, for a given W (s) and ¯V (s), E,22 and ˜ F are defined by W (s) and V (s) = ¯ε ¯V (s), as in (33). is important infinitely many combinations of ¯εE and ¯εF that guarantee ΛC ∈ C. To select which unique combination is the “optimal” one, we introduce an additional scalar parameter β to weigh the relative importance of ˜ F over E,22. This results in the following optimization problem. Theorem 3. Consider the transfer functions Σ(s), E(s) and Fl(E, Σ) satisfying Assumption 1 and error dynamics (15). Let the requirements E,22, ˜ F and C be given as in (25) and let ¯V (s) and W (s) be prescribed bistable and biproper weighting functions as in (37) and (26), respectively. Consider now the optimization problem where β ∈ R>0 is a given tuning variable: given ¯V (s), W (s) maximize ¯ε2 subject to ¯ε2 N (iω)DrN H (iω) ⪯ Dℓ ∀ ω ∈ R, where N = ¯V N W , N is given in (16) and D in (27). If ¯εE, ¯εF is a feasible solution to (39), then for any ΛE,22 ∈ RH∞ and ˜ΛF ∈ RH∞ that satisfy the reduced, interconnected system Fl(E, ˆΣ) ∈ RH∞ and the error system satisfies ΛC ∈ C. Proof. The proof follows from Theorem 2, where only V (s) is replaced by ¯ε ¯V (s). Substitution of V = ¯ε ¯V into (28) gives ■ the constraint of (39). Remark 4. The matrix inequality of the optimization problem in Theorem 3 is not linear in its unknowns, but can be solved efficiently by iteratively solving for ¯ε and Dr, as shown in [17]. The solution to the optimization problem of Theorem 3 de- termines the maximum weighted H∞-bounds ¯εE and ¯εF , that define E,22 and ˜ F . However, to make sure these accuracy specifications can be satisfied by significantly reduced models ˆE and ˆΣ, the weighting functions ¯V and W should reflect the expected trend of the error system’s frequency response. For example, if the reduction method for abstracting the envi- ronment is known to particularly approximate low-frequency dynamics, ¯VE and WE could be prescribed as low-pass filters to ensure a more uniform response of W −1 E . This results in a less conservative H∞-bound and a lower-order abstraction of E. To systematically reduce an interconnected system, we present the robust abstracted reduction framework: an ex- tension of Algorithm 1 with the optimization problem of Theorem 3. Using this framework in combination with ap- propriate (structure-preserving) reduction methods, Fl(E, Σ) is efficiently reduced to Fl(E, ˆΣ), such that Fl(E, ˆΣ) is well- posed, internally stable and ΛC ∈ C (i.e., the reduced-order interconnected system satisfies a given error specification). Algorithm 2. Robust Abstracted Reduction Input: Transfer functions Σ(s), E(s) and Fl(E, Σ) satisfying Assumption 1, bistable and biproper ¯V and W as in (37) and (26), scalar β ∈ R≥0 and full-rank weighting matrices Gu ∈ Cm×m and Gy ∈ Cp×p. Output: Surrogate model ˆΣ(s) of reduced order rΣ, such that Fl(E, ˆΣ) is well-posed, internally stable and ΛC ∈ C. 1) Optimization Solve the optimization problem given in Theorem 3 to attain specifications ˜ 2) Abstraction of E. Reduce E to ˆE of the lowest order rE, such that ΛE,22 ∈ E,22. 3) Augmentation of ˆE. Augment the inputs and outputs of Fl( ˆE, Σ), resulting in Fl( ˆF , Σ), with ˆF as in (5). 4) Reduction of Σ(s). Reduce Σ(s) to ˆΣ(s) of the lowest order rΣ, such that ˜ΛF ∈ ˜ F , where 5) Substitution of E. Substitute the original environment E to obtain Fl(E, ˆΣ). B. Frequency-based robust abstracted reduction Algorithm 2 fully addresses the problem statement of Section II-C by providing a systematic and efficient way to reduce Fl(E, Σ). However, the algorithm requires several inputs, among which the bistable weighting functions ¯V (s) and W (s). In Section V-A, we advise ¯V (s) and W (s) to reflect the expected trend error system’s response, but this might be unknown or very irregular over the frequency range of interest. To avoid providing these weighting functions, we will formulate an alternative approach, based on Corollary 1, to relate the error specifications E,22(ω), ˜ F (ω) and C(ω), as in (33), for a specific discrete frequency grid ω ∈ . To simplify computation, we restrict V (s) and W (s), eval- uated at ω, to satisfy V (iω) ∈ V and W (iω) ∈ W, with V and W given as This results in the following optimization problem. Theorem 4. Consider the transfer functions Σ(s) and E(s), such that Fl(E, Σ) is well-posed and stable. Let N (s), D, V and W, as given in (16), (27), (42) and (43), respectively, and let the sets E,22(ω), ˜ F (ω) and C(ω) be given as in (33). Consider now the optimization problem at the frequency point ω ∈ R where VC(iω) and WC(iω) are prescribed weighting matrices and β ∈ R>0 is a given tuning variable: given VC(iω), WC(iω) minimize tr(XV V −2(iω)) + tr(XW W −2(iω)) subject to W −2(iω)D−1 r N (iω) V (iω) ∈ V, W (iω) ∈ W, (Dℓ, Dr) ∈ D, XW = diag(Im, βIp, Im, IpC ), XV = diag(Ip, βIm, Ip, ImC ). If V (iω), W (iω) is a feasible solution to (44), then for any F (ω), it is ensured ΛE,22(iω) ∈ E,22(ω) and ˜ΛF (iω) ∈ ˜ that ΛC(iω) ∈ C(ω). Proof. In [17, Theorem 1] the inequality of (44) is shown to be equivalent to (34) when V (iω) ∈ V and W (iω) ∈ W. The ■ rest of the proof follows directly from Corollary 1. Remark 5. The matrix inequality of the optimization problem in Theorem 4 is not linear in its unknowns, but can be solved efficiently by iteratively solving for V −2(ω), W −2(ω) and Dℓ, Dr as shown in [17]. C(ω) for a specific frequency ω. In addition, Compared to Theorem 3, which required the bistable trans- fer matrices ¯V (s) and W (s), Theorem 4 only needs to be supplied with the required coupled accuracy specification C(ω) can be selected more freely, as the weighting matrices V (iω) and W (iω) do not even need to represent actual transfer functions. However, this comes at the loss of any guarantees on well- posedness, stability or on an error bound for other frequency points. Remark 6. A third abstracted reduction algorithm could be formulated based on Theorem 4, using frequency-dependent bounds as in (33). However, as this algorithm would be nearly equivalent to Algorithm 2, it is omitted for brevity. C. Computational considerations and tuning parameters The main drawback of the systematic approach of Algo- rithm 2 is the increase of computational cost with respect to standard abstracted reduction as in Algorithm 1. The additional cost, however, heavily depends on the system under consid- eration. The computational cost of the optimization problems as presented in Theorem 3 and Theorem 4, scales with the number of inputs and outputs of the nominal model N (s) [27]. Therefore, the robust approach is best applicable to systems where the number of inputs and outputs, m and p, are small (e.g., less than 10). Furthermore, in the frequency-based approach, optimization is typically conducted for a discrete frequency grid ω ∈ . To expedite this process, parallel com- putation can be employed, simultaneously addressing multiple frequency points. Besides the additional computational cost of optimization in step 1) of Algorithm 2, the robust approach also complicates the reduction of E and Fl( ˆF , Σ) in step 2) and 4). Namely, the models should be reduced as much as possible, while satisfy- ing ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜ F , which typically results in an iterative procedure. In case of standard, projection-based reduction methods, this too can be implemented efficiently by iteratively increasing the order of the projection matrix. To check efficiently whether ΛE,22 ∈ E,22 and ˜ΛF ∈ ˜ F at each iteration, the H∞-norm can be calculated using the instead, frequency-based bounds are approach of [30]. If,  ˆF (iω), Σ(iω) can used, as in Theorem 4, E22(iω) and Fl be determined beforehand, such that ΛE,22(iω) and ˜ΛF (iω) can be determined rapidly by only calculating ˆE22(iω) and Fl( ˆF (iω), ˆΣ(iω). Particular reduction methods also permit a priori lower or upper error bounds [31, 32], which may be used to select an initial rE, rΣ for faster convergence. In Algorithm 2, β, Gy and Gu are tuning parameters to be supplied by the user. Although any selection of these parameters guarantees ΛC to be in C, they greatly influence the resulting reduced-order model ˆΣ(s) and the required com- putational cost. Their specific influence is discussed below: Optimization parameter β F at the cost of a smaller set size of Parameter β is used to choose how to allocate the total F in the C between allowed reduction error optimization of Theorem 4. A larger β therefore increases the set size of ˜ E,22, such that Σ(s) can be reduced further and E(s) can be reduced less. Vice versa, a smaller β allows more reduction of E(s) and lesser reduction of Σ(s). Thus, β gives a trade- off between the computational cost of the structure-preserving reduction (smaller ˆE(s) reduces cost) and the amount of effective reduction of Σ(s). Remark 7. While β allows the user to increase the size of ˜ F , there exists an upper bound to ˜ F for which E,22 is an empty set, i.e., ΛE,22 = O. At this point, the reduction converts to the expensive structure-preserving reduction of Fl(E, Σ), E,22 however, ˜ which we aim to avoid with abstracted reduction (see also Section IV-A). For a sufficiently small F approximates this upper bound and further increasing β does not allow further reduction of ˆΣ(s). This value of β is in some sense optimal, as ˆΣ(s) is reduced as far as possible using Algorithm 2, and further increasing β only results in an increased order of ˆE(s) and thus in an increased computational cost of the reduction. This value is however only attainable through iterative evaluation of the resulting rΣ and rE for variable β, which is very costly itself. Augmented weighting Gu and Gy Weighting matrices Gu and Gy scale the magnitude of the augmented outputs. Intuitively, increasing their magnitude therefore increases the importance of the augmented outputs, i.e., the 22-partition of Fl( ˆF , Σ) as in (10), with respect to the external inputs and outputs of Fl( ˆE, Σ). Large Gu and Gy would therefore improve the approximation Fl( ˆF , Σ)22, such that fewer states are required to achieve ˜ΛF ∈ ˜ F , whereas small Gu and Gy would improve the approximation Fl( ˆF , Σ)11 = Fl(E, Σ). Thus, the magnitudes of Gu and Gy give a trade-off between accuracy of Fl(E, ˆΣ) and the amount of reduction. This means that for smaller Gu and Gy, ΛC becomes smaller, i.e., the reduction becomes more conservative with respect to the specified C, because 1) there is more focus on the accuracy of Fl( ˆE, Σ) compared to Fl( ˆF , Σ)22 and 2) rΣ is increased. In addition to the simple scaling of magnitudes, Gu and Gy can also be related to VF (s) and WF (s), for instance, as Gu,ij = α (∥VF,ij∥2)−2 , Gy,ij = α (∥WF,ij∥2)−2 , where (.)ij denotes the i,j’th element of the transfer matrix, α is a scalar R>0 and ∥(.)∥2 denotes the H2-norm. By the inverse relation of (45), the reduction can be steered to focus most on the input-output pairs for which the bounds are tight, allowing further reduction. Additional frequency dependencies can also be reflected by augmentation with transfer matrices Gu(s) and Gy(s), which should be bistable and biproper to allow Lemma 2. This is considered out of the scope of this paper. To evaluate the framework of abstracted reduction, we consider a structural-dynamics model for equipment in the lithography industry. The system, as shown schematically in Figure 9, represents a simplified, scaled-down frame of a lithography machine, consisting of several interconnected components. The system is a typical example of an intercon- nected structural dynamics system encountered in industry. The interconnected system is about 25×42×40 cm (x×y×z) and is made of 5 aluminium components (or subsystems), as shown in Figure 9: two plates of different thickness, a frame for the support of optical equipment, a bridge-like frame and a frame of beams connecting all components. The two plates are connected to the ground with three translational springs with a stiffness of 1010 N/m each and three rotational springs with a stiffness of 105 Nm/rad each in two locations per plate, see 2) In Section VI-B, we evaluate the frequency-based robust abstracted reduction framework of Section V-B, where we input C(ω) and reduce the thin plate to an order rΣ, such that the resulting ΛC(s) ∈ C(ω), for all ω ∈ . The abstracted environment ˆE(s) is obtained by the Hintz-Herting (HH) component mode synthesis method [34], whereas the reduction of Σ(s) (a component model) is per- formed using Closed-Loop Balanced Reduction (CLBR), as introduced by Ceton and Wortelboer et al. [18, 19]. Specifi- cally, the reduction of Σ(s) is performed using residualization (also called singular perturbation), which retains the steady state transfer. See [6] for more details. A. Fixed-order reduction For this evaluation, all 5 subsystems are reduced to a lower order rΣ, as indicated in Table I, using the abstracted reduction approach introduced in this paper. To this end, we first formulate an environment model Ej, for each j ∈ {1, . . . , 5}, as the interconnection of all remaining subsystems Σl, l ∈ {1, . . . , 5}\\{j}, and then perform Algorithm 1 once for each subsystem Σj. To properly evaluate the reduction of all Σj in the abstracted reduction framework, three balanced reduction methods are used: subsystem balanced reduction (ssBR), without taking the environment into account (see Figure 2a and [22]), in- terconnected systems balanced reduction (ISBR), taking its full environment into account (see Figure 2b and [9]), and abstracted reduction using CLBR (aCLBR), taking only an abstraction of the environment into account (see Figure 2c, Algorithm 1 and [19]). The three resulting reduction methods are then compared in terms of computational cost and the accuracy of the resulting reduced-order, interconnected model. The ISBR approach, as introduced by Vandendorpe and Van Dooren [9], is a generalization of CLBR. Whereas CLBR is only defined for 2 interconnected subsystems, ISBR reduces all k ≥ 2 subsystems to retain their relevance with respect to the interconnected system. For aCLBR, we use Gy = Gu = Om×m, i.e., no augmentation, to focus solely on the accuracy of Fl(E, ˆΣ). The accuracy of the reduced-order, interconnected models is measured by visually comparing their frequency response functions (FRFs) with the FRFs of the unreduced intercon- nected model, the FRFs of their error ΛC(s) and the bounded L2-norm of ΛC(s) [20] (on the frequency-domain of 10 to 106 Hz, relevant for this application) given by  2π×106 Table II compares the computational cost of the reduc- tion methods1 and the obtained accuracy. Clearly, and as expected, ssBR is the most computationally efficient, as only the dynamics of the individual subsystem models are evaluated upon their reduction. ISBR, on the other hand, considers the full interconnected model dynamics, which results in a considerable increase in computational cost with a factor 12. Figure 9. The components are connected to each other with linear springs with a stiffness of 108 N/m per spring in x-, y- and z-directions at the interface points shown in Figure 9. Each component has a modal damping factor [33] of 5% for each eigenmode. As a result, the interconnected model has no rigid-body modes and is asymptotically stable. All components are modeled by high-order transfer function matrices with forces as their inputs and collocated displace- ments as outputs, such that the spring interconnection is represented by a static interconnection matrix [17]. The model order and the number of inputs and outputs per component model are indicated in Table I. The interconnected system has two external, collocated, force inputs and displacement outputs (mC = pC = 2): one at the interface between the thin plate and the beam frame in y-direction and one at the interface between the bridge and the beam frame in x-direction, as indicated in Figure 9. The original interconnected system model, with an order of 2136, is too computationally costly for various industrial applications, such as real-time simulation, (low-order) con- troller synthesis, online monitoring, and sensitivity analysis. Therefore, in this section, we will reduce the interconnected system model to a lower order. Specifically, we will perform two evaluations: 1) In Section VI-A, we evaluate the abstracted reduction framework of Algorithm 1, where we select the re- duction orders rE and rΣ beforehand, as indicated in Table I, and reduce all subsystems. By taking only an abstraction into account, aCLBR reduces this cost by a factor 6 to only twice the cost of ssBR. Remark 8. When Σ(s) represents the beam frame, the order of Fl( ˆF , Σ) is 1128, which remains relatively high. This high order can be attributed to the disparity in order between the beam frame and the other subsystems. Recall that aCLBR demonstrates its greatest efficiency improvement when the environment is substantially larger than the subsystem, as illustrated in Figure 5. If all subsystems would be of similar size, the computational cost of aCLBR would approach the cost of ssBR. As mentioned before, Table II also indicates the accuracy of the various reduced-order models (ROMs) by means of the (relative) L2-norm of the corresponding error systems. While all relative L2-norms are quite large due to the significant order reduction, a clear distinction in accuracy is observable. First of all, the ssBR-ROM results in a significantly higher L2 error norm than the other two ROMs. This is as expected, as ssBR considers only the separate subsystems. Furthermore, the accuracy of the ISBR-ROM, in terms of its L2 error norm, shows a slight superiority with respect to the accuracy of the aCLBR-ROM. This small sacrifice in accuracy is a logical result from the introduced abstraction error with aCLBR. We can conclude that aCLBR is capable of achieving an accuracy level comparable to ISBR, while requiring computational cost almost competitive wth ssBR. The magnitudes of the two collocated FRFs of the full-order model (FOM) of the interconnected system are visualized together with the FRFs of the three corresponding reduced- order models (ROMs) in Figures 10a and 10b. The FRFs of the collocated errors from ΛC(s), i.e., the differences between the FRFs of ROMs and of the FOM, are visualized underneath in Figures 10c and 10d. These error plots reflect in more detail the observations made above regarding the L2 error norms. Namely, the ssBR-ROM displays a clearly inferior accuracy with respect to the other two, whereas the accuracy of the ISBR- and aCLBR-ROMs seems similar. Summarizing, we have evaluated (open-loop) subsystem reduction (ssBR), structure-preserving reduction (ISBR) and an abstract implementation (aCLBR), as presented in Algo- rithm 1, by means of a benchmark system from the field of structural dynamics. For this example, the proposed abstracted reduction approach achieves similar accuracy to the accurate but expensive ISBR method, while having a computational cost similar to the cheap but inaccurate ssBR method. In this example, we will focus on the reduction of the thin plate, denoted Σ(s), such that the remaining (connected) components/subsystem models form the environment model E(s) with an order of nE = 1756, p + mC = 11 inputs and m + pC = 11 outputs. Our goal is to reduce Σ(s) to ˆΣ(s) with abstracted reduction, such that ΛC(iω) ∈ C(ω) for all ω ∈ , where ΛC := Fl(E, ˆΣ) − Fl(E, Σ). We first select the frequency grid as 250 logarithmically equidistantly spaced points between 5 Hz and 2 kHz. We then visualize the FRF matrices of Fl(E, Σ), E22(s) and Fl( ˆF , Σ), , as by means of their spectral norm per frequency in the black lines in Figure 11a, Figure 11b and Figure 11c, respectively. To simplify interpretation of the accuracy specifications, we restrict the scaling matrices to be of the form VE(iω) = εE(ω)Ip, WE(iω) = εE(ω)Im, VF (iω) = εF (ω)Im, WF (iω) = εF (ω)Ip, WC(iω) = εC(ω)IpC , VC(iω) = εC(ω)ImC , for nonnegative, real scalars εE(ω), εF (ω), εC(ω). The error specifications can then be simplified to E,22(ω) = {ΛE,22(iω) | ∥ΛE,22(iω)∥ < εE(ω)}, ˜ F (ω) = {˜ΛF (iω) | ∥˜ΛF (iω)∥ < εF (ω)}, C(ω) = {ΛC(iω) | ∥ΛC(iω)∥ < εC(ω)}. We specify the allowed coupled inaccuracy C(ω) by setting εC(ω) = 10−7, for all ω ∈ . The coupled inaccuracy specification C(ω) is visualized accordingly in Figure 11a as the blue area. This rather simple choice of εC(ω) emphasizes the accurate prediction of the resonance peaks, which might be relevant in, for example, a structural health monitoring use case where structural wear or damage may result in a frequency shift of the resonance peaks. The specifications F (ω) are subsequently determined using The- orem 4 for a range of β. The influence of β on the bounds εF and εE is visualized in Figure 12a. As explained in Section V-C, β influences the C(ω). Specifically, a distribution of the total error budget large β increases the bound εF (ω) at the cost of a smaller bound εE(ω). For β → ∞, only εF (ω) is maximized, regardless of εE(ω), i.e., εF (ω) is the bound on ˜ΛF (ω) if the full E(s) is considered instead of ˆE(s). For β = 0, the opposite occurs, and εE(ω) is maximized, regardless of εF (ω). However, the latter optimization problem is ill-posed as the F , because E,22 is theoretically unbounded for an empty set ˜ for ˜ΛF = O, ˆΣ(s) = Σ(s) regardless of ˆE(s). Naturally, a larger allowed error bound can be satisfied more easily by a reduced model, so that the model’s order can be decreased further. Therefore, varying β also allows a trade- off between rΣ and rE. Assuming Gy = Ip, Gu = Im, we can visualize this trade-off in Figure 12b. Note that we want to reduce Σ(s) as far as possible, i.e, nΣ − rΣ should be large, while nE − rE should only be sufficiently small to reduce the computational complexity of the reduction ap- proach. Figure 12b indicates that E(s) can be reduced by over 80% without significantly influencing the allowed reduction of Σ(s). This exemplifies the motivation of using environment abstraction for effective reduction of coupled systems. In addition to the influence of β on F , weighting matrices Gy and Gu determine ˆF (s), enabling to change the importance of the augmented outputs compared to the interconnected system outputs in the structure-preserving reduction of Fl( ˆF , Σ) (see Section V-C). To evaluate the influ- ence of these weighting matrices, we determine the maximum order reduction with weighting Gy = αIp, Gu = αIm for α = 0.01, 1, and 100, as visualized in Figure 13. As explained in Section V-C, a high value α favors the accuracy of the augmented outputs, such that, for a large α, ˜ΛF (s) would be relatively small, whereas ΛC(s) would be relatively large. This implies that for a given rE, a smaller rΣ would be and rΣ = 63 (nE = 1756, nΣ = 380). The FRFs of ˆE22 and Fl( ˆF , ˆΣ)22 and their errors are visualized by red dashed lines in Figure 11b and Figure 11c, respectively, which are, by definition, fully included in the blue area. Interconnection of ˆΣ(s) with E(s) gives the reduced interconnected model Fl(E, ˆΣ), whose FRF and error are visualized by red dashed lines in Figure 11a, which are also well within the specification of C(ω). Remark 9. The full execution of the robust abstracted re- duction framework of Algorithm 2 using these settings takes approximately 450 s, of which most time is required to solve the optimization problem of Theorem 4. The computation time depends on the number of inputs and outputs of Σ (which determine the dimensions of N ) and the efficiency of the used numerical method. Currently, V −2(iω), W −2(iω) and Dℓ, Dr are solved iteratively using MOSEK [35]. However, there exist much more efficient methods to calculate bounds on µ∆(V N W ) (as used in Theorem 3) [36]. Incorporating such methods could potentially speed up the determination of E,22 and ˜ F significantly. This is, however, outside the scope of this paper and is left for further research. The robust abstracted reduction framework allocates an error budget, εE(ω), to the reduction of E and, εF (ω), to the reduction of Σ. To reduce E and Σ as far as possible, we should aim to use as much of these budgets as pos- sible. However, the chosen reduction methods do not take these error budgets into account, resulting in considerable conservatism. This is especially apparent for the abstraction, where ∥ΛE,22(iω)∥ ≪ εE(ω) for most frequencies, as shown in Figure 11b. In addition, even when ∥ΛE,22(iω)∥ ≈ εE(ω), usually only one input-output pair restricts further reduction, while other input-output pairs are well within specification. These two sources of conservatism result in significant conservatism of the eventual reduced, interconnected model Fl(E, ˆΣ), as shown by difference of a factor 100 between actual error and allowed error. In addition, the reduced orders of rE = 184 and rΣ = 63 remain quite large. Through iterative reduction and evaluation of ΛC(s), a process that is far from C(ω), straightforward, we found that the specification of with εC(ω) = 10−7, for all ω ∈ , is achievable by aCLBR with rE = 20 and rΣ = 8 and by ssBR with rΣ = 22. the above analysis gives insight into the sensitivity of the resulting error ΛC(s) to inaccuracies of the environment model. Namely, the environment model can be reduced significantly without seriously impacting the resulting accuracy of the reduced interconnected system model. This observation therefore also strengthens the case for using the general abstracted reduction framework of Algorithm 1. C. Key insights from numerical evaluation For the considered use case, abstracted model reduction, as introduced in Section III and evaluated in Section VI-A, yielded an accuracy of the reduced interconnected system similar to the expensive structure-preserving method, while having a computational cost similar to the cheap subsystem reduction method. In other words, the framework of abstracted model reduction can significantly improve the computational Fig. 13. Maximum reduction allowed for the environment model E(s) and thin plate model Σ to satisfy E,22(ω) and ˜ F (ω), respectively, for different weighting matrices Gu = αIp and Gy = αIm. required for ˜ΛF ∈ ˜ F if α is large. However, the results shown in Figure 13 are not consistent with this, as a larger α often allows less reduction of Σ(s), given a certain given rE. In addition, we observe a rather nonlinear relation between error bounds and reduction order, which makes it difficult to set proper α and β that result in the maximum reduction of E(s) and Σ(s). This inconsistency between the theory and the results of Figure 13 is attributed to the presented use case (where the dynamics of Σ relevant to the input-output behaviour of Σ and Fl(E, Σ) seems to align) and the non- optimality of CLBR (or weighted CLBR [8]). Further study is required to asses the influence of Gy and Gu in alternate use cases using other reduction methods. Because the above evaluation of β and α to find ‘optimal’ values is usually too time-consuming (±1 hour for this use case), it is typically wise to select β > 1, which puts emphasis on reduction of Σ(s), accepting a higher order ˆE(s), resulting in a slightly higher computational cost (see Section V-C). For the remainder of the evaluation in this section, we will use β = 100. As CLBR does not respond intuitively to the weighting of Gy and Gu, we simply select Gy = Ip, Gu = Im. The frequency-dependent accuracy specifications E,22(ω) and ˜ F (ω) for these choices of β, Gy and Gu are visualized by the blue areas in Figure 11b and Figure 11c, respectively. The environment model E(s) and augmented, abstracted sys- tem Fl( ˆF , Σ) are subsequently reduced as far as possible subject to ΛE,22(iω) ∈ E,22(ω), ˜ΛF (iω) ∈ ˜ F (ω), for all ω ∈ using Hintz-Herting reduction for the environment and CLBR for the thin plate model, resulting in rE = 184 tractability of structure preserving methods while retaining similar accuracy. This indicates that the low-order abstractions of the environment models are sufficient to indicate what subsystem dynamics needs to be retained to attain an accurate reduced-order interconnected system model. This observation regarding the sufficiency of low-order abstractions is reaffirmed in the assessment of the robust abstracted reduction framework, as introduced in Section V and evaluated in Section VI-B, which showed that reducing the environment up to 80% does not significantly impact the reduced system. Although the evaluation in Section VI-B indicates that robust abstracted reduction tends to be conserva- tive, this tendency might significantly mitigated by utilization of alternative reduction methods. In addition, the stability guarantee, given by the robust abstracted reduction framework, remains valuable even in cases of conservatism. We have introduced the framework of abstracted reduction to improve the tractability of the structure-preserving reduction of interconnected systems. In this framework, the structure- preserving reduction method is not applied to the full inter- connected system model, but to a single subsystem model con- nected to a low-order abstraction of its environment. By thus applying structure-preserving reduction to a much lower-order model, the computational cost of this reduction is significantly reduced. Leveraging techniques from robust performance, we introduced a second approach to also automatically determine (environment) abstraction and (subsystem) reduction orders that guarantee the reduced interconnected system model to be stable and to satisfy a prescribed H∞-accuracy specification. By means of a high-dimensional model representing an interconnected lithography machine frame, we have illustrated that employing a structure-preserving reduction method within the abstracted reduction framework can significantly decrease the reduction’s computational cost without significant loss of accuracy. Although the robust performance-based approach tends to yield a conservative reduced-order model of the inter- connected system, it effectively illustrates the relation between the introduced error budgets. It is important to emphasize that the introduced abstracted reduction framework is versatile, i.e., it is compatible with any structure-preserving reduction method. This versatility suggests the potential for numerous al- ternative implementations that offer enhanced accuracy, greater order reduction, and less conservatism compared to the current implementation. VIII. ACKNOWLEDGEMENTS The authors would like to thank Dr. Victor Dolk and Thijs Verhees, M.Sc., for valuable discussions.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2411/2411.13344v1.pdf",
         "extracted",
         "None",
         "",
         "Abstracted Model Reduction: A General Framework for Efficient Interconnected System Reduction"
        ],
        [
         "16",
         "0070139c46648999df1072c940d0b9f7ad25f258",
         "Vehicle-to-grid (V2G) energy trading based on distributed ledger technologies (DLT), such as blockchains, has attracted much attention due to its promising features, including ease of deployment, decentralization, transparency, and security. However, existing DLT-based models do not support microtransactions due to the low value of such transactions relative to the incentives offered to transaction verifiers. To address this issue, we propose an IOTA DLT-based efficient and secure energy trading model for V2G networks, where electric vehicles (EVs) and grids negotiate energy prices in an off-chain manner. The proposed model utilizes a privacy-preserving protocol to prevent real-time tracking of EV locations. We develop a Stackelberg game model to represent the interactions between the EVs and grids, from which we derive a pricing scheme and propose a deposit mechanism to prevent fake energy trading between the EVs and grids. Extensive simulations demonstrate that our proposed scheme outperforms existing V2G energy trading mechanisms regarding transaction efficiency, provides enhanced EV privacy, and improves resilience against fake energy trading. Offering robust computational performance and addressing computational complexity (time, space, and message), our model presents a comprehensive V2G energy trading solution, balancing efficiency, security, and privacy.",
         "Muhammad Rizwan,Mudassir Ali,Ammar Hawbani,Xingfu Wang,Adeel Anjum,Pelin Angin,Olaoluwa R. Popoola,M. A. Imran",
         "\n**BLOCK**fs== 12.0**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nRizwan, M., Ali, M., Hawbani, A., Wang, X., Anjum, A., Angin, P., Popoola,\nO.  and Imran, M. A.  (2024) IOTA-based game-theoretic energy trading\nwith privacy-preservation for V2G networks. IEEE Transactions on\nSustainable Computing, (doi: 10.1109/TSUSC.2024.3410237)\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nThe University of Glasgow has an agreement with IEEE which allows all\nUofG authors to self-archive accepted manuscripts submitted to any of the\nsubscription-based (hybrid) IEEE journals, magazines, or conference\nproceedings. Authors can immediately self-archive accepted manuscripts in\nan institutional or subject based repository with a self-attributed CC BY\nlicence. The agreement covers all original research and review articles.\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.4**l== 0.2**r== 0.3**\nCopyright © 2024 IEEE. Reproduced under a Creative Commons\nAttribution 4.0 International License.\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nhttps://doi.org/10.1109/TSUSC.2024.3410237\n**BLOCK**fs== 14.3**p== 0.0**b== 0.4**t== 0.5**l== 0.2**r== 0.5**\nhttps://eprints.gla.ac.uk/328280/\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nDeposited on: 12 August 2024\n**BLOCK**fs== 12.0**p== 0.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nEnlighten – Research publications by members of the University of Glasgow\nhttps://eprints.gla.ac.uk\n**BLOCK**fs== 24.0**p== 1.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nIOTA-based Game-Theoretic Energy Trading\nwith Privacy-Preservation for V2G Networks\n**BLOCK**fs== 11.0**p== 1.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nMuhammad Rizwan, Mudassir Ali , Ammar Hawbani, Wang Xingfu, Adeel Anjum,\nPelin Angin, Olaoluwa Popoola, and Muhammad Ali Imran\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nAbstract—Vehicle-to-grid (V2G) energy trading based on distributed ledger technologies (DLT), such as blockchains, has attracted\nmuch attention due to its promising features, including ease of deployment, decentralization, transparency, and security. However,\nexisting DLT-based models do not support microtransactions due to the low value of such transactions relative to the incentives offered to\ntransaction verifiers. To address this issue, we propose an IOTA DLT-based efficient and secure energy trading model for V2G networks,\nwhere electric vehicles (EVs) and grids negotiate energy prices in an off-chain manner. The proposed model utilizes a privacy-preserving\nprotocol to prevent real-time tracking of EV locations. We develop a Stackelberg game model to represent the interactions between the\nEVs and grids, from which we derive a pricing scheme and propose a deposit mechanism to prevent fake energy trading between the\nEVs and grids. Extensive simulations demonstrate that our proposed scheme outperforms existing V2G energy trading mechanisms\nregarding transaction efficiency, provides enhanced EV privacy, and improves resilience against fake energy trading.Offering robust\ncomputational performance and addressing computational complexity (time, space, and message), our model presents a comprehensive\nV2G energy trading solution, balancing efficiency, security, and privacy.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\nIndex Terms—Blockchain, game theory, IOTA, privacy, resource management, security, smart grid\n**BLOCK**fs== 8.8**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n1 INTRODUCTION\n**BLOCK**fs== 9.5**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nE Lectric Vehicles (EVs) and renewable energy sources\n**BLOCK**fs== 9.5**p== 1.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n(RES) play an important role in sustainable energy and\nreducing the adverse impacts of fossil fuels, hence attracting\nincreasing attention from both academia and industry in re-\ncent years. Efficient energy utilization requires keeping track\nof the interactions between the producers and consumers so\nthat producers can adjust their supplies according to con-\nsumer demands [1]. Vehicle-to-Grid (V2G) energy trading is\none of the most promising solutions for this problem [2].In\nparticular, EVs can use energy storage to reduce the grid\nload by trading excess energy[3].EVs can accumulate energy\nand sell extra energy to the grid when parked[4].\n**BLOCK**fs== 9.5**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nCentralized platforms are unsuitable for managing V2G\ntransactions due to problems including single point of fail-\nure, poor scalability, reduced control over data integrity, and\nlack of transparency. Hence, distributed ledger technology\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n• Muhammad Rizwan, and Xingfu Wang are with the School of Computer\nScience and Technology, University of Science and Technology of China\n(rizwanramay@gmail.com, wangxfu@ustc.edu.cn).\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• Ammar Hawbani is with the School of Computer Science, Shenyang\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nAerospace University, email: anmande@ustc.edu.cn\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• Mudassir Ali and Adeel Anjum are with the Institute of Information\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nTechnology, Quaid-i-Azam University, Islamabad, Pakistan\nE-mail: mudassir.ktk6@gmail.com, adeelanjum2001@hotmail.com\n**BLOCK**fs== 8.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• Pelin Angin is with the Department of Computer Engineering, Middle\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nEast Technical University, Ankara, Turkey\nE-mail: pangin@ceng.metu.edu.tr\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n• Olaoluwa Popoola and Muhammad Ali Imran are with James Watt\nSchool of Engineering, University of Glasgow, Glasgow, Scotland,\nUnited Kingdom Email: Olaoluwa.Popoola@glasgow.ac.uk, Muham-\nmad.Imran@glasgow.ac.uk\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nA. Hawbani and X. Wang are the corresponding authors.\n**BLOCK**fs== 9.5**p== 1.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n(DLT) based solutions such as blockchains are currently\nfavored for verifying and storing energy trading transac-\ntions[5]. While blockchains offer secure P2P trading and\nreliable storage, their effectiveness in V2G networks is still\nunder evaluation([1], [6], [7]), they still suffer from the\nlong block verification delay resulting in low throughput,\nand they can be rather compute-intensive [8]. Moreover,\nconventional blockchains do not support microtransactions\nsince the value of such transactions is typically less than\nthe incentives offered to miners. On the other hand, large\nV2G transactions can become unprofitable due to increased\ntransaction costs.\n**BLOCK**fs== 9.5**p== 1.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nIn this paper, we propose an IOTA DLT-based approach\n[9] for V2G energy trading, which aims to overcome the\nshortcomings mentioned above of blockchain-based ap-\nproaches. The main contributions of this paper are as fol-\nlows: The main contributions of this paper are as follows:\n**BLOCK**fs== 9.5**p== 1.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n• We design an IOTA DLT-based energy trading model\nfor V2G networks and propose a privacy-preserving\nprotocol for energy trading in V2G networks. The\nprotocol allows the system to prevent tracking the\nexact locations of EVs and securely perform the price\nnegotiations between the EVs and grids in the V2G\nnetwork.\n**BLOCK**fs== 9.5**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n• We show that energy trading between the EVs and\ngrids in the V2G network can be modeled as a\nStackelberg game, with multiple leaders represented\nby EVs and multiple followers represented by grids.\nBased on the game model, we formulate the algo-\nrithm that incentivizes EVs to participate in energy\ntrading while enabling the grids to select the EVs\nwith the best offers.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nsecurity of the IOTA DLT, where EVs must deposit\nIOTA coins with their energy offers, and grids pay\nin IOTA coins at the time of price agreement. This\nensures that the EVs are committed to their energy\noffers and discourages malicious behavior.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nTo evaluate our scheme’s effectiveness, we compare it\nwith a recent blockchain-based V2G energy trading ap-\nproach. Though both leverage DLT and game theory, they\ndiffer in focus and approach. Simulations demonstrate our\nscheme’s superior cost-effectiveness.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nThe rest of this paper is organized as follows. In Section\n2, we review related work on different approaches for V2G\nenergy trading. Section 3 presents the necessary background\non IOTA. Section 4 presents the system model and the pro-\nposed IOTA-based protocol for privacy-preserving energy\ntrading in V2G networks. In Section 5, we formulate the\ngame model of energy trading between the EVs and grids,\nbased on which we construct the algorithms that incentivize\nthe EVs to participate in energy trading while, at the same\ntime, enabling the grids to select the EVs with the best offers.\nIn Section 6, we evaluate the performance and security of\nthe proposed system. Finally,and we conclude the paper and\ndiscuss future work in Section 7.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.2**t== 0.4**l== 0.1**r== 0.5**\n2 RELATED WORK\nThis section reviews existing work on decentralized V2G\nenergy trading, which has captured increasing attention of\nboth industry and academia in recent years. In [10], the\nauthors proposed a privacy-preserving, automated, reliable\nblockchain-based protocol to select the optimum charging\nstations based on the distance from EVs and energy price.\nAlthough the protocol achieves a relatively small overhead,\nit does not prevent possible dishonest behavior by EVs\nin negotiations. In [11], the authors proposed a Bayesian\ngame-based scheme for energy trading in V2V. The result\nshows that user satisfaction in the proposed scheme reaches\n98% with incomplete information. However, the proposed\nscheme has poor runtime performance because all pro-\ncesses run as blockchain transactions. In [12], the authors\ndesigned the architecture of a decentralized power trading\nsystem of EVs, which is consortium blockchain-based. The\nproposed scheme’s security evaluation showed that it is\nresilient against different types of attacks. However, the\nmodel did not consider the uncertainty about the range\nof the discharging vehicles. In [13], the authors proposed a\nfog computing-based architecture for energy trading. Their\nevaluation demonstrated that the genetic algorithm achieves\nmaximum social welfare, which is 71.03% more than the\nLagrange algorithm.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nHowever, performance suffers because all the auction\nprocesses run as a blockchain transaction. In [14], the au-\nthors designed a system called FeneChain for decentral-\nized energy trading. The results showed that FeneChain\nperforms better than the other three schemes regarding\nenergy sales and energy purchase computational costs.\nHowever, the authors did not consider fairness. In [15], the\nauthors proposed a blockchain-based differential auction of\nprivate energy for microgrids. They showed that the pro-\nposed mechanism performs better than other mechanisms\nfor auctions. However, no incentive was provided in the\n**BLOCK**fs== 9.5**p== 2.0**b== 0.5**t== 0.1**l== 0.5**r== 0.1**\nauction process to guide energy suppliers/buyers. In [16],\nthe authors leveraged blockchain technology to develop a\nP2P secure energy trading system. They showed that the\nproposed scheme’s benefits increase when the number of\nEVs in the network increases. In [17], the authors pro-\nposed a framework for secure energy trading based on\na consortium blockchain. Although the scheme performs\nwell in maximizing social welfare, it is rather compute-\nintensive, prohibiting widespread deployment. In [5], the\nauthors proposed a consortium blockchain-based frame-\nwork of V2G energy trading, which is efficient and secure\nfor cyber-physical systems. They showed that the proposed\nframework is promising in terms of provided security, the\nperformance of task offloading, and contract feasibility.\nHowever, the local energy aggregators cannot purchase the\nlarger services when the transaction fee is low. In [18], a\nblockchain-based privacy-preserving network of incentive\nannouncements was proposed. See Supplementary Table\nfor details. The authors compared the proposed protocol\nwith others and showed that it is more efficient. However,\nblockchain’s high computation resource requirements pre-\nvent incentive announcements from being widely deployed.\nIn [19], a blockchain-based real-time system that uses a cryp-\ntocurrency and a prioritization concept called SMERCOIN\nto incentivize EVs to charge in a renewable energy-friendly\nschedule was proposed.\n**BLOCK**fs== 9.5**p== 2.0**b== 0.2**t== 0.5**l== 0.5**r== 0.1**\nThe evaluation results showed that the local consump-\ntion rate increased to 37%, decreasing the aggregator’s\nenergy cost. However, the work only focused on renew-\nable energy consumption rates and did not consider EV\nprivacy. More recent work by Zhang et al. [20], Sharma et\nal. [21] and Liang et al. [22] have also proposed blockchain-\nbased approaches for V2G energy trading, but they carry\nthe same disadvantages as other blockchain-based models.\nIn [1], the authors proposed a Directed Acyclic Graph-\nbased lightweight protocol for V2G (DV2G). The proposed\nmodel’s evaluation showed that it supports microtransac-\ntions and is highly scalable. However, it did not consider EV\nprivacy. In [6], the authors proposed a distributed network\nof charging stations for Unmanned Aerial Vehicles (UAVs)\nbased on IOTA. They showed that the proposed scheme\nprovides better revenue and utility for charging stations and\nUAVs than traditional blockchain-based schemes. In [7], the\nauthors proposed a blockchain-based system of Internet of\nVehicles (IoV) data trading, which uses a debit-credit mech-\nanism using a two-stage Stackelberg game. The scheme\nis limited to data trading and does not focus on energy\ntransactions. In [23], The authors introduced a blockchain-\nbased spectrum trading platform for UAV cellular networks,\ndemonstrating its efficiency and effectiveness in enhancing\nprivacy and security. However, the proposed scheme lacks\nspecific strategies to prevent malicious providers and buy-\ners.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.3**\n3 IOTA DLT OVERVIEW\n**BLOCK**fs== 9.5**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIOTA is an open-source DLT designed specifically for the In-\nternet of Things. It is based on the tangle data structure that\nuses directed acyclic graph (DAG) characteristics. IOTA uti-\nlizes digital identities to assure trust among its participants,\n**BLOCK**fs== 9.5**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ncalled network nodes[24]. In IOTA, digital identity verifica-\ntions are decentralized and free from third parties. Private\nand virtual pseudo-anonymous wallets store the IOTA coins\nof smart devices. Computational cost is a major obstacle\nin verifying transactions in traditional blockchains[25]. The\ndetails are provided in a supplementary file.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nif discharging,\n**BLOCK**fs== 9.5**p== 3.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\n1,\n0, otherwise,.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\n4 SYSTEM MODEL\nThe main objective of our proposed V2G energy trading\nmodel is to encourage more participants to participate in\nthe process of energy trading to maximize the V2G network\nwelfare.The EVs and grids act as prosumers, which produce\nand consume energy. The energy trading benefit in a V2G\nnetwork is maximized by maximizing the revenue of grids\n(buyers) and EVs (sellers). Our proposed model considers\nsix parameters to maximize the overall system benefits:\ntransaction efficiency, EV privacy, fake energy offers, the\nbest EV selection at time slot t, EV distance price, and\nmicrotransactions.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nThe main components of the proposed V2G energy trad-\n**BLOCK**fs== 9.5**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\ning model are as follows:\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n1) Energy nodes: The EVs and grids are the energy nodes in\nthe V2G network. The EVs can act as prosumers (pro-\nducing and consuming energy) and as energy sellers.\nThe grids work as energy buyers.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n2) Energy aggregator: This is an energy-trading broker be-\ntween the EVs as energy sellers and the grids as energy\nbuyers. In the IOTA DLT, the brokerage mechanism\nemployed in the aggregator can be realized using smart\ncontracts that allow direct communication between the\nEVs and grids.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n3) Smart meters: These contain details regarding how much\n**BLOCK**fs== 9.5**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nenergy is traded between the EVs and grids.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\n4.1 V2G Network Energy Trading Model\n**BLOCK**fs== 9.5**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nIn this section, we describe the V2G network energy trading\nmodel. Table 1 provides a summary of the symbols used in\nthe model.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nThe V2G system operates on a time-slotted basis with t\ndenoting the time slot number and ∆t being the time slot\nduration.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nLet P = {1, ..., i, ..., p} be the set of prosumers. We define\nthe energy generation profile of prosumer i for one day as:\n**BLOCK**fs== 9.5**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nwhere Gt\ni is the power generated by the prosumer i during\ntime slot t, and T is the number of time slots per day. We\ndefine the power consumption profile of prosumer i as:\n**BLOCK**fs== 9.5**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nwhere U t\ntime slot t.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\ni is the power consumption of prosumer i during\n**BLOCK**fs== 9.5**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nProsumer i’s energy storage calculated in terms of ESUs\n**BLOCK**fs== 9.5**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nis computed at the time of charging/discharging as:\n**BLOCK**fs== 7.0**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nd,i and Bt\n**BLOCK**fs== 9.5**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nBt\nc,i are binary variables meeting the following\ncondition to avoid simultaneous charging and discharging:\n**BLOCK**fs== 9.5**p== 3.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nWe calculate the ESU’s total energy storage as\n**BLOCK**fs== 7.0**p== 3.0**b== 0.7**t== 0.3**l== 0.7**r== 0.3**\ni = ηt−∆t\nηt\ni\n**BLOCK**fs== 9.5**p== 3.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nHere, ηt\ni represents the prosumer i’s total energy amount\nstored in the ESU at time slot t, and ηt−∆t\nrepresents the\nprosumer i’s energy storage in the ESU at the start of time\nslot t.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nThe minimum and maximum charging limits are ex-\npressed using the following equation, where these limits are\ndecided based on the SP inverter size.\n**BLOCK**fs== 7.0**p== 3.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\np,i ≤ Qmax\np,i\n**BLOCK**fs== 7.0**p== 3.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\np,i ≤ Dmax\n**BLOCK**fs== 7.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nHere, Qmax\nDmax\np,i\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nrepresents the maximum charging power, and\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nrepresents the maximum discharging power.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nProsumer i profits if the ESUs’ daily cost is less than the\n**BLOCK**fs== 9.5**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\ntotal savings obtained in a day.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.7**r== 0.2**\nγi = (CCi + SCi)/d,\n**BLOCK**fs== 9.5**p== 3.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nwhere γi represents the total cost per day. CCi\nis the\ncombined cost for the ESU and converter, SCi represents\nthe annual sustaining cost, and d represents the number of\ndays in a year.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nµi = αi–γi,\n**BLOCK**fs== 9.5**p== 3.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nwhere µi represents the total profit in a day of prosumer i,\nand αi shows the total savings in a day.\n**BLOCK**fs== 9.5**p== 3.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nLet X be the total number of sellers (EVs), and Y be the\ntotal number of buyers (grids), where x ∈ X and y ∈ Y .\nProsumer i’s production-to-consumption ratio at time slot t\nis calculated as\n**BLOCK**fs== 7.0**p== 3.0**b== 0.2**t== 0.7**l== 0.7**r== 0.2**\nGt\nsp,i\nU t\ni\n**BLOCK**fs== 9.5**p== 3.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nIf ξt\ni is greater than 1, it means that the EV has surplus\nenergy. The total amount of energy that the EV i sells to the\ngrid at time slot t is calculated using the following equation:\n**BLOCK**fs== 7.0**p== 3.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\ni,sell = Et\n**BLOCK**fs== 7.0**p== 3.0**b== 0.1**t== 0.9**l== 0.7**r== 0.2**\ny,buy = ψy–ψt\n**BLOCK**fs== 9.5**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nwhere Ψt\ny,buy represents the amount of energy that the grid\nbuys at time slot t [1]. ψy represents the total grid capacity\nof energy storage, and ψt\ny,s represents the grid’s level of\nstorage at time slot t.\n**BLOCK**fs== 6.0**p== 4.0**b== 0.6**t== 0.1**l== 0.1**r== 0.8**\nSymbol Meaning\nP\nT\n∆t\nGt\nU t\ni\nλt\ni\nΛt\ni\nηt\ni\nηt−∆t\ni\nQmax\np,i\nDmax\np,i\nγi\nCCi\nSCi\nµi\nαi\nξt\ni\nEt\nΨt\nry,x\nΨt\nωt\nx\n¯ωt\nx\nCKi\nRt\nSt\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.1**l== 0.2**r== 0.5**\nSet of prosumers\nGame duration in time slots\nTime slot duration\nEnergy generated by prosumer i at time slot t\nProsumer i’s energy consumption at time slot t\nESU i’s energy amount at time slot t during charging\nESU i’s energy amount at time slot t during discharging\nESU i’s total energy amount at time slot t\nESU i’s total energy at the start of time slot t\nMaximum charging power of ESU i\nMaximum discharging power of ESU i\nTotal cost per day of prosumer i’s ESU\nCombined cost of prosumer i’s ESU and converter\nAnnual sustaining cost for prosumer i\nProsumer i’s total profit in a day\nTotal cost savings of prosumer i in a day\nProduction/consumption ratio of prosumer i at time slot t\nEnergy amount EV i sells at time slot t\nEnergy amount grid y buys at time slot t\nRatio of the supply of EV x to the demand of grid y\nGrid true value to select best EV at time slot t\nTotal distance price of EV x\nSupply price imposed by EV x\nEnergy consumption per kilometer of EV i\nDistance range of EV x at time slot t\nDischarging EV i’s enforced price at time slot t\nGrid demand less discharging EV i’s available energy\nat time slot t\nAverage utility of the first group of EVs\nNumber of EVs in the first group\nAverage utility of the second group of EVs\nRatio of average utility\n**BLOCK**fs== 6.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\nUa1\nηt\nx,g1\nUa2\nUa,r\n**BLOCK**fs== 6.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.9**\ni,price\n**BLOCK**fs== 9.5**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n4.2 Threat Model\n**BLOCK**fs== 9.5**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nV2G energy trading in the system scenario considered in\nthis work may face the following threats:\n**BLOCK**fs== 9.5**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n• T1: The EV changes selling prices after a grid com-\n**BLOCK**fs== 9.5**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nmits to an offer made by it.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n• T2: The EV makes fake energy-selling offers to attract\ngrids and manipulate the operation of the whole\nsystem.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n• T3: The grid refuses to pay for the energy provided\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nby an EV after the energy transfer takes place.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n• T4: The EV masquerades as another EV to collect the\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\npayments for its energy sales.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n• T5: The EV masquerades as another EV to make fake\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nenergy offers on its behalf.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n• T6: The grid makes a fake energy purchase commit-\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nment on behalf of another grid.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• T7: The energy selling offer made by an EV is modi-\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nfied by an adversary.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• T8: The energy purchase bid made by a grid is\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nmodified by an adversary.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n4.3 IOTA-Based Privacy-Preserving Energy Trading\nProtocol\n**BLOCK**fs== 9.5**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nfor privacy-\nIn this section, we describe the protocol\npreserving energy trading between the EVs and grids in\nthe V2G network. The basic privacy requirements for this\nprotocol are as follows:\n**BLOCK**fs== 9.5**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n1) LocationPrivacy: No participant can determine the ex-\nact positions of EVs in real time. This ensures that the\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nFigure 1: IOTA-based V2G network energy trading process\n**BLOCK**fs== 9.5**p== 4.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nlocation privacy of EVs is protected, preventing any po-\ntential tracking or profiling based on their movements.\n2) SchedulePrivacy: The privacy of EVs and their charg-\nthe\ning schedules must be maintained throughout\ncharging process. This safeguards the confidentiality of\ntheir charging patterns, which could otherwise reveal\nsensitive information about EV owners’ habits and rou-\ntines.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nIn the DLT, each participant (i.e., the EV or grid) uses\nthe system-provided unique anonymous ID ζ. The map-\nping between the participant’s ID and its true identity is\nknown only to the system. Hence, the true identity of each\nparticipant is unknown to other participants. Nevertheless,\ndeanonymization of participants is possible by relating keys\nand transactions [26]. The ID ζ changes for every request\nto mitigate the deanonymization problem by creating a new\npair of keys to enhance EVs’ privacy. We assume that the\ngrid list and positions are known publicly. Figure 1 shows an\noverview of the V2G energy trading process. The protocol\nconsists of four phases, as described below.\n**BLOCK**fs== 9.5**p== 4.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n4.3.1 Bidding phase\n**BLOCK**fs== 9.5**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIn the bidding phase, EVs place the ESO with a unique\nidentity to the grid in an immutable and public way with\na deposit. The ESO’s public nature incentivizes other dis-\ncharging EVs to keep their prices competitive. The ESOs\ncontain the energy amount e ∈ Q+, at time slot t ∈ T ,\ngeographic region r ∈ R, and selling price p. The region\nshould be chosen broadly so that the privacy of EVs is\nprotected but within EVs’ feasible range. No one participant\nfinds out anything beyond ESO(e, t, r, p,) and the ID ζ.\nGiven (e, t, r, p,), no participant can determine the exact\nlocations of EVs because the different ESOs are disconnected\nfrom others. The selling offers cannot be directly related to\nthe specific discharging vehicle because only the ID ζ of\n**BLOCK**fs== 9.5**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ndischarging EVs is shown with the ESO (without identifying\nthe exact position of the EV). Once the ESOs are submitted to\nthe ledger, they are visible to all the grids and all discharging\nEVs.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\n4.3.2 Evaluation phase\n**BLOCK**fs== 9.5**p== 5.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nIn the evaluation phase, the grids assess the discharging\nEVs’ ESOs based on their distance, energy supply, and price.\nThe grid finds the optimum discharging EVs according to\nthe total energy price. In the case of many demands from\nthe grids to discharge EVs, the EVs select among them\nuniformly. EVs use a non-cooperative game (NCG) strategy\nto update their prices to enhance their selection probability.\nGrids privately decide on the bid in an off-IOTA manner.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n4.3.3 Negotiation phase\n**BLOCK**fs== 9.5**p== 5.0**b== 0.4**t== 0.3**l== 0.1**r== 0.5**\nIn the negotiation phase, the grid communicates with dis-\ncharging EVs to set the energy price off-IOTA. When both\nagree on the price, then the agreed transaction is submitted\nto the IOTA ledger. The ESO of discharging EVs contain\n(e, t, r, p), and the grids i check their positions and other pa-\nrameters discussed in the evaluation phase to find appropri-\nate discharging EVs. When appropriate discharging EVs are\nfound, grids create their bids based on NCG bi = f (e, t, p).\nThis function shows that grid i desires to purchase energy e\nfrom EV ζ in the given time slot for bi ≤ bj, j = 1, ..., N . If\nthe discharging EV agrees on the given grid’s bid bi, then the\ntransaction is written in the IOTA ledger. The negotiation\nprocess continues until price convergence or a set time limit.\nThe grid may accept EV bids immediately or update prices.\nUpon agreement, the final price is determined. Once the\nEV and grid have agreed on the appropriate price, the grid\nbinds the commitment computationally c = H(ζ,¯i, rn) by\ncombining the index of grid i and ID of EV ζ and freshly\ncreating a random number for it. The binding commitment\nis sent to the IOTA ledger.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\n4.3.4 Charging phase\n**BLOCK**fs== 9.5**p== 5.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nThe transaction is executed directly between the grid and\nEV in the charging phase. The phase opens the commitment\nby sending ζ, ¯i, and rn to verify the selected grid. The\ngrid checks the commitment and verifies H(ζ,¯i, rn) = c\nand verifies whether the time of the transaction matches the\ncommitment time. Energy e is exchanged on commitment\nprice bi in the given time slot t. This commitment transaction\nis only performed between the selected grid and EV. The\ndischarging EV’s actual position is shown to the selected\ngrid at this stage. However, this commitment information\nis not shown to the IOTA network. In the process of open\ncommitment, EV reveals the ID ζ, and no other EV has the\nsame identity due to using a cryptographic hash function\nfor the commitment binding. As such, the grid proves that\nit communicates with the valid discharging EVs. After the\ncharging phase is complete, a new ID is assigned to each\ndischarging EV.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n5 GAME MODEL OF THE V2G NETWORK\nThis section presents the hierarchical game model governing\nenergy trading dynamics in the V2G system. EVs act as\nsellers, while smart grids serve as buyers. The hierarchy\n**BLOCK**fs== 9.5**p== 5.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nstarts with a non-cooperative game (NCG), representing\nEVs competing to sell power at optimal prices to the grid.\nEVs equipped with solar panels negotiate with smart grids\nthroughout the day. EVs strategically adjust their selling\nprices based on energy generation and battery levels, while\ngrids dynamically adjust purchase prices based on predicted\nconsumption patterns. Next, a Stackelberg game (SG) cap-\ntures the interaction between EVs and grids. Here, EVs\nalternate between leading and following roles, influencing\nmarket dynamics with surplus energy. For instance, an EV\nmay lead by strategically withholding energy during peak\ndemand, prompting grids to offer better purchase terms.\nFinally, another NCG governs grid interactions, with oper-\nators adapting strategies to optimize profit while ensuring\nenergy supply meets demand.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\n5.1 EVs employ NCG to make more profit\n**BLOCK**fs== 9.5**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nThe EVs employ NCG because they compete in a non-\ncooperative way with each other to make more profit by\nselling energy at the best price to the grid. When the grid’s\ndemand is greater than or equal to EV i’s supply, EV i’s\nutility is calculated by\nui(Et\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\ni,sell, ¯ωt\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.4**l== 0.8**r== 0.2**\ni,sell ¯ωt\ni.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nWhen the grid’s demand is less than the supply, EV i’s utility\nis calculated by\n**BLOCK**fs== 7.0**p== 5.0**b== 0.5**t== 0.5**l== 0.7**r== 0.3**\ni,sell, ¯ωt\n**BLOCK**fs== 7.0**p== 5.0**b== 0.5**t== 0.5**l== 0.8**r== 0.2**\ni,buy ¯ωt\ni.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nNash equilibrium is a notion in game theory that identifies\nthe best solution in an NGC, where participants have no\nincentive to change their initial approach. Under the Nash\nEquilibrium, a player gains nothing by departing from their\ninitial plan, assuming the other players’ strategies remain\nunchanged. There may be several Nash equilibria in a game\nor none at all.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.1**t== 0.6**l== 0.5**r== 0.1**\nThe Nash equilibrium is attained when each EV sells\nits total surplus energy, which is the goal of the proposed\nalgorithm. A predefined set of conditions is in place to\nachieve this equilibrium point in NCG. One necessary con-\ndition is that a finite number of players must be satisfied by\nhaving X EVs participating. The game continues until the\ngrid demand, denoted as Ψt\ny,buy is fully satisfied or all the\nsurplus energy from the discharging EVs has been sold. The\nalgorithm facilitates this equilibrium by allowing each EV\nto decide how much extra energy to deal with, optimizing\ntheir utility or profit. The surplus energy is then allocated\nto the grid, ensuring demand is met while respecting the\nindividual decisions of the EVs. The algorithm checks if no\nEV can unilaterally change its decision to increase its profit,\nindicating the achievement of Nash equilibrium. The game\nterminates when the grid demand is met, or all surplus\nenergy is sold, representing a stable equilibrium state. A\ndischarging EV i uses the following strategy to adjust its\nsupply to maximize its selection probability\n**BLOCK**fs== 7.0**p== 5.0**b== 0.1**t== 0.9**l== 0.7**r== 0.3**\ny,buy–Et\n**BLOCK**fs== 9.5**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nA discharging EV i uses the following strategy to update its\nprices to maximize selection probability\n**BLOCK**fs== 9.5**p== 6.0**b== 0.6**t== 0.1**l== 0.1**r== 0.5**\nwhere n represents the number of iterations. The NCG game\nis defined by the tuple Γ = ⟨X t, Ωt, pt, ⟨Ai, ui, T t\ni ⟩i∈N ⟩,\nwhere X t represents the set of EVs at time slot t, s.t. xt ∈ X t,\nΩt represents the condition of the weather at time slot t,\nAt\ni ) is the set of actions available for EV i at time\nslot t, where At\nN , Ti is the set of types\nfor EV i according to the condition of the weather or the\ncurrent state of the EV. Given the condition of the weather,\nthe type of EV i is given by the function τi : Ω → Ti [27].\nTherefore, according to the weather condition, the game\nwill have different types of EVs. The payoff function for\nEV i is defined by ui : Ti × A → R, and p is the probability\ndistribution for the weather condition Ω. A mixed strategy\nfor EVs i is a function xi : Ti → ∆Ai, where ∆Ai is the set\nof all probability distributions on Ai. Note that a strategy\ndepends only on its type of EVs. A strategy profile x\nrepresents the strategy for each EV. The strategy profile finds\nout the expected payoffs for each EV, where the expectation\nis taken based on both the weather condition and EV types\nin terms of beliefs p, and the randomization over actions\nimplied by any mixed strategies in the profile x.\n**BLOCK**fs== 9.5**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nGiven a game ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, the profile of the\nmixed strategy (xi)i∈N is called the Nash equilibrium of the\nmixed strategy if ∀i ∈ N\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\nui(xi, x−i) ≥ ui(x′\nxi,sell and St\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nxj ,sell and St\n**BLOCK**fs== 9.5**p== 6.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nxi,price be the supply and enforced\nprice of EV i at time slot t with choosing probabilities\nxi1 and xi2. Let Et\nxj ,price be the supply and\nenforced price of EV j at time slot t with choosing prob-\nabilities xj1 and xj2. We use the mixed strategy due to\nthe intermittent nature of supply. Besides, when the player\nuses the same choices every time, then other players will\ntrack these choices. This will create a privacy problem for\nEVs and also create the problem of using these choices to\nmaximize its selection probability at time slot t. Hence, here\nwe use the mixed strategy for the selection probability for\nEVs at time slot t. We use an arithmetic method to achieve\nthe optimal strategy and value of the game at time slot t.\nLet EV i’s mixed strategy at time slot t be (xi1, xi2), where\nxi1 + xi2 = 1.\n**BLOCK**fs== 9.5**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\n5.1.1 Case Study\nThe net expected gain E1, at time slot t of EV i is\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nE1(EV i) = [xi1xj1]xi1 + [xi2xj1]xi2,\n**BLOCK**fs== 9.5**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.6**\nwhen EV j increases the supply at time slot t.\nThe net expected gain E2, at time slot t of EV i is\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nE2(EV i) = [xi1xj2]xi1 + [xi2xj2]xi2,\n**BLOCK**fs== 9.5**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nwhen EV j decreases the price at time slot t. So for EV i,\nwe have to find the supply and its enforced price at time\nslot t and value v of the game that satisfy the following\nrelationships\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.2**r== 0.6**\n[xi1xj1]xi1 + [xi2xj1]xi2 ≥ v\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.2**r== 0.6**\n[xi1xj2]xi1 + [xi2xj2]xi2 ≥ v\n**BLOCK**fs== 9.5**p== 6.0**b== 0.9**t== 0.1**l== 0.5**r== 0.1**\nThe inequalities become strict equations for the optimum\nstrategies.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.6**r== 0.2**\n[xi1xj1]xi1 + [xi2xj1]xi2 = v\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\n[xi1xj2]xi1 + [xi2xj2]xi2 = v\n**BLOCK**fs== 9.5**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nFrom (23a) − (23b), we get\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.2**l== 0.7**r== 0.2**\n(xi2xj2 − xi2xj1)\n(xi1xj1 − xi1xj2)\n**BLOCK**fs== 9.5**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nPlugging this value into (22c) to get the optimal price\nstrategy at time slot t we get\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.6**r== 0.2**\n(xi2xj2 − xi2xj1)\n(xi1xj1 − xi1xj2)\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\n(xi1xj1 − xi1xj2)\n(xi2xj2 − xi2xj1) + (xi1xj1 − xi1xj2)\n**BLOCK**fs== 9.5**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nFrom (24a), we get\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\n(xi2xj2 − xi2xj1)\n(xi2xj2 − xi2xj1) + (xi1xj1 − xi1xj2)\n**BLOCK**fs== 9.5**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nPlugging xi1 and xi2 into (23a), we get the Nash equilib-\nrium or value of the game, as follows:\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\n(xi1xj1)(xi2xj1) − (xi1xj1xi2xj1)\n(xi2xj2 − x2xj1) + (xi1xj1 − xi1xj2)\n**BLOCK**fs== 9.5**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.3**\n5.2 Stackelberg Game (SG)\n**BLOCK**fs== 9.5**p== 6.0**b== 0.1**t== 0.6**l== 0.5**r== 0.1**\nA Stackelberg Game (SG) models the relationship between\nthe EVs acting as leaders and the microgrids acting as\nfollowers [7]. Enhances the Stackelberg game method for en-\nergy trading by introducing novel features like microtrans-\nactions and optimized decision-making. Leveraging IOTA’s\nplatform ensures secure, decentralized trading focusing on\ndata privacy. These innovations demonstrate the originality\nand significance of our work in advancing energy trading\nmethodologies. In the SG, EVs declare their available energy\nand price range for the specific time slot, and grids use the\nNCG to select a suitable EV. EVs use NCG to maximize\ntheir selection probability to update prices and adjust their\nsupply according to demand based on the NCG output. EVs\nuse NCG because they are unfamiliar with each other. The\ndouble auction algorithm achieves the Nash equilibrium in\nSG. The EVs update their prices by using the strategy in\n(18). The EVs adjust their supply utilizing the strategy in\n(17), and the grids use the NCG to select the best discharging\nEV. The energy price is the input for EVs’ NCG and grids’\nNCG. The EVs’ NCG output is the best-selling energy price,\nwhich is further used as input for the grids’ NCG, and the\ngrids’ NCG output is the best discharging EV selection. The\nSG establishes a connection between EVs’ NCG and grids’\nNCG. EVs use the best energy supply and its price according\nto (24c) and (25) to maximize their selection probability at\ntime slot t with suitable gain. Grids use (50c) and (50b) to\nselect the best suitable EV at time slot t with appropriate\ngain.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nThe grids’ utility sum is the social welfare (SW) of V2G\n**BLOCK**fs== 9.5**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.8**\nenergy trading:\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.3**r== 0.7**\narg max\nwt\ny\n**BLOCK**fs== 9.5**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nWhere Y is the number of grids. The grids’ and EVs’ total\nprofit from V2G energy trading is calculated by\n**BLOCK**fs== 9.5**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\ndefined\n**BLOCK**fs== 9.5**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.8**\ntime slot\n**BLOCK**fs== 9.5**p== 7.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\ntime slot\n**BLOCK**fs== 9.5**p== 7.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\nby\nwhere\n**BLOCK**fs== 9.5**p== 7.0**b== 0.3**t== 0.3**l== 0.1**r== 0.5**\nWhere X is the number of EVs, TB represents the total profit\nof grids and EVs and pt\nx represents the discharging EVs’\nreceived payment.\ntuple\nproposed\nΓ = ⟨XY t, Ωt, pt, ⟨Ai, ui, T t\nXY t\nt,\nrepresents the set of grids and EVs at\nwhere xyt ∈ XY t, Ωt represents the condition of the\npi) is the set of\nweather at\nactions available for EVs and grids i at time slot t, where\nAt\nN , Ti is the set of types for grids\nand EVs i according to the condition of the weather or the\ncurrent state of the EVs and grids. Given the condition\nof the weather, the type of EVs and grids i is given by\nthe function τi : Ω → Ti. Hence, according to the weather\ncondition, the game will have different types of EVs and\ngrids, and the payoff function for EVs and grids i is defined\nby ui : Ti × A → R. A mixed strategy for EVs and grids\ni is a function σi : Ti → ∆Ai, where ∆Ai\nis the set of\nall probability distributions on Ai. Note that a strategy\ndepends only on its own type of EVs and grids. A strategy\nprofile σ represents the strategy for each EV and grid.\nThe strategy profile finds out the expected payoffs for\neach EV and grid, where the expectation is taken based\non both the weather conditions and EV and grid types\nin terms of beliefs p, and the randomization over actions\nimplied by any mixed strategies in the profile σ. Given a\ngame ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, profile of the mixed strategy\n(σi)i∈N is called Nash equilibrium of the mixed strategy if\n∀i∈N\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nui(σi, σ−i) ≥ ui(σ′\n**BLOCK**fs== 9.5**p== 7.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nn Vn). Let Et\n**BLOCK**fs== 9.5**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nLet the Bayes-Nash equilibrium be given by the strategy\nprofile ( n−1\nyj ,price be the\ndemand and demand price of Gridsj at time slot t according\nto 1\nxi,price) be the discharging EV’s\noffers at time slot t. EV i wins when V2 ≤ 2S1 and utility\ngains V1 − S1, EVi loses when when V2 > 2S1 and gets\nutility 0.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\n2 V . Let S1 = (Et\n**BLOCK**fs== 7.0**p== 7.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nyj ,buy and Et\n**BLOCK**fs== 7.0**p== 7.0**b== 0.2**t== 0.7**l== 0.2**r== 0.7**\nxi,sell, St\n**BLOCK**fs== 9.5**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n2s1\nE[ui] = 2S1V1 − 2(S1)2\nNow we find the best response for EV i at time slot t to\ngrids by taking the partial derivatives of the expected utility\nof EV i at time slot t and setting it to zero.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nThus, when a grid’s energy demand and energy demand\nprice is half of its valuation, EV i’s best response is to offer\nthe energy at half its valuation.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.2**\n5.3 Suitable EV selection by using NCG\n**BLOCK**fs== 9.5**p== 7.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nThe best discharging EV selection is made by using the\nNCG. The focus of NCG is on the dynamic strategy. Here we\nuse NCG to resolve the competition among the grid. NCG\nis used because the grids’ strategies change dynamically to\nobtain a higher profit.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThe NCG model group y ∈ Y consists of buyers, which\nare smart grids. When the EVs submit prices to the IOTA\nledger, each grid for energy purchasing chooses the best\npossible EV. The grids select the EV independently, and the\ngrid selection strategy is adjusted progressively. mt\np denotes\nthe probability of grid y ∈ Y choosing the EV x ∈ X in the\ntth time slot. The following equation is used to calculate the\nsupply-to-demand ratio of EV x ∈ X at time slot t:\n**BLOCK**fs== 9.5**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nIf ry,x is greater than or equal to 1, then the grid’s true\nvalue to select the suitable EV at time t to buy energy from\nthe discharging EV is as follows:\n**BLOCK**fs== 7.0**p== 7.0**b== 0.4**t== 0.5**l== 0.6**r== 0.3**\n∂Ψt\ntrue\n∂t\n**BLOCK**fs== 7.0**p== 7.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\ny,buy)St\n**BLOCK**fs== 7.0**p== 7.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nx,price + ωt\nx,\n**BLOCK**fs== 9.5**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nwhere the distance price of EV x at time slot t is calculated\nby\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nx = (CKx)(Rt\nωt\n**BLOCK**fs== 7.0**p== 7.0**b== 0.4**t== 0.6**l== 0.8**r== 0.2**\nx,price).\n**BLOCK**fs== 9.5**p== 7.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nHere, ωt\nx represents the total distance price for EV x, CKx\nrepresents the energy consumption per kilometer of EV x,\nRt\nx,k represents the discharging EV’s total distance range\nat time slot t. St\nx,price represents the enforced price of the\ndischarging EV at time slot t.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nIf ry,x is lower than 1, then the grid’s true value to\nselect the suitable EV at time slot t to buy energy from the\ndischarging EV is as follows:\n**BLOCK**fs== 7.0**p== 7.0**b== 0.2**t== 0.7**l== 0.6**r== 0.3**\n∂Ψt\nl,true\n∂t\n**BLOCK**fs== 7.0**p== 7.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\nx,less)(St\n**BLOCK**fs== 7.0**p== 7.0**b== 0.3**t== 0.7**l== 0.8**r== 0.2**\nx,price) + Ψt\n**BLOCK**fs== 7.0**p== 7.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\nx,less = Ψt\n**BLOCK**fs== 7.0**p== 7.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\ny,buy − Et\n**BLOCK**fs== 9.5**p== 7.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nwhere Et\nx,less represents how much the discharging EV’s\nenergy is less than grid demand.Grid prioritizes price or\nsupply. For each (≥ or < demand), grid selects closest,\ncheapest EV at time t.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nLet EV1 represent the first group’s best discharging EV,\nwhose energy supply is greater than or equal to the grid\ndemand, and EV2 represents the second group’s best EV,\nwhose energy supply is less than the grid demand. The grid\ncompares the prices of these two EVs EV1 and EV2. If both\nEVs’ prices are equal, then the grid selects the EV of the\nfirst group, which is EV1 because it fulfills the grid’s energy\n**BLOCK**fs== 9.5**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ndemand at time t in every aspect. It should be noted that\nthe first group’s and second group’s prices are calculated\nusing (36) and (38), respectively. Another method is the\naverage utility method, which the grids use to find the best\ndischarging EV at time slot t. Ψt\ntrue is the net utility of a\nspecific discharging EV for grids in which the energy supply\nis greater than or equal to the power demand. The average\nutility at time slot t is calculated by\n**BLOCK**fs== 7.0**p== 8.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\nx,sell and St\n**BLOCK**fs== 9.5**p== 8.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\ndemand, and EVn represents the second group’s best EV,\nwhose energy supply is less than the grid demand. Let\nEt\nx,price be the supply and enforced price of\nEVx at time slot t. The grid selects the EVs according to the\nbest-fit price and supply at time slot t. Let grid yj’s mixed\nstrategy at time slot t be (yj1, yj2), where yj1 + yj2 = 1. Let\ngrid yi’s mixed strategy at time slot t be (yi1, yi2), where\nyi1 + yi2 = 1, to select the best discharging EV at time slot\nt. The net expected gain E1, at time slot t of yi is\n**BLOCK**fs== 7.0**p== 8.0**b== 0.7**t== 0.2**l== 0.3**r== 0.7**\nx=1 Ψt\nηt\nx,g1\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\nE1(yi) = [yi1yj1]yi1 + [yi2yj1]yi2,\n**BLOCK**fs== 9.5**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nΨt\nl,true is the net utility of the specific discharging EV l for\ngrids whose energy supply is less than the power demand\n**BLOCK**fs== 9.5**p== 8.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\naccording to the supply of EVj at time slot t. The net\nexpected gain E2 at time slot t of yi is\n**BLOCK**fs== 7.0**p== 8.0**b== 0.6**t== 0.3**l== 0.3**r== 0.7**\nl=1 Ψt\nηt\nx,g2\nU t\na1\nU t\na2\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nE2(yi) = [yi1xj2]yi1 + [yi2yj2]yi2,\n**BLOCK**fs== 9.5**p== 8.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\naccording to the price of EVj at time slot t. So for yi, we have\nto find the best demand price of energy at time slot t and the\nvalue of the game that satisfy the following relationships\n**BLOCK**fs== 9.5**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nIf the average utility ratio is less than 1, then the first group\nis better for searching for the best EV. If the average utility\nratio is greater than 1, then the second group is better for\nsearching for the best EV.\n**BLOCK**fs== 9.5**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nThe utility of the grids is calculated as follows\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nUn = arg max\n**BLOCK**fs== 9.5**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nThe grids’ NCG solution is represented as follows\n4 , ...., EV t∗\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nEV t∗ = {EV t∗\n**BLOCK**fs== 9.5**p== 8.0**b== 0.1**t== 0.5**l== 0.1**r== 0.5**\nAlgorithm 1 shows the detailed process of the grids’ NCG.\ndefined\ntuple\nNCG\nΓ = ⟨N t, Ωt, pt, ⟨Ai, ui, T t\ni ⟩i∈N ⟩, where N t represents\nthe set of grids at time slot t, where nt ∈ N t, Ωt represents\nthe condition of the weather at time slot t, At\npi)\nis the set of actions available for grids i at time slot t,\nwhere At\nis the set of types\nfor grids i according to the condition of the weather\nor the current state of the grids. Given the condition of\nthe weather, the type of grids i is given by the function\nτi : Ω → Ti [27]. So, according to the weather condition,\nthe game will have different types of grids; the payoff\nfunction for grids i is defined by ui : Ti × A → R, p is\nthe probability distribution for the weather condition Ω.\nA mixed strategy for grids i is a function yi : Ti → ∆Ai,\nwhere ∆Ai is the set of all probability distributions on\nAi. Note that a strategy depends only on its own type\nof the grid. A strategy profile y represents the strategy\nfor each grid. The strategy profile finds out the expected\npayoffs for each grid, where the expectation is taken on\nthe basis of both the weather condition and grids’ types\nin terms of beliefs p, and the randomization over actions\nimplied by any mixed strategies in the profile y. Given a\ngame ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, profile of the mixed strategy\n(yi)i∈N is called Nash equilibrium of the mixed strategy if\n∀i∈N\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\n[yi1yj1]yi1 + [yi2yj1]yi2 ≥ v\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\n[yi1yj2]yi1 + [yi2yj2]yi2 ≥ v\n**BLOCK**fs== 9.5**p== 8.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nThe inequalities become strict equations for the optimum\nstrategies.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\n[yi1yj1]yi1 + [yi2yj1]yi2 = v\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\n[yi1yj2]yi1 + [yi2yj2]yi2 = v\n**BLOCK**fs== 9.5**p== 8.0**b== 0.4**t== 0.5**l== 0.5**r== 0.3**\nFrom (49a) − (49b), we get\n**BLOCK**fs== 7.0**p== 8.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\n(yi2yj2 − yi2yj1)\n(yi1yj1 − yi1yj2)\n**BLOCK**fs== 9.5**p== 8.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nPlugging this value into (48c) to get the optimal price at\ntime slot t:\n**BLOCK**fs== 7.0**p== 8.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\n(yi2yj2 − yi2yj1)\n(yi1yj1 − yi1yj2)\n**BLOCK**fs== 7.0**p== 8.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\n(yi1yj1 − yi1yj2)\n(yi2yj2 − yi2yj1) + (yi1yj1 − yi1yj2)\n**BLOCK**fs== 9.5**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\nFrom (50a), we get\n**BLOCK**fs== 7.0**p== 8.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\n(yi2yj2 − yi2yj1)\n(yi2yj2 − yi2yj1) + (yi1yj1 − yi1yj2)\n**BLOCK**fs== 9.5**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nAfter substituting yi1 and yi2 in (49a), we get the value of\nthe game:\n**BLOCK**fs== 7.0**p== 8.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\n(yi1yj1)(yi2yj1) − (yi1yj1yi2yj1)\n(yi2yj2 − yi2yj1) + (yi1yj1 − yi1yj2)\n**BLOCK**fs== 8.8**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.3**\n6 EVALUATION\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nui(yi, y−i) ≥ ui(y′\n**BLOCK**fs== 9.5**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nLet EVm represent the first group’s best discharging EV,\nwhose energy supply is equal to or larger than the grid\n**BLOCK**fs== 9.5**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIn this section, we perform a performance evaluation of the\nproposed scheme based on simulation experiments, which\nincludes a comparison with a blockchain-based approach,\nfollowed by a security analysis of the proposed approach.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nAlgorithm 1 Algorithmic implementation of grids’ NCG\nInput: ESOs from EVs ESOt\n3, ..., ESOt\nx\nOutput: Grids’ NCG equilibrium state EV t∗\n4 , ...., EV t∗\n3 , EV t∗\nX }\nx into two groups\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\n{EV t∗\n2 , EV t∗\n1 , EV t∗\n(1) Divide all ESOt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\ni = i+1;\nfor all x ∈ X do\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.2**l== 0.1**r== 0.8**\n1: i=0;\n2: repeat\n3:\n4:\n5:\n6:\n7:\n8:\n9:\n10:\nend for\n11:\n12: until ESOt\nx\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.2**l== 0.2**r== 0.6**\nCalculate ry,x according to (35)\nif ry,x(i) ≥ 1 then\nCalculate Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\ntrue according to (36)\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nelse if ry,x(i) < 1 then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nCalculate Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nl,true according to (38)\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\n(2) Compare the average utility of both groups\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nSearch best EV in the first group\n**BLOCK**fs== 9.5**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\n13: Calculate Ua,r according to (42)\n14: if Ua,r < 1 then\n15:\n16: else if Ua,r > 1 then\n17:\n18: end if\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nSearch best EV in the second group\n**BLOCK**fs== 9.5**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\n(3) Selection of best EV from the first group\na1 according to (40)\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\nj = j + 1;\nfor all Ψt\nif U t\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.5**l== 0.1**r== 0.8**\n19: Calculate U t\nj = 0;\n20:\n21: repeat\n22:\n23:\n24:\n25:\n26:\n27:\n28:\n29:\n30:\n31:\n32:\n33:\n34: until Ψt∗\n**BLOCK**fs== 9.5**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nend for\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\n35: Calculate U t\n36: k = 0;\n37: repeat\n38:\n39:\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\nk = k + 1;\nfor all Ψt\nif U t\n**BLOCK**fs== 7.0**p== 9.0**b== 0.4**t== 0.5**l== 0.2**r== 0.7**\ntrue(j) do\na1 > Ψt\nif Ψt\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.5**l== 0.2**r== 0.7**\ntrue(j) then\ntrue(j − 1) < Ψt\nSelect Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.8**\nelse if Ψt\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\ntrue(j − 1)\ntrue(j − 1) > Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nSelect Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.8**\nend if\nelse if U t\n**BLOCK**fs== 7.0**p== 9.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\ntrue(j) then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nNeglect Ψt\n**BLOCK**fs== 7.0**p== 9.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\ntrue(j) then\n**BLOCK**fs== 7.0**p== 9.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\ntrue(j) then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\n(4) Selection of best EV from the second group\n**BLOCK**fs== 9.5**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\na2 according to (41)\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nl,true(k) do\na2 > Ψt\nif ( thenΨt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nSelect Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.8**\nelse if Ψt\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nl,true(k) then\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nl,true(k − 1) < Ψt\nl,true(k − 1)\nl,true(k − 1) > Ψt\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nSelect Ψt\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\nl,true(k)\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\nl,true(k))\n**BLOCK**fs== 7.0**p== 9.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\nl,true(k) then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.1**t== 0.8**l== 0.2**r== 0.8**\nend if\nelse if U t\n**BLOCK**fs== 7.0**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\nl,true(k) then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nNeglect Ψt\n**BLOCK**fs== 7.0**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nl,true(k)\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\n47:\n48:\n49:\n50: until Ψt∗\n**BLOCK**fs== 9.5**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nend for\n**BLOCK**fs== 7.0**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\nl,true(k)\n**BLOCK**fs== 7.0**p== 9.0**b== 0.9**t== 0.1**l== 0.7**r== 0.2**\nl,true(k) then\n**BLOCK**fs== 7.0**p== 9.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\ntrue(j) < Ψt∗\nSelect Ψt∗\ntrue(j)\ntrue(j) == Ψt∗\ntrue(j)\ntrue(j) > Ψt∗\nl,true(k)\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\n51: if Ψt∗\n52:\n53: else if Ψt∗\n54:\n55: else if Ψt∗\n56:\n57: end if\n**BLOCK**fs== 9.5**p== 9.0**b== 0.8**t== 0.2**l== 0.6**r== 0.4**\nSelect Ψt∗\n**BLOCK**fs== 9.5**p== 9.0**b== 0.8**t== 0.2**l== 0.6**r== 0.4**\nSelect Ψt∗\n**BLOCK**fs== 7.0**p== 9.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nl,true(k) then\n**BLOCK**fs== 7.0**p== 9.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nl,true(k) then\n**BLOCK**fs== 9.5**p== 9.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nAlgorithm 2 Algorithmic implementation of SG\nInput: Initialize ESOt\n3, ..., ESOt\nx\nOutput: Nash equilibrium in SG\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.3**l== 0.5**r== 0.3**\n1: for all y ∈ Y do\nm=0;\n2:\nrepeat\n3:\n4:\n5:\n6:\n7:\n8:\n9: end for\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nuntil (St\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\nm = s+1;\nCalculate Ψt\nExecute algorithm 1\nEVs update ESO prices according to (18)\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.3**l== 0.7**r== 0.2**\ny,buy according to (14)\n**BLOCK**fs== 7.0**p== 9.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nx,price(m + 1)–St\n**BLOCK**fs== 7.0**p== 9.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\nx,price(m)) > 0\n**BLOCK**fs== 9.5**p== 9.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\n6.1 Performance Evaluation\n**BLOCK**fs== 9.5**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nThis section encompasses the overall strategy and tools used\nto evaluate the performance of the proposed V2G energy\ntrading model. It includes the setup of the simulation envi-\nronment, the categorization of EVs, and the consideration of\nvarious factors, such as the EVs’ distance from the grid and\ntheir energy supply capabilities.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.5**l== 0.5**r== 0.4**\n6.1.1 Metrics\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nThe proposed V2G energy trading model is evaluated based\non several critical performance indicators. These metrics are:\n**BLOCK**fs== 9.5**p== 9.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n• Transaction Efficiency: The ability of the system\nto handle energy trades swiftly and with minimal\noverhead.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n• EV Selection: System can select the best EVs for\ntransactions based on their energy supply and the\ndistance price, which reflects the EVs’ location rela-\ntive to the grid.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n• Distance Price Consideration:How the distance of\nan EV from the grid affects the pricing and selection\nin the energy trade.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n• Microtransaction Capability:The system’s function-\nality supports small-scale transactions efficiently.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nThese metrics are designed to ensure that the model not\nonly fosters competitive behavior among participants but\nalso maximizes the welfare of the V2G network by balancing\nthe revenues of EVs with the costs incurred by the grids.\n**BLOCK**fs== 9.5**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n6.1.2 Benchmark Approaches\n**BLOCK**fs== 9.5**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nFor a comprehensive assessment, the performance of the\nproposed V2G energy trading model was benchmarked\nagainst three other systems:\n**BLOCK**fs== 9.5**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n1) DV2G: A contemporary V2G energy trading model em-\nploying DAG for transactions, referenced in [1]. This\nmodel serves as a benchmark for transaction efficiency\nand microtransaction support.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\n2) Blockchain-Based Approach: A traditional approach\nto V2G energy trading that is grounded in blockchain\ntechnology, as detailed in [28].This approach provides\na baseline for evaluating the enhancements our model\nbrings to the V2G energy trading landscape.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n3) Peer-to-peer Energy Trading: Designing Fairness in\nAutonomous Peer-to-peer Energy Trading [29] provides\na foundational benchmark for fairness in V2G systems.\nOur IOTA-based algorithm, in comparison, excels in\ntransaction efficiency and scalability, significantly en-\nhancing the V2G energy trading landscape.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n4) Hierarchical Game-Theoretic Framework: Designing\nFairness in Real-Time Energy Trading in Smart Grids\n[30], a seminal work in fairness evaluation for energy\ntrading. Our IOTA-based algorithm,\nin comparison,\nexcels in transaction efficiency and scalability, signifi-\ncantly enhancing the V2G energy trading landscape.\n5) EV Aggregator Liability Model:Electric Vehicle Aggre-\ngators to Grid Liability Trading [31], a seminal work\nin fairness evaluation for energy trading. Our IOTA-\nbased algorithm, in comparison, excels in transaction\nefficiency and scalability, significantly enhancing the\nV2G energy trading landscape.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nThe benchmarking process involves directly comparing\nsystems based on transactional throughput, EV selection\nefficiency, and overall V2G network welfare impact. Our\nproposed V2G energy trading model aims to increase par-\nticipant engagement to maximize network welfare. This\nentails maximizing EV revenue, minimizing grid costs, and\nfostering healthy competition among EVs and grids\n**BLOCK**fs== 9.5**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\n6.1.3 Results\n**BLOCK**fs== 9.5**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nIn the next section,we’ll discuss our simulation results, fo-\ncusing on key parameters like energy efficiency, transaction\nspeed, security, privacy, and scalability to evaluate our pro-\nposed methodology.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n6.1.3.1 Parameter Values for Grid Selection:\n**BLOCK**fs== 9.5**p== 10.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nFigure 2 and Figure 3 show the parameter values for\nthe first and second groups of EVs, respectively, used by\nthe grid to select the appropriate EV to buy energy from.\nThese figures present the EV supply, grid demand, supply-\ndemand ratio, kWh, distance, distance price, and total price\nof the six EVs in each group. The grid aims to find the\nEV that provides the lowest price based on the unit price,\nproximity, and energy supply. The best value for the grid\nis the lowest accumulative price of energy-selling EVs. The\ngraphs show that the grid finds the best EVs in both groups\nseparately (EV2 in Figure 2 and EV6 in Figure 3) and com-\npares these best-discharging EVs based on the total energy\nsupply price. If the prices of both EVs are equal, then the\ngrid selects the EV of the first group because it fulfills the\ngrid demand at time slot t. In Figure 2 and Figure 3, the\ndistance and distance price parameters reflect the location\nof each EV relative to the grid. The graphs indicate that if\nan EV is closer to the grid, its distance reward will be lower\nthan when it is far away. This suggests that the grid prior-\nitizes selecting EVs closer to the grid to minimize energy\ntransportation costs. The supply-demand ratio parameter\nreflects the balance between the energy supply and demand\nin the grid. The graphs show that the grid selects the EVs\n**BLOCK**fs== 9.5**p== 10.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nthat can provide energy to the grid based on the supply-\ndemand ratio. The kWh and total price parameters reflect\nthe energy supply and price of each EV. The graphs suggest\nthat the grid prioritizes selecting the EVs that can provide\nenergy at a lower price to the grid to minimize energy costs.\nFigure 2 and Figure 3 provide important information about\nthe parameters used by the grid to select the appropriate EV\nto buy energy from and the best value for the grid, which is\nthe lowest accumulative price of energy-selling EVs. These\nfigures can help inform decisions about the management\nof EVs in the grid and to optimize their utilization in the\nenergy system. If the prices of both EVs are equal, then the\ngrid selects the EV of the first group because it fulfills the\ngrid demand at time slot t\n**BLOCK**fs== 9.5**p== 10.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\n6.1.3.2 EV Pricing and Utility Analysis:\n**BLOCK**fs== 9.5**p== 10.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nFigure 4 shows the price comparison of the first group’s\ntotal energy prices of EVs with the average net utility of\nEVs and Figure 5 shows the price comparison of the second\ngroup’s total energy prices of EVs with the average net\nutility of EVs. In the figures, the blue bars indicate the\naverage net utility and the red bars show the EVs whose\nenergy prices are greater than the average net utility. The\ngray bars indicate the EVs whose prices are lower than the\naverage net utility. The green bars show the best EV, i.e., the\nEV with the lowest price at time slot t. In this case, as the\nbest prices in both groups are equal, EV2 in the first group\nis chosen by the grid.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nFigure 6 shows iterations and NCG convergence. The\ngraph shows that EVs change their energy price with the\niterations and reach a stable state, where they achieve\nmaximum utility. The EVs change their prices to increase\nthe selection probability that is given by the grid to EVs.\nThe noncooperative game among the EVs begins for energy\ntrading when the grid assigns selection probabilities to the\nEVs.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n6.1.3.3 Transaction Costs and Execution Time:\nFigure 7 shows the execution cost of transaction con-\nfirmation. The bubble sizes show that when the number\nof transactions increases, the transactions’ cumulative ex-\necution cost also increases. It is observed from the graph\nthat system performance suffers when all the transactions\nof the V2G energy trading auction process run as IOTA\ntransactions.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nFigure 8 shows the execution time for reading and writ-\ning transactions in the IOTA ledger. The bubble sizes show\nthat when the number of IOTA transactions increases, the\ntransaction execution time also increases. This graph also\nshows that system performance suffers when all read/write\ntransactions of the V2G energy trading auction process run\nas an IOTA transaction. Figure 9 shows execution cost vs the\nsize of data (in bytes). The graph shows that the execution\ncost increases with increasing data size.\n**BLOCK**fs== 9.5**p== 10.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\n6.1.3.4 DLT Transaction Comparison:\n**BLOCK**fs== 9.5**p== 10.0**b== 0.1**t== 0.8**l== 0.5**r== 0.2**\nFigure 10 shows a comparison of\n**BLOCK**fs== 9.5**p== 10.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nthe traditional\nblockchain-based auction scheme in [28] and the proposed\nauction scheme based on the number of IOTA transactions.\nThe graph shows that the number of IOTA transactions for\nevery EV is fixed in the proposed auction scheme, reducing\nthe IOTA transaction execution cost. Only three transactions\nin the proposed auction scheme are stored in the IOTA\nledger (bidding, price agreement, and confirmation of en-\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nFigure 2: First group’s actual parameter values for the grid\nto select the best discharging EV\n**BLOCK**fs== 8.0**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nFigure 3: Second group’s actual parameter values for the\ngrid to select the best discharging EV\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nFigure 4: First group’s EV price comparison\nwith EVs’ average net utility.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\nFigure 5: Second group’s EV price compari-\nson with EVs’ average net utility.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\nFigure 6: EVs’ average net utility.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nFigure 7: Transaction confirmation cumula-\ntive execution cost with the number of trans-\nactions.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\nFigure 8: Execution time vs number of IOTA\npublic transactions.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nFigure 9: Execution cost with the size of\ndata.\n**BLOCK**fs== 9.5**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nergy transaction). Therefore the proposed auction scheme is\nmore efficient than the traditional blockchain-based auction\nscheme compared against.\n**BLOCK**fs== 9.5**p== 11.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nconsumption ratios. The first and last three hours have\nan energy production of zero, which means no energy is\ngenerated through solar power in these periods.\n**BLOCK**fs== 9.5**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n6.1.3.5 V2G Supply and Production Ratios:\n**BLOCK**fs== 9.5**p== 11.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nFigure 11 shows the supply-to-demand ratio for three EVs\nfor different iterations. EVs must adjust their supply to\nincrease the supply-to-demand ratio [1], as their selection\nprobability increases with increasing supply-to-demand ra-\ntio. The EVs’ revenue also increases with increases in the\nsupply-to-demand ratio.\n**BLOCK**fs== 9.5**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nFigure 12 shows EVs’ production consumption ratio\n(PCR) on an hour-of-the-day basis. In this experiment,\nwe show the three EVs that have different production-to-\n**BLOCK**fs== 9.5**p== 11.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nFigure 13 shows the grids’ production-to-consumption\nratio on an hour-of-the-day basis. It is crucial to investigate\nthe value of PCR to understand the model’s actual high\nusage at any time. The energy supply and demand and\nthe energy sales/purchase rates also depend on the energy\nproduction-consumption ratio. When the PCR value is\ngreater than 1, the EVs sell their excess energy at any\ntime. When the PCR value is less than 1, the grid buys the\namount of energy needed by the grid from EVs at any time.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nbut also facilitates a deeper understanding and broader\nacceptance of the effectiveness of our proposed algorithm\nin reaching Nash equilibrium.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\nImproving V2G network benefits entails addressing fac-\ntors such as location privacy, resilience against fake energy\noffers, optimal price selection, EV distance pricing, and\nmicrotransaction support. The proposed model provides\nlocation privacy features to protect EVs’ privacy and has\nbuilt-in resilience against fake energy offers, ensuring that\nthe network remains secure and transparent. The model\nis designed to select the best price for energy, considering\nboth the grid’s energy demand and the EVs’ availability. The\nproposed model also considers distance pricing, which can\nresult in more efficient and cost-effective energy manage-\nment. By addressing these various aspects of V2G energy\ntrading, the proposed model reduces reluctance for EVs and\ngrids to participate, leading to an overall increase in the\nnetwork benefit.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\n6.2 Security Evaluation\n**BLOCK**fs== 9.5**p== 12.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nIn this section we discuss how the proposed scheme miti-\ngates the potential threats discussed in Section 4.2.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n• T1: Due to the immutable writing of an energy offer\nby an EV to the ledger along with the deposit of an\nIOTA coin, it is not possible for an EV to change the\nselling price after a grid commits to the offer.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n• T2: The deposit of an IOTA coin with an energy-\nselling offer prevents a fake energy-selling offer from\nthe EV, as the deposit would be lost.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n• T3: The automated handling of the payment by the\ngrid through smart contracts prevents the case of a\ngrid not paying for the energy transfer.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n• T4: All transactions are performed with authentica-\ntion of the selling and buying parties through their\ndigital IOTA IDs, preventing EVs from masquerad-\ning as other EVs to collect payments.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n• T5: Energy offer transactions are digitally signed by\nthe prosumers and verified by the other parties in\nDLT, making it impossible to make fake energy offers\non behalf of other EVs.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n• T6: Energy purchase commitments made by grids in\nthe system are digitally signed by the grids, making it\nimpossible to make an energy purchase commitment\non behalf of another grid.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n• T7: The digital signature on the cryptographic hash\nof each transaction prevents adversaries from modi-\nfying contents of an energy selling offer to produce\nthe correct signature.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n• T8: Grid’s digital signature on the bid’s hash ensures\n**BLOCK**fs== 9.5**p== 12.0**b== 0.2**t== 0.8**l== 0.6**r== 0.2**\ntamper-proof energy purchase bids,\n**BLOCK**fs== 9.5**p== 12.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nLeveraging IOTA’s features and a designed energy trading\nprotocol, our system ensures security and fairness. The\nnon-cooperative game model prevents price manipulation,\nfostering equitable outcomes for all parties involved.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n7 CONCLUSION AND FUTURE WORK\nIn this work, we proposed an IOTA-based efficient and\nsecure energy trading model for V2G networks, where EVs\n**BLOCK**fs== 8.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFigure 10: Number of DLT transactions comparison between Chen et\nal.’s traditional blockchain-based auction scheme [28] and proposed\nauction scheme.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n6.1.3.6 EV Pricing and Utility Analysis: Figure 14\nshows how the EV selection probability varies with the\nprice. The graph shows that the EV providing a lower price\nhave a higher selection probability than those providing\nhigher prices. The figure shows the changes in price values\nwith color. The red color indicates the minimum probability\nof selection and maximum price, and the dark blue color\nshows the maximum likelihood of selection with minimum\nprice.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nThe DV2G algorithm optimizes energy flow between\nEVs and the grid to minimize costs and maximize revenue.\nIn our model, a privacy-preserving protocol in IOTA pro-\ntects EV location data. We mitigate risks of fake offers and\nmalicious behavior by implementing a deposit mechanism,\nensuring payment based on price agreements before energy\ntransfer. In V2G energy trading, there are chances of fake\nbuyers and sellers, such as EVs making offers for energy\nthey do not have and malicious grids refusing to pay for\nalready bought energy. In the proposed model, we use a\ndeposit mechanism in which each EV deposits some money\nwith every offer of energy selling, and the grid will make its\npayments with the price agreement, not after receiving the\nenergy to mitigate these threats.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nIn V2G energy trading, the grid always wants to buy\nenergy cheaply. In the DV2G model, the auction selects\nthe EV providing the lowest price. The lowest price may\nbe unsuitable for the grid to buy energy, or multiple EVs\nmay have the lowest price. However, the DV2G model\nhas no mechanism to handle these cases. In the proposed\nmodel, we use off-IOTA negotiation, in which the EV and\ngrid negotiate the energy price at time slot t. EV prices are\nreduced in the proposed model, which increases the grids’\nwelfare.\n**BLOCK**fs== 9.5**p== 12.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nWe have conducted an extensive and meticulous analy-\nsis, providing substantial evidence to substantiate our claim\nthat the proposed algorithm achieves Nash equilibrium. Our\nrigorous mathematical analysis demonstrates that the algo-\nrithm satisfies the conditions for a potential game, which\nguarantees the existence of a Nash equilibrium. Further-\nmore, our meticulously designed and executed simulation\nexperiments consistently exhibit convergence to Nash equi-\nlibrium across a range of scenarios. This comprehensive\nvalidation not only fortifies our contribution to the field\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nFigure 11: Supply to demand ratio of EVs.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\nFigure 12: EVs’ production to consumption\nratio.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.7**r== 0.1**\nFigure 13: Grids’ production to consump-\ntion ratio.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\nTable 2: Comparative Evaluation of Models\n**BLOCK**fs== 8.0**p== 13.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nMetric\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nEnergy Efficiency\nTransaction Speed\nSecurity Level\nPrivacy\ntion\nScalability\nSuccess Rate\nEV Selection\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nPreserva-\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nDistance Price\nMicrotransaction\nFairness\nNash Equilibrium\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.3**r== 0.7**\nProposed\nModel\nHigh\nHigh\nHigh\nExcellent\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nExcellent\nVery High\nOptimal\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\nYes\nEnhanced\nExcellent\nYes\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\nModerate\nMedium\nMedium\nFair\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.5**r== 0.4**\nBlockchain-\nBased [28]\nLow\nLow\nHigh\nPoor\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nGood\nHigh\nPrice based\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\nFair\nModerate\nRandom\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\nNo\nBasic\nFair\nNo\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\nNo\nLimited\nPoor\nNo\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\nPeer-to-\npeer [29]\nModerate\nLow\nMedium\nGood\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\nGood\nModerate\nFairness-\nbased\nNo\nBasic\nExcellent\nYes\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.7**r== 0.2**\nHierarchical\nGame [30]\nLow\nModerate\nMedium\nGood\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\nGood\nHigh\nDemand-based\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nYes\nEnhanced\nExcellent\nYes\n**BLOCK**fs== 8.0**p== 13.0**b== 0.6**t== 0.3**l== 0.8**r== 0.1**\nAggregator\nLiability [31]\nModerate\nHigh\nMedium\nGood\n**BLOCK**fs== 8.0**p== 13.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\nLow\nFair\nDemand-\nbased\nyes\nBasic\nFair\nyes\n**BLOCK**fs== 9.5**p== 13.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nAs part of future work, we aim to extend this study\nto focus on grid-to-vehicle (G2V) scenarios, exploring en-\nergy trading dynamics between grids and individual vehi-\ncles. Furthermore, we will explore privacy-preserving tech-\nniques for anonymizing data in G2V energy trading, specif-\nically tailored to this context. These research directions will\ncontribute to a more comprehensive understanding of en-\nergy trading dynamics in V2G systems and facilitate the de-\nvelopment of robust, secure, and privacy-aware G2V energy\ntrading frameworks.\n**BLOCK**fs== 9.5**p== 13.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nREFERENCES\n[1] V. Hassija, V. Chamola, S. Garg, D. N. G. Krishna,\nG. Kaddoum, and D. N. K. Jayakody, “A blockchain-\nbased framework for lightweight data sharing and\nenergy trading in v2g network,” IEEE Transactions on\nVehicular Technology, vol. 69, no. 6, pp. 5799–5812, 2020.\n[2] W. Kempton and S. E. Letendre, “Electric vehicles as a\nnew power source for electric utilities,” Transportation\nResearch Part D: Transport and Environment, vol. 2, no. 3,\npp. 157–175, 1997.\n**BLOCK**fs== 9.5**p== 13.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[3] L. Gan, U. Topcu, and S. H. Low, “Optimal decen-\ntralized protocol for electric vehicle charging,” IEEE\nTransactions on Power Systems, vol. 28, no. 2, pp. 940–\n951, 2012.\n**BLOCK**fs== 9.5**p== 13.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[4] M. Kiaee, A. Cruden, and S. Sharkh, “Estimation of\ncost savings from participation of electric vehicles in\nvehicle to grid (v2g) schemes,” Journal of Modern Power\nSystems and Clean Energy, vol. 3, no. 2, pp. 249–258,\n2015.\n**BLOCK**fs== 8.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nFigure 14: EVs’ selection probability with price variation.\n**BLOCK**fs== 9.5**p== 13.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nand grids negotiate energy prices in an off-chain manner.\nThe main objective of the proposed V2G energy trading\nmodel is to encourage more participants in the trading pro-\ncess to maximize the V2G network welfare. A three-game\nmodel is used for optimal price selection with interactions\nbetween EVs and grids. A deposit mechanism is proposed\nfor preventing fake energy trading between the EVs and\ngrids, where EVs deposit IOTA coins with energy offers and\ngrids pay with IOTA coins at the time of price agreement.\nThe proposed scheme also protects the location privacy of\nEVs. We have shown with simulations that the proposed\nscheme performs better than a recently proposed DLT-based\nscheme in terms of efficiency, privacy, resilience against fake\nenergy trading, and price.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\n[5] Z. Zhou, B. Wang, M. Dong, and K. Ota, “Secure\nand efficient vehicle-to-grid energy trading in cyber\nphysical systems: Integration of blockchain and edge\ncomputing,” IEEE Transactions on Systems, Man, and\nCybernetics: Systems, vol. 50, no. 1, pp. 43–57, 2019.\n[6] V. Hassija, V. Chamola, D. N. G. Krishna, and M.\nGuizani, “A distributed framework for energy trading\nbetween uavs and charging stations for critical ap-\nplications,” IEEE Transactions on Vehicular Technology,\nvol. 69, no. 5, pp. 5391–5402, 2020.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\n[7] K. Liu, W. Chen, Z. Zheng, Z. Li, and W. Liang,\n“A novel debt-credit mechanism for blockchain-based\ndata-trading in internet of vehicles,” IEEE Internet of\nThings Journal, vol. 6, no. 5, pp. 9098–9111, 2019.\n[8] W. Jiang, H. Li, G. Xu, M. Wen, G. Dong, and X. Lin,\n“Ptas: Privacy-preserving thin-client authentication\nscheme in blockchain-based pki,” Future Generation\nComputer Systems, vol. 96, pp. 185–195, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n[9] S. Popov, “The tangle,” cit. on, p. 131, 2016.\n[10] F. Knirsch, A. Unterweger, and D. Engel, “Privacy-\npreserving blockchain-based electric vehicle charg-\ning with dynamic tariff decisions,” Computer Science-\nResearch and Development, vol. 33, no. 1-2, pp. 71–79,\n2018.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[11] S. Xia, F. Lin, Z. Chen, C. Tang, Y. Ma, and X. Yu,\n“A bayesian game based vehicle-to-vehicle electric-\nity trading scheme for blockchain-enabled internet of\nvehicles,” IEEE Transactions on Vehicular Technology,\nvol. 69, no. 7, pp. 6856–6868, 2020.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n[12] Y. Li and B. Hu, “A consortium blockchain-enabled\nsecure and privacy-preserving optimized charging\nand discharging trading scheme for electric vehicles,”\nIEEE Transactions on Industrial Informatics, 2020.\n[13] G. Sun, M. Dai, F. Zhang, H. Yu, X. Du, and M.\nGuizani, “Blockchain enhanced high-confidence en-\nergy sharing in internet of electric vehicles,” IEEE\nInternet of Things Journal, 2020.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[14] M. Li, D. Hu, C. Lal, M. Conti, and Z. Zhang,\n“Blockchain-enabled secure energy trading with ver-\nifiable fairness in industrial internet of things,” IEEE\nTransactions on Industrial Informatics, vol. 16, no. 10,\npp. 6564–6574, 2020.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[15] M. U. Hassan, M. H. Rehmani, and J. Chen, “Deal:\nDifferentially private auction for blockchain-based mi-\ncrogrids energy trading,” IEEE Transactions on Services\nComputing, vol. 13, no. 2, pp. 263–275, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n[16] H. Liu, Y. Zhang, S. Zheng, and Y. Li, “Electric vehicle\npower trading mechanism based on blockchain and\nsmart contract in v2g network,” IEEE Access, vol. 7,\npp. 160 546–160 558, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[17] Z. Zhou, B. Wang, Y. Guo, and Y. Zhang, “Blockchain\nand computational\nintelligence inspired incentive-\ncompatible demand response in internet of electric\nvehicles,” IEEE Transactions on Emerging Topics in Com-\nputational Intelligence, vol. 3, no. 3, pp. 205–216, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[18] L. Li, J. Liu, L. Cheng, et al., “Creditcoin: A privacy-\npreserving blockchain-based incentive announcement\nnetwork for communications of smart vehicles,”\nIEEE Transactions on Intelligent Transportation Systems,\nvol. 19, no. 7, pp. 2204–2220, 2018.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[19] T. Zhang, H. Pota, C.-C. Chu, and R. Gadh, “Real-time\nrenewable energy incentive system for electric vehi-\ncles using prioritization and cryptocurrency,” Applied\nenergy, vol. 226, pp. 582–594, 2018.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[20] L. Zhang, L. Cheng, F. Alsokhiry, and M. A. Mo-\nhamed, “A novel stochastic blockchain-based energy\nmanagement in smart cities using v2s and v2g,”\nIEEE Transactions on Intelligent Transportation Systems,\nvol. 24, no. 1, pp. 915–922, 2022.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[21] G. Sharma, A. M. Joshi, and S. P. Mohanty, “Strade:\nBlockchain based secure energy trading using vehicle-\nto-grid mutual authentication in smart transporta-\ntion,” Sustainable Energy Technologies and Assessments,\nvol. 57, p. 103 296, 2023.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[22] Y. Liang, Z. Wang, and A. B. Abdallah, “V2gnet:\nRobust blockchain-based energy trading method and\nimplementation in vehicle-to-grid network,” IEEE Ac-\ncess, vol. 10, pp. 131 442–131 455, 2022.\nJ. Qiu, D. Grace, G. Ding,\nJ. Yao, and Q.\nWu, “Blockchain-based secure spectrum trading for\nunmanned-aerial-vehicle-assisted cellular networks:\nAn operator’s perspective,” IEEE Internet of Things\nJournal, vol. 7, no. 1, pp. 451–466, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[24] H. Cara, Iota’s tangle powers iampass biometric palm vein\nauthentication for digital identity, https://blog.iota.org/\niotas- tangle- powers- iampass- biometric- palm- vein-\nauthentication - for - digital - identity - 3cd0acef8bd9,\n(Accessed on 07/07/2023).\n**BLOCK**fs== 9.5**p== 14.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[25] S. Maharjan, Q. Zhu, Y. Zhang, S. Gjessing, and T.\nBasar, “Dependable demand response management in\nthe smart grid: A stackelberg game approach,” IEEE\nTransactions on Smart Grid, vol. 4, no. 1, pp. 120–132,\n2013.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[26] F. Reid and M. Harrigan, “An analysis of anonymity\nin the bitcoin system,” in Security and privacy in social\nnetworks, Springer, 2013, pp. 197–223.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[27] W. Tushar, T. K. Saha, C. Yuen, et al., “A motivational\ngame-theoretic approach for peer-to-peer energy trad-\ning in the smart grid,” Applied energy, vol. 243, pp. 10–\n20, 2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[28] C. Chen, J. Wu, H. Lin, W. Chen, and Z. Zheng,\n“A secure and efficient blockchain-based data trading\napproach for internet of vehicles,” IEEE Transactions\non Vehicular Technology, vol. 68, no. 9, pp. 9110–9121,\n2019.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[29] V. Behrunani, A. Irvine, G. Belgioioso, P. Heer, J.\nLygeros, and F. D ¨orfler, “Designing fairness in au-\ntonomous peer-to-peer energy trading,” arXiv preprint\narXiv:2302.04771, 2023.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[30] Y. You, Q. Xu, and C. Fischione, “Hierarchical online\ngame-theoretic framework for real-time energy trad-\ning in smart grid,” IEEE Transactions on Smart Grid,\nvol. 15, no. 2, pp. 1634–1645, 2024.\n**BLOCK**fs== 9.5**p== 14.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[31] W. Wu, J. Zhu, Y. Liu, T. Luo, Z. Chen, and H. Dong,\n“A coordinated model for multiple electric vehicle\naggregators to grid considering imbalanced liability\ntrading,” IEEE Transactions on Smart Grid, vol. 15,\nno. 2, pp. 1876–1890, 2024.",
         "Rizwan, M., Ali, M., Hawbani, A., Wang, X., Anjum, A., Angin, P., Popoola, O.  and Imran, M. A.  (2024) IOTA-based game-theoretic energy trading with privacy-preservation for V2G networks. IEEE Transactions on Sustainable Computing, (doi: 10.1109/TSUSC.2024.3410237) The University of Glasgow has an agreement with IEEE which allows all UofG authors to self-archive accepted manuscripts submitted to any of the subscription-based (hybrid) IEEE journals, magazines, or conference proceedings. Authors can immediately self-archive accepted manuscripts in an institutional or subject based repository with a self-attributed CC BY licence. The agreement covers all original research and review articles. Copyright © 2024 IEEE. Reproduced under a Creative Commons Attribution 4.0 International License. Deposited on: 12 August 2024 Enlighten – Research publications by members of the University of Glasgow https://eprints.gla.ac.uk IOTA-based Game-Theoretic Energy Trading with Privacy-Preservation for V2G Networks Muhammad Rizwan, Mudassir Ali , Ammar Hawbani, Wang Xingfu, Adeel Anjum, Pelin Angin, Olaoluwa Popoola, and Muhammad Ali Imran E Lectric Vehicles (EVs) and renewable energy sources (RES) play an important role in sustainable energy and reducing the adverse impacts of fossil fuels, hence attracting increasing attention from both academia and industry in re- cent years. Efficient energy utilization requires keeping track of the interactions between the producers and consumers so that producers can adjust their supplies according to con- sumer demands [1]. Vehicle-to-Grid (V2G) energy trading is one of the most promising solutions for this problem [2].In particular, EVs can use energy storage to reduce the grid load by trading excess energy[3].EVs can accumulate energy and sell extra energy to the grid when parked[4]. Centralized platforms are unsuitable for managing V2G transactions due to problems including single point of fail- ure, poor scalability, reduced control over data integrity, and lack of transparency. Hence, distributed ledger technology (DLT) based solutions such as blockchains are currently favored for verifying and storing energy trading transac- tions[5]. While blockchains offer secure P2P trading and reliable storage, their effectiveness in V2G networks is still under evaluation([1], [6], [7]), they still suffer from the long block verification delay resulting in low throughput, and they can be rather compute-intensive [8]. Moreover, conventional blockchains do not support microtransactions since the value of such transactions is typically less than the incentives offered to miners. On the other hand, large V2G transactions can become unprofitable due to increased transaction costs. In this paper, we propose an IOTA DLT-based approach [9] for V2G energy trading, which aims to overcome the shortcomings mentioned above of blockchain-based ap- proaches. The main contributions of this paper are as fol- lows: The main contributions of this paper are as follows: • We design an IOTA DLT-based energy trading model for V2G networks and propose a privacy-preserving protocol for energy trading in V2G networks. The protocol allows the system to prevent tracking the exact locations of EVs and securely perform the price negotiations between the EVs and grids in the V2G network. • We show that energy trading between the EVs and grids in the V2G network can be modeled as a Stackelberg game, with multiple leaders represented by EVs and multiple followers represented by grids. Based on the game model, we formulate the algo- rithm that incentivizes EVs to participate in energy trading while enabling the grids to select the EVs with the best offers. security of the IOTA DLT, where EVs must deposit IOTA coins with their energy offers, and grids pay in IOTA coins at the time of price agreement. This ensures that the EVs are committed to their energy offers and discourages malicious behavior. To evaluate our scheme’s effectiveness, we compare it with a recent blockchain-based V2G energy trading ap- proach. Though both leverage DLT and game theory, they differ in focus and approach. Simulations demonstrate our scheme’s superior cost-effectiveness. The rest of this paper is organized as follows. In Section 2, we review related work on different approaches for V2G energy trading. Section 3 presents the necessary background on IOTA. Section 4 presents the system model and the pro- posed IOTA-based protocol for privacy-preserving energy trading in V2G networks. In Section 5, we formulate the game model of energy trading between the EVs and grids, based on which we construct the algorithms that incentivize the EVs to participate in energy trading while, at the same time, enabling the grids to select the EVs with the best offers. In Section 6, we evaluate the performance and security of the proposed system. Finally,and we conclude the paper and discuss future work in Section 7. 2 RELATED WORK This section reviews existing work on decentralized V2G energy trading, which has captured increasing attention of both industry and academia in recent years. In [10], the authors proposed a privacy-preserving, automated, reliable blockchain-based protocol to select the optimum charging stations based on the distance from EVs and energy price. Although the protocol achieves a relatively small overhead, it does not prevent possible dishonest behavior by EVs in negotiations. In [11], the authors proposed a Bayesian game-based scheme for energy trading in V2V. The result shows that user satisfaction in the proposed scheme reaches 98% with incomplete information. However, the proposed scheme has poor runtime performance because all pro- cesses run as blockchain transactions. In [12], the authors designed the architecture of a decentralized power trading system of EVs, which is consortium blockchain-based. The proposed scheme’s security evaluation showed that it is resilient against different types of attacks. However, the model did not consider the uncertainty about the range of the discharging vehicles. In [13], the authors proposed a fog computing-based architecture for energy trading. Their evaluation demonstrated that the genetic algorithm achieves maximum social welfare, which is 71.03% more than the Lagrange algorithm. However, performance suffers because all the auction processes run as a blockchain transaction. In [14], the au- thors designed a system called FeneChain for decentral- ized energy trading. The results showed that FeneChain performs better than the other three schemes regarding energy sales and energy purchase computational costs. However, the authors did not consider fairness. In [15], the authors proposed a blockchain-based differential auction of private energy for microgrids. They showed that the pro- posed mechanism performs better than other mechanisms for auctions. However, no incentive was provided in the auction process to guide energy suppliers/buyers. In [16], the authors leveraged blockchain technology to develop a P2P secure energy trading system. They showed that the proposed scheme’s benefits increase when the number of EVs in the network increases. In [17], the authors pro- posed a framework for secure energy trading based on a consortium blockchain. Although the scheme performs well in maximizing social welfare, it is rather compute- intensive, prohibiting widespread deployment. In [5], the authors proposed a consortium blockchain-based frame- work of V2G energy trading, which is efficient and secure for cyber-physical systems. They showed that the proposed framework is promising in terms of provided security, the performance of task offloading, and contract feasibility. However, the local energy aggregators cannot purchase the larger services when the transaction fee is low. In [18], a blockchain-based privacy-preserving network of incentive announcements was proposed. See Supplementary Table for details. The authors compared the proposed protocol with others and showed that it is more efficient. However, blockchain’s high computation resource requirements pre- vent incentive announcements from being widely deployed. In [19], a blockchain-based real-time system that uses a cryp- tocurrency and a prioritization concept called SMERCOIN to incentivize EVs to charge in a renewable energy-friendly schedule was proposed. The evaluation results showed that the local consump- tion rate increased to 37%, decreasing the aggregator’s energy cost. However, the work only focused on renew- able energy consumption rates and did not consider EV privacy. More recent work by Zhang et al. [20], Sharma et al. [21] and Liang et al. [22] have also proposed blockchain- based approaches for V2G energy trading, but they carry the same disadvantages as other blockchain-based models. In [1], the authors proposed a Directed Acyclic Graph- based lightweight protocol for V2G (DV2G). The proposed model’s evaluation showed that it supports microtransac- tions and is highly scalable. However, it did not consider EV privacy. In [6], the authors proposed a distributed network of charging stations for Unmanned Aerial Vehicles (UAVs) based on IOTA. They showed that the proposed scheme provides better revenue and utility for charging stations and UAVs than traditional blockchain-based schemes. In [7], the authors proposed a blockchain-based system of Internet of Vehicles (IoV) data trading, which uses a debit-credit mech- anism using a two-stage Stackelberg game. The scheme is limited to data trading and does not focus on energy transactions. In [23], The authors introduced a blockchain- based spectrum trading platform for UAV cellular networks, demonstrating its efficiency and effectiveness in enhancing privacy and security. However, the proposed scheme lacks specific strategies to prevent malicious providers and buy- ers. IOTA is an open-source DLT designed specifically for the In- ternet of Things. It is based on the tangle data structure that uses directed acyclic graph (DAG) characteristics. IOTA uti- lizes digital identities to assure trust among its participants, called network nodes[24]. In IOTA, digital identity verifica- tions are decentralized and free from third parties. Private and virtual pseudo-anonymous wallets store the IOTA coins of smart devices. Computational cost is a major obstacle in verifying transactions in traditional blockchains[25]. The details are provided in a supplementary file. if discharging, 1, 0, otherwise,. 4 SYSTEM MODEL The main objective of our proposed V2G energy trading model is to encourage more participants to participate in the process of energy trading to maximize the V2G network welfare.The EVs and grids act as prosumers, which produce and consume energy. The energy trading benefit in a V2G network is maximized by maximizing the revenue of grids (buyers) and EVs (sellers). Our proposed model considers six parameters to maximize the overall system benefits: transaction efficiency, EV privacy, fake energy offers, the best EV selection at time slot t, EV distance price, and microtransactions. The main components of the proposed V2G energy trad- ing model are as follows: 1) Energy nodes: The EVs and grids are the energy nodes in the V2G network. The EVs can act as prosumers (pro- ducing and consuming energy) and as energy sellers. The grids work as energy buyers. 2) Energy aggregator: This is an energy-trading broker be- tween the EVs as energy sellers and the grids as energy buyers. In the IOTA DLT, the brokerage mechanism employed in the aggregator can be realized using smart contracts that allow direct communication between the EVs and grids. 3) Smart meters: These contain details regarding how much energy is traded between the EVs and grids. In this section, we describe the V2G network energy trading model. Table 1 provides a summary of the symbols used in the model. The V2G system operates on a time-slotted basis with t denoting the time slot number and ∆t being the time slot duration. Let P = {1, ..., i, ..., p} be the set of prosumers. We define the energy generation profile of prosumer i for one day as: where Gt i is the power generated by the prosumer i during time slot t, and T is the number of time slots per day. We define the power consumption profile of prosumer i as: where U t time slot t. i is the power consumption of prosumer i during Prosumer i’s energy storage calculated in terms of ESUs is computed at the time of charging/discharging as: Bt c,i are binary variables meeting the following condition to avoid simultaneous charging and discharging: We calculate the ESU’s total energy storage as Here, ηt i represents the prosumer i’s total energy amount stored in the ESU at time slot t, and ηt−∆t represents the prosumer i’s energy storage in the ESU at the start of time slot t. The minimum and maximum charging limits are ex- pressed using the following equation, where these limits are decided based on the SP inverter size. represents the maximum charging power, and represents the maximum discharging power. Prosumer i profits if the ESUs’ daily cost is less than the total savings obtained in a day. γi = (CCi + SCi)/d, where γi represents the total cost per day. CCi is the combined cost for the ESU and converter, SCi represents the annual sustaining cost, and d represents the number of days in a year. µi = αi–γi, where µi represents the total profit in a day of prosumer i, and αi shows the total savings in a day. Let X be the total number of sellers (EVs), and Y be the total number of buyers (grids), where x ∈ X and y ∈ Y . Prosumer i’s production-to-consumption ratio at time slot t is calculated as If ξt i is greater than 1, it means that the EV has surplus energy. The total amount of energy that the EV i sells to the grid at time slot t is calculated using the following equation: where Ψt y,buy represents the amount of energy that the grid buys at time slot t [1]. ψy represents the total grid capacity of energy storage, and ψt y,s represents the grid’s level of storage at time slot t. V2G energy trading in the system scenario considered in this work may face the following threats: • T1: The EV changes selling prices after a grid com- mits to an offer made by it. • T2: The EV makes fake energy-selling offers to attract grids and manipulate the operation of the whole system. • T3: The grid refuses to pay for the energy provided by an EV after the energy transfer takes place. • T4: The EV masquerades as another EV to collect the payments for its energy sales. • T5: The EV masquerades as another EV to make fake energy offers on its behalf. • T6: The grid makes a fake energy purchase commit- ment on behalf of another grid. • T7: The energy selling offer made by an EV is modi- fied by an adversary. • T8: The energy purchase bid made by a grid is modified by an adversary. for privacy- In this section, we describe the protocol preserving energy trading between the EVs and grids in the V2G network. The basic privacy requirements for this protocol are as follows: 1) LocationPrivacy: No participant can determine the ex- act positions of EVs in real time. This ensures that the location privacy of EVs is protected, preventing any po- tential tracking or profiling based on their movements. 2) SchedulePrivacy: The privacy of EVs and their charg- the ing schedules must be maintained throughout charging process. This safeguards the confidentiality of their charging patterns, which could otherwise reveal sensitive information about EV owners’ habits and rou- tines. In the DLT, each participant (i.e., the EV or grid) uses the system-provided unique anonymous ID ζ. The map- ping between the participant’s ID and its true identity is known only to the system. Hence, the true identity of each participant is unknown to other participants. Nevertheless, deanonymization of participants is possible by relating keys and transactions [26]. The ID ζ changes for every request to mitigate the deanonymization problem by creating a new pair of keys to enhance EVs’ privacy. We assume that the grid list and positions are known publicly. Figure 1 shows an overview of the V2G energy trading process. The protocol consists of four phases, as described below. 4.3.1 Bidding phase In the bidding phase, EVs place the ESO with a unique identity to the grid in an immutable and public way with a deposit. The ESO’s public nature incentivizes other dis- charging EVs to keep their prices competitive. The ESOs contain the energy amount e ∈ Q+, at time slot t ∈ T , geographic region r ∈ R, and selling price p. The region should be chosen broadly so that the privacy of EVs is protected but within EVs’ feasible range. No one participant finds out anything beyond ESO(e, t, r, p,) and the ID ζ. Given (e, t, r, p,), no participant can determine the exact locations of EVs because the different ESOs are disconnected from others. The selling offers cannot be directly related to the specific discharging vehicle because only the ID ζ of discharging EVs is shown with the ESO (without identifying the exact position of the EV). Once the ESOs are submitted to the ledger, they are visible to all the grids and all discharging EVs. 4.3.2 Evaluation phase In the evaluation phase, the grids assess the discharging EVs’ ESOs based on their distance, energy supply, and price. The grid finds the optimum discharging EVs according to the total energy price. In the case of many demands from the grids to discharge EVs, the EVs select among them uniformly. EVs use a non-cooperative game (NCG) strategy to update their prices to enhance their selection probability. Grids privately decide on the bid in an off-IOTA manner. 4.3.3 Negotiation phase In the negotiation phase, the grid communicates with dis- charging EVs to set the energy price off-IOTA. When both agree on the price, then the agreed transaction is submitted to the IOTA ledger. The ESO of discharging EVs contain (e, t, r, p), and the grids i check their positions and other pa- rameters discussed in the evaluation phase to find appropri- ate discharging EVs. When appropriate discharging EVs are found, grids create their bids based on NCG bi = f (e, t, p). This function shows that grid i desires to purchase energy e from EV ζ in the given time slot for bi ≤ bj, j = 1, ..., N . If the discharging EV agrees on the given grid’s bid bi, then the transaction is written in the IOTA ledger. The negotiation process continues until price convergence or a set time limit. The grid may accept EV bids immediately or update prices. Upon agreement, the final price is determined. Once the EV and grid have agreed on the appropriate price, the grid binds the commitment computationally c = H(ζ,¯i, rn) by combining the index of grid i and ID of EV ζ and freshly creating a random number for it. The binding commitment is sent to the IOTA ledger. 4.3.4 Charging phase The transaction is executed directly between the grid and EV in the charging phase. The phase opens the commitment by sending ζ, ¯i, and rn to verify the selected grid. The grid checks the commitment and verifies H(ζ,¯i, rn) = c and verifies whether the time of the transaction matches the commitment time. Energy e is exchanged on commitment price bi in the given time slot t. This commitment transaction is only performed between the selected grid and EV. The discharging EV’s actual position is shown to the selected grid at this stage. However, this commitment information is not shown to the IOTA network. In the process of open commitment, EV reveals the ID ζ, and no other EV has the same identity due to using a cryptographic hash function for the commitment binding. As such, the grid proves that it communicates with the valid discharging EVs. After the charging phase is complete, a new ID is assigned to each discharging EV. 5 GAME MODEL OF THE V2G NETWORK This section presents the hierarchical game model governing energy trading dynamics in the V2G system. EVs act as sellers, while smart grids serve as buyers. The hierarchy starts with a non-cooperative game (NCG), representing EVs competing to sell power at optimal prices to the grid. EVs equipped with solar panels negotiate with smart grids throughout the day. EVs strategically adjust their selling prices based on energy generation and battery levels, while grids dynamically adjust purchase prices based on predicted consumption patterns. Next, a Stackelberg game (SG) cap- tures the interaction between EVs and grids. Here, EVs alternate between leading and following roles, influencing market dynamics with surplus energy. For instance, an EV may lead by strategically withholding energy during peak demand, prompting grids to offer better purchase terms. Finally, another NCG governs grid interactions, with oper- ators adapting strategies to optimize profit while ensuring energy supply meets demand. 5.1 EVs employ NCG to make more profit The EVs employ NCG because they compete in a non- cooperative way with each other to make more profit by selling energy at the best price to the grid. When the grid’s demand is greater than or equal to EV i’s supply, EV i’s utility is calculated by ui(Et When the grid’s demand is less than the supply, EV i’s utility is calculated by Nash equilibrium is a notion in game theory that identifies the best solution in an NGC, where participants have no incentive to change their initial approach. Under the Nash Equilibrium, a player gains nothing by departing from their initial plan, assuming the other players’ strategies remain unchanged. There may be several Nash equilibria in a game or none at all. The Nash equilibrium is attained when each EV sells its total surplus energy, which is the goal of the proposed algorithm. A predefined set of conditions is in place to achieve this equilibrium point in NCG. One necessary con- dition is that a finite number of players must be satisfied by having X EVs participating. The game continues until the grid demand, denoted as Ψt y,buy is fully satisfied or all the surplus energy from the discharging EVs has been sold. The algorithm facilitates this equilibrium by allowing each EV to decide how much extra energy to deal with, optimizing their utility or profit. The surplus energy is then allocated to the grid, ensuring demand is met while respecting the individual decisions of the EVs. The algorithm checks if no EV can unilaterally change its decision to increase its profit, indicating the achievement of Nash equilibrium. The game terminates when the grid demand is met, or all surplus energy is sold, representing a stable equilibrium state. A discharging EV i uses the following strategy to adjust its supply to maximize its selection probability A discharging EV i uses the following strategy to update its prices to maximize selection probability where n represents the number of iterations. The NCG game is defined by the tuple Γ = ⟨X t, Ωt, pt, ⟨Ai, ui, T t i ⟩i∈N ⟩, where X t represents the set of EVs at time slot t, s.t. xt ∈ X t, Ωt represents the condition of the weather at time slot t, At i ) is the set of actions available for EV i at time slot t, where At N , Ti is the set of types for EV i according to the condition of the weather or the current state of the EV. Given the condition of the weather, the type of EV i is given by the function τi : Ω → Ti [27]. Therefore, according to the weather condition, the game will have different types of EVs. The payoff function for EV i is defined by ui : Ti × A → R, and p is the probability distribution for the weather condition Ω. A mixed strategy for EVs i is a function xi : Ti → ∆Ai, where ∆Ai is the set of all probability distributions on Ai. Note that a strategy depends only on its type of EVs. A strategy profile x represents the strategy for each EV. The strategy profile finds out the expected payoffs for each EV, where the expectation is taken based on both the weather condition and EV types in terms of beliefs p, and the randomization over actions implied by any mixed strategies in the profile x. Given a game ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, the profile of the mixed strategy (xi)i∈N is called the Nash equilibrium of the mixed strategy if ∀i ∈ N xi,price be the supply and enforced price of EV i at time slot t with choosing probabilities xi1 and xi2. Let Et xj ,price be the supply and enforced price of EV j at time slot t with choosing prob- abilities xj1 and xj2. We use the mixed strategy due to the intermittent nature of supply. Besides, when the player uses the same choices every time, then other players will track these choices. This will create a privacy problem for EVs and also create the problem of using these choices to maximize its selection probability at time slot t. Hence, here we use the mixed strategy for the selection probability for EVs at time slot t. We use an arithmetic method to achieve the optimal strategy and value of the game at time slot t. Let EV i’s mixed strategy at time slot t be (xi1, xi2), where xi1 + xi2 = 1. 5.1.1 Case Study The net expected gain E1, at time slot t of EV i is E1(EV i) = [xi1xj1]xi1 + [xi2xj1]xi2, when EV j increases the supply at time slot t. The net expected gain E2, at time slot t of EV i is E2(EV i) = [xi1xj2]xi1 + [xi2xj2]xi2, when EV j decreases the price at time slot t. So for EV i, we have to find the supply and its enforced price at time slot t and value v of the game that satisfy the following relationships [xi1xj1]xi1 + [xi2xj1]xi2 ≥ v [xi1xj2]xi1 + [xi2xj2]xi2 ≥ v The inequalities become strict equations for the optimum strategies. [xi1xj1]xi1 + [xi2xj1]xi2 = v [xi1xj2]xi1 + [xi2xj2]xi2 = v From (23a) − (23b), we get Plugging this value into (22c) to get the optimal price strategy at time slot t we get From (24a), we get Plugging xi1 and xi2 into (23a), we get the Nash equilib- rium or value of the game, as follows: A Stackelberg Game (SG) models the relationship between the EVs acting as leaders and the microgrids acting as followers [7]. Enhances the Stackelberg game method for en- ergy trading by introducing novel features like microtrans- actions and optimized decision-making. Leveraging IOTA’s platform ensures secure, decentralized trading focusing on data privacy. These innovations demonstrate the originality and significance of our work in advancing energy trading methodologies. In the SG, EVs declare their available energy and price range for the specific time slot, and grids use the NCG to select a suitable EV. EVs use NCG to maximize their selection probability to update prices and adjust their supply according to demand based on the NCG output. EVs use NCG because they are unfamiliar with each other. The double auction algorithm achieves the Nash equilibrium in SG. The EVs update their prices by using the strategy in (18). The EVs adjust their supply utilizing the strategy in (17), and the grids use the NCG to select the best discharging EV. The energy price is the input for EVs’ NCG and grids’ NCG. The EVs’ NCG output is the best-selling energy price, which is further used as input for the grids’ NCG, and the grids’ NCG output is the best discharging EV selection. The SG establishes a connection between EVs’ NCG and grids’ NCG. EVs use the best energy supply and its price according to (24c) and (25) to maximize their selection probability at time slot t with suitable gain. Grids use (50c) and (50b) to select the best suitable EV at time slot t with appropriate gain. The grids’ utility sum is the social welfare (SW) of V2G energy trading: arg max wt y Where Y is the number of grids. The grids’ and EVs’ total profit from V2G energy trading is calculated by defined time slot time slot by where Where X is the number of EVs, TB represents the total profit of grids and EVs and pt x represents the discharging EVs’ received payment. tuple proposed Γ = ⟨XY t, Ωt, pt, ⟨Ai, ui, T t XY t t, represents the set of grids and EVs at where xyt ∈ XY t, Ωt represents the condition of the pi) is the set of weather at actions available for EVs and grids i at time slot t, where At N , Ti is the set of types for grids and EVs i according to the condition of the weather or the current state of the EVs and grids. Given the condition of the weather, the type of EVs and grids i is given by the function τi : Ω → Ti. Hence, according to the weather condition, the game will have different types of EVs and grids, and the payoff function for EVs and grids i is defined by ui : Ti × A → R. A mixed strategy for EVs and grids i is a function σi : Ti → ∆Ai, where ∆Ai is the set of all probability distributions on Ai. Note that a strategy depends only on its own type of EVs and grids. A strategy profile σ represents the strategy for each EV and grid. The strategy profile finds out the expected payoffs for each EV and grid, where the expectation is taken based on both the weather conditions and EV and grid types in terms of beliefs p, and the randomization over actions implied by any mixed strategies in the profile σ. Given a game ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, profile of the mixed strategy (σi)i∈N is called Nash equilibrium of the mixed strategy if ∀i∈N ui(σi, σ−i) ≥ ui(σ′ n Vn). Let Et Let the Bayes-Nash equilibrium be given by the strategy profile ( n−1 yj ,price be the demand and demand price of Gridsj at time slot t according to 1 xi,price) be the discharging EV’s offers at time slot t. EV i wins when V2 ≤ 2S1 and utility gains V1 − S1, EVi loses when when V2 > 2S1 and gets utility 0. 2 V . Let S1 = (Et 2s1 E[ui] = 2S1V1 − 2(S1)2 Now we find the best response for EV i at time slot t to grids by taking the partial derivatives of the expected utility of EV i at time slot t and setting it to zero. Thus, when a grid’s energy demand and energy demand price is half of its valuation, EV i’s best response is to offer the energy at half its valuation. 5.3 Suitable EV selection by using NCG The best discharging EV selection is made by using the NCG. The focus of NCG is on the dynamic strategy. Here we use NCG to resolve the competition among the grid. NCG is used because the grids’ strategies change dynamically to obtain a higher profit. The NCG model group y ∈ Y consists of buyers, which are smart grids. When the EVs submit prices to the IOTA ledger, each grid for energy purchasing chooses the best possible EV. The grids select the EV independently, and the grid selection strategy is adjusted progressively. mt p denotes the probability of grid y ∈ Y choosing the EV x ∈ X in the tth time slot. The following equation is used to calculate the supply-to-demand ratio of EV x ∈ X at time slot t: If ry,x is greater than or equal to 1, then the grid’s true value to select the suitable EV at time t to buy energy from the discharging EV is as follows: where the distance price of EV x at time slot t is calculated by x = (CKx)(Rt ωt Here, ωt x represents the total distance price for EV x, CKx represents the energy consumption per kilometer of EV x, Rt x,k represents the discharging EV’s total distance range at time slot t. St x,price represents the enforced price of the discharging EV at time slot t. If ry,x is lower than 1, then the grid’s true value to select the suitable EV at time slot t to buy energy from the discharging EV is as follows: where Et x,less represents how much the discharging EV’s energy is less than grid demand.Grid prioritizes price or supply. For each (≥ or < demand), grid selects closest, cheapest EV at time t. Let EV1 represent the first group’s best discharging EV, whose energy supply is greater than or equal to the grid demand, and EV2 represents the second group’s best EV, whose energy supply is less than the grid demand. The grid compares the prices of these two EVs EV1 and EV2. If both EVs’ prices are equal, then the grid selects the EV of the first group, which is EV1 because it fulfills the grid’s energy demand at time t in every aspect. It should be noted that the first group’s and second group’s prices are calculated using (36) and (38), respectively. Another method is the average utility method, which the grids use to find the best discharging EV at time slot t. Ψt true is the net utility of a specific discharging EV for grids in which the energy supply is greater than or equal to the power demand. The average utility at time slot t is calculated by demand, and EVn represents the second group’s best EV, whose energy supply is less than the grid demand. Let Et x,price be the supply and enforced price of EVx at time slot t. The grid selects the EVs according to the best-fit price and supply at time slot t. Let grid yj’s mixed strategy at time slot t be (yj1, yj2), where yj1 + yj2 = 1. Let grid yi’s mixed strategy at time slot t be (yi1, yi2), where yi1 + yi2 = 1, to select the best discharging EV at time slot t. The net expected gain E1, at time slot t of yi is E1(yi) = [yi1yj1]yi1 + [yi2yj1]yi2, Ψt l,true is the net utility of the specific discharging EV l for grids whose energy supply is less than the power demand according to the supply of EVj at time slot t. The net expected gain E2 at time slot t of yi is E2(yi) = [yi1xj2]yi1 + [yi2yj2]yi2, according to the price of EVj at time slot t. So for yi, we have to find the best demand price of energy at time slot t and the value of the game that satisfy the following relationships If the average utility ratio is less than 1, then the first group is better for searching for the best EV. If the average utility ratio is greater than 1, then the second group is better for searching for the best EV. The utility of the grids is calculated as follows Un = arg max The grids’ NCG solution is represented as follows 4 , ...., EV t∗ EV t∗ = {EV t∗ Algorithm 1 shows the detailed process of the grids’ NCG. defined tuple NCG Γ = ⟨N t, Ωt, pt, ⟨Ai, ui, T t i ⟩i∈N ⟩, where N t represents the set of grids at time slot t, where nt ∈ N t, Ωt represents the condition of the weather at time slot t, At pi) is the set of actions available for grids i at time slot t, where At is the set of types for grids i according to the condition of the weather or the current state of the grids. Given the condition of the weather, the type of grids i is given by the function τi : Ω → Ti [27]. So, according to the weather condition, the game will have different types of grids; the payoff function for grids i is defined by ui : Ti × A → R, p is the probability distribution for the weather condition Ω. A mixed strategy for grids i is a function yi : Ti → ∆Ai, where ∆Ai is the set of all probability distributions on Ai. Note that a strategy depends only on its own type of the grid. A strategy profile y represents the strategy for each grid. The strategy profile finds out the expected payoffs for each grid, where the expectation is taken on the basis of both the weather condition and grids’ types in terms of beliefs p, and the randomization over actions implied by any mixed strategies in the profile y. Given a game ⟨N t, (Ai)i∈N , (ui)i∈N ⟩, profile of the mixed strategy (yi)i∈N is called Nash equilibrium of the mixed strategy if ∀i∈N [yi1yj1]yi1 + [yi2yj1]yi2 ≥ v [yi1yj2]yi1 + [yi2yj2]yi2 ≥ v The inequalities become strict equations for the optimum strategies. [yi1yj1]yi1 + [yi2yj1]yi2 = v [yi1yj2]yi1 + [yi2yj2]yi2 = v From (49a) − (49b), we get Plugging this value into (48c) to get the optimal price at time slot t: From (50a), we get After substituting yi1 and yi2 in (49a), we get the value of the game: ui(yi, y−i) ≥ ui(y′ Let EVm represent the first group’s best discharging EV, whose energy supply is equal to or larger than the grid In this section, we perform a performance evaluation of the proposed scheme based on simulation experiments, which includes a comparison with a blockchain-based approach, followed by a security analysis of the proposed approach. Algorithm 1 Algorithmic implementation of grids’ NCG Input: ESOs from EVs ESOt 3, ..., ESOt x Output: Grids’ NCG equilibrium state EV t∗ 4 , ...., EV t∗ 3 , EV t∗ X } x into two groups {EV t∗ 2 , EV t∗ 1 , EV t∗ (1) Divide all ESOt i = i+1; for all x ∈ X do Calculate ry,x according to (35) if ry,x(i) ≥ 1 then Calculate Ψt true according to (36) else if ry,x(i) < 1 then l,true according to (38) (2) Compare the average utility of both groups Search best EV in the first group 13: Calculate Ua,r according to (42) 14: if Ua,r < 1 then 15: 16: else if Ua,r > 1 then 17: 18: end if Search best EV in the second group (3) Selection of best EV from the first group a1 according to (40) j = j + 1; for all Ψt if U t end for 35: Calculate U t 36: k = 0; 37: repeat 38: 39: k = k + 1; for all Ψt if U t true(j) then true(j − 1) < Ψt Select Ψt else if Ψt true(j − 1) true(j − 1) > Ψt end if else if U t (4) Selection of best EV from the second group a2 according to (41) else if Ψt end if else if U t end for Algorithm 2 Algorithmic implementation of SG Input: Initialize ESOt 3, ..., ESOt x Output: Nash equilibrium in SG 1: for all y ∈ Y do m=0; 2: repeat 3: 4: 5: 6: 7: 8: 9: end for until (St m = s+1; Calculate Ψt Execute algorithm 1 EVs update ESO prices according to (18) y,buy according to (14) This section encompasses the overall strategy and tools used to evaluate the performance of the proposed V2G energy trading model. It includes the setup of the simulation envi- ronment, the categorization of EVs, and the consideration of various factors, such as the EVs’ distance from the grid and their energy supply capabilities. The proposed V2G energy trading model is evaluated based on several critical performance indicators. These metrics are: • Transaction Efficiency: The ability of the system to handle energy trades swiftly and with minimal overhead. • EV Selection: System can select the best EVs for transactions based on their energy supply and the distance price, which reflects the EVs’ location rela- tive to the grid. • Distance Price Consideration:How the distance of an EV from the grid affects the pricing and selection in the energy trade. • Microtransaction Capability:The system’s function- ality supports small-scale transactions efficiently. These metrics are designed to ensure that the model not only fosters competitive behavior among participants but also maximizes the welfare of the V2G network by balancing the revenues of EVs with the costs incurred by the grids. For a comprehensive assessment, the performance of the proposed V2G energy trading model was benchmarked against three other systems: 1) DV2G: A contemporary V2G energy trading model em- ploying DAG for transactions, referenced in [1]. This model serves as a benchmark for transaction efficiency and microtransaction support. 2) Blockchain-Based Approach: A traditional approach to V2G energy trading that is grounded in blockchain technology, as detailed in [28].This approach provides a baseline for evaluating the enhancements our model brings to the V2G energy trading landscape. 3) Peer-to-peer Energy Trading: Designing Fairness in Autonomous Peer-to-peer Energy Trading [29] provides a foundational benchmark for fairness in V2G systems. Our IOTA-based algorithm, in comparison, excels in transaction efficiency and scalability, significantly en- hancing the V2G energy trading landscape. 4) Hierarchical Game-Theoretic Framework: Designing Fairness in Real-Time Energy Trading in Smart Grids [30], a seminal work in fairness evaluation for energy trading. Our IOTA-based algorithm, in comparison, excels in transaction efficiency and scalability, signifi- cantly enhancing the V2G energy trading landscape. 5) EV Aggregator Liability Model:Electric Vehicle Aggre- gators to Grid Liability Trading [31], a seminal work in fairness evaluation for energy trading. Our IOTA- based algorithm, in comparison, excels in transaction efficiency and scalability, significantly enhancing the V2G energy trading landscape. The benchmarking process involves directly comparing systems based on transactional throughput, EV selection efficiency, and overall V2G network welfare impact. Our proposed V2G energy trading model aims to increase par- ticipant engagement to maximize network welfare. This entails maximizing EV revenue, minimizing grid costs, and fostering healthy competition among EVs and grids In the next section,we’ll discuss our simulation results, fo- cusing on key parameters like energy efficiency, transaction speed, security, privacy, and scalability to evaluate our pro- posed methodology. 6.1.3.1 Parameter Values for Grid Selection: Figure 2 and Figure 3 show the parameter values for the first and second groups of EVs, respectively, used by the grid to select the appropriate EV to buy energy from. These figures present the EV supply, grid demand, supply- demand ratio, kWh, distance, distance price, and total price of the six EVs in each group. The grid aims to find the EV that provides the lowest price based on the unit price, proximity, and energy supply. The best value for the grid is the lowest accumulative price of energy-selling EVs. The graphs show that the grid finds the best EVs in both groups separately (EV2 in Figure 2 and EV6 in Figure 3) and com- pares these best-discharging EVs based on the total energy supply price. If the prices of both EVs are equal, then the grid selects the EV of the first group because it fulfills the grid demand at time slot t. In Figure 2 and Figure 3, the distance and distance price parameters reflect the location of each EV relative to the grid. The graphs indicate that if an EV is closer to the grid, its distance reward will be lower than when it is far away. This suggests that the grid prior- itizes selecting EVs closer to the grid to minimize energy transportation costs. The supply-demand ratio parameter reflects the balance between the energy supply and demand in the grid. The graphs show that the grid selects the EVs that can provide energy to the grid based on the supply- demand ratio. The kWh and total price parameters reflect the energy supply and price of each EV. The graphs suggest that the grid prioritizes selecting the EVs that can provide energy at a lower price to the grid to minimize energy costs. Figure 2 and Figure 3 provide important information about the parameters used by the grid to select the appropriate EV to buy energy from and the best value for the grid, which is the lowest accumulative price of energy-selling EVs. These figures can help inform decisions about the management of EVs in the grid and to optimize their utilization in the energy system. If the prices of both EVs are equal, then the grid selects the EV of the first group because it fulfills the grid demand at time slot t 6.1.3.2 EV Pricing and Utility Analysis: Figure 4 shows the price comparison of the first group’s total energy prices of EVs with the average net utility of EVs and Figure 5 shows the price comparison of the second group’s total energy prices of EVs with the average net utility of EVs. In the figures, the blue bars indicate the average net utility and the red bars show the EVs whose energy prices are greater than the average net utility. The gray bars indicate the EVs whose prices are lower than the average net utility. The green bars show the best EV, i.e., the EV with the lowest price at time slot t. In this case, as the best prices in both groups are equal, EV2 in the first group is chosen by the grid. Figure 6 shows iterations and NCG convergence. The graph shows that EVs change their energy price with the iterations and reach a stable state, where they achieve maximum utility. The EVs change their prices to increase the selection probability that is given by the grid to EVs. The noncooperative game among the EVs begins for energy trading when the grid assigns selection probabilities to the EVs. 6.1.3.3 Transaction Costs and Execution Time: Figure 7 shows the execution cost of transaction con- firmation. The bubble sizes show that when the number of transactions increases, the transactions’ cumulative ex- ecution cost also increases. It is observed from the graph that system performance suffers when all the transactions of the V2G energy trading auction process run as IOTA transactions. Figure 8 shows the execution time for reading and writ- ing transactions in the IOTA ledger. The bubble sizes show that when the number of IOTA transactions increases, the transaction execution time also increases. This graph also shows that system performance suffers when all read/write transactions of the V2G energy trading auction process run as an IOTA transaction. Figure 9 shows execution cost vs the size of data (in bytes). The graph shows that the execution cost increases with increasing data size. Figure 10 shows a comparison of the traditional blockchain-based auction scheme in [28] and the proposed auction scheme based on the number of IOTA transactions. The graph shows that the number of IOTA transactions for every EV is fixed in the proposed auction scheme, reducing the IOTA transaction execution cost. Only three transactions in the proposed auction scheme are stored in the IOTA ledger (bidding, price agreement, and confirmation of en- ergy transaction). Therefore the proposed auction scheme is more efficient than the traditional blockchain-based auction scheme compared against. consumption ratios. The first and last three hours have an energy production of zero, which means no energy is generated through solar power in these periods. 6.1.3.5 V2G Supply and Production Ratios: Figure 11 shows the supply-to-demand ratio for three EVs for different iterations. EVs must adjust their supply to increase the supply-to-demand ratio [1], as their selection probability increases with increasing supply-to-demand ra- tio. The EVs’ revenue also increases with increases in the supply-to-demand ratio. Figure 12 shows EVs’ production consumption ratio (PCR) on an hour-of-the-day basis. In this experiment, we show the three EVs that have different production-to- Figure 13 shows the grids’ production-to-consumption ratio on an hour-of-the-day basis. It is crucial to investigate the value of PCR to understand the model’s actual high usage at any time. The energy supply and demand and the energy sales/purchase rates also depend on the energy production-consumption ratio. When the PCR value is greater than 1, the EVs sell their excess energy at any time. When the PCR value is less than 1, the grid buys the amount of energy needed by the grid from EVs at any time. but also facilitates a deeper understanding and broader acceptance of the effectiveness of our proposed algorithm in reaching Nash equilibrium. Improving V2G network benefits entails addressing fac- tors such as location privacy, resilience against fake energy offers, optimal price selection, EV distance pricing, and microtransaction support. The proposed model provides location privacy features to protect EVs’ privacy and has built-in resilience against fake energy offers, ensuring that the network remains secure and transparent. The model is designed to select the best price for energy, considering both the grid’s energy demand and the EVs’ availability. The proposed model also considers distance pricing, which can result in more efficient and cost-effective energy manage- ment. By addressing these various aspects of V2G energy trading, the proposed model reduces reluctance for EVs and grids to participate, leading to an overall increase in the network benefit. In this section we discuss how the proposed scheme miti- gates the potential threats discussed in Section 4.2. • T1: Due to the immutable writing of an energy offer by an EV to the ledger along with the deposit of an IOTA coin, it is not possible for an EV to change the selling price after a grid commits to the offer. • T2: The deposit of an IOTA coin with an energy- selling offer prevents a fake energy-selling offer from the EV, as the deposit would be lost. • T3: The automated handling of the payment by the grid through smart contracts prevents the case of a grid not paying for the energy transfer. • T4: All transactions are performed with authentica- tion of the selling and buying parties through their digital IOTA IDs, preventing EVs from masquerad- ing as other EVs to collect payments. • T5: Energy offer transactions are digitally signed by the prosumers and verified by the other parties in DLT, making it impossible to make fake energy offers on behalf of other EVs. • T6: Energy purchase commitments made by grids in the system are digitally signed by the grids, making it impossible to make an energy purchase commitment on behalf of another grid. • T7: The digital signature on the cryptographic hash of each transaction prevents adversaries from modi- fying contents of an energy selling offer to produce the correct signature. • T8: Grid’s digital signature on the bid’s hash ensures tamper-proof energy purchase bids, Leveraging IOTA’s features and a designed energy trading protocol, our system ensures security and fairness. The non-cooperative game model prevents price manipulation, fostering equitable outcomes for all parties involved. 7 CONCLUSION AND FUTURE WORK In this work, we proposed an IOTA-based efficient and secure energy trading model for V2G networks, where EVs 6.1.3.6 EV Pricing and Utility Analysis: Figure 14 shows how the EV selection probability varies with the price. The graph shows that the EV providing a lower price have a higher selection probability than those providing higher prices. The figure shows the changes in price values with color. The red color indicates the minimum probability of selection and maximum price, and the dark blue color shows the maximum likelihood of selection with minimum price. The DV2G algorithm optimizes energy flow between EVs and the grid to minimize costs and maximize revenue. In our model, a privacy-preserving protocol in IOTA pro- tects EV location data. We mitigate risks of fake offers and malicious behavior by implementing a deposit mechanism, ensuring payment based on price agreements before energy transfer. In V2G energy trading, there are chances of fake buyers and sellers, such as EVs making offers for energy they do not have and malicious grids refusing to pay for already bought energy. In the proposed model, we use a deposit mechanism in which each EV deposits some money with every offer of energy selling, and the grid will make its payments with the price agreement, not after receiving the energy to mitigate these threats. In V2G energy trading, the grid always wants to buy energy cheaply. In the DV2G model, the auction selects the EV providing the lowest price. The lowest price may be unsuitable for the grid to buy energy, or multiple EVs may have the lowest price. However, the DV2G model has no mechanism to handle these cases. In the proposed model, we use off-IOTA negotiation, in which the EV and grid negotiate the energy price at time slot t. EV prices are reduced in the proposed model, which increases the grids’ welfare. We have conducted an extensive and meticulous analy- sis, providing substantial evidence to substantiate our claim that the proposed algorithm achieves Nash equilibrium. Our rigorous mathematical analysis demonstrates that the algo- rithm satisfies the conditions for a potential game, which guarantees the existence of a Nash equilibrium. Further- more, our meticulously designed and executed simulation experiments consistently exhibit convergence to Nash equi- librium across a range of scenarios. This comprehensive validation not only fortifies our contribution to the field As part of future work, we aim to extend this study to focus on grid-to-vehicle (G2V) scenarios, exploring en- ergy trading dynamics between grids and individual vehi- cles. Furthermore, we will explore privacy-preserving tech- niques for anonymizing data in G2V energy trading, specif- ically tailored to this context. These research directions will contribute to a more comprehensive understanding of en- ergy trading dynamics in V2G systems and facilitate the de- velopment of robust, secure, and privacy-aware G2V energy trading frameworks. REFERENCES [1] V. Hassija, V. Chamola, S. Garg, D. N. G. Krishna, G. Kaddoum, and D. N. K. Jayakody, “A blockchain- based framework for lightweight data sharing and energy trading in v2g network,” IEEE Transactions on Vehicular Technology, vol. 69, no. 6, pp. 5799–5812, 2020. [2] W. Kempton and S. E. Letendre, “Electric vehicles as a new power source for electric utilities,” Transportation Research Part D: Transport and Environment, vol. 2, no. 3, pp. 157–175, 1997. [3] L. Gan, U. Topcu, and S. H. Low, “Optimal decen- tralized protocol for electric vehicle charging,” IEEE Transactions on Power Systems, vol. 28, no. 2, pp. 940– 951, 2012. [4] M. Kiaee, A. Cruden, and S. Sharkh, “Estimation of cost savings from participation of electric vehicles in vehicle to grid (v2g) schemes,” Journal of Modern Power Systems and Clean Energy, vol. 3, no. 2, pp. 249–258, 2015. and grids negotiate energy prices in an off-chain manner. The main objective of the proposed V2G energy trading model is to encourage more participants in the trading pro- cess to maximize the V2G network welfare. A three-game model is used for optimal price selection with interactions between EVs and grids. A deposit mechanism is proposed for preventing fake energy trading between the EVs and grids, where EVs deposit IOTA coins with energy offers and grids pay with IOTA coins at the time of price agreement. The proposed scheme also protects the location privacy of EVs. We have shown with simulations that the proposed scheme performs better than a recently proposed DLT-based scheme in terms of efficiency, privacy, resilience against fake energy trading, and price. [5] Z. Zhou, B. Wang, M. Dong, and K. Ota, “Secure and efficient vehicle-to-grid energy trading in cyber physical systems: Integration of blockchain and edge computing,” IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 50, no. 1, pp. 43–57, 2019. [6] V. Hassija, V. Chamola, D. N. G. Krishna, and M. Guizani, “A distributed framework for energy trading between uavs and charging stations for critical ap- plications,” IEEE Transactions on Vehicular Technology, vol. 69, no. 5, pp. 5391–5402, 2020. [7] K. Liu, W. Chen, Z. Zheng, Z. Li, and W. Liang, “A novel debt-credit mechanism for blockchain-based data-trading in internet of vehicles,” IEEE Internet of Things Journal, vol. 6, no. 5, pp. 9098–9111, 2019. [8] W. Jiang, H. Li, G. Xu, M. Wen, G. Dong, and X. Lin, “Ptas: Privacy-preserving thin-client authentication scheme in blockchain-based pki,” Future Generation Computer Systems, vol. 96, pp. 185–195, 2019. [9] S. Popov, “The tangle,” cit. on, p. 131, 2016. [10] F. Knirsch, A. Unterweger, and D. Engel, “Privacy- preserving blockchain-based electric vehicle charg- ing with dynamic tariff decisions,” Computer Science- Research and Development, vol. 33, no. 1-2, pp. 71–79, 2018. [11] S. Xia, F. Lin, Z. Chen, C. Tang, Y. Ma, and X. Yu, “A bayesian game based vehicle-to-vehicle electric- ity trading scheme for blockchain-enabled internet of vehicles,” IEEE Transactions on Vehicular Technology, vol. 69, no. 7, pp. 6856–6868, 2020. [12] Y. Li and B. Hu, “A consortium blockchain-enabled secure and privacy-preserving optimized charging and discharging trading scheme for electric vehicles,” IEEE Transactions on Industrial Informatics, 2020. [13] G. Sun, M. Dai, F. Zhang, H. Yu, X. Du, and M. Guizani, “Blockchain enhanced high-confidence en- ergy sharing in internet of electric vehicles,” IEEE Internet of Things Journal, 2020. [14] M. Li, D. Hu, C. Lal, M. Conti, and Z. Zhang, “Blockchain-enabled secure energy trading with ver- ifiable fairness in industrial internet of things,” IEEE Transactions on Industrial Informatics, vol. 16, no. 10, pp. 6564–6574, 2020. [15] M. U. Hassan, M. H. Rehmani, and J. Chen, “Deal: Differentially private auction for blockchain-based mi- crogrids energy trading,” IEEE Transactions on Services Computing, vol. 13, no. 2, pp. 263–275, 2019. [16] H. Liu, Y. Zhang, S. Zheng, and Y. Li, “Electric vehicle power trading mechanism based on blockchain and smart contract in v2g network,” IEEE Access, vol. 7, pp. 160 546–160 558, 2019. [17] Z. Zhou, B. Wang, Y. Guo, and Y. Zhang, “Blockchain and computational intelligence inspired incentive- compatible demand response in internet of electric vehicles,” IEEE Transactions on Emerging Topics in Com- putational Intelligence, vol. 3, no. 3, pp. 205–216, 2019. [18] L. Li, J. Liu, L. Cheng, et al., “Creditcoin: A privacy- preserving blockchain-based incentive announcement network for communications of smart vehicles,” IEEE Transactions on Intelligent Transportation Systems, vol. 19, no. 7, pp. 2204–2220, 2018. [19] T. Zhang, H. Pota, C.-C. Chu, and R. Gadh, “Real-time renewable energy incentive system for electric vehi- cles using prioritization and cryptocurrency,” Applied energy, vol. 226, pp. 582–594, 2018. [20] L. Zhang, L. Cheng, F. Alsokhiry, and M. A. Mo- hamed, “A novel stochastic blockchain-based energy management in smart cities using v2s and v2g,” IEEE Transactions on Intelligent Transportation Systems, vol. 24, no. 1, pp. 915–922, 2022. [21] G. Sharma, A. M. Joshi, and S. P. Mohanty, “Strade: Blockchain based secure energy trading using vehicle- to-grid mutual authentication in smart transporta- tion,” Sustainable Energy Technologies and Assessments, vol. 57, p. 103 296, 2023. [22] Y. Liang, Z. Wang, and A. B. Abdallah, “V2gnet: Robust blockchain-based energy trading method and implementation in vehicle-to-grid network,” IEEE Ac- cess, vol. 10, pp. 131 442–131 455, 2022. J. Qiu, D. Grace, G. Ding, J. Yao, and Q. Wu, “Blockchain-based secure spectrum trading for unmanned-aerial-vehicle-assisted cellular networks: An operator’s perspective,” IEEE Internet of Things Journal, vol. 7, no. 1, pp. 451–466, 2019. [24] H. Cara, Iota’s tangle powers iampass biometric palm vein authentication for digital identity, https://blog.iota.org/ iotas- tangle- powers- iampass- biometric- palm- vein- authentication - for - digital - identity - 3cd0acef8bd9, (Accessed on 07/07/2023). [25] S. Maharjan, Q. Zhu, Y. Zhang, S. Gjessing, and T. Basar, “Dependable demand response management in the smart grid: A stackelberg game approach,” IEEE Transactions on Smart Grid, vol. 4, no. 1, pp. 120–132, 2013. [26] F. Reid and M. Harrigan, “An analysis of anonymity in the bitcoin system,” in Security and privacy in social networks, Springer, 2013, pp. 197–223. [27] W. Tushar, T. K. Saha, C. Yuen, et al., “A motivational game-theoretic approach for peer-to-peer energy trad- ing in the smart grid,” Applied energy, vol. 243, pp. 10– 20, 2019. [28] C. Chen, J. Wu, H. Lin, W. Chen, and Z. Zheng, “A secure and efficient blockchain-based data trading approach for internet of vehicles,” IEEE Transactions on Vehicular Technology, vol. 68, no. 9, pp. 9110–9121, 2019. [29] V. Behrunani, A. Irvine, G. Belgioioso, P. Heer, J. Lygeros, and F. D ¨orfler, “Designing fairness in au- tonomous peer-to-peer energy trading,” arXiv preprint arXiv:2302.04771, 2023. [30] Y. You, Q. Xu, and C. Fischione, “Hierarchical online game-theoretic framework for real-time energy trad- ing in smart grid,” IEEE Transactions on Smart Grid, vol. 15, no. 2, pp. 1634–1645, 2024. [31] W. Wu, J. Zhu, Y. Liu, T. Luo, Z. Chen, and H. Dong, “A coordinated model for multiple electric vehicle aggregators to grid considering imbalanced liability trading,” IEEE Transactions on Smart Grid, vol. 15, no. 2, pp. 1876–1890, 2024.",
         "https://eprints.gla.ac.uk/328280/2/328280.pdf",
         "extracted",
         "None",
         "Hierarchical Online Game-Theoretic Framework for Real-Time Energy Trading in Smart Grid;sTrade: Blockchain based secure energy trading using vehicle-to-grid mutual authentication in smart transportation;Designing Fairness in Autonomous Peer-to-peer Energy Trading;A Consortium Blockchain-Enabled Secure and Privacy-Preserving Optimized Charging and Discharging Trading Scheme for Electric Vehicles;Blockchain-Enhanced High-Confidence Energy Sharing in Internet of Electric Vehicles;A Bayesian Game Based Vehicle-to-Vehicle Electricity Trading Scheme for Blockchain-Enabled Internet of Vehicles;A Distributed Framework for Energy Trading Between UAVs and Charging Stations for Critical Applications;Blockchain-Enabled Secure Energy Trading With Verifiable Fairness in Industrial Internet of Things;A Blockchain-Based Framework for Lightweight Data Sharing and Energy Trading in V2G Network;Blockchain-Based Secure Spectrum Trading for Unmanned-Aerial-Vehicle-Assisted Cellular Networks: An Operator’s Perspective;Electric Vehicle Power Trading Mechanism Based on Blockchain and Smart Contract in V2G Network;A Novel Debt-Credit Mechanism for Blockchain-Based Data-Trading in Internet of Vehicles;A Secure and Efficient Blockchain-Based Data Trading Approach for Internet of Vehicles;PTAS: Privacy-preserving Thin-client Authentication Scheme in blockchain-based PKI;Blockchain and Computational Intelligence Inspired Incentive-Compatible Demand Response in Internet of Electric Vehicles;Real-time renewable energy incentive system for electric vehicles using prioritization and cryptocurrency;CreditCoin: A Privacy-Preserving Blockchain-Based Incentive Announcement Network for Communications of Smart Vehicles;Estimation of cost savings from participation of electric vehicles in vehicle to grid (V2G) schemes;Dependable Demand Response Management in the Smart Grid: A Stackelberg Game Approach;Optimal decentralized protocol for electric vehicle charging;ELECTRIC VEHICLES AS A NEW POWER SOURCE FOR ELECTRIC UTILITIES;Technology;“Anovelstochastic blockchain-basedenergymanagementinsmartcitiesusingV2SandV2G,”;V2GNet: Robust Blockchain-Based Energy Trading Method and Implementation in Vehicle-to-Grid Network;International Semantic Intelligence Conference, ISIC 2021, New Delhi, India, 25 - 27 February 2021, vol.2786 pp.60-66 VII. A Novel SDN Dataset for Intrusion Detection in IoT Networks;“DEAL:Differentiallyprivate auctionforblockchain-basedmicrogridsenergytrading,”;“Secure and efﬁcient vehicle-to-grid energy trading in cyber physical systems: Integration of blockchain andedgecomputing,”;Semantic Intelligence;. A self-protecting agents based model for high-performance mobile-cloud A self-protecting agents based model for high-performance mobile-cloud;“IOTA’s tangle powers IAMPASS biometric palm vein authentication for digital identity,”;“Privacy-preservingblockchain-basedelectricvehiclechargingwithdynamictariffdecisions,”;The Tangle;“Ananalysisofanonymityinthebitcoinsystem,”in;Human-Centric Analysis;AmmarHawbaniiswiththeSchoolofComputerScience,Shenyang AerospaceUniversity,Shenyang110136,China",
         "IOTA-Based Game-Theoretic Energy Trading With Privacy-Preservation for V2G Networks"
        ],
        [
         "17",
         "007e7d6cb64a7dfcdcad9fc6f4f0ba69fdc88203",
         "None",
         "Mingjin Zhang,Xiaoming Shen,Jiannong Cao,Zeyang Cui,Shan Jiang",
         "\n**BLOCK**fs== 7.0**p== 0.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 23.9**p== 0.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nEdgeShard: Efficient LLM Inference via\nCollaborative Edge Computing\n**BLOCK**fs== 11.0**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nMingjin Zhang, Jiannong Cao, Fellow, IEEE, Xiaoming Shen, Zeyang Cui\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nAbstract—Large language models (LLMs) have shown great\npotential in natural language processing and content generation.\nHowever, current LLMs heavily rely on cloud computing, leading\nto prolonged latency, high bandwidth cost, and privacy concerns.\nEdge computing is promising to address such concerns by\ndeploying LLMs on edge devices, closer to data sources. Some\nworks try to leverage model quantization to reduce the model\nsize to fit the resource-constraint edge devices, but they lead\nto accuracy loss. Other works use cloud-edge collaboration,\nsuffering from unstable network connections. In this work, we\nleverage collaborative edge computing to facilitate the collabora-\ntion among edge devices and cloud servers for jointly performing\nefficient LLM inference. We propose a general framework to\npartition the LLM model into shards and deploy on distributed\ndevices. To achieve efficient LLM inference, we formulate an\nadaptive joint device selection and model partition problem and\ndesign an efficient dynamic programming algorithm to optimize\nthe inference latency and throughput, respectively. Experiments\nof Llama2 serial models on a heterogeneous physical prototype\ndemonstrate that EdgeShard achieves up to 50% latency reduc-\ntion and 2x throughput improvement over baseline methods.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nIndex Terms—Large Language Models, Edge Computing, Edge\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nAI, Distributed Machine Learning.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nI. INTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nR Ecently,\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nthe emergence of Large Language Models\n(LLMs) has attracted widespread attention from the\nindustry, and academia, representing a significant\npublic,\nbreakthrough in artificial intelligence (AI). Many players are\ncoming into this field with their advanced models, such as\nOpenAI’s GPT-4 [1], Meta’s Llama [2], and Google’s PALM\n[3]. Built on the foundation of transformer architecture [4],\nLLMs are characterized by their massive scale in terms of\nthe number of parameters and the amount of data they are\ntrained on. The scale of LLMs, often numbering in hundreds\nof billions of parameters, enables the models to capture\ncomplex patterns in language and context, making them highly\neffective at generating coherent and contextually appropriate\nresponses. Such a phenomenon is also known as ”intelligence\nemergence”. The outstanding capability of LLMs makes them\nvaluable and well-performed in a wide range of applications,\nfrom ChatBot and content generation (e.g., text summation and\ncode generation) to assisting tools of education and research.\nHowever, current LLMs heavily rely on cloud computing,\nsuffering from long response time, high bandwidth cost, and\nprivacy concerns [5]. Firstly, the reliance on cloud computing\nhampers the capability for rapid model inference necessary for\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nM. Zhang, J. Cao, and X. Shen, and Z. Cui are with the Department of\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nComputing, The Hong Kong Polytechnic University, Hong Kong.\nE-mail: {csmzhang, csjcao}@comp.polyu.edu.hk\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nFig. 1. Collaborative edge computing integrates the computing resources of\nubiquitous geo-distributed devices for jointly performing computational tasks,\nwith great benefits of enlarged resource pool, low-latency data processing,\nflexible device access, and expanded service region.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.6**r== 0.2**\nimages, audio, and IoT sensing data,\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nreal-time applications such as robotics control, navigation, or\nexploration, where immediate responses are crucial. Secondly,\nthe transmission of large amounts of data, including texts,\nto the cloud\nvideo,\ndata centers leads to substantial bandwidth consumption and\nimmense strain on the network architecture. Thirdly, cloud-\nbased LLMs raise significant privacy issues, especially when\nhandling sensitive data of hospitals and banks, as well as\npersonal data like text inputs and photos on mobile phones.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nEdge computing is a promising solution to address the afore-\nmentioned challenges by deploying LLMs on edge devices\n(e.g., edge servers, edge gateways, and mobile phones) at the\nnetwork edge closer to the data sources [6]. However, LLMs\nare computation-intensive and resource-greedy. For example,\nthe inference of a full-precision Llama2-7B model requires at\nleast 28GB memory, which may exceed the capacity of most\nedge devices. Some works leverage model quantization [7]–\n[12] to reduce the model size to fit into the resource-constraint\nedge devices. However, they often lead to accuracy loss. Other\nworks tend to use cloud-edge collaboration [13], [14], which\npartitions the LLMs into two sub-models and offloads part of\nthe computation workload to the powerful cloud servers with\nhigh-end GPUs. However, the latency between edge devices\nand cloud servers is usually high and unstable.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nAlternatively, we have witnessed the continuous growth\nof the computing power of edge in recent years, and a\nlarge number of edge servers and edge clouds have been\ndeployed at the network edge, leaving significant resources\nto be used. Collaborative edge computing (CEC) [15], [16]\nis hence proposed recently to integrate the computing re-\n**BLOCK**fs== 7.0**p== 1.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nsources of geo-distributed edge devices and cloud servers for\nefficient resource utilization and performance optimization.\nAs shown in Fig. 1, ubiquitous and distributed edge devices\nand cloud servers are connected and form a shared resource\npool, collaboratively providing instant data processing and\nAI services. CEC is different from existing edge computing\nresearch. Existing edge computing research focuses on the\nvertical collaboration among cloud, edge, and end devices,\nwhile neglecting horizontal edge-to-edge collaborations, suf-\nfering from unoptimized resource utilization, restricted service\ncoverage, and uneven performance.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nMotivated by the vision of CEC, we propose a general LLM\ninference framework, named EdgeShard, to support efficient\ncollaborative LLM inference on distributed edge devices and\ncloud servers. For simplicity, we use computing devices below\nto refer to edge devices and cloud servers. Given a network\nwith heterogeneous computing devices, EdgeShard partitions\nthe LLM into multiple shards and allocates them to judicious\ndevices based on the heterogeneous computation and network-\ning resources, as well as the memory budget of devices. To\noptimize performance, we formulate a joint device selection\nand model partition problem and design an efficient dynamic\nprogramming algorithm to minimize the inference latency and\nmaximize the inference throughput, respectively. Extensive ex-\nperiments on a practical testbed show that EdgeShard reduces\nup to 50% latency and achieves 2x throughput over on-device\nand vertical cloud-edge collaborative inference methods.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nOur work is different from those works that partition the\nLLMs and allocate to multiple GPUs in cloud data centers,\nsuch as Gpipe [17] and PipeDream [18]. Deploying LLM at\nedge computing is vastly different from that in the cloud.\nFirst, cloud servers are usually with homogeneous GPUs,\nwhile edge devices are with heterogeneous computation ca-\npabilities in nature. Second, modern cloud GPUs for LLMs\nare usually connected by high-bandwidth networks, such as\nInfiniBand and Nvlinks, while edge devices are connected with\nheterogeneous and low-bandwidth networks. For example, the\nbandwidth of NVlinks can go up to 600GB/s, while the\nbandwidth among edge devices ranges from dozens of Kbps\nto 1000Mbps. The solution of LLMs deployment designed for\ncloud data centers neglect the heterogeneous and resource-\nconstrained edge computing environment.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nOur contributions are three folds.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n• First, we propose a general LLM inference framework\nfor deploying LLMs in the edge computing environment,\nwhich enables the collaborative inference among hetero-\ngeneous edge devices and cloud servers.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n• Further, we quantitatively study how to select computing\ndevices and how to partition the LLM for optimized\nperformance. We mathematically formulate a joint device\nselection and model partition problem, and propose a\ndynamic programming algorithm to optimize the latency\nand throughput, respectively.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n• We also evaluate the performance of EdgeShard with\nstate-of-the-art Llama2 serial models on a physical\ntestbed. Experimental results show EdgeShard remark-\nably outperforms various baseline methods.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nFig. 2. LLM inference has an autoregressive nature.\n**BLOCK**fs== 6.4**p== 1.0**b== 0.6**t== 0.3**l== 0.6**r== 0.1**\nTABLE I\nMINIMUM MEMORY USAGE OF LLMS INFERENCE AND MEMORY\nCAPACITY OF EDGE DEVICES.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.5**r== 0.4**\nLlama2-7B\nLlama2-13B\nLlama2-70B\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nFull\nPrecision\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\n28GB\n52GB\n280GB\n**BLOCK**fs== 8.0**p== 1.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\nEdge\nDevices\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.7**r== 0.3**\n7GB\n13GB\n70GB\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.7**r== 0.2**\n3.5GB\n6.5GB\n35GB\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\nSmartphone(6-12GB)\nJetson Orin(8-16GB)\nJetson AGX(32-64GB)\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nII. PRELIMINARIES AND MOTIVATIONS\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nGenerative LLM Inference. LLMs generally refer to\ndecoder-based transformer models with billions of parameters.\nDifferent from encoder-based architecture like BERT [19],\nwhose inference process is single phase, the process of LLM\ninference is iterative and typically involves two phases: the\nprompt processing phase and the autoregressive generation.\nThe prompt processing phase is also known as prefill.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nIn the prompt processing phase, the model takes the user\ninitial token (x1, ..., xn) as input and generates the first new to-\nken xn+1 by computing the probability P (xn+1 | x1, ..., xn).\nIn the autoregressive generation phase, the model generates\none token at a time, based on both the initial input and the\ntokens it has generated so far. This phase generates tokens\nsequentially for multiple iterations until a stopping criterion\nis met, i.e., either when generating an end-of-sequence (EOS)\ntoken or reaching the maximum number of tokens specified\nby user or constrained by the LLM.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nthe model\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nAs shown in Fig. 2, suppose the LLM model has N layers,\nwhich will take a sequence of input tokens and run all layers\nto generate a token in a one-by-one manner. In the prefill\nphase,\ntakes the input (”Today is a”) at once,\nand the first generated token is ”good.” In the autoregressvie\ngeneration phase, the model first takes (”Today is a good”)\nas input and generates the next token (”day”). It then takes\n(”Today is a good day”) as input and generates the next token\n(”EOS”), which indicates the end of the generation. Since a\ntoken generated is determined by all its previous token in\na sequence, LLMs utilize Key-Value caching (KV caching)\nto avoid repetitive computation, storing past computations to\nexpedite responses, thereby reducing computational workload\nand improving response times. The time to generate a token\n**BLOCK**fs== 7.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 8.0**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nFig. 3. Framework of EdgeLLM. It consists of three stages: offline profiling, task scheduling optimization, and online collaborative LLM inference.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nin the prefill stage is much higher (usually 10x) than that of in\nthe autoregressive stage, as the prefill stage needs to calculate\nthe KV cahche of all input tokens as initialization.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nleast 28GB memory, but\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nLLMs are memory-consuming. A single edge device may\nnot have sufficient memory to accommodate a LLM model.\nTake one of the most popular LLM models, i.e., Llama2,\nas an example. As shown in Table. I, Llama2 has three\ndifferent versions, i.e., 7B, 13B, and 70B. We can see from the\nTable that the full precision inference of Llama2-7B requires\nthe smartphones usually only\nat\nhave 6-12 GB memory, and the Jetson Orin NX has 8-16\nGB memory. They are unable to burden the on-device LLM\ninference. Some works try to use low-precision quantization,\ne.g., 8 bit and 4 bit. However, it may still exceed the memory\ncapacity of edge devices. For example, the 4-bit inference of\nLlama2-70B requires at least 35GB memory, which cannot be\naccommodated on most edge devices. Moreover, low-precision\ninference leads to performance degradation.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nIn this work, we leverage collaborative edge computing,\na computing paradigm where geo-distributed edge devices\nand cloud servers collaborate to perform computational tasks.\nBased on that idea, we propose EdgeShard, a general LLM\ninference framework that allows adaptive device selection and\nLLM partition over distributed computing devices, to address\nthe high memory requirements and leverage heterogeneous\nresources to optimize LLM inference.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nIII. COLLABORATIVE EDGE COMPUTING FOR LLMS\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nThere are three stages of the framework, including profiling,\ntask scheduling optimization, and collaborative inference. The\nworkflow is shown in Fig. 3.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nProfiling is an offline step that profiles the necessary run-\ntime traces for the optimization step and only needs to be\ndone once. Those traces include: 1) the execution time of\neach layer on different devices; 2) the size of activations and\nmemory consumption for each layer of the LLM model; 3)\navailable memory of each device and the bandwidth among\ndevices. For the execution time of each layer, we profile the\ntime to generate a token in the prefill stage and autoregressive\nstage, respectively, and take the average. For those devices\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\n(a) Sequential inference\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\n(b) Pipeline parallel inference\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\nFig. 4. Collaborative LLM inference\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nthat may not have efficient memory to hold the full model for\nperforming the profiling, we utilize a dynamic model loading\ntechnology, where the model layers are consecutively loaded\nto fit the constrained memory. The profiling information will\nthen be used to support intelligent task scheduling strategies.\nScheduling Optimization. At the task scheduling optimiza-\ntion stage, the scheduler generates a deployment strategy by\ndetermining which device to participate in, how to partition\nthe LLM model in a layer wise, and which device should the\nmodel shard be allocated to. The strategy thoroughly considers\nthe heterogeneous resources, the memory budget of devices,\nand the privacy constraint, and later be applied to selected\ndevices for efficient LLM inference. More details is described\nin Sec. IV.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nCollaborative inference. After getting the LLM model par-\ntition and allocation strategy, the selected devices will perform\nthe collaborative inference. We pre-allocate memory space for\nKV cache on each participating device. We consider two cases\nfor the collaborative inference, i.e., sequential inference and\npipeline parallel inference.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIn sequential inference, devices take turns to perform the\ncomputation with the allocated model shards. As shown in\nFig. 4(a), suppose the LLM model is partitioned into 3 shards\nand allocated to device 1, 2, and 3, respectively. Device 1 will\nfirst process the input data and then send the activations/out-\nputs to device 2, which will process the data and then transmit\nto device 3. Sequential inference is suitable for serving a single\nuser, such as in smart home scenario, where users’ personal\ndevices (e.g., tablet, phones, and smart speaker) collaborate to\nperform LLM inference. In such scenario, user inputs a prompt\n**BLOCK**fs== 7.0**p== 3.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 6.4**p== 3.0**b== 0.9**t== 0.1**l== 0.2**r== 0.7**\nTABLE II\nLIST OF NOTATIONS\n**BLOCK**fs== 8.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.9**\nSymbol\nXi,j\n**BLOCK**fs== 6.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.9**\nti,j\ncomp\nti→m,j\ncomp\nti−1,k,j\ncomm\n**BLOCK**fs== 8.0**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nDescriptions\nbinary variable, whether layer i of a model is allocated to\ndevice j\ncomputation time of layer i on device j\ncomputation time of layer i to layer m on device j\ncommunication time to transmit activations of layer i−1 from\ndevice k to device j\n**BLOCK**fs== 8.0**p== 3.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nDP (i, j) minimal total execution time of the first i layers if layer i is\n**BLOCK**fs== 8.0**p== 3.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nallocated to device j\nprocessing time of the slowest node to process the first i\nlayers with device set S\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nand gets the response and then input another prompt. We aims\nto minimize the latency of sequential inference.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nHowever, sequential inference is not resource-efficient from\nthe system’s perspective. When device 1 is performing com-\nputation, device 2 and device 3 are idle. We thus take pipeline\nparallelism to improve resource utilization. For the pipeline\nparallel inference as taken in previous work Gpipe [17] and\nPipeDream [18] for cloud servers, the input data will first be\nsplit into micro-batch and subsequently feed into the system.\nAs depicted in Fig. 4(b), device 1 first handles data B1 and\nthen transmits intermediate data to device 2. After handling\ndata B1, device 1 immediately goes to handle data B2. In\nsuch a pipeline manner, every device is busy with high system\nresource utilization.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nIV. OPTIMIZE LLM INFERENCE\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nWe consider a general collaborative edge network with het-\nerogeneous devices and bandwidth connection. More specif-\nically, given a set of heterogeneous devices connected with\nheterogeneous bandwidth, EdgeShard aims to select a subset\nof devices and partition the LLM into shards, which will be\nallocated to the selected devices to minimize the inference\nlatency or maximize the throughput.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nSystem Model. LLMs usually have a layered architecture,\nwhich consists of an embedding layer, multiple decoder layer,\nand an output layer. Sizes of parameters and activations (i.e.,\nthe output of a layer) vary across layers. We assume the model\nis with N layers. Oi represents the size of activations of layer\ni, 0 ≤ i ≤ N − 1. The memory consumption of a layer i is\ndenoted by Reqi.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nWe consider a network consisting of M edge devices and\ncloud servers. The devices have heterogeneous computation\nand memory capabilities, and cloud servers are much more\npowerful than edge devices in terms of computation capability.\nThe memory budget of a device j is M emj. The computing\ndevices are interconnected. Bandwidth between a device k and\na device j is Bk,j, 0 ≤ k ≤ M − 1, 0 ≤ j ≤ M − 1. There\nis a source node where the input tokens reside. Without loss\nof generality, we set the source node as node 0. The main\nnotations used in this paper are shown in Table. II.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nA. Optimize LLM inference latency\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nProblem Formulation. We use a binary variable Xi,j to\ndenote the LLM allocation strategy. Xi,j equals to 1 if layer\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\nj=0 Xi,j = 1, ∀i. Let ti,j\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\ni is allocated to node j. Otherwise, Xi,j equals to zero. A\nlayer will be and only be allocated to one node. Hence, we\nhave M −1\ncomp denotes the computation\ntime of layer i on node j. Suppose layer i − 1 and layer i are\nallocated to node k and node j, respectively. We use ti−1,k,j\ncomm to\ndenote the communication time to transmit the activations of\nlayer i − 1 from node k to node j. The data transmission time\nis determined by the output size of a layer and the bandwidth\nbetween two nodes. If layer i − 1 and layer i are on the same\nnode, we assume the transmission time is zero. Hence, we\nhave\n**BLOCK**fs== 7.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nti−1,k,j\ncomm =\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.8**r== 0.2**\notherwise.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\nThe total\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\ninference time can thus be calculated by the\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nfollowing equation.\n**BLOCK**fs== 7.0**p== 3.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nXi,j∗ti,j\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\n(2)\nthe problem of minimizing the LLM inference\nlatency can be formulated as follows, where Eq. (4) is the\nprivacy constraint. It shows that the first layer of the LLM\nmodel should always be allocated to node 0, which is set to\nbe the source node with input tokens. In such a case, the\nraw input data resides on the source node and avoids to be\ntransmitted among computing devices. Eq. (5) shows that the\nmemory requirements of all the layers allocated to node j\ncannot exceed its memory budget.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nmin Ttol\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nXi,j ∗ Reqi ≤ M emj\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nSolution. To minimize the inference latency, we design\na dynamic programming algorithm. The intuition is that the\nminimal execution time of the first i layer is determined by\nthe first i − 1 layer, which means the optimal solution can be\nconstructed from the optimal results of the sub-problems. It\nhas the optimal sub-problem property, which motivates us to\nuse dynamic programming.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nLet DP (i, j) denote the minimal total execution time of the\nfirst i layers after the layer i is allocated to the node j. The\nstate transition equation is formulated as:\n**BLOCK**fs== 7.0**p== 3.0**b== 0.1**t== 0.8**l== 0.6**r== 0.3**\nmin\nk∈M\n1≤i<N −1\nmin\nk∈M\ni=N −1\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\n(DP (i − 1, k) + ti,j\n**BLOCK**fs== 7.0**p== 3.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\ncomp + ti−1,k,j\ncomm )\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.7**r== 0.2**\n(DP (i − 1, k) + ti,j\n**BLOCK**fs== 7.0**p== 3.0**b== 0.1**t== 0.9**l== 0.8**r== 0.1**\ncomp + ti−1,k,j\n**BLOCK**fs== 7.0**p== 3.0**b== 0.1**t== 0.9**l== 0.9**r== 0.1**\ncomm + ti,j,0\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n(6)\nWhere DP (i − 1, k) indicates the minimal execution time\nof the first i − 1 layers if layer i − 1 is allocated to device k.\nEq. (6) shows that DP (i, j) is determined by traversing at all\npossible nodes of the previous layer and choosing the one that\n**BLOCK**fs== 7.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nminimizes the execution time of the first i layers. Moreover,\ndue to the autogressive nature of LLM, the generated token\nneeds to be sent back to the source node for next iteration of\ngeneration. Hence, for the last layer N −1, the communication\ntime not only includes the data transmission time from the\nN − 2 layer, but also the transmission time to the source\nnode tN −1,j,0\ncomm . Additionally, we initialize DP (0, 0) as shown\nin Eq. (7) by considering the privacy constraint.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nAlgorithm 1: Joint device selection and LLM partition\nfor optimizing latency\nInput: A LLM model; Computing device M ; Profiled\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\ntraces; bandwidth Bk,j;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nOutput: the device selection and LLM partition\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nstrategy\n// initialization\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n1 Initialize DP table DP (i, j) = IN F , and choice table\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nchoice(i, j) = N U LL to record the strategy;\n2 Enforce first layer to be allocated to node 0 by\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nBy traversing each layer and each node based on Eq. (6),\nwe can fill in the dynamic programming table DP (i, j) to\ntrack the minimum total execution time to reach each layer.\nFinally, the minimal total execution time at the last layer can\nbe calculated by Eq. (8). We can then get the optimal node\nallocation for each layer by backtracking DP (i, j).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nminj=0,...,M −1(DP (N − 1, j))\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nThis method is simple and effective. With dynamic pro-\ngramming, we can quickly traverse the solution space and find\nthe best LLM partition and allocation strategy. The algorithm\nto find the optimal LLM partition and allocation strategy for\nminimizing inference latency is shown in Algo. 1.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nIn Algo. 1, we first initialize the dynamic programming\ntable DP (i, j) and choice table choice(i, j) (lines 1-2). We\ninitialize DP (0, 0) according to Eq. (7). The choice(i, j)\nrecords the node k to host the i − 1 layer. It is the optimal\nvariable of Eq. (6). We then traverse the layers of the large\nlanguage model from layer 1. For each layer, we traverse all\nthe computing devices with sufficient memory and calculate\nthe inference time (lines 3-19). After filling the DP table, we\ncan find the minimal DP (N − 1, j), which represents the\nminimal time for executing the LLM model, and the last node\nto host layer N − 1. Finally, by backtracing choice(i, j), we\nget the model partition and allocation strategy R (lines 20-28).\nThe computational complexity of Algo. 1 is O(N × M × M ),\nwhere N is the number of layers of the LLM model and M\nis the number of devices in the network.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nB. Optimize LLM inference throughput\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nProblem Formulation. For optimizing throughput, pipeline\nparallelism is adopted to avoid device idleness. As illustrated\nbefore, the computation time of layer i on node j is ti,j\ncomp, and\nif layer i to layer m are all allocated to node j, the computation\ntime is indicated by ti→m,j\ncomp . The data transmission time of\nthe activations of layer i − 1 from node k to node j is\nti−1,k,j\ncomm . In pipeline parallel inference, the computation time\nand communication time can be overlapped to maximize the\nthroughput. Thus, for the inference task, the maximum latency\nfor the device j can be calculated as:\n**BLOCK**fs== 7.0**p== 4.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nT j\nlatency = max\n**BLOCK**fs== 7.0**p== 4.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\n ti→m,j\ncomp\nti−1,k,j\ncomm\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nIdeally, for the selected devices, achieving the maximal\nto minimizing the latency of the\nthroughput\nslowest device. We use S to denote the selected devices, and\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nis equivalent\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nDP (0, 0) = t0,0\n// fill in the DP table\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.6**r== 0.2**\ncomp and choice(0, 0) = 0;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\n3 for i = 1 to N − 1 do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nfor j = 0 to M − 1 do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nif M emj ≤ Reqi then\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\nContinue;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nend\nelse\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nfor k = 0 to M − 1 do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nCalculate the total execution time by\nEq. (6) and assign it to ttotal;\nif ttotal ≤ DP (i, j) then\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.7**r== 0.1**\nUpdate DP (i, j) by assigning\nDP (i, j) = ttotal;\nUpdate memory M emj;\nRecord allocation plan\nchoice(i, j) = k;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n// backtrace for allocation strategy\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\n20 Initialize optimal strategy R;\n21 Find the last selected node\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nNlast = argminj(DP (N − 1, j));\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nFind the previous node Nlast = choice(i, Nlast);\nAdd Nlast to R;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.3**\n22 Add Nlast to R;\n23 for i = N − 1 to 0 do\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\n26 end\n27 Reverse R;\n28 return R;\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nthen the problem of maximizing the inference throughput can\nthus be formulated as follows, where j ∈ S.\n**BLOCK**fs== 7.0**p== 4.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nlatency|j ∈ S}\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nSolution. Similar to minimizing the inference latency, the\nproblem of maximizing the throughput also has an optimal\nsub-problem property. Maximizing the throughput of the first\ni layer can be deduced from solving the problem of allocating\nthe first i−1 layer, which indicates that the optimal solution of\nthe whole problem can be constructed from the sub-problems.\nWe also use dynamic programming to solve the problem.\n**BLOCK**fs== 7.0**p== 5.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nLet g(i, S, k) denote the minimum time to process the first\ni layers with the set of used devices S, and the device k is\nthe last node to be used, k ∈ S. We use g(m, S′, j) to denote\nthe next state to process the first m layers with the set of used\ndevices S′, and the device j is the last node to be used, where\n0 ≤ i < m ≤ N − 1, j ∈ M \\ S, S′ = S ∪ {j}.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nThe state transition equation is formulated in Eq.\nis determined by the previous\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n(11),\nwhere g(m, S′, j)\nstate\ng(i, S, k), and the maximum latency of devive j, i.e., the com-\nputation time ti−1,k,j\ncomp . The\nfinal optimal solution T opt\nthrou is the minimum g(N − 1, S′, j),\nwhere S′ ⊆ M .\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\ncomm and the communication time ti→m,j\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nAlgorithm 2: Joint device selection and LLM partition\nfor optimizing throughput\nInput: A LLM model; Computing devices M ; Profiled\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\ntraces; bandwidth Bk,j;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nOutput: the device selection and LLM partition\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nstrategy R\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\n// initialization\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n1 Initialize DP table g(i, S, k) = IN F , and choice table\nchoice(m, S, j) = N U LL to record the strategy;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n2 Enforce first layer to be allocated to node 0 by\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\ng(1, 1, 0) = t0,0\n// fill in DP table\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\ncomp and choice(1, 1, 0) = (0, 0, 0);\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.8**\ng(m, S′, j)\nS′=S∪{j}\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.3**l== 0.2**r== 0.7**\nmin\n0≤i<m≤N −1\nj∈M \\S\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.3**l== 0.4**r== 0.6**\ng(i, S, k)\nti−1,k,j\ncomm\nti→m,j\ncomp\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nAdditionally, we have constraints when performing state\ntransition. They are the memory constraint shown in Eq. (12)\nand privacy constraint in Eq. (13).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nReqi→m ≤ M emj\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nAlgo. 2 describes the pseudo-code to find the optimal solu-\ntion T opt\nthrou and the corresponding model partition and alloca-\ntion strategy. In Algo. 2, we first initialize the dynamic pro-\ngramming table g(m, S′, j) and choice table choice(m, S, j),\nand assign t0,0\ncomp to g(1, 1, 0) (lines 1-2). We then traverse\nthe layers of the large language model from layer 1. For each\nlayer, we traverse all the computing devices with sufficient\nmemory and calculate the maximum latency (lines 3-23). After\nfilling the DP table, we can find the maximum latency, based\non which we then backtrace the choice table and finally get\nthe model partition and allocation strategy (lines 24-32). The\ncomputational complexity of Algo. 2 is O(N 2 × 2M × M 2),\nwhere N is the number of layers of the LLM model and M\nis the number devices in the network.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nPipeline Execution Optimization. Note that\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nthe above\nproblem formulation and solution are based on the ideal case,\nwhere there is no idle device at any time. A device processes\na batch of data and continues to handle another batch of data\nwithout waiting. However, it is impractical for LLM inference\nin real-world cases.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nAs shown in Fig. 5(a), different from those one-phase\ncomputation applications, the decoder-based LLM application\nhas an autoregressive nature, where there will be multiple\ntokens to be generated and the calculation of the current token\nrelies on all the previous tokens. The computation of the\ncurrent token cannot start until it gets the previously generated\ntoken. It leads to bubbles in pipeline execution.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nTo approximate the ideal case and enhance the resource\nutilization for improving throughput, we tend to reduce the\nbubbles in the pipeline execution. We propose EdgeShard-No-\nbubbles, which allows for immediate token generation without\nwaiting for the ending of all micro-batches in an iteration. As\nshown in Fig. 5(b), after the prefill stage P 1 ends of the first\nbatch, Device 1 immediately executes the token generation of\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\n3 for i = 1 to N − 1 do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.6**r== 0.2**\nfor each subset S ⊆ M do\nfor last node k ∈ S do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.6**r== 0.2**\nfor m = i + 1 to N − 1 do\nfor j ∈ M \\ S do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\nif M emj ≤ m\nContinue;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\ni Reqi then\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\nend\nelse\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.7**r== 0.1**\nGet S′ by adding node j to the\nselected device set S;\nCalculate current mamixum\nexecution time Tmax via\nEq. (11) for the maximum\nexecution time in all stages;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.7**r== 0.1**\nend\nif Tmax ≤ g(i, S, k) then\ng(m, S′, j) = Tmax;\nRecord the current strategy\nchoice(m, S′, j) = (i, j, k);\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n// backtrace for optimal allocation\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n24 Initialize optimal strategy R;\n25 Find selected device set S and the last selected node\nNlast by S, Nlast = argminS,k(g(N − 1, S, k));\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.5**r== 0.3**\n26 Initialize layer = N − 1;\n27 while layer > 0 do\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.6**r== 0.2**\n(i, j, k) = choice(layer, S, Nlast);\nAdd (i → layer, j) to R;\nUpdate layer, S and Nlast;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\n31 end\n32 return R;\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nthe first batch as indicated by G1A. Similarly, when G1A ends,\nDevice 1 goes to the next iteration of token generation indi-\ncated by G1B. Compared to EdgeShard-Bubbles, EdgeShard-\nNo-bubbles reduces bubbles by mitigating device idle time\nand is expected to improve throughput. From the pipeline\nexecution graph in Fig. 5, we can see that EdgeShard-No-\n**BLOCK**fs== 7.0**p== 6.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.5**\n(a) Bubbles\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.3**l== 0.5**r== 0.4**\n(b) No-bubbles\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFig. 5. Different pipeline execution strategies of EdgeShard. EdgeShard-No-bubbles reduces device idle time to improve throughput by allowing immediate\ntoken generation of a micro-batch without waiting for other micro-batches.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n2023 and is one of the most popular and powerful open-\nsource large language models, representing a groundbreaking\nleap in the field of artificial intelligence and natural language\nprocessing. For the model inference, we adopt the text gen-\neration task to test the performance. We use the WikiText-2\ndataset [21] from HuggingFace. We extract a subset of samples\nwith the length of input tokens as 32 and generate 96 tokens.\nWe use full-precision model inference in all the following\nexperiments.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nBaselines. We compare the performance in terms of latency\nand throughput of EdgeShard with various baselines. (We\ndon’t use the cloud-only as a baseline because it requires the\ninput token to be transmitted to the cloud server, which may\nlead to privacy concerns).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n• Edge-Solo. In this case, the LLMs are deployed locally\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\non an edge device without model partition.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\n• Cloud-Edge-Even. In this case, the LLMs are evenly\npartitioned into two parts. One is allocated to the edge\ndevice, and another is allocated to the cloud server.\n• Cloud-Edge-Opt. In this case, the LLMs are partitioned\ninto two shards. One is allocated to the edge device, and\nanother is allocated to the cloud server. For the partition\nstrategy of LLMs, we also use the proposed dynamic\nprogramming algorithms. The difference is that there is\nonly two devices as the algorithm input.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\nB. Overall Evaluation\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nWe set AGX Orin as the source node and the bandwidth\nbetween the source node and the cloud server as 1Mbps.\nThe bandwidth between other computing devices is set to\nbe 50Mbps with a variance of 20%. To test the throughput,\nwe set the batch size as the maximum batch size that the\nparticipating devices can support. The latency and throughput\nof LLM inference are shown in Table. IV.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nFig. 6. Our testbed has heterogeneous edge devices and cloud server. Their\nspecifications are shown in Table III.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nTABLE III\nSPECIFICATIONS OF HETEROGENEOUS PHYSICAL DEVICES\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nCategory\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nDevice\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nMemory\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nAI Performance\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.8**\nEdge Device\nEdge Device\nCloud Server\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.6**l== 0.2**r== 0.7**\nJetson AGX Orin\nJetson Orin NX\nRTX 3090\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.6**l== 0.3**r== 0.6**\n32GB\n16GB\n24GB\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.6**l== 0.4**r== 0.5**\n3.33 TFLOPS\n1.88 TFLOPS\n36 TFLOPS\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nbubbles generates more tokens at the same time.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nV. EXPERIMENTAL EVALUATION\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\nA. Experimental Setup\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nTestbed. We use various edge devices and cloud servers to\nact as the heterogeneous computation devices in collaborative\nedge computing. The specifications of those devices are listed\nin Table. III. We use 15 devices, including 12 Jetson AGX\nOrin, 2 Jetson Orin NX, and one cloud server to configure the\ncollaborative edge network. The physical testbed is shown in\nFig. 6. Those devices are connected with a route and a switch.\nThe bandwidth between any two devices is 1000Mbps. We\nuse the Linux TC tool [20] to vary network bandwidth and\ncommunication latency between devices.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nBenchmarks. We test the performance of EdgeShard with a\nseries of Llama2 models [2], including Llama2-7B, Llama2-\n13B, and Llama2-70B. Llama2 is released by Meta in July\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWe have the following observations. First, EdgeShard is\npotential and beneficial for large language model deployment.\nFor Llama2-70B model, the memory requirement is about\n**BLOCK**fs== 7.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 6.4**p== 7.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nTABLE IV\nPERFORMANCE OF LLM INFERENCE. (AVERAGE LATENCY: MILLISECONDS/TOKEN; THROUGHPUT: TOKENS/SECOND).\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nLlama2-7B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nLlama2-13B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nLlama2-70B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nEdge-Solo\nCloud-Edge-Even\nCloud-Edge-Opt\nEdgeShard\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.4**r== 0.6**\nLatency\n140.34\n227.35\n140.34\n75.88\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nThroughput\n24.36\n7.56\n24.36\n52.45\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nLatency\nOOM\n319.44\n243.45\n173.43\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.6**r== 0.4**\nThroughput\nOOM\n4.68\n4.74\n10.45\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.7**r== 0.3**\nLatency\nOOM\nOOM\nOOM\n3086.43\n**BLOCK**fs== 8.0**p== 7.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nThroughput\nOOM\nOOM\nOOM\n1.25\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\n(a) Llama2-7B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\n(b) Llama2-13B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n(c) Llama2-70B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nImpact of Network Bandwidth to Latency of Collaborative LLMs inference\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\n(a) Llama2-7B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\n(b) Llama2-13B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\n(c) Llama2-70B\n**BLOCK**fs== 8.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nImpact of Bandwidth to Throughput of Collaborative LLMs Inference\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\n280GB, which far exceeds the memory capacity of solo edge\ndeployment and cloud-edge collaborative deployment. They\nwill have the out-of-memory issue (OOM). However, Edge-\nShard tackles this challenge by splitting the large model into\nshards and allocating them to multiple devices, enabling col-\nlaborative model inference. Second, EdgeShard achieves obvi-\nously lower inference latency and higher inference throughput\nthan baseline methods. For Llama2-7B model, EdgeShard\nachieves 75.88ms latency, which is about 1.85x faster than\nEdge-Solo and Cloud-Edge-Opt, and about 3x faster than\nCloud-Edge-Even. For the inference throughput, EdgeShard\nachieves 52.45 tokens per second with a maximum batch size\nof 8, which is around 2.2 times larger than Edge-Solo and\nCloud-Edge-Opt, and about 7 times larger than Cloud-Edge-\nis also observed\nEven. Similar performance improvement\nfor Llama2-13B model, where EdgeShard achieves 45.7%\nand 28.8% lower latency than Cloud-Edge-Even and Cloud-\nEdge-Opt, respectively. Also, EdgeShard has 2.23x and 2.2x\nhigher throughput than Cloud-Edge-Even and Cloud-Edge-\nOpt. Third, we can also see that, for Llama2-7B, Cloud-Edge-\nOpt tends to have the same performance in terms of both\ninference latency and throughput as Edge-Solo. This is because\nthe bandwidth between the source node and the cloud server\nis very limited in this experimental setting, i.e., 1Mbps. The\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\noptimal deployment strategy of Cloud-Edge-Collaboration is\nlocal execution, which is the same as Edge-Solo.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\nC. Effects of Bandwidth\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nWe set the source node as AGX Orin and vary the bandwidth\nbetween the cloud server and the source node from 1Mbps to\n50Mbps. The performance of the latency and throughput of\nLLM inference are shown in Fig. 7 and Fig. 8, respectively.\nFor Llama2-13B, a single AGX Orin cannot accommodate\nthe full model. We only compare the performance among\nCloud-Edge-Even, Cloud-Edge-Opt, and EdgeShard. Simi-\nlarly, due to the memory constraint, the three baseline methods\nare not able to deploy the Llama2-70B model. Instead, we\ncompare the performance of EdgeShard with its variant, i.e.,\nEdgeShard-Even, where the model is equally partitioned and\ndeployed to all the participating computing devices. It selects\n11 AGX Orin and 1 RTX 3090 to deploy the Llama2-70B\nmodel.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIn terms of latency, except for Edge-Solo, the latency of the\nother three methods decreases with the increasing bandwidth.\nThis is because the three methods are collaboration-based,\nand the latency is influenced by the data transmission time.\nThe increasing bandwidth leads to reduced communication\n**BLOCK**fs== 7.0**p== 8.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\ntime. We can also see that for the collaboration methods,\nthere is a dramatically latency reduction when the cloud-\nsource bandwidth changes from 1Mbps to 10Mbps and a\nminor variance from 10Mbps to 50Mbps. This is because\nthe bandwidth is gradually saturated at that time, and the\ncomputation time becomes the bottleneck.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nMoreover, we can see that when the bandwidth is greater\nthan 10Mbps, cloud-edge collaboration methods outperform\nthe Edge-Solo method, as the cloud-edge collaboration meth-\nods introduce the powerful cloud server for computation\nacceleration. However, when the bandwidth is 1Mbps, Cloud-\nEdge-Even performs worse than EdgeSolo. This is because the\ndata transmission cost is high in this case. The Cloud-Edge-\nOpt method tends to deploy the LLM model locally, which is\nthe same as the Edge-Solo method. Interestingly, the latency of\nCloud-Edge-Opt and EdgeShard is nearly the same when the\nbandwidth is greater than 10Mbps. We found that EdgeShard\ngenerates the same model partition and allocation policies as\nthe Cloud-Edge-Opt method. The variance comes from the\nsmall fluctuations in model execution. It shows that the per-\nformance of EdgeShard will not be worse than that of Cloud-\nEdge-Opt, and the Cloud-Edge-Opt method is a special case of\nEdgeShard. A similar pattern is also observed for Llama2-13B.\nFor Llama2-70B, EdgeShard performs better than its variant\nEdgeShard-Even, as there is resource heterogeneity among\ncloud server and edge devices, and EdgeShard adaptively\npartitions the LLMs among computing devices. However, the\nperformance improvement is not so obvious as there are 11\nAGX with the same computation capacity and only 1 RTX\n3090.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nIn terms of throughput, similar patterns to the latency\nevaluation are also found for Llama2-7B model. Differently\nand interestingly, for Llama2-13B, EdgeShard does not show\na closing performance with the Cloud-Edge-Opt method when\nthe bandwidth is 10Mbps, but with a great\nimprovement,\nwhere EdgeShard has about 2x higher throughput than the\nCloud-Edge-Opt method. This is because of the high memory\nconsumption of the RTX 3090 and the source node,\ni.e.,\nAGX Orin. We observed that for the Cloud-Edge-Opt, the\nmemory consumption of the two devices goes up to 95%\nand 98%, respectively, which only allows for a maximum\nbatch size of 4. Otherwise, there will not be enough memory\nfor the KV cache on the computing devices. However, when\nthe bandwidth is 10Mbps, EdgeShard involves several edge\ndevices where the memory consumption of an individual\ndevice becomes dramatically decreased, allowing for a larger\nbatch size, i.e., 8 in this case. When the bandwidth is higher\nthan 10Mbps, EdgeShards tends to have the same model\npartition and allocation strategy as Cloud-Edge-Opt, which\nyields a closing performance, as shown in Llama2-7B. For\nLlama2-70B,\nimprovement of\nEdgeShard, and EdgeShard-Even shows a steady throughput\nas the evenly partition strategy will not change with the cloud-\nsource bandwidth.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nthere is a slight\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\nthroughput\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nD. Effects of Source Node\n**BLOCK**fs== 8.0**p== 8.0**b== 0.7**t== 0.3**l== 0.7**r== 0.2**\n(a) Llama2-7B - Latency\n**BLOCK**fs== 8.0**p== 8.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n(b) Llama2-7B - Throughput\n**BLOCK**fs== 8.0**p== 8.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nImpact of Source Node\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\ndifferent computation and memory capacities, and EdgeShard\nenforces the first layer of LLM models residing on the source\nnode to avoid raw data transmission. We set the source node\nas AGX Orin and Orin NX, respectively, and compare their\nperformance. We set the bandwidth between the source node\nand the cloud server as 1Mbps. The results of Llama2-7B\ninference are shown in Fig. 9.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nWe find that when the source node is Orin NX, the Edge-\nSolo and Cloud-Edge-Even methods encounter the OOM error.\nThis is due to the relatively lower memory of Orin NX, which\ncannot accommodate the Llama2-7B model, even for half part\nof the model. The difference between the two cases under the\nCloud-Edge-Opt method is much more obvious than that of\nEdgeShard. For Cloud-Edge-Opt, there is about a 60ms gap,\nand for EdgeShard, the gap is about 5ms. This is because there\nare only two devices in the Cloud-Edge-Opt case, and it tends\nto put more layers on the source node. However, AGX Orin is\nmuch more powerful than Orin NX in terms of computation\ncapacity. EdgeShard tends to involve more devices and put\nfewer model layers on the source node, which can fill in\nthe gap in computation capacity between the source nodes. A\nsimilar phenomenon is also observed for the throughput, where\nAGX Orin has 6x higher throughput than Orin Nx for the\nCloud-Edge-Opt method and only 2x higher throughput under\nthe EdgeShard method. It shows EdgeShard can make full use\nof the computation resources in the network to optimize the\nperformance.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nE. Effects of Pipeline Execution strategy\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWe evaluate the two pipeline execution strategies. We set\nthe bandwidth between the cloud server and the source node\nas 1Mbps. The results are shown in Fig. 10.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nWe also test\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nthe influence of the source node on the\ninference latency and throughput, as the source node may have\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWe can see that for all methods, EdgeShard-No-bubble\noutperforms EdgeShard-Bubble. Specifically, for Llama2-7b,\n**BLOCK**fs== 7.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.1**l== 0.5**r== 0.1**\nOther works [13], [14] tend to leverage the cloud-edge\ncollaboration to partition and distribute the massive compu-\ntation workload of LLM inference and finetuning. Wang et\nal. [13] increase the throughput by distributing the computa-\ntion between cloud servers and edge devices, and reducing\nthe communication overhead of transmitting the activations\nbetween the central cloud and edge devices by leveraging\nthe low-rank property of residual activations. Chen et al. [14]\nefficiently leverage location-based information of edge devices\nfor personalized prompt completion during collaborative edge-\ncloud LLM serving. However, the latency between edge de-\nvices and the central cloud is usually high and unstable, which\nwill affect the inference and finetuning performance of LLM.\nOur work is different from those works. We propose a\ngeneral framework to integrate the computation resources of\nheterogeneous and ubiquitous cloud servers and edge devices.\nThe framework allows the adaptive selection of computation\ndevices and partition of the computation workload of LLM\ninference for optimized latency and throughput.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nB. LLM for Optimizing Edge Computing\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.4**l== 0.5**r== 0.1**\nLLMs also have great potential in making complex and\ncoherent decisions. There are also some works that leverage\nLLM to optimize resource utilization in edge computing,\nsuch as resource allocation and task offloading, network man-\nagement, and intelligent IoT control. Li et al. [22] propose\nLAMBO, a LLM-based task offloading framework for mo-\nbile edge computing, to address the challenging issues of\nheterogeneous constraints, partial status perception, diverse\noptimization objectives, and dynamic environment that are not\nwell addressed in traditional task offloading research. LAMBO\nshows that LLM is more effective compared to traditional\nDNN and deep reinforcement learning-based methods in com-\nplex and dynamic edge computing environments. They further\ndesign a LLM-based multi-agent system and incorporate com-\nmunication knowledge and tools into the system, empowering\nit with the ability to optimize semantic communication in\na 6G network [23]. Apart from optimization of resource\nutilization, Shen et al. [24] leverage the outstanding abilities of\nGPT in language understanding and code generation to train\nnew models among federated edge devices. Rong et al. [25]\nleverage LLMs to generate adaptive control algorithms for\naddressing the diverse, dynamic, and decentralized network\nconditions in 6G integrated terrestrial network (TN) and non-\nterrestrial network (NTN). Though LLMs have shown great\npotential in making intelligent decisions, especially in complex\nand dynamic edge computing systems, the related research is\nstill in the early stages. Challenges such as significant resource\nconsumption, latency of decision-making, and uncertainty of\ngenerated decisions need further studies.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.9**l== 0.6**r== 0.1**\nVII. DISCUSSION AND FUTURE WORKS\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nThis section discusses some open issues and future works\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.3**\nthat may appeal to readers.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIncentive mechanisms. In this work, we partition the\nLLM into multiple shards and allocate them to heterogeneous\ndevices. For edge computing scenarios, such as smart home\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\n(a) Llama2-7B - Throughput\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\n(b) Llama2-13B - Throughput\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nImpact of Pipeline Execution Strategy\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nEdgeShard-No-bubble achieves an improvement of about 0.36\nand 6.96 tokens per second than Edgeshard-bubble for Cloud-\nEdge-Even and EdgeShard, respectively. For the Cloud-Edge-\nOpt method, it selects local execution in this case. There is no\npipeline execution, so the throughput for the two methods is\nthe same. For Llama2-13b, EdgeShard-No-bubble achieves an\nimprovement of about 1.69, 1.89, and 5.21 tokens per second\nthan Edgeshard-Bubble for Cloud-Edge-Even, Cloud-Edge,\nand EdgeShard, respectively. Compared to EdgeShard-Bubble,\nEdgeShard-No-bubble does not need to wait for the completion\nof all micro-batches in an iteration and can effectively reduce\nthe devices’ idle time, thus leading to a higher throughput.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nVI. RELATED WORK\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nThis section reviews research works of LLM in the edge\ncomputing environment from two aspects, i.e., edge computing\nfor efficient LLM deployment and LLM for optimizing edge\ncomputing.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.7**\nA. Edge Computing for Efficient LLM\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nLLM is computation-intensive and memory-consuming. To\naddress the issue of memory wall, quantization is widely\nadopted [7]–[12]. GPTQ [8] quantizes LLM with hundreds of\nbillions of parameters to 3-4bits based on approximate second-\norder information. Lin et al. [10] reduce quantization error by\noptimizing channel scaling to preserve the salient important\nweights. They are weight-only quantization. SmoothQuant\n[11] and Agile-Quant [7] take a further step, which quantize\nnot only the model weights, but also the model activations.\nHowever, the computation capacity and memory of a single\ndevice is still limited even for quantized LLM. Moreover, the\nperformance of quantized LLM usually cannot be compared\nto that of its full-size model.\n**BLOCK**fs== 7.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n[5] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu, “Edge computing: Vision\nand challenges,” IEEE Internet of Things Journal, vol. 3, no. 5, pp.\n637–646, 2016.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[6] J. Chen and X. Ran, “Deep learning with edge computing: A review,”\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nProceedings of the IEEE, vol. 107, no. 8, pp. 1655–1674, 2019.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[7] X. Shen, P. Dong, L. Lu, Z. Kong, Z. Li, M. Lin, C. Wu, and Y. Wang,\n“Agile-quant: Activation-guided quantization for faster inference of llms\non the edge,” arXiv preprint arXiv:2312.05693, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[8] E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh, “Gptq: Accurate\npost-training quantization for generative pre-trained transformers,” arXiv\npreprint arXiv:2210.17323, 2022.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[9] ——, “Optq: Accurate quantization for generative pre-trained transform-\ners,” in The Eleventh International Conference on Learning Represen-\ntations, 2022.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[10] J. Lin, J. Tang, H. Tang, S. Yang, X. Dang, and S. Han, “Awq:\nActivation-aware weight quantization for llm compression and accel-\neration,” arXiv preprint arXiv:2306.00978, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n[11] G. Xiao, J. Lin, M. Seznec, H. Wu, J. Demouth, and S. Han,\n“Smoothquant: Accurate and efficient post-training quantization for large\nlanguage models,” in International Conference on Machine Learning.\nPMLR, 2023, pp. 38 087–38 099.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[12] X. Shen, Z. Kong, C. Yang, Z. Han, L. Lu, P. Dong, C. Lyu, C.-h.\nLi, X. Guo, Z. Shu et al., “Edgeqat: Entropy and distribution guided\nquantization-aware training for the acceleration of lightweight llms on\nthe edge,” arXiv preprint arXiv:2402.10787, 2024.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[13] Y. Wang, Y. Lin, X. Zeng, and G. Zhang, “Privatelora for efficient\nprivacy preserving llm,” arXiv preprint arXiv:2311.14030, 2023.\n[14] Y. Chen, R. Li, Z. Zhao, C. Peng, J. Wu, E. Hossain, and H. Zhang,\n“Netgpt: A native-ai network architecture beyond provisioning person-\nalized generative services,” 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[15] M. Zhang, J. Cao, Y. Sahni, Q. Chen, S. Jiang, and T. Wu, “Eaas: A\nservice-oriented edge computing framework towards distributed intel-\nligence,” in 2022 IEEE International Conference on Service-Oriented\nSystem Engineering (SOSE).\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\nIEEE, 2022, pp. 165–175.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[16] M. Zhang, J. Cao, L. Yang, L. Zhang, Y. Sahni, and S. Jiang, “Ents: An\nedge-native task scheduling system for collaborative edge computing,”\nin 2022 IEEE/ACM 7th Symposium on Edge Computing (SEC).\nIEEE,\n2022, pp. 149–161.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[17] Y. Huang, Y. Cheng, A. Bapna, O. Firat, D. Chen, M. Chen, H. Lee,\nJ. Ngiam, Q. V. Le, Y. Wu et al., “Gpipe: Efficient training of giant neu-\nral networks using pipeline parallelism,” Advances in neural information\nprocessing systems, vol. 32, 2019.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[18] D. Narayanan, A. Harlap, A. Phanishayee, V. Seshadri, N. R. Devanur,\nG. R. Ganger, P. B. Gibbons, and M. Zaharia, “Pipedream: Generalized\npipeline parallelism for dnn training,” in Proceedings of the 27th ACM\nSymposium on Operating Systems Principles, 2019, pp. 1–15.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[19] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\nof deep bidirectional transformers for language understanding,” arXiv\npreprint arXiv:1810.04805, 2018.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[20] B. Hubert et al., “Linux advanced routing & traffic control howto,”\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.6**r== 0.2**\nNetherlabs BV, vol. 1, pp. 99–107, 2002.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[21] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel mix-\nture models,” in International Conference on Learning Representations,\n2017.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[22] L. Dong, F. Jiang, Y. Peng, K. Wang, K. Yang, C. Pan, and R. Schober,\n“Lambo: Large language model empowered edge intelligence,” arXiv\npreprint arXiv:2308.15078, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n[23] F. Jiang, L. Dong, Y. Peng, K. Wang, K. Yang, C. Pan, D. Niyato, and\nO. A. Dobre, “Large language model enhanced multi-agent systems for\n6g communications,” arXiv preprint arXiv:2312.07850, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[24] Y. Shen, J. Shao, X. Zhang, Z. Lin, H. Pan, D. Li, J. Zhang, and K. B.\nLetaief, “Large language models empowered autonomous edge ai for\nconnected intelligence,” IEEE Communications Magazine, 2024.\n[25] B. Rong and H. Rutagemwa, “Leveraging large language models for\nintelligent control of 6g integrated tn-ntn with iot service,” IEEE\nNetwork, 2024.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nand smart factory, there is a set of trusted devices owned by a\nsingle stakeholder. They may be able to use those devices\nfor collaborative inference. However, if the devices belong\nto different stakeholders, they may not be willing to share\ndevices’ computation resources. Further incentive mechanisms\nare needed to reward resource sharing.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nBatch size aware optimization. Large batch size will\nincrease memory usage and affect the inference throughput.\nAs shown in the experiment, by partitioning the workload\nof LLM inference to multiple devices, the memory usage of\nparticipating devices can be reduced and thus allows for a\nlarger batch size, leading to increased throughput. However,\nthe designed dynamic programming algorithm does not con-\nsider the influence of batch size, which remains space for\nfurther optimization.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nVIII. CONCLUSION\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nIn this work, we propose EdgeShard to enable the efficient\ndeployment and distributed inference of LLMs on collabo-\nrative edge devices and cloud servers. We formulate a joint\ndevice selection and model partition problem to optimize in-\nference latency and throughput, respectively, and solve it using\ndynamic programming algorithms. Experimental results show\nthat edgesplit can adaptively determine the LLM partition\nand deployment strategy under various heterogeneous network\nconditions for optimizing inference performance. Edgeshard\nis not designed to replace cloud-based LLM inference, but\nto provide a flexible and adaptive LLM serving methods\nby utilizing ubiquitous computing devices. Experiments also\nshows that EdgeShard outperforms the cloud-edge collabora-\ntive inference method when cloud bandwidth is insufficient\nand tends to yield the same deployment strategy as the cloud-\nedge collaborative inference method when facing relatively\nabundant cloud bandwidth.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nThis is a pioneering work of deploying LLM in collaborative\nedge computing environment. We hope this work can stimulate\nmore ideas and further research in this promising area.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nIX. ACKNOWLEDGEMENT\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nThis work was supported by the Research Institute for\nArtificial Intelligence of Things, The Hong Kong Polytechnic\nUniversity, HK RGC Grant for Theme-based Research Scheme\nNo. T43-513/23-N, and National Natural Science Founda-\ntion of China and Hong Kong RGC Collaborative Research\nScheme No. CRS PolyU501-23.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nREFERENCES\n**BLOCK**fs== 8.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman,\nD. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4\ntechnical report,” arXiv preprint arXiv:2303.08774, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[2] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei,\nN. Bashlykov, S. Batra, P. Bhargava, S. Bhosale et al., “Llama\n2: Open foundation and fine-tuned chat models,” arXiv preprint\narXiv:2307.09288, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[3] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos,\nS. Shakeri, E. Taropa, P. Bailey, Z. Chen et al., “Palm 2 technical report,”\narXiv preprint arXiv:2305.10403, 2023.\n**BLOCK**fs== 8.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems, vol. 30, 2017.",
         "the emergence of Large Language Models (LLMs) has attracted widespread attention from the industry, and academia, representing a significant public, breakthrough in artificial intelligence (AI). Many players are coming into this field with their advanced models, such as OpenAI’s GPT-4 [1], Meta’s Llama [2], and Google’s PALM [3]. Built on the foundation of transformer architecture [4], LLMs are characterized by their massive scale in terms of the number of parameters and the amount of data they are trained on. The scale of LLMs, often numbering in hundreds of billions of parameters, enables the models to capture complex patterns in language and context, making them highly effective at generating coherent and contextually appropriate responses. Such a phenomenon is also known as ”intelligence emergence”. The outstanding capability of LLMs makes them valuable and well-performed in a wide range of applications, from ChatBot and content generation (e.g., text summation and code generation) to assisting tools of education and research. However, current LLMs heavily rely on cloud computing, suffering from long response time, high bandwidth cost, and privacy concerns [5]. Firstly, the reliance on cloud computing hampers the capability for rapid model inference necessary for images, audio, and IoT sensing data, real-time applications such as robotics control, navigation, or exploration, where immediate responses are crucial. Secondly, the transmission of large amounts of data, including texts, to the cloud video, data centers leads to substantial bandwidth consumption and immense strain on the network architecture. Thirdly, cloud- based LLMs raise significant privacy issues, especially when handling sensitive data of hospitals and banks, as well as personal data like text inputs and photos on mobile phones. Edge computing is a promising solution to address the afore- mentioned challenges by deploying LLMs on edge devices (e.g., edge servers, edge gateways, and mobile phones) at the network edge closer to the data sources [6]. However, LLMs are computation-intensive and resource-greedy. For example, the inference of a full-precision Llama2-7B model requires at least 28GB memory, which may exceed the capacity of most edge devices. Some works leverage model quantization [7]– [12] to reduce the model size to fit into the resource-constraint edge devices. However, they often lead to accuracy loss. Other works tend to use cloud-edge collaboration [13], [14], which partitions the LLMs into two sub-models and offloads part of the computation workload to the powerful cloud servers with high-end GPUs. However, the latency between edge devices and cloud servers is usually high and unstable. Alternatively, we have witnessed the continuous growth of the computing power of edge in recent years, and a large number of edge servers and edge clouds have been deployed at the network edge, leaving significant resources to be used. Collaborative edge computing (CEC) [15], [16] is hence proposed recently to integrate the computing re- sources of geo-distributed edge devices and cloud servers for efficient resource utilization and performance optimization. As shown in Fig. 1, ubiquitous and distributed edge devices and cloud servers are connected and form a shared resource pool, collaboratively providing instant data processing and AI services. CEC is different from existing edge computing research. Existing edge computing research focuses on the vertical collaboration among cloud, edge, and end devices, while neglecting horizontal edge-to-edge collaborations, suf- fering from unoptimized resource utilization, restricted service coverage, and uneven performance. Motivated by the vision of CEC, we propose a general LLM inference framework, named EdgeShard, to support efficient collaborative LLM inference on distributed edge devices and cloud servers. For simplicity, we use computing devices below to refer to edge devices and cloud servers. Given a network with heterogeneous computing devices, EdgeShard partitions the LLM into multiple shards and allocates them to judicious devices based on the heterogeneous computation and network- ing resources, as well as the memory budget of devices. To optimize performance, we formulate a joint device selection and model partition problem and design an efficient dynamic programming algorithm to minimize the inference latency and maximize the inference throughput, respectively. Extensive ex- periments on a practical testbed show that EdgeShard reduces up to 50% latency and achieves 2x throughput over on-device and vertical cloud-edge collaborative inference methods. Our work is different from those works that partition the LLMs and allocate to multiple GPUs in cloud data centers, such as Gpipe [17] and PipeDream [18]. Deploying LLM at edge computing is vastly different from that in the cloud. First, cloud servers are usually with homogeneous GPUs, while edge devices are with heterogeneous computation ca- pabilities in nature. Second, modern cloud GPUs for LLMs are usually connected by high-bandwidth networks, such as InfiniBand and Nvlinks, while edge devices are connected with heterogeneous and low-bandwidth networks. For example, the bandwidth of NVlinks can go up to 600GB/s, while the bandwidth among edge devices ranges from dozens of Kbps to 1000Mbps. The solution of LLMs deployment designed for cloud data centers neglect the heterogeneous and resource- constrained edge computing environment. Our contributions are three folds. • First, we propose a general LLM inference framework for deploying LLMs in the edge computing environment, which enables the collaborative inference among hetero- geneous edge devices and cloud servers. • Further, we quantitatively study how to select computing devices and how to partition the LLM for optimized performance. We mathematically formulate a joint device selection and model partition problem, and propose a dynamic programming algorithm to optimize the latency and throughput, respectively. • We also evaluate the performance of EdgeShard with state-of-the-art Llama2 serial models on a physical testbed. Experimental results show EdgeShard remark- ably outperforms various baseline methods. Generative LLM Inference. LLMs generally refer to decoder-based transformer models with billions of parameters. Different from encoder-based architecture like BERT [19], whose inference process is single phase, the process of LLM inference is iterative and typically involves two phases: the prompt processing phase and the autoregressive generation. The prompt processing phase is also known as prefill. In the prompt processing phase, the model takes the user initial token (x1, ..., xn) as input and generates the first new to- ken xn+1 by computing the probability P (xn+1 | x1, ..., xn). In the autoregressive generation phase, the model generates one token at a time, based on both the initial input and the tokens it has generated so far. This phase generates tokens sequentially for multiple iterations until a stopping criterion is met, i.e., either when generating an end-of-sequence (EOS) token or reaching the maximum number of tokens specified by user or constrained by the LLM. the model As shown in Fig. 2, suppose the LLM model has N layers, which will take a sequence of input tokens and run all layers to generate a token in a one-by-one manner. In the prefill phase, takes the input (”Today is a”) at once, and the first generated token is ”good.” In the autoregressvie generation phase, the model first takes (”Today is a good”) as input and generates the next token (”day”). It then takes (”Today is a good day”) as input and generates the next token (”EOS”), which indicates the end of the generation. Since a token generated is determined by all its previous token in a sequence, LLMs utilize Key-Value caching (KV caching) to avoid repetitive computation, storing past computations to expedite responses, thereby reducing computational workload and improving response times. The time to generate a token in the prefill stage is much higher (usually 10x) than that of in the autoregressive stage, as the prefill stage needs to calculate the KV cahche of all input tokens as initialization. least 28GB memory, but LLMs are memory-consuming. A single edge device may not have sufficient memory to accommodate a LLM model. Take one of the most popular LLM models, i.e., Llama2, as an example. As shown in Table. I, Llama2 has three different versions, i.e., 7B, 13B, and 70B. We can see from the Table that the full precision inference of Llama2-7B requires the smartphones usually only at have 6-12 GB memory, and the Jetson Orin NX has 8-16 GB memory. They are unable to burden the on-device LLM inference. Some works try to use low-precision quantization, e.g., 8 bit and 4 bit. However, it may still exceed the memory capacity of edge devices. For example, the 4-bit inference of Llama2-70B requires at least 35GB memory, which cannot be accommodated on most edge devices. Moreover, low-precision inference leads to performance degradation. In this work, we leverage collaborative edge computing, a computing paradigm where geo-distributed edge devices and cloud servers collaborate to perform computational tasks. Based on that idea, we propose EdgeShard, a general LLM inference framework that allows adaptive device selection and LLM partition over distributed computing devices, to address the high memory requirements and leverage heterogeneous resources to optimize LLM inference. There are three stages of the framework, including profiling, task scheduling optimization, and collaborative inference. The workflow is shown in Fig. 3. Profiling is an offline step that profiles the necessary run- time traces for the optimization step and only needs to be done once. Those traces include: 1) the execution time of each layer on different devices; 2) the size of activations and memory consumption for each layer of the LLM model; 3) available memory of each device and the bandwidth among devices. For the execution time of each layer, we profile the time to generate a token in the prefill stage and autoregressive stage, respectively, and take the average. For those devices that may not have efficient memory to hold the full model for performing the profiling, we utilize a dynamic model loading technology, where the model layers are consecutively loaded to fit the constrained memory. The profiling information will then be used to support intelligent task scheduling strategies. Scheduling Optimization. At the task scheduling optimiza- tion stage, the scheduler generates a deployment strategy by determining which device to participate in, how to partition the LLM model in a layer wise, and which device should the model shard be allocated to. The strategy thoroughly considers the heterogeneous resources, the memory budget of devices, and the privacy constraint, and later be applied to selected devices for efficient LLM inference. More details is described in Sec. IV. Collaborative inference. After getting the LLM model par- tition and allocation strategy, the selected devices will perform the collaborative inference. We pre-allocate memory space for KV cache on each participating device. We consider two cases for the collaborative inference, i.e., sequential inference and pipeline parallel inference. In sequential inference, devices take turns to perform the computation with the allocated model shards. As shown in Fig. 4(a), suppose the LLM model is partitioned into 3 shards and allocated to device 1, 2, and 3, respectively. Device 1 will first process the input data and then send the activations/out- puts to device 2, which will process the data and then transmit to device 3. Sequential inference is suitable for serving a single user, such as in smart home scenario, where users’ personal devices (e.g., tablet, phones, and smart speaker) collaborate to perform LLM inference. In such scenario, user inputs a prompt and gets the response and then input another prompt. We aims to minimize the latency of sequential inference. However, sequential inference is not resource-efficient from the system’s perspective. When device 1 is performing com- putation, device 2 and device 3 are idle. We thus take pipeline parallelism to improve resource utilization. For the pipeline parallel inference as taken in previous work Gpipe [17] and PipeDream [18] for cloud servers, the input data will first be split into micro-batch and subsequently feed into the system. As depicted in Fig. 4(b), device 1 first handles data B1 and then transmits intermediate data to device 2. After handling data B1, device 1 immediately goes to handle data B2. In such a pipeline manner, every device is busy with high system resource utilization. We consider a general collaborative edge network with het- erogeneous devices and bandwidth connection. More specif- ically, given a set of heterogeneous devices connected with heterogeneous bandwidth, EdgeShard aims to select a subset of devices and partition the LLM into shards, which will be allocated to the selected devices to minimize the inference latency or maximize the throughput. System Model. LLMs usually have a layered architecture, which consists of an embedding layer, multiple decoder layer, and an output layer. Sizes of parameters and activations (i.e., the output of a layer) vary across layers. We assume the model is with N layers. Oi represents the size of activations of layer i, 0 ≤ i ≤ N − 1. The memory consumption of a layer i is denoted by Reqi. We consider a network consisting of M edge devices and cloud servers. The devices have heterogeneous computation and memory capabilities, and cloud servers are much more powerful than edge devices in terms of computation capability. The memory budget of a device j is M emj. The computing devices are interconnected. Bandwidth between a device k and a device j is Bk,j, 0 ≤ k ≤ M − 1, 0 ≤ j ≤ M − 1. There is a source node where the input tokens reside. Without loss of generality, we set the source node as node 0. The main notations used in this paper are shown in Table. II. A. Optimize LLM inference latency Problem Formulation. We use a binary variable Xi,j to denote the LLM allocation strategy. Xi,j equals to 1 if layer j=0 Xi,j = 1, ∀i. Let ti,j i is allocated to node j. Otherwise, Xi,j equals to zero. A layer will be and only be allocated to one node. Hence, we have M −1 comp denotes the computation time of layer i on node j. Suppose layer i − 1 and layer i are allocated to node k and node j, respectively. We use ti−1,k,j comm to denote the communication time to transmit the activations of layer i − 1 from node k to node j. The data transmission time is determined by the output size of a layer and the bandwidth between two nodes. If layer i − 1 and layer i are on the same node, we assume the transmission time is zero. Hence, we have otherwise. The total inference time can thus be calculated by the following equation. (2) the problem of minimizing the LLM inference latency can be formulated as follows, where Eq. (4) is the privacy constraint. It shows that the first layer of the LLM model should always be allocated to node 0, which is set to be the source node with input tokens. In such a case, the raw input data resides on the source node and avoids to be transmitted among computing devices. Eq. (5) shows that the memory requirements of all the layers allocated to node j cannot exceed its memory budget. min Ttol Xi,j ∗ Reqi ≤ M emj Solution. To minimize the inference latency, we design a dynamic programming algorithm. The intuition is that the minimal execution time of the first i layer is determined by the first i − 1 layer, which means the optimal solution can be constructed from the optimal results of the sub-problems. It has the optimal sub-problem property, which motivates us to use dynamic programming. Let DP (i, j) denote the minimal total execution time of the first i layers after the layer i is allocated to the node j. The state transition equation is formulated as: (DP (i − 1, k) + ti,j (DP (i − 1, k) + ti,j (6) Where DP (i − 1, k) indicates the minimal execution time of the first i − 1 layers if layer i − 1 is allocated to device k. Eq. (6) shows that DP (i, j) is determined by traversing at all possible nodes of the previous layer and choosing the one that minimizes the execution time of the first i layers. Moreover, due to the autogressive nature of LLM, the generated token needs to be sent back to the source node for next iteration of generation. Hence, for the last layer N −1, the communication time not only includes the data transmission time from the N − 2 layer, but also the transmission time to the source node tN −1,j,0 comm . Additionally, we initialize DP (0, 0) as shown in Eq. (7) by considering the privacy constraint. Algorithm 1: Joint device selection and LLM partition for optimizing latency Input: A LLM model; Computing device M ; Profiled traces; bandwidth Bk,j; Output: the device selection and LLM partition strategy // initialization 1 Initialize DP table DP (i, j) = IN F , and choice table choice(i, j) = N U LL to record the strategy; 2 Enforce first layer to be allocated to node 0 by By traversing each layer and each node based on Eq. (6), we can fill in the dynamic programming table DP (i, j) to track the minimum total execution time to reach each layer. Finally, the minimal total execution time at the last layer can be calculated by Eq. (8). We can then get the optimal node allocation for each layer by backtracking DP (i, j). minj=0,...,M −1(DP (N − 1, j)) This method is simple and effective. With dynamic pro- gramming, we can quickly traverse the solution space and find the best LLM partition and allocation strategy. The algorithm to find the optimal LLM partition and allocation strategy for minimizing inference latency is shown in Algo. 1. In Algo. 1, we first initialize the dynamic programming table DP (i, j) and choice table choice(i, j) (lines 1-2). We initialize DP (0, 0) according to Eq. (7). The choice(i, j) records the node k to host the i − 1 layer. It is the optimal variable of Eq. (6). We then traverse the layers of the large language model from layer 1. For each layer, we traverse all the computing devices with sufficient memory and calculate the inference time (lines 3-19). After filling the DP table, we can find the minimal DP (N − 1, j), which represents the minimal time for executing the LLM model, and the last node to host layer N − 1. Finally, by backtracing choice(i, j), we get the model partition and allocation strategy R (lines 20-28). The computational complexity of Algo. 1 is O(N × M × M ), where N is the number of layers of the LLM model and M is the number of devices in the network. B. Optimize LLM inference throughput Problem Formulation. For optimizing throughput, pipeline parallelism is adopted to avoid device idleness. As illustrated before, the computation time of layer i on node j is ti,j comp, and if layer i to layer m are all allocated to node j, the computation time is indicated by ti→m,j comp . The data transmission time of the activations of layer i − 1 from node k to node j is ti−1,k,j comm . In pipeline parallel inference, the computation time and communication time can be overlapped to maximize the throughput. Thus, for the inference task, the maximum latency for the device j can be calculated as: Ideally, for the selected devices, achieving the maximal to minimizing the latency of the throughput slowest device. We use S to denote the selected devices, and is equivalent DP (0, 0) = t0,0 // fill in the DP table comp and choice(0, 0) = 0; 3 for i = 1 to N − 1 do for j = 0 to M − 1 do if M emj ≤ Reqi then end else for k = 0 to M − 1 do Calculate the total execution time by Eq. (6) and assign it to ttotal; if ttotal ≤ DP (i, j) then Update DP (i, j) by assigning DP (i, j) = ttotal; Update memory M emj; Record allocation plan choice(i, j) = k; // backtrace for allocation strategy 20 Initialize optimal strategy R; 21 Find the last selected node Nlast = argminj(DP (N − 1, j)); Find the previous node Nlast = choice(i, Nlast); Add Nlast to R; 22 Add Nlast to R; 23 for i = N − 1 to 0 do 26 end 27 Reverse R; 28 return R; then the problem of maximizing the inference throughput can thus be formulated as follows, where j ∈ S. Solution. Similar to minimizing the inference latency, the problem of maximizing the throughput also has an optimal sub-problem property. Maximizing the throughput of the first i layer can be deduced from solving the problem of allocating the first i−1 layer, which indicates that the optimal solution of the whole problem can be constructed from the sub-problems. We also use dynamic programming to solve the problem. Let g(i, S, k) denote the minimum time to process the first i layers with the set of used devices S, and the device k is the last node to be used, k ∈ S. We use g(m, S′, j) to denote the next state to process the first m layers with the set of used devices S′, and the device j is the last node to be used, where 0 ≤ i < m ≤ N − 1, j ∈ M \\ S, S′ = S ∪ {j}. The state transition equation is formulated in Eq. is determined by the previous (11), where g(m, S′, j) state g(i, S, k), and the maximum latency of devive j, i.e., the com- putation time ti−1,k,j comp . The final optimal solution T opt throu is the minimum g(N − 1, S′, j), where S′ ⊆ M . comm and the communication time ti→m,j Algorithm 2: Joint device selection and LLM partition for optimizing throughput Input: A LLM model; Computing devices M ; Profiled traces; bandwidth Bk,j; Output: the device selection and LLM partition strategy R // initialization 1 Initialize DP table g(i, S, k) = IN F , and choice table choice(m, S, j) = N U LL to record the strategy; 2 Enforce first layer to be allocated to node 0 by g(1, 1, 0) = t0,0 // fill in DP table comp and choice(1, 1, 0) = (0, 0, 0); g(m, S′, j) S′=S∪{j} Additionally, we have constraints when performing state transition. They are the memory constraint shown in Eq. (12) and privacy constraint in Eq. (13). Reqi→m ≤ M emj Algo. 2 describes the pseudo-code to find the optimal solu- tion T opt throu and the corresponding model partition and alloca- tion strategy. In Algo. 2, we first initialize the dynamic pro- gramming table g(m, S′, j) and choice table choice(m, S, j), and assign t0,0 comp to g(1, 1, 0) (lines 1-2). We then traverse the layers of the large language model from layer 1. For each layer, we traverse all the computing devices with sufficient memory and calculate the maximum latency (lines 3-23). After filling the DP table, we can find the maximum latency, based on which we then backtrace the choice table and finally get the model partition and allocation strategy (lines 24-32). The computational complexity of Algo. 2 is O(N 2 × 2M × M 2), where N is the number of layers of the LLM model and M is the number devices in the network. Pipeline Execution Optimization. Note that the above problem formulation and solution are based on the ideal case, where there is no idle device at any time. A device processes a batch of data and continues to handle another batch of data without waiting. However, it is impractical for LLM inference in real-world cases. As shown in Fig. 5(a), different from those one-phase computation applications, the decoder-based LLM application has an autoregressive nature, where there will be multiple tokens to be generated and the calculation of the current token relies on all the previous tokens. The computation of the current token cannot start until it gets the previously generated token. It leads to bubbles in pipeline execution. To approximate the ideal case and enhance the resource utilization for improving throughput, we tend to reduce the bubbles in the pipeline execution. We propose EdgeShard-No- bubbles, which allows for immediate token generation without waiting for the ending of all micro-batches in an iteration. As shown in Fig. 5(b), after the prefill stage P 1 ends of the first batch, Device 1 immediately executes the token generation of 3 for i = 1 to N − 1 do for each subset S ⊆ M do for last node k ∈ S do for m = i + 1 to N − 1 do for j ∈ M \\ S do if M emj ≤ m Continue; i Reqi then end else Get S′ by adding node j to the selected device set S; Calculate current mamixum execution time Tmax via Eq. (11) for the maximum execution time in all stages; end if Tmax ≤ g(i, S, k) then g(m, S′, j) = Tmax; Record the current strategy choice(m, S′, j) = (i, j, k); // backtrace for optimal allocation 24 Initialize optimal strategy R; 25 Find selected device set S and the last selected node Nlast by S, Nlast = argminS,k(g(N − 1, S, k)); 26 Initialize layer = N − 1; 27 while layer > 0 do (i, j, k) = choice(layer, S, Nlast); Add (i → layer, j) to R; Update layer, S and Nlast; 31 end 32 return R; the first batch as indicated by G1A. Similarly, when G1A ends, Device 1 goes to the next iteration of token generation indi- cated by G1B. Compared to EdgeShard-Bubbles, EdgeShard- No-bubbles reduces bubbles by mitigating device idle time and is expected to improve throughput. From the pipeline execution graph in Fig. 5, we can see that EdgeShard-No- 2023 and is one of the most popular and powerful open- source large language models, representing a groundbreaking leap in the field of artificial intelligence and natural language processing. For the model inference, we adopt the text gen- eration task to test the performance. We use the WikiText-2 dataset [21] from HuggingFace. We extract a subset of samples with the length of input tokens as 32 and generate 96 tokens. We use full-precision model inference in all the following experiments. Baselines. We compare the performance in terms of latency and throughput of EdgeShard with various baselines. (We don’t use the cloud-only as a baseline because it requires the input token to be transmitted to the cloud server, which may lead to privacy concerns). • Edge-Solo. In this case, the LLMs are deployed locally on an edge device without model partition. • Cloud-Edge-Even. In this case, the LLMs are evenly partitioned into two parts. One is allocated to the edge device, and another is allocated to the cloud server. • Cloud-Edge-Opt. In this case, the LLMs are partitioned into two shards. One is allocated to the edge device, and another is allocated to the cloud server. For the partition strategy of LLMs, we also use the proposed dynamic programming algorithms. The difference is that there is only two devices as the algorithm input. We set AGX Orin as the source node and the bandwidth between the source node and the cloud server as 1Mbps. The bandwidth between other computing devices is set to be 50Mbps with a variance of 20%. To test the throughput, we set the batch size as the maximum batch size that the participating devices can support. The latency and throughput of LLM inference are shown in Table. IV. bubbles generates more tokens at the same time. Testbed. We use various edge devices and cloud servers to act as the heterogeneous computation devices in collaborative edge computing. The specifications of those devices are listed in Table. III. We use 15 devices, including 12 Jetson AGX Orin, 2 Jetson Orin NX, and one cloud server to configure the collaborative edge network. The physical testbed is shown in Fig. 6. Those devices are connected with a route and a switch. The bandwidth between any two devices is 1000Mbps. We use the Linux TC tool [20] to vary network bandwidth and communication latency between devices. Benchmarks. We test the performance of EdgeShard with a series of Llama2 models [2], including Llama2-7B, Llama2- 13B, and Llama2-70B. Llama2 is released by Meta in July We have the following observations. First, EdgeShard is potential and beneficial for large language model deployment. For Llama2-70B model, the memory requirement is about 280GB, which far exceeds the memory capacity of solo edge deployment and cloud-edge collaborative deployment. They will have the out-of-memory issue (OOM). However, Edge- Shard tackles this challenge by splitting the large model into shards and allocating them to multiple devices, enabling col- laborative model inference. Second, EdgeShard achieves obvi- ously lower inference latency and higher inference throughput than baseline methods. For Llama2-7B model, EdgeShard achieves 75.88ms latency, which is about 1.85x faster than Edge-Solo and Cloud-Edge-Opt, and about 3x faster than Cloud-Edge-Even. For the inference throughput, EdgeShard achieves 52.45 tokens per second with a maximum batch size of 8, which is around 2.2 times larger than Edge-Solo and Cloud-Edge-Opt, and about 7 times larger than Cloud-Edge- is also observed Even. Similar performance improvement for Llama2-13B model, where EdgeShard achieves 45.7% and 28.8% lower latency than Cloud-Edge-Even and Cloud- Edge-Opt, respectively. Also, EdgeShard has 2.23x and 2.2x higher throughput than Cloud-Edge-Even and Cloud-Edge- Opt. Third, we can also see that, for Llama2-7B, Cloud-Edge- Opt tends to have the same performance in terms of both inference latency and throughput as Edge-Solo. This is because the bandwidth between the source node and the cloud server is very limited in this experimental setting, i.e., 1Mbps. The optimal deployment strategy of Cloud-Edge-Collaboration is local execution, which is the same as Edge-Solo. C. Effects of Bandwidth We set the source node as AGX Orin and vary the bandwidth between the cloud server and the source node from 1Mbps to 50Mbps. The performance of the latency and throughput of LLM inference are shown in Fig. 7 and Fig. 8, respectively. For Llama2-13B, a single AGX Orin cannot accommodate the full model. We only compare the performance among Cloud-Edge-Even, Cloud-Edge-Opt, and EdgeShard. Simi- larly, due to the memory constraint, the three baseline methods are not able to deploy the Llama2-70B model. Instead, we compare the performance of EdgeShard with its variant, i.e., EdgeShard-Even, where the model is equally partitioned and deployed to all the participating computing devices. It selects 11 AGX Orin and 1 RTX 3090 to deploy the Llama2-70B model. In terms of latency, except for Edge-Solo, the latency of the other three methods decreases with the increasing bandwidth. This is because the three methods are collaboration-based, and the latency is influenced by the data transmission time. The increasing bandwidth leads to reduced communication time. We can also see that for the collaboration methods, there is a dramatically latency reduction when the cloud- source bandwidth changes from 1Mbps to 10Mbps and a minor variance from 10Mbps to 50Mbps. This is because the bandwidth is gradually saturated at that time, and the computation time becomes the bottleneck. Moreover, we can see that when the bandwidth is greater than 10Mbps, cloud-edge collaboration methods outperform the Edge-Solo method, as the cloud-edge collaboration meth- ods introduce the powerful cloud server for computation acceleration. However, when the bandwidth is 1Mbps, Cloud- Edge-Even performs worse than EdgeSolo. This is because the data transmission cost is high in this case. The Cloud-Edge- Opt method tends to deploy the LLM model locally, which is the same as the Edge-Solo method. Interestingly, the latency of Cloud-Edge-Opt and EdgeShard is nearly the same when the bandwidth is greater than 10Mbps. We found that EdgeShard generates the same model partition and allocation policies as the Cloud-Edge-Opt method. The variance comes from the small fluctuations in model execution. It shows that the per- formance of EdgeShard will not be worse than that of Cloud- Edge-Opt, and the Cloud-Edge-Opt method is a special case of EdgeShard. A similar pattern is also observed for Llama2-13B. For Llama2-70B, EdgeShard performs better than its variant EdgeShard-Even, as there is resource heterogeneity among cloud server and edge devices, and EdgeShard adaptively partitions the LLMs among computing devices. However, the performance improvement is not so obvious as there are 11 AGX with the same computation capacity and only 1 RTX 3090. In terms of throughput, similar patterns to the latency evaluation are also found for Llama2-7B model. Differently and interestingly, for Llama2-13B, EdgeShard does not show a closing performance with the Cloud-Edge-Opt method when the bandwidth is 10Mbps, but with a great improvement, where EdgeShard has about 2x higher throughput than the Cloud-Edge-Opt method. This is because of the high memory consumption of the RTX 3090 and the source node, i.e., AGX Orin. We observed that for the Cloud-Edge-Opt, the memory consumption of the two devices goes up to 95% and 98%, respectively, which only allows for a maximum batch size of 4. Otherwise, there will not be enough memory for the KV cache on the computing devices. However, when the bandwidth is 10Mbps, EdgeShard involves several edge devices where the memory consumption of an individual device becomes dramatically decreased, allowing for a larger batch size, i.e., 8 in this case. When the bandwidth is higher than 10Mbps, EdgeShards tends to have the same model partition and allocation strategy as Cloud-Edge-Opt, which yields a closing performance, as shown in Llama2-7B. For Llama2-70B, improvement of EdgeShard, and EdgeShard-Even shows a steady throughput as the evenly partition strategy will not change with the cloud- source bandwidth. there is a slight throughput D. Effects of Source Node different computation and memory capacities, and EdgeShard enforces the first layer of LLM models residing on the source node to avoid raw data transmission. We set the source node as AGX Orin and Orin NX, respectively, and compare their performance. We set the bandwidth between the source node and the cloud server as 1Mbps. The results of Llama2-7B inference are shown in Fig. 9. We find that when the source node is Orin NX, the Edge- Solo and Cloud-Edge-Even methods encounter the OOM error. This is due to the relatively lower memory of Orin NX, which cannot accommodate the Llama2-7B model, even for half part of the model. The difference between the two cases under the Cloud-Edge-Opt method is much more obvious than that of EdgeShard. For Cloud-Edge-Opt, there is about a 60ms gap, and for EdgeShard, the gap is about 5ms. This is because there are only two devices in the Cloud-Edge-Opt case, and it tends to put more layers on the source node. However, AGX Orin is much more powerful than Orin NX in terms of computation capacity. EdgeShard tends to involve more devices and put fewer model layers on the source node, which can fill in the gap in computation capacity between the source nodes. A similar phenomenon is also observed for the throughput, where AGX Orin has 6x higher throughput than Orin Nx for the Cloud-Edge-Opt method and only 2x higher throughput under the EdgeShard method. It shows EdgeShard can make full use of the computation resources in the network to optimize the performance. E. Effects of Pipeline Execution strategy We evaluate the two pipeline execution strategies. We set the bandwidth between the cloud server and the source node as 1Mbps. The results are shown in Fig. 10. We also test the influence of the source node on the inference latency and throughput, as the source node may have We can see that for all methods, EdgeShard-No-bubble outperforms EdgeShard-Bubble. Specifically, for Llama2-7b, Other works [13], [14] tend to leverage the cloud-edge collaboration to partition and distribute the massive compu- tation workload of LLM inference and finetuning. Wang et al. [13] increase the throughput by distributing the computa- tion between cloud servers and edge devices, and reducing the communication overhead of transmitting the activations between the central cloud and edge devices by leveraging the low-rank property of residual activations. Chen et al. [14] efficiently leverage location-based information of edge devices for personalized prompt completion during collaborative edge- cloud LLM serving. However, the latency between edge de- vices and the central cloud is usually high and unstable, which will affect the inference and finetuning performance of LLM. Our work is different from those works. We propose a general framework to integrate the computation resources of heterogeneous and ubiquitous cloud servers and edge devices. The framework allows the adaptive selection of computation devices and partition of the computation workload of LLM inference for optimized latency and throughput. B. LLM for Optimizing Edge Computing LLMs also have great potential in making complex and coherent decisions. There are also some works that leverage LLM to optimize resource utilization in edge computing, such as resource allocation and task offloading, network man- agement, and intelligent IoT control. Li et al. [22] propose LAMBO, a LLM-based task offloading framework for mo- bile edge computing, to address the challenging issues of heterogeneous constraints, partial status perception, diverse optimization objectives, and dynamic environment that are not well addressed in traditional task offloading research. LAMBO shows that LLM is more effective compared to traditional DNN and deep reinforcement learning-based methods in com- plex and dynamic edge computing environments. They further design a LLM-based multi-agent system and incorporate com- munication knowledge and tools into the system, empowering it with the ability to optimize semantic communication in a 6G network [23]. Apart from optimization of resource utilization, Shen et al. [24] leverage the outstanding abilities of GPT in language understanding and code generation to train new models among federated edge devices. Rong et al. [25] leverage LLMs to generate adaptive control algorithms for addressing the diverse, dynamic, and decentralized network conditions in 6G integrated terrestrial network (TN) and non- terrestrial network (NTN). Though LLMs have shown great potential in making intelligent decisions, especially in complex and dynamic edge computing systems, the related research is still in the early stages. Challenges such as significant resource consumption, latency of decision-making, and uncertainty of generated decisions need further studies. This section discusses some open issues and future works that may appeal to readers. Incentive mechanisms. In this work, we partition the LLM into multiple shards and allocate them to heterogeneous devices. For edge computing scenarios, such as smart home EdgeShard-No-bubble achieves an improvement of about 0.36 and 6.96 tokens per second than Edgeshard-bubble for Cloud- Edge-Even and EdgeShard, respectively. For the Cloud-Edge- Opt method, it selects local execution in this case. There is no pipeline execution, so the throughput for the two methods is the same. For Llama2-13b, EdgeShard-No-bubble achieves an improvement of about 1.69, 1.89, and 5.21 tokens per second than Edgeshard-Bubble for Cloud-Edge-Even, Cloud-Edge, and EdgeShard, respectively. Compared to EdgeShard-Bubble, EdgeShard-No-bubble does not need to wait for the completion of all micro-batches in an iteration and can effectively reduce the devices’ idle time, thus leading to a higher throughput. This section reviews research works of LLM in the edge computing environment from two aspects, i.e., edge computing for efficient LLM deployment and LLM for optimizing edge computing. A. Edge Computing for Efficient LLM LLM is computation-intensive and memory-consuming. To address the issue of memory wall, quantization is widely adopted [7]–[12]. GPTQ [8] quantizes LLM with hundreds of billions of parameters to 3-4bits based on approximate second- order information. Lin et al. [10] reduce quantization error by optimizing channel scaling to preserve the salient important weights. They are weight-only quantization. SmoothQuant [11] and Agile-Quant [7] take a further step, which quantize not only the model weights, but also the model activations. However, the computation capacity and memory of a single device is still limited even for quantized LLM. Moreover, the performance of quantized LLM usually cannot be compared to that of its full-size model. and smart factory, there is a set of trusted devices owned by a single stakeholder. They may be able to use those devices for collaborative inference. However, if the devices belong to different stakeholders, they may not be willing to share devices’ computation resources. Further incentive mechanisms are needed to reward resource sharing. Batch size aware optimization. Large batch size will increase memory usage and affect the inference throughput. As shown in the experiment, by partitioning the workload of LLM inference to multiple devices, the memory usage of participating devices can be reduced and thus allows for a larger batch size, leading to increased throughput. However, the designed dynamic programming algorithm does not con- sider the influence of batch size, which remains space for further optimization. In this work, we propose EdgeShard to enable the efficient deployment and distributed inference of LLMs on collabo- rative edge devices and cloud servers. We formulate a joint device selection and model partition problem to optimize in- ference latency and throughput, respectively, and solve it using dynamic programming algorithms. Experimental results show that edgesplit can adaptively determine the LLM partition and deployment strategy under various heterogeneous network conditions for optimizing inference performance. Edgeshard is not designed to replace cloud-based LLM inference, but to provide a flexible and adaptive LLM serving methods by utilizing ubiquitous computing devices. Experiments also shows that EdgeShard outperforms the cloud-edge collabora- tive inference method when cloud bandwidth is insufficient and tends to yield the same deployment strategy as the cloud- edge collaborative inference method when facing relatively abundant cloud bandwidth. This is a pioneering work of deploying LLM in collaborative edge computing environment. We hope this work can stimulate more ideas and further research in this promising area. This work was supported by the Research Institute for Artificial Intelligence of Things, The Hong Kong Polytechnic University, HK RGC Grant for Theme-based Research Scheme No. T43-513/23-N, and National Natural Science Founda- tion of China and Hong Kong RGC Collaborative Research Scheme No. CRS PolyU501-23.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2405/2405.14371v1.pdf",
         "extracted",
         "None",
         "",
         "EdgeShard: Efficient LLM Inference via Collaborative Edge Computing"
        ],
        [
         "18",
         "007f0fb7f697b3fe52d828a5b9d4472583d69d41",
         "PurposeIn the context of nursing in higher education, digital competencies are increasingly recognised as a necessary skillset, within a continuously evolving healthcare professional landscape. This study sought to explore nursing students’ digital competencies and to further understand the digital literacy gaps and barriers they encounter for both learning and future work.Design/methodology/approachThe research involved a cross-sectional, discipline-based empirical study of nursing students’ self-assessed digital competencies via a questionnaire survey, which collected quantitative and qualitative data from a total of five hundred and fifty-three students. The study explored the role of demographics (age, urban/rural geographical location of growing up, study year, learning disabilities (neurodiversity)) and experiences of digital divides (e.g., access, contextual and behavioural barriers) play on students’ digital competencies and outcomes.FindingsStudents’ digital competencies were found at an intermediate level, with younger and first-year students self-assessing higher. Significant differences were identified between students who had encountered digital barriers/divides and those who had not, with the former, self-reporting lower digital competencies. Students with learning disabilities reported complex support needs for processing and organizing digital information and for productivity. Almost all the individual digital competencies items assessed had strong statistical correlations between them.Originality/valueThe research offers key recommendations for academic libraries for the ongoing, evolving exploration of students’ digital competencies and for the need to follow tailored, discipline-related, holistic, practice-based and curriculum-embedded approaches to students’ digital skills development and support. It provides novel insights into digital competencies development for nursing students, particularly those who experience digital divides.",
         "Konstantina Martzoukou,Errol Sadullah Luders,Fiona Work,Petros A. Kostagiolas,Neil Johnson",
         "\n**BLOCK**fs== 11.0**p== 0.0**b== 0.9**t== 0.0**l== 0.1**r== 0.1**\nMARTZOUKOU, K., LUDERS, E.S., WORK, F., KOSTAGIOLAS, P.A. and JOHNSON, N. 2025. Digital divides in nursing\nstudents: an exploration of the relationship between self-perceived digital competencies and digital barriers.\nJournal of documentation [online], 81(2), pages 330-350. Available from: https://doi.org/10.1108/JD-09-2024-0209\n**BLOCK**fs== 26.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nDigital divides in nursing students: an\nexploration of the relationship between self-\nperceived digital competencies and digital\nbarriers.\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nThis author accepted manuscript is deposited under a Creative Commons Attribution Non-commercial\n4.0 International (CC BY-NC) licence. This means that anyone may distribute, adapt, and build upon\nthe work for non-commercial purposes, subject to full attribution. If you wish to use this manuscript\nfor commercial purposes, please visit Marketplace.\n**BLOCK**fs== 11.0**p== 1.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nDigital divides in nursing students: an exploration of the\nrelationship between self-perceived digital competencies\no\nand digital barriers\n**BLOCK**fs== 8.5**p== 1.0**b== 0.7**t== 0.3**l== 0.3**r== 0.7**\nJournal:\n**BLOCK**fs== 8.5**p== 1.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nJournal of Documentation\n**BLOCK**fs== 8.5**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\nManuscript ID JD-09-2024-0209.R1\n**BLOCK**fs== 8.5**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nManuscript Type: Article\na\n**BLOCK**fs== 8.5**p== 1.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nKeywords:\n**BLOCK**fs== 16.0**p== 2.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nDigital divides in nursing students: an exploration of the\nrelationship between self-perceived digital competencies and\ndigital barriers\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nAbstract\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nPurpose\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nIn the context of Higher Education nursing education, digital competencies are increasingly recognised\nas  a  necessary  skillset,  within  a  continuously  evolving  healthcare  professional  landscape.  This  study\nsought to explore nursing students’ digital competencies and to further understand the digital literacy\ngaps and barriers they encounter for both learning and future work.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nDesign/methodology/approach\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nThe  research  involved  a  cross  sectional,  discipline-based  empirical  study  of  nursing  students’  self-\nassessed digital competencies via a questionnaire survey, which collected quantitative and qualitative\ndata from a total of five hundred and fifty-three students. The study explored the role of demographics\n(age, urban/rural geographical location of growing up, study year, learning disabilities (neurodiversity)\nand experiences of digital divides (e.g., access, contextual and behavioural barriers) play on students’\ndigital competencies and outcomes.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.2**r== 0.8**\nFindings\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nStudents’ digital competencies were found at intermediate level with younger and first year students\nself-assessing higher. Significant differences were identified between students who had encountered\nc\ndigital  barriers/divides  and  those  who  had  not,  with  the  former,  self-reporting  lower  digital\ncompetencies. Students with learning disabilities reported complex support needs for processing and\norganizing digital information and for productivity. Almost all the individual digital competencies items\nassessed had strong statistical correlations between them.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.8**\nOriginality\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nThe research offers key recommendations for academic libraries for the on-going, evolving exploration\nof  students’  digital  competencies  and  for  the  need  to  follow  tailored,  discipline-related,  holistic,\npractice-based  and  curriculum  embedded  approaches  to  students’  digital  skills  development  and\nsupport.  It  provides  novel  insights  into  digital  competencies  development  for  nursing  students  and\nparticularly those who experience digital divides.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.2**r== 0.1**\nWithin the context of university nursing education, digital competencies are increasingly recognised as\na necessary skillset for studying, keeping up with technological advancements (Harrison, 2024; RCN,\n2024)  and  developing  an  “ability  to  adapt  and  innovate”  (Hughes  2024),  preparing  students  for  the\nfuture  healthcare  professional  landscape  and  for  roles  that  demand  digital  skills  in  the  provision  of\neffective nursing care (Isidori et al, 2022; RCN, 2021). The rapid digital transformation caused by the\npandemic necessitated digital competence development needs in both nursing education and practice\nwith changes that are “likely to be sustained”, while the need for nurses who have “digital expertise\nand  the  ability  to  lead  change  is  increasing  exponentially”  (NHS  England,  n.d.).  Within  the  next  two\ndecades,  most  jobs  in  the  UK  National  Health  System  (NHS)  will  have  a  digital  component,  as  staff\nnavigate  a  data-rich  healthcare  environment  and  develop  digital  competence  skills  for  fast  growing\ntechnologically  enhanced  work  settings  (Topol  Review,  2019)  dealing  with  increased  digital  data\n(Capgemini, 2022) and a “digital future” that “is already transforming the way nursing care is delivered”\n(RCN, 2024).  A priority area for the health and care sector is, therefore, “when, why and, crucially, how\nto use digital”, with essential digital workforce development (Scottish Government, 2021).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.3**l== 0.2**r== 0.1**\nThe Code of the Nursing and Midwifery Council (2023) identifies digital skills as integral for all registered\nnurses, however, a lack of formal digital competencies training structure in nursing education results in\nfragmented  digital  knowledge  and  experiences  (De  Leeuw  et  al.,  2022).  Frustration  with  new  and\nongoing integration of technology and lack of confidence/skills with healthcare technology is associated\nwith emotional exhaustion among nurses in practice (Tawfik et al. 2021). Among nursing students, who\nprepare for increasingly digitalised future careers, the existence of digital divides also creates significant\nchallenges (Saeed and Masters, 2021). Despite the widespread presence of digital technology in nursing\nstudents' lives, students still experience gaps even in baseline digital literacy (NMC, 2023). For example,\ntargeted digital literacy education interventions around technology-enhanced learning and simulation\nare needed as part of foundational nursing studies to improve nursing students' baseline digital literacy\nbefore commencing clinical placement (Lokmic-Tomkins et al., 2022).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nc\nTo realise the true potential of digitally enabled health and social care services, it becomes necessary\nto develop a unified and concentrated effort to transform the education and skills provision for those\nworking in delivering health and social care (Morrison et al., 2022). This necessitates a deeper and on-\ngoing exploration of nursing students’ development needs and readiness to apply digital skills within a\nconstantly evolving nursing education and professional environment.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.6**l== 0.2**r== 0.1**\nAcademic libraries have established expertise in developing subject support for nursing and offering\ntraining for students on the basis of health information literacy (Purnell, Royal and Warton, 2020), such\nas how to identify database search techniques across different health related sources, using effective\nsearch approaches (e.g., Boolean operators and advanced searching), and how to evaluate and ethically\nuse information following referencing standards and academic integrity. However, health information\nliteracy is also a crucial professional skill for the delivery of evidence-based health information services\n(e.g.,  systematic  literature  reviews).  Academic  libraries  have  been  supporting  nursing  students  to\ndevelop  different  digital  skills  to  navigate  broader  technological  developments,  from  using  internet\nsearch engines and Web 2.0 to sourcing and analysing big data and to the use of digital health services\nfor their potential to advance clinical practice and the delivery of patient care as well as the current\nfocus  on  the  ethical  use  of  generative  artificial  intelligence  for  information  discovery  (e.g.,  using  AI\nSearch Tools). Davenport and Kalakota (2019) discuss the opportunities created by Natural language\nprocessing (NLP) in the health professional environment for “understanding and classification of clinical\ndocumentation and published research” for the purpose, for example, of analyzing unstructured clinical\nnotes,  reports  and  patient  interactions.  Academic  libraries  empower  students  to  engage  with\ntechnology,  explore  digital  content,  and  develop  their  digital  literacy  skills.  Increasingly,  academic\nlibraries  have  also  started  to  develop  support  and  guidance  in  the  form  of  LibGuides  that  focus  on\nnavigating the artificial intelligence (AI) landscape. For example, the University of Cambridge libraries\noffer guidance on the use of AI answering questions such as which AI tools to use, how to get the best\nresults from AI and how to reference AI tools (University of Cambridge 2023). Subject specific Libguides\nin health developed by academic libraries, aim to increase awareness of how it is currently transforming\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nhealthcare with new applications and advancements which enhance health related clinical practice and\nas well as evidence-based research (e.g., systematic reviews) (Khalil, Ameen, & Zarnegar, 2022).  For\nexample, King’s College Libraries and Collections (2024) offers access to AI tools for evidence synthesis\nproviding resources for health students on AI tools and how to use them for learning, research and\nhealthcare related practice.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nHowever,  developing  library  support  and  implementing  digital  skills  programmes  necessitates\nunderstanding of students’ existing digital skills gaps. Not all students arrive to education with the same\ndigital skills and competencies and therefore, ongoing critical exploration of existing digital divides and\nneeds is crucial for offering meaningful digital literacy programmes and support.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.2**r== 0.7**\nJ\nLiterature Review\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.3**l== 0.2**r== 0.1**\nRecent research exploring the development of nursing students’ digital skills or competencies has found\nvariability in focus and directions (Matthews 2021; Nes, 2021) and a lack of a holistic approach to digital\nliteracy skills development in academia. For example, in a scoping review of technological literacy in\nnursing  education,  Nes  identified  several  different  foci,  including  computer  literacy,  health/nursing\ninformatics  and  technology  acceptance,  while  a  direction  towards  higher  level  digital  skills,  such  as\nproblem-solving and critical thinking was omitted. Similarly, Harerimana et al. (2022) highlighted a need\nto incorporate digital literacy education beyond basic computer, internet and digital device use–related\nskills, while Brown et al. (2020) noticed the lack of advanced/more specialised digital skills for transferal\nto the clinical/care working environment. Other research has emphasised gaps in students’ knowledge\non eHealth literacy (Holt et al., 2020; Jeon and Kim, 2022; Mather et al., 2022; Blakemore et al., 2020)\nand students’ attitudes to technology (Lekalakala-Mokgele et al., 2023). However, overall, studies are\ninconclusive  as  the  methodologies  and  measurements  followed  are  either  dissimilar  or  focused  on\ndifferent digital skills required (Erdat et al., 2023).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nBove  and  Sauer  (2023)  explored  levels  of  knowledge  and  skills  that  nursing  academic  staff  should\npossess to teach their students, and the need for both educators and nursing practitioners to embrace\nAI-enabled innovations to “lead the digital future” (Castonguay et al., 2023). The need for continuous\nc\neducation  has  been  identified  for  years  as  a  priority  in  the  European  agenda  to  digitize  healthcare\n(European Health Parliament, 2016, p.8) with a call for mandatory, continuous and tailored training\nprograms on digital skills. At UK level, however, although “Digital health is a high priority in government,\nNHS  organisations  and  Royal  Colleges”  there  is  a  gap  between  expectations  around  digital  skills\ndevelopment and the actual implementation of education within school curricula and training for staff\nvia professional development activities. Post pandemic, the need for digital health education is even\ngreater with remote health consultations and digital health solutions (Holland Brown and Bewick, 2022,\np.214).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nDespite the urgent call for the ongoing development of digital skills, “digital divides” amongst the health\nand  social  care  workforce  (including  nurses)  still  exist.  For  example,  in  relation  to  the  geographical\ninterest of this study, NHS Education for Scotland indicates a digital literacy skills gap in the healthcare\nsector, with key findings from a large-scale digital skills user research study (Digital Health and Care,\n2022), which indicates both a lack of digital skills training and agreed terminology which can result in\ndigital  exclusion,  manifested  though  lack  of  engagement  or  confidence,  competence  and  access\n(Capgemini, 2022).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nTo support nursing students building digital competencies as future professionals operating within a\ncomplex digitally enabled health arena, a holistic understanding of digital skills, gaps and barriers is\nrequired, focusing on moving from baseline to more advanced digital literacy skills development and to\nan  effective  transition  towards  technologically  advanced  health  working  environments  (Lokmic-\nTomkins et al. 2022). This study therefore aims to offer a better understanding of nursing students’\ndifferent levels of digital competencies and explore how digital exclusion experiences may play a role\nin the way in which they develop them.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.9**t== 0.1**l== 0.2**r== 0.7**\nAims and Objectives\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nThis research presents an approach that aims to explore students’ diverse digital competencies that are\nkey  for  learning  and  for  supporting  a  digital  evolving  professional  environment,  as  well  as  examine\nstudents’  diverse  experiences  of  digital  divides.  Specifically,  the  research  addresses  the  following\nobjectives:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nTo explore how nursing students self-assess their digital competencies for nursing related\nlearning and professional practice.\nTo examine nursing students’ digital barriers/divides related to technological access and\nconnectivity (first level divide), digital competencies development (second-level divide), and\nJ\ndigital outcomes (third-level digital divide)\nTo identify the impact of students’ demographic divides on their digital competencies’\no\ndevelopment.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.2**r== 0.3**\nIn relation to Objectives 2 and 3, two working hypotheses were put forward:\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nH1. Self-assessed digital competencies of students will be correlated with students’ experienced digital\ndivides/barriers  (age,  learning  disabilities  (neurodiversity),  urban/rural  geographical  location  of\ngrowing up and study year).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nH2.  Self-assessed  digital  competencies  of  students  will  be  correlated  with  demographic  differences\n(age, learning disabilities (neurodiversity), geographical location and study year).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.2**r== 0.8**\nMethodology\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nThis study followed a cross-sectional survey of nursing students by means of an online questionnaire\nadministered  to  all  students  studying  in  undergraduate  (Year  1,  2  and  3)  and  postgraduate  nursing\ncourses within a single Scottish HE institution. The questionnaire instrument collected quantitative and\nc\nqualitative data in a concurrent mixed methodological survey design, with a) closed ended questions\nexploring students’ demographics (age, learning disabilities (neurodiversity), urban/rural geographical\nlocation of growing up and study year), students’ self-perceived digital competencies, and digital divide\nbarriers  and  b)  open-ended  questions  which  aimed  to  examine,  in  more  detail,  challenges  and\nstrategies of students with learning disabilities/neurodiversity.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nDigital competencies\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.6**l== 0.2**r== 0.1**\nThe  main  position  of  this  research  is  that  students  do  not  arrive  at  university  with  the  same  digital\ncompetencies  and  that  it  is  important  to  consider  the  issue  of  “widening  participation”  and  “digital\ninclusion”  in  nursing  education.   Previous  research  with  students  has  found  that  they  have  positive\nattitudes  and  feel  competent  towards  information  and  communication  technology  use  in  clinical\npractice to support care values and work efficiency (Warshawski et al., 2019). However, not only the\ndigital  environment  is  constantly  evolving,  but  also  more  recent  studies  have  extended  a  focus  on\ntechnological skills to cover additional areas of digital capability that have a behavioural and “soft skills”\nfocus, encompassing digital “learning and development”, “identity and wellbeing”, “problem solving\nand innovation”, “information, data and media literacies” and “digital communication, collaboration\nand  participation”.  These  emphasise  the  importance  of  improving  students’  digital  capabilities  to\nenhance  their  self-efficacy,  confidence  and  self-actualization  in  their  academic  studies  (Ibrahim  and\nAldawsari, 2023).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nIn this study, we utilised an empirically tested digital competencies self-assessment survey tool that\nwas adapted based on the European Digital Competence Framework for Citizens (Carretero et al., 2017)\nand The Digital Capabilities framework (JISC, 2022) to holistically explore digital competencies from a\nnursing-based  perspective.  The  survey  explored  digital  competencies  within  everyday  life,  nursing\nrelated education and practice, addressing nursing related digital competencies with examples from\nthe context of nursing: for example, the use of health related information sources (such as CINAHL,\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nMedline, Cochrane Library), the application of digital creation skills in nursing (such as those for using\nsimulation/virtual reality tools and discipline specific apps, e.g.,  BNF British National Formulary) and\nfor the use of health digital research skills (such as those for using health specific critical appraisal tools,\ne.g., Critical Appraisals Skills Programme (CASP) and evidence-based research tools). The structure and\nthe  dimensions  of  the  questionnaire  survey  are  available  in  Supplementary_material_appendix_A,\nTable A1. The survey measurement was based on a five-point Likert type scale of digital competencies\nwhich  represented  different  levels  of  knowledge  and  self-sufficiency  based  on  performing  specific\ndigital tasks (Supplementary_material_appendix_A, Table A2).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nDigital barriers/divides\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.3**l== 0.2**r== 0.1**\nWei,  Chan  and  Tan  (2011)  highlight  three  potential  levels  of  digital  divide  including  access  to\ninformation technology (first level divide), digital capability (second-level divide), and digital outcomes\n(third-level digital divide) which relate to learning and productivity. In relation to first level divides, data\nin the survey were collected on information technology access barriers experienced by students related\nto an urban/rural divide (up to the time of finishing school), such as lack of access to electricity, and\naccess to basic computer training, broadband, desktop computers/laptop, and smart mobile phones\nuse (Sparks, 2013, p.28; DiMaggio et al. 2010; Wei, Chan and Tan, 2011). Second-level divides were\nexplored by means of identifying self-assessed digital competencies gaps, described above, which were\nfurther elaborated based on contextual and behavioural barriers students experienced in developing\nthem,  such  as  lack  of  time,  up-to-date  training  in  specific  digital  skills  (Gilmour  et  al.,  2008)  and\nstudents’  interest,  urgency,  confidence  and  their  perceptions  of  difficulty  around  developing  these\nskills. These questions helped to explore more holistically intersecting digital divides variables that may\nplay a role in students’ digital competencies development.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.1**\nThird-level digital divides were explored via an overarching question that addressed students’ overall\ndigital abilities to fulfil academic outcomes (Supplementary_material_appendix_A, Table A1).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nAge demographics divides\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.5**l== 0.2**r== 0.1**\nThe impact of age demographics, may be difficult to delineate with different studies following diverse\nways of categorising age groupings (Dimock, 2019). This study focused on a binary categorisation, given\nthe focus of the research on digital skills and digital connectivity: students born before the year 2000\nand students born in that year or after (which characterises approximately the start of Generation Z\nlearners) (Shorey et al., 2021). The change of the millennium marked an important technological shift\nin everyday life digital access and interaction, with the widespread adoption and use of the Internet,\ndigital technologies and social media. People born after the change of the millennium had experiences\nof growing up in a more technologically saturated world and this may have shaped up for them different\nonline experiences. Prensky describes these individuals as ‘Digital Natives’, in other words the “native\nspeakers” of the digital language of computers, video games and the Internet” and the first generation\nto grow up with these new technologies (2001a; 2001b).  In a literature review of 80 studies, Alruthaya,\nNguyen and Lokuge (2021) reported on different research where Gen Z students were found “to be\nable to access digital technologies more than other generations” (Sakdiyakorn et al., 2021), noting a\npreference  towards  visual  versus  textual  information  (Hernandez-de-Menendez  et  al.,  2020).  Other\nstudies focusing on nursing students have reported differences in both everyday life digital activities,\nsuch  as  using  daily  social  media  (Vizcaya-Moreno  and  Pérez-Cañaveras,  2020)  and  preferences  for\nspecific learning approaches, such as experiential learning, independent learning and use of multimedia\n(Hampton and Keys, 2017).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\nLearning disabilities (neurodivergence) divides\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.2**r== 0.1**\nThe  study  also  sought  to  explore  potential  first  and  second-level  digital  divides  within  the\nunderrepresented  15-20%  neurodivergent  student  population  (Doyle,  2020).  Despite  the  high\nincidence  of  neurodivergence  in  students  attending  universities  internationally  (which  is  growing),\nthere  appears  a  dearth  of  neurodivergent  pedagogical  literature  (Hamilton  and  Petty  2023).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nNeurodiversity “is an umbrella term that represents the neurological variability of the human brain”\nwhich includes many terms such as autism, attention-deficit/hyperactivity disorder (ADHD), dyslexia,\ndyspraxia, epilepsy, and obsessive-compulsive disorder (Lukava, et al., 2022 p.76) and can be formally\ndiagnosed or a self-reported protected characteristic (Equality Act, 2010). Although there are various\nstatistics, it is suggested that 15-20% of the population is reported as neurodivergent (Doyle, 2020).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nStudents were asked to first indicate if they had a neurodivergent condition (actual or suspected) in\none or more of the following areas: autism, dyslexia, dyspraxia, dyscalculia, dysgraphia and Attention\nDeficit  Hyperactivity  Disorder  (ADHD).  Following  that,  the  students  were  asked  to  explain  if  they\nencountered  any  problems,  difficulties  or  barriers  when  completing  digital  tasks/using  digital  tools\nrelated to their study.  Finally, students were asked to list any apps, programmes, or digital tools that\nhelped them as a neurodivergent person or any other elements that supported their life or learning\nthat  they  felt  might  also  be  useful  to  others  (e.g.,  for  accessibility,  time  management,  study\norganisation/prioritisation, visualisation).\nu\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nDivides related to rural/urban experiences of growing up\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.3**l== 0.2**r== 0.1**\nThe presence of a “urban/rural digital divide” is “widely acknowledged” in previous research (Philip et\nal.  2017,  p.386)  and  policy  (ITU,  2020)  as  a  determining  factor  for  digital  skills  development.  For\nexample, the Organisation for Economic Co-operation and Development (2021) has described the term\n“digital divide” as “different levels of access and use of information and communication technologies\n(ICTs) and, most often, to the gaps in access and use of Internet-based digital services” which can “vary\nin terms of geography (e.g. as urban and rural areas), by gender, by age, by skill level, by firm size, and\nin general, by different vulnerable groups in society, among others” (pp. 4-5). The European Network\nfor Rural Development (2017) refers to rural areas based on facing the risk of a “double digital divide”,\nlacking  access  to  modern  infrastructure  which  leads  to  “lack  the  basic  skills  and  knowledge  of  the\npotential of digital technology so that even if the ‘digital highways’ are in place, they may remain under-\nexploited” (p.1).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nTo explore experiences of rurality, students were asked to report on the area they mostly lived in when\nthey were a child up to finishing school as this is a time when fundamental digital gaps based on unequal\naccess  to  technology  and  the  internet  would  have  been  created  to  impact  students’  digital  skills\ndevelopment,  disparities,  which  could  be  further  amplified  in  students’  transitions  into  Higher\nEducation.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nValidity and rigour\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.6**l== 0.2**r== 0.1**\nThe self-assessment survey tool has been through different rounds of quality assurance and peer review\nby subject experts in a way that reflects disciplinary needs in the context of both learning and nursing\nprofessional practice, which can “facilitate increased reproducibility of statistical design and reporting”\n(Hildebrandt and Peroneal (2020, p.1). The conceptual framework and the evidence-building processes\nthat underly the methods used in assessing students' self-perceived digital competencies, have been\npreviously reported in different empirical studies with students from diverse subject areas (such as Law,\nLibrary and Information Science and Nursing) (Martzoukou, 2020; 2021; 2023). The strengths of the\nprocess  of  self-assessment  have  also  been  extensively  discussed  in  previous  research  on  students'\nInternet  skills  development  (Van  Deursen  et  al., 2014)  highlighting  its  value  in  improving  students’\nlearning  (Klenowski,  1995;  Ross,  2006;  JISC,  nd).  However,  within  a  fast-developing  technological\nenvironment,  iterative  changes  of  the  questionnaire  were  necessary  for  the  purpose  of  this  study,\naddressing emerging digital skills areas, such as artificial intelligence.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nThe  reliability  of  the  amended  survey  instrument  was  tested  using  Cronbach's  alpha.  The  results\nshowed that all item groups in the questionnaire had a Cronbach's alpha index much higher than 0.7,\nwith almost all the values above 0.9. The lowest value was 0.897 for information literacy (identification\nof different information types) and the highest was for digital wellbeing (0.980) (Table 3). As the sample\n**BLOCK**fs== 10.0**p== 8.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nsize was small with ordinal scale data, non-parametric tests were employed in the analysis (Corder and\nForeman, 2014).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.9**t== 0.1**l== 0.2**r== 0.8**\nSampling\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.2**l== 0.2**r== 0.1**\nThe research design followed a total population sampling approach with email invitations sent to all\nthe  population  of  Undergraduate  (UG)  and  Postgraduate  (PG)  students  studying  at  the  School  of\nNursing,  Midwifery  and  Paramedic  Practice  at  the  Robert  Gordon  University  in  Aberdeen,  Scotland.\nThe  students  were  recruited  following  a  targeted  approach  which  involved  meeting  them  online,\nduring planned  ‘stage  meetings’  sessions,  designed  as  part  of  their  preparation  for  practice  at  the\nNHS.  An hourly online meeting was organised with each stage group (i.e., Stage 1, 2 and 3, which is\nequivalent  to  Year  1,  2,  and  3)  as  well  with  MSc  students.  During  the  meeting  the  students  were\nbriefed on the purposes, objectives and procedures of the research project and they were then asked\nto  fill  in  an  online  questionnaire  survey.  The  sample  consisted  of  555  students  out  of  the  potential\npopulation  of  964  UG  students  and  32  PG  registered  students  in  the  school,  representing  a  total\nresponse  rate  of  55.5%  (two  respondents,  however,  were  removed  from  this  sample  due  to\ninsufficient  data).  The  rationale  for  inviting  all  students  was  that  they  attended  diverse  courses\ncovering  adult,  mental  health,  and  children  and  young  people’s  nursing  and  it  was  important  to\nensure  adequate  representation  from  all  groups  and  capture,\nin  a  holistic  way,  different\nperspectives  on  digital  competencies  development  and  experiences  that  related  to  digital  divide\nbarriers. Detailed demographic characteristics are provided in Table 1. The survey was administered\nin June 2023 with student voluntary and anonymous participation and informed online consent.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nEthical considerations\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.1**\nThe  research  project  was  approved  by  the  ethics  committee  of  the  school  in  the  participating\ninstitution  in  the  UK  with  GDPR  (2018)  compliance.  The  ethical  procedure  followed  the  school\nresearch  ethics  policy,  addressing  anonymity,  confidentiality,  informed  consent,  the  right  to\nwithdraw, data handling, privacy, and potential risks, for example, reassuring students that the results\nc\nof  the  survey  would  not  be  linked  to  their  academic  progress  and  that  none  of  the  students\nwould  be  identifiable  via  the questionnaire outcome.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.6**l== 0.2**r== 0.8**\nData Analysis\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.6**l== 0.2**r== 0.1**\nIBM SPSS Statistics (v28) was employed for the statistical analysis of the survey data (IBM Corp, 2022)\nto  explore  correlations  between  age  and  study  year  demographic  data,  digital  competencies  and\ndigital divides. Cronbach's alpha was used to assess the internal consistency reliability of the survey\ntool.  The  results  were  reported  through  descriptive  statistical  analysis  (frequencies,  valid\npercentages  and median values). Following Kolmogorov–Smirnov and Shapiro–Wilk normality tests,\nthe questionnaire items  did  not  follow  a  normal  distribution  and  therefore,  Mann–Whitney  (U-\ntest)  non-parametric  statistical  test  was  used  to  identify  significant  statistical  differences  between\ndifferent  groups.  A  p  value  of  <.05  was  followed  to  indicate  statistical  significance  for  all  the  tests.\nPrincipal components analysis (PCA)  following  the  varimax  orthogonal  rotation  method  was  used\nto  identify  groups  of  digital competencies in (Supplementary_material_appendix_B, Tables B1-13).\nWe  considered  factors  reaching  eigenvalue  1  as  a  factor  extraction  method  following  Kaiser’s\ncriterion.  The  results  of  Bartlett’s sphericity test at p < 0.05 and the Kaiser Meyer–Olkin (value of\n0.6 or above) confirmed the suitability of  our  dataset  for  structure  detection.  Bivariate  correlation\nstatistics  between  all  clustered  variables  reported\nthe\ndifferent  items  of  the  research  instrument (Supplementary_material_appendix_B, Table B14).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nthe  statistical  associations  between\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nThematic analysis and manual coding (Kiger and Varpio, 2020) was applied to the survey qualitative\nopen data identifying key themes reflected in the questions with subthemes.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\nLimitations\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nThe main limitation of the study comprises of a potential narrow perspective of a group of students\nstudying  within  a  single  university  and  country.  Therefore,  the  results  of  the  survey  should  be\ngeneralized with caution. However, the approach followed presents a replicable process that can offer\na more holistic framework to study the digital competencies development of students in a discipline\nfocused way and design subject related learning interventions in nursing curricula.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nSurvey results\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nDemographics\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nThe  majority  of  the  participants  were  female  (91.3%,  n=505),  undergraduate  students  studying  BSc\nNursing  (96,9%,  n=536),  with  almost  an  equal  split  between  those  born  on  or  after  the  year  2000\n(Generation  Z)  (51.1%,  n=282)  and  those  before  (49%,  n=271).  The  female  gender  demographic\ncomposition of students in this study is not surprising as it reflects a gender imbalance that is evident\nin the nursing profession overall (RCN, 2018). Most of the students were born in Great Britain (73.6%,\nn=407)  with  the  next  larger  group  being  Nigerian  students  (8.9%,  n=49).  Approximately  a  third  of\nstudents studied in Year 1 (35.8%, n=198), in Year 2 (29.1%, n=161) and in Year 3 (35.1%, n=194) and\nmost had a part-time job while studying at university (Table 1).\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\n{insert Table 1 Demographic characteristics around here}\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nSelf-assessed digital competencies results\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.4**l== 0.2**r== 0.1**\nTables B1-B13 (in Supplementary_material_appendix_B) summarize the descriptive statistics in all the\nsurvey  digital  competencies  items  using  frequencies  and  median  values.  In  addition,  subgroup  test\nstatistics for all demographic variables are reported through Mann–Whitney U test and Kruskal-Wallis\nH  tests.  The  strongest  area  reported  was  ‘Digital  wellbeing’  with  all  the  items  at  median  4.0\n(‘advanced’). This was followed by ‘Everyday life as a digital citizen’, were most of the items were at\nc\n‘advanced’  level  (median  4.0),  while  three  items  were  at  ‘intermediate’  level:  ‘e-democracy’,  ‘e-\ngovernment’  and  ‘e-employment’  (median  3.0)  and  ‘ICT  Proficiency’  were  two  items  were  found  at\n‘intermediate’  (median  3.0) level: ‘University  management systems’ and ‘Communication  platforms’\nwhile the rest were all at ‘advanced’ level. ‘Digital communication’ was also a strong area for the group\nwith the majority of items reported at ‘advanced’ (median 4.0) level, while three directions were found\nto be at intermediate level.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.6**l== 0.2**r== 0.1**\n‘Digital identity management’ was mainly at ‘intermediate’ level with two areas at ‘advanced’ (median\n4.0) level: ‘Being aware of the potential positive or negative impact of what you communicate online\non your online reputation’ and ‘Understanding the impact of your online interactions’. ‘Information\nliteracy’,  was  found  at  ‘intermediate’  level,  with  only  a  single  item  performing  at  ‘advanced’  level:\n‘Popular  information’  (median  4.0).  ‘ICT  productivity’,  ‘Digital  Innovation’  and  Digital  Learning  and\nDevelopment’  were  found  to  be  at  ‘intermediate’  level  in  all  items.  ‘Digital  creation’  and  ‘Digital\nresearch skills’, were both at ‘intermediate’ level throughout, expect for the creation of ‘infographics’\nin  the  former  category  and  ‘Using  a  Critical  Appraisal  Tool’  in  the  latter  category,  that  were  both\nreported at ‘basic’ level (median 2.0). Overall, nursing students assessed themselves at “intermediate”\nlevel (median 3.0) in most of the survey constructs and in relation to their digital ability to complete\nacademic work.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nAge  demographics  significant  differences  were  identified  in  several  areas  (Supplementary_material\n_appendix_B), including ‘Digital Learning and Development’ (Table B10), ‘Digital Identity Management’\n(Table B11) and ‘Digital Wellbeing’ (Table B12). In addition, significant differences were identified in\nfive items within ‘ICT Proficiency’ (Table B2), three items in ‘Digital Innovation’ (Table B9), seven items\nin ‘Digital Communication’ skills (Table B8), five items in ‘Digital creation skills’ (Table B6) and three\nitems  in  ‘Everyday  participation  as  digital  citizens”.  There  were  also  other  individual  items,  where\nsignificant differences were observed: ‘Sharing securely your digital files with others’ (ICT Productivity)\n(Table B3), ‘Finding digital information relevant to your academic studies, using databases’ (Information\n**BLOCK**fs== 10.0**p== 10.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nLiteracy) (Table B5) as well as ‘Organising and storing research raw/open data online’ and ‘Using a survey\ntool’ (Digital Research) (Table B7). It is interesting to note that the direction of the mean rank values of\nthe non-parametric (Man Whitney) test indicated that students who were born in year 2000 or after\nself-assessed higher overall based on their digital competencies.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nIn addition, significant differences were observed between first year and continuing students in the\nfollowing digital competencies items, where the former group self-assessed higher:  ‘Digital Creation’\n(one item: ‘Vlog/Podcasts’)  (Table B6), ‘ICT Proficiency’  (one item: ‘Search engines’) (Table B2),  ‘Digital\nInnovation’  (one  item:  ‘Working  collaboratively  on  different  aspects  of  a  creative/innovative\nproject/service  design  &  managing  the  process  as  a  team’)  (Table  B9)  and  ‘Digital  learning  and\ndevelopment’ (one item: ‘Using online tools to record learning events/outcomes and use them for self-\nanalysis, reflection, and showcasing of achievement’) (Table B10). Continuing students, on the other\nhand, only self-assessed higher in two items in ‘Information Literacy’ (‘Scholarly Academic Literature’\nand ‘Professional Literature’) (Table B5) and in one item in ‘Everyday participation as digital citizen’ (‘e-\ndemocracy’) (Table B1).\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nIn  relation  to  the  overarching  academic  outcomes  question  ‘Which  level  best  describes  your  digital\nabilities to complete your academic work’ (B13), significant differences were found on the basis of: a)\nage demographics, b) digital challenges experienced in the area in which students mostly lived (e.g.,\nrural/urban  before  joining  the  university  (e.g.,  access  to  electricity,  computer,  laptop,  mobile  more,\ntablet, broadband, basic computer training),  c) digital barriers students had experienced in relation to\nproactively developing their digital skills and d) year of study.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nGrouping Variables\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nFurthermore, the study employed PCA (Principal Component Analysis) to reduce the number of digital\ncompetencies  variables  in  the  dataset  and  Exploratory  Factor  Analysis  (EFA)  for  the  purposes  of\nassessing whether they were representative of each of the of each of the underlying construct. PCA\nc\ntransforms  a  set  of  variables  into  a  smaller  set  of  variables,  called  “principal  components”,  which\naccount for most of the variance in the original variables (Comrey and Lee, 1992). PCA with Varimax\nrotation was employed for grouping the digital competencies constructs. The output of this process is\npresented in Supplementary_material_appendix_C, Tables C1-C12. The use of KMO and Bartlett Test\nof  Sphericity  indicated  that  it  was  possible  to  proceed  with  principal  components  factor  analysis\n(Tabachnick and Fidell, 2007).  Each of the survey constructs were grouped into a single component,\nwhile the single-item factor loadings were quite high.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nThe  descriptive  statistics  (mean  and  standard  deviation)  of  the  examined  constructs  for  the  entire\nsample are presented in the last two rows of Tables C1-C12. As it can be observed that higher digital\ncompetencies  were\n‘ICT\nfor ‘Digital  Wellbeing’\nProficiency’ (mean = 3.64). Low competencies were reported for ‘Digital Creation’ skills (mean = 2.77)\nand ‘Digital Research’ skills (mean = 2.87).\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nreported\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nPearson  correlation  coefficients  and  the  corresponding  significance  levels  for  all  the  construct\ncomponents are presented in Table C13 with Pearson's test (2-tailed) at significance level p < 0.05(*)\nand significance level p < 0.01(**). It is worth noting that strong statistically significant correlations at\nlevel p < 0.01(**)  were  identified  between  almost  all  the  self-reported  dimensions  of  digital\ncompetencies,  encompassing  digital  skills  that  were  related  to  everyday  life  digital  activities  to  ICT\nproficiency  and  productivity,  information  literacy,  and  digital  creation,  research  communication,\ninnovation, identity management and wellbeing.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.9**l== 0.2**r== 0.4**\nWhat would empower students to further develop their digital skills\n**BLOCK**fs== 10.0**p== 11.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nIn the survey, students answered an open-ended question which helped to contextualize the above\nfindings. The question centered on ways that would empower them to further develop their digital\nskills.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nStudents mentioned several digital skills areas they would need further support with or training on,\nincluding learning new software/tools and understanding university systems (e.g., Moodle). Digital skills\ndevelopment  was  centred  on  completing  coursework,  such  as  preparing  online  posters  and\npresentations (PowerPoint) and formatting information, using referencing tools (such as RefWorks),\ndeveloping online database searching skills/library searching, data analysis (e.g. Microsoft Excel), digital\nproductivity tools for note-taking and time management. In relation to digital creativity tasks, several\nskills  mentioned  addressed  blogs,  podcasts  and  creating  videos,  while  in  relation  to  digital\ncommunication,  students  referred  to  skills  for  using  social  media  and  for  digital  learning  and\ndevelopment (e.g., e-portfolio).\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.3**l== 0.2**r== 0.1**\nRespondents also offered ideas for different preferred types of training including workbooks/tutorials,\npresentations,  bitesize  guides,  video  guides  and  tutorials,  as  well  as  online  training  and  courses,  in-\nperson  sessions  and  one-to-one  support.  Whatever  the  method  proposed,  students  preferred  clear\nexplanations,  “consistent  information\",  and  “accessible  interfaces”,  while  several  respondents\nmentioned tailored support that is relevant to their careers. In addition, students’ comments indicated\nthat  digital  skills  should  be  taught  early  in  a  course  and    in  collaboration:  “Taught  earlier  and  in\ncollaboration with study skills and the library”, “Teach more in first year to help us build every year we\nstudy more sessions when beginning uni to go over how to use the systems”, “Incorporating structured\ndigital skills education and identification of beneficial skills from the beginning of the course”, “Study\nskills and library support to teach a class at the start of each academic year as a reminder”. In addition,\nmore time dedicated to digital skills development was necessary: “What would empower me would be\nmore  time  to  do  digital  skills”,  “More  time  -  life/study  balance”,  “More  time  to  practice”.  Personal\nc\nmotivation to develop digital skills was equally deemed important. As one student explained: “I decide\nwhat I feel is relevant for me to know and the things that I have self-assessed as lower are not important\nor useful to me”, indicating that a low score on certain digital skills could mean that students were not\nengaged with the particular skills, or they deemed them necessary or unimportant:\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\n“I don't know I don't use certain things or have interest in doing blogs or podcasts etc so that’s why I\nscore low in sections related to that not sure really not interested in using many online tools I like pen\nand paper”.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\n“It’s down to priorities. When content isn’t so engaging or urgent I don’t feel the need to reach out for\nhelp so much”.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\n“Motivation for using these tools is lacking for me. I’m not sure how this can be supported by academic\nstaff but perhaps if more coursework demanded the use of these digital skills”.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.1**t== 0.7**l== 0.2**r== 0.1**\nStudents required an “interest to learn” which could be triggered by connecting these skills to their\ncourse  related  experiences  together  with  reassurance  and  guidance  that  they  were  “in  the  right\ndirection”. As students also explained, digital skills classes could be part of a course: “Incorporate these\nclasses into our timetable” and, in that way, students could be “given time within the module to learn\nthat skill”, especially if “an assignment was in line with a digital literacy skill that I’m lacking”. In addition,\nteaching staff could use more advanced and interactive tools that would “inspire” them to “develop\ndigital  skills  in  these  areas”  and  “actively  involve”  students  “in  digital  learning  and  collaboration\ninitiatives - e.g., sharing project results online”. Interestingly, beyond embedding digital skills into the\nstudy programme, students’ perspectives overall, conveyed a sense of connecting the significance of\ndigital skills to the purposes of academic study rather than to digitally-enabled nursing practice.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nStudents  had  experiences  of  growing  up  in  both  urban  (44.7%,  n=247)  and  rural  (46.5%,  n=257)\ngeographical  areas  (Table  2).  First  level  digital  divides  were  identified  in  17%  (n=97)  of  the  study\npopulation, who reported having experienced digital challenges prior to joining the university (such as\naccess to electricity, computer, laptop, mobile more, tablet, broadband, basic computer training), while\n77.9% (n=431) reported experiences of at least one second-level barrier to developing their digital skills\n(e.g., lack of time, training, interest, urgency, confidence, task complexity) (Table 2).\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.2**l== 0.2**r== 0.1**\nGeographical location was not found to directly play a role in the way in which students self-assessed\nspecific digital competencies, although they had an impact on the digital abilities self-assessment of\nstudents  for  overall  completing  academic  work.  Significant  statistical  differences  were  identified\nbetween  students  who  experienced  at  least  one  of  the  listed  first  level  digital  divides  (e.g.,  lack  of\ncontinuous access to electricity, access to a desktop computer, smart mobile phone, tablet broadband,\nor basic computer training) and self-assessed digital competencies. Students who encountered digital\nr\nchallenges/divides were more likely to self-report lower digital competencies than students who did\n‘Everyday  participation  as  digital  citizens’\nin\nnot.  The  most  notable  differences  were\n(Supplementary_material_appendix_B, Table B1), ‘Digital Creation’ (Table B6) and ‘Digital Innovation’\n(Table B9), where statistically significant correlations were found across all question items. These were\nfollowed  by  ‘ICT  Proficiency’  (Table  B2)  and  ‘Digital  Identity  Management’  (Table  B11),  where  all\nquestion items, except for one, were found significant. Additionally, there were three items identified\nin ‘ICT Productivity’ (Table B3), ‘Digital Research’ (Table B7), and ‘Digital Communication (Table B8),\ntwo items in ‘Information Literacy’ (Table B5) and ‘Digital Learning and Development’ (Table B10) and\none item in ‘Digital wellbeing’ (Table B12).\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.2**r== 0.1**\nSignificant statistical differences were also found in second level digital barriers and self-assessed digital\ncompetences, indicating that students who had experienced at least one of the listed barriers in that\ncategory (e.g., lack of time, training, interest, confidence) were more likely to self-report lower digital\nc\ncompetencies than students who did not encounter any challenges.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\n{Insert Table 2 Digital challenges and barriers}\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nLearning Disability (neurodivergence) Divides\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nA total of 89 students (16.1%) self-reported a neurodiverse condition, while 82 (14.8%) indicated that\nthey may be neurodivergent, but they are not sure, or they have not been formally diagnosed. The high\npotential  incidence  of  neurodivergent  students  in  this  study  (total  of  30.9%,  n=171)  is  in  par  with\nprevious studies where a percentage as high as 33% has been reported (HESA 2021) (Table2).\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.7**l== 0.2**r== 0.1**\nLearning disabilities (neurodivergence) were not found to play a role in students’ digital competencies\nself-assessments  as  no  significant  differences  were  identified  based  on  that  variable,  although\ntransitions are reported as a significant issue for neurodivergent students in previous research (Bakker\net  al.  2023).  However,  students  shared  additional  ideas,  which  helped  to  further  contextualize  the\nfindings  in  the  area  of  digital  divides  connected  to  learning  disabilities.  For  example,  different\nchallenges they experienced with ICT proficiency and productivity, such as keeping focused on tasks\nand avoiding distractions and reading on screen (Supplementary_material_appendix_D, Table D1):\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\n“Struggle to focus on one thing at a time, easily distracted, always need to be doing\nsomething else at same time as doing digital tasks”.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nStudents with Dyspraxia, who typically have difficulty with motor skills in their learning ability to write,\ntype, draw and grasp small objects, also mentioned that the design of the keyboard tools with smaller\nobjects can become an issue for them:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.9**t== 0.1**l== 0.2**r== 0.4**\n“I find it hard to find the correct keys when typing”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nIn  addition,  students  mentioned  challenges  which  could  create  problems  with  feeling  overwhelmed\ndue to information overload that could have a negative impact on processing information from multiple\nonline sources or complex tools which could be a barrier to information literacy and digital research\nskills development:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\n“Being presented with large amounts of information at once makes it difficult to\ncomprehend instructions or maintain focus without feeling overwhelmed”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nStudents  required  more  support  in  navigating  different  technologies  and  assistive  tools  available  to\nJ\nthem  and  they  preferred  solutions  considering  the  unique  challenges  of  their  specific  conditions,\nespecially dyslexia:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\n“Try to use systems available but would be interested to see more specific for dyslexia”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nSeveral students also shared different methods and strategies for overcoming these challenges, with\nthe most popular being using assistive technologies (which were popular with dyslexic students) and\naudio-visual strategies (Supplementary_material_appendix_D, Table D2):\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\n“I have found apps such as Read & Write Gold extremely helpful. Grammarly has also\nhelped”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nBesides the use of videos, students with autism specifically, highlighted the use of time-management\nmemory-improving tools to address a need for structured learning actions:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\n“Good routine helps me, so things like a calendar and well-organised meetings”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.5**l== 0.2**r== 0.1**\nStudents with dyscalculia mentioned the need for “Numeracy tools would be helpful to enhance my\nnumeracy skills”, referring to “Websites calculators and British National Formulary (BNF) app” and to\nc\nthe of “dyscalculia-friendly fonts and coloured backgrounds to help the numbers stand out”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nStudents with dyspraxia revealed the use of multiple tools to overcome challenges around a set of skills\nknown as transcription and writing. Again, students used Grammarly, Dragon, Read and Write Gold and\nDragon:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\n“An app that converts my handwriting into text. Also, dragon that turns speech into text”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.2**r== 0.3**\nHowever, students also highlighted that some students can have multiple disabilities.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nSeveral students with ADHD mentioned challenges related to lack of attention to detail and continually\nstarting new tasks before finishing old ones, also reporting that they were unaware of tools available\nto them, highlighting a need for the development of a toolkit considering apps, programmes and digital\ntools to support them:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.7**l== 0.2**r== 0.4**\n“There are none that I have found or know about”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nHowever, some students mentioned using various assistive technology tools to manage their workload\nsuch as “Speechify app”, “Google Calendar for planning”. As another student explained:\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\n“I need to make sure I am very organised, and I write everything down. Lately, I put tasks I don't want\nto forget in my calendar on my iPad because that gives me the best overview of everything. I colour-\ncode everything as well, which is very helpful”.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nStudents mentioned the effective role of the university’s support services in supplying these assistive\nlearning technology tools: “I have many tools on my laptop provided by the learning team now” and\n“The  university  has  supplied  me  with  a  laptop  with  various  apps  on  to  help  with  this”.    They  also\nmentioned  several  approaches  that  bring  structure  into  their  learning  process,  such  as  listening  to\nmusic,  taking  small  “breaks  little  and  often”,  and  advised  that  making  “lectures  more  interactive  or\n**BLOCK**fs== 10.0**p== 14.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nprerecorded  so  we  can  pause  and  take  breaks  when  necessary  to  stay  focused”  and  “Videos  and\nvisualisation” are beneficial for their comprehension.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nDiscussion\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\nThis study sought to explore how nursing students self-assess based on their digital competencies and\nto further understand any existing obstacles to digital literacy development they encountered. Digital\nexclusion in Higher Education has been examined in previous research, however, most frequently, at\nthe level of technological infrastructure and internet connectivity and in relation global geographical\ndivisions created between the Global North and the Global South countries (Thomas-Slayter, 2003),\nwhere  people  are  more  likely  to  experience  poverty  and  limited  access  to  resources  or  educational\nopportunities (ACU, 2020, Lembani et. al., 2020). At EU level, it has been reported that digital divides\nbased on accessibility have been reduced over the last years, however, there is still a fundamental need\nfor upskilling, with one of the four key goals of the European Commission (2021) focusing on “a digitally\nskilled population and highly-skilled digital professionals”.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nThis need for upskilling was also prevalent in this study in which nursing students self-assessed their\ndigital competencies at intermediate level in most digital skills areas. This research also offered a better\nunderstanding of how students may transfer into HE existing digital divides from everyday life in a way\nthat may have an impact on their follow up digital literacy development; these highlight the need for\nfurther  learning  opportunities  to  develop  digital  skills  that  meet  the  expectations  of  the  nursing\nprofession,  particularly  with  the  emergence  of  new  innovative  technologies  and  AI  related\ntransformations that require advanced digital skills (Rony, Parvin and Ferdousi, 2024).\n**BLOCK**fs== 10.0**p== 14.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nSignificant differences were also observed in relation to age demographics, with younger students self-\nassessing  their  digital  competencies  at  a  higher  level  overall.  In  addition,  first  year  students  self-\nassessed higher than continuing students in certain digital skills areas, which required digital creation,\nc\nICT proficiency and innovation skills, while continuing students were stronger in information literacy,\nwhich  presents  a  fundamental  academic  skill,  especially  in  nursing  education  and  practice,  where\nevidence-based practice is a core direction in clinical decision making and for the delivery of quality\nhealthcare  (Majid  et  al.,  2011).  On  the  other  hand,  research  skills  did  not  appear  to  be  an  area  of\nstrength of students, possibly because most of the students were UG and in their first year of study.\nThis signifies a need to develop more robust strategies for supporting students at early levels to excel\nin  digital  research  foundational  skills.  Further  research  replicating  this  methodology  could  further\nexplore this outcome with diverse students at different study levels.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.1**t== 0.6**l== 0.2**r== 0.1**\nThis  research  also  offered  a  deeper  contextual  understanding  of  the  diverse  range  of  digital  skills\nchallenges  and  the  variability  of  strategies  followed  by  neurodivergent  students  which  signifies  the\nneed for a universal design to nursing education to accommodate diverse needs and requirements of\nall learners (Halligan et al., 2019). In this study students’ existing neurodiverse conditions did not appear\nto  play  a  role  in  the  way  in  which  they  self-assessed  their  digital  competencies.  This  adds  some\nadditional  evidence  to  the  position  that  people  with  neurodiverse  conditions  do  not  necessarily\nencounter challenges in their development of digital skills more broadly and may instead be presented\nwith unique opportunities in digital tech employment environments that require digital innovation and\ncreativity  (Autism  Network  Scotland,  n.d.).  Despite  this  result,  neurodivergent  students  described\ndifferent  barriers  they  experienced  particularly  within  the  areas  of  ‘ICT  proficiency’  and  ‘ICT\nproductivity’,  where  they  recommended  available  tools  and  strategies  that  can  assist  in  keeping\nfocused on tasks and avoiding distractions. These suggestions can assist in developing more tailored\nand informed digital skills support. They also offered personal strategies for overcoming these barriers,\nwhich provide helpful insights and directions for digital skills programme development. It is important\nto  cater  for  these  challenges  in  a  way  that  is  different  according  to  the  individual  neurodivergent\nconditions of students.\n**BLOCK**fs== 10.0**p== 15.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nOverall, the strong statistical correlations between the self-reported digital competencies dimensions\nin  this  study,  offered  empirical  evidence  of  the  interplay  between  everyday  life,  learning  and  work-\nrelated digital competencies, putting forward the need for a more holistic approach to the teaching of\ndigital skills in nursing education. Previous research with nursing students has mainly placed emphasis\non  individual  digital  skills,  such  as  “digital  professionalism”  (Mather  et  al,  2018),  electronic  health\nliteracy (Anderberg et al. 2019, p. 5), or information literacy (Aylward et al. (2020), centred on “the\nreliability and validity of online health care information” (Blakemore et al., 2020). Other research has\nexplored the socio-emotional factors on students’ digital literacy, such their awareness of digital issues\nin the online environment (Erdat, 2023; Okumus and Atılgan, 2021; Park, 2013).\n**BLOCK**fs== 10.0**p== 15.0**b== 0.5**t== 0.2**l== 0.2**r== 0.1**\nThe  above  findings  offer  important  directions  for  the  nature  of  support  that  academic  libraries  can\nprovide  for  nursing  students’  development  of  digital  competencies.  The  most\nimportant\nrecommendation  addresses  the  need  to  design  tailored  digital  literacy  programmes  which  focus  on\nspecific digital skills, such as digital creation and digital research and in a way that carers for the needs\nof different students (e.g., first year and continuing students).  Digital literacy programs should not only\nbe offered at an appropriate knowledge level, but also support nursing students to develop awareness\nof state-of-the art knowledge of digital tools and methodologies for healthcare, such as evidence-based\npractice,  predictive  analytics  and  artificial  intelligence  for  patient  care  and  clinical  decision-making\n(Agnew, 2022). Finally, more emphasis is necessary in promoting the importance of continuous learning\nand  upskilling  in  digital  competencies  and  the  relevance  of  advanced  digital  skills  in  the  context  of\nemerging  technologies  and  transformations  in  healthcare.  Current  research  points  to  evidence  that\nlibrary  support  has  a  positive  impact  on  nursing  students’  information  literacy  skill  development\n(Purnell, Royal and Warton (2020). However, information literacy skills development takes place within\nthe  context  of  developing  a  range  of  digital  skills  that  involve  other  interrelated  skills,  such  as  ICT\nproficiency, digital communication and digital learning and development, among others. Approaching\nthe development of digital skills holistically means working synergistically with students and adopting\na  learner-centered  approach  that  identifies  and  addresses  existing  gaps  in  information  and  digital\nliteracy.  This  approach  necessitates  nurturing  a  lifelong  learning  mindset  in  students  to  ensure\ncontinuous skills development.\nc\n**BLOCK**fs== 10.0**p== 15.0**b== 0.5**t== 0.5**l== 0.2**r== 0.8**\nConclusion\n**BLOCK**fs== 10.0**p== 15.0**b== 0.2**t== 0.6**l== 0.2**r== 0.1**\nThere is not a one-fits-all approach to digital competencies development, as not one student is similar\nbecause of their individual characteristics and life experiences. However, developing a more informed\nunderstanding  of  students’  digital  competencies  gaps  and  the  multiple  shapes  that  digital  exclusion\nmay take is important for the design of meaningful digital skills enhancement programmes in Higher\nEducation.  As this study showed, digital competencies were not only multidimensional, complex and\ninterrelated, but also influenced by diverse digital challenges and barriers. The results of this study put\nforward  the  importance  of  libraries  collaborating  with  schools  for  offering  a  discipline-based  and\ntailored scaffolding approach to the development of nursing students’ digital competencies, as opposed\nto a ‘one fits-all’, generic or baseline direction. Higher Education should focus on equipping students\nwith discipline related digital skills and knowledge in a way that relates to students’ future professional\ntrajectories and ensure a “digitally fluent workforce” (Lokmic-Tomkins, et al., 2021), not only a digitally\nfluent student. It should also develop increased awareness of the digital barriers and experiences that\nstudents encounter within their everyday lives. This involves a continuous engagement with evolving\ndigital skills needs in the profession and a focus on students’ learning and development for life. Future\nresearch  should  explore  the  parameters  of  interrelated  digital  skills  withing  everyday  life  and  work\nenvironments and examine how experiences within different settings influence strategies for students’\nongoing learning and professional growth.\n**BLOCK**fs== 10.0**p== 15.0**b== 0.1**t== 0.8**l== 0.2**r== 0.1**\nFinally,  it  is  important  to  note  that,  although  this  study  explored  nursing  students,  its  design  and\nfindings  are  relevant  and  applicable  to  digital  divides  that  may  be  present  in  other  student\npopulations. Digital  competencies  is  a  critical  skillset  for  students  across  different  disciplines  and\nnot  unique  to nursing,  and,  as  changing  digital  technologies  become  integral  to  different  aspects\nof  learning  and  diverse  professional  practice,  it  is  important    to  develop  tailored  digital  literacy\nsupport, informed by detailed  understanding  of  students’  development  needs,  in  a  way  that  relates\nmeaningfully to their study directions, their future professional trajectories and their individual\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nknowledge levels and skills.  The research methodology applied in this study has already been tested\nwith  other  student  populations  with  the  aim  to  explore  pockets  of  digital  inequalities  across\ndifferent  discipline  areas,  such  as  Law  (Martzoukou  et  al.,  2022)  and  Information  Science\n(Martzoukou et al. 2020), with the input of academic staff/students  and  with  the  aim  to  offer  digital\nliteracy  training  and  support  and  enhance  students’  digital  capacity  as  future  professionals.  In\naddition,  the  study’s  novel  insights  into  the  digital  challenges  that  neurodivergent  students\nencounter  demonstrates  the  necessity  for\ninclusive  educational  strategies,  in  a  way  that  can\nbe  applied  to  other  fields  beyond  nursing,  to  ensure  that  all  students, regardless of their learning\nneeds, have equal opportunities to develop essential digital competencies.\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nReferences\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nAgnew, T. (2022).” Digital engagement in nursing: the benefits and barriers, Nursing Times, Vol. 118\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\no\nIssue 3, pp.1-4\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nAlruthaya, A., Nguyen, T., & Lokuge, S. (2021). “The application of digital technology and the learning\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.3**\ncharacteristics of Generation Z in higher education”, available at:\nhttp://arxiv.org/pdf/2111.05991.pdf (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nAnderberg, P., Eivazzadeh, S., & Berglund, J. S. (2019). “A novel instrument for measuring older\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\npeople’s attitudes toward technology (TechPH): Development and validation”. Journal of\nMedical Internet Research, Vol. 21. No. 5, e13951. https://doi.org/10.2196/13951\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nAtherton, P. 2020. “The digital divide and other big questions - education and COVID-19”. Medium,\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\navailable at: https://peteath.medium.com/the-digital-divide-and-other-big-questions-\neducation-and-covid-19-f74f9c1963c6 (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nAutism Network Scotland (n.d.) “Neurodiversity in Digital Technology Summary Report”, available at:\n**BLOCK**fs== 10.0**p== 16.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nhttps://www.autismnetworkscotland.org.uk/documents/view/1cea599e-a02f-47c0-aa07-\nf75e02664854.pdf (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nc\nAylward, K., Sbaffi, L., & Weist, A. (2020). “Peer-led information literacy training: a qualitative study of\nstudents’ experiences of the NICE Evidence search Student Champion Scheme”. Health\nInformation & Libraries Journal, No. 37, No. 3, pp. 216-227. https://doi.org/10.1111/hir.12301\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nBlakemore, L. M., Meek, S. E., & Marks, L. K. (2020). “Equipping learners to evaluate online health\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\ncare resources: longitudinal study of learning design strategies in a health care massive open\nonline course”. Journal of Medical Internet Research, Vol. 22, No.2, e15177.\nhttps://doi.org/10.2196/15177\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nBove, L. A., & Sauer, P. (2023). “Nursing faculty informatics competencies”. CIN: Computers,\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.6**l== 0.2**r== 0.4**\nInformatics, Nursing, Vol. 41, No. 1), pp. 18-23.\nhttps://doi.org/10.1097/CIN.0000000000000894\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nCapgemini (2022). “User Research for a Shared Library of Digital Skills Learning Resources”. NHS\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nEducation for Scotland (NES), available at: https://learn.nes.nhs.scot/63467 (accessed\n30/08/2024)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nCarretero, S., Vuorikari, R., & Punie, Y. (2017). “DigComp 2.1: The digital competence framework for\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\ncitizens with eight proficiency levels and examples of use”. Publications Office of the European\nUnion, available from\nhttps://publications.jrc.ec.europa.eu/repository/handle/JRC106281(accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nCastonguay, A., Farthing, P., Davies, S., Vogelsang, L., Kleib, M., Risling, T., & Green, N. (2023).\n**BLOCK**fs== 10.0**p== 16.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\n“Revolutionizing nursing education through AI integration: A reflection on the disruptive\nimpact of ChatGPT”. Nurse Education Today, Vol. 129, p. 105916.\nhttps://doi.org/10.1016/j.nedt.2023.105916\n**BLOCK**fs== 10.0**p== 16.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nChang, J., Poynton, M. R., Gassert, C. A., & Staggers, N. (2011). “Nursing informatics competencies\nrequired of nurses in Taiwan”. International Journal of Medical Informatics, Vol. 80. No. 53,\npp.32-340. https://doi.org/10.1016/j.ijmedinf.2011.01.011\n**BLOCK**fs== 10.0**p== 17.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nComrey, A.L. and Lee, H.B. (1992). A First Course in Factor Analysis, 2nd ed., Lawrence Erlbaum\n**BLOCK**fs== 10.0**p== 17.0**b== 0.9**t== 0.1**l== 0.2**r== 0.6**\nAssociates, Hillsdale, NJ.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nCorder, G. W., & Foreman, D. I. (2014). Nonparametric statistics: A step-by-step approach. John Wiley\n**BLOCK**fs== 10.0**p== 17.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nCreswell, J. W., & Plano Clark, V. L. (2011). Designing and Conducting Mixed Methods Research, 2nd\n**BLOCK**fs== 11.0**p== 17.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nEdition, Sage Publications, Los Angeles\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nDavenport T, Kalakota R. (2019). The potential for artificial intelligence in healthcare”, Future\nHealthcare  Journal. Vo.6. No. 2, pp.94-98. doi: 10.7861/futurehosp.6-2-94.\nhttps://doi.org/10.7861/futurehosp.6-2-94\nJ\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nDigital Health and Care (2022). “Digital Skills User Research. NHS Education for Scotland”, available at:\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.2**r== 0.4**\nhttps://learn.nes.nhs.scot/61462 (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nDimock M (2019). “Defining generations: Where Millennials end and Generation Z begins”. Pew\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nResearch Center, available at: https://www.pewresearch.org/fact-tank/2019/01/17/where-\nmillennials-end-and-generation-z-begins/(accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nDoyle, O. (2020). “COVID-19: Exacerbating educational inequalities?” Public Policy, Vol. 9, pp.1-10,\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.2**r== 0.3**\navailable at: https://publicpolicy.ie/covid/covid-19-exacerbating-educational-\ninequalities/(accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nEquality Act 2010 (2010), available at: https://www.legislation.gov.uk/ukpga/2010/15/section/15\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\n(accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\nErdat, Y., Ceren, R. E. S., Ozdemir, L., Uslu-Sahan, F., & Bilgin, A. (2023). “Influence of technical,\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\ncognitive and socio-emotional factors on digital literacy in nursing students assessed using\nstructural equation modeling”. Nurse Education Today, Vol. 130, p. 105937.\nhttps://doi.org/10.1016/j.nedt.2023.105937\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nEuropean Commission, Directorate-General for Communications Networks, Content and Technology\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\n(2021). “2030 Digital Compass: the European way for the Digital Decade. Communication\nfrom the Commission to the European Parliament, The Council, The European Economic and\nSocial Committee And The Committee Of The Regions. European Union (EU)”, available at:\nhttps://eur-lex.europa.eu/legal-content/en/TXT/?uri=CELEX:52021DC0118 (accessed\n30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nEuropean Network for Rural Development (2017). ENRD Seminar on ‘Revitalising Rural Areas through\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.6**l== 0.2**r== 0.2**\nBusiness Innovation’”. Brussels. March 2017, available at:\nhttps://ec.europa.eu/enrd/sites/default/files/s4_rural-businesses-factsheet_digital-hubs.pdf\n(accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nt\nGilmour, J. A., Scott, S. D., & Huntington, N. (2008). “Nurses and Internet health information: a\ni\nquestionnaire survey.” Journal of Advanced Nursing, Vol. 61, No. 1, pp.19-28.\nhttps://doi.org/10.1111/j.1365-2648.2007.04460.x\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nHalligan, P., Martyn, K., & Pace, K. (2019). “Universal Design for Learning to support nursing students:\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.7**l== 0.2**r== 0.2**\nExperiences in the Field”. Research Repository University College Dublin (DCU), available at:\nhttp://hdl.handle.net/10197/10154 (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nHamilton, L. G., & Petty, S. (2023). “Compassionate pedagogy for neurodiversity in higher education:\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\nA conceptual analysis”. Frontiers in Psychology, Vol. 14, p. 1093290.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nHampton, D., & Pearce, P. F. (2016). “Student engagement in online nursing courses”. Nurse Educator,\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\n41(6), 294-298. https://doi.org/10.1097/nne.0000000000000275\n**BLOCK**fs== 10.0**p== 17.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nHampton, D. C., & Keys, Y. (2017).” Generation Z students: Will they change our nursing classrooms”.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.1**t== 0.9**l== 0.2**r== 0.4**\nJournal of Nursing Education and Practice, Vol. 7, No. 4, pp. 111-\n115.  https://doi.org/10.5430/jnep.v7n4p111\n**BLOCK**fs== 10.0**p== 18.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nHarerimana, A., Duma, S. E., & Mtshali, N. G. (2022). “First-year nursing students’ digital literacy: a\n**BLOCK**fs== 10.0**p== 18.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\ncross-sectional study”. Journal of Nursing Education and Practice, Vol. 13, No. 1, pp. 31.\nhttps://doi.org/10.5430/jnep.v13n1p31\n**BLOCK**fs== 10.0**p== 18.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nHarrison, N. (2024). “Simulation in Nursing Education: An Evidence Base for the Future”. Council of\n**BLOCK**fs== 10.0**p== 18.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nDeans of Health: London, available at: https://www.councilofdeans.org.uk/wp-\ncontent/uploads/2024/01/CoDH-ARU-Simulation-in-Nursing-Education-Report-Jan-\n2024.pdf  (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 18.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nHensley, A., Hampton, D., Wilson, J. L., Culp-Roche, A., & Wiggins, A. T. (2021). “A multi-center study\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nof student engagement and satisfaction in online programs”. Journal of Nursing Education,\nVol. 60, No.5, pp. 259–264. https://doi.org/10.3928/01484834-20210420-04\nJ\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nHernandez-de-Menendez, M., Escobar Díaz, C. A., & Morales-Menendez, R. (2020). “Educational\nexperiences with Generation Z”. International Journal on Interactive Design and\nManufacturing (IJIDeM), Vol. 14, No. 3, pp.847-859. https://doi.org/10.1007/s12008-020-\n00674-9\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nHildebrandt, T., & Prenoveau, J. M. (2020). “Rigor and reproducibility for data analysis and design in\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nthe behavioral sciences”. Behaviour Research and Therapy, Vol. 126, p. 103552.\na\nhttps://doi.org/10.1016/j.brat.2020.103552\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nHolland Brown, T. M., & Bewick, M. (2023). “Digital health education: the need for a digitally ready\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nworkforce”. Archives of Disease in Childhood-Education and Practice, Vol. 108. No. 3, pp. 214-\no\n217. https://doi.org/10.1136/archdischild-2021-322022\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nHolt, K. A., et al. (2020). “Health Literacy, Digital Literacy and eHealth Literacy in Danish Nursing\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\nStudents at Entry and Graduate Level: A Cross Sectional Study”. BMC Nursing, Vol. 19, No. 1,\npp. 1-12. https://doi.org/10.1186/s12912-020-00418-w\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nHughes, E. (2024). “Report: Simulation in Nursing Education: An Evidence Base for the Future”.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nc\nCouncil of Deans of Health: London, available from:\nhttps://www.councilofdeans.org.uk/2024/01/report-simulation-in-nursing-education-an-\nu\nevidence-base-for-the-future/ (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.2**r== 0.3**\nIBM Corp. (2022). IBM SPSS statistics for windows, version 28. 0.1. IBM Corp.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nIbrahim, R. K., & Aldawsari, A. N. (2023). “Relationship between digital capabilities and academic\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nperformance: the mediating effect of self-efficac”y. Bio Medical Central (BMC) Nursing, Vol.\n22. No. 1, p. 434. https://doi.org/10.1186/s12912-023-01593-2\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nIsidori, V., Diamanti, F., Gios, L., Malfatti, G., Perini, F., Nicolini, A., & Gaudino, A. (2022). “Digital\n**BLOCK**fs== 10.0**p== 18.0**b== 0.3**t== 0.6**l== 0.2**r== 0.2**\ntechnologies and the role of health care professionals: scoping review exploring nurses’ skills\nin the digital era and in the light of the COVID-19 pandemic”. JMIR Nursing, Vol. 5. No. 1,\ne37631. https://doi.org/10.2196/37631.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.7**l== 0.2**r== 0.1**\nInternational Telecommunication Union (ITU) (2020). “Household Internet access in urban areas twice\nas high as in rural areas”, available at:  https://www.itu.int/en/mediacentre/Pages/pr27-\n2020-facts-figures-urban-areas-higher-internet-access-than-\nrural.aspx#:~:text=Furthermore%2C%20according%20to%202019%20data,areas%20(38%20p\ner%20cent), (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nJeon, J., and Kim, S. (2022). “The Mediating Effects of Digital Literacy and Self-Efficacy on the\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nRelationship between Learning Attitudes and Ehealth Literacy in Nursing Students: A Cross-\nSectional Study”. Nurse Education Today, No. 113.\nhttps://doi.org/10.1016/j.nedt.2022.105378\n**BLOCK**fs== 10.0**p== 18.0**b== 0.1**t== 0.8**l== 0.2**r== 0.3**\nJoint Information Systems Committee (JISC). (n.d.). “Discovery tool”. JISC, available at:\n**BLOCK**fs== 10.0**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nhttps://digitalcapability.jisc.ac.uk/our-service/discovery-tool/ (accessed 30/08/2024)\n**BLOCK**fs== 10.0**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nJoint Information Systems Committee (JISC). (2022). “Building digital capabilities framework: The six\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nKhalil H, Ameen D, Zarnegar A. (2022). “Tools to support the automation of systematic reviews: a\nscoping review”. Journal of Clinical Epidemiology. 2022, Vol. 144, pp. 22-42. doi:\n10.1016/j.jclinepi.2021.12.005 (accessed 05/09/2024)\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nKiger, M. E., & Varpio, L. (2020). “Thematic analysis of qualitative data: Amee guide”, N. 131. Medical\nTeacher, Vol. 42, No. 8, pp. 846–854. https://doi.org/10.1080/0142159x.2020.1755030\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nKings College Libraries and Collections (2024). Searching for Systematic Reviews & Evidence Synthesis:\n**BLOCK**fs== 10.0**p== 19.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nAI tools in evidence. https://libguides.kcl.ac.uk/systematicreview/ai (accessed 05/09/2024)\nJ\n**BLOCK**fs== 10.0**p== 19.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nKlenowski, V. (1995). “Student self-evaluation processes in student-centred teaching and learning\n**BLOCK**fs== 10.0**p== 19.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\ncontexts of Australia and England”. Assessment in Education: Principles, Policy & Practice, Vol.\n2. No.2, pp. 145–163. https://doi.org/10.1080/0969594950020203\n**BLOCK**fs== 10.0**p== 19.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nLekalakala-Mokgele, E., Lowane, M. P., & Mogale, N. M. (2023). “Knowledge, perceptions and\n**BLOCK**fs== 10.0**p== 19.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nattitudes of eHealth and health technology among nursing students from Auteng province,\nSouth Africa”. Healthcare, Vol. 11, No. 12, p. 1672.\na\nhttps://doi.org/10.3390/healthcare11121672\n**BLOCK**fs== 10.0**p== 19.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nLembani, R., Gunter, A., Breines, M., & Dalu, M. T. B. (2020). “The same course, different access: the\ndigital divide between urban and rural distance education students in South Africa”. Journal\no\nof Geography in Higher Education, No. 4, Vol. 1, pp.70-84.\nhttps://doi.org/10.1080/03098265.2019.1694876\n**BLOCK**fs== 10.0**p== 19.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\nLokmic-Tomkins, Z., Khor, M. K. Y., Matthews, K. A., Martin, J. A., & McGillion, A. (2021). “Improving\nthe health assistant in nursing employment model through entry to practice nursing student\nperceptions: a cross-sectional study.” Contemporary Nurse, 57(6), 472-481.\nhttps://doi.org/10.1080/10376178.2022.2049615\nc\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\nLoureiro, F., Sousa, L., & Antunes, V. (2021). “Use of digital educational technologies among nursing\nstudents and teachers: An exploratory study”. Journal of Personalized Medicine, Vol. 11, No.\n10, p. 1010. https://doi.org/10.3390/jpm11101010\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nLukava, T., Morgado Ramirez, D. Z., & Barbareschi, G. (2022). “Two sides of the same coin:\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\naccessibility practices and neurodivergent users' experience of extended reality”. Journal of\nEnabling Technologies, Vol. 16, No. 2, pp. 75-90. https://doi.org/10.1108/JET-03-2022-0025\n**BLOCK**fs== 10.0**p== 19.0**b== 0.3**t== 0.6**l== 0.2**r== 0.2**\nMajid, S., Foo, S., Luyt, B., Zhang, X., Theng, Y. L., Chang, Y. K., & Mokhtar, I. A. (2011). “Adopting\nevidence-based practice in clinical decision making: nurses' perceptions, knowledge, and\nbarriers”. Journal of the Medical Library Association JMLA, Vol. 99, No. 3, p.229.\nhttps://doi.org/10.3163/1536-5050.99.3.010\n**BLOCK**fs== 10.0**p== 19.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nMartzoukou, K., Fulton, C., Kostagiolas, P., & Lavranos, C. (2020). “A study of higher education\n**BLOCK**fs== 10.0**p== 19.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nstudents' self-perceived digital competences for learning and everyday life online\no\nparticipation”. Journal of Documentation, Vol. 76(6), pp. 1413–1458. https://doi.org/10.1108/\njd-03-2020-0041\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nMartzoukou, K., Kostagiolas, P., Lavranos, C., Lauterbach, T., & Fulton, C. (2021). “A study of university\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nlaw students' self-perceived digital competences”. Journal of Librarianship and Information\nScience, Vol. 54(4), pp. 751–769. https://doi.org/10.1177/09610006211048004\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nMartzoukou, K. Luders, E.S. Mair, J., Kostagiolas, P., Johnson, N., Work, F., Fulton, C. (2023). A\n**BLOCK**fs== 10.0**p== 19.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\ncross-sectional study of discipline-based self-perceived digital literacy competencies of\nnursing students. Journal of Advanced Nursing, Vol. 80(2), pp. 656-672.\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/jan.15801\n**BLOCK**fs== 10.0**p== 19.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nMather, C. A., Cheng, C., Douglas, T. Elsworth, G. Osbrne, R. (2022). “eHealth Literacy of Australian\nUndergraduate Health Profession Students: A Descriptive Study”. International Journal of",
         "MARTZOUKOU, K., LUDERS, E.S., WORK, F., KOSTAGIOLAS, P.A. and JOHNSON, N. 2025. Digital divides in nursing students: an exploration of the relationship between self-perceived digital competencies and digital barriers. Journal of documentation [online], 81(2), pages 330-350. Available from: https://doi.org/10.1108/JD-09-2024-0209 Digital divides in nursing students: an exploration of the relationship between self- perceived digital competencies and digital barriers. This author accepted manuscript is deposited under a Creative Commons Attribution Non-commercial 4.0 International (CC BY-NC) licence. This means that anyone may distribute, adapt, and build upon the work for non-commercial purposes, subject to full attribution. If you wish to use this manuscript for commercial purposes, please visit Marketplace. Digital divides in nursing students: an exploration of the relationship between self-perceived digital competencies o and digital barriers Digital divides in nursing students: an exploration of the relationship between self-perceived digital competencies and digital barriers In the context of Higher Education nursing education, digital competencies are increasingly recognised as  a  necessary  skillset,  within  a  continuously  evolving  healthcare  professional  landscape.  This  study sought to explore nursing students’ digital competencies and to further understand the digital literacy gaps and barriers they encounter for both learning and future work. The  research  involved  a  cross  sectional,  discipline-based  empirical  study  of  nursing  students’  self- assessed digital competencies via a questionnaire survey, which collected quantitative and qualitative data from a total of five hundred and fifty-three students. The study explored the role of demographics (age, urban/rural geographical location of growing up, study year, learning disabilities (neurodiversity) and experiences of digital divides (e.g., access, contextual and behavioural barriers) play on students’ digital competencies and outcomes. Students’ digital competencies were found at intermediate level with younger and first year students self-assessing higher. Significant differences were identified between students who had encountered c digital  barriers/divides  and  those  who  had  not,  with  the  former,  self-reporting  lower  digital competencies. Students with learning disabilities reported complex support needs for processing and organizing digital information and for productivity. Almost all the individual digital competencies items assessed had strong statistical correlations between them. The research offers key recommendations for academic libraries for the on-going, evolving exploration of  students’  digital  competencies  and  for  the  need  to  follow  tailored,  discipline-related,  holistic, practice-based  and  curriculum  embedded  approaches  to  students’  digital  skills  development  and support.  It  provides  novel  insights  into  digital  competencies  development  for  nursing  students  and particularly those who experience digital divides. Within the context of university nursing education, digital competencies are increasingly recognised as a necessary skillset for studying, keeping up with technological advancements (Harrison, 2024; RCN, 2024)  and  developing  an  “ability  to  adapt  and  innovate”  (Hughes  2024),  preparing  students  for  the future  healthcare  professional  landscape  and  for  roles  that  demand  digital  skills  in  the  provision  of effective nursing care (Isidori et al, 2022; RCN, 2021). The rapid digital transformation caused by the pandemic necessitated digital competence development needs in both nursing education and practice with changes that are “likely to be sustained”, while the need for nurses who have “digital expertise and  the  ability  to  lead  change  is  increasing  exponentially”  (NHS  England,  n.d.).  Within  the  next  two decades,  most  jobs  in  the  UK  National  Health  System  (NHS)  will  have  a  digital  component,  as  staff navigate  a  data-rich  healthcare  environment  and  develop  digital  competence  skills  for  fast  growing technologically  enhanced  work  settings  (Topol  Review,  2019)  dealing  with  increased  digital  data (Capgemini, 2022) and a “digital future” that “is already transforming the way nursing care is delivered” (RCN, 2024).  A priority area for the health and care sector is, therefore, “when, why and, crucially, how to use digital”, with essential digital workforce development (Scottish Government, 2021). The Code of the Nursing and Midwifery Council (2023) identifies digital skills as integral for all registered nurses, however, a lack of formal digital competencies training structure in nursing education results in fragmented  digital  knowledge  and  experiences  (De  Leeuw  et  al.,  2022).  Frustration  with  new  and ongoing integration of technology and lack of confidence/skills with healthcare technology is associated with emotional exhaustion among nurses in practice (Tawfik et al. 2021). Among nursing students, who prepare for increasingly digitalised future careers, the existence of digital divides also creates significant challenges (Saeed and Masters, 2021). Despite the widespread presence of digital technology in nursing students' lives, students still experience gaps even in baseline digital literacy (NMC, 2023). For example, targeted digital literacy education interventions around technology-enhanced learning and simulation are needed as part of foundational nursing studies to improve nursing students' baseline digital literacy before commencing clinical placement (Lokmic-Tomkins et al., 2022). c To realise the true potential of digitally enabled health and social care services, it becomes necessary to develop a unified and concentrated effort to transform the education and skills provision for those working in delivering health and social care (Morrison et al., 2022). This necessitates a deeper and on- going exploration of nursing students’ development needs and readiness to apply digital skills within a constantly evolving nursing education and professional environment. Academic libraries have established expertise in developing subject support for nursing and offering training for students on the basis of health information literacy (Purnell, Royal and Warton, 2020), such as how to identify database search techniques across different health related sources, using effective search approaches (e.g., Boolean operators and advanced searching), and how to evaluate and ethically use information following referencing standards and academic integrity. However, health information literacy is also a crucial professional skill for the delivery of evidence-based health information services (e.g.,  systematic  literature  reviews).  Academic  libraries  have  been  supporting  nursing  students  to develop  different  digital  skills  to  navigate  broader  technological  developments,  from  using  internet search engines and Web 2.0 to sourcing and analysing big data and to the use of digital health services for their potential to advance clinical practice and the delivery of patient care as well as the current focus  on  the  ethical  use  of  generative  artificial  intelligence  for  information  discovery  (e.g.,  using  AI Search Tools). Davenport and Kalakota (2019) discuss the opportunities created by Natural language processing (NLP) in the health professional environment for “understanding and classification of clinical documentation and published research” for the purpose, for example, of analyzing unstructured clinical notes,  reports  and  patient  interactions.  Academic  libraries  empower  students  to  engage  with technology,  explore  digital  content,  and  develop  their  digital  literacy  skills.  Increasingly,  academic libraries  have  also  started  to  develop  support  and  guidance  in  the  form  of  LibGuides  that  focus  on navigating the artificial intelligence (AI) landscape. For example, the University of Cambridge libraries offer guidance on the use of AI answering questions such as which AI tools to use, how to get the best results from AI and how to reference AI tools (University of Cambridge 2023). Subject specific Libguides in health developed by academic libraries, aim to increase awareness of how it is currently transforming healthcare with new applications and advancements which enhance health related clinical practice and as well as evidence-based research (e.g., systematic reviews) (Khalil, Ameen, & Zarnegar, 2022).  For example, King’s College Libraries and Collections (2024) offers access to AI tools for evidence synthesis providing resources for health students on AI tools and how to use them for learning, research and healthcare related practice. However,  developing  library  support  and  implementing  digital  skills  programmes  necessitates understanding of students’ existing digital skills gaps. Not all students arrive to education with the same digital skills and competencies and therefore, ongoing critical exploration of existing digital divides and needs is crucial for offering meaningful digital literacy programmes and support. Recent research exploring the development of nursing students’ digital skills or competencies has found variability in focus and directions (Matthews 2021; Nes, 2021) and a lack of a holistic approach to digital literacy skills development in academia. For example, in a scoping review of technological literacy in nursing  education,  Nes  identified  several  different  foci,  including  computer  literacy,  health/nursing informatics  and  technology  acceptance,  while  a  direction  towards  higher  level  digital  skills,  such  as problem-solving and critical thinking was omitted. Similarly, Harerimana et al. (2022) highlighted a need to incorporate digital literacy education beyond basic computer, internet and digital device use–related skills, while Brown et al. (2020) noticed the lack of advanced/more specialised digital skills for transferal to the clinical/care working environment. Other research has emphasised gaps in students’ knowledge on eHealth literacy (Holt et al., 2020; Jeon and Kim, 2022; Mather et al., 2022; Blakemore et al., 2020) and students’ attitudes to technology (Lekalakala-Mokgele et al., 2023). However, overall, studies are inconclusive  as  the  methodologies  and  measurements  followed  are  either  dissimilar  or  focused  on different digital skills required (Erdat et al., 2023). Bove  and  Sauer  (2023)  explored  levels  of  knowledge  and  skills  that  nursing  academic  staff  should possess to teach their students, and the need for both educators and nursing practitioners to embrace AI-enabled innovations to “lead the digital future” (Castonguay et al., 2023). The need for continuous c education  has  been  identified  for  years  as  a  priority  in  the  European  agenda  to  digitize  healthcare (European Health Parliament, 2016, p.8) with a call for mandatory, continuous and tailored training programs on digital skills. At UK level, however, although “Digital health is a high priority in government, NHS  organisations  and  Royal  Colleges”  there  is  a  gap  between  expectations  around  digital  skills development and the actual implementation of education within school curricula and training for staff via professional development activities. Post pandemic, the need for digital health education is even greater with remote health consultations and digital health solutions (Holland Brown and Bewick, 2022, p.214). Despite the urgent call for the ongoing development of digital skills, “digital divides” amongst the health and  social  care  workforce  (including  nurses)  still  exist.  For  example,  in  relation  to  the  geographical interest of this study, NHS Education for Scotland indicates a digital literacy skills gap in the healthcare sector, with key findings from a large-scale digital skills user research study (Digital Health and Care, 2022), which indicates both a lack of digital skills training and agreed terminology which can result in digital  exclusion,  manifested  though  lack  of  engagement  or  confidence,  competence  and  access (Capgemini, 2022). To support nursing students building digital competencies as future professionals operating within a complex digitally enabled health arena, a holistic understanding of digital skills, gaps and barriers is required, focusing on moving from baseline to more advanced digital literacy skills development and to an  effective  transition  towards  technologically  advanced  health  working  environments  (Lokmic- Tomkins et al. 2022). This study therefore aims to offer a better understanding of nursing students’ different levels of digital competencies and explore how digital exclusion experiences may play a role in the way in which they develop them. Aims and Objectives This research presents an approach that aims to explore students’ diverse digital competencies that are key  for  learning  and  for  supporting  a  digital  evolving  professional  environment,  as  well  as  examine students’  diverse  experiences  of  digital  divides.  Specifically,  the  research  addresses  the  following objectives: To explore how nursing students self-assess their digital competencies for nursing related learning and professional practice. To examine nursing students’ digital barriers/divides related to technological access and connectivity (first level divide), digital competencies development (second-level divide), and J digital outcomes (third-level digital divide) To identify the impact of students’ demographic divides on their digital competencies’ o development. In relation to Objectives 2 and 3, two working hypotheses were put forward: H1. Self-assessed digital competencies of students will be correlated with students’ experienced digital divides/barriers  (age,  learning  disabilities  (neurodiversity),  urban/rural  geographical  location  of growing up and study year). H2.  Self-assessed  digital  competencies  of  students  will  be  correlated  with  demographic  differences (age, learning disabilities (neurodiversity), geographical location and study year). This study followed a cross-sectional survey of nursing students by means of an online questionnaire administered  to  all  students  studying  in  undergraduate  (Year  1,  2  and  3)  and  postgraduate  nursing courses within a single Scottish HE institution. The questionnaire instrument collected quantitative and c qualitative data in a concurrent mixed methodological survey design, with a) closed ended questions exploring students’ demographics (age, learning disabilities (neurodiversity), urban/rural geographical location of growing up and study year), students’ self-perceived digital competencies, and digital divide barriers  and  b)  open-ended  questions  which  aimed  to  examine,  in  more  detail,  challenges  and strategies of students with learning disabilities/neurodiversity. Digital competencies The  main  position  of  this  research  is  that  students  do  not  arrive  at  university  with  the  same  digital competencies  and  that  it  is  important  to  consider  the  issue  of  “widening  participation”  and  “digital inclusion”  in  nursing  education.   Previous  research  with  students  has  found  that  they  have  positive attitudes  and  feel  competent  towards  information  and  communication  technology  use  in  clinical practice to support care values and work efficiency (Warshawski et al., 2019). However, not only the digital  environment  is  constantly  evolving,  but  also  more  recent  studies  have  extended  a  focus  on technological skills to cover additional areas of digital capability that have a behavioural and “soft skills” focus, encompassing digital “learning and development”, “identity and wellbeing”, “problem solving and innovation”, “information, data and media literacies” and “digital communication, collaboration and  participation”.  These  emphasise  the  importance  of  improving  students’  digital  capabilities  to enhance  their  self-efficacy,  confidence  and  self-actualization  in  their  academic  studies  (Ibrahim  and Aldawsari, 2023). In this study, we utilised an empirically tested digital competencies self-assessment survey tool that was adapted based on the European Digital Competence Framework for Citizens (Carretero et al., 2017) and The Digital Capabilities framework (JISC, 2022) to holistically explore digital competencies from a nursing-based  perspective.  The  survey  explored  digital  competencies  within  everyday  life,  nursing related education and practice, addressing nursing related digital competencies with examples from the context of nursing: for example, the use of health related information sources (such as CINAHL, Medline, Cochrane Library), the application of digital creation skills in nursing (such as those for using simulation/virtual reality tools and discipline specific apps, e.g.,  BNF British National Formulary) and for the use of health digital research skills (such as those for using health specific critical appraisal tools, e.g., Critical Appraisals Skills Programme (CASP) and evidence-based research tools). The structure and the  dimensions  of  the  questionnaire  survey  are  available  in  Supplementary_material_appendix_A, Table A1. The survey measurement was based on a five-point Likert type scale of digital competencies which  represented  different  levels  of  knowledge  and  self-sufficiency  based  on  performing  specific digital tasks (Supplementary_material_appendix_A, Table A2). Digital barriers/divides Wei,  Chan  and  Tan  (2011)  highlight  three  potential  levels  of  digital  divide  including  access  to information technology (first level divide), digital capability (second-level divide), and digital outcomes (third-level digital divide) which relate to learning and productivity. In relation to first level divides, data in the survey were collected on information technology access barriers experienced by students related to an urban/rural divide (up to the time of finishing school), such as lack of access to electricity, and access to basic computer training, broadband, desktop computers/laptop, and smart mobile phones use (Sparks, 2013, p.28; DiMaggio et al. 2010; Wei, Chan and Tan, 2011). Second-level divides were explored by means of identifying self-assessed digital competencies gaps, described above, which were further elaborated based on contextual and behavioural barriers students experienced in developing them,  such  as  lack  of  time,  up-to-date  training  in  specific  digital  skills  (Gilmour  et  al.,  2008)  and students’  interest,  urgency,  confidence  and  their  perceptions  of  difficulty  around  developing  these skills. These questions helped to explore more holistically intersecting digital divides variables that may play a role in students’ digital competencies development. Third-level digital divides were explored via an overarching question that addressed students’ overall digital abilities to fulfil academic outcomes (Supplementary_material_appendix_A, Table A1). Age demographics divides The impact of age demographics, may be difficult to delineate with different studies following diverse ways of categorising age groupings (Dimock, 2019). This study focused on a binary categorisation, given the focus of the research on digital skills and digital connectivity: students born before the year 2000 and students born in that year or after (which characterises approximately the start of Generation Z learners) (Shorey et al., 2021). The change of the millennium marked an important technological shift in everyday life digital access and interaction, with the widespread adoption and use of the Internet, digital technologies and social media. People born after the change of the millennium had experiences of growing up in a more technologically saturated world and this may have shaped up for them different online experiences. Prensky describes these individuals as ‘Digital Natives’, in other words the “native speakers” of the digital language of computers, video games and the Internet” and the first generation to grow up with these new technologies (2001a; 2001b).  In a literature review of 80 studies, Alruthaya, Nguyen and Lokuge (2021) reported on different research where Gen Z students were found “to be able to access digital technologies more than other generations” (Sakdiyakorn et al., 2021), noting a preference  towards  visual  versus  textual  information  (Hernandez-de-Menendez  et  al.,  2020).  Other studies focusing on nursing students have reported differences in both everyday life digital activities, such  as  using  daily  social  media  (Vizcaya-Moreno  and  Pérez-Cañaveras,  2020)  and  preferences  for specific learning approaches, such as experiential learning, independent learning and use of multimedia (Hampton and Keys, 2017). Learning disabilities (neurodivergence) divides The  study  also  sought  to  explore  potential  first  and  second-level  digital  divides  within  the underrepresented  15-20%  neurodivergent  student  population  (Doyle,  2020).  Despite  the  high incidence  of  neurodivergence  in  students  attending  universities  internationally  (which  is  growing), there  appears  a  dearth  of  neurodivergent  pedagogical  literature  (Hamilton  and  Petty  2023). Neurodiversity “is an umbrella term that represents the neurological variability of the human brain” which includes many terms such as autism, attention-deficit/hyperactivity disorder (ADHD), dyslexia, dyspraxia, epilepsy, and obsessive-compulsive disorder (Lukava, et al., 2022 p.76) and can be formally diagnosed or a self-reported protected characteristic (Equality Act, 2010). Although there are various statistics, it is suggested that 15-20% of the population is reported as neurodivergent (Doyle, 2020). Students were asked to first indicate if they had a neurodivergent condition (actual or suspected) in one or more of the following areas: autism, dyslexia, dyspraxia, dyscalculia, dysgraphia and Attention Deficit  Hyperactivity  Disorder  (ADHD).  Following  that,  the  students  were  asked  to  explain  if  they encountered  any  problems,  difficulties  or  barriers  when  completing  digital  tasks/using  digital  tools related to their study.  Finally, students were asked to list any apps, programmes, or digital tools that helped them as a neurodivergent person or any other elements that supported their life or learning that  they  felt  might  also  be  useful  to  others  (e.g.,  for  accessibility,  time  management,  study organisation/prioritisation, visualisation). u Divides related to rural/urban experiences of growing up The presence of a “urban/rural digital divide” is “widely acknowledged” in previous research (Philip et al.  2017,  p.386)  and  policy  (ITU,  2020)  as  a  determining  factor  for  digital  skills  development.  For example, the Organisation for Economic Co-operation and Development (2021) has described the term “digital divide” as “different levels of access and use of information and communication technologies (ICTs) and, most often, to the gaps in access and use of Internet-based digital services” which can “vary in terms of geography (e.g. as urban and rural areas), by gender, by age, by skill level, by firm size, and in general, by different vulnerable groups in society, among others” (pp. 4-5). The European Network for Rural Development (2017) refers to rural areas based on facing the risk of a “double digital divide”, lacking  access  to  modern  infrastructure  which  leads  to  “lack  the  basic  skills  and  knowledge  of  the potential of digital technology so that even if the ‘digital highways’ are in place, they may remain under- exploited” (p.1). To explore experiences of rurality, students were asked to report on the area they mostly lived in when they were a child up to finishing school as this is a time when fundamental digital gaps based on unequal access  to  technology  and  the  internet  would  have  been  created  to  impact  students’  digital  skills development,  disparities,  which  could  be  further  amplified  in  students’  transitions  into  Higher Education. Validity and rigour The self-assessment survey tool has been through different rounds of quality assurance and peer review by subject experts in a way that reflects disciplinary needs in the context of both learning and nursing professional practice, which can “facilitate increased reproducibility of statistical design and reporting” (Hildebrandt and Peroneal (2020, p.1). The conceptual framework and the evidence-building processes that underly the methods used in assessing students' self-perceived digital competencies, have been previously reported in different empirical studies with students from diverse subject areas (such as Law, Library and Information Science and Nursing) (Martzoukou, 2020; 2021; 2023). The strengths of the process  of  self-assessment  have  also  been  extensively  discussed  in  previous  research  on  students' Internet  skills  development  (Van  Deursen  et  al., 2014)  highlighting  its  value  in  improving  students’ learning  (Klenowski,  1995;  Ross,  2006;  JISC,  nd).  However,  within  a  fast-developing  technological environment,  iterative  changes  of  the  questionnaire  were  necessary  for  the  purpose  of  this  study, addressing emerging digital skills areas, such as artificial intelligence. The  reliability  of  the  amended  survey  instrument  was  tested  using  Cronbach's  alpha.  The  results showed that all item groups in the questionnaire had a Cronbach's alpha index much higher than 0.7, with almost all the values above 0.9. The lowest value was 0.897 for information literacy (identification of different information types) and the highest was for digital wellbeing (0.980) (Table 3). As the sample size was small with ordinal scale data, non-parametric tests were employed in the analysis (Corder and Foreman, 2014). The research design followed a total population sampling approach with email invitations sent to all the  population  of  Undergraduate  (UG)  and  Postgraduate  (PG)  students  studying  at  the  School  of Nursing,  Midwifery  and  Paramedic  Practice  at  the  Robert  Gordon  University  in  Aberdeen,  Scotland. The  students  were  recruited  following  a  targeted  approach  which  involved  meeting  them  online, during planned  ‘stage  meetings’  sessions,  designed  as  part  of  their  preparation  for  practice  at  the NHS.  An hourly online meeting was organised with each stage group (i.e., Stage 1, 2 and 3, which is equivalent  to  Year  1,  2,  and  3)  as  well  with  MSc  students.  During  the  meeting  the  students  were briefed on the purposes, objectives and procedures of the research project and they were then asked to  fill  in  an  online  questionnaire  survey.  The  sample  consisted  of  555  students  out  of  the  potential population  of  964  UG  students  and  32  PG  registered  students  in  the  school,  representing  a  total response  rate  of  55.5%  (two  respondents,  however,  were  removed  from  this  sample  due  to insufficient  data).  The  rationale  for  inviting  all  students  was  that  they  attended  diverse  courses covering  adult,  mental  health,  and  children  and  young  people’s  nursing  and  it  was  important  to ensure  adequate  representation  from  all  groups  and  capture, in  a  holistic  way,  different perspectives  on  digital  competencies  development  and  experiences  that  related  to  digital  divide barriers. Detailed demographic characteristics are provided in Table 1. The survey was administered in June 2023 with student voluntary and anonymous participation and informed online consent. Ethical considerations The  research  project  was  approved  by  the  ethics  committee  of  the  school  in  the  participating institution  in  the  UK  with  GDPR  (2018)  compliance.  The  ethical  procedure  followed  the  school research  ethics  policy,  addressing  anonymity,  confidentiality,  informed  consent,  the  right  to withdraw, data handling, privacy, and potential risks, for example, reassuring students that the results c of  the  survey  would  not  be  linked  to  their  academic  progress  and  that  none  of  the  students would  be  identifiable  via  the questionnaire outcome. IBM SPSS Statistics (v28) was employed for the statistical analysis of the survey data (IBM Corp, 2022) to  explore  correlations  between  age  and  study  year  demographic  data,  digital  competencies  and digital divides. Cronbach's alpha was used to assess the internal consistency reliability of the survey tool.  The  results  were  reported  through  descriptive  statistical  analysis  (frequencies,  valid percentages  and median values). Following Kolmogorov–Smirnov and Shapiro–Wilk normality tests, the questionnaire items  did  not  follow  a  normal  distribution  and  therefore,  Mann–Whitney  (U- test)  non-parametric  statistical  test  was  used  to  identify  significant  statistical  differences  between different  groups.  A  p  value  of  <.05  was  followed  to  indicate  statistical  significance  for  all  the  tests. Principal components analysis (PCA)  following  the  varimax  orthogonal  rotation  method  was  used to  identify  groups  of  digital competencies in (Supplementary_material_appendix_B, Tables B1-13). We  considered  factors  reaching  eigenvalue  1  as  a  factor  extraction  method  following  Kaiser’s criterion.  The  results  of  Bartlett’s sphericity test at p < 0.05 and the Kaiser Meyer–Olkin (value of 0.6 or above) confirmed the suitability of  our  dataset  for  structure  detection.  Bivariate  correlation statistics  between  all  clustered  variables  reported the different  items  of  the  research  instrument (Supplementary_material_appendix_B, Table B14). the  statistical  associations  between Thematic analysis and manual coding (Kiger and Varpio, 2020) was applied to the survey qualitative open data identifying key themes reflected in the questions with subthemes. The main limitation of the study comprises of a potential narrow perspective of a group of students studying  within  a  single  university  and  country.  Therefore,  the  results  of  the  survey  should  be generalized with caution. However, the approach followed presents a replicable process that can offer a more holistic framework to study the digital competencies development of students in a discipline focused way and design subject related learning interventions in nursing curricula. Survey results The  majority  of  the  participants  were  female  (91.3%,  n=505),  undergraduate  students  studying  BSc Nursing  (96,9%,  n=536),  with  almost  an  equal  split  between  those  born  on  or  after  the  year  2000 (Generation  Z)  (51.1%,  n=282)  and  those  before  (49%,  n=271).  The  female  gender  demographic composition of students in this study is not surprising as it reflects a gender imbalance that is evident in the nursing profession overall (RCN, 2018). Most of the students were born in Great Britain (73.6%, n=407)  with  the  next  larger  group  being  Nigerian  students  (8.9%,  n=49).  Approximately  a  third  of students studied in Year 1 (35.8%, n=198), in Year 2 (29.1%, n=161) and in Year 3 (35.1%, n=194) and most had a part-time job while studying at university (Table 1). {insert Table 1 Demographic characteristics around here} Self-assessed digital competencies results Tables B1-B13 (in Supplementary_material_appendix_B) summarize the descriptive statistics in all the survey  digital  competencies  items  using  frequencies  and  median  values.  In  addition,  subgroup  test statistics for all demographic variables are reported through Mann–Whitney U test and Kruskal-Wallis H  tests.  The  strongest  area  reported  was  ‘Digital  wellbeing’  with  all  the  items  at  median  4.0 (‘advanced’). This was followed by ‘Everyday life as a digital citizen’, were most of the items were at c ‘advanced’  level  (median  4.0),  while  three  items  were  at  ‘intermediate’  level:  ‘e-democracy’,  ‘e- government’  and  ‘e-employment’  (median  3.0)  and  ‘ICT  Proficiency’  were  two  items  were  found  at ‘intermediate’  (median  3.0) level: ‘University  management systems’ and ‘Communication  platforms’ while the rest were all at ‘advanced’ level. ‘Digital communication’ was also a strong area for the group with the majority of items reported at ‘advanced’ (median 4.0) level, while three directions were found to be at intermediate level. ‘Digital identity management’ was mainly at ‘intermediate’ level with two areas at ‘advanced’ (median 4.0) level: ‘Being aware of the potential positive or negative impact of what you communicate online on your online reputation’ and ‘Understanding the impact of your online interactions’. ‘Information literacy’,  was  found  at  ‘intermediate’  level,  with  only  a  single  item  performing  at  ‘advanced’  level: ‘Popular  information’  (median  4.0).  ‘ICT  productivity’,  ‘Digital  Innovation’  and  Digital  Learning  and Development’  were  found  to  be  at  ‘intermediate’  level  in  all  items.  ‘Digital  creation’  and  ‘Digital research skills’, were both at ‘intermediate’ level throughout, expect for the creation of ‘infographics’ in  the  former  category  and  ‘Using  a  Critical  Appraisal  Tool’  in  the  latter  category,  that  were  both reported at ‘basic’ level (median 2.0). Overall, nursing students assessed themselves at “intermediate” level (median 3.0) in most of the survey constructs and in relation to their digital ability to complete academic work. Age  demographics  significant  differences  were  identified  in  several  areas  (Supplementary_material _appendix_B), including ‘Digital Learning and Development’ (Table B10), ‘Digital Identity Management’ (Table B11) and ‘Digital Wellbeing’ (Table B12). In addition, significant differences were identified in five items within ‘ICT Proficiency’ (Table B2), three items in ‘Digital Innovation’ (Table B9), seven items in ‘Digital Communication’ skills (Table B8), five items in ‘Digital creation skills’ (Table B6) and three items  in  ‘Everyday  participation  as  digital  citizens”.  There  were  also  other  individual  items,  where significant differences were observed: ‘Sharing securely your digital files with others’ (ICT Productivity) (Table B3), ‘Finding digital information relevant to your academic studies, using databases’ (Information Literacy) (Table B5) as well as ‘Organising and storing research raw/open data online’ and ‘Using a survey tool’ (Digital Research) (Table B7). It is interesting to note that the direction of the mean rank values of the non-parametric (Man Whitney) test indicated that students who were born in year 2000 or after self-assessed higher overall based on their digital competencies. In addition, significant differences were observed between first year and continuing students in the following digital competencies items, where the former group self-assessed higher:  ‘Digital Creation’ (one item: ‘Vlog/Podcasts’)  (Table B6), ‘ICT Proficiency’  (one item: ‘Search engines’) (Table B2),  ‘Digital Innovation’  (one  item:  ‘Working  collaboratively  on  different  aspects  of  a  creative/innovative project/service  design  &  managing  the  process  as  a  team’)  (Table  B9)  and  ‘Digital  learning  and development’ (one item: ‘Using online tools to record learning events/outcomes and use them for self- analysis, reflection, and showcasing of achievement’) (Table B10). Continuing students, on the other hand, only self-assessed higher in two items in ‘Information Literacy’ (‘Scholarly Academic Literature’ and ‘Professional Literature’) (Table B5) and in one item in ‘Everyday participation as digital citizen’ (‘e- democracy’) (Table B1). In  relation  to  the  overarching  academic  outcomes  question  ‘Which  level  best  describes  your  digital abilities to complete your academic work’ (B13), significant differences were found on the basis of: a) age demographics, b) digital challenges experienced in the area in which students mostly lived (e.g., rural/urban  before  joining  the  university  (e.g.,  access  to  electricity,  computer,  laptop,  mobile  more, tablet, broadband, basic computer training),  c) digital barriers students had experienced in relation to proactively developing their digital skills and d) year of study. Furthermore, the study employed PCA (Principal Component Analysis) to reduce the number of digital competencies  variables  in  the  dataset  and  Exploratory  Factor  Analysis  (EFA)  for  the  purposes  of assessing whether they were representative of each of the of each of the underlying construct. PCA c transforms  a  set  of  variables  into  a  smaller  set  of  variables,  called  “principal  components”,  which account for most of the variance in the original variables (Comrey and Lee, 1992). PCA with Varimax rotation was employed for grouping the digital competencies constructs. The output of this process is presented in Supplementary_material_appendix_C, Tables C1-C12. The use of KMO and Bartlett Test of  Sphericity  indicated  that  it  was  possible  to  proceed  with  principal  components  factor  analysis (Tabachnick and Fidell, 2007).  Each of the survey constructs were grouped into a single component, while the single-item factor loadings were quite high. The  descriptive  statistics  (mean  and  standard  deviation)  of  the  examined  constructs  for  the  entire sample are presented in the last two rows of Tables C1-C12. As it can be observed that higher digital competencies  were ‘ICT for ‘Digital  Wellbeing’ Proficiency’ (mean = 3.64). Low competencies were reported for ‘Digital Creation’ skills (mean = 2.77) and ‘Digital Research’ skills (mean = 2.87). reported Pearson  correlation  coefficients  and  the  corresponding  significance  levels  for  all  the  construct components are presented in Table C13 with Pearson's test (2-tailed) at significance level p < 0.05(*) and significance level p < 0.01(**). It is worth noting that strong statistically significant correlations at level p < 0.01(**)  were  identified  between  almost  all  the  self-reported  dimensions  of  digital competencies,  encompassing  digital  skills  that  were  related  to  everyday  life  digital  activities  to  ICT proficiency  and  productivity,  information  literacy,  and  digital  creation,  research  communication, innovation, identity management and wellbeing. What would empower students to further develop their digital skills In the survey, students answered an open-ended question which helped to contextualize the above findings. The question centered on ways that would empower them to further develop their digital skills. Students mentioned several digital skills areas they would need further support with or training on, including learning new software/tools and understanding university systems (e.g., Moodle). Digital skills development  was  centred  on  completing  coursework,  such  as  preparing  online  posters  and presentations (PowerPoint) and formatting information, using referencing tools (such as RefWorks), developing online database searching skills/library searching, data analysis (e.g. Microsoft Excel), digital productivity tools for note-taking and time management. In relation to digital creativity tasks, several skills  mentioned  addressed  blogs,  podcasts  and  creating  videos,  while  in  relation  to  digital communication,  students  referred  to  skills  for  using  social  media  and  for  digital  learning  and development (e.g., e-portfolio). Respondents also offered ideas for different preferred types of training including workbooks/tutorials, presentations,  bitesize  guides,  video  guides  and  tutorials,  as  well  as  online  training  and  courses,  in- person  sessions  and  one-to-one  support.  Whatever  the  method  proposed,  students  preferred  clear explanations,  “consistent  information\",  and  “accessible  interfaces”,  while  several  respondents mentioned tailored support that is relevant to their careers. In addition, students’ comments indicated that  digital  skills  should  be  taught  early  in  a  course  and    in  collaboration:  “Taught  earlier  and  in collaboration with study skills and the library”, “Teach more in first year to help us build every year we study more sessions when beginning uni to go over how to use the systems”, “Incorporating structured digital skills education and identification of beneficial skills from the beginning of the course”, “Study skills and library support to teach a class at the start of each academic year as a reminder”. In addition, more time dedicated to digital skills development was necessary: “What would empower me would be more  time  to  do  digital  skills”,  “More  time  -  life/study  balance”,  “More  time  to  practice”.  Personal c motivation to develop digital skills was equally deemed important. As one student explained: “I decide what I feel is relevant for me to know and the things that I have self-assessed as lower are not important or useful to me”, indicating that a low score on certain digital skills could mean that students were not engaged with the particular skills, or they deemed them necessary or unimportant: “I don't know I don't use certain things or have interest in doing blogs or podcasts etc so that’s why I score low in sections related to that not sure really not interested in using many online tools I like pen and paper”. “It’s down to priorities. When content isn’t so engaging or urgent I don’t feel the need to reach out for help so much”. “Motivation for using these tools is lacking for me. I’m not sure how this can be supported by academic staff but perhaps if more coursework demanded the use of these digital skills”. Students required an “interest to learn” which could be triggered by connecting these skills to their course  related  experiences  together  with  reassurance  and  guidance  that  they  were  “in  the  right direction”. As students also explained, digital skills classes could be part of a course: “Incorporate these classes into our timetable” and, in that way, students could be “given time within the module to learn that skill”, especially if “an assignment was in line with a digital literacy skill that I’m lacking”. In addition, teaching staff could use more advanced and interactive tools that would “inspire” them to “develop digital  skills  in  these  areas”  and  “actively  involve”  students  “in  digital  learning  and  collaboration initiatives - e.g., sharing project results online”. Interestingly, beyond embedding digital skills into the study programme, students’ perspectives overall, conveyed a sense of connecting the significance of digital skills to the purposes of academic study rather than to digitally-enabled nursing practice. Students  had  experiences  of  growing  up  in  both  urban  (44.7%,  n=247)  and  rural  (46.5%,  n=257) geographical  areas  (Table  2).  First  level  digital  divides  were  identified  in  17%  (n=97)  of  the  study population, who reported having experienced digital challenges prior to joining the university (such as access to electricity, computer, laptop, mobile more, tablet, broadband, basic computer training), while 77.9% (n=431) reported experiences of at least one second-level barrier to developing their digital skills (e.g., lack of time, training, interest, urgency, confidence, task complexity) (Table 2). Geographical location was not found to directly play a role in the way in which students self-assessed specific digital competencies, although they had an impact on the digital abilities self-assessment of students  for  overall  completing  academic  work.  Significant  statistical  differences  were  identified between  students  who  experienced  at  least  one  of  the  listed  first  level  digital  divides  (e.g.,  lack  of continuous access to electricity, access to a desktop computer, smart mobile phone, tablet broadband, or basic computer training) and self-assessed digital competencies. Students who encountered digital r challenges/divides were more likely to self-report lower digital competencies than students who did ‘Everyday  participation  as  digital  citizens’ in not.  The  most  notable  differences  were (Supplementary_material_appendix_B, Table B1), ‘Digital Creation’ (Table B6) and ‘Digital Innovation’ (Table B9), where statistically significant correlations were found across all question items. These were followed  by  ‘ICT  Proficiency’  (Table  B2)  and  ‘Digital  Identity  Management’  (Table  B11),  where  all question items, except for one, were found significant. Additionally, there were three items identified in ‘ICT Productivity’ (Table B3), ‘Digital Research’ (Table B7), and ‘Digital Communication (Table B8), two items in ‘Information Literacy’ (Table B5) and ‘Digital Learning and Development’ (Table B10) and one item in ‘Digital wellbeing’ (Table B12). Significant statistical differences were also found in second level digital barriers and self-assessed digital competences, indicating that students who had experienced at least one of the listed barriers in that category (e.g., lack of time, training, interest, confidence) were more likely to self-report lower digital c competencies than students who did not encounter any challenges. {Insert Table 2 Digital challenges and barriers} Learning Disability (neurodivergence) Divides A total of 89 students (16.1%) self-reported a neurodiverse condition, while 82 (14.8%) indicated that they may be neurodivergent, but they are not sure, or they have not been formally diagnosed. The high potential  incidence  of  neurodivergent  students  in  this  study  (total  of  30.9%,  n=171)  is  in  par  with previous studies where a percentage as high as 33% has been reported (HESA 2021) (Table2). Learning disabilities (neurodivergence) were not found to play a role in students’ digital competencies self-assessments  as  no  significant  differences  were  identified  based  on  that  variable,  although transitions are reported as a significant issue for neurodivergent students in previous research (Bakker et  al.  2023).  However,  students  shared  additional  ideas,  which  helped  to  further  contextualize  the findings  in  the  area  of  digital  divides  connected  to  learning  disabilities.  For  example,  different challenges they experienced with ICT proficiency and productivity, such as keeping focused on tasks and avoiding distractions and reading on screen (Supplementary_material_appendix_D, Table D1): “Struggle to focus on one thing at a time, easily distracted, always need to be doing something else at same time as doing digital tasks”. Students with Dyspraxia, who typically have difficulty with motor skills in their learning ability to write, type, draw and grasp small objects, also mentioned that the design of the keyboard tools with smaller objects can become an issue for them: “I find it hard to find the correct keys when typing”. In  addition,  students  mentioned  challenges  which  could  create  problems  with  feeling  overwhelmed due to information overload that could have a negative impact on processing information from multiple online sources or complex tools which could be a barrier to information literacy and digital research skills development: “Being presented with large amounts of information at once makes it difficult to comprehend instructions or maintain focus without feeling overwhelmed”. Students  required  more  support  in  navigating  different  technologies  and  assistive  tools  available  to J them  and  they  preferred  solutions  considering  the  unique  challenges  of  their  specific  conditions, especially dyslexia: “Try to use systems available but would be interested to see more specific for dyslexia”. Several students also shared different methods and strategies for overcoming these challenges, with the most popular being using assistive technologies (which were popular with dyslexic students) and audio-visual strategies (Supplementary_material_appendix_D, Table D2): “I have found apps such as Read & Write Gold extremely helpful. Grammarly has also helped”. Besides the use of videos, students with autism specifically, highlighted the use of time-management memory-improving tools to address a need for structured learning actions: “Good routine helps me, so things like a calendar and well-organised meetings”. Students with dyscalculia mentioned the need for “Numeracy tools would be helpful to enhance my numeracy skills”, referring to “Websites calculators and British National Formulary (BNF) app” and to c the of “dyscalculia-friendly fonts and coloured backgrounds to help the numbers stand out”. Students with dyspraxia revealed the use of multiple tools to overcome challenges around a set of skills known as transcription and writing. Again, students used Grammarly, Dragon, Read and Write Gold and Dragon: “An app that converts my handwriting into text. Also, dragon that turns speech into text”. However, students also highlighted that some students can have multiple disabilities. Several students with ADHD mentioned challenges related to lack of attention to detail and continually starting new tasks before finishing old ones, also reporting that they were unaware of tools available to them, highlighting a need for the development of a toolkit considering apps, programmes and digital tools to support them: “There are none that I have found or know about”. However, some students mentioned using various assistive technology tools to manage their workload such as “Speechify app”, “Google Calendar for planning”. As another student explained: “I need to make sure I am very organised, and I write everything down. Lately, I put tasks I don't want to forget in my calendar on my iPad because that gives me the best overview of everything. I colour- code everything as well, which is very helpful”. Students mentioned the effective role of the university’s support services in supplying these assistive learning technology tools: “I have many tools on my laptop provided by the learning team now” and “The  university  has  supplied  me  with  a  laptop  with  various  apps  on  to  help  with  this”.    They  also mentioned  several  approaches  that  bring  structure  into  their  learning  process,  such  as  listening  to music,  taking  small  “breaks  little  and  often”,  and  advised  that  making  “lectures  more  interactive  or prerecorded  so  we  can  pause  and  take  breaks  when  necessary  to  stay  focused”  and  “Videos  and visualisation” are beneficial for their comprehension. This study sought to explore how nursing students self-assess based on their digital competencies and to further understand any existing obstacles to digital literacy development they encountered. Digital exclusion in Higher Education has been examined in previous research, however, most frequently, at the level of technological infrastructure and internet connectivity and in relation global geographical divisions created between the Global North and the Global South countries (Thomas-Slayter, 2003), where  people  are  more  likely  to  experience  poverty  and  limited  access  to  resources  or  educational opportunities (ACU, 2020, Lembani et. al., 2020). At EU level, it has been reported that digital divides based on accessibility have been reduced over the last years, however, there is still a fundamental need for upskilling, with one of the four key goals of the European Commission (2021) focusing on “a digitally skilled population and highly-skilled digital professionals”. This need for upskilling was also prevalent in this study in which nursing students self-assessed their digital competencies at intermediate level in most digital skills areas. This research also offered a better understanding of how students may transfer into HE existing digital divides from everyday life in a way that may have an impact on their follow up digital literacy development; these highlight the need for further  learning  opportunities  to  develop  digital  skills  that  meet  the  expectations  of  the  nursing profession,  particularly  with  the  emergence  of  new  innovative  technologies  and  AI  related transformations that require advanced digital skills (Rony, Parvin and Ferdousi, 2024). Significant differences were also observed in relation to age demographics, with younger students self- assessing  their  digital  competencies  at  a  higher  level  overall.  In  addition,  first  year  students  self- assessed higher than continuing students in certain digital skills areas, which required digital creation, c ICT proficiency and innovation skills, while continuing students were stronger in information literacy, which  presents  a  fundamental  academic  skill,  especially  in  nursing  education  and  practice,  where evidence-based practice is a core direction in clinical decision making and for the delivery of quality healthcare  (Majid  et  al.,  2011).  On  the  other  hand,  research  skills  did  not  appear  to  be  an  area  of strength of students, possibly because most of the students were UG and in their first year of study. This signifies a need to develop more robust strategies for supporting students at early levels to excel in  digital  research  foundational  skills.  Further  research  replicating  this  methodology  could  further explore this outcome with diverse students at different study levels. This  research  also  offered  a  deeper  contextual  understanding  of  the  diverse  range  of  digital  skills challenges  and  the  variability  of  strategies  followed  by  neurodivergent  students  which  signifies  the need for a universal design to nursing education to accommodate diverse needs and requirements of all learners (Halligan et al., 2019). In this study students’ existing neurodiverse conditions did not appear to  play  a  role  in  the  way  in  which  they  self-assessed  their  digital  competencies.  This  adds  some additional  evidence  to  the  position  that  people  with  neurodiverse  conditions  do  not  necessarily encounter challenges in their development of digital skills more broadly and may instead be presented with unique opportunities in digital tech employment environments that require digital innovation and creativity  (Autism  Network  Scotland,  n.d.).  Despite  this  result,  neurodivergent  students  described different  barriers  they  experienced  particularly  within  the  areas  of  ‘ICT  proficiency’  and  ‘ICT productivity’,  where  they  recommended  available  tools  and  strategies  that  can  assist  in  keeping focused on tasks and avoiding distractions. These suggestions can assist in developing more tailored and informed digital skills support. They also offered personal strategies for overcoming these barriers, which provide helpful insights and directions for digital skills programme development. It is important to  cater  for  these  challenges  in  a  way  that  is  different  according  to  the  individual  neurodivergent conditions of students. Overall, the strong statistical correlations between the self-reported digital competencies dimensions in  this  study,  offered  empirical  evidence  of  the  interplay  between  everyday  life,  learning  and  work- related digital competencies, putting forward the need for a more holistic approach to the teaching of digital skills in nursing education. Previous research with nursing students has mainly placed emphasis on  individual  digital  skills,  such  as  “digital  professionalism”  (Mather  et  al,  2018),  electronic  health literacy (Anderberg et al. 2019, p. 5), or information literacy (Aylward et al. (2020), centred on “the reliability and validity of online health care information” (Blakemore et al., 2020). Other research has explored the socio-emotional factors on students’ digital literacy, such their awareness of digital issues in the online environment (Erdat, 2023; Okumus and Atılgan, 2021; Park, 2013). The  above  findings  offer  important  directions  for  the  nature  of  support  that  academic  libraries  can provide  for  nursing  students’  development  of  digital  competencies.  The  most important recommendation  addresses  the  need  to  design  tailored  digital  literacy  programmes  which  focus  on specific digital skills, such as digital creation and digital research and in a way that carers for the needs of different students (e.g., first year and continuing students).  Digital literacy programs should not only be offered at an appropriate knowledge level, but also support nursing students to develop awareness of state-of-the art knowledge of digital tools and methodologies for healthcare, such as evidence-based practice,  predictive  analytics  and  artificial  intelligence  for  patient  care  and  clinical  decision-making (Agnew, 2022). Finally, more emphasis is necessary in promoting the importance of continuous learning and  upskilling  in  digital  competencies  and  the  relevance  of  advanced  digital  skills  in  the  context  of emerging  technologies  and  transformations  in  healthcare.  Current  research  points  to  evidence  that library  support  has  a  positive  impact  on  nursing  students’  information  literacy  skill  development (Purnell, Royal and Warton (2020). However, information literacy skills development takes place within the  context  of  developing  a  range  of  digital  skills  that  involve  other  interrelated  skills,  such  as  ICT proficiency, digital communication and digital learning and development, among others. Approaching the development of digital skills holistically means working synergistically with students and adopting a  learner-centered  approach  that  identifies  and  addresses  existing  gaps  in  information  and  digital literacy.  This  approach  necessitates  nurturing  a  lifelong  learning  mindset  in  students  to  ensure continuous skills development. c There is not a one-fits-all approach to digital competencies development, as not one student is similar because of their individual characteristics and life experiences. However, developing a more informed understanding  of  students’  digital  competencies  gaps  and  the  multiple  shapes  that  digital  exclusion may take is important for the design of meaningful digital skills enhancement programmes in Higher Education.  As this study showed, digital competencies were not only multidimensional, complex and interrelated, but also influenced by diverse digital challenges and barriers. The results of this study put forward  the  importance  of  libraries  collaborating  with  schools  for  offering  a  discipline-based  and tailored scaffolding approach to the development of nursing students’ digital competencies, as opposed to a ‘one fits-all’, generic or baseline direction. Higher Education should focus on equipping students with discipline related digital skills and knowledge in a way that relates to students’ future professional trajectories and ensure a “digitally fluent workforce” (Lokmic-Tomkins, et al., 2021), not only a digitally fluent student. It should also develop increased awareness of the digital barriers and experiences that students encounter within their everyday lives. This involves a continuous engagement with evolving digital skills needs in the profession and a focus on students’ learning and development for life. Future research  should  explore  the  parameters  of  interrelated  digital  skills  withing  everyday  life  and  work environments and examine how experiences within different settings influence strategies for students’ ongoing learning and professional growth. Finally,  it  is  important  to  note  that,  although  this  study  explored  nursing  students,  its  design  and findings  are  relevant  and  applicable  to  digital  divides  that  may  be  present  in  other  student populations. Digital  competencies  is  a  critical  skillset  for  students  across  different  disciplines  and not  unique  to nursing,  and,  as  changing  digital  technologies  become  integral  to  different  aspects of  learning  and  diverse  professional  practice,  it  is  important    to  develop  tailored  digital  literacy support, informed by detailed  understanding  of  students’  development  needs,  in  a  way  that  relates meaningfully to their study directions, their future professional trajectories and their individual knowledge levels and skills.  The research methodology applied in this study has already been tested with  other  student  populations  with  the  aim  to  explore  pockets  of  digital  inequalities  across different  discipline  areas,  such  as  Law  (Martzoukou  et  al.,  2022)  and  Information  Science (Martzoukou et al. 2020), with the input of academic staff/students  and  with  the  aim  to  offer  digital literacy  training  and  support  and  enhance  students’  digital  capacity  as  future  professionals.  In addition,  the  study’s  novel  insights  into  the  digital  challenges  that  neurodivergent  students encounter  demonstrates  the  necessity  for inclusive  educational  strategies,  in  a  way  that  can be  applied  to  other  fields  beyond  nursing,  to  ensure  that  all  students, regardless of their learning needs, have equal opportunities to develop essential digital competencies. Agnew, T. (2022).” Digital engagement in nursing: the benefits and barriers, Nursing Times, Vol. 118 Alruthaya, A., Nguyen, T., & Lokuge, S. (2021). “The application of digital technology and the learning characteristics of Generation Z in higher education”, available at: http://arxiv.org/pdf/2111.05991.pdf (accessed 30/08/2024) Anderberg, P., Eivazzadeh, S., & Berglund, J. S. (2019). “A novel instrument for measuring older people’s attitudes toward technology (TechPH): Development and validation”. Journal of Medical Internet Research, Vol. 21. No. 5, e13951. https://doi.org/10.2196/13951 Atherton, P. 2020. “The digital divide and other big questions - education and COVID-19”. Medium, available at: https://peteath.medium.com/the-digital-divide-and-other-big-questions- education-and-covid-19-f74f9c1963c6 (accessed 30/08/2024) Autism Network Scotland (n.d.) “Neurodiversity in Digital Technology Summary Report”, available at: https://www.autismnetworkscotland.org.uk/documents/view/1cea599e-a02f-47c0-aa07- f75e02664854.pdf (accessed 30/08/2024) c Aylward, K., Sbaffi, L., & Weist, A. (2020). “Peer-led information literacy training: a qualitative study of students’ experiences of the NICE Evidence search Student Champion Scheme”. Health Information & Libraries Journal, No. 37, No. 3, pp. 216-227. https://doi.org/10.1111/hir.12301 Blakemore, L. M., Meek, S. E., & Marks, L. K. (2020). “Equipping learners to evaluate online health care resources: longitudinal study of learning design strategies in a health care massive open online course”. Journal of Medical Internet Research, Vol. 22, No.2, e15177. https://doi.org/10.2196/15177 Bove, L. A., & Sauer, P. (2023). “Nursing faculty informatics competencies”. CIN: Computers, Informatics, Nursing, Vol. 41, No. 1), pp. 18-23. https://doi.org/10.1097/CIN.0000000000000894 Capgemini (2022). “User Research for a Shared Library of Digital Skills Learning Resources”. NHS Education for Scotland (NES), available at: https://learn.nes.nhs.scot/63467 (accessed 30/08/2024) Carretero, S., Vuorikari, R., & Punie, Y. (2017). “DigComp 2.1: The digital competence framework for citizens with eight proficiency levels and examples of use”. Publications Office of the European Union, available from https://publications.jrc.ec.europa.eu/repository/handle/JRC106281(accessed 30/08/2024) Castonguay, A., Farthing, P., Davies, S., Vogelsang, L., Kleib, M., Risling, T., & Green, N. (2023). “Revolutionizing nursing education through AI integration: A reflection on the disruptive impact of ChatGPT”. Nurse Education Today, Vol. 129, p. 105916. https://doi.org/10.1016/j.nedt.2023.105916 Chang, J., Poynton, M. R., Gassert, C. A., & Staggers, N. (2011). “Nursing informatics competencies required of nurses in Taiwan”. International Journal of Medical Informatics, Vol. 80. No. 53, pp.32-340. https://doi.org/10.1016/j.ijmedinf.2011.01.011 Comrey, A.L. and Lee, H.B. (1992). A First Course in Factor Analysis, 2nd ed., Lawrence Erlbaum Corder, G. W., & Foreman, D. I. (2014). Nonparametric statistics: A step-by-step approach. John Wiley Creswell, J. W., & Plano Clark, V. L. (2011). Designing and Conducting Mixed Methods Research, 2nd Davenport T, Kalakota R. (2019). The potential for artificial intelligence in healthcare”, Future Healthcare  Journal. Vo.6. No. 2, pp.94-98. doi: 10.7861/futurehosp.6-2-94. https://doi.org/10.7861/futurehosp.6-2-94 J Digital Health and Care (2022). “Digital Skills User Research. NHS Education for Scotland”, available at: https://learn.nes.nhs.scot/61462 (accessed 30/08/2024) Dimock M (2019). “Defining generations: Where Millennials end and Generation Z begins”. Pew Research Center, available at: https://www.pewresearch.org/fact-tank/2019/01/17/where- millennials-end-and-generation-z-begins/(accessed 30/08/2024) Doyle, O. (2020). “COVID-19: Exacerbating educational inequalities?” Public Policy, Vol. 9, pp.1-10, available at: https://publicpolicy.ie/covid/covid-19-exacerbating-educational- inequalities/(accessed 30/08/2024) Equality Act 2010 (2010), available at: https://www.legislation.gov.uk/ukpga/2010/15/section/15 (accessed 30/08/2024) Erdat, Y., Ceren, R. E. S., Ozdemir, L., Uslu-Sahan, F., & Bilgin, A. (2023). “Influence of technical, cognitive and socio-emotional factors on digital literacy in nursing students assessed using structural equation modeling”. Nurse Education Today, Vol. 130, p. 105937. https://doi.org/10.1016/j.nedt.2023.105937 European Commission, Directorate-General for Communications Networks, Content and Technology (2021). “2030 Digital Compass: the European way for the Digital Decade. Communication from the Commission to the European Parliament, The Council, The European Economic and Social Committee And The Committee Of The Regions. European Union (EU)”, available at: https://eur-lex.europa.eu/legal-content/en/TXT/?uri=CELEX:52021DC0118 (accessed 30/08/2024) European Network for Rural Development (2017). ENRD Seminar on ‘Revitalising Rural Areas through Business Innovation’”. Brussels. March 2017, available at: https://ec.europa.eu/enrd/sites/default/files/s4_rural-businesses-factsheet_digital-hubs.pdf (accessed 30/08/2024) t Gilmour, J. A., Scott, S. D., & Huntington, N. (2008). “Nurses and Internet health information: a i questionnaire survey.” Journal of Advanced Nursing, Vol. 61, No. 1, pp.19-28. https://doi.org/10.1111/j.1365-2648.2007.04460.x Halligan, P., Martyn, K., & Pace, K. (2019). “Universal Design for Learning to support nursing students: Experiences in the Field”. Research Repository University College Dublin (DCU), available at: http://hdl.handle.net/10197/10154 (accessed 30/08/2024) Hamilton, L. G., & Petty, S. (2023). “Compassionate pedagogy for neurodiversity in higher education: A conceptual analysis”. Frontiers in Psychology, Vol. 14, p. 1093290. Hampton, D., & Pearce, P. F. (2016). “Student engagement in online nursing courses”. Nurse Educator, Hampton, D. C., & Keys, Y. (2017).” Generation Z students: Will they change our nursing classrooms”. Journal of Nursing Education and Practice, Vol. 7, No. 4, pp. 111- 115.  https://doi.org/10.5430/jnep.v7n4p111 Harerimana, A., Duma, S. E., & Mtshali, N. G. (2022). “First-year nursing students’ digital literacy: a cross-sectional study”. Journal of Nursing Education and Practice, Vol. 13, No. 1, pp. 31. https://doi.org/10.5430/jnep.v13n1p31 Harrison, N. (2024). “Simulation in Nursing Education: An Evidence Base for the Future”. Council of Deans of Health: London, available at: https://www.councilofdeans.org.uk/wp- content/uploads/2024/01/CoDH-ARU-Simulation-in-Nursing-Education-Report-Jan- 2024.pdf  (accessed 30/08/2024) Hensley, A., Hampton, D., Wilson, J. L., Culp-Roche, A., & Wiggins, A. T. (2021). “A multi-center study of student engagement and satisfaction in online programs”. Journal of Nursing Education, Vol. 60, No.5, pp. 259–264. https://doi.org/10.3928/01484834-20210420-04 J Hernandez-de-Menendez, M., Escobar Díaz, C. A., & Morales-Menendez, R. (2020). “Educational experiences with Generation Z”. International Journal on Interactive Design and Manufacturing (IJIDeM), Vol. 14, No. 3, pp.847-859. https://doi.org/10.1007/s12008-020- 00674-9 Hildebrandt, T., & Prenoveau, J. M. (2020). “Rigor and reproducibility for data analysis and design in the behavioral sciences”. Behaviour Research and Therapy, Vol. 126, p. 103552. a https://doi.org/10.1016/j.brat.2020.103552 Holland Brown, T. M., & Bewick, M. (2023). “Digital health education: the need for a digitally ready workforce”. Archives of Disease in Childhood-Education and Practice, Vol. 108. No. 3, pp. 214- o 217. https://doi.org/10.1136/archdischild-2021-322022 Holt, K. A., et al. (2020). “Health Literacy, Digital Literacy and eHealth Literacy in Danish Nursing Students at Entry and Graduate Level: A Cross Sectional Study”. BMC Nursing, Vol. 19, No. 1, pp. 1-12. https://doi.org/10.1186/s12912-020-00418-w Hughes, E. (2024). “Report: Simulation in Nursing Education: An Evidence Base for the Future”. c Council of Deans of Health: London, available from: https://www.councilofdeans.org.uk/2024/01/report-simulation-in-nursing-education-an- u evidence-base-for-the-future/ (accessed 30/08/2024) IBM Corp. (2022). IBM SPSS statistics for windows, version 28. 0.1. IBM Corp. Ibrahim, R. K., & Aldawsari, A. N. (2023). “Relationship between digital capabilities and academic performance: the mediating effect of self-efficac”y. Bio Medical Central (BMC) Nursing, Vol. 22. No. 1, p. 434. https://doi.org/10.1186/s12912-023-01593-2 Isidori, V., Diamanti, F., Gios, L., Malfatti, G., Perini, F., Nicolini, A., & Gaudino, A. (2022). “Digital technologies and the role of health care professionals: scoping review exploring nurses’ skills in the digital era and in the light of the COVID-19 pandemic”. JMIR Nursing, Vol. 5. No. 1, e37631. https://doi.org/10.2196/37631. International Telecommunication Union (ITU) (2020). “Household Internet access in urban areas twice as high as in rural areas”, available at:  https://www.itu.int/en/mediacentre/Pages/pr27- 2020-facts-figures-urban-areas-higher-internet-access-than- rural.aspx#:~:text=Furthermore%2C%20according%20to%202019%20data,areas%20(38%20p er%20cent), (accessed 30/08/2024) Jeon, J., and Kim, S. (2022). “The Mediating Effects of Digital Literacy and Self-Efficacy on the Relationship between Learning Attitudes and Ehealth Literacy in Nursing Students: A Cross- Sectional Study”. Nurse Education Today, No. 113. https://doi.org/10.1016/j.nedt.2022.105378 Joint Information Systems Committee (JISC). (n.d.). “Discovery tool”. JISC, available at: https://digitalcapability.jisc.ac.uk/our-service/discovery-tool/ (accessed 30/08/2024) Joint Information Systems Committee (JISC). (2022). “Building digital capabilities framework: The six Khalil H, Ameen D, Zarnegar A. (2022). “Tools to support the automation of systematic reviews: a scoping review”. Journal of Clinical Epidemiology. 2022, Vol. 144, pp. 22-42. doi: 10.1016/j.jclinepi.2021.12.005 (accessed 05/09/2024) Kiger, M. E., & Varpio, L. (2020). “Thematic analysis of qualitative data: Amee guide”, N. 131. Medical Teacher, Vol. 42, No. 8, pp. 846–854. https://doi.org/10.1080/0142159x.2020.1755030 Kings College Libraries and Collections (2024). Searching for Systematic Reviews & Evidence Synthesis: AI tools in evidence. https://libguides.kcl.ac.uk/systematicreview/ai (accessed 05/09/2024) J Klenowski, V. (1995). “Student self-evaluation processes in student-centred teaching and learning contexts of Australia and England”. Assessment in Education: Principles, Policy & Practice, Vol. 2. No.2, pp. 145–163. https://doi.org/10.1080/0969594950020203 Lekalakala-Mokgele, E., Lowane, M. P., & Mogale, N. M. (2023). “Knowledge, perceptions and attitudes of eHealth and health technology among nursing students from Auteng province, South Africa”. Healthcare, Vol. 11, No. 12, p. 1672. a https://doi.org/10.3390/healthcare11121672 Lembani, R., Gunter, A., Breines, M., & Dalu, M. T. B. (2020). “The same course, different access: the digital divide between urban and rural distance education students in South Africa”. Journal o of Geography in Higher Education, No. 4, Vol. 1, pp.70-84. https://doi.org/10.1080/03098265.2019.1694876 Lokmic-Tomkins, Z., Khor, M. K. Y., Matthews, K. A., Martin, J. A., & McGillion, A. (2021). “Improving the health assistant in nursing employment model through entry to practice nursing student perceptions: a cross-sectional study.” Contemporary Nurse, 57(6), 472-481. https://doi.org/10.1080/10376178.2022.2049615 c Loureiro, F., Sousa, L., & Antunes, V. (2021). “Use of digital educational technologies among nursing students and teachers: An exploratory study”. Journal of Personalized Medicine, Vol. 11, No. 10, p. 1010. https://doi.org/10.3390/jpm11101010 Lukava, T., Morgado Ramirez, D. Z., & Barbareschi, G. (2022). “Two sides of the same coin: accessibility practices and neurodivergent users' experience of extended reality”. Journal of Enabling Technologies, Vol. 16, No. 2, pp. 75-90. https://doi.org/10.1108/JET-03-2022-0025 Majid, S., Foo, S., Luyt, B., Zhang, X., Theng, Y. L., Chang, Y. K., & Mokhtar, I. A. (2011). “Adopting evidence-based practice in clinical decision making: nurses' perceptions, knowledge, and barriers”. Journal of the Medical Library Association JMLA, Vol. 99, No. 3, p.229. https://doi.org/10.3163/1536-5050.99.3.010 Martzoukou, K., Fulton, C., Kostagiolas, P., & Lavranos, C. (2020). “A study of higher education students' self-perceived digital competences for learning and everyday life online o participation”. Journal of Documentation, Vol. 76(6), pp. 1413–1458. https://doi.org/10.1108/ jd-03-2020-0041 Martzoukou, K., Kostagiolas, P., Lavranos, C., Lauterbach, T., & Fulton, C. (2021). “A study of university law students' self-perceived digital competences”. Journal of Librarianship and Information Science, Vol. 54(4), pp. 751–769. https://doi.org/10.1177/09610006211048004 cross-sectional study of discipline-based self-perceived digital literacy competencies of nursing students. Journal of Advanced Nursing, Vol. 80(2), pp. 656-672. https://onlinelibrary.wiley.com/doi/full/10.1111/jan.15801 Mather, C. A., Cheng, C., Douglas, T. Elsworth, G. Osbrne, R. (2022). “eHealth Literacy of Australian Undergraduate Health Profession Students: A Descriptive Study”. International Journal of",
         "https://rgu-repository.worktribe.com/preview/2571863/MARTZOUKOU%202024%20Digital%20divides%20in%20nursing%20%28AAM%29.pdf",
         "extracted",
         "None",
         "Advancing nursing practice with artificial intelligence: Enhancing preparedness for the future;Relationship between digital capabilities and academic performance: the mediating effect of self-efficacy;Influence of technical, cognitive and socio-emotional factors on digital literacy in nursing students assessed using structural equation modeling.;A cross-sectional study of discipline-based self-perceived digital literacy competencies of nursing students.;Revolutionizing nursing education through Ai integration: A reflection on the disruptive impact of ChatGPT.;Knowledge, Perceptions and Attitudes of eHealth and Health Technology among Nursing Students from Gauteng Province, South Africa;Compassionate pedagogy for neurodiversity in higher education: A conceptual analysis;First-year nursing students’ digital literacy: A cross-sectional study;eHealth Literacy of Australian Undergraduate Health Profession Students: A Descriptive Study;Digital health education: the need for a digitally ready workforce;Two sides of the same coin: accessibility practices and neurodivergent users' experience of extended reality;The mediating effects of digital literacy and self-efficacy on the relationship between learning attitudes and Ehealth literacy in nursing students: A cross-sectional study.;Nursing Faculty Informatics Competencies;Study progression and degree completion of autistic students in higher education: a longitudinal study;Digital Technologies and the Role of Health Care Professionals: Scoping Review Exploring Nurses’ Skills in the Digital Era and in the Light of the COVID-19 Pandemic;Tools to support the automation of systematic reviews: A scoping review.;Improving the health assistant in nursing employment model through entry to practice nursing student perceptions: a cross-sectional study;Learning styles, preferences and needs of generation Z healthcare students: Scoping review.;A study of university law students’ self-perceived digital competences;Disparities in Health Care and the Digital Divide;ÜNİVERSİTE ÖĞRENCİLERİNİN DİJİTAL OKURYAZARLIK BECERİLERİ İLE DİJİTAL MAHREMİYET KAYGISI ARASINDAKİ İLİŞKİ;Digital Literacy in UK Health Education: What Can Be Learnt from International Research?;Understanding Generation Z through collective consciousness: Impacts for hospitality work and employment;Frustration With Technology and its Relation to Emotional Exhaustion Among Health Care Workers: Cross-sectional Observational Study;Social Media Used and Teaching Methods Preferred by Generation Z Students in the Nursing Clinical Learning Environment: A Cross-Sectional Research Study;Supporting the development of information literacy skills and knowledge in undergraduate nursing students: An integrative review.;Educational experiences with Generation Z;A study of higher education students' self-perceived digital competences for learning and everyday life online participation;Thematic analysis of qualitative data: AMEE Guide No. 131;Health literacy, digital literacy and eHealth literacy in Danish nursing students at entry and graduate level: a cross sectional study;Student Nurses' Digital Literacy Levels: Lessons for Curricula.;Peer-led information literacy training: a qualitative study of students' experiences of the NICE Evidence search Student Champion Scheme.;Equipping Learners to Evaluate Online Health Care Resources: Longitudinal Study of Learning Design Strategies in a Health Care Massive Open Online Course;Rigor and reproducibility for data analysis and design in the behavioral sciences.;The same course, different access: the digital divide between urban and rural distance education students in South Africa;Identification of Factors Influencing the Adoption of Health Information Technology by Nurses Who Are Digitally Lagging: In-Depth Interview Study;The potential for artificial intelligence in healthcare;A Novel Instrument for Measuring Older People’s Attitudes Toward Technology (TechPH): Development and Validation;Nurse and Nurse Student Attitudes and Perceived Self-efficacy in Use of Information and Communication Technologies: Professional and Cultural Differences;The digital divide: Patterns, policy and scenarios for connecting the ‘final few’ in rural communities across Great Britain;Generation Z students: Will they change our nursing classrooms?;Digital Literacy and Privacy Behavior Online;What is the “Digital Divide” and why is it Important?;Adopting evidence-based practice in clinical decision making: nurses' perceptions, knowledge, and barriers.;Conceptualizing and Testing a Social Cognitive Model of the Digital Divide;The Reliability, Validity, and Utility of Self-Assessment;Do They Really Think Differently;Student Self‐evaluation Processes in Student‐centred Teaching and Learning Contexts of Australia and England;Cambridge LibGuides. AI:Home;Digital engagement in nursing: the benefits and barriers;Technological literacy in nursing education: A scoping review.;COVID-19: exacerbating educational inequalities?;Mobile Learning in Nursing: Tales from the Profession.;The UK nursing labour market review 2008;Nurses and Internet health information: a questionnaire survey.;Discovery tool",
         "Digital divides in nursing students: an exploration of the relationship between self-perceived digital competencies and digital barriers"
        ],
        [
         "19",
         "0082b6dd5b95334df816971d506e22a0f0da9cc4",
         "Two new amino acid-derived oximes N-(2-hydroxyimino-4-methyl-pentanoyl)-L-isoleucine (1) and N-(2-hydroxyimino-4-methyl-pentanoyl)-L-leucine (2), along with two known analogues (E)-N-(2-hydroxyimino-3-phenylpropanoyl)-L-phenylalanine (3) and methyl (E)-N- (2-hydroxyimino-3-phenylpropanoyl)-L-phenylalaninate (4), were isolated from the mangrove-sediment-derived fungus Lecanicillium kalimantanense SCSIO 41702. Their structures were determined by spectroscopic analysis. The absolute configurations of 1 and 2 were determined by Marfey's method. Compounds 1 and 2 showed medium inhibitory activity against LPS-induced NO production.",
         "Xu-Meng Ren,Lin-Fang Zhong,Ke-Yue Wu,Xiao Liang,Shu-Hua Qi",
         "\n**BLOCK**fs== 10.6**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nXu-Meng Rena, b, Lin-Fang Zhonga, b, Ke-Yue Wua, b, Xiao Lianga, Shu-Hua Qia, *\n**BLOCK**fs== 10.6**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\na CAS Key Laboratory of Tropical Marine Bio-resources and Ecology, Guangdong Key Laboratory of\n**BLOCK**fs== 10.6**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nMarine Materia Medica, South China Sea Institute of Oceanology, Chinese Academy of Sciences, 164\n**BLOCK**fs== 10.6**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nWest Xingang Road, Guangzhou, 510301, Guangdong, China\n**BLOCK**fs== 10.6**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nb University of Chinese Academy of Sciences, Beijing, 100049, China\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nAbstract:\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nacid-derived\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\noximes\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\nN-(2-hydroxyimino-4-methylpentanoyl)-L-isoleucine\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nN-(2-hydroxyimino-3-phenylpropanoyl)-L-phenylalanine\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nmethyl\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n(E)-N-(2-hydroxyimino-3-phenylpropanoyl)-L-phenylalaninate  (4),  were  isolated  from  the\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nmangrove-sediment-derived  fungus  Lecanicillium  kalimantanense  SCSIO  41702.  Their\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nstructures were determined by spectroscopic analysis. The absolute configurations of 1 and 2\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nwere  determined  by  Marfey’s  method.  Compounds  1  and  2  showed  medium  inhibitory\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nactivity against LPS-induced NO production.\n**BLOCK**fs== 10.6**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nFigure S1. The 1H NMR spectrum of 1 in DMSO-d6.................................................................................... 4\n**BLOCK**fs== 10.6**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nFigure S2. The 13C NMR spectrum of 1 in DMSO-d6 .................................................................................. 4\n**BLOCK**fs== 10.6**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure S3. The HSQC spectrum of 1 in DMSO-d6 ....................................................................................... 5\n**BLOCK**fs== 10.6**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure S4. The HMBC spectrum of 1 in DMSO-d6 ...................................................................................... 5\n**BLOCK**fs== 10.6**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure S5. The 1H-1H COSY spectrum of 1 in DMSO-d6 ............................................................................ 6\n**BLOCK**fs== 10.6**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFigure S9. The 13C NMR spectrum of 2 in DMSO-d6 .................................................................................. 8\n**BLOCK**fs== 10.6**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFigure S10. The HSQC spectrum of 2 in DMSO-d6 ..................................................................................... 8\n**BLOCK**fs== 10.6**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nFigure S11. The HMBC spectrum of 2 in DMSO-d6 .................................................................................... 9\n**BLOCK**fs== 10.6**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nFigure S12. The 1H-1H COSY spectrum of 2 in DMSO-d6 .......................................................................... 9\n**BLOCK**fs== 10.6**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFigure S15. The UV spectra of compounds 1 and 2.................................................................................... 11\n**BLOCK**fs== 10.6**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFigure S16. HPLC analysis of FDAA derivates of two standard amino acids and compound 2 (Column;\n**BLOCK**fs== 10.6**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nYMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm) .................................................................... 12\n**BLOCK**fs== 10.6**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFigure S17. HPLC analysis of FDAA derivates of four standard amino acids and compound 1 (Column;\n**BLOCK**fs== 10.6**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nYMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm) .................................................................... 13\n**BLOCK**fs== 10.6**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nFigure S18. Chairal analysis of  FDAA derivates of two  standard amino acids and compound  1 (Chairal\n**BLOCK**fs== 10.6**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nFigure S19. Key COSY and HMBC correlations of 1 and 2. .................................................................... 155\n**BLOCK**fs== 10.6**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nFigure  S20.  The  ability  of  compounds  1-3  to  inhibit  LPS-induced  NO  production  in  RAW264.7\n**BLOCK**fs== 12.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nGeneral  experimental  procedures:  UV  spectra  were  measured  using  a  UV-2600\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nspectrophotometer  (Shimadzu).  IR  spectra  were  obtained  on  an  IR  Affinity-1  Fourier\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\non a Chirascan circular dichroism spectrometer (Applied Photophysics Ltd., Graz, Austria).\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nOptical rotations were recorded using a MCP 500 polarimeter (Anton Paar). Melting points\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwere  recorded  with  a  digital  display  microscopic  melting  point  instrument  (SGW  X-5).\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nNMR  data  were  acquired  with  a  Bruker  AVANCE  III  HD  700  MHz  NMR  spectrometer\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n(Bruker) with  TMS as reference. HRESIMS spectroscopic data  were obtained on  a MaXis\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nquadrupole-time-of-flight  mass  spectrometer  (Bruker,  Karlsruhe,  Germany).  Preparative\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nreversed-phase  HPLC  was  performed  on  a  Shimadzu  LC-20A  preparative\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\nliquid\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nchromatography  system  with  a  YMC-Pack  ODS  column  (250  ×  20  mm,  S-5  µm,  12  nm).\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nSephadex  LH-20  (GE  Healthcare)  was  used  for  the  chromatographic  column  (CC).\n**BLOCK**fs== 12.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nRP-MPLC  (reversed-phase-medium  pressure  preparative  liquid  chromatography)  was\n**BLOCK**fs== 12.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\ncarried  out  using  the  CHEETAH  MP200  system  (Agela  Technologies,  Tianjin,  China)  and\n**BLOCK**fs== 12.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nClaricep Flash columns filled with ODS (40-63 µm, YMC). Silica gel (200–300 mesh) for\n**BLOCK**fs== 12.0**p== 2.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nCC and GF254 for TLC were purchased from Yantai Jiangyou Silica Gel Development Co.,\n**BLOCK**fs== 12.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nLtd.  Sea  salts  were  commercially  obtained  from  Guangzhou  Hai  Li  Aquarium  Technology\n**BLOCK**fs== 12.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nFigure S16. HPLC analysis of FDAA derivates of two standard amino acids and compound\n**BLOCK**fs== 12.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.3**\n2 (Column; YMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm)\n**BLOCK**fs== 12.0**p== 12.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nFigure S17. HPLC analysis of FDAA derivates of four standard amino acids and compound\n**BLOCK**fs== 12.0**p== 12.0**b== 0.9**t== 0.1**l== 0.1**r== 0.3**\n1 (Column; YMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm)\n**BLOCK**fs== 12.0**p== 13.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nFigure S18. Chairal analysis of FDAA derivates of two standard amino acids and compound\n**BLOCK**fs== 12.0**p== 14.0**b== 0.9**t== 0.1**l== 0.1**r== 0.4**\nFigure S19. Key COSY and HMBC correlations of 1 and 2.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nFigure  S20.  The  ability  of  compounds  1-3  to  inhibit  LPS-induced  NO  production  in\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nRAW264.7 cells were pretreated with compounds (10 μM) for 1 h and treated with LPS (100 ng/ml) for 24 h.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\n###, p<0.001 vs control; *, p<0.005, **, p<0.01 , ***, p<0.001 vs LPS treated group.",
         "acid-derived oximes methyl (E)-N-(2-hydroxyimino-3-phenylpropanoyl)-L-phenylalaninate  (4),  were  isolated  from  the mangrove-sediment-derived  fungus  Lecanicillium  kalimantanense  SCSIO  41702.  Their structures were determined by spectroscopic analysis. The absolute configurations of 1 and 2 were  determined  by  Marfey’s  method.  Compounds  1  and  2  showed  medium  inhibitory activity against LPS-induced NO production. General  experimental  procedures:  UV  spectra  were  measured  using  a  UV-2600 spectrophotometer  (Shimadzu).  IR  spectra  were  obtained  on  an  IR  Affinity-1  Fourier on a Chirascan circular dichroism spectrometer (Applied Photophysics Ltd., Graz, Austria). Optical rotations were recorded using a MCP 500 polarimeter (Anton Paar). Melting points were  recorded  with  a  digital  display  microscopic  melting  point  instrument  (SGW  X-5). NMR  data  were  acquired  with  a  Bruker  AVANCE  III  HD  700  MHz  NMR  spectrometer (Bruker) with  TMS as reference. HRESIMS spectroscopic data  were obtained on  a MaXis quadrupole-time-of-flight  mass  spectrometer  (Bruker,  Karlsruhe,  Germany).  Preparative reversed-phase  HPLC  was  performed  on  a  Shimadzu  LC-20A  preparative liquid chromatography  system  with  a  YMC-Pack  ODS  column  (250  ×  20  mm,  S-5  µm,  12  nm). Sephadex  LH-20  (GE  Healthcare)  was  used  for  the  chromatographic  column  (CC). RP-MPLC  (reversed-phase-medium  pressure  preparative  liquid  chromatography)  was carried  out  using  the  CHEETAH  MP200  system  (Agela  Technologies,  Tianjin,  China)  and Claricep Flash columns filled with ODS (40-63 µm, YMC). Silica gel (200–300 mesh) for CC and GF254 for TLC were purchased from Yantai Jiangyou Silica Gel Development Co., Ltd.  Sea  salts  were  commercially  obtained  from  Guangzhou  Hai  Li  Aquarium  Technology Figure S16. HPLC analysis of FDAA derivates of two standard amino acids and compound 2 (Column; YMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm) Figure S17. HPLC analysis of FDAA derivates of four standard amino acids and compound 1 (Column; YMC-Pack ODS-A clum, 250 x 4.6 mml.D., s-5 μm, 12 nm) Figure S18. Chairal analysis of FDAA derivates of two standard amino acids and compound Figure S19. Key COSY and HMBC correlations of 1 and 2. Figure  S20.  The  ability  of  compounds  1-3  to  inhibit  LPS-induced  NO  production  in",
         "https://figshare.com/articles/journal_contribution/Two_new_amino_acid-derived_oximes_from_the_mangrove-sediment-derived_fungus_i_Lecanicillium_kalimantanense_i_SCSIO_41702/28323314/1/files/52058141.pdf",
         "extracted",
         "None",
         "",
         "Two new amino acid-derived oximes from the mangrove-sediment-derived fungus Lecanicillium kalimantanense SCSIO 41702."
        ],
        [
         "20",
         "008b67207bda1f15d92c5c6d9283c2fae1ace158",
         "None",
         "Samirah Altukhaim,Naoko Sakabe,Kirubananthan Nagaratnam,Neelima Mannava,Toshiyuki Kondo,Yoshikatsu Hayashi",
         "\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nUniversity of Reading\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nTokyo University of Agriculture and Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nRoyal Berkshire Hospital\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nTokyo University of Agriculture and Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nUniversity of Reading\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.2**\nKeywords: stroke, affected upper limb, impairment, motor recovery and Virtual reality\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.7**l== 0.0**r== 0.1**\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.\nRead Full License\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nmotor impairment of the upper limb (UL) after a stroke is common, which negatively impacts patients’\nquality of life. Stroke survivors may develop a condition known as learned non-use, resulting in a\ntendency to avoid using the affected hand due to failure. Previous research has shown that constraint-\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\ninduced movement therapy (CIMT), where the healthy arm is physically constrained to encourage the use\nof the stroke-affected arm, is effective in UL rehabilitation. However, some patients \u0000nd it exhausting and\ntiring. New technologies have been applied to stroke rehabilitation alongside conventional techniques in\nrecent years. For example, immersive virtual reality (IVR) has emerged as a new treatment approach for\nstroke rehabilitation, simulating real-life activities to work on self-care skills. Method: in this pilot study,\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nwe evaluated the e\u0000cacy of the IVR, which incorporates positive reinforcement components in motor\ncoordination as opposed to CIMT using IVR technology. Eighteen participants were randomized to an IVR\ngroup to receive VR intervention plus physical therapy (PT) sessions or a control group to receive PT\nsessions alone. Participants were instructed to reach with either their affected or unaffected hand to a\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.4**l== 0.0**r== 0.1**\nrandomly assigned target in the VR. The movement of the virtual image of the UL was reinforced by\nvisual feedback to the participants. Treatment effects on motor recovery were investigated using the\nFugl-Meyer (FM) scale for the UL, kinematic dataset, and a questionnaire.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nthe IVR group exhibited signi\u0000cant improvements in FM scores (p < 0.05) between the \u0000rst and \u0000fth\nsession, signifying a substantial recovery of UL motor function, with the \u0000fth session showing higher\n**BLOCK**fs== 12.0**p== 1.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nscores. The time to target in the last session reduced compared with that in the \u0000rst session, suggesting\nmotor learning and recovery (p < 0.05). The patients were highly engaged and motivated during the\nsessions because they felt like they were in charge of the virtual image of their upper body.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nThe results suggest that positive reinforcement within the IVR could encourage motor recovery of the\naffected hand and may facilitate the application of motor learning and neuroplasticity principles during\nneurological rehabilitation.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nA stroke occurs when blood \u0000ow to the brain is interrupted or is insu\u0000cient, leading to brain injury or cell\ndeath and subsequent impairment of physical and mental functions [1–3]. This may cause sensory,\nmotor, and cognitive impairments as well as impaired self-care ability and participation in social and\ncommunal activities [4, 5]. The number of stroke deaths in England decreased by half during the \u0000rst\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.1**l== 0.0**r== 0.1**\ndecade of the 21st century [6], and in 2018 it ranked as the fourth leading cause of mortality [7].\nNonetheless, a signi\u0000cant proportion of stroke survivors continue to live with disabilities. Motor\nimpairment is the most common complication after a stroke, and it can negatively affect health and\nmotor skills, particularly when it affects the upper limbs [8, 9].\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nAccording to Adamovich et al. [10], stroke patients undergoing treatment for upper limb impairment\nencounter various challenges. The functional outcome is highly variable; some patients are unable to\nfully recover functionality and are forced to live with varying degrees of upper limb paresis for the rest of\ntheir lives. It has also been reported that the treatment of upper limb hemiparesis is time-sensitive and\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\ninvolves various therapeutic modalities [11, 12]. Thus, these scienti\u0000c studies emphasize the need for\nappropriate rehabilitation procedures that can provide highly effective therapy and a greater possibility of\na higher-level functional recovery. Successful rehabilitation depends on the stroke’s characteristics (such\nas severity, nature, and location) as well as the patient’s age, general health, and pre-stroke function [13].\n**BLOCK**fs== 12.0**p== 2.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nOtherwise, the stroke patient whose impaired hand is rendered inactive for an extended period may\nacquire learned non-use. Learned non-use is the outcome of repeated unsuccessful attempts to use the\naffected upper limb coupled with the reinforcement of compensatory methods (such as the use of the\nunaffected upper limb), which leads to deterrence in using the affected arm [14–17]. Therefore, it is\nnecessary to consider the optimal rehabilitation therapy for stroke patients with upper limb disability and\nlimitations.\n**BLOCK**fs== 12.0**p== 2.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nAccording to the International Classi\u0000cation of Functioning, Disability, and Health, physiotherapists are\nan essential component of multidisciplinary stroke rehabilitation teams [18, 19], as they assist patients in\nregaining mobility and independence by addressing impairments in bodily functions, activity limitations,\nand participation restrictions [20]. To recover movement, coordination, and balance, a physiotherapist\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nprovides conventional physical therapy (PT) for upper limb rehabilitation through exercises, training, and\nphysical movement of the limbs [21].\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nIt has been established that repetitive task training is bene\u0000cial in certain aspects of rehabilitation, such\n**BLOCK**fs== 12.0**p== 2.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nas improving upper limb function [22, 23]. Hence, the term “sensory motor training” was established to\nrepresent various physical activities designed to improve motor performance, strength, power,\nendurance, and sensory integrity, such as proprioception. Moreover, the neuroscience and rehabilitation\nliterature are supporting the idea that task-speci\u0000c or task-oriented practice is essential for restoring\nfunctionality in stroke-impaired limbs. This implies that repeatedly practicing a di\u0000cult activity can alter\nbrain networks responsible for motor control, leading to long-term improvements in motor learning and\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nMotor coordination can only be regained through a neuroplasticity process [25], which is described as\nthe rewiring of the brain’s synaptic connections to develop appropriate communication with the body’s\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nThe most crucial component is performing repeated movements, which provides patients with the ability\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nto perform an activity normally [27]. Constraint-induced movement therapy (CIMT) has been reported to\nbe effective in treating severe paralysis in the body by training the nerve impulses of damaged muscles\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\nthrough constant repetition of movement on the affected side [23, 28, 29]. However, CIMT has major\ndisadvantages, such as exhausting the patient owing to its intensity [30, 31]. Consequently, recent\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\ntechnological solutions have shown promise in terms of improving the function of impaired limbs\nwithout exhausting patients.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nVirtual reality (VR) has emerged as a new treatment approach for stroke rehabilitation, simulating real-\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nlife activities to improve self-care skills [32, 33]. In virtual rehabilitation, patients receive visual feedback\nfrom simulated environments and objects through a head-mounted device, projection system, or \u0000at\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nscreen, while all body senses offer feedback [34]. Virtual tasks and environments affect the users’\nsenses, and they perceive their presence in the virtual world [35, 36]. By adjusting stimuli to movements\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nin real time and incorporating and modifying feedback, VR may enhance the application of motor\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nlearning and neuroplasticity principles during rehabilitation [35] as it provides components (such as goal-\noriented tasks and repetition) demonstrated to be vital in rehabilitation [10].\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nAlthough there is limited evidence of neuroplasticity during VR training, neuroimaging discoveries are\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nguiding the development of VR to meet the highest treatment standards [37]. As technology becomes a\nbroader component of daily life, it is anticipated that the use of VR in rehabilitation settings will increase\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\n[38, 39]. Thus, it is essential to evaluate the effectiveness of VR in order to de\u0000ne its future designs and\nimplementations. The VR environment motivates patients to perform repetitive, motor-intensive tasks\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nthat are crucial for rehabilitation [40–44]. Compared with conventional rehabilitation techniques, a\nconcise adaptive game can improve mobility, motor function, and mental wellbeing.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nNeurological patients generally lack therapy motivation [44]. Possible explanations for this lack of\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.6**l== 0.0**r== 0.1**\nmotivation include patients’ belief that therapy only intends to enable adaptation to the disease rather\nthan providing complete healing, or a lack of motivating input from a therapist [44, 45]. Other logistic,\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\n\u0000nancial, environmental, and human obstacles may restrict the e\u0000cacy and commitment to long-term\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nrehabilitation regimens [42] found that combining VR with modi\u0000ed CIMT encouraged stroke patients to\nuse the affected hand without constraining the unaffected side (both hands were free to move). Another\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.7**l== 0.0**r== 0.3**\nstudy investigated the safety and effectiveness of VR and modi\u0000ed CIMT [46].\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nRelevant to our investigation, [47] proposed a new treatment that combines CIMT and reinforcement-\ninduced movement therapy (RIMT). They demonstrated the e\u0000cacy of RIMT by speeding up the hindered\n**BLOCK**fs== 12.0**p== 3.0**b== 0.1**t== 0.8**l== 0.0**r== 0.1**\nhand in VR using the goal-oriented reaching task. After the RIMT intervention, the Fugl-Meyer (FM)\nscores of stroke patients improved; however, their study did not report the subjective feeling of being\n**BLOCK**fs== 12.0**p== 3.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\ncompletely engaged in VR. Although they pioneered positive reinforcement utilizing computer-simulated\nlimbs in the display, the RIMT concept should be developed to use immersive VR (IVR).\n**BLOCK**fs== 12.0**p== 3.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nVisual feedback in IVR simply displays the simulated upper limb. Only the simulated hand should be seen\n**BLOCK**fs== 12.0**p== 3.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nduring the task. If people watch their real hand move in front of them while viewing the simulated hand\n**BLOCK**fs== 12.0**p== 4.0**b== 0.9**t== 0.1**l== 0.0**r== 0.1**\non the display, the discrepancy in visual feedback of motor coordination will induce a sense of loss of\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nownership of the simulated upper limb or, in certain situations, the subjective awareness of the loss of\nbodily control.\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\nOur study by [48] that used IVR on healthy subjects with a weight attached to their dominant hand to\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nsimulate the impairment of a stroke patient is also relevant to our investigation. Their system was\nportable (head-mounted VR), and the objective was to reach a target in VR without forcing the subjects\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nto use their dominant hand, with an option to use either hand. The movement of the virtual image of the\nupper limb was reinforced by visual feedback to the participants, such that they perceived their motor\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\ncoordination as if their upper limb was moving to a greater extent than normal. These \u0000ndings suggest\nthat positive reinforcement within IVR can in\u0000uence hand usage decision-making.\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.3**l== 0.0**r== 0.1**\nThus, herein, we modi\u0000ed the protocol developed by [48] for stroke survivors to accommodate the\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nspeci\u0000c requirements of the patients, including extended task completion time and breaks to prevent\nfatigue, as detailed in the method section. Our study aimed to evaluate a new therapeutic approach for\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nthe rehabilitation of the upper limbs of stroke patients to demonstrate the effectiveness of IVR-enhanced\n**BLOCK**fs== 12.0**p== 4.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nPT by measuring the improvement in upper limb motion using the FM score. Additionally, to conduct a\nlarger study in the future, a participant experience questionnaire was administered to evaluate the\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nEighteen subjects (69.4 ± 13.5 years, eight women) with acute post-stroke hemiparesis (16 ischemic\nstrokes) were recruited in the study at the stroke unit of the Royal Berkshire Hospital in Reading, United\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nKingdom. The sample size was limited by the number of patients that could be enrolled over the project’s\nduration. The experiment was approved by the ethics committee Health Research Authority and Health\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nand Care Research Wales (IRAS project ID: 264096) and performed according to relevant guidelines and\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nThe participants were screened for study eligibility by the clinical team according to the inclusion and\nexclusion criteria. The inclusion criteria were (i) age ≥ 18 years; (ii) recent stroke (ischemic/hemorrhagic)\nwithin the last 4 weeks; (iii) Montreal Cognitive Assessment score > 18; (iv) ability to sit independently in\na chair; (v) upper limb weakness; and (vi) ability to speak and read English. The exclusion criteria were (i)\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nvisual \u0000eld defect; (ii) visual or sensory neglect; (iii) strokes affecting both upper limbs; (iv) poor static\nand dynamic balance in sitting; (v) shoulder subluxation or dislocation; (vi) upper limb weakness due to\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nconditions other than stroke; (vii) presence of emotional and/or cognitive de\u0000cits (such as global\naphasia, apraxia, dementia, and depression) that could interfere with the understanding and execution of\n**BLOCK**fs== 12.0**p== 5.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nParticipants provided written informed consent after being informed about the aims and procedure of\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.1**l== 0.0**r== 0.1**\nthe experiment. They were allocated to either receive IVR and conventional PT (intervention group, 10\npatients) or receive conventional PT alone (control group, 8 patients) (Tables 1 and 2). Both groups\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nreceived conventional PT on the ward, administered in accordance with national guidelines. The patient\nallocation, conducted through a randomization process, occurred at a 1:1 ratio using pre-prepared sealed\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nopaque envelopes. These envelopes, numbered by the Trust the Research & Development department\nbefore recruitment began, contained information identifying the assigned group for each patient. To\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nensure equitable and unbiased distribution, an online random number generator utilizing atmospheric\nnoise assigned numbers to each envelope [49]. The research team sequentially opened the sealed\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nenvelopes (numbered 1–30) to determine group allocation for each participant. Additionally, the\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.3**l== 0.0**r== 0.1**\nassigned number served as the participant identi\u0000cation number throughout the study. This rigorous\nrandomization process aimed to enhance the validity and reliability of the research \u0000ndings.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nParticipants could withdraw consent at any time during the study, yet the collected data were retained\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nand used without additional procedures on or in relation to the participant. Two patients in the\nintervention group withdrew from the trial owing to di\u0000culty to complete the task, a perception of\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.4**l== 0.0**r== 0.3**\ntherapy being ineffective, or a desire to concentrate more on the lower limb.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nTable 1\nDemographic characteristic and stroke subtypes (N = 10) of the intervention group.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\nStroke type\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nLesion site\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nIntervention\ngroup\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.8**r== 0.2**\nAffected\nside\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.9**r== 0.0**\nDominant\nhand\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nRight LACI\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nRight LACI\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.2**l== 0.6**r== 0.3**\nRight posterior\ncerebral\ncirculation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\nRight total\nanterior cerebral\ncirculation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nRight partial\nanterior cerebral\ncirculation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\nLeft partial\nanterior cerebral\ncirculation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\nRight posterior\ncirculation stroke\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.5**\nHaemorrhage\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.6**r== 0.4**\nLeft LACI\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\nIschemic with\nhaemorrhagic\ntransformation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nRight MCA\ninfarct\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nRight LACI\n**BLOCK**fs== 12.0**p== 7.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nTable 2\nDemographic characteristics and stroke subtypes (N = 8) of the control group.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\nStroke\ntype\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.4**r== 0.5**\nLesion site\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.7**r== 0.2**\nAffected\nside\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.9**r== 0.1**\nDominant\nhand\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\nRight posterior cerebral\ncirculation\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.2**l== 0.4**r== 0.3**\nRight total anterior cerebral\ncirculation\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\nRight partial anterior\ncerebral circulation\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.3**l== 0.4**r== 0.4**\nLeft posterior cerebral\ncirculation infarction\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\nRight total anterior cerebral\ncirculation s\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\nRight pontine infarct\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.4**r== 0.3**\nRight partial anterior\ncerebral circulation infarct\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nIschemic\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\nRight lacunar infarct\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.9**\nControl\ngroup\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nWe utilized the same method as used for healthy subjects; for more information, please refer to the\npaper by [48]. An integrated IVR system consists of a VR headset (Oculus Rift) and a small motion\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\ncapture sensor (Leap Motion) attached to the headset (Fig. 1) Both products are CE marked. This system\ncan monitor the actual upper limb movements of the participants and create a virtual image of the\ncorresponding upper limb in the IVR environment. It also provides a real time motion of the\ncorresponding virtual upper limb. The person using IVR equipment can “look around” the arti\u0000cial world\n**BLOCK**fs== 12.0**p== 7.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nand interact with virtual features or objects. Through iterative visual-motor loops in the brain, the person\nexperiences a feeling of controlling the virtual image of their body in such a way that the virtual world\ncan be perceived as a real one. Stroke survivors go through task-oriented training of the upper limb in the\n**BLOCK**fs== 12.0**p== 7.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nIVR environment. As they experience the ideal motor coordination of their upper limb’s avatar, successful\nmatching of motor intention and resultant motor coordination in the IVR allows brain networks to form\nnew neuronal pathways for spontaneous motion in their daily life. Therefore, IVR-enhanced therapy may\noffer a powerful rehabilitation approach, allowing PT to be tailored to the speci\u0000c needs of survivors with\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nParticipants were asked to sit comfortably on a chair and place their upper extremities on a table in front\nof them (Fig. 1A). Seven targets were arranged in a semi-circular orientation within the IVR environment\n(Fig. 2A). As a goal-oriented task, participants were asked to reach for the target immediately by\nchoosing their healthy or impaired upper limb hand (Fig. 2B). To implement reinforcement-induced PT,\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nthe velocity of the hand of the impaired upper limb was ampli\u0000ed in the virtual environment in the\ndirection of the target. The target turned blue when reached by the virtual hand and immediately\ndisappeared. Unlike for healthy individuals, we increased the time to 4 seconds after the ball appeared to\nprevent in-depth consideration regarding choosing, as stroke patients require more time. If this condition\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.0**r== 0.3**\nwas not ful\u0000lled, the target disappeared, and the trial was invalidated.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nThe experiment included three stages: familiarization, intervention, and washout (Fig. 3). At each stage,\nvisual ampli\u0000cation is consistently applied to the affected side (right or left), in contrast to the healthy\nexperiment where the visual ampli\u0000cation depended on the experimental phase, speci\u0000cally for the right\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nside. The visual ampli\u0000cation, de\u0000ned as increasing the velocity of the virtual hand corresponding to the\nimpaired upper limb by 1.4 times compared to the actual hand motion, will be described. It was\nhypothesized that the participants would start to use the affected hand more often as the velocity was\nampli\u0000ed in the IVR environment.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nThe aim of the familiarization stage was to acquaint the participants with the task. In this stage, \u0000ve\ntargets (excluding the far right and far left targets) appeared randomly in a semi-circular array in the\nvirtual environment (see Fig. 2A), each target appeared four times. For example, participants completed\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\n20 reaching trials, equally divided between using the right hand (the \u0000ve targets appearing twice) and the\nleft hand in 10 trials each (the \u0000ve targets appearing twice). This stage was applied only once at the\nbeginning of each session.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nSubsequently, the primary stage in this experiment was the intervention stage/free choice stage, wherein\nthe participants were free to choose the right or left hand (unaffected or affected limb) to reach the\ntarget that randomly appeared in seven different positions. To accommodate the patients in the study,\n**BLOCK**fs== 12.0**p== 8.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nwe reduced the number of times they reached for the ball from 70 to 35 (5 times per target), This\nadjustment was implemented due to our concern about potential participant fatigue. Post-stroke fatigue,\nwhich is prevalent throughout the acute and chronic phases following a stroke and can substantially\nimpact rehabilitation outcomes, should also be considered when designing a treatment plan [50]. Due to\n**BLOCK**fs== 12.0**p== 8.0**b== 0.1**t== 0.8**l== 0.0**r== 0.1**\nbrain damage and limb weakening, stroke survivors are more likely to experience fatigue than healthy\nindividuals. In this stage, the participants repeated the reaching task at their own pace, with varying\nrepetitions per person in each session. Each task comprised 35 balls and lasted for 3–5 minutes. To\n**BLOCK**fs== 12.0**p== 8.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\navoid fatigue, participants were given 2-minute rest periods between each task. The term \"session\" refers\nto the time when patients receive IVR training, occurring once per day. The number of sessions is\n**BLOCK**fs== 12.0**p== 9.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\ndetermined by the duration of the patient's hospital stay until discharge or completion of 15 sessions—\nwhichever comes sooner.\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\nThe \u0000nal stage was the washout, similar to the intervention stage (35 target per task) but gradual\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nreduction in the velocity of ampli\u0000cation in the IVR environment to 1.2 times the actual hand motion. We\nhypothesized that even when the ampli\u0000cation is reduced in the IVR environment, the participants would\ncontinue to utilize the affected upper limb, resulting in increased use of the affected upper limb in daily\nlife. This stage was intended to commence from the 10th session and extend until the 15th session.\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nHowever, because of early discharge of patients, we could complete this stage with only two patients.\nThe entire session lasted for 20–40 minutes, depending on the patient’s condition.\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nThe Fugl Meyer for upper limb (FM) assessment was used to evaluate the functional motor condition as\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nthe primary outcome in this study. FM score was selected as the primary outcome measure because FM\nassessment is a well-designed, feasible, and effective clinical examination technique that has been\nextensively used in the stroke population [51–54]. This scale is highly recommended as a clinical and\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nresearch instrument for assessing changes in motor impairment after stroke [55]. The evaluation was\nconducted by a physiotherapist who participated in the program. The FM assessment is crucial for\ndetermining motor recovery and disease severity [56]. It has \u0000ve domains: motor function, sensory\nfunction, balance, joint range of motion, and joint pain [57, 58]. The motor function domain is the most\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nwidely used and plays a primary role in monitoring motor recovery after stroke. The items in the FM\nmotor function domain are based on patient motion, coordination, and re\u0000ex action in the shoulder,\nelbow, forearm, wrist, and hand. Each domain contains multiple items, each scored on a 3-point ordinal\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nscale (0 = cannot perform, 1 = performs partially, 2 = performs fully). The total score varies from 0 to 66.\nThe measurements were utilized to assess the e\u0000cacy of IVR feedback in restoring motor coordination\naffecting the patient’s QoL. Our initial plan was to collect FM scores from participants at the beginning,\nmiddle, and end of their participation in the study. However, because of the COVID-19 pandemic, the\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nlength of hospitalization varied, and patients could be discharged without notice. Hence, depending on\nthe length of stay, we evaluated the patients in the \u0000rst, \u0000fth, and tenth sessions. The control group\nunderwent evaluations during corresponding sessions, ensuring consistent assessment across both\ngroups with the same timescales as the intervention group. Note that the ethical approval allowed a\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\ncertain period for our clinical study, not allowing us to extend our study to recruit more patients.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nWe used a questionnaire administered at the end of the last session to evaluate patient experience,\nprovide information regarding the sense of agency (subjective awareness of initiating and controlling\none’s own activities) [59], and obtain comments about the training sessions in the IVR environment. The\nquestionnaire contained four short items that required participants to respond with a simple “yes,” “no,”\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.0**r== 0.5**\n• Did you feel that you were controlling the virtual hand?\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.0**r== 0.3**\n• Did you feel a sense of achievement during the virtual reality therapy?\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.0**r== 0.4**\n• Did you feel dizzy when looking around in the virtual reality?\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.0**r== 0.4**\n• Did you feel any fatigue in any of your muscles during the therapy?\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.4**l== 0.0**r== 0.2**\n• If you have any comments or feedback on your experience, please include them below.\nB. Barthel Index (Clinical Outcome)\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nThe Barthel index (BI; modi\u0000ed 10-item version) is used to measure the amount of independence and\nmobility of patients in their activities of daily living (ADL), such as feeding, bathing, grooming, dressing,\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nbowel control, bladder control, toileting, chair transfer, ambulation, and stair climbing [60]. The evaluation\nwas conducted by a physiotherapist who was not involved in the training. This tool indicates the need for\nassistance in care and is widely used as a measure of functional disability [61]. Depending on the item,\nfunctional categories may be rated 0–1, 0–2, or 0–3 points. The range of possible total scores is 0–20.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.0**r== 0.3**\nTwo measurements were taken at both the baseline and discharge stages.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nTo evaluate the use of unaffected and affected hands in the VR environment during the training sessions\nbased on enhanced visual feedback, we calculated the border angle (BA) of the \u0000rst two repetitions of\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nthe task (total of 70 times) in each patient across the sessions. A psychometric function was \u0000tted to\nthe plots of the probability of affected hand usage as a function of the target angles; (see Fig. 2B in [48]).\nThe angle at which the psychometric function corresponds to a 50% probability was de\u0000ned as the BA.\nII. Time to Target\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nTo determine the time to target for each subject, the reaction time of the affected hand for each target\nwas recorded, encompassing the duration from the ball's onset to the participant reaching it. Each trial\ncommenced with participants placing their hands at the starting point (home position), triggering the\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nappearance of the ball upon accurate hand placement. Following this, participants reached the target,\nreturned their hands to the starting position, and repeated the process for successive targets in different\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nlocations (35 balls). We considered it important to compare subjects’ reaction times during the therapy\nacross the sessions to evaluate the improvements; we hypothesized that faster reaction times indicated\neffective motor learning resulting in motor recovery.\nD. Observation of Patient’s Strategy\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nThe physiotherapist who participated in the training sessions reported all vital observations, which were\nnecessary to comprehend the patient’s treatment strategies.\nAnalysis and Statistics\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nTo establish the e\u0000cacy of IVR feedback in the recovery of motor coordination, the statistical difference\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nin FM scores between the \u0000rst and \u0000fth sessions for each patient in both groups was analyzed. For\nfurther analysis, we conducted paired compression test for BI, BA and time to target. The Shapiro-Wilk\ntest was used to check the normality of the distribution, and the Wilcoxon signed-rank test or the paired\nStudent’s t-test was applied to evaluate. The level of signi\u0000cance was set at p < 0.05. In addition,\nrepeated measures analysis of variance (ANOVA) mixed model was employed to determine the in\u0000uence\nof two factors, namely the target locations and the sessions, on the reaction time.\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nThe answers derived from the questionnaire were not compared statistically between the groups.\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nHowever, subjective experience is crucial for determining whether a larger community would be\ninterested in IVR physical treatment.\n**BLOCK**fs== 12.0**p== 11.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nIn this study with stroke patients, we noted that they adopted certain intriguing methods while\nundergoing therapy. The observations were made from the perspective of a physiotherapist. These\n\u0000ndings were considered important in the study because they revealed how the patients coped or\nutilized other motor movements to complete the task. Hence, the patients were separated into distinct\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nTwo signi\u0000cant observations were made in this study. Firstly, each patient underwent a varying number\nof sessions, as outlined in Table 3. This number was correlated with the duration of hospitalization, with\nsome patients receiving \u0000ve sessions and others having more or fewer; there was no standard quantity\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nfor sessions. Secondly, each patient was able to repeat the number of tasks per session according to\ntheir condition and endurance level. Some patients repeated the task twice, while others repeated it more\ntimes per session. Consequently, patients were categorized into three main groups (Table 4).\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nTwo sessions\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\nFour sessions\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\nFive sessions\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nSeven sessions\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.8**r== 0.1**\n10–14 sessions\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nET009 (withdraw)\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nTable 4 The number of task repetition per session. The \u0000rst row under each patient's ID indicates the\nnumber of sessions, whereas the second row indicates the number of times they could repeat the task in\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nThe FM score measured predominantly in the \u0000rst and \u0000fth sessions (seven and eight patients in the\nintervention and control groups, respectively) as shown in Table 5A and B. One patient’s (ET017) data\nwas eliminated from the intervention group because he underwent only four sessions, and we could not\nrepeat the evaluation due to his discharge from the stroke unit. Additionally, two patients (ET013 and\n**BLOCK**fs== 12.0**p== 14.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nET019) who stayed longer in the hospital were evaluated three times. Nevertheless, data from only the\n\u0000rst and \u0000fth sessions were analyzed (Table 5A).\n**BLOCK**fs== 12.0**p== 14.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nConversely, two patients in the control group (ET010 and ET015) had a full score at the beginning of the\nstudy. However, we repeated the assessment in the \u0000fth session to ensure that there was no\ndeterioration in their motor function, as neurological deterioration is common in some stroke patients\n[62] and we observed that their scores remained unchanged (Table 5B).\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nAs shown in (Fig. 4A and B), all seven patients in the intervention group showed improvement in the FM\nscore following IVR-enhanced visual feedback, while only two of eight patients in the control group\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nshowed improvement in the FM score. Moreover, there was no change in the FM score between the \u0000rst\nand \u0000fth sessions for six patients.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\nTable 5\nFugel Meyer score for both groups in \u0000rst and last session. (A)\nFM scores for the intervention (A) and control (B) groups. The\ndifferences in FM scores between the \u0000rst and \u0000fth sessions\nfor each patient are displayed in both tables. The data in red\nindicate an improvement. (The total score of FM is = 66).\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.5**l== 0.2**r== 0.6**\nIntervention group\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\nFM_1st_session\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nFM_5th_session\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.7**r== 0.2**\nDifference\n**BLOCK**fs== 12.0**p== 15.0**b== 0.9**t== 0.1**l== 0.2**r== 0.6**\nControl group\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.1**l== 0.3**r== 0.5**\nFM_1st_session\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.1**l== 0.5**r== 0.3**\nFM_5th_ session\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.1**l== 0.7**r== 0.2**\nDifference\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nBefore conducting paired comparison analysis, we used the Shapiro–Wilk test to ensure that the data\nmet normal distribution requirements. For the intervention group, the p-values obtained from the\nnormality test were 0.23 and 0.02 for FM assessments in the \u0000rst and \u0000fth sessions, respectively,\nwhereas for the control group, they were 0.03 and 0.01, respectively. Because the data obtained from FM\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nassessments in both groups were not normally distributed, we used the Wilcoxon signed-rank test for the\npaired sample comparison of the data. As shown in the box plot in Fig. 5, the FM scores differed\nsigni\u0000cantly between the \u0000rst and \u0000fth sessions for the intervention group (P = 0.08) but not for the\ncontrol group (P = 0.16), indicating that IVR enhanced the motor function of the affected upper extremity.\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nOnly seven patients responded to the questionnaire. Their responses indicate that they were engaged in\nthe therapy, motivated, and felt a sense of achievement. The crucial part was that this therapy induced a\nsense of agency over the virtual hand because they felt as if they were controlling the avatar. Their\nanswers were “somewhat” and “no” when they were asked if they felt dizzy during the therapy. They all\nreported that they experienced no muscle fatigue during the task. Finally, they provided comments\nregarding the therapy, such as “Enjoyed the therapy,” “Therapy was fun,” and “It improved my hand\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.0**r== 0.1**\ncoordination and control.” However, one of them stated that the “headset was quite heavy.”\nB. Barthel Index (BI)\n**BLOCK**fs== 12.0**p== 15.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nIn terms of BI, not all individuals were evaluated twice; only nine participants (four in the intervention\ngroup and \u0000ve in control group) had their data recorded twice (see the supplementary \u0000les A1 and A2).\n**BLOCK**fs== 12.0**p== 16.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nWe used the Shapiro–Wilk test to compare the normality of the distributions of the two groups’ data. For\nthe intervention group, the p-values obtained from the normality test were 0.07 and 0.02 for the \u0000rst and\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nlast sessions, respectively, whereas p-values in the control group were 0.19 and 0.80, respectively. As we\nhad a small data size and some of them were not normally distributed, we considered that our data were\nnot normally distributed.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nTherefore, the Wilcoxon signed-rank test was used. We found that BI scores did not differ signi\u0000cantly\nbetween the \u0000rst and last sessions in the intervention group (p = 0.07), whereas they differed\nsigni\u0000cantly in the control group (p = 0.04).\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nThree of nine patients were excluded from further analysis as the BA could not be calculated because\nthey chose a biased strategy, such as using their affected hand for all the targets (ET001, ET009, and\nET017). We only calculated the BA for each session’s two task repetitions (total of 70 balls). Additionally,\nwe only analyzed the data of patients who underwent \u0000ve sessions and calculated their BA. Patients who\nunderwent less than \u0000ve sessions were therefore excluded from the analysis. Nevertheless, the data\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nfrom only the \u0000rst \u0000ve sessions were analyzed for individuals who underwent more than \u0000ve sessions\n(ET013, ET018, and ET019).\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nWe excluded the patient whose right side was affected (ET017) from the analysis because the data of\nthe patient could not be combined with that of the group with the left side affected as each group had a\ndifferent strategy for achieving targets. Before performing the paired comparison analysis, we used the\nShapiro–Wilk test to ensure that the data met normal distribution requirements. The p-values obtained\n**BLOCK**fs== 12.0**p== 16.0**b== 0.2**t== 0.6**l== 0.0**r== 0.0**\nfrom the test for normality were 0.20, 0.15, 0.83, 0.52, and 0.59 for sessions 1, 2, 3, 4, and 5, respectively.\nOwing to the normal distribution of the BA data across all sessions, we used the paired Student's t-test to\nassess the differences in BA between sessions and the results indicated that there was no statistically\nsigni\u0000cant difference across the session, as indicated by a p-value greater than 0.05. Unlike the healthy\nparticipants in Sakabe et al. study [48] the stroke patients used a different strategy to reach the target.\nFor example, they developed their own exercise plan, i.e., they used the affected hand only in reaching\nmost of the targets, and other time they train the non-affected side.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nOne participant was excluded from further analysis (ET008), for the reason that his reaction time was\naffected because of spatial neglect, for example, lack of attention towards the targets near the affected\nside and he needed to be reminded to refocus his attention. Furthermore, he employed a distinct\napproach when attempting to reach the target.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nWe found that the patients with left-side impairment were always able to reach the targets closest to the\naffected side (targets 7, 6, and 5) but occasionally reached the other targets, whereas patients with right-\n**BLOCK**fs== 12.0**p== 17.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nside impairment were always able to reach targets 1, 2, and 3. Hence, a repeated measures analysis of\nvariance (ANOVA) mixed model was employed to determine the in\u0000uence of two factors, namely the\n**BLOCK**fs== 12.0**p== 17.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\ntarget locations and the sessions, on the reaction time. The analysis revealed that there is no statistically\nsigni\u0000cant difference in the Targets (p = 0.67). However, a signi\u0000cant difference was seen between\nsessions (\u0000rst and last) (P < 0.01).\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.2**l== 0.0**r== 0.1**\nTherefore, we combined the average value of the reaction time of targets 5, 6, and 7 for the left sided\npatients and targets 1, 2 and 3 for the right sided patients. We then proceeded to compare the results\nobtained from the \u0000rst and last sessions.\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nBefore the paired sample comparison test, we used the Shapiro–Wilk test to determine whether the data\nmet the normal distribution criteria. The resulting p-value was P < 0.05, indicating that the data were not\nnormally distributed. We then performed the Wilcoxon signed rank test on eight patients in order to\nreveal the improvement of motor recovery between the \u0000rst and last session in terms of the reaction\ntime of the affected hand.\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nBased on the box plot depicted in (Fig. 6), there is a statistically signi\u0000cant difference found between the\n**BLOCK**fs== 12.0**p== 17.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\n\u0000rst session and the last session (P = 0.03), suggesting the motor recovery of the affected limb in terms\nof kinematics. In contrast, we found that there was no motor learning on the unaffected upper limb (P =\n0.20).\n**BLOCK**fs== 12.0**p== 17.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nWe subgrouped the patients based on the similarity of their strategies and highlighted the following three\nsigni\u0000cant characteristics from the therapist’s observation:\n**BLOCK**fs== 21.0**p== 17.0**b== 0.3**t== 0.6**l== 0.0**r== 0.1**\nI. Patients Categorized Based on the Frequency Hand\nUsage (Affected or Unaffected hand)\n**BLOCK**fs== 12.0**p== 17.0**b== 0.2**t== 0.7**l== 0.0**r== 0.3**\nBased on the recorded data, we identi\u0000ed two categories of patients;\n1. The Frequency of Using the Affected Side\n**BLOCK**fs== 12.0**p== 17.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nThis category comprised two types of patients who predominantly used their affected hand to reach the\nmajority of targets, potentially indicating self-motivation and competitiveness. The \u0000rst type achieving ≥\n80% of the affected hand usage (28 targets out of 35), The second type patients used 71–77% (25 to 27\ntargets out of 35). Notably, this method was not used for every session; for example, patient ET001 used\nboth methods.\n2. The Frequency of Using the Unaffected Side\n**BLOCK**fs== 12.0**p== 18.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nThis category included patients who did not use the affected hand to reach targets because they wanted\nto train the opposite side; they used the affected 25% (0 to 8 times out of 35).\nII. Patients Categorized Based on Strategy for Reaching\nTargets\n**BLOCK**fs== 12.0**p== 18.0**b== 0.6**t== 0.2**l== 0.0**r== 0.0**\nEach patient employed a unique strategy for achieving the targets. For instance, some patients utilized\ntrunk movement to assist in reaching the target, while others switched to their unaffected hand if they\nwere unable to reach the target, returned to their starting position, and repeated the task. Additionally,\ncertain patients exhibited circumduction movements rather than moving in a direct line. Moreover, some\npatients tapped the table upon successfully reaching the target.\nIII. Patient Categorised Based on Factors Affecting\nPerformance\n**BLOCK**fs== 12.0**p== 18.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nSome patients exhibited characteristics that could affect their performance. For instance, neglecting the\naffected side resulted in overlooking targets close to that side, while leaning towards the affected side\nled to neglecting targets on the opposite side. Others had hand deformities, although this did not impact\nthe e\u0000cacy of the system. Additionally, negative mood and lack of sleep were observed to have\n**BLOCK**fs== 12.0**p== 18.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nThe primary goal of this pilot study was to investigate the feasibility of IVR technology in the upper limb\nrehabilitation of stroke patients, as opposed to traditional CIMT that combines positive reinforcement in\nPT. Our study by [48] con\u0000rmed that positive reinforcement in IVR in\u0000uences hand usage decisions in\n**BLOCK**fs== 12.0**p== 18.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nhealthy participants. In this study, we modi\u0000ed the IVR system in order to meet the speci\u0000c requirements\nof the patients by reducing the target number and extending the time limit to reach the targets. The\ne\u0000cacy of the IVR-enhanced PT was validated using the Fugl-Meyer (FM) assessment to test the\nimprovement of the upper limb motion with respect to the control group.\n**BLOCK**fs== 12.0**p== 18.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nBased on our \u0000ndings, it is evident that the intervention group, which received IVR combined with\nconventional physical therapy (PT), exhibited improvement in the FM score in all patients compared to\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nthe control group (Table 5 and Figs. 4 and 5) which received only PT. This observation is promising,\nindicating a positive trajectory that may offer insights into the e\u0000cacy of the IVR intervention. The\npositive outcomes observed in the intervention group suggest the effectiveness of IVR in enhancing\nmotor function. However, the question persists: Can this improvement be attributed solely to the system,\nthe physiotherapy sessions, or their combined synergistic impact, serving as compelling evidence of\ne\u0000cacy?\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.9**l== 0.0**r== 0.1**\nVR is frequently compared to conventional therapy (CT) administered by physio- and occupational\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\ntherapists in studies on stroke rehabilitation. The updated Cochrane review by Laver et al. [8] concluded\n**BLOCK**fs== 12.0**p== 19.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nthat the e\u0000cacy of VR-based therapy was not superior to that of CT in enhancing upper limb function.\nSpeci\u0000cally, they reported that VR “may be bene\u0000cial in improving upper limb function and ADL function\n**BLOCK**fs== 12.0**p== 19.0**b== 0.7**t== 0.1**l== 0.0**r== 0.0**\nwhen used as an adjunct to conventional care (to increase overall therapy time)”. It is essential to note\nthat their study primarily focused on commercial video gaming consoles, a prevalent choice in VR-based\nrehabilitation due to their ease of use, enjoyment, and cost-effectiveness [63, 64]. Nevertheless, present-\nday researchers are increasingly avoiding these approaches as these systems are primarily designed for\nhealthy individuals, thereby presenting signi\u0000cant challenges for patients [63]. Consequently, our study\nimplemented an IVR system that is tailored to the speci\u0000c requirements, bene\u0000ts, and conditions of the\npatients. The inherent simplicity of this approach may account for the observed improvement in their FM\n**BLOCK**fs== 12.0**p== 19.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nThis simplicity aligns seamlessly with the overarching goals of stroke rehabilitation, particularly when\nconsidering early initiation to minimize the disease's impact. Given that the participants in our study\nwere acute cases, we promptly initiated IVR in combination with PT once they were medically stable. The\ncombination of therapies in our study, emphasizing both task-oriented exercises and repetitive\nmovements, holds the potential to facilitate patient recovery through intensive treatment.\n**BLOCK**fs== 12.0**p== 19.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nIn IVR training, it involved task-oriented exercises, particularly actions like reaching for ball—a movement\nintegral to activities of daily living (ADL) that frequently necessitates the use of the arm [65, 66].\nAdditionally, the task contained repetitive movements [67]. This approach has the potential to enhance\nneuroplasticity [68, 69] by facilitating the restoration of movement on the impaired side through the\nactivation of a new motor projection region and the resting of synapses [70, 71]. As mentioned in\nprevious studies [8, 70, 72, 73], the current focus in clinical settings is on the combined use of VR and PT\nfor rehabilitation. These associated technologies are becoming more accessible and prevalent [74].\n**BLOCK**fs== 12.0**p== 19.0**b== 0.2**t== 0.6**l== 0.0**r== 0.0**\nNevertheless, within the domain of VR, the direct effects of VR therapy on neuroplasticity are still under\ninvestigation, and current evidence is limited [8]. However, Wang et al. [70] employed functional magnetic\nresonance imaging to investigate neuronal remodelling in subacute stroke patients before and after\ntraining with a Leap Motion-based VR system. They compared it to CT alone. Patients were instructed to\nposition their affected thumb on their palm. They found that sensorimotor cortex activation moved from\nthe ipsilateral to the contralateral region and increased in the contralateral cortex in both groups. On the\nWolf motor function test, which assesses upper limb motor function, the experimental VR group had a\n**BLOCK**fs== 12.0**p== 19.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nsigni\u0000cantly greater improvement and better performance than the control group. These results\ndemonstrate that repeated exercises with the affected arm combined with task-oriented practice in a\nvirtual environment can enhance motor recovery of the upper limb more than CT alone. Neuroimaging\nresearch can help increase the training-dependent effects of VR and contribute to the development of VR\ntherapies. These \u0000ndings add to the current evidence that VR therapy should not be ignored in upper limb\nrehabilitation, as it may have apparent advantages for patients’ recovery. More conclusive \u0000ndings to\ndate suggest that VR can improve PT and increase the potential for rehabilitation [51, 52, 75, 76, 77].\n**BLOCK**fs== 12.0**p== 19.0**b== 0.0**t== 0.9**l== 0.0**r== 0.1**\nRather than relying solely on a single method, incorporating VR therapy into existing rehabilitation\nprograms appears effective for enhancing stroke rehabilitation outcomes.",
         "University of Reading Tokyo University of Agriculture and Technology Tokyo University of Agriculture and Technology University of Reading Keywords: stroke, affected upper limb, impairment, motor recovery and Virtual reality License:   This work is licensed under a Creative Commons Attribution 4.0 International License. Read Full License motor impairment of the upper limb (UL) after a stroke is common, which negatively impacts patients’ quality of life. Stroke survivors may develop a condition known as learned non-use, resulting in a tendency to avoid using the affected hand due to failure. Previous research has shown that constraint- induced movement therapy (CIMT), where the healthy arm is physically constrained to encourage the use of the stroke-affected arm, is effective in UL rehabilitation. However, some patients \u0000nd it exhausting and tiring. New technologies have been applied to stroke rehabilitation alongside conventional techniques in recent years. For example, immersive virtual reality (IVR) has emerged as a new treatment approach for stroke rehabilitation, simulating real-life activities to work on self-care skills. Method: in this pilot study, we evaluated the e\u0000cacy of the IVR, which incorporates positive reinforcement components in motor coordination as opposed to CIMT using IVR technology. Eighteen participants were randomized to an IVR group to receive VR intervention plus physical therapy (PT) sessions or a control group to receive PT sessions alone. Participants were instructed to reach with either their affected or unaffected hand to a randomly assigned target in the VR. The movement of the virtual image of the UL was reinforced by visual feedback to the participants. Treatment effects on motor recovery were investigated using the Fugl-Meyer (FM) scale for the UL, kinematic dataset, and a questionnaire. the IVR group exhibited signi\u0000cant improvements in FM scores (p < 0.05) between the \u0000rst and \u0000fth session, signifying a substantial recovery of UL motor function, with the \u0000fth session showing higher scores. The time to target in the last session reduced compared with that in the \u0000rst session, suggesting motor learning and recovery (p < 0.05). The patients were highly engaged and motivated during the sessions because they felt like they were in charge of the virtual image of their upper body. The results suggest that positive reinforcement within the IVR could encourage motor recovery of the affected hand and may facilitate the application of motor learning and neuroplasticity principles during neurological rehabilitation. A stroke occurs when blood \u0000ow to the brain is interrupted or is insu\u0000cient, leading to brain injury or cell death and subsequent impairment of physical and mental functions [1–3]. This may cause sensory, motor, and cognitive impairments as well as impaired self-care ability and participation in social and communal activities [4, 5]. The number of stroke deaths in England decreased by half during the \u0000rst decade of the 21st century [6], and in 2018 it ranked as the fourth leading cause of mortality [7]. Nonetheless, a signi\u0000cant proportion of stroke survivors continue to live with disabilities. Motor impairment is the most common complication after a stroke, and it can negatively affect health and motor skills, particularly when it affects the upper limbs [8, 9]. According to Adamovich et al. [10], stroke patients undergoing treatment for upper limb impairment encounter various challenges. The functional outcome is highly variable; some patients are unable to fully recover functionality and are forced to live with varying degrees of upper limb paresis for the rest of their lives. It has also been reported that the treatment of upper limb hemiparesis is time-sensitive and involves various therapeutic modalities [11, 12]. Thus, these scienti\u0000c studies emphasize the need for appropriate rehabilitation procedures that can provide highly effective therapy and a greater possibility of a higher-level functional recovery. Successful rehabilitation depends on the stroke’s characteristics (such as severity, nature, and location) as well as the patient’s age, general health, and pre-stroke function [13]. Otherwise, the stroke patient whose impaired hand is rendered inactive for an extended period may acquire learned non-use. Learned non-use is the outcome of repeated unsuccessful attempts to use the affected upper limb coupled with the reinforcement of compensatory methods (such as the use of the unaffected upper limb), which leads to deterrence in using the affected arm [14–17]. Therefore, it is necessary to consider the optimal rehabilitation therapy for stroke patients with upper limb disability and limitations. According to the International Classi\u0000cation of Functioning, Disability, and Health, physiotherapists are an essential component of multidisciplinary stroke rehabilitation teams [18, 19], as they assist patients in regaining mobility and independence by addressing impairments in bodily functions, activity limitations, and participation restrictions [20]. To recover movement, coordination, and balance, a physiotherapist provides conventional physical therapy (PT) for upper limb rehabilitation through exercises, training, and physical movement of the limbs [21]. It has been established that repetitive task training is bene\u0000cial in certain aspects of rehabilitation, such as improving upper limb function [22, 23]. Hence, the term “sensory motor training” was established to represent various physical activities designed to improve motor performance, strength, power, endurance, and sensory integrity, such as proprioception. Moreover, the neuroscience and rehabilitation literature are supporting the idea that task-speci\u0000c or task-oriented practice is essential for restoring functionality in stroke-impaired limbs. This implies that repeatedly practicing a di\u0000cult activity can alter brain networks responsible for motor control, leading to long-term improvements in motor learning and Motor coordination can only be regained through a neuroplasticity process [25], which is described as the rewiring of the brain’s synaptic connections to develop appropriate communication with the body’s The most crucial component is performing repeated movements, which provides patients with the ability to perform an activity normally [27]. Constraint-induced movement therapy (CIMT) has been reported to be effective in treating severe paralysis in the body by training the nerve impulses of damaged muscles through constant repetition of movement on the affected side [23, 28, 29]. However, CIMT has major disadvantages, such as exhausting the patient owing to its intensity [30, 31]. Consequently, recent technological solutions have shown promise in terms of improving the function of impaired limbs without exhausting patients. Virtual reality (VR) has emerged as a new treatment approach for stroke rehabilitation, simulating real- life activities to improve self-care skills [32, 33]. In virtual rehabilitation, patients receive visual feedback from simulated environments and objects through a head-mounted device, projection system, or \u0000at screen, while all body senses offer feedback [34]. Virtual tasks and environments affect the users’ senses, and they perceive their presence in the virtual world [35, 36]. By adjusting stimuli to movements in real time and incorporating and modifying feedback, VR may enhance the application of motor learning and neuroplasticity principles during rehabilitation [35] as it provides components (such as goal- oriented tasks and repetition) demonstrated to be vital in rehabilitation [10]. Although there is limited evidence of neuroplasticity during VR training, neuroimaging discoveries are guiding the development of VR to meet the highest treatment standards [37]. As technology becomes a broader component of daily life, it is anticipated that the use of VR in rehabilitation settings will increase [38, 39]. Thus, it is essential to evaluate the effectiveness of VR in order to de\u0000ne its future designs and implementations. The VR environment motivates patients to perform repetitive, motor-intensive tasks that are crucial for rehabilitation [40–44]. Compared with conventional rehabilitation techniques, a concise adaptive game can improve mobility, motor function, and mental wellbeing. Neurological patients generally lack therapy motivation [44]. Possible explanations for this lack of motivation include patients’ belief that therapy only intends to enable adaptation to the disease rather than providing complete healing, or a lack of motivating input from a therapist [44, 45]. Other logistic, \u0000nancial, environmental, and human obstacles may restrict the e\u0000cacy and commitment to long-term rehabilitation regimens [42] found that combining VR with modi\u0000ed CIMT encouraged stroke patients to use the affected hand without constraining the unaffected side (both hands were free to move). Another study investigated the safety and effectiveness of VR and modi\u0000ed CIMT [46]. Relevant to our investigation, [47] proposed a new treatment that combines CIMT and reinforcement- induced movement therapy (RIMT). They demonstrated the e\u0000cacy of RIMT by speeding up the hindered hand in VR using the goal-oriented reaching task. After the RIMT intervention, the Fugl-Meyer (FM) scores of stroke patients improved; however, their study did not report the subjective feeling of being completely engaged in VR. Although they pioneered positive reinforcement utilizing computer-simulated limbs in the display, the RIMT concept should be developed to use immersive VR (IVR). Visual feedback in IVR simply displays the simulated upper limb. Only the simulated hand should be seen during the task. If people watch their real hand move in front of them while viewing the simulated hand on the display, the discrepancy in visual feedback of motor coordination will induce a sense of loss of ownership of the simulated upper limb or, in certain situations, the subjective awareness of the loss of bodily control. Our study by [48] that used IVR on healthy subjects with a weight attached to their dominant hand to simulate the impairment of a stroke patient is also relevant to our investigation. Their system was portable (head-mounted VR), and the objective was to reach a target in VR without forcing the subjects to use their dominant hand, with an option to use either hand. The movement of the virtual image of the upper limb was reinforced by visual feedback to the participants, such that they perceived their motor coordination as if their upper limb was moving to a greater extent than normal. These \u0000ndings suggest that positive reinforcement within IVR can in\u0000uence hand usage decision-making. Thus, herein, we modi\u0000ed the protocol developed by [48] for stroke survivors to accommodate the speci\u0000c requirements of the patients, including extended task completion time and breaks to prevent fatigue, as detailed in the method section. Our study aimed to evaluate a new therapeutic approach for the rehabilitation of the upper limbs of stroke patients to demonstrate the effectiveness of IVR-enhanced PT by measuring the improvement in upper limb motion using the FM score. Additionally, to conduct a larger study in the future, a participant experience questionnaire was administered to evaluate the Eighteen subjects (69.4 ± 13.5 years, eight women) with acute post-stroke hemiparesis (16 ischemic strokes) were recruited in the study at the stroke unit of the Royal Berkshire Hospital in Reading, United Kingdom. The sample size was limited by the number of patients that could be enrolled over the project’s duration. The experiment was approved by the ethics committee Health Research Authority and Health and Care Research Wales (IRAS project ID: 264096) and performed according to relevant guidelines and The participants were screened for study eligibility by the clinical team according to the inclusion and exclusion criteria. The inclusion criteria were (i) age ≥ 18 years; (ii) recent stroke (ischemic/hemorrhagic) within the last 4 weeks; (iii) Montreal Cognitive Assessment score > 18; (iv) ability to sit independently in a chair; (v) upper limb weakness; and (vi) ability to speak and read English. The exclusion criteria were (i) visual \u0000eld defect; (ii) visual or sensory neglect; (iii) strokes affecting both upper limbs; (iv) poor static and dynamic balance in sitting; (v) shoulder subluxation or dislocation; (vi) upper limb weakness due to conditions other than stroke; (vii) presence of emotional and/or cognitive de\u0000cits (such as global aphasia, apraxia, dementia, and depression) that could interfere with the understanding and execution of Participants provided written informed consent after being informed about the aims and procedure of the experiment. They were allocated to either receive IVR and conventional PT (intervention group, 10 patients) or receive conventional PT alone (control group, 8 patients) (Tables 1 and 2). Both groups received conventional PT on the ward, administered in accordance with national guidelines. The patient allocation, conducted through a randomization process, occurred at a 1:1 ratio using pre-prepared sealed opaque envelopes. These envelopes, numbered by the Trust the Research & Development department before recruitment began, contained information identifying the assigned group for each patient. To ensure equitable and unbiased distribution, an online random number generator utilizing atmospheric noise assigned numbers to each envelope [49]. The research team sequentially opened the sealed envelopes (numbered 1–30) to determine group allocation for each participant. Additionally, the assigned number served as the participant identi\u0000cation number throughout the study. This rigorous randomization process aimed to enhance the validity and reliability of the research \u0000ndings. Participants could withdraw consent at any time during the study, yet the collected data were retained and used without additional procedures on or in relation to the participant. Two patients in the intervention group withdrew from the trial owing to di\u0000culty to complete the task, a perception of therapy being ineffective, or a desire to concentrate more on the lower limb. Table 1 Demographic characteristic and stroke subtypes (N = 10) of the intervention group. Stroke type Lesion site Right posterior cerebral circulation Right total anterior cerebral circulation Right partial anterior cerebral circulation Left partial anterior cerebral circulation Right posterior circulation stroke Ischemic with haemorrhagic transformation Table 2 Demographic characteristics and stroke subtypes (N = 8) of the control group. Lesion site Right posterior cerebral circulation Right total anterior cerebral circulation Right partial anterior cerebral circulation Left posterior cerebral circulation infarction Right total anterior cerebral circulation s Right pontine infarct Right partial anterior cerebral circulation infarct Right lacunar infarct We utilized the same method as used for healthy subjects; for more information, please refer to the paper by [48]. An integrated IVR system consists of a VR headset (Oculus Rift) and a small motion capture sensor (Leap Motion) attached to the headset (Fig. 1) Both products are CE marked. This system can monitor the actual upper limb movements of the participants and create a virtual image of the corresponding upper limb in the IVR environment. It also provides a real time motion of the corresponding virtual upper limb. The person using IVR equipment can “look around” the arti\u0000cial world and interact with virtual features or objects. Through iterative visual-motor loops in the brain, the person experiences a feeling of controlling the virtual image of their body in such a way that the virtual world can be perceived as a real one. Stroke survivors go through task-oriented training of the upper limb in the IVR environment. As they experience the ideal motor coordination of their upper limb’s avatar, successful matching of motor intention and resultant motor coordination in the IVR allows brain networks to form new neuronal pathways for spontaneous motion in their daily life. Therefore, IVR-enhanced therapy may offer a powerful rehabilitation approach, allowing PT to be tailored to the speci\u0000c needs of survivors with Participants were asked to sit comfortably on a chair and place their upper extremities on a table in front of them (Fig. 1A). Seven targets were arranged in a semi-circular orientation within the IVR environment (Fig. 2A). As a goal-oriented task, participants were asked to reach for the target immediately by choosing their healthy or impaired upper limb hand (Fig. 2B). To implement reinforcement-induced PT, the velocity of the hand of the impaired upper limb was ampli\u0000ed in the virtual environment in the direction of the target. The target turned blue when reached by the virtual hand and immediately disappeared. Unlike for healthy individuals, we increased the time to 4 seconds after the ball appeared to prevent in-depth consideration regarding choosing, as stroke patients require more time. If this condition was not ful\u0000lled, the target disappeared, and the trial was invalidated. The experiment included three stages: familiarization, intervention, and washout (Fig. 3). At each stage, visual ampli\u0000cation is consistently applied to the affected side (right or left), in contrast to the healthy experiment where the visual ampli\u0000cation depended on the experimental phase, speci\u0000cally for the right side. The visual ampli\u0000cation, de\u0000ned as increasing the velocity of the virtual hand corresponding to the impaired upper limb by 1.4 times compared to the actual hand motion, will be described. It was hypothesized that the participants would start to use the affected hand more often as the velocity was ampli\u0000ed in the IVR environment. The aim of the familiarization stage was to acquaint the participants with the task. In this stage, \u0000ve targets (excluding the far right and far left targets) appeared randomly in a semi-circular array in the virtual environment (see Fig. 2A), each target appeared four times. For example, participants completed 20 reaching trials, equally divided between using the right hand (the \u0000ve targets appearing twice) and the left hand in 10 trials each (the \u0000ve targets appearing twice). This stage was applied only once at the beginning of each session. Subsequently, the primary stage in this experiment was the intervention stage/free choice stage, wherein the participants were free to choose the right or left hand (unaffected or affected limb) to reach the target that randomly appeared in seven different positions. To accommodate the patients in the study, we reduced the number of times they reached for the ball from 70 to 35 (5 times per target), This adjustment was implemented due to our concern about potential participant fatigue. Post-stroke fatigue, which is prevalent throughout the acute and chronic phases following a stroke and can substantially impact rehabilitation outcomes, should also be considered when designing a treatment plan [50]. Due to brain damage and limb weakening, stroke survivors are more likely to experience fatigue than healthy individuals. In this stage, the participants repeated the reaching task at their own pace, with varying repetitions per person in each session. Each task comprised 35 balls and lasted for 3–5 minutes. To avoid fatigue, participants were given 2-minute rest periods between each task. The term \"session\" refers to the time when patients receive IVR training, occurring once per day. The number of sessions is determined by the duration of the patient's hospital stay until discharge or completion of 15 sessions— whichever comes sooner. The \u0000nal stage was the washout, similar to the intervention stage (35 target per task) but gradual reduction in the velocity of ampli\u0000cation in the IVR environment to 1.2 times the actual hand motion. We hypothesized that even when the ampli\u0000cation is reduced in the IVR environment, the participants would continue to utilize the affected upper limb, resulting in increased use of the affected upper limb in daily life. This stage was intended to commence from the 10th session and extend until the 15th session. However, because of early discharge of patients, we could complete this stage with only two patients. The entire session lasted for 20–40 minutes, depending on the patient’s condition. The Fugl Meyer for upper limb (FM) assessment was used to evaluate the functional motor condition as the primary outcome in this study. FM score was selected as the primary outcome measure because FM assessment is a well-designed, feasible, and effective clinical examination technique that has been extensively used in the stroke population [51–54]. This scale is highly recommended as a clinical and research instrument for assessing changes in motor impairment after stroke [55]. The evaluation was conducted by a physiotherapist who participated in the program. The FM assessment is crucial for determining motor recovery and disease severity [56]. It has \u0000ve domains: motor function, sensory function, balance, joint range of motion, and joint pain [57, 58]. The motor function domain is the most widely used and plays a primary role in monitoring motor recovery after stroke. The items in the FM motor function domain are based on patient motion, coordination, and re\u0000ex action in the shoulder, elbow, forearm, wrist, and hand. Each domain contains multiple items, each scored on a 3-point ordinal scale (0 = cannot perform, 1 = performs partially, 2 = performs fully). The total score varies from 0 to 66. The measurements were utilized to assess the e\u0000cacy of IVR feedback in restoring motor coordination affecting the patient’s QoL. Our initial plan was to collect FM scores from participants at the beginning, middle, and end of their participation in the study. However, because of the COVID-19 pandemic, the length of hospitalization varied, and patients could be discharged without notice. Hence, depending on the length of stay, we evaluated the patients in the \u0000rst, \u0000fth, and tenth sessions. The control group underwent evaluations during corresponding sessions, ensuring consistent assessment across both groups with the same timescales as the intervention group. Note that the ethical approval allowed a certain period for our clinical study, not allowing us to extend our study to recruit more patients. We used a questionnaire administered at the end of the last session to evaluate patient experience, provide information regarding the sense of agency (subjective awareness of initiating and controlling one’s own activities) [59], and obtain comments about the training sessions in the IVR environment. The questionnaire contained four short items that required participants to respond with a simple “yes,” “no,” • Did you feel that you were controlling the virtual hand? • Did you feel a sense of achievement during the virtual reality therapy? • Did you feel dizzy when looking around in the virtual reality? • Did you feel any fatigue in any of your muscles during the therapy? • If you have any comments or feedback on your experience, please include them below. B. Barthel Index (Clinical Outcome) The Barthel index (BI; modi\u0000ed 10-item version) is used to measure the amount of independence and mobility of patients in their activities of daily living (ADL), such as feeding, bathing, grooming, dressing, bowel control, bladder control, toileting, chair transfer, ambulation, and stair climbing [60]. The evaluation was conducted by a physiotherapist who was not involved in the training. This tool indicates the need for assistance in care and is widely used as a measure of functional disability [61]. Depending on the item, functional categories may be rated 0–1, 0–2, or 0–3 points. The range of possible total scores is 0–20. Two measurements were taken at both the baseline and discharge stages. To evaluate the use of unaffected and affected hands in the VR environment during the training sessions based on enhanced visual feedback, we calculated the border angle (BA) of the \u0000rst two repetitions of the task (total of 70 times) in each patient across the sessions. A psychometric function was \u0000tted to the plots of the probability of affected hand usage as a function of the target angles; (see Fig. 2B in [48]). The angle at which the psychometric function corresponds to a 50% probability was de\u0000ned as the BA. II. Time to Target To determine the time to target for each subject, the reaction time of the affected hand for each target was recorded, encompassing the duration from the ball's onset to the participant reaching it. Each trial commenced with participants placing their hands at the starting point (home position), triggering the appearance of the ball upon accurate hand placement. Following this, participants reached the target, returned their hands to the starting position, and repeated the process for successive targets in different locations (35 balls). We considered it important to compare subjects’ reaction times during the therapy across the sessions to evaluate the improvements; we hypothesized that faster reaction times indicated effective motor learning resulting in motor recovery. D. Observation of Patient’s Strategy The physiotherapist who participated in the training sessions reported all vital observations, which were necessary to comprehend the patient’s treatment strategies. Analysis and Statistics To establish the e\u0000cacy of IVR feedback in the recovery of motor coordination, the statistical difference in FM scores between the \u0000rst and \u0000fth sessions for each patient in both groups was analyzed. For further analysis, we conducted paired compression test for BI, BA and time to target. The Shapiro-Wilk test was used to check the normality of the distribution, and the Wilcoxon signed-rank test or the paired Student’s t-test was applied to evaluate. The level of signi\u0000cance was set at p < 0.05. In addition, repeated measures analysis of variance (ANOVA) mixed model was employed to determine the in\u0000uence of two factors, namely the target locations and the sessions, on the reaction time. The answers derived from the questionnaire were not compared statistically between the groups. However, subjective experience is crucial for determining whether a larger community would be interested in IVR physical treatment. In this study with stroke patients, we noted that they adopted certain intriguing methods while undergoing therapy. The observations were made from the perspective of a physiotherapist. These \u0000ndings were considered important in the study because they revealed how the patients coped or utilized other motor movements to complete the task. Hence, the patients were separated into distinct Two signi\u0000cant observations were made in this study. Firstly, each patient underwent a varying number of sessions, as outlined in Table 3. This number was correlated with the duration of hospitalization, with some patients receiving \u0000ve sessions and others having more or fewer; there was no standard quantity for sessions. Secondly, each patient was able to repeat the number of tasks per session according to their condition and endurance level. Some patients repeated the task twice, while others repeated it more times per session. Consequently, patients were categorized into three main groups (Table 4). Two sessions Four sessions Five sessions Seven sessions 10–14 sessions ET009 (withdraw) Table 4 The number of task repetition per session. The \u0000rst row under each patient's ID indicates the number of sessions, whereas the second row indicates the number of times they could repeat the task in The FM score measured predominantly in the \u0000rst and \u0000fth sessions (seven and eight patients in the intervention and control groups, respectively) as shown in Table 5A and B. One patient’s (ET017) data was eliminated from the intervention group because he underwent only four sessions, and we could not repeat the evaluation due to his discharge from the stroke unit. Additionally, two patients (ET013 and ET019) who stayed longer in the hospital were evaluated three times. Nevertheless, data from only the \u0000rst and \u0000fth sessions were analyzed (Table 5A). Conversely, two patients in the control group (ET010 and ET015) had a full score at the beginning of the study. However, we repeated the assessment in the \u0000fth session to ensure that there was no deterioration in their motor function, as neurological deterioration is common in some stroke patients [62] and we observed that their scores remained unchanged (Table 5B). As shown in (Fig. 4A and B), all seven patients in the intervention group showed improvement in the FM score following IVR-enhanced visual feedback, while only two of eight patients in the control group showed improvement in the FM score. Moreover, there was no change in the FM score between the \u0000rst and \u0000fth sessions for six patients. Table 5 Fugel Meyer score for both groups in \u0000rst and last session. (A) FM scores for the intervention (A) and control (B) groups. The differences in FM scores between the \u0000rst and \u0000fth sessions for each patient are displayed in both tables. The data in red indicate an improvement. (The total score of FM is = 66). Intervention group Control group FM_5th_ session Before conducting paired comparison analysis, we used the Shapiro–Wilk test to ensure that the data met normal distribution requirements. For the intervention group, the p-values obtained from the normality test were 0.23 and 0.02 for FM assessments in the \u0000rst and \u0000fth sessions, respectively, whereas for the control group, they were 0.03 and 0.01, respectively. Because the data obtained from FM assessments in both groups were not normally distributed, we used the Wilcoxon signed-rank test for the paired sample comparison of the data. As shown in the box plot in Fig. 5, the FM scores differed signi\u0000cantly between the \u0000rst and \u0000fth sessions for the intervention group (P = 0.08) but not for the control group (P = 0.16), indicating that IVR enhanced the motor function of the affected upper extremity. Only seven patients responded to the questionnaire. Their responses indicate that they were engaged in the therapy, motivated, and felt a sense of achievement. The crucial part was that this therapy induced a sense of agency over the virtual hand because they felt as if they were controlling the avatar. Their answers were “somewhat” and “no” when they were asked if they felt dizzy during the therapy. They all reported that they experienced no muscle fatigue during the task. Finally, they provided comments regarding the therapy, such as “Enjoyed the therapy,” “Therapy was fun,” and “It improved my hand coordination and control.” However, one of them stated that the “headset was quite heavy.” B. Barthel Index (BI) In terms of BI, not all individuals were evaluated twice; only nine participants (four in the intervention group and \u0000ve in control group) had their data recorded twice (see the supplementary \u0000les A1 and A2). We used the Shapiro–Wilk test to compare the normality of the distributions of the two groups’ data. For the intervention group, the p-values obtained from the normality test were 0.07 and 0.02 for the \u0000rst and last sessions, respectively, whereas p-values in the control group were 0.19 and 0.80, respectively. As we had a small data size and some of them were not normally distributed, we considered that our data were not normally distributed. Therefore, the Wilcoxon signed-rank test was used. We found that BI scores did not differ signi\u0000cantly between the \u0000rst and last sessions in the intervention group (p = 0.07), whereas they differed signi\u0000cantly in the control group (p = 0.04). Three of nine patients were excluded from further analysis as the BA could not be calculated because they chose a biased strategy, such as using their affected hand for all the targets (ET001, ET009, and ET017). We only calculated the BA for each session’s two task repetitions (total of 70 balls). Additionally, we only analyzed the data of patients who underwent \u0000ve sessions and calculated their BA. Patients who underwent less than \u0000ve sessions were therefore excluded from the analysis. Nevertheless, the data from only the \u0000rst \u0000ve sessions were analyzed for individuals who underwent more than \u0000ve sessions (ET013, ET018, and ET019). We excluded the patient whose right side was affected (ET017) from the analysis because the data of the patient could not be combined with that of the group with the left side affected as each group had a different strategy for achieving targets. Before performing the paired comparison analysis, we used the Shapiro–Wilk test to ensure that the data met normal distribution requirements. The p-values obtained from the test for normality were 0.20, 0.15, 0.83, 0.52, and 0.59 for sessions 1, 2, 3, 4, and 5, respectively. Owing to the normal distribution of the BA data across all sessions, we used the paired Student's t-test to assess the differences in BA between sessions and the results indicated that there was no statistically signi\u0000cant difference across the session, as indicated by a p-value greater than 0.05. Unlike the healthy participants in Sakabe et al. study [48] the stroke patients used a different strategy to reach the target. For example, they developed their own exercise plan, i.e., they used the affected hand only in reaching most of the targets, and other time they train the non-affected side. One participant was excluded from further analysis (ET008), for the reason that his reaction time was affected because of spatial neglect, for example, lack of attention towards the targets near the affected side and he needed to be reminded to refocus his attention. Furthermore, he employed a distinct approach when attempting to reach the target. We found that the patients with left-side impairment were always able to reach the targets closest to the affected side (targets 7, 6, and 5) but occasionally reached the other targets, whereas patients with right- side impairment were always able to reach targets 1, 2, and 3. Hence, a repeated measures analysis of variance (ANOVA) mixed model was employed to determine the in\u0000uence of two factors, namely the target locations and the sessions, on the reaction time. The analysis revealed that there is no statistically signi\u0000cant difference in the Targets (p = 0.67). However, a signi\u0000cant difference was seen between sessions (\u0000rst and last) (P < 0.01). Therefore, we combined the average value of the reaction time of targets 5, 6, and 7 for the left sided patients and targets 1, 2 and 3 for the right sided patients. We then proceeded to compare the results obtained from the \u0000rst and last sessions. Before the paired sample comparison test, we used the Shapiro–Wilk test to determine whether the data met the normal distribution criteria. The resulting p-value was P < 0.05, indicating that the data were not normally distributed. We then performed the Wilcoxon signed rank test on eight patients in order to reveal the improvement of motor recovery between the \u0000rst and last session in terms of the reaction time of the affected hand. Based on the box plot depicted in (Fig. 6), there is a statistically signi\u0000cant difference found between the \u0000rst session and the last session (P = 0.03), suggesting the motor recovery of the affected limb in terms of kinematics. In contrast, we found that there was no motor learning on the unaffected upper limb (P = 0.20). We subgrouped the patients based on the similarity of their strategies and highlighted the following three signi\u0000cant characteristics from the therapist’s observation: I. Patients Categorized Based on the Frequency Hand Usage (Affected or Unaffected hand) Based on the recorded data, we identi\u0000ed two categories of patients; 1. The Frequency of Using the Affected Side This category comprised two types of patients who predominantly used their affected hand to reach the majority of targets, potentially indicating self-motivation and competitiveness. The \u0000rst type achieving ≥ 80% of the affected hand usage (28 targets out of 35), The second type patients used 71–77% (25 to 27 targets out of 35). Notably, this method was not used for every session; for example, patient ET001 used both methods. 2. The Frequency of Using the Unaffected Side This category included patients who did not use the affected hand to reach targets because they wanted to train the opposite side; they used the affected 25% (0 to 8 times out of 35). II. Patients Categorized Based on Strategy for Reaching Targets Each patient employed a unique strategy for achieving the targets. For instance, some patients utilized trunk movement to assist in reaching the target, while others switched to their unaffected hand if they were unable to reach the target, returned to their starting position, and repeated the task. Additionally, certain patients exhibited circumduction movements rather than moving in a direct line. Moreover, some patients tapped the table upon successfully reaching the target. III. Patient Categorised Based on Factors Affecting Performance Some patients exhibited characteristics that could affect their performance. For instance, neglecting the affected side resulted in overlooking targets close to that side, while leaning towards the affected side led to neglecting targets on the opposite side. Others had hand deformities, although this did not impact the e\u0000cacy of the system. Additionally, negative mood and lack of sleep were observed to have The primary goal of this pilot study was to investigate the feasibility of IVR technology in the upper limb rehabilitation of stroke patients, as opposed to traditional CIMT that combines positive reinforcement in PT. Our study by [48] con\u0000rmed that positive reinforcement in IVR in\u0000uences hand usage decisions in healthy participants. In this study, we modi\u0000ed the IVR system in order to meet the speci\u0000c requirements of the patients by reducing the target number and extending the time limit to reach the targets. The e\u0000cacy of the IVR-enhanced PT was validated using the Fugl-Meyer (FM) assessment to test the improvement of the upper limb motion with respect to the control group. Based on our \u0000ndings, it is evident that the intervention group, which received IVR combined with conventional physical therapy (PT), exhibited improvement in the FM score in all patients compared to the control group (Table 5 and Figs. 4 and 5) which received only PT. This observation is promising, indicating a positive trajectory that may offer insights into the e\u0000cacy of the IVR intervention. The positive outcomes observed in the intervention group suggest the effectiveness of IVR in enhancing motor function. However, the question persists: Can this improvement be attributed solely to the system, the physiotherapy sessions, or their combined synergistic impact, serving as compelling evidence of e\u0000cacy? VR is frequently compared to conventional therapy (CT) administered by physio- and occupational therapists in studies on stroke rehabilitation. The updated Cochrane review by Laver et al. [8] concluded that the e\u0000cacy of VR-based therapy was not superior to that of CT in enhancing upper limb function. Speci\u0000cally, they reported that VR “may be bene\u0000cial in improving upper limb function and ADL function when used as an adjunct to conventional care (to increase overall therapy time)”. It is essential to note that their study primarily focused on commercial video gaming consoles, a prevalent choice in VR-based rehabilitation due to their ease of use, enjoyment, and cost-effectiveness [63, 64]. Nevertheless, present- day researchers are increasingly avoiding these approaches as these systems are primarily designed for healthy individuals, thereby presenting signi\u0000cant challenges for patients [63]. Consequently, our study implemented an IVR system that is tailored to the speci\u0000c requirements, bene\u0000ts, and conditions of the patients. The inherent simplicity of this approach may account for the observed improvement in their FM This simplicity aligns seamlessly with the overarching goals of stroke rehabilitation, particularly when considering early initiation to minimize the disease's impact. Given that the participants in our study were acute cases, we promptly initiated IVR in combination with PT once they were medically stable. The combination of therapies in our study, emphasizing both task-oriented exercises and repetitive movements, holds the potential to facilitate patient recovery through intensive treatment. In IVR training, it involved task-oriented exercises, particularly actions like reaching for ball—a movement integral to activities of daily living (ADL) that frequently necessitates the use of the arm [65, 66]. Additionally, the task contained repetitive movements [67]. This approach has the potential to enhance neuroplasticity [68, 69] by facilitating the restoration of movement on the impaired side through the activation of a new motor projection region and the resting of synapses [70, 71]. As mentioned in previous studies [8, 70, 72, 73], the current focus in clinical settings is on the combined use of VR and PT for rehabilitation. These associated technologies are becoming more accessible and prevalent [74]. Nevertheless, within the domain of VR, the direct effects of VR therapy on neuroplasticity are still under investigation, and current evidence is limited [8]. However, Wang et al. [70] employed functional magnetic resonance imaging to investigate neuronal remodelling in subacute stroke patients before and after training with a Leap Motion-based VR system. They compared it to CT alone. Patients were instructed to position their affected thumb on their palm. They found that sensorimotor cortex activation moved from the ipsilateral to the contralateral region and increased in the contralateral cortex in both groups. On the Wolf motor function test, which assesses upper limb motor function, the experimental VR group had a signi\u0000cantly greater improvement and better performance than the control group. These results demonstrate that repeated exercises with the affected arm combined with task-oriented practice in a virtual environment can enhance motor recovery of the upper limb more than CT alone. Neuroimaging research can help increase the training-dependent effects of VR and contribute to the development of VR therapies. These \u0000ndings add to the current evidence that VR therapy should not be ignored in upper limb rehabilitation, as it may have apparent advantages for patients’ recovery. More conclusive \u0000ndings to date suggest that VR can improve PT and increase the potential for rehabilitation [51, 52, 75, 76, 77]. Rather than relying solely on a single method, incorporating VR therapy into existing rehabilitation programs appears effective for enhancing stroke rehabilitation outcomes.",
         "https://www.researchsquare.com/article/rs-4132920/latest.pdf",
         "extracted",
         "None",
         "Immersive Virtual Reality in Post-Stroke Rehabilitation: A Systematic Review;Effectiveness, safety and patients’ perceptions of an immersive virtual reality–based exercise system for poststroke upper limb motor rehabilitation: A proof-of-concept and feasibility randomized controlled trial;New technologies promoting active upper limb rehabilitation after stroke: an overview and network meta-analysis;Effectiveness of Using Virtual Reality–Supported Exercise Therapy for Upper Extremity Motor Rehabilitation in Patients With Stroke: Systematic Review and Meta-analysis of Randomized Controlled Trials;Enhanced Visual Feedback Using Immersive VR Affects Decision Making Regarding Hand Use With a Simulated Impaired Limb;A novel fully immersive virtual reality environment for upper extremity rehabilitation in patients with stroke;Neuroplasticity;Virtual reality games for rehabilitation of upper extremities in stroke patients.;On Shooting Stars;Post-stroke depression: A 2020 updated review.;Virtual reality therapy for upper limb rehabilitation in patients with stroke: a meta-analysis of randomized clinical trials;Principles of Neurorehabilitation After Stroke Based on Motor Learning and Brain Plasticity Mechanisms;Exergaming for stroke rehabilitation: Lessons learned for future implementation strategies;Elements virtual rehabilitation improves motor, cognitive, and functional outcomes in adult stroke: evidence from a randomized controlled pilot study;Comparison of Kinect2Scratch game-based training and therapist-based training for the improvement of upper extremity functions of patients with chronic stroke: a randomized controlled single-blinded trial.;Evaluating the effect and mechanism of upper limb motor function recovery induced by immersive virtual-reality-based rehabilitation for subacute stroke subjects: study protocol for a randomized controlled trial;Virtual Reality in Upper Extremity Rehabilitation of Stroke Patients: A Randomized Controlled Trial.;Project Star Catcher;Rehabilitation via HOMe Based gaming exercise for the Upper-limb post Stroke (RHOMBUS): protocol of an intervention feasibility trial;Virtual Reality Clinical Research: Promises and Challenges;Combining the benefits of tele-rehabilitation and virtual reality-based balance training: a systematic review on feasibility and effectiveness;Towards an Immersive Virtual Reality Game for Smarter Post-Stroke Rehabilitation;Effectiveness of Wii-based rehabilitation in stroke: A randomized controlled study.;Virtual Reality for Upper Limb Rehabilitation in Subacute and Chronic Stroke: A Randomized Controlled Trial.;Game-Based Virtual Reality Canoe Paddling Training to Improve Postural Balance and Upper Extremity Function: A Preliminary Randomized Controlled Study of 30 Patients with Subacute Stroke;What do randomized controlled trials say about virtual rehabilitation in stroke? A systematic literature review and meta-analysis of upper-limb and cognitive outcomes;In-Home Delivery of Constraint-Induced Movement Therapy via Virtual Reality Gaming.;Effects of Kinect-based virtual reality game training on upper extremity motor recovery in chronic stroke;Increasing upper limb training intensity in chronic stroke using embodied virtual reality: a pilot study;Leap Motion-based virtual reality training for improving motor functional recovery of upper limbs and neural reorganization in subacute stroke patients;Stroke recovery and rehabilitation in 2016: a year in review of basic science and clinical science;Effects of virtual reality for stroke individuals based on the International Classification of Functioning and Health: a systematic review;Does the use of Nintendo Wii SportsTM improve arm function? Trial of WiiTM in Stroke: a randomized controlled trial and economics analysis;What Is the Sense of Agency and Why Does it Matter?;Counteracting learned non-use in chronic stroke patients with reinforcement-induced movement therapy;Coaching or gaming? Implications of strategy choice for home based stroke rehabilitation;Post-stroke fatigue: a review on prevalence, correlates, measurement, and management;Constraint-induced movement therapy after stroke;CI Therapy is Beneficial to Patients with Chronic Low-Functioning Hemiparesis after Stroke;Virtual Reality Therapy for Adults Post-Stroke: A Systematic Review and Meta-Analysis Exploring Virtual Environments and Commercial Games in Therapy;What Is the Evidence for Physical Therapy Poststroke? A Systematic Review and Meta-Analysis;Plasticity in the Injured Brain;Connectome: How the Brain’s Wiring Makes Us Who We Are;Mechanism of Kinect-based virtual reality training for motor functional recovery of upper limbs after subacute stroke;Virtual reality for the rehabilitation of the upper limb motor function after stroke: a prospective controlled trial;Depression, activities of daily living and quality of life in patients with stroke;Arm Motor Recovery Using a Virtual Reality Intervention in Chronic Stroke;Maladaptive Plasticity for Motor Recovery after Stroke: Mechanisms and Approaches;Neurorehabilitation of stroke;Virtual reality in neuroscience research and therapy;Virtual Reality for Stroke Rehabilitation;The Stroke Association;Stroke rehabilitation;Potential for new technologies in clinical practice.;Creating an Interface Between the International Classification of Functioning, Disability and Health and Physical Therapist Practice;Apathy following Stroke;The neural basis of constraint-induced movement therapy;Exercises for paretic upper limb after stroke: a combined virtual-reality and telemedicine approach.;Observation of amounts of movement practice provided during stroke rehabilitation.;Repetitive Task Training for Improving Functional Ability After Stroke;Sense of Agency Primes Manual Motor Responses;Training and exercise to drive poststroke recovery;Principles of experience-dependent neural plasticity: implications for rehabilitation after brain damage.;Poststroke shoulder pain: its relationship to motor impairment, activity limitation, and quality of life.;The learned nonuse phenomenon: implications for rehabilitation.;Textbook of Neural Repair and Rehabilitation: Virtual reality in neurorehabilitation;Ambulatory monitoring of arm movement using accelerometry: an objective measure of upper-extremity rehabilitation in persons with chronic stroke.;A Virtual RealityBased Exercise System for Hand Rehabilitation Post-Stroke;Motor Impairment and Recovery in the Upper Limb After Stroke: Behavioral and Neuroanatomical Correlates;Reaching in reality and virtual reality: a comparison of movement kinematics in healthy subjects and in adults with hemiparesis;A Theory of Fun for Game Design;Mixed reality environments in stroke rehabilitation: Development as rehabilitation tools;Rules of play: game design fundamentals;The Fugl-Meyer Assessment of Motor Recovery after Stroke: A Critical Review of Its Measurement Properties;What are the components of effective stroke unit care?;Stroke patients' and therapists' opinions of constraint-induced movement therapy;Research on Presence in Virtual Reality: A Survey;Neurological deterioration in acute ischemic stroke: potential predictors and associated factors in the European cooperative acute stroke study (ECASS) I.;Impairment and disability: their relation during stroke rehabilitation.;From apoplexy to stroke.;Assessment and psychologic factors in stroke rehabilitation.;Motor learning after recovery from hemiparesis;Reliability of the Fugl-Meyer assessment for testing motor performance in patients following stroke.;RECOVERY TIME OF INDEPENDENT FUNCTION POST-STROKE;Neuropsychological impairments associated with lesions caused by tumor or stroke.;A Motor Learning Model for Stroke Rehabilitation;Reliability of the Fugl-Meyer assessment of sensorimotor recovery following cerebrovascular accident.;Long‐lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path;The information capacity of the human motor system in controlling the amplitude of movement.;Virtual Activities of Daily Living for Recovery of Upper Extremity Motor Function;Neurobiology of Sleep and Circadian Rhythms The role of sleep in recovery following ischemic stroke: A review of human and animal data;Motor learning and motor recovery in poststroke individuals: a review of the evidence;Virtual reality training for upper extremity in subacute stroke (VIRTUES): a multicenter RCT;Stroke Rehabilitation A Function Based Approach;The brain's way of healing : stories of remarkable recoveries and discoveries;Febr 25. Stroke deaths in England halved in the �rst decade of the 21st century;Using the international classi�cation of functioning, disability and health in physiotherapy in multidisciplinary vocational rehabilitation: a case study of low back pain;Contribution of the shaping and restraint components of Constraint-Induced Movement therapy to treatment outcome.;Random.org.;Contemporary management of motor control problems;Improving the sensitivity of the Barthel Index for stroke rehabilitation.;The Barthel ADL Index: a reliability study.;Cerebrovascular disease in the community: results of a WHO collaborative study.;ET019) who stayed longer in the hospital were evaluated three times. Nevertheless, data from only the �rst and �fth sessions were analyzed (Table 5A)",
         "Immersive virtual reality enhanced reinforcement induced physical therapy (EVEREST)"
        ],
        [
         "21",
         "008dbf8a0db8fa34cd847d7937b8ddbd2c0b37df",
         "Motivational theories of imitation state that we imitate because this led to positive social consequences in the past. Because movement imitation typically only leads to these consequences when perceived by the imitated person, it should increase when the interaction partner sees the imitator. Current evidence for this hypothesis is mixed, potentially due to the low ecological validity in previous studies. We conducted two experiments (NExperiment 1 = 94, NExperiment 2 = 110) in which we resolved this limitation by placing participants in a virtual environment with a seeing and a blindfolded virtual agent, where they reacted to auditory cues with a head movement to the left or right, while the agent(s) also made a left or right head movement. We tested the effect of model eyesight (Experiments 1 and 2) and social reward on imitation (Experiment 2). Data were collected in 2023 and 2024. As expected, participants tended to imitate the agents. However, we found only limited evidence for the effect of model eyesight on automatic imitation in Experiment 1 and no evidence for the effect of model eyesight or social reward in Experiment 2. These findings challenge claims made by motivational theories. (PsycInfo Database Record (c) 2025 APA, all rights reserved).",
         "Maura Nevejans,J. Wiersema,J. de Houwer,Emiel Cracco",
         "\n**BLOCK**fs== 12.0**p== 0.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nThe impact of model eyesight and social reward on automatic imitation in virtual reality\n**BLOCK**fs== 12.0**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nMaura Nevejans1, Jan R. Wiersema1, Jan De Houwer1, Emiel Cracco1\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n1Department of Experimental Clinical and Health Psychology, Ghent University, Ghent,\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\nBelgium\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\nWord count: 11516\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\nAuthor Note\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.4**l== 0.2**r== 0.1**\nThis study was funded by two Research Foundation – Flanders grants awarded to MN\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n(11E5223N) and EC (12U0322N). JDH is supported by the Ghent University Methusalem\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\naddressed to Maura Nevejans, Department of Experimental Clinical and Health Psychology,\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nmaura.nevejans@ugent.be. Ethical approval was granted by the ethical committee of the\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFaculty of Psychology and Educational Sciences with reference number 2023-004. This study\n**BLOCK**fs== 12.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nauthors would like to thank Nelle Baetens, Lynn Buyens, Emilia Deslee, Maxence Soulliaert,\n**BLOCK**fs== 12.0**p== 1.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nMotivational theories of imitation state that we imitate because this led to positive\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nsocial consequences in the past. Because movement imitation typically only leads to these\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nconsequences when perceived by the imitated person, it should increase when the interaction\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\npartner sees the imitator. Current evidence for this hypothesis is mixed, potentially due to the\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nlow ecological validity in previous studies. We conducted two experiments (Nexp1 = 94, Nexp2 =\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n110) in which we resolved this limitation by placing participants in a virtual environment with\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\na seeing and a blindfolded virtual agent, where they reacted to auditory cues with a head\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nmovement to the left or right, while the agent(s) also made a left or right head movement. We\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\ntested the effect of model eyesight (Experiments 1 and 2) and social reward on imitation\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n(Experiment 2). Data were collected in 2023 and 2024. As expected, participants tended to\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nimitate the agents. However, we found only limited evidence for the effect of model eyesight\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\non automatic imitation in Experiment 1 and no evidence for the effect of model eyesight or\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nsocial reward in Experiment 2. These findings challenge claims made by motivational\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nKeywords: Automatic imitation, social reward, model eyesight, motivational theories,\n**BLOCK**fs== 12.0**p== 2.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nMotivational theories argue that humans imitate more in situations where imitation is\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nmore likely to have positive social consequences. Based on this, it has been hypothesized that\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nmovement imitation should be stronger when the model can see the imitator because only\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nthen imitation can lead to a positive reaction. However, evidence for this effect has been\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nmixed, potentially due to the low ecological validity of previous tasks. In two experiments, we\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nuse virtual-reality tasks to address this issue and thereby maximize the putative effect of\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nmodel eyesight. In Experiment 2, we also tested the effect of the model’s emotional reaction\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nto imitation. We found only limited evidence for the effect of the other person’s sight in\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nExperiment 1, whereas no such effect was found in Experiment 2. Furthermore, imitation was\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nnot influenced by whether the other person (dis)liked being imitated. These findings raise\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nHumans have an automatic tendency to copy the behavior of others, including their\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nmannerisms (Chartrand & Bargh, 1999; Tschacher et al., 2014), gestures (Cracco, Genschow,\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\net al., 2018), facial expressions (Dimberg, 1982; Dimberg et al., 2000), and eye gaze (Cracco\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\net al., 2022; Driver et al., 1999; Milgram et al., 1969). According to the Associative Sequence\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nLearning (ASL) model, these imitative tendencies emerge from a link between perceptual and\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nmotor representations of actions in the brain, formed through repeated sensorimotor\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nexperiences over the course of development. As a result, the perceptual representation of an\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\naction automatically activates its corresponding motor representation, leading to the tendency\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nThese imitative tendencies are, in turn, thought to support successful social interaction\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nby fostering affiliation between the imitator (i.e., the person who imitates) and the imitated\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nperson (Hess & Fischer, 2013, 2022; Lakin et al., 2003). For instance, imitation has been\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nfound to increase empathy (De Coster et al., 2013; Stel & Vonk, 2009) and trust (Maddux et\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nal., 2008; Over et al., 2013; Verberne et al., 2013) toward the imitator, as well as liking\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nbetween the interaction partners (Chartrand & Bargh, 1999; Salazar Kämpf et al., 2018; for a\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nreview, see Chartrand & Lakin, 2013). Based on these findings, motivational theories argue\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nthat imitation can be seen as a strategy to obtain social reward, such as affiliation with others\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n(Stel et al., 2016; Wang & Hamilton, 2012). In line with this idea, research has shown that\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nimitation increases when individuals are more motivated to affiliate with other people, for\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nexample, after being socially excluded (Lakin et al., 2008) or after being primed with\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nHowever, imitation will not always lead to social reward. For example, imitating the\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nmovements of someone who cannot see you is unlikely to cause them to like you more\n**BLOCK**fs== 12.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.2**\nbecause they do not see your imitative behavior. Motivational theories incorporate these\n**BLOCK**fs== 12.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\ncontextual constraints by arguing that individuals imitate more if imitation can be expected to\n**BLOCK**fs== 12.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nproduce social reward in that particular context (Stel et al., 2016). This implies that imitation\n**BLOCK**fs== 12.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\ncan be seen as a form of operant behavior, with social reward as the reinforcer and contextual\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\ncues like whether the other person sees the imitator as discriminative stimuli determining if\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nimitation is likely to lead to such reward (Wang & Hamilton, 2012). Previous research\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\ntypically investigated this prediction by manipulating the gaze direction of a model. These\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nstudies found that a direct gaze from a model (vs. an averted gaze) not only leads to increased\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nmotor activation in the brain during observation of hand movements (Prinsen et al., 2017,\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n2018; Prinsen & Alaerts, 2019) but also more imitation of the model’s hand movements\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\n(Wang et al., 2011; Wang & Hamilton, 2014). However, recent research, including a well-\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\npowered study by Carr et al. (2021), could not replicate this effect on imitation (Carr et al.,\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n2021; Farmer et al., 2021). Hence, the evidence for the effect of gaze direction on imitative\n**BLOCK**fs== 12.0**p== 4.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nThere are two limitations in previous research that could have caused this\n**BLOCK**fs== 12.0**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\ninconsistency in the literature. The first limitation is the low ecological validity of the\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nimitation tasks typically used to study the influence of social factors on imitation. Most\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nresearch on this topic uses the imitation-inhibition paradigm to measure automatic imitation\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n(Carr et al., 2021; Farmer et al., 2021; Wang et al., 2011; Wang & Hamilton, 2014). In this\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\ntask, participants respond to symbolic cues with certain hand movements, while a hand in the\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nbackground performs a congruent movement (identical to the correct response) or an\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nincongruent movement (different from the correct response) (Brass et al., 2000; Cracco,\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nBardi, et al., 2018). Participants tend to respond more slowly and with lower accuracy when\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nthe hand performs an incongruent compared to a congruent movement (Brass et al., 2000).\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nAlthough this congruency effect has been replicated in various studies (Cracco, Bardi, et al.,\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n2018) and proven to be a reliable (Genschow et al., 2017) and valid (Cracco & Brass, 2019)\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nindex of covert imitative tendencies, it is very different from how imitation typically occurs in\n**BLOCK**fs== 12.0**p== 5.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nreal life. Whereas the imitation-inhibition task measures covert imitation of meaningless hand\n**BLOCK**fs== 12.0**p== 5.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nmovements on a computer screen (Brass et al., 2000; Cracco, Bardi, et al., 2018), everyday\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nsituations typically involve overt imitation of meaningful social behavior. Therefore, this task\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nmight be suboptimal to test the predictions by motivational theories, which focus on these\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nreal-life imitative tendencies (Stel et al., 2016; Wang & de Hamilton, 2012). Despite attempts\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nto make the task more social, such as presenting a picture of a person together with the hand\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n(e.g., Forbes et al., 2017; Wang et al., 2011), the imitation-inhibition imitation task remains\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nrather artificial. A possible solution to this problem is to use real-life interactions to study\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nimitation (e.g., Chartrand & Bargh, 1999). However, whereas these paradigms have higher\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\necological validity, they have lower experimental control and reliability (Genschow et al.,\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nBesides the limited ecological validity, a second limitation in previous work is the\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nabsence of direct social comparison. In daily life, we often observe multiple individuals acting\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nsimultaneously, whereas only a single hand is typically shown in each trial during imitation\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\ntasks. This distinction is important because, according to social judgment theories, humans\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\ntypically evaluate someone by comparing them to a salient reference within a specific context\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n(Mussweiler, 2003). Hence, it is possible that certain characteristics of a model influence\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nimitation only when this model is compared to another model that serves as a reference. By\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\npresenting only one model per trial and comparing the effect of whether this model looks at\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nthe participant across trials, the social comparison between both models has been merely\n**BLOCK**fs== 12.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nimplicit, potentially attenuating the effect of the model’s gaze direction on imitative\n**BLOCK**fs== 12.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\ntendencies. In contrast, when participants observe two models simultaneously, the fact that\n**BLOCK**fs== 12.0**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nonly one of both models looks at them becomes an important distinguishing factor between\n**BLOCK**fs== 12.0**p== 6.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nTo resolve both limitations in previous work, the current study builds on a recent study\n**BLOCK**fs== 12.0**p== 6.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nby Cracco et al. (2022) to investigate the effect of whether the other person sees the imitator\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\non imitation. In their study, Cracco et al. (2022) bridged the gap between the artificial\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nimitation-inhibition task and more naturalistic paradigms by using virtual reality (VR). More\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nprecisely, they created an immersive VR imitation task in which they measured imitation of\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nsocially relevant behavior, namely gaze following. Participants were placed in a virtual city\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nwith ten life-sized virtual agents. Once in a while, a sound was played, which cued\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nparticipants to look up to the left or right target window, in which a fire was burning. At the\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nsame time, a variable number of virtual agents also looked up to the left or right target\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nlocation. Imitation was assessed by measuring the influence of the virtual agents’ movements\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\non the participant’s behavior. Automatic imitation was measured via the congruency effect in\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nforced-choice trials, identical to how it is typically measured in an imitation-inhibition task.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nHowever, because in daily life, people can typically choose their responses, and thus also\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nchoose (not) to imitate, Cracco et al. (2022) also added another measure of imitation via so-\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\ncalled free-choice trials. In these trials, there was no correct response and participants could\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nchoose (not) to follow the virtual agents’ movements, thereby representing real-life imitative\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nCracco et al. (2022) effectively measured participants’ imitative tendencies in both\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nforced- and free-choice conditions. Moreover, they replicated findings from previous research\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nusing the typical imitation-inhibition task, by showing that automatic imitation increased with\n**BLOCK**fs== 12.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nthe number of observed movements (Cracco et al., 2015; Cracco & Brass, 2018). Altogether,\n**BLOCK**fs== 12.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nby using VR, the researchers could increase the ecological validity of the typical imitation-\n**BLOCK**fs== 12.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\ninhibition task while also retaining experimental control (Parsons, 2015), thereby resolving\n**BLOCK**fs== 12.0**p== 7.0**b== 0.9**t== 0.1**l== 0.2**r== 0.2**\nTo resolve the second limitation, we adapted this VR task to align with theories of\n**BLOCK**fs== 12.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nsocial judgment. First, only two agents were present during the task: one blindfolded agent\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nand one agent who looked directly at the participant. By presenting both agents together in\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\neach trial, we emphasized the agent’s eyesight as a distinguishing feature between them.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nSecond, we included two different trial types to measure the effect of model eyesight both\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nacross and within trials. In the majority of the trials, one of both agents (i.e., the seeing or the\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nblindfolded agent) looked in a certain direction, similar to the trials in Cracco et al. (2022).\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nBased on the predictions by motivational theories, we expected to find more imitation of the\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nseeing agent compared to the blindfolded agent across trials. More precisely, we expected\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nparticipants to show a stronger congruency effect for this agent (forced-choice trials) and to\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nfollow this agent more frequently (free-choice trials) compared to the blindfolded agent.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.2**\nHowever, there were also trials in which both agents looked in opposite directions, which\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nallowed us to compare the effect of model eyesight within trials. When both agents move\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\ndifferently, the differences between both agents become essential, as participants are forced to\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nimitate either the seeing or the blindfolded agent and counter-imitate the other (for a similar\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\ndesign, see De Souter et al., 2021). Therefore, these trials were added to maximize the\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\neffectiveness of the model eyesight manipulation. Whereas the effect of the models’\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nmovements is usually canceled out when they move differently, causing the congruency effect\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nto disappear (Cracco et al., 2015), we expected to find stronger imitative tendencies for the\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nseeing agent, reflected in a congruency effect in the direction of this agent and more frequent\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.3**\nAll data and analysis code for the analyses for Experiment 1\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nOpen Science Framework (OSF). Data were processed and analyzed using R (version 4.3.1; R\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nCore Team, 2023). We report all measures and manipulations, and how we determined the\n**BLOCK**fs== 12.0**p== 8.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nsample size and participant and data exclusions. The experiments’ designs, hypotheses, and\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nboth experiments, there were no departures from the preregistered plan for the confirmatory\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nanalyses, and analyses that were not preregistered are identified as exploratory. Both\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.5**l== 0.1**r== 0.2**\nexperiments were approved by the ethical committee of the Faculty of Psychology and\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nParticipants were recruited through the research participation system of Ghent\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nUniversity (Sona Systems) and social media posts. Data for this study were collected in 2023.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nNinety-eight participants took part in this study in return for course credit or €10. Participants\n**BLOCK**fs== 12.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nwho took part in return for course credit (N = 77) were first-year psychology students at\n**BLOCK**fs== 12.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nGhent University. All participants had normal or corrected-to-normal vision, were Dutch-\n**BLOCK**fs== 12.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nspeaking, were naïve to the purpose of the experiment, and signed an informed consent before\n**BLOCK**fs== 12.0**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nthe start of the procedure. They were further informed that a side effect of VR is that some\n**BLOCK**fs== 12.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\npeople get dizzy or nauseous (Pan & Hamilton, 2018). Two participants could not complete\n**BLOCK**fs== 12.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nthe VR task because they experienced dizziness during the experiment. One of these\n**BLOCK**fs== 12.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nparticipants did not complete the first experimental block and was therefore excluded. For the\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nsecond participant, we used their data for two of the four experimental blocks. After further\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nexclusions (see the Analysis section for details), the final sample consisted of 94 participants\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nfor the analysis of the forced-choice trials (58 female, 33 male, 2 non-binary, 1 “rather not\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nsay”, Mage = 20.36, SDage = 3.08) and 91 participants for the analysis of the free-choice trials\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n(56 female, 32 male, 2 non-binary, 1 “rather not say”, Mage = 20.41, SDage = 3.11).\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nThe minimum sample size was determined via a power analysis with simulated data\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nusing the mixedpower package for mixed-effects models (Kumle et al., 2021). The power\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nanalysis was based on the expected effects in trials in which only one agent moved, because\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nthese trials are similar to trials in the study by Cracco et al. (2022). We aimed to detect the\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nsame main effects as Cracco et al. (2022) for the preregistered primary outcome measures\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n(i.e., reaction times (RTs) and error rates (ERs) on forced-choice trials and follow decisions\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\non free-choice trials) but multiplied these effects by 75% to obtain a conservative estimate.\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nThis corresponded to an estimated main effect of 27 ms for RTs, 4% for ERs, and 7% for the\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nfollow decisions. We then divided the obtained effect sizes by two to estimate the interactions\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nof interest (Baranger et al., 2023). The power analysis indicated that a sample of 90\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nparticipants would allow us to detect these effects with ≥ 82% power and a significance\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nForced-Choice Trials. For trials in which one agent moved, the within-subject factors\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nwere the agent’s eyesight (blindfolded, can see) and movement congruency (congruent,\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nincongruent). For trials in which the two agents looked in opposite directions, the within-\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nsubject factor was the movement congruency of the seeing agent (congruent, incongruent).\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nBecause both agents made different movements in these trials, the congruency effect for one\n**BLOCK**fs== 12.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nagent was always the opposite of the congruency effect for the other agent. Therefore, a\n**BLOCK**fs== 12.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\npositive congruency effect for the seeing agent implies that this agent caused a stronger\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\ncongruency effect than the blindfolded agent. The primary outcome measures for these trials\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nwere RTs and ERs. We included the partial errors and movement times (MTs) as secondary\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nFree-Choice Trials. For trials in which one agent moved, the within-subject factor\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nwas the agent’s eyesight (blindfolded, can see). The primary measure of interest was the\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nparticipant’s choice (not) to follow the moving agent. For trials in which the two agents\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nlooked in opposite directions, we simply measured whether participants followed the seeing\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nagent instead of the blindfolded agent. RTs, MTs, and partial choices were analyzed as\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nsecondary outcome measures. Figure 1 represents a visual overview of all the different trial\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.3**\nOverview of the Different Trial Types in the Design of Experiment 1\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nNote. The colored boxes represent trial types. The white boxes are the different conditions\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nwithin the trials. Note that there were no conditions in free-choice trials in which both agents\n**BLOCK**fs== 12.0**p== 11.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nThe study took place in the faculty of Psychology and Educational Sciences at Ghent\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nthey would perform a task together with two virtual people. These instructions explicitly\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nmentioned that one virtual person would be blindfolded during the task and were\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\naccompanied by a picture of the agents in which one of them wore the blindfold. This was\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\ndone to ensure participants recognized the blindfold. After the instructions, participants put on\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nthe head-mounted display (HMD). We used an HTC Vive Pro HMD with built-in\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nheadphones, a visual field of 110° with a resolution of 1440 x 1600 pixels per eye, and a\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nrefresh rate of 90 Hz. Next, participants completed nine practice trials of the VR experiment\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nwith auditory accuracy feedback. Participants heard a “ping” sound if they provided the\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.2**\ncorrect response and a “buzz” sound if they made an error. All responses were considered\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\ncorrect in free-choice trials. If necessary, participants could repeat the practice phase once\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nmore before proceeding to the test phase. The test phase contained 288 trials without accuracy\n**BLOCK**fs== 12.0**p== 11.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nfeedback, divided into four blocks with 72 trials each. All conditions were randomized within\n**BLOCK**fs== 12.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\neach block. The agent who wore the blindfold alternated across blocks, which means that each\n**BLOCK**fs== 12.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nagent wore the blindfold in two of the four blocks. Which agent wore the blindfold in the first\n**BLOCK**fs== 12.0**p== 11.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nThe VR environment was constructed in Unity Engine (version 2019.4.29f), based on\n**BLOCK**fs== 12.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nthe environment used in Cracco et al. (2022). Participants stood on a street, surrounded by\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\napartment buildings. Two virtual agents, a male and a female agent, stood in front of the\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nparticipant. The virtual agents and their animations were created using the Character Creator\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nand iClone software from Reallusion (2022). The position of these agents (i.e., left or right)\n**BLOCK**fs== 12.0**p== 11.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\nwas counterbalanced across participants. Both agents had a subtle smile during the task\n**BLOCK**fs== 12.0**p== 11.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nbecause an entirely neutral expression could come across as not socially engaging (Wang &\n**BLOCK**fs== 12.0**p== 12.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nHamilton, 2014). The buildings left and right of the participant contained a window in which\n**BLOCK**fs== 12.0**p== 12.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\na fire was burning. These windows were used as target locations in the imitation task.\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nFigure 2 provides an example trial of the VR task. Each trial started with a variable\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nperiod of 1500 to 3000 ms (randomized in steps of 500 ms), after which a sound was played\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nto cue the correct response. This sound was non-directional, which means that it was\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\npresented simultaneously to both ears. There were three distinct sounds used, each with a total\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nduration of one second: an explosion, a collapsing structure, and breaking glass. One sound –\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nfor example, the explosion – indicated that participants had to make a head movement toward\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nthe left window (forced-choice trial). The second sound – the collapsing structure – indicated\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nthat they had to look at the right window (forced-choice trial). The third sound – breaking\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nglass – indicated that participants were free to choose in which direction to look (free-choice\n**BLOCK**fs== 12.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\ntrial). However, they were asked to balance the number of times they looked at the left versus\n**BLOCK**fs== 12.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nright window across trials without using an explicit strategy (e.g., switching between the\n**BLOCK**fs== 12.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nwindows on each free-choice trial) (Arrington & Logan, 2004; Vandierendonck et al., 2010).\n**BLOCK**fs== 12.0**p== 12.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nOne hundred to 300 ms after the start of the sound (randomized in steps of 100 ms),\n**BLOCK**fs== 12.0**p== 12.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\none virtual agent (192 trials: 128 forced-choice, 64 free-choice) or both virtual agents (96\n**BLOCK**fs== 12.0**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\ntrials: 64 forced-choice, 32 free-choice) looked at one of the two target locations. If both\n**BLOCK**fs== 12.0**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nvirtual agents made a head movement, they always looked in opposite directions. In forced-\n**BLOCK**fs== 12.0**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nchoice trials, the agent(s) could look at the correct window (congruent trial) or the incorrect\n**BLOCK**fs== 12.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nwindow (incongruent trial). In free-choice trials, there was no (in)correct response.\n**BLOCK**fs== 12.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nParticipants could respond from the start of the auditory cue until the response deadline of\n**BLOCK**fs== 12.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\n3000 ms. When the participant’s gaze reached one of the target windows, the fire was\n**BLOCK**fs== 12.0**p== 12.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nextinguished to indicate that their response was registered. The next trial immediately started\n**BLOCK**fs== 12.0**p== 12.0**b== 0.1**t== 0.9**l== 0.1**r== 0.3**\nwhen the participant looked back in the direction of the virtual agents.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nExample Trial in the Virtual Reality Task of Experiment 1 From Participant Viewpoint\n**BLOCK**fs== 12.0**p== 13.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nNote. The duration of the auditory cue was one second, which means that the sound was still\n**BLOCK**fs== 12.0**p== 13.0**b== 0.5**t== 0.5**l== 0.2**r== 0.1**\nAfter the VR task, participants were asked to provide their demographic information\n**BLOCK**fs== 12.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nand complete several questionnaires on a laptop. They first indicated their age and gender. To\n**BLOCK**fs== 12.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nindicate their gender, participants could choose one of the following options: “male”,\n**BLOCK**fs== 12.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n“female”, “non-binary”, “not listed”, or “prefer not to say”. If they indicated that their gender\n**BLOCK**fs== 12.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nwas “not listed”, they could fill in an alternative. Participants then completed three\n**BLOCK**fs== 12.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nquestionnaires, the Autism Spectrum Quotient (AQ; Baron-Cohen et al., 2001), the Social\n**BLOCK**fs== 12.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nReward Questionnaire (Foulkes et al., 2014), and the Need To Belong Scale (NTBS; Leary et\n**BLOCK**fs== 12.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nal., 2013), in a randomized order. These questionnaires were used for an exploratory analysis,\n**BLOCK**fs== 12.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nfor which the materials, analysis, results, and discussion can be found in the Supplementary\n**BLOCK**fs== 12.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nMaterials (S1). Students who participated in return for course credit were debriefed via e-mail\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nafter data collection was finished. Participants could also share their e-mail address if they\n**BLOCK**fs== 12.0**p== 14.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nCalculation of the Outcome Measures. The x, y, and z coordinates of the HMD were\n**BLOCK**fs== 12.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\ncontinuously tracked throughout the experiment to measure the precise onset and direction of\n**BLOCK**fs== 12.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nthe participant’s head movement together with the moment they reached the target location.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nWe followed the procedure from Cracco et al. (2022) to calculate the participants’ RTs, ERs,\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nMTs, partial errors/choices, and the participant’s decision (not) to follow the agent(s).\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nRT was defined as the onset of the upward movement toward one of the targets. To\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\ncalculate this measure, we determined the first derivative of the HMD position on the y-axis\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n(up/down), which represents the velocity of the upward movement at each time point. We\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nthen searched for the last time point at which this first derivative was ≤ 0 before reaching its\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nmaximum value, indicating the onset of the upward head movement. MT was defined as the\n**BLOCK**fs== 12.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nduration of the head movement. This measure was calculated by subtracting RT (i.e., the\n**BLOCK**fs== 12.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nonset) from the first timepoint at which the y-axis’ (up/down) first derivative was ≤ 0 again\n**BLOCK**fs== 12.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nafter reaching its maximum, indicating the end of the head movement.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nPartial errors (forced-choice trials) and partial choices (free-choice trials) were trials in\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nwhich the participant first moved their head in the direction of one target location but then\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nchanged direction and hit the other target instead. Partial errors/choices were calculated by\n**BLOCK**fs== 12.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\ntaking the first derivative of the HMD position on the z-axis (left/right) and recoding the\n**BLOCK**fs== 12.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nobtained values such that values reflected a movement in the direction of the participant’s\n**BLOCK**fs== 12.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nfinal target. We then searched for a substantial deviation in the opposite direction. More\n**BLOCK**fs== 12.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nspecifically, if there was a five-point local minimum of <-0.05 preceding the maximum first\n**BLOCK**fs== 12.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nderivative value, a partial error/choice was registered. The final target was saved as the\n**BLOCK**fs== 12.0**p== 14.0**b== 0.1**t== 0.9**l== 0.2**r== 0.1**\nParticipant and Trial Exclusion. Participant and trial exclusions were preregistered\n**BLOCK**fs== 12.0**p== 15.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nParticipants were excluded from all analyses if their ER on forced-choice trials was ≥\n**BLOCK**fs== 12.0**p== 15.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n40% (none). Three participants were excluded from the forced-choice analysis because their\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nER exceeded the average ER in the sample with ≥ 2.5 SD or because their mean RT on\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nforced-choice trials was ≥ 2.5 SD above or below the mean RT in the sample. Six participants\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nwere excluded from the free-choice analysis because they chose the same target on ≥ 75% of\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nthe trials or because their mean RT on free-choice trials was ≥ 2.5 SD above or below the\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nmean RT in the sample. Ninety-four participants (58 female, 33 male, 2 non-binary, 1 “rather\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nnot say”, Mage = 20.36, SDage = 3.08) were included in the forced-choice analysis and 91\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nparticipants (56 female, 32 male, 2 non-binary, 1 “rather not say”, Mage = 20.41, SDage = 3.11)\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nTrials were excluded from all analyses if the RT was ≤ 200 ms (0.45%), if the RT was\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n≥ 4000 ms (0.00%), or if the MT was ≥ 2000 ms (0.01%). In addition, trials were excluded\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nfrom the forced-choice RT/MT analysis if the response was incorrect (1.71%) or if a partial\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nerror was made (8.59%). In the RT/MT analysis, trials were also excluded if the RT was ≥ 2.5\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nSD above or below the participant’s mean RT (1.97%) or if the MT was ≥ 2.5 SD above or\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nbelow the participant’s mean MT (1.92%). The same criteria were used in the partial error\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nanalysis, except that partial errors were included, and in the forced-choice ER analysis, except\n**BLOCK**fs== 12.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nthat the errors were included. Trials were excluded in the error (3.10%) and partial error\n**BLOCK**fs== 12.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n(4.08%) analyses if the RT and/or MT was ≥ 2.5 SD above or below the participant’s mean\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nApart from the trials that were excluded from all analyses, trials were also excluded\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nfrom the free-choice RT/MT/participant’s decision analysis if a partial choice was made\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n(7.63%), if the RT was ≥ 2.5 SD above or below the participant’s mean RT (1.76%) or if the\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nMT was ≥ 2.5 SD above or below the participant’s mean MT (1.71%) on free-choice trials\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nwithout partial choices. The same criteria were used for trial exclusion in the partial choice\n**BLOCK**fs== 12.0**p== 16.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nanalysis, except that partial choices were included. In this analysis, 3.54% of the trials were\n**BLOCK**fs== 12.0**p== 16.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nexcluded because the RT and/or MT was ≥ 2.5 SD above or below the participant’s mean\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nPreregistered Data Analysis. RTs and MTs were analyzed with linear mixed-effects\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nmodels (Bates et al., 2015) and p-values were calculated using the Satterthwaite correction for\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nKuznetsova et al., 2017). As a measure of effect size, we report the beta estimates and their\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n95% confidence interval. ERs, partial errors, partial choices, and the participant’s decision\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nwere analyzed with generalized mixed-effects models, using the binomial logit link function\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n(Baayen et al., 2008; Bates et al., 2015). P-values were calculated using Wald Chi-Square\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\ntests for generalized mixed-effects models. We report the unsigned z-values and add the odds\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nratios and their 95% confidence interval as a measure of effect size. Type three sum of\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nsquares and contrast coding were used in all analyses. The random-effects structure of the\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nmodels was determined through the procedure suggested by Scandola and Tidoni (2024) to\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nbalance type I and type II errors. This procedure fits complex random intercepts rather than\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nrandom slopes, which allows us to fit more complex models without convergency or\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nsingularity issues (i.e., the statistical procedure fails to fit an optimal model with the given\n**BLOCK**fs== 12.0**p== 16.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nModels in Forced-Choice Trials. RTs and ERs were the primary measures of interest\n**BLOCK**fs== 12.0**p== 16.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nin forced-choice trials. MTs and partial errors were analyzed as secondary outcome measures.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nFor trials in which only one agent moved, the moving agent’s eyesight (blindfolded, can see)\n**BLOCK**fs== 12.0**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nfactors. For trials in which the two agents looked in opposite directions, only the seeing\n**BLOCK**fs== 12.0**p== 16.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nagent’s congruency was included as a fixed within-subject factor. Because both agents made\n**BLOCK**fs== 12.0**p== 17.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\nopposite movements, a congruent movement by the seeing agent implied an incongruent\n**BLOCK**fs== 12.0**p== 17.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nModels in Free-Choice Trials. For trials in which only one agent moved, the primary\n**BLOCK**fs== 12.0**p== 17.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nmeasure of interest for free-choice trials was the participant’s decision (not) to follow the\n**BLOCK**fs== 12.0**p== 17.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nmoving agent. The agent’s eyesight (blindfolded, can see) was included as a fixed within-\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nsubject factor in this model. RTs, MTs, and partial choices were analyzed as secondary\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\noutcome measures. For these outcome measures, the participant’s decision (followed agent,\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\ndid not follow agent) and the agent’s eyesight (blindfolded, can see) were included as fixed\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nFor trials in which the two agents looked in opposite directions, the primary measure\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nof interest was the participant’s decision to follow the seeing agent (as opposed to the\n**BLOCK**fs== 12.0**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nblindfolded agent). For this measure, only the intercept was included in the model. In the\n**BLOCK**fs== 12.0**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nmodels for RTs, MTs, and partial choices, the participant’s decision (followed seeing agent,\n**BLOCK**fs== 12.0**p== 17.0**b== 0.3**t== 0.6**l== 0.2**r== 0.3**\nConfirmatory Analysis for Trials in Which One Agent Moved.\n**BLOCK**fs== 12.0**p== 17.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nReaction Times on Forced-Choice Trials. The RT analysis revealed a main effect of\n**BLOCK**fs== 12.0**p== 17.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\ncongruency, F(1, 93) = 130.74, p < .001, b = 20.10, 95% CI [16.61, 23.60]. Participants were\n**BLOCK**fs== 12.0**p== 17.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\nfaster when the moving agent made a congruent movement (M = 597 ms, SD = 118 ms)\n**BLOCK**fs== 12.0**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\ncompared to an incongruent movement (M = 637 ms, SD = 128 ms). There was no significant\n**BLOCK**fs== 12.0**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\neffect of the moving agent’s sight, F(1, 9975) = 0.17, p = .681, b = 0.65, 95% CI [-2.47, 3.77].\n**BLOCK**fs== 12.0**p== 17.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nThere was no significant interaction between the agent’s congruency and sight, F(1, 9974) =\n**BLOCK**fs== 12.0**p== 17.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n0.43, p = .514, b = -1.04, 95% CI [-4.16, 2.08], on RTs, suggesting that the congruency effect\n**BLOCK**fs== 12.0**p== 18.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\ndid not differ for the seeing versus blindfolded agent. Figure 3A shows the congruency effect\n**BLOCK**fs== 12.0**p== 18.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nError Rates on Forced-Choice Trials. The ER analysis (Figure 3B) revealed a\n**BLOCK**fs== 12.0**p== 18.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nsignificant effect of congruency on ERs, z = 5.32, p < .001, OR = 1.80, 95% CI [1.45, 2.23],\n**BLOCK**fs== 12.0**p== 18.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nwith more errors for incongruent (M = 2.73%, SD = 3.91%) than congruent (M = 0.87%, SD =\n**BLOCK**fs== 12.0**p== 18.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n1.64%) movements by the moving agent. There was no significant main effect of the moving\n**BLOCK**fs== 12.0**p== 18.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nagent’s sight, z = 1.33, p = .185, OR = 1.13, 95% CI [0.95, 1.34], and no significant\n**BLOCK**fs== 12.0**p== 18.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\ninteraction between congruency and sight of the agent, z = 1.12, p = .265, OR = 0.91, 95% CI\n**BLOCK**fs== 12.0**p== 18.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nMovement Times on Forced-Choice Trials. There was no significant effect of\n**BLOCK**fs== 12.0**p== 18.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\ncongruency on MTs, F(1, 10046) = 3.74, p = .053, b = -2.60, 95% CI [-5.24, 0.04]. Note that,\n**BLOCK**fs== 12.0**p== 18.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nnumerically, this effect showed faster MTs for incongruent (M = 635 ms, SD = 143 ms)\n**BLOCK**fs== 12.0**p== 18.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\ncompared to congruent movements (M = 640 ms, SD = 146 ms), a pattern opposite to the\n**BLOCK**fs== 12.0**p== 18.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nsignificant congruency effects found in our primary outcome measures. There was no\n**BLOCK**fs== 12.0**p== 18.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nsignificant effect of the agent’s sight, F(1, 10045) = 0.67, p = .413, b = -1.10, 95% CI [-3.74,\n**BLOCK**fs== 12.0**p== 18.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n1.54], nor a significant interaction effect, F(1, 10045) = 0.09, p = .761, b = 0.41, 95% CI [-\n**BLOCK**fs== 12.0**p== 18.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nPartial Errors on Forced-Choice Trials. The analysis of partial errors revealed a\n**BLOCK**fs== 12.0**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nsignificant effect of congruency, z = 8.45, p < .001, OR = 1.45, 95% CI [1.33, 1.58].\n**BLOCK**fs== 12.0**p== 18.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nParticipants made more partial errors when the moving agent made incongruent (M = 11.09%,\n**BLOCK**fs== 12.0**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nSD = 9.10%) compared to congruent movements (M = 5.68%, SD = 4.93%). We further found\n**BLOCK**fs== 12.0**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\na significant main effect of the agent’s sight, z = 2.25, p = .025, OR = 0.92, 95% CI [0.86,\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n0.99], with more partial errors when the agent was blindfolded (M = 8.93%, SD = 6.95%) than\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nwhen the agent could see (M = 7.84%, SD = 6.46%). In line with previous outcome measures,\n**BLOCK**fs== 12.0**p== 19.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nthe interaction between the agent’s congruency and sight was non-significant, z = 0.50, p =\n**BLOCK**fs== 12.0**p== 19.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nThe Participant’s Decision on Free-Choice Trials.  The analysis of the participants’\n**BLOCK**fs== 12.0**p== 19.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\ndecision (not) to follow the moving agent (Figure 3C) revealed a significant intercept, z =\n**BLOCK**fs== 12.0**p== 19.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\n7.69, p < .001, OR = 1.33, 95% CI [1.24, 1.43]. Participants followed the moving agent in\n**BLOCK**fs== 12.0**p== 19.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n57.02% (SD = 8.52%) of the trials, which is significantly more than the chance level. There\n**BLOCK**fs== 12.0**p== 19.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwas no significant effect of the moving agent’s sight on the participant’s decision, z = 0.27, p\n**BLOCK**fs== 12.0**p== 19.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nReaction Times on Free-Choice Trials. There was a significant effect of the\n**BLOCK**fs== 12.0**p== 19.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nparticipants’ decision to follow the agent on RTs, F(1, 90) = 28.30, p < .001, b = 17.88, 95%\n**BLOCK**fs== 12.0**p== 19.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nCI [11.20, 24.55]. Participants had faster RTs when they followed the moving agent (M = 675\n**BLOCK**fs== 12.0**p== 19.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nms, SD = 158 ms) than when they did not follow the agent (M = 712 ms, SD = 169 ms). We\n**BLOCK**fs== 12.0**p== 19.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nfound no effect of the agent’s sight, F(1, 4937) = 2.09, p = .148, b = 4.08, 95% CI [-1.45,\n**BLOCK**fs== 12.0**p== 19.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n9.62], nor a significant interaction between the participant's decision and the agent’s sight,\n**BLOCK**fs== 12.0**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nMovement Times on Free-Choice Trials.  There was no significant effect of the\n**BLOCK**fs== 12.0**p== 19.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\nparticipant’s decision to follow the agent, F(1, 89) = 0.07, p = 0.797, b = -0.55, 95% CI [-\n**BLOCK**fs== 12.0**p== 19.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n4.76, 3.66], or the sight of the agent, F(1, 4942) = 0.09, p = .759, b = -0.61, 95% CI [-4.54,\n**BLOCK**fs== 12.0**p== 19.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n3.31], and no significant interaction effect, F(1, 4890) = 0.12, p = .730, b = -0.70, 95% CI [-\n**BLOCK**fs== 12.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nPartial Choices on Free-Choice Trials. The analysis of partial choices revealed a\n**BLOCK**fs== 12.0**p== 19.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nsignificant effect of the participant’s decision to follow the moving agent on the number of\n**BLOCK**fs== 12.0**p== 19.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\npartial choices, z = 5.88, p < .001, OR = 1.43, 95% CI [1.27, 1.61], with fewer direction\n**BLOCK**fs== 12.0**p== 19.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nchanges when participants chose to follow the moving agent (M = 5.57%, SD = 5.97%) than",
         "The impact of model eyesight and social reward on automatic imitation in virtual reality 1Department of Experimental Clinical and Health Psychology, Ghent University, Ghent, Word count: 11516 This study was funded by two Research Foundation – Flanders grants awarded to MN (11E5223N) and EC (12U0322N). JDH is supported by the Ghent University Methusalem addressed to Maura Nevejans, Department of Experimental Clinical and Health Psychology, maura.nevejans@ugent.be. Ethical approval was granted by the ethical committee of the Faculty of Psychology and Educational Sciences with reference number 2023-004. This study authors would like to thank Nelle Baetens, Lynn Buyens, Emilia Deslee, Maxence Soulliaert, Motivational theories of imitation state that we imitate because this led to positive social consequences in the past. Because movement imitation typically only leads to these consequences when perceived by the imitated person, it should increase when the interaction partner sees the imitator. Current evidence for this hypothesis is mixed, potentially due to the low ecological validity in previous studies. We conducted two experiments (Nexp1 = 94, Nexp2 = 110) in which we resolved this limitation by placing participants in a virtual environment with a seeing and a blindfolded virtual agent, where they reacted to auditory cues with a head movement to the left or right, while the agent(s) also made a left or right head movement. We tested the effect of model eyesight (Experiments 1 and 2) and social reward on imitation (Experiment 2). Data were collected in 2023 and 2024. As expected, participants tended to imitate the agents. However, we found only limited evidence for the effect of model eyesight on automatic imitation in Experiment 1 and no evidence for the effect of model eyesight or social reward in Experiment 2. These findings challenge claims made by motivational Keywords: Automatic imitation, social reward, model eyesight, motivational theories, Motivational theories argue that humans imitate more in situations where imitation is more likely to have positive social consequences. Based on this, it has been hypothesized that movement imitation should be stronger when the model can see the imitator because only then imitation can lead to a positive reaction. However, evidence for this effect has been mixed, potentially due to the low ecological validity of previous tasks. In two experiments, we use virtual-reality tasks to address this issue and thereby maximize the putative effect of model eyesight. In Experiment 2, we also tested the effect of the model’s emotional reaction to imitation. We found only limited evidence for the effect of the other person’s sight in Experiment 1, whereas no such effect was found in Experiment 2. Furthermore, imitation was not influenced by whether the other person (dis)liked being imitated. These findings raise Humans have an automatic tendency to copy the behavior of others, including their mannerisms (Chartrand & Bargh, 1999; Tschacher et al., 2014), gestures (Cracco, Genschow, et al., 2018), facial expressions (Dimberg, 1982; Dimberg et al., 2000), and eye gaze (Cracco et al., 2022; Driver et al., 1999; Milgram et al., 1969). According to the Associative Sequence Learning (ASL) model, these imitative tendencies emerge from a link between perceptual and motor representations of actions in the brain, formed through repeated sensorimotor experiences over the course of development. As a result, the perceptual representation of an action automatically activates its corresponding motor representation, leading to the tendency These imitative tendencies are, in turn, thought to support successful social interaction by fostering affiliation between the imitator (i.e., the person who imitates) and the imitated person (Hess & Fischer, 2013, 2022; Lakin et al., 2003). For instance, imitation has been found to increase empathy (De Coster et al., 2013; Stel & Vonk, 2009) and trust (Maddux et al., 2008; Over et al., 2013; Verberne et al., 2013) toward the imitator, as well as liking between the interaction partners (Chartrand & Bargh, 1999; Salazar Kämpf et al., 2018; for a review, see Chartrand & Lakin, 2013). Based on these findings, motivational theories argue that imitation can be seen as a strategy to obtain social reward, such as affiliation with others (Stel et al., 2016; Wang & Hamilton, 2012). In line with this idea, research has shown that imitation increases when individuals are more motivated to affiliate with other people, for example, after being socially excluded (Lakin et al., 2008) or after being primed with However, imitation will not always lead to social reward. For example, imitating the movements of someone who cannot see you is unlikely to cause them to like you more because they do not see your imitative behavior. Motivational theories incorporate these contextual constraints by arguing that individuals imitate more if imitation can be expected to produce social reward in that particular context (Stel et al., 2016). This implies that imitation can be seen as a form of operant behavior, with social reward as the reinforcer and contextual cues like whether the other person sees the imitator as discriminative stimuli determining if imitation is likely to lead to such reward (Wang & Hamilton, 2012). Previous research typically investigated this prediction by manipulating the gaze direction of a model. These studies found that a direct gaze from a model (vs. an averted gaze) not only leads to increased motor activation in the brain during observation of hand movements (Prinsen et al., 2017, 2018; Prinsen & Alaerts, 2019) but also more imitation of the model’s hand movements (Wang et al., 2011; Wang & Hamilton, 2014). However, recent research, including a well- powered study by Carr et al. (2021), could not replicate this effect on imitation (Carr et al., 2021; Farmer et al., 2021). Hence, the evidence for the effect of gaze direction on imitative There are two limitations in previous research that could have caused this inconsistency in the literature. The first limitation is the low ecological validity of the imitation tasks typically used to study the influence of social factors on imitation. Most research on this topic uses the imitation-inhibition paradigm to measure automatic imitation (Carr et al., 2021; Farmer et al., 2021; Wang et al., 2011; Wang & Hamilton, 2014). In this task, participants respond to symbolic cues with certain hand movements, while a hand in the background performs a congruent movement (identical to the correct response) or an incongruent movement (different from the correct response) (Brass et al., 2000; Cracco, Bardi, et al., 2018). Participants tend to respond more slowly and with lower accuracy when the hand performs an incongruent compared to a congruent movement (Brass et al., 2000). Although this congruency effect has been replicated in various studies (Cracco, Bardi, et al., 2018) and proven to be a reliable (Genschow et al., 2017) and valid (Cracco & Brass, 2019) index of covert imitative tendencies, it is very different from how imitation typically occurs in real life. Whereas the imitation-inhibition task measures covert imitation of meaningless hand movements on a computer screen (Brass et al., 2000; Cracco, Bardi, et al., 2018), everyday situations typically involve overt imitation of meaningful social behavior. Therefore, this task might be suboptimal to test the predictions by motivational theories, which focus on these real-life imitative tendencies (Stel et al., 2016; Wang & de Hamilton, 2012). Despite attempts to make the task more social, such as presenting a picture of a person together with the hand (e.g., Forbes et al., 2017; Wang et al., 2011), the imitation-inhibition imitation task remains rather artificial. A possible solution to this problem is to use real-life interactions to study imitation (e.g., Chartrand & Bargh, 1999). However, whereas these paradigms have higher ecological validity, they have lower experimental control and reliability (Genschow et al., Besides the limited ecological validity, a second limitation in previous work is the absence of direct social comparison. In daily life, we often observe multiple individuals acting simultaneously, whereas only a single hand is typically shown in each trial during imitation tasks. This distinction is important because, according to social judgment theories, humans typically evaluate someone by comparing them to a salient reference within a specific context (Mussweiler, 2003). Hence, it is possible that certain characteristics of a model influence imitation only when this model is compared to another model that serves as a reference. By presenting only one model per trial and comparing the effect of whether this model looks at the participant across trials, the social comparison between both models has been merely implicit, potentially attenuating the effect of the model’s gaze direction on imitative tendencies. In contrast, when participants observe two models simultaneously, the fact that only one of both models looks at them becomes an important distinguishing factor between To resolve both limitations in previous work, the current study builds on a recent study by Cracco et al. (2022) to investigate the effect of whether the other person sees the imitator on imitation. In their study, Cracco et al. (2022) bridged the gap between the artificial imitation-inhibition task and more naturalistic paradigms by using virtual reality (VR). More precisely, they created an immersive VR imitation task in which they measured imitation of socially relevant behavior, namely gaze following. Participants were placed in a virtual city with ten life-sized virtual agents. Once in a while, a sound was played, which cued participants to look up to the left or right target window, in which a fire was burning. At the same time, a variable number of virtual agents also looked up to the left or right target location. Imitation was assessed by measuring the influence of the virtual agents’ movements on the participant’s behavior. Automatic imitation was measured via the congruency effect in forced-choice trials, identical to how it is typically measured in an imitation-inhibition task. However, because in daily life, people can typically choose their responses, and thus also choose (not) to imitate, Cracco et al. (2022) also added another measure of imitation via so- called free-choice trials. In these trials, there was no correct response and participants could choose (not) to follow the virtual agents’ movements, thereby representing real-life imitative Cracco et al. (2022) effectively measured participants’ imitative tendencies in both forced- and free-choice conditions. Moreover, they replicated findings from previous research using the typical imitation-inhibition task, by showing that automatic imitation increased with the number of observed movements (Cracco et al., 2015; Cracco & Brass, 2018). Altogether, by using VR, the researchers could increase the ecological validity of the typical imitation- inhibition task while also retaining experimental control (Parsons, 2015), thereby resolving To resolve the second limitation, we adapted this VR task to align with theories of social judgment. First, only two agents were present during the task: one blindfolded agent and one agent who looked directly at the participant. By presenting both agents together in each trial, we emphasized the agent’s eyesight as a distinguishing feature between them. Second, we included two different trial types to measure the effect of model eyesight both across and within trials. In the majority of the trials, one of both agents (i.e., the seeing or the blindfolded agent) looked in a certain direction, similar to the trials in Cracco et al. (2022). Based on the predictions by motivational theories, we expected to find more imitation of the seeing agent compared to the blindfolded agent across trials. More precisely, we expected participants to show a stronger congruency effect for this agent (forced-choice trials) and to follow this agent more frequently (free-choice trials) compared to the blindfolded agent. However, there were also trials in which both agents looked in opposite directions, which allowed us to compare the effect of model eyesight within trials. When both agents move differently, the differences between both agents become essential, as participants are forced to imitate either the seeing or the blindfolded agent and counter-imitate the other (for a similar design, see De Souter et al., 2021). Therefore, these trials were added to maximize the effectiveness of the model eyesight manipulation. Whereas the effect of the models’ movements is usually canceled out when they move differently, causing the congruency effect to disappear (Cracco et al., 2015), we expected to find stronger imitative tendencies for the seeing agent, reflected in a congruency effect in the direction of this agent and more frequent All data and analysis code for the analyses for Experiment 1 Open Science Framework (OSF). Data were processed and analyzed using R (version 4.3.1; R Core Team, 2023). We report all measures and manipulations, and how we determined the sample size and participant and data exclusions. The experiments’ designs, hypotheses, and both experiments, there were no departures from the preregistered plan for the confirmatory analyses, and analyses that were not preregistered are identified as exploratory. Both experiments were approved by the ethical committee of the Faculty of Psychology and Participants were recruited through the research participation system of Ghent University (Sona Systems) and social media posts. Data for this study were collected in 2023. Ninety-eight participants took part in this study in return for course credit or €10. Participants who took part in return for course credit (N = 77) were first-year psychology students at Ghent University. All participants had normal or corrected-to-normal vision, were Dutch- speaking, were naïve to the purpose of the experiment, and signed an informed consent before the start of the procedure. They were further informed that a side effect of VR is that some people get dizzy or nauseous (Pan & Hamilton, 2018). Two participants could not complete the VR task because they experienced dizziness during the experiment. One of these participants did not complete the first experimental block and was therefore excluded. For the second participant, we used their data for two of the four experimental blocks. After further exclusions (see the Analysis section for details), the final sample consisted of 94 participants for the analysis of the forced-choice trials (58 female, 33 male, 2 non-binary, 1 “rather not say”, Mage = 20.36, SDage = 3.08) and 91 participants for the analysis of the free-choice trials (56 female, 32 male, 2 non-binary, 1 “rather not say”, Mage = 20.41, SDage = 3.11). The minimum sample size was determined via a power analysis with simulated data using the mixedpower package for mixed-effects models (Kumle et al., 2021). The power analysis was based on the expected effects in trials in which only one agent moved, because these trials are similar to trials in the study by Cracco et al. (2022). We aimed to detect the same main effects as Cracco et al. (2022) for the preregistered primary outcome measures (i.e., reaction times (RTs) and error rates (ERs) on forced-choice trials and follow decisions on free-choice trials) but multiplied these effects by 75% to obtain a conservative estimate. This corresponded to an estimated main effect of 27 ms for RTs, 4% for ERs, and 7% for the follow decisions. We then divided the obtained effect sizes by two to estimate the interactions of interest (Baranger et al., 2023). The power analysis indicated that a sample of 90 participants would allow us to detect these effects with ≥ 82% power and a significance Forced-Choice Trials. For trials in which one agent moved, the within-subject factors were the agent’s eyesight (blindfolded, can see) and movement congruency (congruent, incongruent). For trials in which the two agents looked in opposite directions, the within- subject factor was the movement congruency of the seeing agent (congruent, incongruent). Because both agents made different movements in these trials, the congruency effect for one agent was always the opposite of the congruency effect for the other agent. Therefore, a positive congruency effect for the seeing agent implies that this agent caused a stronger congruency effect than the blindfolded agent. The primary outcome measures for these trials were RTs and ERs. We included the partial errors and movement times (MTs) as secondary Free-Choice Trials. For trials in which one agent moved, the within-subject factor was the agent’s eyesight (blindfolded, can see). The primary measure of interest was the participant’s choice (not) to follow the moving agent. For trials in which the two agents looked in opposite directions, we simply measured whether participants followed the seeing agent instead of the blindfolded agent. RTs, MTs, and partial choices were analyzed as secondary outcome measures. Figure 1 represents a visual overview of all the different trial Overview of the Different Trial Types in the Design of Experiment 1 Note. The colored boxes represent trial types. The white boxes are the different conditions within the trials. Note that there were no conditions in free-choice trials in which both agents The study took place in the faculty of Psychology and Educational Sciences at Ghent they would perform a task together with two virtual people. These instructions explicitly mentioned that one virtual person would be blindfolded during the task and were accompanied by a picture of the agents in which one of them wore the blindfold. This was done to ensure participants recognized the blindfold. After the instructions, participants put on the head-mounted display (HMD). We used an HTC Vive Pro HMD with built-in headphones, a visual field of 110° with a resolution of 1440 x 1600 pixels per eye, and a refresh rate of 90 Hz. Next, participants completed nine practice trials of the VR experiment with auditory accuracy feedback. Participants heard a “ping” sound if they provided the correct response and a “buzz” sound if they made an error. All responses were considered correct in free-choice trials. If necessary, participants could repeat the practice phase once more before proceeding to the test phase. The test phase contained 288 trials without accuracy feedback, divided into four blocks with 72 trials each. All conditions were randomized within each block. The agent who wore the blindfold alternated across blocks, which means that each agent wore the blindfold in two of the four blocks. Which agent wore the blindfold in the first The VR environment was constructed in Unity Engine (version 2019.4.29f), based on the environment used in Cracco et al. (2022). Participants stood on a street, surrounded by apartment buildings. Two virtual agents, a male and a female agent, stood in front of the participant. The virtual agents and their animations were created using the Character Creator and iClone software from Reallusion (2022). The position of these agents (i.e., left or right) was counterbalanced across participants. Both agents had a subtle smile during the task because an entirely neutral expression could come across as not socially engaging (Wang & Hamilton, 2014). The buildings left and right of the participant contained a window in which a fire was burning. These windows were used as target locations in the imitation task. Figure 2 provides an example trial of the VR task. Each trial started with a variable period of 1500 to 3000 ms (randomized in steps of 500 ms), after which a sound was played to cue the correct response. This sound was non-directional, which means that it was presented simultaneously to both ears. There were three distinct sounds used, each with a total duration of one second: an explosion, a collapsing structure, and breaking glass. One sound – for example, the explosion – indicated that participants had to make a head movement toward the left window (forced-choice trial). The second sound – the collapsing structure – indicated that they had to look at the right window (forced-choice trial). The third sound – breaking glass – indicated that participants were free to choose in which direction to look (free-choice trial). However, they were asked to balance the number of times they looked at the left versus right window across trials without using an explicit strategy (e.g., switching between the windows on each free-choice trial) (Arrington & Logan, 2004; Vandierendonck et al., 2010). One hundred to 300 ms after the start of the sound (randomized in steps of 100 ms), one virtual agent (192 trials: 128 forced-choice, 64 free-choice) or both virtual agents (96 trials: 64 forced-choice, 32 free-choice) looked at one of the two target locations. If both virtual agents made a head movement, they always looked in opposite directions. In forced- choice trials, the agent(s) could look at the correct window (congruent trial) or the incorrect window (incongruent trial). In free-choice trials, there was no (in)correct response. Participants could respond from the start of the auditory cue until the response deadline of 3000 ms. When the participant’s gaze reached one of the target windows, the fire was extinguished to indicate that their response was registered. The next trial immediately started when the participant looked back in the direction of the virtual agents. Example Trial in the Virtual Reality Task of Experiment 1 From Participant Viewpoint Note. The duration of the auditory cue was one second, which means that the sound was still After the VR task, participants were asked to provide their demographic information and complete several questionnaires on a laptop. They first indicated their age and gender. To indicate their gender, participants could choose one of the following options: “male”, “female”, “non-binary”, “not listed”, or “prefer not to say”. If they indicated that their gender was “not listed”, they could fill in an alternative. Participants then completed three questionnaires, the Autism Spectrum Quotient (AQ; Baron-Cohen et al., 2001), the Social Reward Questionnaire (Foulkes et al., 2014), and the Need To Belong Scale (NTBS; Leary et al., 2013), in a randomized order. These questionnaires were used for an exploratory analysis, for which the materials, analysis, results, and discussion can be found in the Supplementary Materials (S1). Students who participated in return for course credit were debriefed via e-mail after data collection was finished. Participants could also share their e-mail address if they Calculation of the Outcome Measures. The x, y, and z coordinates of the HMD were continuously tracked throughout the experiment to measure the precise onset and direction of the participant’s head movement together with the moment they reached the target location. We followed the procedure from Cracco et al. (2022) to calculate the participants’ RTs, ERs, MTs, partial errors/choices, and the participant’s decision (not) to follow the agent(s). RT was defined as the onset of the upward movement toward one of the targets. To calculate this measure, we determined the first derivative of the HMD position on the y-axis (up/down), which represents the velocity of the upward movement at each time point. We then searched for the last time point at which this first derivative was ≤ 0 before reaching its maximum value, indicating the onset of the upward head movement. MT was defined as the duration of the head movement. This measure was calculated by subtracting RT (i.e., the onset) from the first timepoint at which the y-axis’ (up/down) first derivative was ≤ 0 again after reaching its maximum, indicating the end of the head movement. Partial errors (forced-choice trials) and partial choices (free-choice trials) were trials in which the participant first moved their head in the direction of one target location but then changed direction and hit the other target instead. Partial errors/choices were calculated by taking the first derivative of the HMD position on the z-axis (left/right) and recoding the obtained values such that values reflected a movement in the direction of the participant’s final target. We then searched for a substantial deviation in the opposite direction. More specifically, if there was a five-point local minimum of <-0.05 preceding the maximum first derivative value, a partial error/choice was registered. The final target was saved as the Participant and Trial Exclusion. Participant and trial exclusions were preregistered Participants were excluded from all analyses if their ER on forced-choice trials was ≥ 40% (none). Three participants were excluded from the forced-choice analysis because their ER exceeded the average ER in the sample with ≥ 2.5 SD or because their mean RT on forced-choice trials was ≥ 2.5 SD above or below the mean RT in the sample. Six participants were excluded from the free-choice analysis because they chose the same target on ≥ 75% of the trials or because their mean RT on free-choice trials was ≥ 2.5 SD above or below the mean RT in the sample. Ninety-four participants (58 female, 33 male, 2 non-binary, 1 “rather not say”, Mage = 20.36, SDage = 3.08) were included in the forced-choice analysis and 91 participants (56 female, 32 male, 2 non-binary, 1 “rather not say”, Mage = 20.41, SDage = 3.11) Trials were excluded from all analyses if the RT was ≤ 200 ms (0.45%), if the RT was ≥ 4000 ms (0.00%), or if the MT was ≥ 2000 ms (0.01%). In addition, trials were excluded from the forced-choice RT/MT analysis if the response was incorrect (1.71%) or if a partial error was made (8.59%). In the RT/MT analysis, trials were also excluded if the RT was ≥ 2.5 SD above or below the participant’s mean RT (1.97%) or if the MT was ≥ 2.5 SD above or below the participant’s mean MT (1.92%). The same criteria were used in the partial error analysis, except that partial errors were included, and in the forced-choice ER analysis, except that the errors were included. Trials were excluded in the error (3.10%) and partial error (4.08%) analyses if the RT and/or MT was ≥ 2.5 SD above or below the participant’s mean Apart from the trials that were excluded from all analyses, trials were also excluded from the free-choice RT/MT/participant’s decision analysis if a partial choice was made (7.63%), if the RT was ≥ 2.5 SD above or below the participant’s mean RT (1.76%) or if the MT was ≥ 2.5 SD above or below the participant’s mean MT (1.71%) on free-choice trials without partial choices. The same criteria were used for trial exclusion in the partial choice analysis, except that partial choices were included. In this analysis, 3.54% of the trials were excluded because the RT and/or MT was ≥ 2.5 SD above or below the participant’s mean Preregistered Data Analysis. RTs and MTs were analyzed with linear mixed-effects models (Bates et al., 2015) and p-values were calculated using the Satterthwaite correction for Kuznetsova et al., 2017). As a measure of effect size, we report the beta estimates and their 95% confidence interval. ERs, partial errors, partial choices, and the participant’s decision were analyzed with generalized mixed-effects models, using the binomial logit link function (Baayen et al., 2008; Bates et al., 2015). P-values were calculated using Wald Chi-Square tests for generalized mixed-effects models. We report the unsigned z-values and add the odds ratios and their 95% confidence interval as a measure of effect size. Type three sum of squares and contrast coding were used in all analyses. The random-effects structure of the models was determined through the procedure suggested by Scandola and Tidoni (2024) to balance type I and type II errors. This procedure fits complex random intercepts rather than random slopes, which allows us to fit more complex models without convergency or singularity issues (i.e., the statistical procedure fails to fit an optimal model with the given Models in Forced-Choice Trials. RTs and ERs were the primary measures of interest in forced-choice trials. MTs and partial errors were analyzed as secondary outcome measures. For trials in which only one agent moved, the moving agent’s eyesight (blindfolded, can see) factors. For trials in which the two agents looked in opposite directions, only the seeing agent’s congruency was included as a fixed within-subject factor. Because both agents made opposite movements, a congruent movement by the seeing agent implied an incongruent Models in Free-Choice Trials. For trials in which only one agent moved, the primary measure of interest for free-choice trials was the participant’s decision (not) to follow the moving agent. The agent’s eyesight (blindfolded, can see) was included as a fixed within- subject factor in this model. RTs, MTs, and partial choices were analyzed as secondary outcome measures. For these outcome measures, the participant’s decision (followed agent, did not follow agent) and the agent’s eyesight (blindfolded, can see) were included as fixed For trials in which the two agents looked in opposite directions, the primary measure of interest was the participant’s decision to follow the seeing agent (as opposed to the blindfolded agent). For this measure, only the intercept was included in the model. In the models for RTs, MTs, and partial choices, the participant’s decision (followed seeing agent, Confirmatory Analysis for Trials in Which One Agent Moved. Reaction Times on Forced-Choice Trials. The RT analysis revealed a main effect of congruency, F(1, 93) = 130.74, p < .001, b = 20.10, 95% CI [16.61, 23.60]. Participants were faster when the moving agent made a congruent movement (M = 597 ms, SD = 118 ms) compared to an incongruent movement (M = 637 ms, SD = 128 ms). There was no significant effect of the moving agent’s sight, F(1, 9975) = 0.17, p = .681, b = 0.65, 95% CI [-2.47, 3.77]. There was no significant interaction between the agent’s congruency and sight, F(1, 9974) = 0.43, p = .514, b = -1.04, 95% CI [-4.16, 2.08], on RTs, suggesting that the congruency effect did not differ for the seeing versus blindfolded agent. Figure 3A shows the congruency effect Error Rates on Forced-Choice Trials. The ER analysis (Figure 3B) revealed a significant effect of congruency on ERs, z = 5.32, p < .001, OR = 1.80, 95% CI [1.45, 2.23], with more errors for incongruent (M = 2.73%, SD = 3.91%) than congruent (M = 0.87%, SD = 1.64%) movements by the moving agent. There was no significant main effect of the moving agent’s sight, z = 1.33, p = .185, OR = 1.13, 95% CI [0.95, 1.34], and no significant interaction between congruency and sight of the agent, z = 1.12, p = .265, OR = 0.91, 95% CI Movement Times on Forced-Choice Trials. There was no significant effect of congruency on MTs, F(1, 10046) = 3.74, p = .053, b = -2.60, 95% CI [-5.24, 0.04]. Note that, numerically, this effect showed faster MTs for incongruent (M = 635 ms, SD = 143 ms) compared to congruent movements (M = 640 ms, SD = 146 ms), a pattern opposite to the significant congruency effects found in our primary outcome measures. There was no significant effect of the agent’s sight, F(1, 10045) = 0.67, p = .413, b = -1.10, 95% CI [-3.74, 1.54], nor a significant interaction effect, F(1, 10045) = 0.09, p = .761, b = 0.41, 95% CI [- Partial Errors on Forced-Choice Trials. The analysis of partial errors revealed a significant effect of congruency, z = 8.45, p < .001, OR = 1.45, 95% CI [1.33, 1.58]. Participants made more partial errors when the moving agent made incongruent (M = 11.09%, SD = 9.10%) compared to congruent movements (M = 5.68%, SD = 4.93%). We further found a significant main effect of the agent’s sight, z = 2.25, p = .025, OR = 0.92, 95% CI [0.86, 0.99], with more partial errors when the agent was blindfolded (M = 8.93%, SD = 6.95%) than when the agent could see (M = 7.84%, SD = 6.46%). In line with previous outcome measures, the interaction between the agent’s congruency and sight was non-significant, z = 0.50, p = The Participant’s Decision on Free-Choice Trials.  The analysis of the participants’ decision (not) to follow the moving agent (Figure 3C) revealed a significant intercept, z = 7.69, p < .001, OR = 1.33, 95% CI [1.24, 1.43]. Participants followed the moving agent in 57.02% (SD = 8.52%) of the trials, which is significantly more than the chance level. There was no significant effect of the moving agent’s sight on the participant’s decision, z = 0.27, p Reaction Times on Free-Choice Trials. There was a significant effect of the participants’ decision to follow the agent on RTs, F(1, 90) = 28.30, p < .001, b = 17.88, 95% CI [11.20, 24.55]. Participants had faster RTs when they followed the moving agent (M = 675 ms, SD = 158 ms) than when they did not follow the agent (M = 712 ms, SD = 169 ms). We found no effect of the agent’s sight, F(1, 4937) = 2.09, p = .148, b = 4.08, 95% CI [-1.45, 9.62], nor a significant interaction between the participant's decision and the agent’s sight, Movement Times on Free-Choice Trials.  There was no significant effect of the participant’s decision to follow the agent, F(1, 89) = 0.07, p = 0.797, b = -0.55, 95% CI [- 4.76, 3.66], or the sight of the agent, F(1, 4942) = 0.09, p = .759, b = -0.61, 95% CI [-4.54, 3.31], and no significant interaction effect, F(1, 4890) = 0.12, p = .730, b = -0.70, 95% CI [- Partial Choices on Free-Choice Trials. The analysis of partial choices revealed a significant effect of the participant’s decision to follow the moving agent on the number of partial choices, z = 5.88, p < .001, OR = 1.43, 95% CI [1.27, 1.61], with fewer direction changes when participants chose to follow the moving agent (M = 5.57%, SD = 5.97%) than",
         "https://biblio.ugent.be/publication/01JD53YTP2RKAS44E416FSWMXW/file/01JD54148HSWY3634VH3MMMV6V.pdf",
         "extracted",
         "None",
         "",
         "The impact of model eyesight and social reward on automatic imitation in virtual reality."
        ],
        [
         "22",
         "00912d6c3d3e9316039ba93baafbbdce9f19414a",
         "None",
         "Dr. Radha P,Akshayaa S,Vishnu Sree T",
         "\n**BLOCK**fs== 8.0**p== 0.0**b== 0.9**t== 0.1**l== 0.4**r== 0.4**\nContents lists available at ScienceDirect\n**BLOCK**fs== 13.9**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nInternational Journal of Human-Computer Studies\n**BLOCK**fs== 8.0**p== 0.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\njournal homepage: www.elsevier.com/locate/ijhcs\n**BLOCK**fs== 13.4**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nHistory and future of human-automation interaction\nChristian P. Janssena,⁎\n**BLOCK**fs== 10.6**p== 0.0**b== 0.7**t== 0.3**l== 0.2**r== 0.3**\n, Stella F. Donkera, Duncan P. Brumbyb, Andrew L. Kunc\n**BLOCK**fs== 6.4**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\na Utrecht University, Experimental Psychology and Helmholtz Institute, Heidelberglaan 1, Utrecht 3584 CS, the Netherlands\nb UCL Interaction Centre, University College London, London WC1E 6BT, United Kingdom\nc University of New Hampshire, Electrical and Computer Engineering, Kingsbury Hall, Durham, NH 03824, USA\n**BLOCK**fs== 7.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\nA R T I C L E I N F O\n**BLOCK**fs== 7.0**p== 0.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nA B S T R A C T\n**BLOCK**fs== 6.4**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.8**\nKeywords:\nAutomation\nHuman-automation interaction\nSafety-critical systems\nAutonomous agents\nEmbodied systems\nSituated systems\nDivided attention\nEthics\nRobotics, Automated vehicles\n**BLOCK**fs== 8.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n1. Introduction\n**BLOCK**fs== 7.2**p== 0.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nWe review the history of human-automation interaction research, assess its current status and identify future\ndirections. We start by reviewing articles that were published on this topic in the International Journal of\nHuman-Computer Studies during the last 50 years. We ﬁnd that over the years, automated systems have been\nused more frequently (1) in time-sensitive or safety-critical settings, (2) in embodied and situated systems, and\n(3) by non-professional users. Looking to the future, there is a need for human-automation interaction research\nto focus on (1) issues of function and task allocation between humans and machines, (2) issues of trust, incorrect\nuse, and confusion, (3) the balance between focus, divided attention and attention management, (4) the need for\ninterdisciplinary approaches to cover breadth and depth, (5) regulation and explainability, (6) ethical and social\ndilemmas, (7) allowing a human and humane experience, and (8) radically diﬀerent human-automation inter-\naction.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nThe concepts of automation, and mechanized and automated work\nhave been around for decades. According to the Britannica en-\ncyclopedia, automation is “the application of machines to tasks once\nperformed by human beings or, increasingly, to tasks that would otherwise be\nimpossible. Although the term mechanization is often used to refer to the\nsimple replacement of human labour by machines, automation generally\ninto a self-governing system.”\nimplies\n(Groover, 2018).\n**BLOCK**fs== 8.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nthe integration of machines\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nThe above deﬁnition of automation does not involve the require-\nment of a computer processor. However, many modern forms of auto-\nmated (or sometimes: autonomous) machines, such as power plant\nmonitoring devices, automated cars, drones, robots, and chatbots, do\ninvolve computers. These computer-automated systems are used by\nhumans, and humans are expected to remain essential contributors to\nartiﬁcial systems and automated systems in the future (Stone et al.,\n2016). The study of human-computer interaction, or more speciﬁcally\nhuman-automation interaction, therefore continues to remain relevant\nas automated systems are used to support more and more everyday\nactivities, overseen by non-technical and non-professional end-users.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nIn this special\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nissue to celebrate the 50th anniversary of the\nInternational Journal of Human-Computer Studies, and its predecessor\nthe International Journal of Man-Machine Studies (from now on\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.5**l== 0.5**r== 0.1**\ncollectively referred to as IJHCS), we review the contributions that\nIJHCS has made towards the study of human-automation interaction.\nWe therefore analyze published work from the journal to distill historic\ntrends. Our analysis shows that human-automation interaction is a ﬁeld\nthat keeps expanding into new domains and contexts (what we refer to\nas “breadth”), and also keeps improving its performance within do-\nmains and contexts (what we refer to as “depth”). Given these expan-\nsions, and the exposure to more contexts and to a wider and more di-\nverse group of end-users, there is a potential for the broader human-\ncomputer interaction community to contribute skills and knowledge to\ncreate and evaluate safe, engaging, and productive automated systems.\nWe close our analysis by discussing eight trends that we deem of\nparticular relevance for this community, classiﬁed in two segments.\nFirst, we discuss trends that have been around for a while but continue\nto remain important: (1) function and task allocation between humans\nand machines, (2) trust, incorrect use, and confusion, and (3) the bal-\nance between focus, divided attention and attention management.\nThen, we discuss emerging themes: (4) the need for interdisciplinary\napproaches to cover breadth and depth, (5) regulation and explain-\nability, (6) ethical and social dilemmas, (7) allowing a human and\nhumane experience, and (8) radically diﬀerent human-automation in-\nteraction.\n**BLOCK**fs== 7.2**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nCorresponding author.\nE-mail address: c.p.janssen@uu.nl (C.P. Janssen).\n**BLOCK**fs== 7.2**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nhttps://doi.org/10.1016/j.ijhcs.2019.05.006\nReceived 29 January 2019; Received in revised form 2 May 2019; Accepted 16 May 2019\n**BLOCK**fs== 7.2**p== 0.0**b== 0.0**t== 0.9**l== 0.1**r== 0.3**\nAvailable online 17 May 2019\n1071-5819/ © 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license\n(http://creativecommons.org/licenses/BY-NC-ND/4.0/).\n**BLOCK**fs== 7.2**p== 1.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nTable 1\nArticles in IJHCS that self-identiﬁed as covering automation, per decade compared to the total number of articles that appeared in the journal that year.\n**BLOCK**fs== 6.4**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nArticles on “automated”, “automation” or “autonomous” in IJHCS\nReference: total articles in IJHCS per decade\n**BLOCK**fs== 8.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\n2. History of human-automation interaction\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nTo gain an overview of the number of articles that were published\non the topic of human-automation interaction in IJHCS over its 50 year\nexistence, we conducted a Scopus search on January 14th 2019. We\ncollected all articles that had the word “automation”, “automated”, or\n“autonomous” in either the title, abstract, or keywords. Table 1 reports\nthe number of articles that matched the search query per topic and\ndecade, together with the total number of articles that was published in\nIJHCS that decade.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nThe topic of automation covers a substantial subset of the published\nwork in IJHCS: 4–11% of published articles in each decade, with\naround 5–6% of the articles in the last two decades. These percentages\nshould be interpreted as approximate values, as the count is limited by\nthe keywords that authors used in their paper's title, abstract and\nkeywords section. There might be false alarms (papers that were re-\nturned based on keywords, but that did not directly address research on\nhuman-automation interaction) and misses (papers that are relevant for\nthe ﬁeld of human-automation interaction, but did not include these\nspeciﬁc keywords).\n**BLOCK**fs== 8.0**p== 1.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nTo gain a richer understanding of the themes that are discussed in\nIJHCS papers on human-automation interaction, our initial keyword\nsearch was followed by a qualitative analysis. For this analysis, we\nsorted the IJHCS papers on human-automation interaction by year of\npublication. We then read the titles and abstracts of these papers to pick\nup common themes per decade. This revealed four themes which align\nwell with more general trends in artiﬁcial intelligence (e.g., Russell and\nNorvig, 2009, chapter 1) and human-computer interaction (e.g.,\nCarroll, 2013). However, as the analysis method is subjective in nature,\nand limited by the papers that were published in IJHCS, we do not\nclaim that we have identiﬁed all strands of human-automation inter-\naction research that occurred over the last ﬁve decades. We do claim\nthat we identiﬁed relevant themes, which are discussed in more detail\nnext.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\n2.1. Start: automation for dedicated domains\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nPublications on automation in IJHCS largely started oﬀ with the\nstudy of dedicated, domain speciﬁc systems. In the 1970s and 1980s a\nlarge proportion of published work (around 25 papers) focused speci-\nﬁcally on the development and evaluation of automated psychological\ntests (for overview papers, see e.g. Elithorn et al., 1982; Thompson and\nWilson, 1982). The widespread introduction of computers allowed\npsychology researchers to conduct interactive tasks on computers, in-\nstead of just pen-and-paper tests or subjective assessment. Nowadays,\ndigital testing is common in experimental studies involving human\nparticipants, and has given rise to opportunities for conducting large-\nscale studies using crowdsourcing platforms, like Amazon's Mechanical\nTurk (see Gould et al., 2018 for a review). Given the rise and ubiquity of\npersonal computing devices, the idea of completing an online survey\nwould now hardly qualify as an example of “automation” anymore.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nA second dedicated domain in which automation was researched is\nknowledge acquisition (Feigenbaum, 1977). As reviewed in a previous\nIJHCS special issue (Motta, 2013), one of the main aims within this\ndomain in the 1980s was to be able to develop methods to ‘extract’\nknowledge from experts that can be represented in machines. Among\nour dataset of papers on automation, the top-cited papers from the\n1980s all proposed methods for knowledge elicitation (e.g., Belkin\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\net al., 1987; Diederich et al., 1987; Gruber and Cohen, 1987). Since the\n1980s there has been a general shift in perspective that successful\nknowledge acquisition and knowledge engineering requires more than\nextracting knowledge. Considerations of systems engineering and al-\nlowing smart inferences based on multiple sources (e.g., through the\ninternet) are now seen to be key, with modern day knowledge acqui-\nsition research taking on a broad and multi-disciplinary perspective\n(see also Motta, 2013; Gaines, 2013; Breuker, 2013).\n**BLOCK**fs== 8.0**p== 1.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\n2.2. Time-sensitive and safety-critical settings\n**BLOCK**fs== 8.0**p== 1.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nThroughout the last ﬁve decades of IJHCS, automation research has\nbranched out into more domains and settings. One distinct class of re-\nsearch is on tasks that are time-sensitive (i.e., require a response within\na ﬁnite, short time interval) and/or safety-critical (i.e., where an in-\ncorrect action can have disastrous consequences). Work in this area has\nbeen published in every decade, but particularly in the 1990s and early\n2000s. The range of settings in which time-sensitive and safety-critical\ntasks have been studied is diverse and varied: from monitoring dynamic\nprocesses in factories (e.g., Lee and Moray, 1994), power plants (e.g.,\nVicente et al., 2001), and other professional settings (e.g., Bahner et al.,\n2008; van Gigh, 1971), to ﬂight monitoring (e.g., Singh et al., 1997;\nSkitka et al., 1999, 2000), and semi-automated driving (e.g., Rajaonah\net al., 2008, Seppelt and Lee, 2007).\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nThe diversity of domains (and the importance of preventing in-\ncidents) has allowed an exploration of deep general topics throughout\nthe history of IJHCS, which remain relevant for today's research. They\ninclude topics such as how to distribute or allocate tasks between hu-\nmans and machines (Dearden et al., 2000; Hollnagel and Bye, 2000;\nPress, 1971; Sheridan, 2000; de Vries et al., 2003; Milewski and Lewis,\n1997), ﬁnding the right levels of workload to avoid under- and overload\n(Van Gigh, 1971; Rajaonah et al., 2008), how to promote appropriate\nlevels of trust in automation (Dzindolet et al., 2003; Lee and Moray,\n1994), and how to avoid incorrect use and (human) errors such as\nthrough complacency (Bahner et al., 2008) or (human) biases (Skitka\net al., 1999, 2000). We will return to the current status of these topics in\nmore detail in our section on the future of human-automation inter-\naction.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\n2.3. Embodied, situated agents\n**BLOCK**fs== 8.0**p== 1.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nSince the 1990s there has been a gradual shift away from static\nsystems for speciﬁc domains (e.g., expert systems, systems for psycho-\nlogical testing) to systems that involve a dynamic intelligent agent that\nperforms a task (e.g., Milewski and Lewis, 1997; Zeng and Sycara,\n1998). This continues in the 2000s, with a rise of papers on automated\nsystems that act in a dynamic, physical world. This parallels the po-\npularization in Artiﬁcial Intelligence (AI) research of embodied, si-\ntuated agents (Pfeifer and Scheier, 2001): systems that have their own\nsensors and that depend on interaction with the environment for per-\nformance. For example, in the 2000s IJHCS published various studies\non physical robots (e.g., Kaber et al., 2006; Sakamoto et al., 2005) and\ncars (Rajaonah et al., 2008; Seppelt and Lee, 2007). In parallel, there is\nalso research published on aﬀective interaction with robots, and auto-\nmated (emotion) feature detection (e.g., Bailenson et al., 2008; Brave\net al., 2005; Partala and Surakka, 2003). These topics continue in the\n2010s, but also broaden out to include, for example, research on\nhuman-robot interaction with multiple robots (Chien et al., 2018).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nThe relevance of considering embodied and situated robotics and\nautomation explicitly is that the actions of embodied, situated systems\n(at least in part) depend on how the world is perceived through the\nmachine's sensors, and through the environment in which the machine\ninteracts (Pfeifer and Scheier, 2001). Diﬀerent machines can (learn to)\nact diﬀerently if either their sensors have diﬀerent capabilities or if they\nare trained in diﬀerent kinds of environments.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nthese embodied,\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nGeneralization to unknown settings, and adaptation to new settings,\nrequires extensive training for\nsituated robots.\nAutomated vehicles are an example of an embodied, situated robot that\nacts in and adapts to unknown settings. For automated vehicles,\ntraining typically consists of a combination of extensive experience\nunder real-world driving conditions, as well as extensive simulated\ntraining sessions to learn how to act\nin other potential worlds\n(Madrigal, 2017). By contrast, earlier simpler automated systems, such\nas, closed-world factory systems, or virtual systems such as a digital\npsychological test or expert system, require relatively less extensive\ntesting due to their reliance on the assumptions of a closed world.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\n2.4. Rise of the non-professional users\n**BLOCK**fs== 8.0**p== 2.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\nAs chips get smaller and gain more capacity, smart and automated\ntechnology is becoming more widely available for use by non-profes-\nsional users. These users have often not been trained in how to use or\noperate the system and often do not have a detailed technical under-\nstanding of how the automation works and the limitations on its suc-\ncessful operation. The last trend that we observe is then that there has\nbeen an increase in research on automation for use outside of profes-\nsional settings. For example, the availability of smart phones and other\nsmart devices that are connected to the internet and allow users to\ninteract with automated systems and processes. Some examples that are\ncovered in IJHCS include electronic shopping (e.g., Hassanein and\nHead, 2007), robots as social companions (e.g., Leite et al., 2013), and\ncontrol of semi-automated vehicles (e.g., Rajaonah et al., 2008; Seppelt\nand Lee, 2007).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nWhile many of the topics that apply to professional (skilled) users of\nautomated systems also apply to non-professional users, there are some\nadditional considerations that come into play for research on how non-\nprofessional users interact with automated systems. For example, for\nnon-professional users one cannot rely on extensive training and ex-\nperience with the technology, and the technology might be used in a\nwider set of context than that which can be predicted by the profession.\nStudy of use by non-professional users is therefore an emerging setting,\ndiscussed in more detail below that requires the full breadth of HCI\nexpertise. Moreover, the use by non-professional users requires further\nconsideration of more ethical topics such as human attitudes towards\nand acceptance of autonomous systems (Złotowski et al., 2017) and\nhow to handle security and hacking (Chen et al., 2018; Ferreira and\nTeles, 2019).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.6**\n2.5. Summary of human-automation interaction research to date\n**BLOCK**fs== 8.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nIn summary, our analysis of publications in IJHCS on the topic of\nhuman-automation interaction shows that research has expanded be-\nyond the use of automation in dedicated domains such as factory as-\nsembly lines and automated psychological tests. In particular, there are\ndistinct research lines that investigate the use of automation in time-\nsensitive or safety-critical settings, through embodied situated agents,\nand by non-professional users.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nFig. 1 provides a Venn diagram with examples of automated systems\nfor each of these research lines. The Venn diagram also makes explicit\nhow these diﬀerent areas ﬁt together. Speciﬁcally, it identiﬁes that\nthere are many domains and settings in which two or more of these\nresearch lines come together. A prime example is the automated car,\nwhich involves automation in the form of an embodied, situated agent,\nwhich is used by non-professional users in a time-sensitive, safety-\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.9**r== 0.1**\nPfeifer\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.8**r== 0.2**\nagents,\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nsituated\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.7**r== 0.3**\nembodied\n**BLOCK**fs== 8.0**p== 2.0**b== 0.8**t== 0.2**l== 0.6**r== 0.4**\nconsidered\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nFor embodied, situated systems some form of automation (or au-\ntonomy) is almost always required (although by deﬁnition, humans can\nalso\nand\nScheier, 2001). Hence in our Venn Diagram of Fig. 1, embodied, si-\ntuated agents are represented as a subset of the larger automation ca-\ntegory. Moreover, whether something is considered embodied and si-\ntuated might at times be open to interpretation. For example, we opted\nthat a power plant monitoring system is not labeled as embodied and\nsituated, even though such systems can sense and act to maintain a\nbalance in the power plant's processes (e.g.,\nincrease or decrease\ncooling). Our motivation for not including it as a fully embodied, si-\ntuated agent was that—from our understanding—these systems tend to\nrely on if-then rules and are less open to dynamic situations that our\nother examples (e.g., cars and military drones) face.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n3. Future of human-automation interaction: evergreen themes\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nWe now turn our attention to the future of human-automation in-\nteraction research, by describing themes that are important for future\nwork. We start by describing three themes that are “evergreens”:\nthemes that were also covered in the past, but that continue to be im-\nportant areas for research. In particular, these themes require further\nexpansion due to the breadth of domains and users that are involved in\nautomated settings. After discussing these evergreen topics, we go on to\ndiscuss ﬁve new topics in human-automation interaction that we expect\nto increase in importance over the coming years.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n3.1. Function and task allocation between humans and machines\n**BLOCK**fs== 8.0**p== 2.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nThe ﬁrst theme that has had persistent attention in IJHCS research\non automation is the distribution or allocation of tasks between humans\nand automated systems (e.g., Dearden et al., 2000; Hollnagel and Bye,\n2000; Press, 1971; Sheridan, 2000; de Vries et al., 2003; Milewski and\nLewis, 1997). A simple, naive understanding of the introduction of\nautomation might be that automated systems take over the execution of\ntasks from humans, and thereby simply ‘reduce’ the amount of work or\nattention that humans need to dedicate to that task. A colloquial un-\nderstanding is for example that people are better at some tasks (e.g., to\nexercise judgment) and machines are better at other tasks (e.g., to\nperform repetitive routine tasks; Fitts, 1951). However, as analyzed in\ndetail by Sheridan (2000), achieving such allocation in practice is a\nhard problem, as researchers diﬀer in what they set as appropriate\ncriteria for the function allocation.\n**BLOCK**fs== 8.0**p== 2.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nIn line with this view, it is important to consider the so-called “irony\nof automation” (Bainbridge, 1983), which states that introduction of\nautomation can radically change how people perceive or act in a spe-\nciﬁc context. People do not merely reduce what they work on when\n(part of) a task is automated, but use diﬀerent strategies for working on\nthat task altogether. For example, one intention of semi-automated\nvehicles is that the human driver is responsible for fewer basic control-\nmonitoring tasks (e.g., steering, pressing the gas), and can therefore\nswitch his or her attention to monitoring the traﬃc environment and\nthe vehicle. However, a meta-review of research on driving assistance\nsystems suggests that the introduction of automation increases the\nlikelihood that drivers perform non-driving related tasks, which reduces\ntheir situational awareness and response time to alerts (de Winter et al.,\n2014).\n**BLOCK**fs== 8.0**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nAlthough the problem of function allocation, and related themes,\nsuch as the irony of automation, have been known for decades, the\nassociated research questions gain new urgency now that automation is\nbeing used by non-professional users in time-sensitive and safety-cri-\ntical contexts. An underestimation of user interaction in these domains\ncan lead to incidents, and non-professional users might lack the training\nand experience to cope with system failures. Moreover, they might\nunderestimate risks or misplace their trust in the system. For example,\n**BLOCK**fs== 7.2**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nFig. 1. Venn Diagram of current types of human-automation interaction research (not to scale). Automated systems are developed for use by non-professional users,\nin time-sensitive or safety-critical systems. Embodied situated systems are a subset of automated systems that have seen a rise since the early 2000s.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nin the ﬁrst deadly incident with a Tesla model S (a partially automated\nvehicle), the human driver had a prolonged period of visual distraction\nshortly before the crash (Habib, 2017). Although the cause of this\ndistraction is unknown, misplaced trust in the automation might have\nbeen a factor.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nAutomation might also change how, when, and where tasks are\nperformed. For example, if cars become more automated, will they turn\ninto mobile oﬃces (Chuang et al., 2018), or areas of fun and play\n(Kun et al., 2016)? That is, automation might be a radical disruptive\ninnovation that changes more than just the task itself.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\n3.2. Trust, incorrect use, and confusion\n**BLOCK**fs== 8.0**p== 3.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nThe second major theme of human-automation interaction to have\nreceived persistent attention in IJHCS over the years is how to promote\nappropriate levels of trust in automation (Dzindolet et al., 2003; Lee\nand Moray, 1994), how to avoid incorrect use and (human) errors (e.g.,\nBahner et al., 2008; Skitka et al., 1999, 2000), and how to avoid con-\nfusion.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nParasuraman and Riley (1997) introduced four distinct types of use\nof automation that can impact a user's trust in a system. Initial use\nmight already depend on trust, but on top of that users and other sta-\nkeholders of automation might misuse the automation (i.e., show\noverreliance, or too much trust), disuse it (i.e., under rely on the auto-\nmation and distrust it, for example due to false alarms), or abuse it (i.e.,\nintroducing the automation without considering all the consequences of\nit, in line with the irony of automation, Bainbridge, 1983). These four\nforms of use, and their impact on trust are still relevant today. They are\nparticularly relevant now that non-professional users are using auto-\nmation in more settings. As they lack the training and experience of\nprofessional users, they might bring in incorrect expectations of the\ncapabilities of the automated system, resulting in misuse or disuse.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nHow a user uses automation, and how they perceive trust can also\nbe looked at more dynamically, based on a user's understanding of the\nsystem's mode of operation over time. The mode, or state, of an auto-\nmated system determines its response to user input and to changes in\nthe overall context of the system. For example, in automated vehicles,\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\ncruise control and adaptive cruise control can be two automation\nmodes. When human drivers or operators engage adaptive cruise con-\ntrol, their vehicle will attempt to maintain a given speed, but will slow\ndown if there is slower traﬃc ahead; in contrast the same vehicle with\n(non-adaptive) cruise control will not slow down for slower vehicles\nahead. The human operator needs to keep track of mode changes, and\nalso remember how the system will react to user input and context\nchanges in the current mode. Mode confusion (mode error) occurs when\nthe human operator is confused about the current mode of the system,\nor cannot remember how the system will react in the current mode\n(Sarter and Woods, 1992).\n**BLOCK**fs== 8.0**p== 3.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nMode confusion is highly consequential for safety-critical systems,\nsuch as road vehicles, power plants, airplanes, robotic wheelchairs, and\nﬂight control systems. In the above example, if the driver mistakenly\nbelieves that the vehicle is in the adaptive cruise control mode, when it\nis actually in (non-adaptive) cruise control (i.e., a form of misuse of\nautomation in Parasuraman and Riley's terms), the result can be a crash.\nJanssen et al. (2019) discuss this issue in the driving domain by in-\ntroducing a probabilistic (Hidden Markov Model) framework that re-\nlates driver beliefs of the system's mode to actual system modes. Such\nframeworks make explicit in what system states mode confusion might\noccur, and can aid in the (re-) design of safety-critical systems.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nhappen\n**BLOCK**fs== 8.0**p== 3.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nconfusion\n**BLOCK**fs== 8.0**p== 3.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\ncontexts.\nVicente et al. (2001) point out that power plants are highly complex\nsystems, which means that some part of the plant will always be under\nrepair or in a state of being modiﬁed. This eﬀectively changes the mode,\nor state, of the plant, and requires operators to act accordingly. Mode\nconfusion might result in a misinterpretation of alarms: depending on\nthe mode of the power plant, an alarm might indicate an actual problem\nor an expected state of operation.\n**BLOCK**fs== 8.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nIn the coming years, human interactions with automation will\ncontinue to be subject to mode confusion. The reason is twofold. First,\nautomation is not the same as autonomy: our automated systems will be\nvery good at what they do, but in some diﬃcult cases, or in legally\nmandated situations, they will require human intervention. Second,\nautomated systems will continue to be applied in a variety of complex\nsituations—after all, that is where they are the most useful. However,\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nuse in complex situations will result in multiple modes of operation\n(Sarter and Woods, 1995). Researchers need to focus on creating\nmodels of mode confusion for diﬀerent application areas,\n(e.g.\nJanssen et al., 2019). Such models can then be used in the design and\nevaluation of systems that reduce the frequency, and the consequences,\nof these errors.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\n3.3. Focus, divided attention, and attention management\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nA third theme that has had persistent attention in IJHCS research on\nautomation is creating appropriate workload levels for the human in-\nteracting with automation so as to avoid under- and overload (Van\nGigh, 1971; Rajaonah et al., 2008). Taking a broader perspective, one\ncan say there is a need to understand focus, divided attention, and at-\ntention management.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nAs automation continues to improve, automated tasks might require\nless human attention and intervention. This allows humans to focus on\nother activities, such as (other) work and play. At the same time, re-\nsearchers expect that humans will continue to play a role in automated\nsystems such as cars, even under higher levels of automation (e.g.,\nJanssen et al., 2019; Lee et al., 2017; Noy et al., 2018; Stone et al.,\n2016). For example, occasional human aid might be needed if the au-\ntomated system encounters an oﬀ-nominal scenario. In such a case,\nhumans need to revert their attention to the automated task, even\nthough they might feel that their preceding task was more urgent to\nthem. These situations require a detailed understanding of multitasking\nin IJHCS,\nand interleaving processes\nJanssen et al., 2015), and a new view on attention management.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n(see also special\n**BLOCK**fs== 8.0**p== 4.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nFocusing on automated vehicles, a large body of research has in-\nvestigated the eﬀectiveness of providing last-minute alerts to warn\ndrivers about situations where human assistance is needed. However, in\nsuch automated circumstances, people's susceptibility to alerts is re-\nduced (Van der Heiden et al., 2018; Lahmer et al., 2018; Scheer et al.,\n2018). Moreover, even if an alert is processed, mode confusion might\nlimit the human driver's understanding of their role and limit their\nability to take the right action (Janssen et al., 2019). Novel perspectives\non attention management might be needed to minimize these dangers.\nFor example, in our own work we have investigated the use of earlier\nwarnings (pre-alerts) to warn drivers before their action is critical\n(Van der Heiden et al., 2017; see also Borojeni et al., 2018). Beyond\nsimply providing warnings, more research is needed into how the\nhuman and the machine can be partners in a task, instead of one taking\nover the task of the other and only warning in case of emergency. The\nsuccess of such systems will rely both on the system's ability to assess\n(e.g., model and predict) the human state and understanding, and also\non the human's ability to understand the system's functioning.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n4. Future of human-automation interaction: emerging themes\n**BLOCK**fs== 8.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nTo close, we discuss ﬁve themes that are emerging as important\ntopics in automation research, and which we expect to increase in\nimportance over the years to come.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n4.1. Interdisciplinary studies to cover breadth and depth of domains and\nusers\n**BLOCK**fs== 8.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nOur review of the IJHCS literature has shown that over the past ﬁve\ndecades, research on human-automation interaction has broadened out\ninto diﬀerent areas. We expect that automated systems will continue to\nbroaden out into new domains as the principles and methods behind\nautomated technologies aimed at professional users start to penetrate\nthe broader consumer market aimed at non-professional users. For ex-\nample, automated features from commercial airplanes might make it\nover to non-commercial airplanes that are used by trained, but less\nexperienced pilots.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAt the same time, even though technology branches out, in a sense\n**BLOCK**fs== 8.0**p== 4.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nautomated technology is often still specialized and limited, and its ac-\ncuracy can be improved. In the home environment there are dedicated\nmachines for vacuuming, lawn mowing, or playing music, but few de-\nvices that combine such tasks. Personal virtual assistants like Amazon's\nAlexa, Apple's Siri, or Google Assistant can aid in many tasks, but have\nlimited capabilities (e.g., Cohen et al., 2016; Cowan et al., 2017). On\nthe road, automated cars can tackle ever more complex and demanding\nsituations, but still have exceptions where human assistance is needed.\nIn other words, there are opportunities for improvements in both the\n“depth” (i.e.\nimproving performance on speciﬁc tasks) and the\n“breadth” (i.e., how many tasks and contexts they can handle) of stu-\ndies on automated systems.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nAs part of the branching out, automated systems will be used more\nfrequently by non-professional users and with this comes a set of im-\nportant questions about human-automation interaction. For example,\nhow are users trained to work with automated safety-critical devices?\nHow are their skills on a task retained if it is not put to use frequently\n(see also Casner et al., 2014)? How are diﬀerent cultures, and diﬀerent\nnorms, customs, and conventions facilitated? Will the adoption and use\nof automated systems beneﬁt a variety of user groups (e.g., automated\nvehicles hold the potential for improved mobility for people who\ncannot drive or do not have access to their own vehicle)?\n**BLOCK**fs== 8.0**p== 4.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\n4.2. Regulation and explainability\n**BLOCK**fs== 8.0**p== 4.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nThe regulatory landscape for automation depends heavily on the\napplication area. Thus, regulation is well-developed for established\nﬁelds, such as for relatively simple medical devices. However, new\ninterconnected medical devices present a challenge for regulation\n(Sokolsky et al., 2011). Even more so, medical robotics, where auto-\nmation can take on various forms, presents a signiﬁcant challenge for\nregulators—in fact, autonomous robots will not only be medical devices\nbut also entities that practice medicine, and it is not yet clear who\nwould be in charge of regulating them (Yang et al., 2017). Similarly,\nregulation is still under development for cars, where automation is only\nnow making signiﬁcant advances (Inners and Kun, 2017).\n**BLOCK**fs== 8.0**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nA large push on automation research comes from European legis-\nlation on “explainability”. In the context of recent data protection laws,\nEuropean laws now require that decisions that are made for humans by\nautomated systems are explainable to the humans (European Union,\n2016, 2018; see also Goodman and Flaxman, 2017). Automated system\nand (machine learning) algorithms make many decisions, but the rea-\nsons\nthese decisions might be opaque to the end user\n(Burrell, 2016). Moreover, the (decision) models that the algorithms\ncreate to inform their actions necessarily abstract away from some\ndetails in the world. Such abstraction can result in ‘traps’ (Selbst et al.,\n2018) such as an inability to take all of the relevant features into ac-\ncount in decision making (as some were left out in the abstraction) or to\ntransfer learned behavior to new settings (where other features are\nperhaps more important).\n**BLOCK**fs== 8.0**p== 4.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nExplainability is not always straightforward for embodied, situated\nautomated systems such as automated cars, as these systems make\nmany decisions over time. For example, at any given time there is an\nexplicit or implicit decision to accelerate or decelerate, and whether to\nmake a steering adjustment (i.e., Michon's control level; Michon, 1985).\nShould cars be able to explain these decisions continuously? And should\nthis be done in real-time? Or should only more strategic decisions\n(Michon, 1985) such as why particular routes were chosen be ex-\nplainable? Or is only hindsight explanation needed surrounding (near-)\naccidents? Although ideally a system should be able to make multiple\nexplanations, whether they do this can impact a user's attention, and\nmight also have impact on system performance (i.e., when dedicating\ncapacity to the storing of decisions). From a human-computer interac-\ntion perspective, explainability of automated systems should at least be\npresent to avoid mode confusion (Janssen et al., 2019) and to avoid\nalert fatigue and the so-called “cry-wolf eﬀect” (Breznitz, 1983; Sorkin,\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nLike humans, automated machines are not always “perfect”. The\nalgorithms behind automated systems often get trained on data, and the\nresulting decision systems might be limited by the data (“Garbage in,\ngarbage out”). Speciﬁcally, through the training set, the algorithms\nmight pick up on biases or inequalities that exist in society, which can\nhave consequences for the end users. For example, if a gender classi-\nﬁcation algorithm is trained to classify people based on their physical\nfeatures, it might overlook that biological sex and self-identiﬁed gender\nlabels might not align, and the resulting misgendering might have ne-\ngative impacts on mental health (Hamidi et al., 2018).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nHumans might be able to help learning systems to overcome their\nbiases. For example, in recently proposed guidelines for human-AI in-\nteraction, ﬁve of the eighteen guidelines focus on ways to help users\ncorrect the mistakes of an AI system (Amershi et al., 2019). However, it\nis an open question how to design such systems in practice, in particular\nas there might be a disconnect between the low-level features that a\nsystem needs to adjust to improve, and the high-level concepts that a\nuser (incorrectly) thinks they need to adjust (e.g., Kittley-Davies et al.,\n2019).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nFrom a legislative perspective, an important question is then also\nwho is to blame when an accident or incident occurs involving an au-\ntomated system in a safety-critical setting. An initial thought might be\nto think locally, with the human operator or the producer, programmer,\nor seller of the technology. However, the introduction of automation is\nsometimes motivated by a narrative to reduce the frequency or prob-\nability of accidents and incidents. Approaching these from a probabil-\nistic viewpoint raises the question of what is an acceptable probability\nof risk, and how this risk is spread over the population. The con-\nsideration of risk at the population level, then turns the question of\n“who is to blame” into a question that is probably larger than one in-\ndividual.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n4.3. Ethical and social dilemmas\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nAs automated machines achieve more functionality, various ethical\nand social dilemmas become more urgent and prominent. Our overview\nof the history of IJHCS already touched on one such issue: are in-\ncreasingly\nequals\nautonomous\n(Złotowski et al., 2017)?\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\naccepted\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nsystems\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.6**l== 0.3**r== 0.7**\nsocially\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nAnother ethical and social consideration is that of the future of work\nand job security. A model by Frey and Osborne (2017) predicts that\nlow-skill and low-wage jobs, such as in transportation, logistics, and\noﬃce work, in particularly are likely to be replaced by automation.\nFrey and Osborne predict that this will require a shift in skillsets by\nhuman workers to tasks that require creativity or social skills. From our\nperspective, it is unclear whether this prediction will hold, as our lit-\nerature review of IJHCS articles indicates that research is already in-\nvestigating topics such as emotion classiﬁcation and social interaction\nbetween humans and robots (e.g., Brave et al., 2005; Hassanein and\nHead, 2007; Kapoor et al., 2007; Leite et al., 2013). Therefore, we ex-\npect that in the years to come there will be more progress on (partial)\nautomation of creative tasks and social interaction settings than an-\nticipated in the report by Frey and Osborne. If this happens, the ethical\nand social question of job security will be plainly evident.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nMoreover, automation might not increase at a steady, linear pace.\nFor example, Harari (2018) predicts that the pace of improvements in\nautomation might also accelerate as time goes on, thereby making it\never harder for people to catch up with the increasing changes in au-\ntomation and to adapt their skillset. How are humans then equipped for\nthese societal changes? How do we make sure that we create devices\nthat are there for human users? But also, how can technology help to\nachieve a world that provides opportunity for all, and not just for a\nfortunate minority?\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nAnother ethical consideration is what decisions automated systems\nshould take in complex life-or-death situations that are imminent in\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nsafety-critical scenarios. Survey research shows that humans would like\nautomated machines to make morally just decisions in principle, yet\nthey also want the system to deviate from this moral path if a moral\naction would require sacriﬁcing their own life or that of their family\nmembers (Bonnefon et al., 2016). Moreover, the survey research shows\nthat there are individual and cultural diﬀerences in what is considered\nmorally just (Awad et al., 2018). Given that humans cannot agree on\nmoral conﬂicts, a lot more research is needed to guide the regulation of\nautomated systems. For example, the Ethics Commission on Automated\nand Connected Driving, which was appointed by the German govern-\nment, has developed a set of twenty ethical rules related to the design,\ndeployment,\nvehicles\n(Ethics Commission, 2017).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.8**r== 0.1**\nautomated\n**BLOCK**fs== 8.0**p== 5.0**b== 0.7**t== 0.3**l== 0.7**r== 0.3**\nissues,\n**BLOCK**fs== 8.0**p== 5.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nTaken together, the full set of social and ethical considerations also\nposes a fundamental question: whether to automate at all or not? In\nmost safety-critical scenarios where automation is introduced, such as\nautomated driving, the intention is that introduction of automation or\nautomated support can save lives and reduce incidents. However, the\nnew technology can also introduce new problems and incidents. A\nmoral judgment is needed whether the beneﬁts weigh up against the\nchallenges. Although the inclination of some researchers might be to\nminimize new incidents, this might overlook the beneﬁts of automation\n(see also de Winter, 2019).\n**BLOCK**fs== 8.0**p== 5.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n4.4. Continued and improved human and humane experiences\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\nImplicit in the previously discussed trends is the need to consider\nhuman experience. With automation improving, how can we continue\nto maintain a fair and humane interaction (see also section on ethics)?\nWhich aspects of tasks do we automate, and which tasks do we leave to\nthe human? In line with the historical trend of automated testing (e.g.,\nElithorn et al., 1982; Thompson and Wilson, 1982) and expert systems\n(Motta, 2013; Gaines, 2013; Breuker, 2013), we might expect more\nsoftware tasks to become automated in the coming few years. But which\nparts are automated? How is creativity and expertise embedded cor-\nrectly? If creativity is essential for human contributions to an auto-\nmated task, how do we ensure that humans can contribute this, and\nhow do we know when and where it is needed? Or, if humans would\nlike to focus on other aspects of a task, apart from creativity, how do we\ncontinue to allow them to do so? For example, in a world where au-\ntomated vehicles have penetrated the market, will we allow occasional\nhuman driving “just for fun”? How can this be done in a world where\nother cars might rely on the predictability of non-human actions to\nmaintain a stable driving trajectory? If we do not allow humans to\ncontribute to such tasks and activities, how do we allow a humane\nexperience in other ways? The answers to these questions are not yet\nclear, but needed.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n4.5. Radical changes to human-automation interaction\n**BLOCK**fs== 8.0**p== 5.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nAs we look into the future, technological advances in human-ma-\nchine interaction, automation, artiﬁcial intelligence, and related dis-\nciplines are likely to usher in dramatic change in how we live with\ncomputing devices. Although such radical shifts are hard to predict\naccurately, some suggestions and trends are noticeable.\n**BLOCK**fs== 8.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nOne such change is imagined by Yuval Noah Harari in his book “21\nlessons for the 21st century” (Harari, 2018)—he envisions a world in\nwhich AI will become better than we are at many tasks. If this happens,\nthen one question for human-automation design will be how human\nusers can best use such super-smart AI. Will the humans enjoy the in-\nteractions and engage in them? Will they engage with AI while having\nthe appropriate level of trust, taking into account both the beneﬁts and\nthe potential costs of the interactions? Or will they act like the humans\nin Asimov's (1954) novel “Caves of Steel,” where the people of the Earth\nof about 1000 years in the future fear and reject robots, and the com-\nforts that robots can provide humanity?\n**BLOCK**fs== 8.0**p== 6.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nAnother dramatic change is envisioned by the futurist Mark\nPesce—he expects that we will be able to associate digital data with\nphysical objects and view this data through augmented reality glasses\n(Pesce, 2019). Pesce expects that this will lead to the emergence of\nwhat he calls ‘supertools’: tools that can allow us to interact with\ncomputing objects, and thus with the automation around us, while\nhaving at our disposal vast amounts of data about all aspects of the\nwork of automation. One signiﬁcant question for human-computer in-\nteraction design in this case is how to allow users to interact with this\nvast amount of data. Simply put, there will be too much data available\nfor users to be able to handle it all, which means that human-computer\ninteraction design will need to create focused views of the data.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nTurning to art again, and speciﬁcally the science ﬁction of Asimov:\nimagine what it might be like to interact with automation if our in-\nterface technologies can go beyond showing us information with aug-\nmented reality! What if the interfaces could make us feel like the ma-\nchine is an extension of our body? This is what it feels to operate an\nadvanced starship in Asimov's (1982) “Foundation's Edge”—the eﬀort\nrequired to accomplish something is about as much as to think about\nthe goal. Perhaps Asimov overestimated the probability that machines\nwill eventually be able to literally read our minds. But, we can still\nexpect that our minds and the machine automation will not always be\nseparated by keyboards, screens, and brittle speech interfaces. How will\nradically more capable interfaces aﬀect how we can control automa-\ntion, and just as importantly, how we perceive automation and its place\nin our lives?\n**BLOCK**fs== 8.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nAs we contemplate the inevitable radical changes in human-auto-\nmation interaction, it is important to keep asking questions. What are\nthe economic and societal forces that are driving the changes? How will\nnew technologies shape what is possible for these interactions? And\nwhat are the economic and broad societal implications of these dra-\nmatic changes? The answers to these questions will be found through\ninterdisciplinary work that\nincorporates a clear understanding of\nhuman-automation interaction, and leverages it eﬀectively.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nMany previous eras of human development have included radical\nchange in technology, but we expect the change to be faster than it had\nbeen in the past. Where will this change lead us? For all of the themes\nwe mentioned in this document, except for this last one, we have rea-\nsonably clear plans for how to move forward. For some of them, our\nhorizon extends relatively far, for others not that far.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nIn sum, human-automation interaction research has been an area of\nexciting and impactful work for many decades. The readers of IJHCS,\nand more broadly the scientiﬁc community, should expect this trend to\naccelerate in the coming years.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nDeclarations of interest\n**BLOCK**fs== 8.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.9**\nReferences\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nAmershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., Suh, J., Iqbal,\nS.T., Bennett, P.N., Inkpen, K., Teevan, J., Kikin-Gil, R., Horvitz, E., 2019. Guidelines\nfor human-AI interaction. In: Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems. ACM, New York, NY Paper 3.\nAsimov, Isaac, 1954. The Caves of Steel. Doubleday, New York, NY.\nAsimov, Isaac, 1982. Foundation's Edge. Doubleday, New York, NY.\nAwad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariﬀ, A., Bonnefon, J.F., Rawan, I.,\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\n2018. The moral machine experiment. Nature 563 (7729), 59–64.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nBahner, J.E., Hüper, A.D., Manzey, D., 2008. Misuse of automated decision aids: com-\nplacency, automation bias and the impact of training experience. Int. J. Hum.\nComput. Stud. 66 (9), 688–699.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nBailenson, J.N., Pontikakis, E.D., Mauss, I.B., Gross, J.J., Jabon, M.E., Hutcherson, C.A.,\nNass, C., John, O., 2008. Real-time classiﬁcation of evoked emotions using facial\nfeature tracking and physiological responses. Int. J. Hum. Comput. Stud. 66 (5),\n303–317.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nBainbridge, L., 1983. Ironies of automation. Automatica 19, 775–780.\nBelkin, N.J., Brooks, H.M., Daniels, P.J., 1987. Knowledge elicitation using discourse\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nanalysis. Int. J. Man Mach. Stud. 27 (2), 127–144.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nBonnefon, J.F., Shariﬀ, A., Rahwan, I., 2016. The social dilemma of autonomous vehicles.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.9**t== 0.1**l== 0.5**r== 0.1**\nBorojeni, S.S., Weber, L., Heuten, W., Boll, S., 2018. From reading to driving: priming\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nmobile users for take-over situations in highly automated driving. In: Proceedings of\nthe 20th International Conference on Human-Computer Interaction with Mobile\nDevices and Services (article 14). ACM Press, New York, NY.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nBrave, S., Nass, C., Hutchinson, K., 2005. Computers that care: investigating the eﬀects of\norientation of emotion exhibited by an embodied computer agent. Int. J. Hum.\nComput. Stud. 62 (2), 161–178.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nBreuker, J., 2013. A cognitive science perspective on knowledge acquisition. Int. J. Hum.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nComput. Stud. 71 (2), 177–183.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nBreznitz, S., 1983. Crywolf: The Psychology of False Alarms. Lawrence Erlbaum,\n**BLOCK**fs== 6.4**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nHillsdale, NJ.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nBurrell, J., 2016. How the machine ‘thinks’: understanding opacity in machine learning\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nalgorithms. Big Data Soc. 3 (1), 2053951715622512.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nCarroll, J.M. , 2013. Human computer interaction-brief intro. In: The Encyclopedia of\nHuman-Computer Interaction, 2nd Ed. https://www.interaction-design.org/\nliterature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/human-\ncomputer-interaction-brief-intro.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nCasner, S.M., Geven, R.W., Recker, M.P., Schooler, J.W., 2014. The retention of manual\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nﬂying skills in the automated cockpit. Hum. Factors 56 (8), 1506–1516.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nChen, J., Mishler, S., Hu, B., Li, N., Proctor, R.W., 2018. The description-experience gap in\nthe eﬀect of warning reliability on user trust and performance in a phishing detection\ncontext. Int. J. Hum. Comput. Stud. 119, 35–47.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nChien, S.Y., Lin, Y.L., Lee, P.J., Han, S., Lewis, M., Sycara, K., 2018. Attention allocation\nfor human multi-robot control: cognitive analysis based on behavior data and hidden\nstates. Int. J. Hum. Comput. Stud. 117, 30–44.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nChuang, L.L., Donker, S.F., Kun, A.L., Janssen, C.P., 2018. Workshop on the mobile oﬃce.\nIn: Adjunct Proceedings of the 10th International Conference on Automotive User\nInterfaces and Interactive Vehicular Applications. ACM Press, New York, NY, pp.\n10–16.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nCohen, P., Cheyer, A., Horvitz, E., El Kaliouby, R., Whittaker, S., 2016. On the future of\npersonal assistants. In: Proceedings of the SIGCHI Conference Extended Abstracts on\nHuman Factors in Computing Systems. ACM Press, New York, NY, pp. 1032–1037.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nCowan, B.R., Pantidi, N., Coyle, D., Morrissey, K., Clarke, P., Al-Shehri, S., Early, D.,\n**BLOCK**fs== 6.4**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nBandeira, N., 2017. What can I help you with?: infrequent users' experiences of in-\ntelligent personal assistants. In: Proceedings of the 19th International Conference on\nHuman-Computer Interaction with Mobile Devices and Services. ACM Press, New\nYork, NY, pp. 43.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nde Vries, P., Midden, C., Bouwhuis, D., 2003. The eﬀects of errors on system trust, self-\nconﬁdence, and the allocation of control in route planning. Int. J. Hum. Comput.\nStud. 58 (6), 719–735.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nde Winter, J.C.F., 2019. Pitfalls of automation: a faulty narrative? Commentary on\n**BLOCK**fs== 6.4**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nHancock (2019) some pitfalls in the promises of automated and autonomous vehicles.\nErgonomics 1–4.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nde Winter, J.C.F., Happee, R., Martens, M.H., Stanton, N.A., 2014. Eﬀects of adaptive\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\ncruise control and highly automated driving on workload and situation awareness: a\nreview of the empirical evidence. Transp. Res. Part F 27, 196–217.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nDearden, A., Harrison, M., Wright, P., 2000. Allocation of function: scenarios, context and\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nthe economics of eﬀort. Int. J. Hum. Comput. Stud. 52 (2), 289–318.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nDiederich, J., Ruhmann, I., May, M., 1987. KRITON: a knowledge-acquisition tool for\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nexpert systems. Int. J. Man Mach. Stud. 26 (1), 29–40.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nDzindolet, M.T., Peterson, S.A., Pomranky, R.A., Pierce, L.G., Beck, H.P., 2003. The role of\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\ntrust in automation reliance. Int. J. Hum. Comput. Stud. 58 (6), 697–718.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nElithorn, A., Mornington, S., Stavrou, A., 1982. Automated psychological testing: some\n**BLOCK**fs== 6.4**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nprinciples and practice. Int. J. Man Mach. Stud. 17 (3), 247–263.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nEthics Commission (2017) Automated and connected driving. Federal ministry of trans-\nport and digital infrastructure, Germany. Available online at: https://www.bmvi.de/\nSharedDocs/EN/publications/report-ethics-commission.html?nn=187598.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nEuropean Union (2016). Regulation (EU) 2016/679 of the European Parliament and of\nthe Council of 27 April 2016 on the protection of natural persons with regard to the\nprocessing of personal data and on the free movement of such data, and repealing\nDirective 95/46/EC (General Data Protection Regulation). http://data.europa.eu/eli/\nreg/2016/679/oj.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nFeigenbaum, E.A., The art of artiﬁcial intelligence: 1. Themes and case studies of\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nknowledge engineering. No. STAN-CS-77-621. Stanford Univ CA Dept of Computer\nScience, 1977. Available at: https://apps.dtic.mil/dtic/tr/fulltext/u2/a046289.pdf.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nEuropean Union (2018) Corrigendum to Regulation (EU) 2016/679 of the European\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nParliament and of the Council of 27 April 2016 on the protection of natural persons\nwith regard to the processing of personal data and on the free movement of such data,\nand repealing Directive 95/46/EC (General Data Protection Regulation). http://data.\neuropa.eu/eli/reg/2016/679/corrigendum/2018-05-23/oj.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nFerreira, A., Teles, S., 2019. Persuasion: how phishing emails can inﬂuence users and\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nbypass security measures. Int. J. Hum. Comput. Stud. 125, 19–31.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nFitts, P.M., 1951. Human Engineering for an Eﬀective Air Navigation and Traﬃc Control\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nSystem. National Research Council, Washington, DC.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nFrey, C.B., Osborne, M.A., 2017. The future of employment: how susceptible are jobs to\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.8**l== 0.5**r== 0.2**\ncomputerisation? Technol. Forecast. Soc. Change 114, 254–280.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nGaines, B.R., 2013. Knowledge acquisition: past, present and future. Int. J. Hum. Comput.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nGoodman, B., Flaxman, S., 2017. European Union regulations on algorithmic decision-\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.2**\nmaking and a “right to explanation”. AI Mag. 38 (3), 50–57.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nGould, S.J., Cox, A.L., Brumby, D.P., 2018. Inﬂuencing and measuring behaviour in\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\ncrowdsourced activities. In: Filimowicz, M., Tzankova, V. (Eds.), New Directions in\nThird Wave Human-Computer Interaction: Volume 2-Methodologies. Springer, pp.\n103–130.\n**BLOCK**fs== 6.4**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nGroover, M.P., 2018. Automation. Encyclopædia Britannica. Encyclopædia Britannica,\n**BLOCK**fs== 6.4**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\ninc. Accessed online on 26 January 2019, at. https://www.britannica.com/\ntechnology/automation.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nGruber, T.R., Cohen, P.R., 1987. Design for acquisition: principles of knowledge-system\ndesign to facilitate knowledge acquisition. Int. J. Man Mach. Stud. 26 (2), 143–159.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nHabib, K., 2017. Automatic Vehicle Control Systems. National Highway Traﬃc Safety\nAdministration, Department of Transportation, pp. 1–13. Technical Report PE 16-\n007pages. Available online at: https://static.nhtsa.gov/odi/inv/2016/INCLA-\nPE16007-7876.PDF.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nHamidi, F., Scheuerman, M.K., Branham, S.M., 2018. Gender recognition or gender re-\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nductionism?: the social implications of embedded gender recognition systems. In:\nProceedings of the SIGCHI Conference on Human Factors in Computing Systems\n(paper 8). ACM Press, New York, NY.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nHarari, Y.N., 2018. 21 Lessons for the 21st Century. Random House.\nHassanein, K., Head, M., 2007. Manipulating perceived social presence through the web\ninterface and its impact on attitude towards online shopping. Int. J. Hum. Comput.\nStud. 65 (8), 689–708.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nHollnagel, E., Bye, A., 2000. Principles for modelling function allocation. Int. J. Hum.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nComput. Stud. 52 (2), 253–265.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nInners, M, Kun, A, 2017. Beyond liability: legal issues of human-machine interaction for\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nautomated vehicles. In: Proceedings of the 9th International Conference on\nAutomotive User Interfaces and Interactive Vehicular Applications. ACM Press, New\nYork, NY, pp. 245–253.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nJanssen, C.P., Boyle, L., Kun, A.L., Ju, W., Chuang, L.L., 2019. A hidden markov frame-\nwork to capture human–machine interaction in automated vehicles. Int. J. Hum.\nComput. Interact. https://doi.org/10.1080/10447318.2018.1561789.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nJanssen, C.P., Gould, S.J.J., Li, S.Y.W., Brumby, D.R., Cox, A.L., 2015. Integrating\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nknowledge of multitasking and interruptions across diﬀerent perspectives and re-\nsearch methods. Int. J. Hum. Comput. Stud. 79, 1–5.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nKaber, D.B., Wright, M.C., Sheik-Nainar, M.A., 2006. Investigation of multi-modal in-\nterface features for adaptive automation of a human–robot system. Int. J. Hum.\nComput. Stud. 64 (6), 527–540.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nKapoor, A., Burleson, W., Picard, R.W., 2007. Automatic prediction of frustration. Int. J.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nHum. Comput. Stud. 65 (8), 724–736.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nSelbst, A.D., Boyd, D., Friedler, S.A., Venkatasubramanian, S., Vertesi, J., 2018. Fairness\nand abstraction in sociotechnical systems. In: Proceedings of the Conference on\nFairness, Accountability, and Transparency. ACM Press, New York, NY, pp. 59–68.\nSeppelt, B.D., Lee, J.D., 2007. Making adaptive cruise control (ACC) limits visible. Int. J.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nHum. Comput. Stud. 65 (3), 192–205.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nSheridan, T.B., 2000. Function allocation: algorithm, alchemy or apostasy? Int. J. Hum.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nComput. Stud. 52 (2), 203–216.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nSingh, I.L., Molloy, R., Parasuraman, R., 1997. Automation-induced monitoring in-\neﬃciency: role of display location. Int. J. Hum. Comput. Stud. 46 (1), 17–30.\nSkitka, L.J., Mosier, K., Burdick, M.D., 2000. Accountability and automation bias. Int. J.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nHum. Comput. Stud. 52 (4), 701–717.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nSkitka, L.J., Mosier, K.L., Burdick, M., 1999. Does automation bias decision-making? Int.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\nJ. Hum. Comput. Stud. 51 (5), 991–1006.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nSokolsky, O., Lee, I., Heimdahl, M., 2011. Challenges in the regulatory approval of\nmedical cyber-physical systems. In: Proceedings of the Ninth ACM International\nConference on Embedded Software, pp. 227–232.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nSorkin, R.D., 1989. Why are people turning oﬀ our alarms. Hum. Factors Bull. 32 (4), 3–4.\nStone, P., Brooks, R., Brynjolfsson, E., Calo, R., Etzioni, O., Hager, G., et al., 2016.\nArtiﬁcial Intelligence and Life in 2030. Stanford University, Stanford, CA.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nThompson, J.A., Wilson, S.L., 1982. Automated psychological testing. Int. J. Man Mach.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nvan der Heiden, R.M., Iqbal, S.T., Janssen, C.P., 2017. Priming drivers before handover in\nsemi-autonomous cars. In: Proceedings of the SIGCHI Conference on Human Factors\nin Computing Systems. ACM Press, New York, NY, pp. 392–404.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nvan der Heiden, R.M., Janssen, C.P., Donker, S.F., Hardeman, L.E., Mans, K., Kenemans,\nJ.L., 2018. Susceptibility to audio signals during autonomous driving. PloS One 13\n(8), e0201963.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nvan Gigch, J.P., 1971. Changes in the mental content of work exempliﬁed by lumber\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nsorting operationst. Int. J. Man Mach. Stud. 3 (1), 13–29.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nVicente, Kim J., Roth, E.M., Mumaw, R.J., 2001. How do operators monitor a complex,\ndynamic work domain? The impact of control room technology. Int. J. Hum. Comput.\nStud. 54 (6), 831–856.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nKittley-Davies, J., Alqaraawi, A., Yang, R., Costanza, E., Rogers, A., Stein, S., 2019.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nYang, G.Z., Cambias, J., Cleary, K., Daimler, E., Drake, J., Dupont, P.E., et al., 2017.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nEvaluating the eﬀect of feedback from diﬀerent computer vision processing stages: a\ncomparative lab study. In: Proceedings of the SIGCHI Conference on Human Factors\nin Computing Systems Proceedings. ACM Press, New York, NY Paper 43.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nMedical robotics—regulatory, ethical, and legal considerations for increasing levels\nof autonomy. Sci. Robot. 2 (4), 8638.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nZeng, D., Sycara, K., 1998. Bayesian learning in negotiation. Int. J. Hum. Comput. Stud.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nKun, A.L., Boll, S., Schmidt, A., 2016. Shifting gears: user interfaces in the age of au-\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nZłotowski, J., Yogeeswaran, K., Bartneck, C., 2017. Can we control it? Autonomous robots\nthreaten human identity, uniqueness, safety, and resources. In. J. Hum. Comput.\nStud. 100, 48–54.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.5**l== 0.7**r== 0.1**\nChristian P. Janssen is an assistant professor of experi-\nmental psychology at Utrecht University. He received his\nPhD in human-computer interaction from UCL (2012).\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.7**l== 0.7**r== 0.1**\nStella F. Donker is an associate professor of experimental\npsychology at Utrecht University. She received her PhD in\nmedical sciences from the University of Groningen (2002).\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\ntonomous vehicles. IEEE Pervasive Comput. 15, 32–38.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nLahmer, M., Glatz, C., Seibold, V.C., Chuang, L.L., 2018. Looming auditory collision\nwarnings for semi-automated driving: an ERP study. In: Proceedings of the 10th\nInternational Conference on Automotive User Interfaces and Interactive Vehicular\nApplications. ACM Press, New York, NY, pp. 310–319.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nLee, J.D., Moray, N., 1994. Trust, self-conﬁdence, and operators' adaptation to automa-\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.7**\ntion. Int. J. Hum. Comput. Stud. 40 (1), 153–184.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nLee, J.D., Wickens, C.D., Liu, Y., Boyle, L.N., 2017. Human-automation interaction. In:\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nLee, Wickens, Liu, Boyle (Eds.), Designing for People: An Introduction to Human\nFactors Engineering. CreateSpace, Charleston, SC.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nLeite, I., Pereira, A., Mascarenhas, S., Martinho, C., Prada, R., Paiva, A., 2013. The in-\nﬂuence of empathy in human–robot relations. Int. J. Hum. Comput. Stud. 71 (3),\n250–260.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nMadrigal, A. (2017). Inside Waymo's secret world for training self-driving cars. The\n**BLOCK**fs== 6.4**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nAtlantic (August 23, 2017). Available online at:https://www.theatlantic.com/\ntechnology/archive/2017/08/inside-waymos-secret-testing-and-simulation-\nfacilities/537648/.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nMichon, J.A., 1985. A critical view of driver behavior models: what do we know, what\nshould we do? Human Behavior and Traﬃc Safety. Springer, Boston, MA, pp.\n485–524.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nMilewski, A.E., Lewis, S.H., 1997. Delegating to software agents. Int. J. Hum. Comput.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nMotta, E., 2013. 25 years of knowledge acquisition. Int. J. Hum. Comput. Stud. 71 (2),\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nNoy, I.Y., Shinar, D., Horrey, W.J., 2018. Automated driving: safety blind spots. Saf. Sci.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nParasuraman, R., Riley, V., 1997. Humans and automation: use, misuse, disuse, abuse.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\nHum. Factors 39 (2), 230–253.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nPartala, T., Surakka, V., 2003. Pupil size variation as an indication of aﬀective processing.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nInt. J. Hum. Comput. Stud. 59 (1–2), 185–198.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nPesce, M. (2019). Supertools. Retrieved on 26 April 2019 fromhttps://youtu.be/\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.9**\nftYgdpnfc-g.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nPfeifer, R., Scheier, C., 2001. Understanding Intelligence. MIT press, Cambridge, MA.\nPress, L., 1971. Toward balanced man-machine systems. Int. J. Man Mach. Stud. 3 (1),\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nRajaonah, B., Tricot, N., Anceaux, F., Millot, P., 2008. The role of intervening variables in\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\ndriver—ACC cooperation. Int. J. Hum. Comput. Stud. 66 (3), 185–197.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nRussell, S., Norvig, P., 2009. Artiﬁcial Intelligence: A Modern Approach, 3rd ed. Prentice\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.7**\nHall Press, Upper Saddle River, NJ, USA.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nSakamoto, D., Kanda, T., Ono, T., Kamashima, M., Imai, M., Ishiguro, H., 2005.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nCooperative embodied communication emerged by interactive humanoid robots. Int.\nJ. Hum. Comput. Stud. 62 (2), 247–265.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nSarter, N.B., Woods, D.D., 1992. Mode error in supervisory control of automated systems.\nIn: Proceedings of the Human Factors and Ergonomics Society Annual Meeting. 36.\npp. 26–29 Sage CA: Los Angeles, CA: SAGE Publications, 1992.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nSarter, N.B., Woods, D.D., 1995. How in the world did we ever get into that mode? Mode\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nerror and awareness in supervisory control. Hum. Factors 37 (1), 5–19.\n**BLOCK**fs== 6.4**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nScheer, M., Bülthoﬀ, H.H., Chuang, L.L., 2018. Auditory task irrelevance: a basis for\n**BLOCK**fs== 6.4**p== 8.0**b== 0.8**t== 0.1**l== 0.2**r== 0.5**\nDuncan P. Brumby is a reader of Human-Computer\nInteraction at University College London (UCL). He re-\nceived his PhD in psychology from Cardiﬀ University.\n**BLOCK**fs== 6.4**p== 8.0**b== 0.8**t== 0.1**l== 0.7**r== 0.1**\nAndrew L. Kun is an associate professor of electrical and\ncomputer engineering at the University of New Hampshire.\nHe received his PhD in electrical engineering from the\nUniversity of New Hampshire (1997).",
         "Contents lists available at ScienceDirect International Journal of Human-Computer Studies journal homepage: www.elsevier.com/locate/ijhcs History and future of human-automation interaction Christian P. Janssena,⁎ , Stella F. Donkera, Duncan P. Brumbyb, Andrew L. Kunc The concepts of automation, and mechanized and automated work have been around for decades. According to the Britannica en- cyclopedia, automation is “the application of machines to tasks once performed by human beings or, increasingly, to tasks that would otherwise be impossible. Although the term mechanization is often used to refer to the simple replacement of human labour by machines, automation generally into a self-governing system.” implies (Groover, 2018). the integration of machines The above deﬁnition of automation does not involve the require- ment of a computer processor. However, many modern forms of auto- mated (or sometimes: autonomous) machines, such as power plant monitoring devices, automated cars, drones, robots, and chatbots, do involve computers. These computer-automated systems are used by humans, and humans are expected to remain essential contributors to artiﬁcial systems and automated systems in the future (Stone et al., 2016). The study of human-computer interaction, or more speciﬁcally human-automation interaction, therefore continues to remain relevant as automated systems are used to support more and more everyday activities, overseen by non-technical and non-professional end-users. In this special issue to celebrate the 50th anniversary of the International Journal of Human-Computer Studies, and its predecessor the International Journal of Man-Machine Studies (from now on collectively referred to as IJHCS), we review the contributions that IJHCS has made towards the study of human-automation interaction. We therefore analyze published work from the journal to distill historic trends. Our analysis shows that human-automation interaction is a ﬁeld that keeps expanding into new domains and contexts (what we refer to as “breadth”), and also keeps improving its performance within do- mains and contexts (what we refer to as “depth”). Given these expan- sions, and the exposure to more contexts and to a wider and more di- verse group of end-users, there is a potential for the broader human- computer interaction community to contribute skills and knowledge to create and evaluate safe, engaging, and productive automated systems. We close our analysis by discussing eight trends that we deem of particular relevance for this community, classiﬁed in two segments. First, we discuss trends that have been around for a while but continue to remain important: (1) function and task allocation between humans and machines, (2) trust, incorrect use, and confusion, and (3) the bal- ance between focus, divided attention and attention management. Then, we discuss emerging themes: (4) the need for interdisciplinary approaches to cover breadth and depth, (5) regulation and explain- ability, (6) ethical and social dilemmas, (7) allowing a human and humane experience, and (8) radically diﬀerent human-automation in- teraction. 2. History of human-automation interaction To gain an overview of the number of articles that were published on the topic of human-automation interaction in IJHCS over its 50 year existence, we conducted a Scopus search on January 14th 2019. We collected all articles that had the word “automation”, “automated”, or “autonomous” in either the title, abstract, or keywords. Table 1 reports the number of articles that matched the search query per topic and decade, together with the total number of articles that was published in IJHCS that decade. The topic of automation covers a substantial subset of the published work in IJHCS: 4–11% of published articles in each decade, with around 5–6% of the articles in the last two decades. These percentages should be interpreted as approximate values, as the count is limited by the keywords that authors used in their paper's title, abstract and keywords section. There might be false alarms (papers that were re- turned based on keywords, but that did not directly address research on human-automation interaction) and misses (papers that are relevant for the ﬁeld of human-automation interaction, but did not include these speciﬁc keywords). To gain a richer understanding of the themes that are discussed in IJHCS papers on human-automation interaction, our initial keyword search was followed by a qualitative analysis. For this analysis, we sorted the IJHCS papers on human-automation interaction by year of publication. We then read the titles and abstracts of these papers to pick up common themes per decade. This revealed four themes which align well with more general trends in artiﬁcial intelligence (e.g., Russell and Norvig, 2009, chapter 1) and human-computer interaction (e.g., Carroll, 2013). However, as the analysis method is subjective in nature, and limited by the papers that were published in IJHCS, we do not claim that we have identiﬁed all strands of human-automation inter- action research that occurred over the last ﬁve decades. We do claim that we identiﬁed relevant themes, which are discussed in more detail next. 2.1. Start: automation for dedicated domains Publications on automation in IJHCS largely started oﬀ with the study of dedicated, domain speciﬁc systems. In the 1970s and 1980s a large proportion of published work (around 25 papers) focused speci- ﬁcally on the development and evaluation of automated psychological tests (for overview papers, see e.g. Elithorn et al., 1982; Thompson and Wilson, 1982). The widespread introduction of computers allowed psychology researchers to conduct interactive tasks on computers, in- stead of just pen-and-paper tests or subjective assessment. Nowadays, digital testing is common in experimental studies involving human participants, and has given rise to opportunities for conducting large- scale studies using crowdsourcing platforms, like Amazon's Mechanical Turk (see Gould et al., 2018 for a review). Given the rise and ubiquity of personal computing devices, the idea of completing an online survey would now hardly qualify as an example of “automation” anymore. A second dedicated domain in which automation was researched is knowledge acquisition (Feigenbaum, 1977). As reviewed in a previous IJHCS special issue (Motta, 2013), one of the main aims within this domain in the 1980s was to be able to develop methods to ‘extract’ knowledge from experts that can be represented in machines. Among our dataset of papers on automation, the top-cited papers from the 1980s all proposed methods for knowledge elicitation (e.g., Belkin et al., 1987; Diederich et al., 1987; Gruber and Cohen, 1987). Since the 1980s there has been a general shift in perspective that successful knowledge acquisition and knowledge engineering requires more than extracting knowledge. Considerations of systems engineering and al- lowing smart inferences based on multiple sources (e.g., through the internet) are now seen to be key, with modern day knowledge acqui- sition research taking on a broad and multi-disciplinary perspective (see also Motta, 2013; Gaines, 2013; Breuker, 2013). 2.2. Time-sensitive and safety-critical settings Throughout the last ﬁve decades of IJHCS, automation research has branched out into more domains and settings. One distinct class of re- search is on tasks that are time-sensitive (i.e., require a response within a ﬁnite, short time interval) and/or safety-critical (i.e., where an in- correct action can have disastrous consequences). Work in this area has been published in every decade, but particularly in the 1990s and early 2000s. The range of settings in which time-sensitive and safety-critical tasks have been studied is diverse and varied: from monitoring dynamic processes in factories (e.g., Lee and Moray, 1994), power plants (e.g., Vicente et al., 2001), and other professional settings (e.g., Bahner et al., 2008; van Gigh, 1971), to ﬂight monitoring (e.g., Singh et al., 1997; Skitka et al., 1999, 2000), and semi-automated driving (e.g., Rajaonah et al., 2008, Seppelt and Lee, 2007). The diversity of domains (and the importance of preventing in- cidents) has allowed an exploration of deep general topics throughout the history of IJHCS, which remain relevant for today's research. They include topics such as how to distribute or allocate tasks between hu- mans and machines (Dearden et al., 2000; Hollnagel and Bye, 2000; Press, 1971; Sheridan, 2000; de Vries et al., 2003; Milewski and Lewis, 1997), ﬁnding the right levels of workload to avoid under- and overload (Van Gigh, 1971; Rajaonah et al., 2008), how to promote appropriate levels of trust in automation (Dzindolet et al., 2003; Lee and Moray, 1994), and how to avoid incorrect use and (human) errors such as through complacency (Bahner et al., 2008) or (human) biases (Skitka et al., 1999, 2000). We will return to the current status of these topics in more detail in our section on the future of human-automation inter- action. 2.3. Embodied, situated agents Since the 1990s there has been a gradual shift away from static systems for speciﬁc domains (e.g., expert systems, systems for psycho- logical testing) to systems that involve a dynamic intelligent agent that performs a task (e.g., Milewski and Lewis, 1997; Zeng and Sycara, 1998). This continues in the 2000s, with a rise of papers on automated systems that act in a dynamic, physical world. This parallels the po- pularization in Artiﬁcial Intelligence (AI) research of embodied, si- tuated agents (Pfeifer and Scheier, 2001): systems that have their own sensors and that depend on interaction with the environment for per- formance. For example, in the 2000s IJHCS published various studies on physical robots (e.g., Kaber et al., 2006; Sakamoto et al., 2005) and cars (Rajaonah et al., 2008; Seppelt and Lee, 2007). In parallel, there is also research published on aﬀective interaction with robots, and auto- mated (emotion) feature detection (e.g., Bailenson et al., 2008; Brave et al., 2005; Partala and Surakka, 2003). These topics continue in the 2010s, but also broaden out to include, for example, research on human-robot interaction with multiple robots (Chien et al., 2018). The relevance of considering embodied and situated robotics and automation explicitly is that the actions of embodied, situated systems (at least in part) depend on how the world is perceived through the machine's sensors, and through the environment in which the machine interacts (Pfeifer and Scheier, 2001). Diﬀerent machines can (learn to) act diﬀerently if either their sensors have diﬀerent capabilities or if they are trained in diﬀerent kinds of environments. these embodied, Generalization to unknown settings, and adaptation to new settings, requires extensive training for situated robots. Automated vehicles are an example of an embodied, situated robot that acts in and adapts to unknown settings. For automated vehicles, training typically consists of a combination of extensive experience under real-world driving conditions, as well as extensive simulated training sessions to learn how to act in other potential worlds (Madrigal, 2017). By contrast, earlier simpler automated systems, such as, closed-world factory systems, or virtual systems such as a digital psychological test or expert system, require relatively less extensive testing due to their reliance on the assumptions of a closed world. 2.4. Rise of the non-professional users As chips get smaller and gain more capacity, smart and automated technology is becoming more widely available for use by non-profes- sional users. These users have often not been trained in how to use or operate the system and often do not have a detailed technical under- standing of how the automation works and the limitations on its suc- cessful operation. The last trend that we observe is then that there has been an increase in research on automation for use outside of profes- sional settings. For example, the availability of smart phones and other smart devices that are connected to the internet and allow users to interact with automated systems and processes. Some examples that are covered in IJHCS include electronic shopping (e.g., Hassanein and Head, 2007), robots as social companions (e.g., Leite et al., 2013), and control of semi-automated vehicles (e.g., Rajaonah et al., 2008; Seppelt and Lee, 2007). While many of the topics that apply to professional (skilled) users of automated systems also apply to non-professional users, there are some additional considerations that come into play for research on how non- professional users interact with automated systems. For example, for non-professional users one cannot rely on extensive training and ex- perience with the technology, and the technology might be used in a wider set of context than that which can be predicted by the profession. Study of use by non-professional users is therefore an emerging setting, discussed in more detail below that requires the full breadth of HCI expertise. Moreover, the use by non-professional users requires further consideration of more ethical topics such as human attitudes towards and acceptance of autonomous systems (Złotowski et al., 2017) and how to handle security and hacking (Chen et al., 2018; Ferreira and Teles, 2019). 2.5. Summary of human-automation interaction research to date In summary, our analysis of publications in IJHCS on the topic of human-automation interaction shows that research has expanded be- yond the use of automation in dedicated domains such as factory as- sembly lines and automated psychological tests. In particular, there are distinct research lines that investigate the use of automation in time- sensitive or safety-critical settings, through embodied situated agents, and by non-professional users. Fig. 1 provides a Venn diagram with examples of automated systems for each of these research lines. The Venn diagram also makes explicit how these diﬀerent areas ﬁt together. Speciﬁcally, it identiﬁes that there are many domains and settings in which two or more of these research lines come together. A prime example is the automated car, which involves automation in the form of an embodied, situated agent, which is used by non-professional users in a time-sensitive, safety- agents, situated embodied considered For embodied, situated systems some form of automation (or au- tonomy) is almost always required (although by deﬁnition, humans can also and Scheier, 2001). Hence in our Venn Diagram of Fig. 1, embodied, si- tuated agents are represented as a subset of the larger automation ca- tegory. Moreover, whether something is considered embodied and si- tuated might at times be open to interpretation. For example, we opted that a power plant monitoring system is not labeled as embodied and situated, even though such systems can sense and act to maintain a balance in the power plant's processes (e.g., increase or decrease cooling). Our motivation for not including it as a fully embodied, si- tuated agent was that—from our understanding—these systems tend to rely on if-then rules and are less open to dynamic situations that our other examples (e.g., cars and military drones) face. 3. Future of human-automation interaction: evergreen themes We now turn our attention to the future of human-automation in- teraction research, by describing themes that are important for future work. We start by describing three themes that are “evergreens”: themes that were also covered in the past, but that continue to be im- portant areas for research. In particular, these themes require further expansion due to the breadth of domains and users that are involved in automated settings. After discussing these evergreen topics, we go on to discuss ﬁve new topics in human-automation interaction that we expect to increase in importance over the coming years. 3.1. Function and task allocation between humans and machines The ﬁrst theme that has had persistent attention in IJHCS research on automation is the distribution or allocation of tasks between humans and automated systems (e.g., Dearden et al., 2000; Hollnagel and Bye, 2000; Press, 1971; Sheridan, 2000; de Vries et al., 2003; Milewski and Lewis, 1997). A simple, naive understanding of the introduction of automation might be that automated systems take over the execution of tasks from humans, and thereby simply ‘reduce’ the amount of work or attention that humans need to dedicate to that task. A colloquial un- derstanding is for example that people are better at some tasks (e.g., to exercise judgment) and machines are better at other tasks (e.g., to perform repetitive routine tasks; Fitts, 1951). However, as analyzed in detail by Sheridan (2000), achieving such allocation in practice is a hard problem, as researchers diﬀer in what they set as appropriate criteria for the function allocation. In line with this view, it is important to consider the so-called “irony of automation” (Bainbridge, 1983), which states that introduction of automation can radically change how people perceive or act in a spe- ciﬁc context. People do not merely reduce what they work on when (part of) a task is automated, but use diﬀerent strategies for working on that task altogether. For example, one intention of semi-automated vehicles is that the human driver is responsible for fewer basic control- monitoring tasks (e.g., steering, pressing the gas), and can therefore switch his or her attention to monitoring the traﬃc environment and the vehicle. However, a meta-review of research on driving assistance systems suggests that the introduction of automation increases the likelihood that drivers perform non-driving related tasks, which reduces their situational awareness and response time to alerts (de Winter et al., 2014). Although the problem of function allocation, and related themes, such as the irony of automation, have been known for decades, the associated research questions gain new urgency now that automation is being used by non-professional users in time-sensitive and safety-cri- tical contexts. An underestimation of user interaction in these domains can lead to incidents, and non-professional users might lack the training and experience to cope with system failures. Moreover, they might underestimate risks or misplace their trust in the system. For example, in the ﬁrst deadly incident with a Tesla model S (a partially automated vehicle), the human driver had a prolonged period of visual distraction shortly before the crash (Habib, 2017). Although the cause of this distraction is unknown, misplaced trust in the automation might have been a factor. Automation might also change how, when, and where tasks are performed. For example, if cars become more automated, will they turn into mobile oﬃces (Chuang et al., 2018), or areas of fun and play (Kun et al., 2016)? That is, automation might be a radical disruptive innovation that changes more than just the task itself. 3.2. Trust, incorrect use, and confusion The second major theme of human-automation interaction to have received persistent attention in IJHCS over the years is how to promote appropriate levels of trust in automation (Dzindolet et al., 2003; Lee and Moray, 1994), how to avoid incorrect use and (human) errors (e.g., Bahner et al., 2008; Skitka et al., 1999, 2000), and how to avoid con- fusion. Parasuraman and Riley (1997) introduced four distinct types of use of automation that can impact a user's trust in a system. Initial use might already depend on trust, but on top of that users and other sta- keholders of automation might misuse the automation (i.e., show overreliance, or too much trust), disuse it (i.e., under rely on the auto- mation and distrust it, for example due to false alarms), or abuse it (i.e., introducing the automation without considering all the consequences of it, in line with the irony of automation, Bainbridge, 1983). These four forms of use, and their impact on trust are still relevant today. They are particularly relevant now that non-professional users are using auto- mation in more settings. As they lack the training and experience of professional users, they might bring in incorrect expectations of the capabilities of the automated system, resulting in misuse or disuse. How a user uses automation, and how they perceive trust can also be looked at more dynamically, based on a user's understanding of the system's mode of operation over time. The mode, or state, of an auto- mated system determines its response to user input and to changes in the overall context of the system. For example, in automated vehicles, cruise control and adaptive cruise control can be two automation modes. When human drivers or operators engage adaptive cruise con- trol, their vehicle will attempt to maintain a given speed, but will slow down if there is slower traﬃc ahead; in contrast the same vehicle with (non-adaptive) cruise control will not slow down for slower vehicles ahead. The human operator needs to keep track of mode changes, and also remember how the system will react to user input and context changes in the current mode. Mode confusion (mode error) occurs when the human operator is confused about the current mode of the system, or cannot remember how the system will react in the current mode (Sarter and Woods, 1992). Mode confusion is highly consequential for safety-critical systems, such as road vehicles, power plants, airplanes, robotic wheelchairs, and ﬂight control systems. In the above example, if the driver mistakenly believes that the vehicle is in the adaptive cruise control mode, when it is actually in (non-adaptive) cruise control (i.e., a form of misuse of automation in Parasuraman and Riley's terms), the result can be a crash. Janssen et al. (2019) discuss this issue in the driving domain by in- troducing a probabilistic (Hidden Markov Model) framework that re- lates driver beliefs of the system's mode to actual system modes. Such frameworks make explicit in what system states mode confusion might occur, and can aid in the (re-) design of safety-critical systems. happen confusion contexts. Vicente et al. (2001) point out that power plants are highly complex systems, which means that some part of the plant will always be under repair or in a state of being modiﬁed. This eﬀectively changes the mode, or state, of the plant, and requires operators to act accordingly. Mode confusion might result in a misinterpretation of alarms: depending on the mode of the power plant, an alarm might indicate an actual problem or an expected state of operation. In the coming years, human interactions with automation will continue to be subject to mode confusion. The reason is twofold. First, automation is not the same as autonomy: our automated systems will be very good at what they do, but in some diﬃcult cases, or in legally mandated situations, they will require human intervention. Second, automated systems will continue to be applied in a variety of complex situations—after all, that is where they are the most useful. However, use in complex situations will result in multiple modes of operation (Sarter and Woods, 1995). Researchers need to focus on creating models of mode confusion for diﬀerent application areas, (e.g. Janssen et al., 2019). Such models can then be used in the design and evaluation of systems that reduce the frequency, and the consequences, of these errors. 3.3. Focus, divided attention, and attention management A third theme that has had persistent attention in IJHCS research on automation is creating appropriate workload levels for the human in- teracting with automation so as to avoid under- and overload (Van Gigh, 1971; Rajaonah et al., 2008). Taking a broader perspective, one can say there is a need to understand focus, divided attention, and at- tention management. As automation continues to improve, automated tasks might require less human attention and intervention. This allows humans to focus on other activities, such as (other) work and play. At the same time, re- searchers expect that humans will continue to play a role in automated systems such as cars, even under higher levels of automation (e.g., Janssen et al., 2019; Lee et al., 2017; Noy et al., 2018; Stone et al., 2016). For example, occasional human aid might be needed if the au- tomated system encounters an oﬀ-nominal scenario. In such a case, humans need to revert their attention to the automated task, even though they might feel that their preceding task was more urgent to them. These situations require a detailed understanding of multitasking in IJHCS, and interleaving processes Janssen et al., 2015), and a new view on attention management. (see also special Focusing on automated vehicles, a large body of research has in- vestigated the eﬀectiveness of providing last-minute alerts to warn drivers about situations where human assistance is needed. However, in such automated circumstances, people's susceptibility to alerts is re- duced (Van der Heiden et al., 2018; Lahmer et al., 2018; Scheer et al., 2018). Moreover, even if an alert is processed, mode confusion might limit the human driver's understanding of their role and limit their ability to take the right action (Janssen et al., 2019). Novel perspectives on attention management might be needed to minimize these dangers. For example, in our own work we have investigated the use of earlier warnings (pre-alerts) to warn drivers before their action is critical (Van der Heiden et al., 2017; see also Borojeni et al., 2018). Beyond simply providing warnings, more research is needed into how the human and the machine can be partners in a task, instead of one taking over the task of the other and only warning in case of emergency. The success of such systems will rely both on the system's ability to assess (e.g., model and predict) the human state and understanding, and also on the human's ability to understand the system's functioning. 4. Future of human-automation interaction: emerging themes To close, we discuss ﬁve themes that are emerging as important topics in automation research, and which we expect to increase in importance over the years to come. 4.1. Interdisciplinary studies to cover breadth and depth of domains and users Our review of the IJHCS literature has shown that over the past ﬁve decades, research on human-automation interaction has broadened out into diﬀerent areas. We expect that automated systems will continue to broaden out into new domains as the principles and methods behind automated technologies aimed at professional users start to penetrate the broader consumer market aimed at non-professional users. For ex- ample, automated features from commercial airplanes might make it over to non-commercial airplanes that are used by trained, but less experienced pilots. At the same time, even though technology branches out, in a sense automated technology is often still specialized and limited, and its ac- curacy can be improved. In the home environment there are dedicated machines for vacuuming, lawn mowing, or playing music, but few de- vices that combine such tasks. Personal virtual assistants like Amazon's Alexa, Apple's Siri, or Google Assistant can aid in many tasks, but have limited capabilities (e.g., Cohen et al., 2016; Cowan et al., 2017). On the road, automated cars can tackle ever more complex and demanding situations, but still have exceptions where human assistance is needed. In other words, there are opportunities for improvements in both the “depth” (i.e. improving performance on speciﬁc tasks) and the “breadth” (i.e., how many tasks and contexts they can handle) of stu- dies on automated systems. As part of the branching out, automated systems will be used more frequently by non-professional users and with this comes a set of im- portant questions about human-automation interaction. For example, how are users trained to work with automated safety-critical devices? How are their skills on a task retained if it is not put to use frequently (see also Casner et al., 2014)? How are diﬀerent cultures, and diﬀerent norms, customs, and conventions facilitated? Will the adoption and use of automated systems beneﬁt a variety of user groups (e.g., automated vehicles hold the potential for improved mobility for people who cannot drive or do not have access to their own vehicle)? 4.2. Regulation and explainability The regulatory landscape for automation depends heavily on the application area. Thus, regulation is well-developed for established ﬁelds, such as for relatively simple medical devices. However, new interconnected medical devices present a challenge for regulation (Sokolsky et al., 2011). Even more so, medical robotics, where auto- mation can take on various forms, presents a signiﬁcant challenge for regulators—in fact, autonomous robots will not only be medical devices but also entities that practice medicine, and it is not yet clear who would be in charge of regulating them (Yang et al., 2017). Similarly, regulation is still under development for cars, where automation is only now making signiﬁcant advances (Inners and Kun, 2017). A large push on automation research comes from European legis- lation on “explainability”. In the context of recent data protection laws, European laws now require that decisions that are made for humans by automated systems are explainable to the humans (European Union, 2016, 2018; see also Goodman and Flaxman, 2017). Automated system and (machine learning) algorithms make many decisions, but the rea- sons these decisions might be opaque to the end user (Burrell, 2016). Moreover, the (decision) models that the algorithms create to inform their actions necessarily abstract away from some details in the world. Such abstraction can result in ‘traps’ (Selbst et al., 2018) such as an inability to take all of the relevant features into ac- count in decision making (as some were left out in the abstraction) or to transfer learned behavior to new settings (where other features are perhaps more important). Explainability is not always straightforward for embodied, situated automated systems such as automated cars, as these systems make many decisions over time. For example, at any given time there is an explicit or implicit decision to accelerate or decelerate, and whether to make a steering adjustment (i.e., Michon's control level; Michon, 1985). Should cars be able to explain these decisions continuously? And should this be done in real-time? Or should only more strategic decisions (Michon, 1985) such as why particular routes were chosen be ex- plainable? Or is only hindsight explanation needed surrounding (near-) accidents? Although ideally a system should be able to make multiple explanations, whether they do this can impact a user's attention, and might also have impact on system performance (i.e., when dedicating capacity to the storing of decisions). From a human-computer interac- tion perspective, explainability of automated systems should at least be present to avoid mode confusion (Janssen et al., 2019) and to avoid alert fatigue and the so-called “cry-wolf eﬀect” (Breznitz, 1983; Sorkin, Like humans, automated machines are not always “perfect”. The algorithms behind automated systems often get trained on data, and the resulting decision systems might be limited by the data (“Garbage in, garbage out”). Speciﬁcally, through the training set, the algorithms might pick up on biases or inequalities that exist in society, which can have consequences for the end users. For example, if a gender classi- ﬁcation algorithm is trained to classify people based on their physical features, it might overlook that biological sex and self-identiﬁed gender labels might not align, and the resulting misgendering might have ne- gative impacts on mental health (Hamidi et al., 2018). Humans might be able to help learning systems to overcome their biases. For example, in recently proposed guidelines for human-AI in- teraction, ﬁve of the eighteen guidelines focus on ways to help users correct the mistakes of an AI system (Amershi et al., 2019). However, it is an open question how to design such systems in practice, in particular as there might be a disconnect between the low-level features that a system needs to adjust to improve, and the high-level concepts that a user (incorrectly) thinks they need to adjust (e.g., Kittley-Davies et al., 2019). From a legislative perspective, an important question is then also who is to blame when an accident or incident occurs involving an au- tomated system in a safety-critical setting. An initial thought might be to think locally, with the human operator or the producer, programmer, or seller of the technology. However, the introduction of automation is sometimes motivated by a narrative to reduce the frequency or prob- ability of accidents and incidents. Approaching these from a probabil- istic viewpoint raises the question of what is an acceptable probability of risk, and how this risk is spread over the population. The con- sideration of risk at the population level, then turns the question of “who is to blame” into a question that is probably larger than one in- dividual. 4.3. Ethical and social dilemmas As automated machines achieve more functionality, various ethical and social dilemmas become more urgent and prominent. Our overview of the history of IJHCS already touched on one such issue: are in- creasingly equals autonomous (Złotowski et al., 2017)? accepted systems socially Another ethical and social consideration is that of the future of work and job security. A model by Frey and Osborne (2017) predicts that low-skill and low-wage jobs, such as in transportation, logistics, and oﬃce work, in particularly are likely to be replaced by automation. Frey and Osborne predict that this will require a shift in skillsets by human workers to tasks that require creativity or social skills. From our perspective, it is unclear whether this prediction will hold, as our lit- erature review of IJHCS articles indicates that research is already in- vestigating topics such as emotion classiﬁcation and social interaction between humans and robots (e.g., Brave et al., 2005; Hassanein and Head, 2007; Kapoor et al., 2007; Leite et al., 2013). Therefore, we ex- pect that in the years to come there will be more progress on (partial) automation of creative tasks and social interaction settings than an- ticipated in the report by Frey and Osborne. If this happens, the ethical and social question of job security will be plainly evident. Moreover, automation might not increase at a steady, linear pace. For example, Harari (2018) predicts that the pace of improvements in automation might also accelerate as time goes on, thereby making it ever harder for people to catch up with the increasing changes in au- tomation and to adapt their skillset. How are humans then equipped for these societal changes? How do we make sure that we create devices that are there for human users? But also, how can technology help to achieve a world that provides opportunity for all, and not just for a fortunate minority? Another ethical consideration is what decisions automated systems should take in complex life-or-death situations that are imminent in safety-critical scenarios. Survey research shows that humans would like automated machines to make morally just decisions in principle, yet they also want the system to deviate from this moral path if a moral action would require sacriﬁcing their own life or that of their family members (Bonnefon et al., 2016). Moreover, the survey research shows that there are individual and cultural diﬀerences in what is considered morally just (Awad et al., 2018). Given that humans cannot agree on moral conﬂicts, a lot more research is needed to guide the regulation of automated systems. For example, the Ethics Commission on Automated and Connected Driving, which was appointed by the German govern- ment, has developed a set of twenty ethical rules related to the design, deployment, vehicles (Ethics Commission, 2017). automated issues, Taken together, the full set of social and ethical considerations also poses a fundamental question: whether to automate at all or not? In most safety-critical scenarios where automation is introduced, such as automated driving, the intention is that introduction of automation or automated support can save lives and reduce incidents. However, the new technology can also introduce new problems and incidents. A moral judgment is needed whether the beneﬁts weigh up against the challenges. Although the inclination of some researchers might be to minimize new incidents, this might overlook the beneﬁts of automation (see also de Winter, 2019). 4.4. Continued and improved human and humane experiences Implicit in the previously discussed trends is the need to consider human experience. With automation improving, how can we continue to maintain a fair and humane interaction (see also section on ethics)? Which aspects of tasks do we automate, and which tasks do we leave to the human? In line with the historical trend of automated testing (e.g., Elithorn et al., 1982; Thompson and Wilson, 1982) and expert systems (Motta, 2013; Gaines, 2013; Breuker, 2013), we might expect more software tasks to become automated in the coming few years. But which parts are automated? How is creativity and expertise embedded cor- rectly? If creativity is essential for human contributions to an auto- mated task, how do we ensure that humans can contribute this, and how do we know when and where it is needed? Or, if humans would like to focus on other aspects of a task, apart from creativity, how do we continue to allow them to do so? For example, in a world where au- tomated vehicles have penetrated the market, will we allow occasional human driving “just for fun”? How can this be done in a world where other cars might rely on the predictability of non-human actions to maintain a stable driving trajectory? If we do not allow humans to contribute to such tasks and activities, how do we allow a humane experience in other ways? The answers to these questions are not yet clear, but needed. 4.5. Radical changes to human-automation interaction As we look into the future, technological advances in human-ma- chine interaction, automation, artiﬁcial intelligence, and related dis- ciplines are likely to usher in dramatic change in how we live with computing devices. Although such radical shifts are hard to predict accurately, some suggestions and trends are noticeable. One such change is imagined by Yuval Noah Harari in his book “21 lessons for the 21st century” (Harari, 2018)—he envisions a world in which AI will become better than we are at many tasks. If this happens, then one question for human-automation design will be how human users can best use such super-smart AI. Will the humans enjoy the in- teractions and engage in them? Will they engage with AI while having the appropriate level of trust, taking into account both the beneﬁts and the potential costs of the interactions? Or will they act like the humans in Asimov's (1954) novel “Caves of Steel,” where the people of the Earth of about 1000 years in the future fear and reject robots, and the com- forts that robots can provide humanity? Another dramatic change is envisioned by the futurist Mark Pesce—he expects that we will be able to associate digital data with physical objects and view this data through augmented reality glasses (Pesce, 2019). Pesce expects that this will lead to the emergence of what he calls ‘supertools’: tools that can allow us to interact with computing objects, and thus with the automation around us, while having at our disposal vast amounts of data about all aspects of the work of automation. One signiﬁcant question for human-computer in- teraction design in this case is how to allow users to interact with this vast amount of data. Simply put, there will be too much data available for users to be able to handle it all, which means that human-computer interaction design will need to create focused views of the data. Turning to art again, and speciﬁcally the science ﬁction of Asimov: imagine what it might be like to interact with automation if our in- terface technologies can go beyond showing us information with aug- mented reality! What if the interfaces could make us feel like the ma- chine is an extension of our body? This is what it feels to operate an advanced starship in Asimov's (1982) “Foundation's Edge”—the eﬀort required to accomplish something is about as much as to think about the goal. Perhaps Asimov overestimated the probability that machines will eventually be able to literally read our minds. But, we can still expect that our minds and the machine automation will not always be separated by keyboards, screens, and brittle speech interfaces. How will radically more capable interfaces aﬀect how we can control automa- tion, and just as importantly, how we perceive automation and its place in our lives? As we contemplate the inevitable radical changes in human-auto- mation interaction, it is important to keep asking questions. What are the economic and societal forces that are driving the changes? How will new technologies shape what is possible for these interactions? And what are the economic and broad societal implications of these dra- matic changes? The answers to these questions will be found through interdisciplinary work that incorporates a clear understanding of human-automation interaction, and leverages it eﬀectively. Many previous eras of human development have included radical change in technology, but we expect the change to be faster than it had been in the past. Where will this change lead us? For all of the themes we mentioned in this document, except for this last one, we have rea- sonably clear plans for how to move forward. For some of them, our horizon extends relatively far, for others not that far. In sum, human-automation interaction research has been an area of exciting and impactful work for many decades. The readers of IJHCS, and more broadly the scientiﬁc community, should expect this trend to accelerate in the coming years. Declarations of interest",
         "https://dspace.library.uu.nl/bitstream/handle/1874/390597/1_s2.0_S1071581919300552_main.pdf?sequence=1&isAllowed=y",
         "extracted",
         "None",
         "",
         "History and Future of Human-Automation Interaction"
        ],
        [
         "23",
         "00a9a436e7eb5e57de9231fc28b57e8452f45f4c",
         "Research on microbial communities colonizing animals has revealed that the microbiota, despite its typical containment to surfaces, influences virtually all organ systems of the host. In absence of a natural microbiota, the host’s development can be disturbed, but how developmental programs are affected by the microbiota is still poorly understood. Removing the microbiota from Hydra, a classic model animal in developmental biology, causes drastic developmental malformations and leads to polyps that temporarily lack the ability to bud. Recolonizing non-budding germfree Hydra with bacteria reverses this budding inhibition. Single-nucleus ATAC-seq detected a unique chromatin landscape associated with the non-budding phenotype. Single-cell RNA-seq and trajectory-based differential expression analysis showed that epithelial stem cell decision making is disturbed in non-budding polyps, whereby key developmental regulators are not expressed. This process is reversible by adding back bacteria. Transcriptionally silencing of one of the genes that failed to be activated in non-budding animals, GAPR1, led to polyps that have a significantly reduced budding capacity. The results show that maintaining a species-specific microbiota may enable the animal host to maintain its developmental program. Significance Statement Animal developmental programs work within the context of coevolved associations with microbes. Here, we provide mechanistic evidence of the involvement of the microbiota in maintaining the pattern formation program of Hydra with the asexual formation of buds in the lower part of the body column. We demonstrate that in the absence of bacteria both the epigenetic and transcriptomic landscape is changed and that key regulatory factors are not expressed, causing changes in stem cell trajectories that result in loss of budding capacity. This study provides a new perspective on the role that microbiota plays during animal development and evolution. One Sentence Summary Microbiota interfere with Hydra’s asexual reproduction via modulating its stem cell differentiation programs.",
         "Jinru He,A. Klimovich,Sabine Kock,Linus Dahmke,Sören Franzenburg,Thomas C. G. Bosch",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/21/2024.08.20.608462.full.pdf",
         "None",
         "None",
         "The Role of Lung and Gut Microbiota in the Pathology of Asthma;Mouse Microbiota Models: Comparing Germ-Free Mice and Antibiotics Treatment as Tools for Modifying Gut Bacteria;Punctuated Emergences of Genetic and Phenotypic Innovations in Eumetazoan, Bilaterian, Euteleostome, and Hominidae Ancestors;EST Analysis of the Cnidarian Acropora millepora Reveals Extensive Gene Loss and Rapid Sequence Divergence in the Model Invertebrates;Elimination by Hydra interstitial and nerve cells by means of colchicine.",
         "The microbiota affects stem cell decision making in Hydra"
        ],
        [
         "24",
         "00b75582f7204b1bae67a6c5f2fa1652d94c7ce0",
         "Protein engineering holds significant promise for designing proteins with customized functions, yet the vast landscape of potential mutations versus limited lab capacity constrains the discovery of optimal sequences. To address this, we present the µProtein framework, which accelerates protein engineering by combining µFormer, a deep learning model for accurate mutational effect prediction, with µSearch, a reinforcement learning algorithm designed to efficiently navigate the protein fitness landscape using µFormer as an oracle. µProtein leverages single mutation data to predict optimal sequences with complex, multi-amino acid mutations through its modeling of epistatic interactions and a multistep search strategy. Except from state-of-the-art performance on benchmark datasets, µProtein identified high-gain-of-function multi-point mutants for the enzyme β-lactamase, surpassing the highest known activity level, in wet-lab, trained solely on single mutation data. These results demonstrate µProtein’s capability to discover impactful mutations across vast protein sequence space, offering a robust, efficient approach for protein optimization.",
         "Haoran Sun,Liang He,Pan Deng,Guoqing Liu,Zhiyu Zhao,Yuliang Jiang,Chuan Cao,Fusong Ju,Lijun Wu,Haiguang Liu,Tao Qin,Tie-Yan Liu",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2023/11/17/2023.11.16.565910.full.pdf",
         "None",
         "None",
         "Network of epistatic interactions in an enzyme active site revealed by large-scale deep mutational scanning;Contrastive Fitness Learning: Reprogramming Protein Language Models for Low-N Learning of Protein Fitness Landscape;Convolutions are competitive with transformers for protein sequence pretraining;ProteinNPT: Improving Protein Property Prediction and Design with Non-Parametric Transformers;Self-play reinforcement learning guides protein engineering;Improving protein optimization with smoothed fitness landscapes;Efficient evolution of human antibodies from general protein language models;Enzyme function prediction using contrastive learning;Evolutionary-scale prediction of atomic level protein structure with a language model;Learning Epistasis and Residue Coevolution Patterns: Current Trends and Future Perspectives for Advancing Enzyme Engineering;SPRoBERTa: protein embedding learning with local fragment modeling;Insertions and Deletions (Indels): A Missing Piece of the Protein Engineering Jigsaw.;Proximal Exploration for Model-guided Protein Sequence Design;Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval;Mapping the energetic and allosteric landscapes of protein binding domains;Machine learning-aided engineering of hydrolases for PET depolymerization;Training language models to follow instructions with human feedback;Learning protein fitness models from evolutionary and assay-labeled data;Can AlphaFold2 predict the impact of missense mutations on structure?;FLIP: Benchmark tasks in fitness landscape inference for proteins;Pre-training Co-evolutionary Protein Representation via A Pairwise Masked Language Model;Disease variant prediction with deep generative models of evolutionary data;ECNet is an evolutionary context-integrated deep learning framework for protein engineering;Highly accurate protein structure prediction with AlphaFold;Language models enable zero-shot prediction of the effects of mutations on protein function;Deep diversification of an AAV capsid protein by machine learning;GPT-3: Its Nature, Scope, Limits, and Consequences;Is Transfer Learning Necessary for Protein Landscape Prediction?;Neural networks to learn protein sequence–function relationships from deep mutational scanning data;AdaLead: A simple and robust adaptive greedy search algorithm for sequence design;The genetic landscape for amyloid beta fibril nucleation accurately discriminates familial Alzheimer’s disease mutations;ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Deep Learning and High Performance Computing;Learning the language of viral evolution and escape;Model-based reinforcement learning for biological sequence design;5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding;Low-N protein engineering with data-efficient deep learning;Comprehensive AAV capsid fitness landscape reveals a viral gene and enables machine-guided design;Prediction of mutation effects using a deep temporal convolutional network;Drug resistance and combating drug resistance in cancer;Using deep learning to annotate the protein universe;Pervasive Pairwise Intragenic Epistasis among Sequential Mutations in TEM-1 β-Lactamase.;Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences;DeepGOPlus: improved protein function prediction from sequence;Conditioning by adaptive sampling for robust design;Deep generative models of genetic variation capture the effects of mutations;Multiplexed assays of variant effects contribute to a growing genotype–phenotype atlas;Quantitative Missense Variant Effect Prediction Using Large-Scale Mutagenesis Data.;Evolutionary Trajectories to Antibiotic Resistance.;Minimap2: pairwise alignment for nucleotide sequences;Proximal Policy Optimization Algorithms;Attention is All you Need;High-order epistasis shapes evolutionary trajectories;Mutation effects predicted from sequence co-variation;Beta-lactamase database (BLDB) – structure and function;Epistasis in protein evolution;Local fitness landscape of the green fluorescent protein;Survey of variation in human transcription factors reveals prevalent DNA binding changes;Evolvability as a Function of Purifying Selection in TEM-1 β-Lactamase;A Comprehensive Biophysical Description of Pairwise Epistasis throughout an Entire Protein Domain;UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches;Deep mutational scanning: a new style of protein science;Empirical fitness landscapes and the predictability of evolution;A Comprehensive, High-Resolution Map of a Gene’s Fitness Landscape;Deep mutational scanning of an RRM domain of the Saccharomyces cerevisiae poly(A)-binding protein;Capturing the mutational landscape of the beta-lactamase TEM-1;A fundamental protein property, thermodynamic stability, revealed solely from large-scale measurements of protein function;SIFT web server: predicting effects of amino acid substitutions on proteins;PyRosetta: a script-based interface for implementing molecular modeling algorithms using Rosetta;Stability effects of mutations and protein evolvability.;Balancing Robustness and Evolvability;Darwinian Evolution Can Follow Only Very Few Mutational Paths to Fitter Proteins;The distribution of fitness effects among beneficial mutations.;Introducing ChatGPT;Learning Mutational Semantics;Natural Selection and the Concept of a Protein Space",
         "Accelerating protein engineering with fitness landscape modeling and reinforcement learning"
        ],
        [
         "25",
         "00f1e24ed9abc1d314d58bad653da4de8e95539e",
         "None",
         "Felix Langschied,M. Leisegang,Stefan Günther,F. Hahner,Ralf Peter Brandes,Ingo Ebersberger",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/09/2024.12.05.627021.full.pdf",
         "None",
         "None",
         "",
         "Loss of multiple micro-RNAs uncovers multi-level restructuring of gene regulation in rodents"
        ],
        [
         "26",
         "010775b2dc942000269badbc223b65a9b9c67e05",
         "None",
         "Yunusa Haruna,Shiyin Qin,Adamu Lawan,Abdulrahman Hamman Adama Chukkol",
         "\n**BLOCK**fs== 16.1**p== 0.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nKonvLiNA: Integrating Kolmogorov-Arnold Network with Linear\nNyström Attention for feature fusion in Crop Field Detection\n**BLOCK**fs== 12.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n*Haruna Yunusa 1, Prof. Qin Shiyin 1, Adamu Lawan 1, Abdulrahman Hamman Adama Chukkol 2\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.2**l== 0.3**r== 0.3**\n1 Beihang University, Beijing, China\n2 Beijing Institute of Technology, Beijing, China\n**BLOCK**fs== 10.1**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nABSTRACT\nCrop field detection is a critical component of precision agriculture, essential for optimizing resource allocation and\nenhancing  agricultural  productivity.  This  study  introduces  KonvLiNA,  a  novel  framework  that  integrates\nConvolutional  Kolmogorov-Arnold  Networks  (cKAN)  with  Nyström  attention  mechanisms  for  effective  crop  field\ndetection. Leveraging KAN adaptive activation functions and the efficiency of Nyström attention in handling large-\nscale data, KonvLiNA significantly enhances feature extraction, enabling the model to capture intricate patterns in\ncomplex  agricultural  environments.  Experimental  results  on  rice  crop  dataset  demonstrate  KonvLiNA  superiority\nover  state-of-the-art  methods,  achieving  a  0.415  AP  and  0.459  AR  with  the  Swin-L  backbone,  outperforming\ntraditional  YOLOv8  by  significant  margins.  Additionally,  evaluation  on  the  COCO  dataset  showcases  competitive\nperformance  across  small,  medium,  and  large  objects,  highlighting  KonvLiNA  efficacy  in  diverse  agricultural\nsettings.  This  work  highlights  the  potential  of  hybrid  KAN  and  attention  mechanisms  for  advancing  precision\nagriculture through improved crop field detection and management.\n**BLOCK**fs== 9.1**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nKeywords.  Crop Field Detection, Feature Fusion, Kolmogorov-Arnold Networks (KAN), Nyström Attention Mechanism, Object\nDetection\n**BLOCK**fs== 11.0**p== 0.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\n1.   INTRODUCTION\n**BLOCK**fs== 10.1**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nAgricultural  field  disease  detection  is  crucial  due  to  the  significant  threat  these  diseases  pose  to  global  food\nsecurity,  requiring  timely  and  accurate  identification  for  effective  management  and  mitigation  [1].  Advances  in\nimaging  technologies  and  artificial  intelligence  have  enabled  the  development  of  automated  detection  systems,\noffering more efficient and precise solutions, unlike traditional methods which rely on expert knowledge and manual\ninspection, which are time-consuming and error-prone [2].\n**BLOCK**fs== 10.1**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nNotable advancements in deep learning have significantly enhanced the capabilities of computer vision systems\nin  agriculture.  Convolutional  neural  networks  (CNN)  and  attention  mechanisms  have  shown  great  promise  in\nextracting  and  processing  visual  information  for  various  applications  [3,  4].  However,  not  enough  exploration  has\nbeen done in the agricultural domain to specifically design modules that handle the challenge of scale variations and\nenhance  the  capturing  of  intricate  details  prevalent  in  complex  open  fields,  such  as  farms.  Conventional  CNN\npyramid feature fusion struggles with capturing multi-scale objects due to its hierarchical structure that leads to high\ninductive  bias,  while  standard  attention  mechanisms,  despite  having  low  inductive  bias,  can  be  computationally\nintensive [6].\n**BLOCK**fs== 10.1**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nRecently, a novel architecture based on the Kolmogorov-Arnold representation theorem, namely, Kolmogorov-\nArnold Network (KAN) [8], has emerged as promising alternative to Multi-Layer Perceptron (MLP). Unlike MLP,\nwhich have fixed activation functions on nodes, KAN utilize learnable activation functions on edges, replacing linear\nweights with univariate functions parametrized as splines. This structural change allows KANs to outperform MLP\nin terms of both accuracy and interpretability, particularly in tasks requiring fine-grained function fitting. Extending\nthis concept to convolutional operations, KAN Convolutions operate similarly to traditional convolutions but with a\ncritical difference, instead of applying a dot product between the kernel and the corresponding pixels in the image,\nKAN Convolutions apply a learnable nonlinear activation function to each element before summing them up. The\nkernel of a KAN Convolution is equivalent to a KAN linear layer with four inputs and one output neuron. For each\ninput 𝑖, a learnable function 𝜑! is applied, and the resulting pixel of that convolution step is the sum of 𝜑!(𝑥!). This\nprocess enhances the network capacity to model complex function and capture intricate patterns in the data [8].\n**BLOCK**fs== 10.1**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nTo  further  enhance  feature  extraction  and  integration  in  complex  agricultural  landscapes,  we  introduce  Linear\nNyström  Attention  mechanism.  The  traditional  self-attention  mechanism,  while  powerful,  can  be  computationally\ncostly when applied to large-scale images, due to its quadratic complexity in terms of input size [5]. The Nyström\nmethod,  a  well-established  technique  in  numerical  linear  algebra,  approximates  large-scale  kernel  matrices  with  a\n**BLOCK**fs== 10.1**p== 1.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nsmaller subset of columns, significantly reducing computational overhead while maintaining a high level of accuracy\n[7].  By  integrating  Linear  Nyström  Attention  with  KAN  Convolutions,  KonvLiNA,  achieves  a  synergistic  effect,\ncombining  the  fine-grained,  non-linear  function  modeling  capabilities  of  KAN  with  the  efficient  and  scalable\nattention mechanism of the Nyström method. This integration not only addresses the computational challenges posed\nby  large-scale  agricultural  images  but  also  enhances  the  model's  ability  to  capture  both  local  and  global  features\nessential for accurate crop field detection.\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.2**l== 0.1**r== 0.1**\nTo  this  end,  we  propose  KonvLiNA,  a  pyramid  feature  fusion  approach  for  enhancing  object  detection  in\nagricultural  fields.  The  approach  integrates  two  novel  modules:  Convolutional  KAN  Spatial  Pyramid  Pooling\n(cKSPP)  and  Enhanced  Nyström  Attention  Upsample  (ENAU).  The  former  effectively  leverages  the  expressive\npower  of  KAN  to  capture  the  complex,  intricate  details  prevalent  in  large  open  fields  like  farms,  while  the  latter\nutilizes the Linear Nyström Attention mechanism to address information loss, redundancy, and degradation of feature\nmaps during the up-sampling process. Additionally, ENAU mitigates artifacts present during training and inference\nwith  register  tokens.  The  proposed  hybrid  KonvLiNA  network  not  only  enhances  the  ability  to  capture  complex,\nintricate  details  but  also  improves  the  capturing  of  long-range  dependencies  prevalent  in  large,  open  farm  fields,\nwhere objects of interest may be tiny.\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\nThe contributions of this study are summarized below:\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\n•  Designed a novel cKSPP module capable of efficiently capturing the complex, intricate details prevalent in\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nagricultural fields.\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\n•  Designed  a  novel  ENAU  module,  which  mitigates  information  loss  and  artifacts  during  training  and\n**BLOCK**fs== 10.1**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\ninference.\n**BLOCK**fs== 10.1**p== 1.0**b== 0.5**t== 0.4**l== 0.2**r== 0.1**\n•  Extensive  experimental  results  demonstrate  promising  performance  compared  to  some  state-of-the-art\n**BLOCK**fs== 10.1**p== 1.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\npyramid feature fusion approaches.\n**BLOCK**fs== 11.0**p== 1.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\n2.   RELATED WORK\n**BLOCK**fs== 10.1**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nExisting advanced pyramid feature fusion modules for object detection utilize either conventional CNNs, attention\nmechanisms,  or  a  hybrid  of  both  approaches  to  address  the  challenge  of  capturing  multi-scale  variations  in  object\ndetection tasks.\n**BLOCK**fs== 10.1**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nCNN Based. Asymptotic Feature Pyramid Network (AFPN) enhances object detection by enabling direct interaction\nbetween  non-adjacent  pyramid  levels,  initially  fusing  low-level  features  and  progressively  integrating  higher-level\nfeatures  to  minimize  semantic  gaps.  Its  adaptive  spatial  fusion  effectively  handles  inconsistencies,  resulting  in\nimproved  average  precision  and  computational  efficiency  on  the  MS  COCO  2017  dataset  compared  to  traditional\nFPNs [6]. The Parallel Residual Bi-Fusion Feature Pyramid Network (PRB-FPN) introduces a bi-directional feature\nfusion  approach,  utilizing  a  Bottom-Up  Fusion  Module  and  a  Concatenation  and  Re-Organization  module  with\nresidual  design  for  high-quality  single-shot  object  detection.  This  method  achieves  state-of-the-art  results  on\nUAVDT17 and MS COCO datasets [9]. EfficientDet improves object detection through the weighted bi-directional\nfeature  pyramid  network  (BiFPN)  for  efficient  multi-scale  feature  fusion  and  a  compound  scaling  method.  It\nimproves accuracy with fewer parameters and FLOPs, with EfficientDet-D7 reaching 55.1 AP on the COCO test-dev\n[26]. RevBiFPN, a reversible bidirectional feature pyramid network, reduces memory requirements during training\nby  recomputing  hidden  activations.  It  shows  competitive  performance  with  EfficientNet  while  using  significantly\nless memory, making it suitable for large-scale models [16].\n**BLOCK**fs== 10.1**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nAttention and Hybrid Based. The Pyramid Attention Object Detection Network utilizes a multi-scale feature fusion\npyramid  attention  module,  enhancing  the  detection  of  small  and  partially  occluded  objects  by  integrating  global\naverage pooling results from multiple scales. This approach significantly improves detection accuracy on PASCAL\nVOC and MS COCO datasets [11]. ReAFFPN enhances rotation-equivariant feature fusion in aerial object detection\nthrough  Rotation-equivariant  Channel  Attention,  improving  classification  accuracy  and  feature  fusion  consistency.\nThis  method  significantly  boosts  the  accuracy  of  Rotation-equivariant  Convolutional  Networks  (ReCNNs)  [12].\nRHF-Net addresses small object detection on embedded devices by introducing a bidirectional fusion module and a\nrecursive concatenation and reshaping module. It enhances detection accuracy and efficiency on COCO and UAVDT\ndatasets  [10].  The  refined  marine  object  detector,  with  attention-based  spatial  pyramid  pooling  networks  and  a\nbidirectional  feature  fusion  strategy,  enhances  feature  representation  and  detection  accuracy  in  underwater\nenvironments, achieving high mAP on underwater image and URPC datasets [13]. The Attentional Feature Fusion\n**BLOCK**fs== 10.1**p== 2.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nmodule leverages attention mechanisms for superior feature integration, enhancing performance across various CNN\narchitectures and achieving state-of-the-art results on CIFAR-100 and ImageNet [14]. The Feature Pyramid Network\nwith Multi-Scale Prediction Fusion for real-time semantic segmentation uses a dual prediction module and attention\nmechanism  to  enhance  segmentation  accuracy  and  speed,  achieving  notable  performance  on  Cityscapes  and\nMapillary Vistas datasets [15].\n**BLOCK**fs== 10.1**p== 2.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nDiscussion. While these advanced methods significantly improve object detection accuracy through enhanced multi-\nscale feature fusion and contextual information preservation, they primarily focus on general object detection tasks.\nThere  is  a  lack  of  exploration  in  specific  applications  like  agriculture,  where  unique  challenges  such  as  varying\nscales  and  complex  backgrounds  are  prevalent.  To  address  these  challenges,  we  will  explore  integrating  KAN  to\nleverage  its  dynamic  learnable  activation  function  to  capture  richer  semantics  prevalent  in  crop  fields  with  Linear\nNyström  Attention  mechanism  to  efficiently  capture  long-range  dependencies  and  preserve  contextual  information\ndue to the object of interests spanning the whole image. This integration could lead to a more robust and accurate\ndetection systems custom in agricultural applications, contributing significantly to the field of precision agriculture.\n**BLOCK**fs== 11.0**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\n3.   METHOD AND TOOLS\n**BLOCK**fs== 10.1**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nThis section provides a general overview of KonvLiNA, which is based on a multi-scale fusion of Convolutional\nKolmogorov-Arnold Network and up-sampling Linear Nyström Attention mechanism with Registers. High and low-\nlevel features extracted from the backbone networks are fed into KonvLiNA to extract multi-scale information from\nimages  leveraging  the  expressive  power  of  KAN  using  the  cKSPP  module.  Then,  eNAU  to  mitigate  information\ndegradation of spatial details during the fusion. Finally, fusing the top-down and lateral connections and the output is\nsent to the detection head. The remainder of this section presents the components used in the KonvLina framework.\nRefer to Figure 1 for illustrations of all interactions between each component.\n**BLOCK**fs== 9.1**p== 2.0**b== 0.2**t== 0.8**l== 0.4**r== 0.3**\nFigure 1. KonvLina Architectural design\n**BLOCK**fs== 10.1**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nFor precise crop field detection, KonvLiNA uses the Swin Transformer [16], a hierarchical image encoder that\nefficiently captures long-range dependencies and retains both low-level and high-level features by processing images\nin shifted local windows. The input 𝑋\t ∈ ℝ\"×$×% is partitioned into non-overlapping windows of size 𝑀 × 𝑀, where\nself-attention is computed within each window. These windows are then shifted by a fixed offset 𝑠 to capture cross-\nwindow  interactions,  and  features  are  aggregated  and  down-sampled  hierarchically.  Multi-scale  feature  maps\n𝐹&, 𝐹’, 𝐹( are extracted from different layers, making the Swin Transformer a powerful image encoder.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nKolmogorov-Arnold representation theorem states that any multivariate continuous function can be expressed as\n**BLOCK**fs== 10.1**p== 3.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\n’).&\n𝑓(𝑥&, 𝑥’ … , 𝑥)\t) = \t 2 Φ* 42 ∅*,,6𝑥,7\n*-&\n**BLOCK**fs== 10.1**p== 3.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nwhere Φ* and ∅𝒒,𝒑 are continuous functions mapping each input variable, 𝑥, and Φ* respectively. This allows KAN\nto  represent  complex  relationships  in  high-dimensional  data  by  combining  univariate  functions.  It  utilizes  this\ntheorem  by  replacing  traditional  linear  weights  with  spline-parametrized  univariate  functions,  using  adaptive,\nlearnable activation functions on edges between nodes with b-spline curves that adjust during training, which allows\nit  to  capture  complex  nonlinear  relationships  more  effectively  than  traditional  MLPs  with  non-learnable  activation\nfunctions, eqn. 2 is a deeper KAN architecture.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.7**t== 0.3**l== 0.4**r== 0.3**\n𝐾𝐴𝑁(𝑥) = \t (Φ12& \t ∘ \t Φ12’ ∘ … ∘ Φ3\t)(𝑥)\n**BLOCK**fs== 10.1**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nwhere each  Φ1 denotes a KAN layer. The number of layers enables the detection of more complex patterns, with\neach layer 𝑙 applying a sequence of learnable functions ∅𝒒,𝒑, making the network flexible and robust.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nConvolutional KAN. [18] is inspired by the standard CNN architectures, requiring fewer parameters due to the\nuse  of  b-splines.  These  splines  offer  smoother  activation  function  representations  compared  to  ReLU.  In  KAN\nconvolutions, the implementation diverges from traditional CNN convolutions primarily in the nature of the kernel\nemployed. While CNNs utilize weight-based kernels, Convolutional KANs operates kernels where each element, ∅,\nis a learnable non-linear function utilizing b-splines, eqn. 3\n**BLOCK**fs== 10.1**p== 3.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\n∅ = \t 𝑤& ∙ 𝑠𝑝𝑙𝑖𝑛𝑒(𝑥) + \t 𝑤’ ∙ 𝑠𝑖𝑙𝑢(𝑥)\n**BLOCK**fs== 10.1**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nIn KAN Convolutions, the kernel traverses the image, applying the activation function ∅!4 to each pixel 𝑎56 and\ncomputing the output pixel as the sum of ∅!46𝑎!.5,4.67. Formally, if 𝐾 represents a KAN kernel in\tℝ7×8, then the\nimage is represented as a matrix.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\n𝑖𝑚𝑎𝑔𝑒 = H\n**BLOCK**fs== 10.1**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nThe KAN convolution is defined as, (𝑖𝑚𝑎𝑔𝑒\t ∗ 𝐾) = \t ∑\n. This approach effectively integrates\n5-&\nthe  flexibility  of  KANs  with  the  spatial  processing  capabilities  of  convolution  operations,  enhancing  the  model's\nability to capture complex spatial dependencies in data.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nWe  propose  cKSPP  by  leveraging  the  expressive  power  of  convolutional  KAN  using  its  dynamic  learnable\nactivation function to capture richer semantics prevalent in crop open fields images. Our approach defines a multi-\nscale pooling to the outputs of the image encoder 𝐹&, 𝐹’, 𝐹(. Then we apply various pooling scales in order to encode\nmultiple scale features. Adaptive average pooling changes the size of the input feature map to a fixed output size (s,\ns), where s represents the scale, for an input 𝑋\t ∈ ℝ\"×$×%!\", eqn. 4 formulates the spatial pooling operation.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.2**t== 0.7**l== 0.4**r== 0.4**\n(𝔰) = 𝐴𝑣𝑔𝑃𝑜𝑜𝑙2𝐷(𝑋) ∈ ℝ\t𝔰×𝔰×%!\"\n**BLOCK**fs== 10.1**p== 3.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\n(𝔰)\nis the pooled feature map at scale 𝔰. Then we applied KAN layer to 𝑋,::6\n**BLOCK**fs== 10.1**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n(𝔰)\nWhere 𝑋,::6\nprevalent in open fields farms. KAN has a learnable activation function which gives it better expressiveness using it\nsplines curves which adjust during training. The operation is formulated in eqn. 5.\n**BLOCK**fs== 10.1**p== 3.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\ncapture complex pattern\n**BLOCK**fs== 7.0**p== 3.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\n(𝔰) = KAN&×&(XBCCD\nX?@A\n**BLOCK**fs== 10.1**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\ncKSPP captures richer semantics by combining multi-scale pooling with KAN dynamic learnable activation function.\nThis approach enhances the expressiveness of the model, enabling it to detect complex patterns across various scales,\nparticularly  in  challenging  environments  like  open-field  farms.  By  adapting  feature  maps  to  different  scales  and\nrefining them through KAN, cKSPP improves the model's ability to handle diverse and intricate visual data.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nIn  this  section,  we  propose  a  novel  up-sampling  method  using  a  Linear  Nyström  Attention  to  mitigate\ninformation loss, degradation of feature maps, and reduce artifacts in KonvLiNA. Given a normalized feature map\n𝑋\t ∈ ℝ1×% (where 𝐿 represents the length of the sequence) generated by the cKSPP module, we first apply a 1 × 1\nconvolution  for  dimensionality  reduction,  ensuring  the  feature  map  channel  dimension  is  appropriately  scaled  for\nsubsequent processing. Next, we generate the query 𝑄, key 𝐾, and value 𝑉 matrices from input 𝑋. We then apply the\nNyström  method  to  approximate  the  self-attention  mechanism,  which  enables  more  efficient  computation.  The\nNyström  approximation  utilizes  a  subset  of  the  sequence  data  to  estimate  the  full  attention  matrix,  reducing  the\ncomputational complexity while maintaining the benefits of attention. Then we compute low-rank approximations of\nthe  attention  matrix  by  projecting  𝑄  and  𝐾  onto  a  lower-dimensional  space.  This  approximation  allows  us  to\nefficiently compute attention scores and apply them to 𝑉, resulting in attention outputs with reduced computational\ncomplexity to 𝑂(𝑁 log 𝑁). Refer to eqn. 6 for Nyström Approximation.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nTo  preserve  sequence  order,  we  add  relative  positional  encoding.  The  learnable  positional  encodings  are\ninitialized with random values 𝑝FG6 ∈ ℝH×I’×1, where ℎ is the number of heads and 𝐷H is the dimension of each head.\nThis encoding matrix 𝑃 = 𝑝FG6 is used to integrated positional information into the attention mechanism. We utilize\nlearnable  deconvolutional  layers  for  up-sampling  to  better  preserve  fine  details  and  adaptively  enhance  quality,\nunlike nearest neighbor interpolation, which is non-trainable and can lead to redundant up-sample feature maps. This\neffectively up-samples the sequence length, resulting in the projection of the attention outputs with higher resolution.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nLastly, to address the problem of artifacts introduced by attention mechanisms and deconvolutions, we introduce\nregisters  [19].  The  registers  are  added  to 𝑄  and 𝐾  as (𝑄, 𝐾)J = (𝑄𝐾) + 𝑅  and  to 𝑉  as 𝑉J = 𝑉 + 𝑅, where 𝑅  is\ntrainable token with the same size as 𝑄𝐾𝑉 vectors. These registers are discarded after computing the Linear Nyström\nAttention during training and inference.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nThe Nyström method approximates the attention mechanism by selecting a subset of 𝑚 landmarks from 𝐾. Let\n𝐾9 ∈ ℝ9×K( be the subset of landmarks, and 𝑄9 be the corresponding queries. The approx. is computed as in eqn. 6.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nNyström\t(𝑄, 𝐾, 𝑉) ≈ softmax 4\n**BLOCK**fs== 10.1**p== 4.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\n8 nsoftmax 4\n**BLOCK**fs== 10.1**p== 4.0**b== 0.4**t== 0.6**l== 0.7**r== 0.3**\nsoftmax 4\n**BLOCK**fs== 10.1**p== 4.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nThis  approximation  reduces  the  complexity  of  self-attention  from  𝑂(𝑁’)  to  𝑂(𝑁 log 𝑁) ,  making  it  more\n**BLOCK**fs== 10.1**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nKonvLiNA module combines eNAU and cKSPP through a pair-wise addition fusion operation. eNAU utilizes a\nLinear Nyström Attention mechanism to reduce information loss and mitigate homogeneous semantic information,\nwhile cKSPP applies custom spatial pyramid pooling for multi-scale feature extraction, capturing intricate details of\nsmall objects in images. The cKAN layer further enhances the module by capturing complex patterns typical in open-\nfield farms, leveraging KAN expressive power through its learnable activation function. The combined output is then\nfed into a YOLOv8 detection head, which operates across three pyramid levels to effectively detect objects in open\nfarm  environments.  This  approach  ensures  robust  detection  by  preserving  spatial  details  and  capturing  diverse\nfeatures, both crucial for agricultural applications.\n**BLOCK**fs== 11.0**p== 4.0**b== 0.2**t== 0.8**l== 0.3**r== 0.2**\n4 EXPERIMENTAL RESULTS AND EVALUATION\n**BLOCK**fs== 10.1**p== 4.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nIn this section, we report the experimental results and evaluate KonvLiNA both quantitatively and qualitatively\n**BLOCK**fs== 10.1**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nto assess its effectiveness in enhancing crop fields object detection using two main datasets.\n**BLOCK**fs== 10.1**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nDataset and metric. The Mendeley Rice Leaf Disease dataset [20] was used, which consists of 5,932 images of four\ndisease types: Brown Spot, Bacterial Blight, Blast, and Tungro. This dataset was used to validate the effectiveness of\nour method and compare it with existing methods. Additionally, to evaluate the robustness of our method, we utilized\nthe  COCO  dataset,  which  consists  of  330,000  images  of  80  object  categories.  Average  Precision  (AP)  and  Mean\nAverage Precision (mAP) were used to evaluate the model's performance.\n**BLOCK**fs== 10.1**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nExperimental setup. The input images were set to 640 × 640 pixels pixels for both training and evaluation over 90\nepochs  using  the  YOLOv8  network  settings.  The  bias  values  for  the  classification  and  localization  layers  in  the\ndetection  head  were  set  to  0.01  and  0.1,  respectively.  A  Gaussian  weight  with  σ  =  0.01  was  used  in  all  layers,\nincluding  the  proposed  feature  selection  network.  We  used  Adam  optimizer  with  an  initial  learning  rate  of  0.001,\nweight decay of 0.0005, and momentum of 0.95. Data augmentation included 0.5 horizontal/vertical flip, mosaic of\n0.9, and scale of 0.5. Due to the small training dataset, we fine-tuned with the MS-COCO pre-trained weights.\n**BLOCK**fs== 10.1**p== 5.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nThis  section  evaluates  the  performance  of  YOLOv8  with  KonvLiNA  and  with  other  feature  pyramid  fusion\n**BLOCK**fs== 10.1**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nmodels with Mendeley RLD crop dataset. In addition, we evaluated it with COCO dataset for robustness.\n**BLOCK**fs== 9.1**p== 5.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nFaster R-CNN + FPN\n**BLOCK**fs== 9.1**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nDETR\nFigure 2 shows the comparative analysis of AP values across small, medium, and large objects which reveals notable performance\nenhancements  in  DETR  and  KonvLiNA  architectures  relative  to  Faster  R-CNN  +  FPN  on  the  RLD  dataset.  DETR  shows\nimprovements  of  approximately  14.2%  for  small  objects,  23.3%  for  medium  objects,  and  a  marginal  0.5%  for  large  objects\ncompared to Faster R-CNN. In contrast, KonvLiNA exhibits more substantial gains with approximately 21.7% improvement for\nsmall objects, 41.0% for medium objects, and 14.7% for large objects. These results highlight the effectiveness of KonvLiNA in\nhandling scale variations across all object sizes compared to Faster R-CNN + FPN and DETR.\n**BLOCK**fs== 9.1**p== 5.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\nKonvLiNA\n**BLOCK**fs== 10.1**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nRice  Crop  Disease  Dataset.  Utilizing  the  Swin-L  backbone,  KonvLiNA  outperforms  all  other  methods  with\nimprovements of 3.50% in AP and 4.37% in AR over YOLOv8, 0.75% in AP and 2.94% in AR over DETR, 0.73%\nin AP and 3.79% in AR over HTC++, 2.30% in AP and 4.20% in AR over ViT Det, and 0.08% in AP and 3.80% in\nAR over DINO. Overall, these results demonstrate significant performance enhancements in detecting objects with\nvarious variations prevalent in Rice Crop fields, where objects of interest are typically small due to the size of rice\nleaves. This highlights the potential benefits of exploring hybrid KAN and attention mechanisms in such scenarios.\n**BLOCK**fs== 9.1**p== 5.0**b== 0.4**t== 0.6**l== 0.4**r== 0.3**\nTable 1 AP comparison on Rice Crop disease detection\n**BLOCK**fs== 9.1**p== 5.0**b== 0.3**t== 0.6**l== 0.3**r== 0.6**\nObject Detector\nFaster R-CNN+FPN\nYOLOv8\nDETR\nHTC++\nViTDet\nDINO\nKonvLiNA (ours)\n**BLOCK**fs== 9.1**p== 5.0**b== 0.3**t== 0.6**l== 0.4**r== 0.5**\nBackbone\nResNet-101\nDarknet-53\nSwin\nSwin V2-G\nBEiT-3\nSwin-L\nSwin-L\n**BLOCK**fs== 10.1**p== 5.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nCOCO dataset. On the COCO dataset, KonvLiNA achieves competitive AP across small, medium, and large objects\ncompared to various Faster R-CNN configurations with different FPN.\n**BLOCK**fs== 9.1**p== 5.0**b== 0.2**t== 0.8**l== 0.4**r== 0.3**\nTable 2 AP comparison on COCO dataset\n**BLOCK**fs== 9.1**p== 5.0**b== 0.1**t== 0.8**l== 0.3**r== 0.5**\nMethod\nFaster R-CNN + FPN [21]\nFaster R-CNN + PAFPN [22]\nFaster R-CNN + Graph FPN [23]\nFaster R-CNN + LFPN [24]\nFaster R-CNN + CARAFE [25]\nFaster R-CNN + AFPN [6]\nKonvLiNA (ours)\n**BLOCK**fs== 9.1**p== 5.0**b== 0.1**t== 0.8**l== 0.7**r== 0.2**\n𝑨𝑷𝑴  𝑨𝑷𝑳\n50.4\n42.9\n54.0\n42.5\n56.7\n38.9\n49.0\n42.5\n49.7\n42.2\n55.0\n43.0\n56.3\n44.1\n**BLOCK**fs== 10.1**p== 6.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nWe  also  provide  a  qualitative  evaluation  in  Fig.  3,  demonstrating  that  the  KonvLiNA  module  significantly\nenhances the rice crop detection across diverse object sizes, particularly smaller objects, compared to Faster R-CNN\nand DETR. e.g., in the upper-left of Fig. 3a, KonvLiNA effectively identifies small disease spots on rice leaves that\nFaster  R-CNN  misses.  Also,  KonvLiNA  outperforms  Faster  R-CNN  and  DETR  in  detecting  several  very  small\nobjects in Fig. b. These findings align with our quantitative results, emphasizing KonvLiNA robust performance on\nsmall disease spots and its improved accuracy under varying occlusion levels. However, despite these improvements,\nour model still misses some extremely challenging disease objects, as shown in KonvLiNA Fig. c. right side.\n**BLOCK**fs== 10.1**p== 6.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nOverall, these qualitative findings highlight the effectiveness of our approach and the significant improvement\n**BLOCK**fs== 10.1**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nachieved through detecting small or extremely varied objects in open crop field environments i.e. rice crops.\n**BLOCK**fs== 9.1**p== 6.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nGround truth\n**BLOCK**fs== 9.1**p== 6.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\nFaster R-CNN + FPN\n**BLOCK**fs== 9.1**p== 6.0**b== 0.3**t== 0.7**l== 0.8**r== 0.1**\nKonvLiNA\n**BLOCK**fs== 10.1**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nAblation.  On  the  RLD  dataset  demonstrates  that  integrating  eNAU  into  the  baseline  KonvLiNA  configuration\nincreases  AP  by  1.7%  (from  0.359  to  0.365)  and  AR  by  3.5%  (from  0.371  to  0.384),  while  including  cKSPP\nalongside eNAU further enhances AP by 15.6% (from 0.359 to 0.415) and AR by 23.7% (from 0.371 to 0.459).\n**BLOCK**fs== 9.1**p== 6.0**b== 0.3**t== 0.7**l== 0.4**r== 0.3**\nTable 3 Ablation on Rice Crop dataset\n**BLOCK**fs== 9.1**p== 6.0**b== 0.2**t== 0.7**l== 0.3**r== 0.5**\nComponents\nKonvLiNA + Nearest neighbor\nKonvLiNA + eNAU\nKonvLiNA + eNAU + cKSPP\n**BLOCK**fs== 11.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\n5.   CONCLUSION\n**BLOCK**fs== 10.1**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nIn this study, we proposed a novel feature pyramid fusion network, KonvLiNA, aimed at improving crop field\ndetection  by  effectively  addressing  the  challenge  of  scale  variation.  Our  hybrid  module  combines  the  cKAN  and\nNyström  attention  mechanisms.  Additionally,  we  introduced  eNAU  and  cKSPP,  which  reduce  information  loss\nduring feature fusion and enhance the model's ability to capture intricate patterns through the expressiveness of the\nKAN  activation  function.  These  novelties  collectively  improve  the  model's  performance  in  detecting  crop  fields,\ndemonstrating the effectiveness of our approach.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nREFERENCES\n1.  Strange, Richard N., and Peter R. Scott. \"Plant disease: a threat to global food security.\" Annu. Rev. Phytopathol. 43, no. 1\n**BLOCK**fs== 9.1**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\n2.  Niazi, Muhammad Khalid Khan, Anil V. Parwani, and Metin N. Gurcan. \"Digital pathology and artificial intelligence.\" The\n**BLOCK**fs== 9.1**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nlancet oncology 20, no. 5 (2019): e253-e261.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\n3.  Zhai, Xiaohua, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer. \"Scaling vision transformers.\" In Proceedings of the\n**BLOCK**fs== 9.1**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.3**\nIEEE/CVF conference on computer vision and pattern recognition, pp. 12104-12113. 2022.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.7**t== 0.2**l== 0.2**r== 0.1**\n4.  Yunusa,  Haruna,  Shiyin  Qin,  Abdulrahman  Hamman  Adama  Chukkol,  Abdulganiyu  Abdu  Yusuf,  Isah  Bello,  and  Adamu\nLawan. \"Exploring the Synergies of Hybrid CNNs and ViTs Architectures for Computer Vision: A survey.\" arXiv preprint\narXiv:2402.02941 (2024).\n**BLOCK**fs== 9.1**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\n5.  Keles,  Feyza  Duman,  Pruthuvi  Mahesakya  Wijewardena,  and  Chinmay  Hegde.  \"On  the  computational  complexity  of  self-\n**BLOCK**fs== 9.1**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nattention.\" In International Conference on Algorithmic Learning Theory, pp. 597-619. PMLR, 2023.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\n6.  Dosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa\nDehghani  et  al.  \"An  image  is  worth  16x16  words:  Transformers  for  image  recognition  at  scale.\"  arXiv  preprint\narXiv:2010.11929 (2020).\n**BLOCK**fs== 9.1**p== 7.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\n7.  Xiong,  Yunyang,  Zhanpeng  Zeng,  Rudrasis  Chakraborty,  Mingxing  Tan,  Glenn  Fung,  Yin  Li,  and  Vikas  Singh.\n\"Nyströmformer: A nyström-based algorithm for approximating self-attention.\" In Proceedings of the AAAI Conference on\nArtificial Intelligence, vol. 35, no. 16, pp. 14138-14148. 2021.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\n8.  Liu,  Ziming,  Yixuan  Wang,  Sachin  Vaidya,  Fabian  Ruehle,  James  Halverson,  Marin  Soljačić,  Thomas  Y.  Hou,  and  Max\n**BLOCK**fs== 9.1**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.3**\nTegmark. \"Kan: Kolmogorov-arnold networks.\" arXiv preprint arXiv:2404.19756 (2024).\n**BLOCK**fs== 9.1**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\n9.  Chen, Ping-Yang, Ming-Ching Chang, Jun-Wei Hsieh, and Yong-Sheng Chen. \"Parallel residual bi-fusion feature pyramid\n**BLOCK**fs== 9.1**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nnetwork for accurate single-shot object detection.\" IEEE transactions on Image Processing 30 (2021): 9099-9111.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n10.  Chen, Ping-Yang, Jun-Wei Hsieh, Chien-Yao Wang, and Hong-Yuan Mark Liao. \"Recursive hybrid fusion pyramid network\nfor real-time small object detection on embedded devices.\" In Proceedings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition Workshops, pp. 402-403. 2020.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n11.  Chen, Xiu, Yujie Li, and Yoshihisa Nakatoh. \"Pyramid attention object detection network with multi-scale feature fusion.\"\n**BLOCK**fs== 9.1**p== 7.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nComputers and Electrical Engineering 104 (2022): 108436.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n12.  Sun, Chongyu, Yang Xu, Zebin Wu, and Zhihui Wei. \"ReAFFPN: Rotation-Equivariant Attention Feature Fusion Pyramid\nNetworks  for  Aerial  Object  Detetcion.\"  In  IGARSS  2022-2022  IEEE  International  Geoscience  and  Remote  Sensing\nSymposium, pp. 3055-3058. IEEE, 2022.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\n13.  Xu, Fengqiang, Huibing Wang, Xudong Sun, and Xianping Fu. \"Refined marine object detector with attention-based spatial\npyramid pooling networks and bidirectional feature fusion strategy.\" Neural Computing and Applications 34, no. 17 (2022):\n14881-14894.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n14.  Dai, Yimian, Fabian Gieseke, Stefan Oehmcke, Yiquan Wu, and Kobus Barnard. \"Attentional feature fusion.\" In Proceedings\n**BLOCK**fs== 9.1**p== 7.0**b== 0.4**t== 0.6**l== 0.2**r== 0.3**\nof the IEEE/CVF winter conference on applications of computer vision, pp. 3560-3569. 2021.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n15.  Van Quyen, Toan, and Min Young Kim. \"Feature pyramid network with multi-scale prediction fusion for real-time semantic\n**BLOCK**fs== 9.1**p== 7.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nsegmentation.\" Neurocomputing 519 (2023): 104-113.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n16.  Chiley, Vitaliy, Vithursan Thangarasa, Abhay Gupta, Anshul Samar, Joel Hestness, and Dennis DeCoste. \"RevBiFPN: the\nfully reversible bidirectional feature pyramid network.\" Proceedings of Machine Learning and Systems 5 (2023): 625-645.\n17.  Liu,  Ze,  Yutong  Lin,  Yue  Cao,  Han  Hu,  Yixuan  Wei,  Zheng  Zhang,  Stephen  Lin,  and  Baining  Guo.  \"Swin  transformer:\nHierarchical  vision  transformer  using  shifted  windows.\"  In  Proceedings  of  the  IEEE/CVF  international  conference  on\ncomputer vision, pp. 10012-10022. 2021.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n18.  Bodner,  Alexander  Dylan,  Antonio  Santiago  Tepsich,  Jack  Natan  Spolski,  and  Santiago  Pourteau.  \"Convolutional\n**BLOCK**fs== 9.1**p== 7.0**b== 0.3**t== 0.7**l== 0.2**r== 0.4**\nKolmogorov-Arnold Networks.\" arXiv preprint arXiv:2406.13155 (2024).\n**BLOCK**fs== 9.1**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n19.  Darcet, Timothée, Maxime Oquab, Julien Mairal, and Piotr Bojanowski. \"Vision transformers need registers.\" arXiv preprint\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n20.  Hossain, Md Fahad; Abujar , Sheikh ; Noori, Sheak Rashed Haider ; Hossain, Syed Akhter  (2021), Dhan-Shomadhan: A\nDataset of Rice Leaf Disease Classification for Bangladeshi Local Rice [R], Mendeley Data, V1, doi: 10.17632/znsxdctwtt.1\n21.  Lin, Tsung-Yi, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. \"Feature pyramid networks\nfor  object  detection.\"  In  Proceedings  of  the  IEEE  conference  on  computer  vision  and  pattern  recognition,  pp.  2117-2125.\n2017.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n22.  Liu,  Shu,  Lu  Qi,  Haifang  Qin,  Jianping  Shi,  and  Jiaya  Jia.  \"Path  aggregation  network  for  instance  segmentation.\"  In\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nProceedings of the IEEE conference on computer vision and pattern recognition, pp. 8759-8768. 2018.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n23.  Zhao,  Gangming,  Weifeng  Ge,  and  Yizhou  Yu.  \"GraphFPN:  Graph  feature  pyramid  network  for  object  detection.\"  In\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.2**r== 0.2**\nProceedings of the IEEE/CVF international conference on computer vision, pp. 2763-2772. 2021.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n24.  Xie, Jin, Yanwei Pang, Jing Nie, Jiale Cao, and Jungong Han. \"Latent feature pyramid network for object detection.\" IEEE\n**BLOCK**fs== 9.1**p== 7.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\nTransactions on Multimedia 25 (2022): 2153-2163.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n25.  Wang,  Jiaqi,  Kai  Chen,  Rui  Xu,  Ziwei  Liu,  Chen  Change  Loy,  and  Dahua  Lin.  \"Carafe:  Content-aware  reassembly  of\n**BLOCK**fs== 9.1**p== 7.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nfeatures.\" In Proceedings of the IEEE/CVF international conference on computer vision, pp. 3007-3016. 2019.\n**BLOCK**fs== 9.1**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n26.  Tan, Mingxing, Ruoming Pang, and Quoc V. Le. \"Efficientdet: Scalable and efficient object detection.\" In Proceedings of the\n**BLOCK**fs== 9.1**p== 7.0**b== 0.1**t== 0.9**l== 0.2**r== 0.3**\nIEEE/CVF conference on computer vision and pattern recognition, pp. 10781-10790. 2020.\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nYour Name\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\nHaruna\n**BLOCK**fs== 10.1**p== 8.0**b== 0.7**t== 0.2**l== 0.2**r== 0.8**\nQin Shiyin\n**BLOCK**fs== 10.1**p== 8.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\nFull Professor\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nResearch Field\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\nPersonal website\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nComputer Vision,\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nhttps://yunusa2k2.github.io/portfolio/\n**BLOCK**fs== 10.1**p== 8.0**b== 0.7**t== 0.2**l== 0.6**r== 0.1**\nhttps://ieeexplore.ieee.org/author/37271751500\n**BLOCK**fs== 10.1**p== 8.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\nDeep Learning, Machine\nLearning\n**BLOCK**fs== 10.1**p== 8.0**b== 0.7**t== 0.2**l== 0.4**r== 0.4**\npattern\nrecognition  and\nmachine  learning,  image\nprocessing  and  computer\nartificial\nvision,\nand\nintelligence\nand\nknowledge engineering\n**BLOCK**fs== 10.1**p== 8.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nNatural\n**BLOCK**fs== 10.1**p== 8.0**b== 0.6**t== 0.3**l== 0.4**r== 0.4**\nLanguage\nProcessing, Deep Learning\n**BLOCK**fs== 10.1**p== 8.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nComputer\n**BLOCK**fs== 10.1**p== 8.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nVision,\n**BLOCK**fs== 10.1**p== 8.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nSecurity\n**BLOCK**fs== 10.1**p== 8.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\n*This form helps us to understand your paper better, the form itself will not be published.\n**BLOCK**fs== 10.1**p== 8.0**b== 0.5**t== 0.4**l== 0.2**r== 0.1**\n*Title  can  be  chosen  from:  master  student,  Phd  candidate,  assistant  professor,  lecture,  senior  lecture,  associate",
         "KonvLiNA: Integrating Kolmogorov-Arnold Network with Linear Nyström Attention for feature fusion in Crop Field Detection 1 Beihang University, Beijing, China 2 Beijing Institute of Technology, Beijing, China ABSTRACT Crop field detection is a critical component of precision agriculture, essential for optimizing resource allocation and enhancing  agricultural  productivity.  This  study  introduces  KonvLiNA,  a  novel  framework  that  integrates Convolutional  Kolmogorov-Arnold  Networks  (cKAN)  with  Nyström  attention  mechanisms  for  effective  crop  field detection. Leveraging KAN adaptive activation functions and the efficiency of Nyström attention in handling large- scale data, KonvLiNA significantly enhances feature extraction, enabling the model to capture intricate patterns in complex  agricultural  environments.  Experimental  results  on  rice  crop  dataset  demonstrate  KonvLiNA  superiority over  state-of-the-art  methods,  achieving  a  0.415  AP  and  0.459  AR  with  the  Swin-L  backbone,  outperforming traditional  YOLOv8  by  significant  margins.  Additionally,  evaluation  on  the  COCO  dataset  showcases  competitive performance  across  small,  medium,  and  large  objects,  highlighting  KonvLiNA  efficacy  in  diverse  agricultural settings.  This  work  highlights  the  potential  of  hybrid  KAN  and  attention  mechanisms  for  advancing  precision agriculture through improved crop field detection and management. 1.   INTRODUCTION Agricultural  field  disease  detection  is  crucial  due  to  the  significant  threat  these  diseases  pose  to  global  food security,  requiring  timely  and  accurate  identification  for  effective  management  and  mitigation  [1].  Advances  in imaging  technologies  and  artificial  intelligence  have  enabled  the  development  of  automated  detection  systems, offering more efficient and precise solutions, unlike traditional methods which rely on expert knowledge and manual inspection, which are time-consuming and error-prone [2]. Notable advancements in deep learning have significantly enhanced the capabilities of computer vision systems in  agriculture.  Convolutional  neural  networks  (CNN)  and  attention  mechanisms  have  shown  great  promise  in extracting  and  processing  visual  information  for  various  applications  [3,  4].  However,  not  enough  exploration  has been done in the agricultural domain to specifically design modules that handle the challenge of scale variations and enhance  the  capturing  of  intricate  details  prevalent  in  complex  open  fields,  such  as  farms.  Conventional  CNN pyramid feature fusion struggles with capturing multi-scale objects due to its hierarchical structure that leads to high inductive  bias,  while  standard  attention  mechanisms,  despite  having  low  inductive  bias,  can  be  computationally intensive [6]. Recently, a novel architecture based on the Kolmogorov-Arnold representation theorem, namely, Kolmogorov- Arnold Network (KAN) [8], has emerged as promising alternative to Multi-Layer Perceptron (MLP). Unlike MLP, which have fixed activation functions on nodes, KAN utilize learnable activation functions on edges, replacing linear weights with univariate functions parametrized as splines. This structural change allows KANs to outperform MLP in terms of both accuracy and interpretability, particularly in tasks requiring fine-grained function fitting. Extending this concept to convolutional operations, KAN Convolutions operate similarly to traditional convolutions but with a critical difference, instead of applying a dot product between the kernel and the corresponding pixels in the image, KAN Convolutions apply a learnable nonlinear activation function to each element before summing them up. The kernel of a KAN Convolution is equivalent to a KAN linear layer with four inputs and one output neuron. For each input 𝑖, a learnable function 𝜑! is applied, and the resulting pixel of that convolution step is the sum of 𝜑!(𝑥!). This process enhances the network capacity to model complex function and capture intricate patterns in the data [8]. To  further  enhance  feature  extraction  and  integration  in  complex  agricultural  landscapes,  we  introduce  Linear Nyström  Attention  mechanism.  The  traditional  self-attention  mechanism,  while  powerful,  can  be  computationally costly when applied to large-scale images, due to its quadratic complexity in terms of input size [5]. The Nyström method,  a  well-established  technique  in  numerical  linear  algebra,  approximates  large-scale  kernel  matrices  with  a smaller subset of columns, significantly reducing computational overhead while maintaining a high level of accuracy [7].  By  integrating  Linear  Nyström  Attention  with  KAN  Convolutions,  KonvLiNA,  achieves  a  synergistic  effect, combining  the  fine-grained,  non-linear  function  modeling  capabilities  of  KAN  with  the  efficient  and  scalable attention mechanism of the Nyström method. This integration not only addresses the computational challenges posed by  large-scale  agricultural  images  but  also  enhances  the  model's  ability  to  capture  both  local  and  global  features essential for accurate crop field detection. To  this  end,  we  propose  KonvLiNA,  a  pyramid  feature  fusion  approach  for  enhancing  object  detection  in agricultural  fields.  The  approach  integrates  two  novel  modules:  Convolutional  KAN  Spatial  Pyramid  Pooling (cKSPP)  and  Enhanced  Nyström  Attention  Upsample  (ENAU).  The  former  effectively  leverages  the  expressive power  of  KAN  to  capture  the  complex,  intricate  details  prevalent  in  large  open  fields  like  farms,  while  the  latter utilizes the Linear Nyström Attention mechanism to address information loss, redundancy, and degradation of feature maps during the up-sampling process. Additionally, ENAU mitigates artifacts present during training and inference with  register  tokens.  The  proposed  hybrid  KonvLiNA  network  not  only  enhances  the  ability  to  capture  complex, intricate  details  but  also  improves  the  capturing  of  long-range  dependencies  prevalent  in  large,  open  farm  fields, where objects of interest may be tiny. The contributions of this study are summarized below: •  Designed a novel cKSPP module capable of efficiently capturing the complex, intricate details prevalent in agricultural fields. •  Designed  a  novel  ENAU  module,  which  mitigates  information  loss  and  artifacts  during  training  and inference. •  Extensive  experimental  results  demonstrate  promising  performance  compared  to  some  state-of-the-art pyramid feature fusion approaches. 2.   RELATED WORK Existing advanced pyramid feature fusion modules for object detection utilize either conventional CNNs, attention mechanisms,  or  a  hybrid  of  both  approaches  to  address  the  challenge  of  capturing  multi-scale  variations  in  object detection tasks. CNN Based. Asymptotic Feature Pyramid Network (AFPN) enhances object detection by enabling direct interaction between  non-adjacent  pyramid  levels,  initially  fusing  low-level  features  and  progressively  integrating  higher-level features  to  minimize  semantic  gaps.  Its  adaptive  spatial  fusion  effectively  handles  inconsistencies,  resulting  in improved  average  precision  and  computational  efficiency  on  the  MS  COCO  2017  dataset  compared  to  traditional FPNs [6]. The Parallel Residual Bi-Fusion Feature Pyramid Network (PRB-FPN) introduces a bi-directional feature fusion  approach,  utilizing  a  Bottom-Up  Fusion  Module  and  a  Concatenation  and  Re-Organization  module  with residual  design  for  high-quality  single-shot  object  detection.  This  method  achieves  state-of-the-art  results  on UAVDT17 and MS COCO datasets [9]. EfficientDet improves object detection through the weighted bi-directional feature  pyramid  network  (BiFPN)  for  efficient  multi-scale  feature  fusion  and  a  compound  scaling  method.  It improves accuracy with fewer parameters and FLOPs, with EfficientDet-D7 reaching 55.1 AP on the COCO test-dev [26]. RevBiFPN, a reversible bidirectional feature pyramid network, reduces memory requirements during training by  recomputing  hidden  activations.  It  shows  competitive  performance  with  EfficientNet  while  using  significantly less memory, making it suitable for large-scale models [16]. Attention and Hybrid Based. The Pyramid Attention Object Detection Network utilizes a multi-scale feature fusion pyramid  attention  module,  enhancing  the  detection  of  small  and  partially  occluded  objects  by  integrating  global average pooling results from multiple scales. This approach significantly improves detection accuracy on PASCAL VOC and MS COCO datasets [11]. ReAFFPN enhances rotation-equivariant feature fusion in aerial object detection through  Rotation-equivariant  Channel  Attention,  improving  classification  accuracy  and  feature  fusion  consistency. This  method  significantly  boosts  the  accuracy  of  Rotation-equivariant  Convolutional  Networks  (ReCNNs)  [12]. RHF-Net addresses small object detection on embedded devices by introducing a bidirectional fusion module and a recursive concatenation and reshaping module. It enhances detection accuracy and efficiency on COCO and UAVDT datasets  [10].  The  refined  marine  object  detector,  with  attention-based  spatial  pyramid  pooling  networks  and  a bidirectional  feature  fusion  strategy,  enhances  feature  representation  and  detection  accuracy  in  underwater environments, achieving high mAP on underwater image and URPC datasets [13]. The Attentional Feature Fusion module leverages attention mechanisms for superior feature integration, enhancing performance across various CNN architectures and achieving state-of-the-art results on CIFAR-100 and ImageNet [14]. The Feature Pyramid Network with Multi-Scale Prediction Fusion for real-time semantic segmentation uses a dual prediction module and attention mechanism  to  enhance  segmentation  accuracy  and  speed,  achieving  notable  performance  on  Cityscapes  and Mapillary Vistas datasets [15]. Discussion. While these advanced methods significantly improve object detection accuracy through enhanced multi- scale feature fusion and contextual information preservation, they primarily focus on general object detection tasks. There  is  a  lack  of  exploration  in  specific  applications  like  agriculture,  where  unique  challenges  such  as  varying scales  and  complex  backgrounds  are  prevalent.  To  address  these  challenges,  we  will  explore  integrating  KAN  to leverage  its  dynamic  learnable  activation  function  to  capture  richer  semantics  prevalent  in  crop  fields  with  Linear Nyström  Attention  mechanism  to  efficiently  capture  long-range  dependencies  and  preserve  contextual  information due to the object of interests spanning the whole image. This integration could lead to a more robust and accurate detection systems custom in agricultural applications, contributing significantly to the field of precision agriculture. 3.   METHOD AND TOOLS This section provides a general overview of KonvLiNA, which is based on a multi-scale fusion of Convolutional Kolmogorov-Arnold Network and up-sampling Linear Nyström Attention mechanism with Registers. High and low- level features extracted from the backbone networks are fed into KonvLiNA to extract multi-scale information from images  leveraging  the  expressive  power  of  KAN  using  the  cKSPP  module.  Then,  eNAU  to  mitigate  information degradation of spatial details during the fusion. Finally, fusing the top-down and lateral connections and the output is sent to the detection head. The remainder of this section presents the components used in the KonvLina framework. Refer to Figure 1 for illustrations of all interactions between each component. For precise crop field detection, KonvLiNA uses the Swin Transformer [16], a hierarchical image encoder that efficiently captures long-range dependencies and retains both low-level and high-level features by processing images in shifted local windows. The input 𝑋\t ∈ ℝ\"×$×% is partitioned into non-overlapping windows of size 𝑀 × 𝑀, where self-attention is computed within each window. These windows are then shifted by a fixed offset 𝑠 to capture cross- window  interactions,  and  features  are  aggregated  and  down-sampled  hierarchically.  Multi-scale  feature  maps 𝐹&, 𝐹’, 𝐹( are extracted from different layers, making the Swin Transformer a powerful image encoder. Kolmogorov-Arnold representation theorem states that any multivariate continuous function can be expressed as ’).& 𝑓(𝑥&, 𝑥’ … , 𝑥)\t) = \t 2 Φ* 42 ∅*,,6𝑥,7 *-& where Φ* and ∅𝒒,𝒑 are continuous functions mapping each input variable, 𝑥, and Φ* respectively. This allows KAN to  represent  complex  relationships  in  high-dimensional  data  by  combining  univariate  functions.  It  utilizes  this theorem  by  replacing  traditional  linear  weights  with  spline-parametrized  univariate  functions,  using  adaptive, learnable activation functions on edges between nodes with b-spline curves that adjust during training, which allows it  to  capture  complex  nonlinear  relationships  more  effectively  than  traditional  MLPs  with  non-learnable  activation functions, eqn. 2 is a deeper KAN architecture. 𝐾𝐴𝑁(𝑥) = \t (Φ12& \t ∘ \t Φ12’ ∘ … ∘ Φ3\t)(𝑥) where each  Φ1 denotes a KAN layer. The number of layers enables the detection of more complex patterns, with each layer 𝑙 applying a sequence of learnable functions ∅𝒒,𝒑, making the network flexible and robust. Convolutional KAN. [18] is inspired by the standard CNN architectures, requiring fewer parameters due to the use  of  b-splines.  These  splines  offer  smoother  activation  function  representations  compared  to  ReLU.  In  KAN convolutions, the implementation diverges from traditional CNN convolutions primarily in the nature of the kernel employed. While CNNs utilize weight-based kernels, Convolutional KANs operates kernels where each element, ∅, is a learnable non-linear function utilizing b-splines, eqn. 3 ∅ = \t 𝑤& ∙ 𝑠𝑝𝑙𝑖𝑛𝑒(𝑥) + \t 𝑤’ ∙ 𝑠𝑖𝑙𝑢(𝑥) In KAN Convolutions, the kernel traverses the image, applying the activation function ∅!4 to each pixel 𝑎56 and computing the output pixel as the sum of ∅!46𝑎!.5,4.67. Formally, if 𝐾 represents a KAN kernel in\tℝ7×8, then the image is represented as a matrix. 𝑖𝑚𝑎𝑔𝑒 = H The KAN convolution is defined as, (𝑖𝑚𝑎𝑔𝑒\t ∗ 𝐾) = \t ∑ . This approach effectively integrates 5-& the  flexibility  of  KANs  with  the  spatial  processing  capabilities  of  convolution  operations,  enhancing  the  model's ability to capture complex spatial dependencies in data. We  propose  cKSPP  by  leveraging  the  expressive  power  of  convolutional  KAN  using  its  dynamic  learnable activation function to capture richer semantics prevalent in crop open fields images. Our approach defines a multi- scale pooling to the outputs of the image encoder 𝐹&, 𝐹’, 𝐹(. Then we apply various pooling scales in order to encode multiple scale features. Adaptive average pooling changes the size of the input feature map to a fixed output size (s, s), where s represents the scale, for an input 𝑋\t ∈ ℝ\"×$×%!\", eqn. 4 formulates the spatial pooling operation. (𝔰) = 𝐴𝑣𝑔𝑃𝑜𝑜𝑙2𝐷(𝑋) ∈ ℝ\t𝔰×𝔰×%!\" (𝔰) is the pooled feature map at scale 𝔰. Then we applied KAN layer to 𝑋,::6 (𝔰) Where 𝑋,::6 prevalent in open fields farms. KAN has a learnable activation function which gives it better expressiveness using it splines curves which adjust during training. The operation is formulated in eqn. 5. capture complex pattern cKSPP captures richer semantics by combining multi-scale pooling with KAN dynamic learnable activation function. This approach enhances the expressiveness of the model, enabling it to detect complex patterns across various scales, particularly  in  challenging  environments  like  open-field  farms.  By  adapting  feature  maps  to  different  scales  and refining them through KAN, cKSPP improves the model's ability to handle diverse and intricate visual data. In  this  section,  we  propose  a  novel  up-sampling  method  using  a  Linear  Nyström  Attention  to  mitigate information loss, degradation of feature maps, and reduce artifacts in KonvLiNA. Given a normalized feature map 𝑋\t ∈ ℝ1×% (where 𝐿 represents the length of the sequence) generated by the cKSPP module, we first apply a 1 × 1 convolution  for  dimensionality  reduction,  ensuring  the  feature  map  channel  dimension  is  appropriately  scaled  for subsequent processing. Next, we generate the query 𝑄, key 𝐾, and value 𝑉 matrices from input 𝑋. We then apply the Nyström  method  to  approximate  the  self-attention  mechanism,  which  enables  more  efficient  computation.  The Nyström  approximation  utilizes  a  subset  of  the  sequence  data  to  estimate  the  full  attention  matrix,  reducing  the computational complexity while maintaining the benefits of attention. Then we compute low-rank approximations of the  attention  matrix  by  projecting  𝑄  and  𝐾  onto  a  lower-dimensional  space.  This  approximation  allows  us  to efficiently compute attention scores and apply them to 𝑉, resulting in attention outputs with reduced computational complexity to 𝑂(𝑁 log 𝑁). Refer to eqn. 6 for Nyström Approximation. To  preserve  sequence  order,  we  add  relative  positional  encoding.  The  learnable  positional  encodings  are initialized with random values 𝑝FG6 ∈ ℝH×I’×1, where ℎ is the number of heads and 𝐷H is the dimension of each head. This encoding matrix 𝑃 = 𝑝FG6 is used to integrated positional information into the attention mechanism. We utilize learnable  deconvolutional  layers  for  up-sampling  to  better  preserve  fine  details  and  adaptively  enhance  quality, unlike nearest neighbor interpolation, which is non-trainable and can lead to redundant up-sample feature maps. This effectively up-samples the sequence length, resulting in the projection of the attention outputs with higher resolution. Lastly, to address the problem of artifacts introduced by attention mechanisms and deconvolutions, we introduce registers  [19].  The  registers  are  added  to 𝑄  and 𝐾  as (𝑄, 𝐾)J = (𝑄𝐾) + 𝑅  and  to 𝑉  as 𝑉J = 𝑉 + 𝑅, where 𝑅  is trainable token with the same size as 𝑄𝐾𝑉 vectors. These registers are discarded after computing the Linear Nyström Attention during training and inference. The Nyström method approximates the attention mechanism by selecting a subset of 𝑚 landmarks from 𝐾. Let 𝐾9 ∈ ℝ9×K( be the subset of landmarks, and 𝑄9 be the corresponding queries. The approx. is computed as in eqn. 6. Nyström\t(𝑄, 𝐾, 𝑉) ≈ softmax 4 8 nsoftmax 4 softmax 4 This  approximation  reduces  the  complexity  of  self-attention  from  𝑂(𝑁’)  to  𝑂(𝑁 log 𝑁) ,  making  it  more KonvLiNA module combines eNAU and cKSPP through a pair-wise addition fusion operation. eNAU utilizes a Linear Nyström Attention mechanism to reduce information loss and mitigate homogeneous semantic information, while cKSPP applies custom spatial pyramid pooling for multi-scale feature extraction, capturing intricate details of small objects in images. The cKAN layer further enhances the module by capturing complex patterns typical in open- field farms, leveraging KAN expressive power through its learnable activation function. The combined output is then fed into a YOLOv8 detection head, which operates across three pyramid levels to effectively detect objects in open farm  environments.  This  approach  ensures  robust  detection  by  preserving  spatial  details  and  capturing  diverse features, both crucial for agricultural applications. In this section, we report the experimental results and evaluate KonvLiNA both quantitatively and qualitatively to assess its effectiveness in enhancing crop fields object detection using two main datasets. Dataset and metric. The Mendeley Rice Leaf Disease dataset [20] was used, which consists of 5,932 images of four disease types: Brown Spot, Bacterial Blight, Blast, and Tungro. This dataset was used to validate the effectiveness of our method and compare it with existing methods. Additionally, to evaluate the robustness of our method, we utilized the  COCO  dataset,  which  consists  of  330,000  images  of  80  object  categories.  Average  Precision  (AP)  and  Mean Average Precision (mAP) were used to evaluate the model's performance. Experimental setup. The input images were set to 640 × 640 pixels pixels for both training and evaluation over 90 epochs  using  the  YOLOv8  network  settings.  The  bias  values  for  the  classification  and  localization  layers  in  the detection  head  were  set  to  0.01  and  0.1,  respectively.  A  Gaussian  weight  with  σ  =  0.01  was  used  in  all  layers, including  the  proposed  feature  selection  network.  We  used  Adam  optimizer  with  an  initial  learning  rate  of  0.001, weight decay of 0.0005, and momentum of 0.95. Data augmentation included 0.5 horizontal/vertical flip, mosaic of 0.9, and scale of 0.5. Due to the small training dataset, we fine-tuned with the MS-COCO pre-trained weights. This  section  evaluates  the  performance  of  YOLOv8  with  KonvLiNA  and  with  other  feature  pyramid  fusion models with Mendeley RLD crop dataset. In addition, we evaluated it with COCO dataset for robustness. Rice  Crop  Disease  Dataset.  Utilizing  the  Swin-L  backbone,  KonvLiNA  outperforms  all  other  methods  with improvements of 3.50% in AP and 4.37% in AR over YOLOv8, 0.75% in AP and 2.94% in AR over DETR, 0.73% in AP and 3.79% in AR over HTC++, 2.30% in AP and 4.20% in AR over ViT Det, and 0.08% in AP and 3.80% in AR over DINO. Overall, these results demonstrate significant performance enhancements in detecting objects with various variations prevalent in Rice Crop fields, where objects of interest are typically small due to the size of rice leaves. This highlights the potential benefits of exploring hybrid KAN and attention mechanisms in such scenarios. COCO dataset. On the COCO dataset, KonvLiNA achieves competitive AP across small, medium, and large objects compared to various Faster R-CNN configurations with different FPN. We  also  provide  a  qualitative  evaluation  in  Fig.  3,  demonstrating  that  the  KonvLiNA  module  significantly enhances the rice crop detection across diverse object sizes, particularly smaller objects, compared to Faster R-CNN and DETR. e.g., in the upper-left of Fig. 3a, KonvLiNA effectively identifies small disease spots on rice leaves that Faster  R-CNN  misses.  Also,  KonvLiNA  outperforms  Faster  R-CNN  and  DETR  in  detecting  several  very  small objects in Fig. b. These findings align with our quantitative results, emphasizing KonvLiNA robust performance on small disease spots and its improved accuracy under varying occlusion levels. However, despite these improvements, our model still misses some extremely challenging disease objects, as shown in KonvLiNA Fig. c. right side. Overall, these qualitative findings highlight the effectiveness of our approach and the significant improvement achieved through detecting small or extremely varied objects in open crop field environments i.e. rice crops. Ablation.  On  the  RLD  dataset  demonstrates  that  integrating  eNAU  into  the  baseline  KonvLiNA  configuration increases  AP  by  1.7%  (from  0.359  to  0.365)  and  AR  by  3.5%  (from  0.371  to  0.384),  while  including  cKSPP alongside eNAU further enhances AP by 15.6% (from 0.359 to 0.415) and AR by 23.7% (from 0.371 to 0.459). 5.   CONCLUSION In this study, we proposed a novel feature pyramid fusion network, KonvLiNA, aimed at improving crop field detection  by  effectively  addressing  the  challenge  of  scale  variation.  Our  hybrid  module  combines  the  cKAN  and Nyström  attention  mechanisms.  Additionally,  we  introduced  eNAU  and  cKSPP,  which  reduce  information  loss during feature fusion and enhance the model's ability to capture intricate patterns through the expressiveness of the KAN  activation  function.  These  novelties  collectively  improve  the  model's  performance  in  detecting  crop  fields, demonstrating the effectiveness of our approach. Personal website pattern recognition  and machine  learning,  image processing  and  computer artificial vision, and intelligence and knowledge engineering *This form helps us to understand your paper better, the form itself will not be published. *Title  can  be  chosen  from:  master  student,  Phd  candidate,  assistant  professor,  lecture,  senior  lecture,  associate",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2408/2408.13160v1.pdf",
         "extracted",
         "None",
         "",
         "KonvLiNA: integrating Kolmogorov-Arnold Network with linear Nyström attention for feature fusion in crop field detection"
        ],
        [
         "27",
         "01214e9843a9cb75620b8f1af6eee62236745c96",
         "Sperm motility is crucial for male reproduction and relies on the structural integrity of the sperm axoneme, which has a “9+2” microtubule configuration. This structure includes nine outer doublet microtubules (DMTs) that house various macromolecular complexes. The nexin-dynein regulatory complex (N-DRC) forms a crossbridge between adjacent DMTs, stabilizing them and facilitates sperm tail bending. Our study of ANKRD5, which is highly expressed in the sperm axoneme, reveals its interaction with DRC5/TCTE1 and DRC4/GAS8, both critical components of the N-DRC, and these interactions were found to be independent of calcium regulation. ANKRD5-/- mice exhibited reduced sperm motility and male infertility. Cryo-electron tomography analysis reveals typical “9+2” axoneme and intact DMT structures in Ankrd5-/- mouse sperm, but the DMTs displayed significant morphological variations and greater structural heterogeneity. Furthermore, ANKRD5 deficiency did not affect ATP level, ROS levels, or mitochondrial membrane potential. These findings suggest that ANKRD5 may weaken the N-DRC’s “car bumper” role, reducing the buffering effect between adjacent DMTs and thereby destabilizing axoneme structures during intense axoneme motility. Graphic Abstract Significance Statement Male infertility affects 8%-12% of men globally, with defects in sperm motility accounting for 40%-50% of these cases. The axoneme, serving as the sperm’s motor apparatus, features a 9+2 microtubule arrangement, with the nexin-dynein regulatory complex (N-DRC) providing essential structural support between outer microtubule doublets. Understanding the synergistic relationship between the N-DRC’s structure and its protein composition is crucial for advancing male reproductive biology. In this study, we identify the protein ANKRD5 as a component of the axoneme that can interact with N-DRC components, which is crucial for sperm motility. This discovery enhances our understanding of sperm motility mechanisms and suggests potential targets for male contraceptive development.",
         "Shuntai Yu,Guoliang Yin,Peng Jin,Weilin Zhang,Yingchao Tian,Xiaotong Xu,Tianyu Shao,Yushan Li,Fei Sun,Yun Zhu,Fengchao Wang",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/07/2024.12.03.626701.full.pdf",
         "None",
         "None",
         "",
         "ANKRD5: a key component of the axoneme required for sperm motility and male fertility"
        ],
        [
         "28",
         "01229dfa2329d554185174e6705a95fae143cf63",
         "Activities of daily living rely on our ability to acquire new motor skills composed of precise action sequences. Here, we asked if the millisecond-level neural representation of an action performed at different contextual sequence locations within a skill differentiates or remains stable during early motor learning. We first optimized machine learning decoders predictive of sequence-embedded finger movements from magnetoencephalographic (MEG) activity. Using this approach, we found that the neural representation of the same action performed in different contextual sequence locations, progressively differentiated—primarily during rest intervals of early learning (offline)—correlating with skill gains. In contrast, representational differentiation during practice (online) did not reflect learning. The regions contributing to this representational differentiation evolved with learning, shifting from the contralateral pre- and post-central cortex during early learning (trials 1–11) to increased involvement of the superior and middle frontal cortex once skill performance plateaued (trials 12–36). Thus, the neural substrates supporting finger movements and their representational differentiation during early skill learning differ from those supporting stable performance during the subsequent skill plateau period. Representational contextualization extended to Day 2, exhibiting specificity for the practiced skill sequence. Altogether, our findings indicate that sequence action representations contextually differentiate during early skill learning, an issue relevant to brain-computer interface applications in neurorehabilitation.",
         "Dabedatta Dash,Fumiaki Iwane,William Hayward,R. Salamanca-Giron,Marlene Bonstrup,E. Buch,L. G. Cohen",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/15/2024.08.15.608189.full.pdf",
         "None",
         "None",
         "",
         "Sequence action representations contextualize during early skill learning"
        ],
        [
         "29",
         "013cb58c3526d64e0f8e0d18d71c57250eaa0db2",
         "Despite the major role of nurseries in raising young plants and trees prior to transplantation, not enough is known about how the nursery climate impacts the growth and development of plants from germination through to maturity. It is important for forestry practitioners to understand the effect that different nursery environments may have on early stage growth as these may exceed differences due to genetic variation and can confound the use of early stage traits for selection. Here, a replicated progeny-provenance experiment of the economically and ecologically important species Scots pine (Pinus sylvestris L.) was established in three environmentally distinct nurseries in Scotland and traits including survival, growth, form and phenology were measured. Temperature variation and photoperiod were the only uncontrolled environmental variables during this period, and their effect on measured traits was found to be significant among nurseries from the first growing season onwards. Trait interactions were not consistent between nurseries, indicating that the effectiveness of using proxy traits to select for desirable characteristics may depend on the environment in which the trees are grown. This study is the first in a series that will examine trait variation in Scots pine from seedlings to mature trees and highlights the importance of carefully considering and accounting for the nursery environment when growing trees for subsequent transplantation.",
         "A. Perry,Joan K. Beaton,J. Stockan,G. Iason,J. Cottrell,S. Cavers",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/08/20/2024.08.20.608769.full.pdf",
         "None",
         "None",
         "Meeting tree planting targets on the UK's path to net-zero: A review of lessons learnt from 100 years of land use policies;Phenotypic trait variation in a long-term multisite common garden experiment of Scots pine in Scotland;Explaining Extreme Events of 2020 from a Climate Perspective;Phenotypes of Pinus sylvestris are more coordinated under local harsher conditions across Europe;Selection patterns on early-life phenotypic traits in Pinus sylvestris are associated with precipitation and temperature along a climatic gradient in Europe.;Reaching Natural Growth: The Significance of Light and Temperature Fluctuations in Plant Performance in Indoor Growth Facilities;Guidance for successful tree planting initiatives;Cryptic genetic variation and adaptation to waterlogging in Caledonian Scots pine, Pinus sylvestris L.;Age–age correlations and early selection for growth traits in 40 half-sib families of Larix principis-rupprechtii;Pampered inside, pestered outside? Differences and similarities between plants growing in controlled conditions and in the field.;Has Scots pine (Pinus sylvestris) co‐evolved with Dothistroma septosporum in Scotland? Evidence for spatial heterogeneity in the susceptibility of native provenances;Bud flush phenology and nursery carryover effect of paper birch provenances;Age trend of heritability, genetic correlation, and efficiency of early selection for wood quality traits in Scots pine;Plant growth and mortality under climatic extremes: An overview;What controls tropical forest architecture: testing environmental, structural and floristic drivers;Cultivation of Norway spruce and Scots pine on organic nitrogen improves seedling morphology and field performance;Seasonal patterns of photochemical capacity and spring phenology reveal genetic differentiation amon;A Large and Persistent Carbon Sink in the World’s Forests;Efficiency of the indirect selection and the evaluation of the genotype by environment interaction using Pilodyn for the genetic improvement of wood density in Cryptomeria japonica;A method to construct dose-response curves for a wide range of environmental factors and plant traits by means of a meta-analysis of phenotypic data.;Evaluation of leaf traits for indirect selection of high yielding poplar hybrids;The physiological basis of containerised tree seedling ‘transplant shock’: a review;Age–age and trait–trait correlations for Eucalyptus grandis Hill ex Maiden and their implications for optimal selection age and design of clonal trials;Effects of soil temperature on biomass and carbohydrate allocation in Scots pine (Pinus sylvestris) seedlings at the beginning of the growing season.;Effect of Peat-based Container Media on Establishment of Scots Pine, Norway Spruce and Silver Birch Seedlings after Transplanting in Contrasting Water Conditions;Current and future status of Scots pine (Pinus sylvestris L.) forests in Europe;Heritable variation and evolution under favourable and unfavourable conditions.;The nitrogen economy of mountain birch seedlings: implications for winter survival;Effect of diurnal temperature alternations on plant morphology in some greenhouse crops. A mini review;Seasonal and geographical variation of terpenes, resin acids and total phenolics in nursery grown seedlings of Scots pine (Pinus sylvestris L.);Effects of root temperature on growth and photosynthesis in conifer seedlings during shoot elongation.;Nestling growth in the Great Tit I. Heritability estimates under different environmental conditions;Accelerated short-term genetic testing for loblolly pine families;Effects of Photoperiod on Growth of Trees;Autumn versus spring planting: the initiation of root growth and subsequent field performance of Scots pine and Norway spruce seedlings;Photoperiod- and temperature-mediated control of phenology in trees - a molecular perspective.;GENETIC SURVEY OF PINUS RADIATA. 5: BETWEEN-TRAIT AND AGE-AGE CORRELATIONS FOR GROWTH RATE, MORPHOLOGY, AND DISEASE RESISTANCE;Plant Growth and Climate Change.;Low temperature, but not photoperiod, controls growth cessation and dormancy induction and release in apple and pear.;Selection of parents for the Scots pine breeding population in Britain;Using Native Stock for Planting Native Trees and Shrubs;On the sampling variance of interclass correlations and genetic 786 correlations;Genotype by environment interaction and genetic 795 correlation of greenhouse and field performance in Pinus contorta ssp. latifolia . 796 Silvae;Forest nursery practice.;Effect of fertilization and watering of Scots pine seedlings on the feeding preference of the pine weevil (Hylobius abietis L.).;Tree planting: not a simple solution;Applied Tree Improvement;Growth response of woody plants to photoperiodic stimuli;Table 1. Traits measured in individual seedlings, grouped into ‘Growth’, ‘Form’, ‘Phenology’ and ‘Survival’. Units for;age of the trees increased and as the number of years between comparisons decreased;through to maturity. The trees in this study have now been transplanted to three field;organisms grow should lead to higher or lower heritability of quantitative traits;Introduction to Quantitative Genetics . 4th ed. Essex, UK: Longman, 1996.;variances when data from 2007 are not included. For traits measured in multiple years, only the most recent year is shown;transplanted to their field locations, as measurements can be made over many more years",
         "Tree nursery environments and their effect on early trait variation"
        ],
        [
         "30",
         "0142fc80cb50bb72904e314218eaebac59ddfa68",
         "Purpose Diffusion MRI (dMRI) data typically suffer of significant cross-site variability, which prevents naively performing pooled analyses. To attenuate cross-site variability, harmonization methods such as the rotational invariant spherical harmonics (RISH) have been introduced to harmonize the dMRI data at the signal level. A common requirement of the RISH method, is the availability of healthy individuals who are matched at the group level, which may not always be readily available, particularly retrospectively. In this work, we propose a framework to harmonize dMRI without matched training groups. Methods Our framework learns harmonization features while controlling for potential covariates using a voxel-based generalized linear model (RISH-GLM). RISH-GLM allows to simultaneously harmonize data from any number of sites while also accounting for covariates of interest, thus not requiring matched training subjects. Additionally, RISH-GLM can harmonize data from multiple sites in a single step, whereas RISH is performed for each site independently. Results We considered data of training subjects from retrospective cohorts acquired with 3 different scanners and performed 3 harmonization experiments of increasing complexity. First, we demonstrate that RISH-GLM is equivalent to conventional RISH when trained with data of matched training subjects. Secondly, we demonstrate that RISH-GLM can effectively learn harmonization with two groups of highly unmatched subjects. Thirdly, we evaluate the ability of RISH-GLM to simultaneously harmonize data from 3 different sites. Discussion RISH-GLM can learn cross-site harmonization both from matched and unmatched groups of training subjects, and can effectively be used to harmonize data of multiple sites in one single step.",
         "A. Luca,Tine Swartenbroekx,H. Seelaar,J. V. van Swieten,Suheyla Cetin Karayumak,Y. Rathi,O. Pasternak,L. Jiskoot,A. Leemans",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/05/03/2024.05.01.591994.full.pdf",
         "None",
         "None",
         "Lifespan reference curves for harmonizing multi-site regional brain white matter metrics from diffusion MRI;Neuroimaging standards for research into small vessel disease—advances since 2013;Abnormal white matter changes in Alzheimer's disease based on diffusion tensor imaging: A systematic review;Improved sensitivity and precision in multicentre diffusion MRI network analysis using thresholding and harmonization;Multimodal tract-based MRI metrics outperform whole brain markers in determining cognitive impact of small vessel disease-related brain injury;Cross-site harmonization of multi-shell diffusion MRI measures based on rotational invariant spherical harmonics (RISH);Diffusion MRI harmonization enables joint-analysis of multicentre data of patients with cerebral small vessel disease;Towards multicentre diffusion MRI studies in cerebral small vessel disease;MarkVCID cerebral small vessel consortium: I. Enrollment, clinical, fluid protocols;Cross-scanner and cross-protocol multi-shell diffusion MRI data harmonization: Algorithms and results;A prospective harmonized multicenter DTI study of cerebral white matter degeneration in ALS;Generalized Richardson-Lucy (GRL) for analyzing multi-shell diffusion MRI data;Cross-scanner and cross-protocol diffusion MRI data harmonisation: A benchmark database and evaluation of algorithms;Scanner invariant representations for diffusion MRI harmonization;Retrospective harmonization of multi-site diffusion MRI data acquired with different acquisition parameters;Inter-Scanner Harmonization of High Angular Resolution DW-MRI using Null Space Deep Learning;Presymptomatic white matter integrity loss in familial frontotemporal dementia in the GENFI cohort: A cross‐sectional diffusion tensor imaging study;On modeling;Current Clinical Applications of Diffusion-Tensor Imaging in Neurological Disorders;Harmonization of cortical thickness measurements across scanners and sites;Harmonization of multi-site diffusion tensor imaging data;The importance of correcting for signal drift in diffusion MRI;Denoising of diffusion MRI using random matrix theory;Inter-site and inter-scanner diffusion MRI data harmonization;The effect of Gibbs ringing artifacts on measures derived from diffusion MRI;REKINDLE: Robust extraction of kurtosis INDices with linear estimation;Lifespan maturation and degeneration of human brain white matter;Faculty Opinions recommendation of Tract-based spatial statistics: voxelwise analysis of multi-subject diffusion data.;Diffusion MRI at 25: Exploring brain tissue structure and function;A reproducible evaluation of ANTs similarity metric performance in brain image registration;Microstructural maturation of the human brain from childhood to adulthood;Empirical Bayes Methods;Harmonization;Toward a quantitative assessment of diffusion anisotropy;Matter;multimodal brain 3 T MRI harmonisation approaches;presymptomatic familial frontotemporal dementia;ExploreDTI: a graphical toolbox for processing, analyzing, and visualizing diffusion MR data;Adjusting batch effects in microarray expression data using empirical Bayes methods.;Microstructural and physiological features of tissues elucidated by quantitative-diffusion-tensor MRI.;MR diffusion tensor spectroscopy and imaging.;Spin diffusion measurements : spin echoes in the presence of a time-dependent field gradient;Submitted to Magnetic Resonance in Medicine Corresponding author: Alberto De Luca (a.deluca-2@umcutrecht.nl) Word count: 3924 words;Discussion: RISH-GLM can learn cross-site harmonization both from matched and unmatched groups training subjects, and can effectively be used to harmonize data of multiple sites in;This study is funded by the Bluefield Project to cure FTD;determined with RISH-GLM on data from all three sites in Experiment 3",
         "Cross-site harmonization of diffusion MRI data without matched training subjects"
        ],
        [
         "31",
         "0155e40ceb6ddc83a93fb431cc86ebe135079cab",
         "None",
         "Yao-Kun Wang,Li-Zhu Ge,Tinggui Zhang,Shao-Ming Fei,Yufeng Gao,Zhixi Wang",
         "\n**BLOCK**fs== 9.0**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nYao-Kun Wang,1 Li-Zhu Ge,2 Tinggui Zhang,3 Shao-Ming Fei,4 and Zhi-Xi Wang4\n1College of Mathematics, Tonghua Normal University, Tonghua, Jilin 134001, China\n2The Branch Campus of Tonghua Normal University, Tonghua, Jilin 134001, China\n3School of Mathematics and Statistics, Hainan Normal University, Haikou, 571158, China\n4School of Mathematical Sciences, Capital Normal University, Beijing 100048, China\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nWe study the dynamics of the quantum battery capacity for the Bell-diagonal states under Marko-\nvian channels on the ﬁrst subsystem. We show that the capacity increases for special Bell-diagonal\nstates under amplitude damping channel. The sudden death of the capacity occurs under depolar-\nizing channel. We also investigate the capacity evolution of Bell-diagonal states under Markovian\nchannels on the ﬁrst subsystem n times. It is shown that the capacity under depolarizing channel\ndecreases initially, then increases for small n and tend to zero for large n. We ﬁnd that under bit\nﬂip channel and amplitude damping channel, the quantum battery capacity of special Bell-diagonal\nstates tends to a constant for large n, namely, the frozen capacity occurs. The dynamics of the\ncapacity of the Bell-diagonal states under two independent same type local Markovian channels is\nalso studied.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\nINTRODUCTION\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nWith the rapid development of quantum information and quantum thermodynamics, some novel quantum\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\ndevices have been introduced recently. The quantum battery presented by R. Alicki and M. Fannes shows\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nthe maximum amount of energy that can be extracted from a quantum system in an informational theoretic\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nview[1]. Since then many interesting results have been obtained [2–53], including the construction of charging\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nmodels [5, 6, 9, 10, 13, 30, 36, 37] and many-body quantum batteries[8, 14, 20–22, 28, 29, 48]. Among them,\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFerraro et al. proved that the quantum battery charges faster than the ordinary batteries in collective\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\ncharging mode[9]. A series of other quantum battery models have been also brought up[8, 16, 53], together\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nwith some experimental studies[54–58], see [50] for a review of quantum batteries.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nAn important indicator of quantum batteries is the battery capacity[35, 42]. Recently, the authors in Ref.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[42] provided a new deﬁnition of quantum battery capacity,\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nλ1 ≤ · · · ≤\nwhere λ0 ≤\neigenenergies of the Hamiltonian H =\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.7**l== 0.3**r== 0.3**\nλd−1 represent the eigenvalues of the quantum state ρ and ǫ0 ≤\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n. C(ρ, H) is a Schur-convex functional of the quantum\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nstate and does not alter whenever the battery is unitarily charged.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nIn this article, we investigate the evolution of quantum battery capacity in Bell-diagonal states, when the\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nﬁrst subsystem undergoes Markovian channels. We show that the quantum battery capacity of the Bell-\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\ndiagonal states increases under amplitude damping channel. In particular, we ﬁnd that the phenomenon\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nof sudden death of the quantum battery capacity occurs for special Bell-diagonal states under depolarizing\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nchannel. We also study the capacity evolution of Bell-diagonal states when the ﬁrst subsystem undergoes n\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\ntimes Markovian channels. It is shown that the capacity under depolarizing channel decreases initially, and\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nthen increases for small n and tends to 0 for large n. We also ﬁnd that phenomenon of frozen of capacity\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\noccurs for special Bell-diagonal states under bit ﬂip channel and amplitude damping channel for large n. In\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\naddition, we investigate the dynamics of capacity of the Bell-diagonal states under two independent local\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nMarkovian channels of the same type.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nII. QUANTUM BATTERY CAPACITY OF BELL-DIAGONAL STATES UNDER\nMARKOVIAN CHANNELS\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nWe consider the initial states to be the two-qubit Bell-diagonal ones,\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwhere σ1, σ2, σ3 are the standard Pauli matrices, ci, i = 1, 2, 3, are real constants such that ρAB is a\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nwell deﬁned density matrix. ρAB has eigenvalues λ0 = (1\nλ2 = (1 + c1 −\nfor j = 0, 1, 2, 3.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\nc2 + c3)/4 and λ3 = (1 + c1 + c2 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nc3)/4. The coeﬃcients ci are chosen such that λj\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.1**r== 0.3**\nLet us consider the following Hamiltonian for the two-qubit system, HAB = ǫAσ3 ⊗\n−\n≥\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\n0. The eigenvalues of HAB are\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.6**r== 0.1**\nσ3, where\nǫB and ǫA + ǫB in ascending order.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nǫA + ǫB, ǫA\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nTherefore, if c1 > c2 > c3 > 0, then λ0 < λ1 < λ2 < λ3. From (1) we have\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.3**r== 0.4**\nC123(ρAB, HAB) = (c1 + c2)(ǫA + ǫB) + (c1 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFor c1 > c3 > c2 > 0, we have λ0 < λ1 < λ3 < λ2 and\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\nC132(ρAB, HAB) = (c1 + c3)(ǫA + ǫB) + (c1 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nFor c2 > c1 > c3 > 0, we have λ0 < λ2 < λ1 < λ3 and\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\nC213(ρAB, HAB) = (c2 + c1)(ǫA + ǫB) + (c2 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nFor c2 > c3 > c1 > 0, we have λ0 < λ2 < λ3 < λ1 and\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nC231(ρAB, HAB) = (c2 + c3)(ǫA + ǫB) + (c2 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nFor c3 > c1 > c2 > 0, we have λ0 < λ3 < λ1 < λ2 and\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nC312(ρAB, HAB) = (c3 + c1)(ǫA + ǫB) + (c3 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nFor c3 > c2 > c1 > 0, we have λ0 < λ3 < λ2 < λ1 and\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nC321(ρAB, HAB) = (c3 + c2)(ǫA + ǫB) + (c3 −\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nThe reduced states of ρAB are ρA = I2/2 and ρB = I2/2, respectively. Consequently, we have C(ρA, HA) = 0.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n(1) Quantum battery capacity evolution of Bell-diagonal states under Markovian channels on the ﬁrst\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nWe will focus on the evolution of a quantum state ρ under a trace-preserving quantum operation ε(ρ)[59],\n**BLOCK**fs== 9.0**p== 2.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\nKraus operators\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nTABLE I: Kraus operators for the qubit quantum channels: bit ﬂip channel (bf), phase ﬂip channel (pf), bit-phase\nﬂip channel(bpf), depolarizing channel (dep), and generalized amplitude damping channel (gad), where p and γ are\ndecoherence probabilities, 0 < p < 1, 0 < γ < 1.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nKraus operators of some typical channels are listed by in Table I [60], where the decoherence processes bit\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nﬂip channel (bf), phase ﬂip channel (pf), bit-phase ﬂip channel(bpf) and depolarizing channel (dep) preserve\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nthe Bell-diagonal form of the density operator ρ. For the case of generalized amplitude damping channel\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n(gad), the Bell-diagonal form is kept for arbitrary γ and p = 1/2. In this situation, one has\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nwhere c′\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.6**\nWhen c1 > c2 > c3 > 0, from Table II, c′\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\n1, 1] are given in Table II [60].\n2, c′\n(dep), and generalized amplitude damping channel (gad) satisfy the condition for Eq. (3), i.e., c′\nLet Cbf\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n3 of ρ′ under bit ﬂip channel (bf), depolarizing channel\n2 > c′\n3.\n123 (ρ′, HAB) be quantum battery capacity of ρ′ under bit ﬂip\nchannel, depolarizing channel and generalized amplitude damping channel, respectively. By Eq. (5) and\n**BLOCK**fs== 7.0**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\n123 (ρ′, HAB) and Cgad\n**BLOCK**fs== 7.0**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\n123(ρ′, HAB), Cdep\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\n(3), we have\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nCbf\n123(ρ′, HAB) = (c1 + c2(1\n−\nCdep\n123 (ρ′, HAB) = (c1 + c2)(1\nCgad\n123 (ρ′, HAB) = (c1 + c2)(1\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.4**r== 0.4**\np)2)(ǫA + ǫB) + (c1 −\n4p/3)(ǫA + ǫB) + (c1 −\n−\np)(ǫA + ǫB) + (c1 −\nc2)(1\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nUnder the amplitude damping channel, the Bell-diagonal states are transformed into the output state,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.0**t== 0.9**l== 0.2**r== 0.6**\n(c1 −\n−\nadc are u0 = 1/4(1\np) + p2), u2 = 1/4(1 + c3(1\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nThe eigenvalues of ρ′\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\nChannel\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nTABLE II: Correlation coeﬃcients for the quantum operations: bit ﬂip channel (bf), phase ﬂip channel (pf), bit-\nphase ﬂip channel (bpf), depolarizing channel (dep), and generalized amplitude damping channel (gad). For gad,\nwe have ﬁxed p = 1/2 and replaced γ by p.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\np) + p2). Set c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. We have u0 < u2 < u3 <\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\np\nu1, see Fig. 1 (a). Using Eq. (1) we obtain\n**BLOCK**fs== 7.0**p== 3.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nadc, HAB) =\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\np) + p2(ǫA + ǫB) +\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nFrom Fig. 1 (b), we see that for the initial Bell-diagonal states the quantum battery capacity decreases as\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\np increases under bit ﬂip channel, depolarizing channel and generalized amplitude damping channel. Under\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\ngeneralized amplitude damping channel the quantum battery capacity approaches to zero as p increases to\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\n1. Under depolarizing channel the quantum battery capacity becomes zero as p\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.7**r== 0.1**\n0.75, a phenomenon of\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nsudden death of quantum battery capacity. On the other hand, the quantum battery capacity increases as\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\np increases under amplitude damping channel.\n**BLOCK**fs== 2.5**p== 3.0**b== 0.3**t== 0.7**l== 0.2**r== 0.8**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 2.2**p== 3.0**b== 0.3**t== 0.7**l== 0.5**r== 0.5**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.4**\nFIG. 1: (a) The eigenvalues of ρ\nQuantum battery capacity evolution for Bell-diagonal states with\nunder bit ﬂip channel (C bf\namplitude damping channel (C gad\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.5**\n123), depolarizing channel (C dep\n123 ) as a function of p.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\n′\nadc as a function of p for c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. (b)\nc1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3\n}\n{\n123 ) and generalized\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.5**r== 0.2**\n123 ), amplitude damping channel (C adc\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nWhen c2 > c3 > c1 > 0, we have c′\n231 (ρ′, HAB) and Cdep\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nTable II. Let Cbpf\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.4**r== 0.1**\n1 under bit-phase ﬂip (bpf), depolarizing channel (dep), see\n231 (ρ′, HAB) denote the quantum battery capacity of ρ under bit-phase\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.4**\nﬂip and depolarizing channel, respectively. By Eq. (5) and (4) we have\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\n231 (ρ′, HAB) = (c2 + c3(1\n−\nCdep\n231 (ρ′, HAB) = (c2 + c3)(1\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\np)2)(ǫA + ǫB) + (c2 −\nc3(1\n4p/3)(ǫA + ǫB) + (c2 −\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nSet c1 = 0.1, c2 = 0.5, c3 = 0.3, ǫA = 0.6 and ǫB = 0.3. We have u0 < u2 < u1 < u3, see Fig. 2. (a).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nUsing Eq. (1) we have\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nadc, HAB) = 1/2(2c3 +\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.7**r== 0.2**\np) + p2)(ǫA + ǫB)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nThe quantum battery capacity evolutions under bit-phase ﬂip channel, depolarizing channel, generalized\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\namplitude damping channel and amplitude damping channel are similar with the situation of c1 > c2 >\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\nc3 > 0, see Fig. 2 (b).\n**BLOCK**fs== 2.5**p== 4.0**b== 0.5**t== 0.5**l== 0.2**r== 0.8**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 2.2**p== 4.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nFIG. 2: (a) The eigenvalues of ρ\nbattery capacity evolution for Bell-diagonal states with\nphase ﬂip channel (C bpf\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\n′\nadc as a function of p for c1 = 0.1, c2 = 0.5, c3 = 0.3, ǫA = 0.6, ǫB = 0.3. (b) Quantum\nunder bit-\n231 )) as a function of p.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.6**l== 0.5**r== 0.2**\nc1 = 0.1, c2 = 0.5, c3 = 0.3, ǫA = 0.6, ǫB = 0.3\n}\n{\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\n231 ) and amplitude damping channel (C adc\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.7**l== 0.3**r== 0.5**\n231 ), depolarizing channel (C dep\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nWhen c3 > c2 > c1 > 0, the quantum battery capacity for the same Bell-diagonal state under phase\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nﬂip channel is similar with the situations of bit ﬂip channel c1 > c2 > c3 > 0 and bit-phase ﬂip channel\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\n(2) Quantum battery capacity evolution under n times Markovian channels on the ﬁrst subsystem\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nNext, we consider the quantum battery capacity dynamics of Bell-diagonal states under n times Markovian\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nchannels on the ﬁrst subsystem. As the decoherence processes bf, pf, bpf, dep and gad preserve the Bell-\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.2**\ndiagonal form of the density operator, the parameters of the output state are given by c′\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.8**r== 0.1**\n3 in table III\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.4**\nwhen a Bell-diagonal state goes through the channel n times.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nSet c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. Using Eq. (3), we obtain quantum battery\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\ncapacity for Bell-diagonal states under n times various Markovian noise channels, see Fig. 3. One sees that\n**BLOCK**fs== 10.0**p== 4.0**b== 0.0**t== 0.9**l== 0.1**r== 0.1**\nwhen p approaches to 1, the quantum battery capacity approaches to a constant for large n, that is, the\n**BLOCK**fs== 9.0**p== 5.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\nChannel\n**BLOCK**fs== 9.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nTABLE III: Correlation coeﬃcients for n times quantum channels: bit ﬂip channel (bf n), phase ﬂip channel (pf n),\nbit-phase ﬂip channel (bpf n), depolarizing channel (depn), and generalized amplitude damping channel(gadn). For\nthe gad, we have ﬁxed p = 1/2 and replaced γ by p.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nfrozen capacity appears, see Fig. 3 (a). When p increases, the quantum battery capacity under depolarizing\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nchannel decreases initially and then increases. It is worth mentioning that the capacity tends to 0 as p\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\napproaches to 1 for large n, see Fig. 3 (b). The quantum battery capacity under n times generalized\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\namplitude damping channel decreases as p increases. The curvatures of the cures gradually become large\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nfor large n, see Fig. 3 (c).\n**BLOCK**fs== 1.5**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 1.5**p== 5.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 1.5**p== 5.0**b== 0.4**t== 0.6**l== 0.7**r== 0.3**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nFIG. 3: Quantum battery capacity for Bell-diagonal state\n: (a)\nunder bit ﬂip channel n times, (b) under depolarizing channel n times, (c) under generalized amplitude damping\nchannel n times.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nc1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3\n}\n{\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nFurthermore, if the ﬁrst subsystem goes through the amplitude damping channel n times, the out-\n**BLOCK**fs== 7.0**p== 5.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nadc is ρ(n)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.2**t== 0.7**l== 0.3**r== 0.6**\nadc = E0 ⊗\nIρabE†\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nput state ρ(n)\nPi1,i2,··· ,in=0,1 Ei1i2···in ⊗\nE0 and E1 in the amplitude damping channel, E2\nto be ρ(n)\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nIρab(En\n**BLOCK**fs== 7.0**p== 5.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\nn−1\ni=0 E1En−i−1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.4**r== 0.4**\n1 ⊗\n0 ⊗\nI with Ei1i2···in = Ei1 Ei2 · · ·\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\n1 = 0, E0E1 = E1 and E1E0 = √1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\nadc is simpliﬁed\n**BLOCK**fs== 7.0**p== 5.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\nIρab(E1En−i−1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\n−\nI, namely,\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\nI, which can be rewritten as ρ(n)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\n−\nadc are u(n)\nc3(1\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nThe eigenvalues of ρ(n)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.4**r== 0.1**\np)n)2). Set c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.4**r== 0.1**\nfor n = 2, n = 3, n = 4, n = 10 and n = 100, see Fig. 4. (a)-(e).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nUsing Eq. (1) we have\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.8**\n123 (ρ(n)\nCadc\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nadc, HAB) =\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\np)n)2(ǫA + ǫB)\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nOne sees from Fig. 4. (f) that under amplitude damping channel n times the quantum battery capacity of\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nBell-diagonal states increases as p and n increases separately. It approaches to a constant for large n, that\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.7**\nis, the frozen capacity appears.\n**BLOCK**fs== 1.7**p== 6.0**b== 0.6**t== 0.4**l== 0.1**r== 0.8**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 1.7**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.8**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 2.4**p== 6.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nuHnL\nuHnL\nuHnL\nuHnL\n**BLOCK**fs== 2.4**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\nuHnL\nuHnL\nuHnL\nuHnL\n**BLOCK**fs== 1.7**p== 6.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 1.7**p== 6.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 2.4**p== 6.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nuHnL\nuHnL\nuHnL\nuHnL\n**BLOCK**fs== 2.4**p== 6.0**b== 0.5**t== 0.5**l== 0.6**r== 0.4**\nuHnL\nuHnL\nuHnL\nuHnL\n**BLOCK**fs== 1.7**p== 6.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\ns\ne\nu\nl\na\nv\nn\ne\ng\ni\nE\n**BLOCK**fs== 1.5**p== 6.0**b== 0.5**t== 0.5**l== 0.7**r== 0.3**\ny\nt\ni\nc\na\np\na\nC\n**BLOCK**fs== 2.4**p== 6.0**b== 0.6**t== 0.4**l== 0.8**r== 0.2**\nuHnL\nuHnL\nuHnL\nuHnL\n**BLOCK**fs== 9.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nFIG. 4: The eigenvalues of ρ(n)\nadc as a function of p for c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3 for (a) n = 2,\n(b) n = 3, (c) n = 4, (d) n = 10 and (e) n = 100. (f) Quantum battery capacity evolution for Bell-diagonal states\nc1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3\n}\n{\n**BLOCK**fs== 9.0**p== 6.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\nunder amplitude damping channel n times as a function of p.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nIII. QUANTUM BATTERY CAPACITY DYNAMICS OF BELL-DIAGONAL STATES UNDER\nBI-SIDE MARKOVIAN CHANNELS OF THE SAME TYPE\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nIn this section, we focus on the dynamics of quantum battery capacity of a two-qubit Bell-diagonal state\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nundergoing two independent local Markovian channels of the same type but with diﬀerent decoherence rates,\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nsee the Kraus operators in Table IV.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nAny Bell-diagonal state ρ given by Eq. (2) evolves to another Bell-diagonal state Eq. (5) under these\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nchannels. The corresponding coeﬃcients are listed in the Table V. As an example, let c1 = 0.5, c2 = 0.3,\nc3 = 0.1, ǫA = 0.6 and ǫB = 0.3. From Eq. (3) we have the dynamical behaviors of the quantum battery\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\ncapacity for Bell-diagonal state under the bi-side same type Markovian channel of bit ﬂip, see Fig. 5. When\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\np and q increase, the quantum battery capacity decreases and tends to constant. The quantum battery\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.2**\ncapacity for Bell-diagonal states under the bi-side channel of phase-ﬂip and bit-ﬂip is similar varied.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nMoreover, if both subsystems go through the same type channel n times, the Bell-diagonal state ρ given\n**BLOCK**fs== 10.0**p== 6.0**b== 0.0**t== 0.9**l== 0.1**r== 0.1**\nby (2) also evolves to another Bell-diagonal state (5). The corresponding coeﬃcients are listed in Table VI.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\nKraus operators\n**BLOCK**fs== 9.0**p== 7.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\npf-pf E(A)\n**BLOCK**fs== 9.0**p== 7.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\nbf-bf E(A)\n**BLOCK**fs== 9.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nbpf-bpf E(A)\n**BLOCK**fs== 9.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nTABLE IV: Kraus operators for two independent local Markovian channels: two independent local phase-ﬂip channels\n(pf-pf), two independent local bit-ﬂip channels(bf-bf), two independent local bit-phase-ﬂip channels (bpf-bpf), where\nγ′t), and γ and γ′ are the phase damping rates for the channels on the qubits A\np = 1\nexp(\nand B, respectively.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\nChannel\n**BLOCK**fs== 9.0**p== 7.0**b== 0.4**t== 0.5**l== 0.3**r== 0.7**\nbpf-bpf\n**BLOCK**fs== 9.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nTABLE V: Correlation coeﬃcients after the quantum channels: two independent local phase-ﬂip channels (pf-\npf), two independent local bit-ﬂip channels (bf-bf), two independent local bit-phase-ﬂip channels (bpf-bpf), where\np = 1\nare the phase damping rates for the channels on the qubits A\nexp(\nand B, respectively.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nt), and γ and γ\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nAs an example, let c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3. From Eq. (3) we obtain the quantum\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nbattery capacity for Bell-diagonal state under bi-side same type Markovian channel n times. In Fig. 6, we\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nsee that when n becomes larger, the quantum battery capacity for Bell-diagonal state under bi-side same\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\ntype Markovian channel decreases quickly as p and q increase. It also increases as n increases. The quantum\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nbattery capacity for Bell-diagonal states under the bi-side channel of phase-ﬂip and bit-ﬂip n times varies\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nsimilarly.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.2**t== 0.8**l== 0.4**r== 0.4**\nIV. SUMMARY\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nIn this work, we have investigated the quantum battery capacity under the channels of bit ﬂip, phase ﬂip,\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nbit-phase ﬂip, depolarizing, amplitude damping and generalized amplitude damping on the ﬁrst subsystem\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nfor Bell-diagonal states. In particular, we have shown that the quantum battery capacity of the Bell-diagonal\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nstates increases under amplitude damping channel. Moreover, the sudden death occurs under depolarizing\n**BLOCK**fs== 4.4**p== 8.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nCapacity\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nFIG. 5: Quantum battery capacity for Bell-diagonal state\nbi-side Markovian channels of the bit ﬂip channel.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nc1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3\n}\n{\n**BLOCK**fs== 9.0**p== 8.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nChannel\n**BLOCK**fs== 9.0**p== 8.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nTABLE VI: Correlation coeﬃcients for n times quantum operations: two independent local phase-ﬂip channels\nbf n), two independent local bit-phase-ﬂip channels\n(pf n\n(bpf n\nare the phase damping rates for the\nchannels on qubits A and B, respectively.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\npf n), two independent local bit-ﬂip channels (bf n\nbpf n), where p = 1\nγ\nexp(\n**BLOCK**fs== 9.0**p== 8.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\n−\nt), and γ and γ\n**BLOCK**fs== 4.2**p== 8.0**b== 0.3**t== 0.7**l== 0.4**r== 0.6**\nCapacity\n**BLOCK**fs== 9.0**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nFIG. 6: Quantum battery capacity for Bell-diagonal state\nunder\nbi-side Markovian channel of the bit ﬂip channel n times: n = 2 [orange surface], n = 10 [blue surface], n = 100\n[green surface].\n**BLOCK**fs== 9.0**p== 8.0**b== 0.2**t== 0.7**l== 0.5**r== 0.2**\nc1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3\n}\n{\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nchannel.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nWe have also studied the quantum battery capacity evolution under Markovian channels on the ﬁrst\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nsubsystem n times. It has been shown that the quantum battery capacity of the Bell-diagonal states tends\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nto a constant for large n under bit ﬂip channel and amplitude damping channel, namely, the frozen capacity\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nshows up. Furthermore, we have studied the dynamics of quantum battery capacity of the Bell-diagonal\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nstates under two independent same type local Markovian channels of bit-ﬂip, phase-ﬂip and bit-phase-ﬂip.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nOur results may highlight further investigations on the quantum battery capacity evolution under local\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nAcknowledgments This work was supported by the National Natural Science Foundation of China under\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\ngrant No. 12371135, 12065021, 12075159 and 12171044, and the speciﬁc research fund of the Innovation\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nPlatform for Academicians of Hainan Province.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[1] R. Alicki and M. Fannes, Entanglement boost for extractable work from ensembles of quantum batteries, Phys.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[2] M. Frey, K. Funo, and M. Hotta, Strong local passivity inﬁnite quantum systems, Phys. Rev. E 90, 012127\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n[3] M. Perarnau-Llobet, K. V. Hovhannisyan, M. Huber, P. Skrzypczyk, J. Tura, and A. Ac´ın, Most energetic\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\npassive states, Phys. Rev. E 92, 042147 (2015).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[4] E. G. Brown, N. Friis, and M. Huber, Passivity and practical work extraction using gaussian operations, New.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[5] G. Francica, J. Goold, F. Plastina, and M. Paternostro, Daemonic ergotropy: enhanced work extraction from\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nquantum correlations, njp Quant. Info. 3, 12 (2017).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[6] F. Campaioli, F. A. Pollock, F. C. Binder, L. C´eleri, J. Goold, S. Vinjanampathy, and K. Modi, Enhancing the\n**BLOCK**fs== 9.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\ncharging power of quantum batteries, Phys. Rev. Lett. 118, 150601 (2017).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n[7] C. Sparaciari, D. Jennings, and J. Oppenheim, Energetic instability of passive states in thermodynamics, Nature\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nCommunications 8, 1895 (2017).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[8] T. P. Le, J. Levinsen, K. Modi, M. M. Parish, and F. A. Pollock, Spin-chain model of a many-body quantum\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nbattery, Phys. Rev. A 97, 022106 (2018).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[9] D. Ferraro, M. Campisi, G. M. Andolina, V. Pellegrini, and M. Polini, High-Power collective charging of a\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nsolid-state quantum battery, Phys. Rev. Lett. 120, 117702 (2018).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[10] G. Manzano, F. Plastina, and R. Zambrini, Optimal work extraction and thermodynamics of quantum mea-\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nsurements and correlations, Phys. Rev. Lett. 121, 120602 (2018).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[11] G. M. Andolina, D. Farina, A. Mari, V. Pellegrini, V. Giovannetti, and M. Polini, Charger-mediated energy\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\ntransfer in exactly solvable models for quantum batteries, Phys. Rev. B 98, 205423 (2018).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[12] R. Alicki, A quantum open system model of molecular battery charged by excitons, Jour. of Chem. Phys. 150,\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[13] G. M. Andolina, M. Keck, A. Mari, V. Giovannetti, and M. Polini, Quantum versus classical many-body\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nbatteries, Phys. Rev. B 99, 205437 (2019).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[14] D. Rossini, G. M. Andolina, and M. Polini, Many-body localized quantum batteries, Phys. Rev. B 100, 115142\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n[15] ´A. M. Alhambra, G. Styliaris, N. A. R. Briones, J. Sikora, and E. M. Martnez, Fundamental limitations to local\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nenergy extraction in quantum systems, Phys. Rev. Lett. 123, 190601 (2019).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[16] D. Rossini, G. M. Andolina, D. Rosa, M. Carrega, and M. Polini, Quantum advantage in the charging process\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.4**\nof Sachdev-Ye-Kitaev batteries, Phys. Rev. Lett. 125, 236402 (2020).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[17] S. Gherardini, F. Campaioli, F. Caruso, and F. C. Binder, Stabilizing open quantum batteries by sequential\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nmeasurements, Phys. Rev. Res. 2, 013095 (2020).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[18] S. Ghosh, T. Chanda, and A. Sen(De), Enhancement in the performance of a quantum battery by ordered and\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\ndisordered interactions, Phys. Rev. A 101, 032115 (2020).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[19] A. Crescente, M. Carrega, M. Sassetti, and D. Ferraro, Ultrafast charging in a two-photon Dicke quantum\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nbattery, Phys. Rev. B 102, 245407 (2020).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[20] K. Xu, H. J. Zhu, G. F. Zhang, and W. M. Liu, Enhancing the performance of an open quantum battery via\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nenvironment engineering, Phys. Rev. E 104, 064143 (2021).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[21] S. Zakavati, F. T. Tabesh, and S. Salimi, Bounds on charging power of open quantum batteries, Phys. Rev. E\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[22] Y. Yao and X. Q. Shao, Stable charging of a Rydberg quantum battery in an open system, Phys. Rev. E 104,\n**BLOCK**fs== 9.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[23] S. Tirone, R. Salvia, and V. Giovannetti, Quantum energy lines and the optimal output ergotropy problem,\n**BLOCK**fs== 9.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\nPhys. Rev. Lett. 127, 210601 (2021).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[24] K. Sen and U. Sen, Local passivity and entanglement in shared quantum batteries, Phys. Rev. A 104, L030402\n**BLOCK**fs== 9.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[25] F. Zhao, F. Q. Dou, and Q. Zhao, Quantum battery of interacting spins with environmental noise, Phys. Rev.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[26] S. Ghosh, T. Chanda, S. Mal, and A. Sen(De), Fast charging of a quantum battery assisted by noise, Phys. Rev.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n[27] M. T. Mitchison, J. Goold, and J. Prior, Charging a quantum battery with linear feedback control, Quantum\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[28] F. Q. Dou, Y. J. Wang, J. A. Sun, Highly eﬃcient charging and discharging of three-level quantum batteries\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.4**\nthrough shortcuts to adiabaticity, Front. Phys. 17(3), 31503 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[29] F. Q. Dou, Y. Q. Lu, Y. J. Wang, and J. A. Sun, Extended Dicke quantum battery with interatomic interactions\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nand driving ﬁeld, Phys. Rev. B 105, 115405 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[30] H. L. Shi, S. Ding, Q. K. Wan, X. H. Wang, and W. L. Yang, Entanglement, coherence, and extractable work\n**BLOCK**fs== 9.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nin quantum batteries, Phys. Rev. Lett. 129, 130602 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n[31] T. K. Konar, L. G. C. Lakkaraju, S. Ghosh, and A. Sen(De), Quantum battery with ultracold atoms: Bosons\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nversus fermions, Phys. Rev. A 106, 022618 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[32] K. Xu, H. G. Li, Z. G. Li, H. J. Zhu, G. F. Zhang, and W. M. Liu, Charging performance of quantum batteries\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nin a double-layer environment, Phys. Rev. A 106, 012425 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[33] R. R. Rodriguez, B. Ahmadi, G. Suarez, P. Mazurek, S. Barzanjeh, and P. Horodecki, Optimal quantum control\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nof charging quantum batteries, arXiv:2207.00094 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[34] F. Q. Dou, H. Zhou, and J. A. Sun, Cavity heisenbergspin-chain quantum battery, Phys. Rev. A 106, 032212\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n[35] S. Tirone, R. Salvia, S. Chessa, and V. Giovannetti, Quantum work capacitances: ultimate limits for energy\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\nextraction on noisy quantum batteries, arXiv:2211.02685 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[36] J. Carrasco, R. Maze, Jeronimo, C. Hermann-Avigliano, and F. Barra, Collective enhancement in dissipative\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nquantum batteries, Phys. Rev. E 105, 064119 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[37] F. Mayo and A. J. Roncaglia, Collective eﬀects and quantum coherence in dissipative charging of quantum\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nbatteries, Phys. Rev. A 105, 062203 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[38] S. Ghosh and A. Sen(De), Dimensional enhancements in a quantum battery with imperfections, Phys. Rev. A\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n[39] R. Salvia, G. De Palma, and V. Giovannetti, Optimal local work extraction from bipartite quantum systems in\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nthe presence of Hamiltonian couplings, Phys. Rev. A 107, 012405 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[40] K. Xu, H. J. Zhu, H. Zhu, G.F. Zhang and W.M. Liu, Charging and self-discharging process of a quantum\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nbattery in composite environments. Front. Phys. 18(3), 31301 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[41] J. S. Yan and J. Jing, Charging by quantum measurement, Phys. Rev. Appl. 19, 064069 (2023).\n[42] X. Yang, Y. H. Yang, M. Alimuddin, R. Salvia, S. M. Fei, L. M. Zhao, S. Nimmrichter, and M. X. Luo, The\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nbattery capacity of energy-storing quantum systems, Phys. Rev. Lett. 131, 030402 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[43] S. Tirone, R. Salvia, S. Chessa, and V. Giovannetti, Work extraction processes from noisy quantum batteries:\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.4**\nthe role of non local resources, Phys. Rev. Lett. 131, 060402 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[44] F. Q. Dou and F. M. Yang, Superconducting transmon qubit-resonator quantum battery, Phys. Rev. A 107,\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[45] K. Sen, U. Sen, Noisy quantum batteries, arXiv:2302.07166v1 (2023).\n[46] S. Tirone, R. Salvia, S. Chessa, and V. Giovannetti, Quantum work extraction eﬃciency for noisy quantum\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nbatteries: the role of coherence, arXiv:2305.16803 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[47] B. A. Mohammad, H. Mohammad, A. Saguia, M. S. Sarandy, and A. C. Santos, Localization eﬀects in disordered\n**BLOCK**fs== 9.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nquantum batteries, arXiv:2306.13164 (2023)\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\n[48] A. G. Catalano, S. M. Giampaolo, O. Morsch, V. Giovannetti, and F. Franchini, Frustrating quantum batteries,\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[49] P. Chaki, A. Bhattacharyya, K. Sen, U.Sen, Auxiliary-assisted stochastic energy extraction from quantum\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nbatteries, arXiv:2307.16856v1(2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[50] F. Campaioli, S. Gherardini, J. Q. Quach, M. Polini, G. M. Andolina, Colloquium: Quantum batteries,\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[51] D. Morrone, M. A. C. Rossi, A. Smirne, and M. G. Genoni, Charging a quantum battery in a nonmarkovian\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nenvironment: a collisional model approach, Quant. Science and Tech. 8, 035007 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n[52] P. Bakhshinezhad, B. R. Jablonski, F. C. Binder, and N. Friis, Trade-oﬀs between precision and ﬂuctuations in\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\ncharging ﬁnite-dimensional quantum batteries, Phys. Rev. E 109, 014131(2024).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[53] H. Y. Yang, H. L. Shi, Q. K. Wan, K. Zhang, X. H. Wang, and W. L.Yang, Optimal energy storage in the\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nTavis-Cummings quantum battery, Phys. Rev. A 109, 012204 (2024).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[54] J. Joshi and T. S. Mahesh, Experimental investigation of a quantum battery using star-topology nmr spin\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nsystems, Phys. Rev. A 106, 042601 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n[55] A. Delgado, P. A. M. Casares, R. dos Reis, M. S. Zini, R. Campos, N. Cruz-Hernandez, A. C. Voigt, A. Lowe,\nS. Jahangiri, M. A. Martin-Delgado, J. E. Mueller, and J. M. Arrazola, Simulating key properties of lithiumion\nbatteries with a fault-tolerant quantum computer, Phys. Rev. A 106, 032428 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[56] J. Q. Quach, K. E. McGhee, L. Ganzer, D. M. Rouse, B. W. Lovett, E. M. Gauger, J. Keeling, G. Cerullo,\nD. G. Lidzey, and T. Virgili, Superabsorption in an organic microcavity: Toward a quantum battery, Science\nAdvances 8, 3160 (2022).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n[57] J. Franklin, J. Bedard, and I. Sochnikov, Versatile millikelvin hybrid cooling platform for superconductivity\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.3**\nresearch, IEEE Transactions on Applied Superconductivity 33, 1600303 (2023).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.0**t== 0.9**l== 0.1**r== 0.1**\n[58] N. C. Rubin, D. W. Berry, F. D. Malone, A. F. White, T Khattar, A. E. De Prince III au2, S. Sicolo, M. K¨uhn,\nM. Kaicher, J. Lee, and R. Babbush, Fault-tolerant quantum simulation of materials using bloch orbitals,\narXiv:2302.05531 (2023).\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n[59] M. A. Nielsen, and I. L. Chuang, Quantum Computation and Quantum Information (Cambridge University\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nPress, Cambridge, UK, 2000).3, 12 (2017).\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[60] Y. K. Wang, S. M. Fei, Z. X. wang, J. P. Cao, H. Fan, Maximal Holevo quantity based on weak measurements,\n**BLOCK**fs== 9.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nSci. Rep. 10, 10727 (2015).",
         "With the rapid development of quantum information and quantum thermodynamics, some novel quantum devices have been introduced recently. The quantum battery presented by R. Alicki and M. Fannes shows the maximum amount of energy that can be extracted from a quantum system in an informational theoretic view[1]. Since then many interesting results have been obtained [2–53], including the construction of charging models [5, 6, 9, 10, 13, 30, 36, 37] and many-body quantum batteries[8, 14, 20–22, 28, 29, 48]. Among them, Ferraro et al. proved that the quantum battery charges faster than the ordinary batteries in collective charging mode[9]. A series of other quantum battery models have been also brought up[8, 16, 53], together with some experimental studies[54–58], see [50] for a review of quantum batteries. An important indicator of quantum batteries is the battery capacity[35, 42]. Recently, the authors in Ref. [42] provided a new deﬁnition of quantum battery capacity, λ1 ≤ · · · ≤ where λ0 ≤ eigenenergies of the Hamiltonian H = λd−1 represent the eigenvalues of the quantum state ρ and ǫ0 ≤ . C(ρ, H) is a Schur-convex functional of the quantum state and does not alter whenever the battery is unitarily charged. In this article, we investigate the evolution of quantum battery capacity in Bell-diagonal states, when the ﬁrst subsystem undergoes Markovian channels. We show that the quantum battery capacity of the Bell- diagonal states increases under amplitude damping channel. In particular, we ﬁnd that the phenomenon of sudden death of the quantum battery capacity occurs for special Bell-diagonal states under depolarizing channel. We also study the capacity evolution of Bell-diagonal states when the ﬁrst subsystem undergoes n times Markovian channels. It is shown that the capacity under depolarizing channel decreases initially, and then increases for small n and tends to 0 for large n. We also ﬁnd that phenomenon of frozen of capacity occurs for special Bell-diagonal states under bit ﬂip channel and amplitude damping channel for large n. In addition, we investigate the dynamics of capacity of the Bell-diagonal states under two independent local Markovian channels of the same type. We consider the initial states to be the two-qubit Bell-diagonal ones, where σ1, σ2, σ3 are the standard Pauli matrices, ci, i = 1, 2, 3, are real constants such that ρAB is a well deﬁned density matrix. ρAB has eigenvalues λ0 = (1 λ2 = (1 + c1 − for j = 0, 1, 2, 3. c2 + c3)/4 and λ3 = (1 + c1 + c2 − c3)/4. The coeﬃcients ci are chosen such that λj Let us consider the following Hamiltonian for the two-qubit system, HAB = ǫAσ3 ⊗ − ≥ 0. The eigenvalues of HAB are σ3, where ǫB and ǫA + ǫB in ascending order. ǫA + ǫB, ǫA Therefore, if c1 > c2 > c3 > 0, then λ0 < λ1 < λ2 < λ3. From (1) we have C123(ρAB, HAB) = (c1 + c2)(ǫA + ǫB) + (c1 − For c1 > c3 > c2 > 0, we have λ0 < λ1 < λ3 < λ2 and C132(ρAB, HAB) = (c1 + c3)(ǫA + ǫB) + (c1 − For c2 > c1 > c3 > 0, we have λ0 < λ2 < λ1 < λ3 and C213(ρAB, HAB) = (c2 + c1)(ǫA + ǫB) + (c2 − For c2 > c3 > c1 > 0, we have λ0 < λ2 < λ3 < λ1 and C231(ρAB, HAB) = (c2 + c3)(ǫA + ǫB) + (c2 − For c3 > c1 > c2 > 0, we have λ0 < λ3 < λ1 < λ2 and C312(ρAB, HAB) = (c3 + c1)(ǫA + ǫB) + (c3 − For c3 > c2 > c1 > 0, we have λ0 < λ3 < λ2 < λ1 and C321(ρAB, HAB) = (c3 + c2)(ǫA + ǫB) + (c3 − The reduced states of ρAB are ρA = I2/2 and ρB = I2/2, respectively. Consequently, we have C(ρA, HA) = 0. (1) Quantum battery capacity evolution of Bell-diagonal states under Markovian channels on the ﬁrst We will focus on the evolution of a quantum state ρ under a trace-preserving quantum operation ε(ρ)[59], Kraus operators of some typical channels are listed by in Table I [60], where the decoherence processes bit ﬂip channel (bf), phase ﬂip channel (pf), bit-phase ﬂip channel(bpf) and depolarizing channel (dep) preserve the Bell-diagonal form of the density operator ρ. For the case of generalized amplitude damping channel (gad), the Bell-diagonal form is kept for arbitrary γ and p = 1/2. In this situation, one has where c′ When c1 > c2 > c3 > 0, from Table II, c′ 1, 1] are given in Table II [60]. 2, c′ (dep), and generalized amplitude damping channel (gad) satisfy the condition for Eq. (3), i.e., c′ Let Cbf 3 of ρ′ under bit ﬂip channel (bf), depolarizing channel 2 > c′ 3. 123 (ρ′, HAB) be quantum battery capacity of ρ′ under bit ﬂip channel, depolarizing channel and generalized amplitude damping channel, respectively. By Eq. (5) and (3), we have Cbf 123(ρ′, HAB) = (c1 + c2(1 − Cdep 123 (ρ′, HAB) = (c1 + c2)(1 Cgad 123 (ρ′, HAB) = (c1 + c2)(1 p)2)(ǫA + ǫB) + (c1 − 4p/3)(ǫA + ǫB) + (c1 − − p)(ǫA + ǫB) + (c1 − c2)(1 Under the amplitude damping channel, the Bell-diagonal states are transformed into the output state, (c1 − − adc are u0 = 1/4(1 p) + p2), u2 = 1/4(1 + c3(1 The eigenvalues of ρ′ p) + p2). Set c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. We have u0 < u2 < u3 < p u1, see Fig. 1 (a). Using Eq. (1) we obtain p) + p2(ǫA + ǫB) + From Fig. 1 (b), we see that for the initial Bell-diagonal states the quantum battery capacity decreases as p increases under bit ﬂip channel, depolarizing channel and generalized amplitude damping channel. Under generalized amplitude damping channel the quantum battery capacity approaches to zero as p increases to 1. Under depolarizing channel the quantum battery capacity becomes zero as p 0.75, a phenomenon of sudden death of quantum battery capacity. On the other hand, the quantum battery capacity increases as p increases under amplitude damping channel. When c2 > c3 > c1 > 0, we have c′ 231 (ρ′, HAB) and Cdep 1 under bit-phase ﬂip (bpf), depolarizing channel (dep), see 231 (ρ′, HAB) denote the quantum battery capacity of ρ under bit-phase ﬂip and depolarizing channel, respectively. By Eq. (5) and (4) we have 231 (ρ′, HAB) = (c2 + c3(1 − Cdep 231 (ρ′, HAB) = (c2 + c3)(1 p)2)(ǫA + ǫB) + (c2 − c3(1 4p/3)(ǫA + ǫB) + (c2 − Set c1 = 0.1, c2 = 0.5, c3 = 0.3, ǫA = 0.6 and ǫB = 0.3. We have u0 < u2 < u1 < u3, see Fig. 2. (a). Using Eq. (1) we have adc, HAB) = 1/2(2c3 + p) + p2)(ǫA + ǫB) The quantum battery capacity evolutions under bit-phase ﬂip channel, depolarizing channel, generalized amplitude damping channel and amplitude damping channel are similar with the situation of c1 > c2 > c3 > 0, see Fig. 2 (b). When c3 > c2 > c1 > 0, the quantum battery capacity for the same Bell-diagonal state under phase ﬂip channel is similar with the situations of bit ﬂip channel c1 > c2 > c3 > 0 and bit-phase ﬂip channel (2) Quantum battery capacity evolution under n times Markovian channels on the ﬁrst subsystem Next, we consider the quantum battery capacity dynamics of Bell-diagonal states under n times Markovian channels on the ﬁrst subsystem. As the decoherence processes bf, pf, bpf, dep and gad preserve the Bell- diagonal form of the density operator, the parameters of the output state are given by c′ 3 in table III when a Bell-diagonal state goes through the channel n times. Set c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. Using Eq. (3), we obtain quantum battery capacity for Bell-diagonal states under n times various Markovian noise channels, see Fig. 3. One sees that when p approaches to 1, the quantum battery capacity approaches to a constant for large n, that is, the frozen capacity appears, see Fig. 3 (a). When p increases, the quantum battery capacity under depolarizing channel decreases initially and then increases. It is worth mentioning that the capacity tends to 0 as p approaches to 1 for large n, see Fig. 3 (b). The quantum battery capacity under n times generalized amplitude damping channel decreases as p increases. The curvatures of the cures gradually become large for large n, see Fig. 3 (c). Furthermore, if the ﬁrst subsystem goes through the amplitude damping channel n times, the out- put state ρ(n) Pi1,i2,··· ,in=0,1 Ei1i2···in ⊗ E0 and E1 in the amplitude damping channel, E2 to be ρ(n) 1 ⊗ 0 ⊗ I with Ei1i2···in = Ei1 Ei2 · · · 1 = 0, E0E1 = E1 and E1E0 = √1 adc is simpliﬁed − I, namely, I, which can be rewritten as ρ(n) The eigenvalues of ρ(n) p)n)2). Set c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. for n = 2, n = 3, n = 4, n = 10 and n = 100, see Fig. 4. (a)-(e). Using Eq. (1) we have p)n)2(ǫA + ǫB) One sees from Fig. 4. (f) that under amplitude damping channel n times the quantum battery capacity of Bell-diagonal states increases as p and n increases separately. It approaches to a constant for large n, that is, the frozen capacity appears. In this section, we focus on the dynamics of quantum battery capacity of a two-qubit Bell-diagonal state undergoing two independent local Markovian channels of the same type but with diﬀerent decoherence rates, see the Kraus operators in Table IV. Any Bell-diagonal state ρ given by Eq. (2) evolves to another Bell-diagonal state Eq. (5) under these channels. The corresponding coeﬃcients are listed in the Table V. As an example, let c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6 and ǫB = 0.3. From Eq. (3) we have the dynamical behaviors of the quantum battery capacity for Bell-diagonal state under the bi-side same type Markovian channel of bit ﬂip, see Fig. 5. When p and q increase, the quantum battery capacity decreases and tends to constant. The quantum battery capacity for Bell-diagonal states under the bi-side channel of phase-ﬂip and bit-ﬂip is similar varied. Moreover, if both subsystems go through the same type channel n times, the Bell-diagonal state ρ given by (2) also evolves to another Bell-diagonal state (5). The corresponding coeﬃcients are listed in Table VI. As an example, let c1 = 0.5, c2 = 0.3, c3 = 0.1, ǫA = 0.6, ǫB = 0.3. From Eq. (3) we obtain the quantum battery capacity for Bell-diagonal state under bi-side same type Markovian channel n times. In Fig. 6, we see that when n becomes larger, the quantum battery capacity for Bell-diagonal state under bi-side same type Markovian channel decreases quickly as p and q increase. It also increases as n increases. The quantum battery capacity for Bell-diagonal states under the bi-side channel of phase-ﬂip and bit-ﬂip n times varies similarly. In this work, we have investigated the quantum battery capacity under the channels of bit ﬂip, phase ﬂip, bit-phase ﬂip, depolarizing, amplitude damping and generalized amplitude damping on the ﬁrst subsystem for Bell-diagonal states. In particular, we have shown that the quantum battery capacity of the Bell-diagonal states increases under amplitude damping channel. Moreover, the sudden death occurs under depolarizing channel. We have also studied the quantum battery capacity evolution under Markovian channels on the ﬁrst subsystem n times. It has been shown that the quantum battery capacity of the Bell-diagonal states tends to a constant for large n under bit ﬂip channel and amplitude damping channel, namely, the frozen capacity shows up. Furthermore, we have studied the dynamics of quantum battery capacity of the Bell-diagonal states under two independent same type local Markovian channels of bit-ﬂip, phase-ﬂip and bit-phase-ﬂip. Our results may highlight further investigations on the quantum battery capacity evolution under local Acknowledgments This work was supported by the National Natural Science Foundation of China under grant No. 12371135, 12065021, 12075159 and 12171044, and the speciﬁc research fund of the Innovation Platform for Academicians of Hainan Province.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2408/2408.03797v1.pdf",
         "extracted",
         "None",
         "",
         "Dynamics of quantum battery capacity under Markovian channels"
        ],
        [
         "32",
         "016c339d6bd3cbd60275c86ff645ffc29b6ea8e7",
         "None",
         "Chunkai Li,Yu Pan,Yu Shi,Wenkai Wang",
         "\n**BLOCK**fs== 24.0**p== 0.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nOptimization of Process Prediction Models for Hot-\nWire Laser Metal Deposition Using Transfer\nLearning Strategies Based on Simulation Datasets\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\nLanzhou University of Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nLanzhou University of Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.4**l== 0.1**r== 0.6**\nLanzhou University of Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nLanzhou University of Technology\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nKeywords: Laser deposition, mechanistic model, melt pool information, deep learning, transfer learning\n**BLOCK**fs== 12.0**p== 0.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.\nRead Full License\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.1**l== 0.0**r== 0.1**\nThis study addresses the challenge of predicting and controlling melt pool behavior in Hot-Wire Laser\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nMetal Deposition (HW-LMD) technology by proposing a transfer learning strategy based on simulation\ndatasets to optimize process parameter prediction. First, a large amount of simulated data was\ngenerated using a mechanistic model to pre-train a deep neural network (DNN). Then, transfer learning\nwas applied by incorporating actual experimental data to enhance the model's accuracy in predicting\n**BLOCK**fs== 12.0**p== 1.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nprocess parameters related to melt pool dimensions. The experimental results demonstrate that this\nmethod signi\u0000cantly reduces the demand for experimental data and lowers prediction errors. The model\ntrained with traditional methods exhibited an error rate of 21.16%, whereas the error was signi\u0000cantly\nreduced to 2.03% after optimization using the transfer learning strategy based on the simulation dataset.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.3**l== 0.0**r== 0.1**\nThe \u0000ndings offer a novel approach to process optimization and quality control in the \u0000eld of additive\nmanufacturing.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nHot-Wire Laser Metal Deposition (HW-LMD) technology, as a key technique in the \u0000eld of Additive\nManufacturing (AM), has garnered signi\u0000cant attention in recent years [1, 2]. By combining laser energy\nwith resistive heating, HW-LMD enables e\u0000cient metal deposition and is widely applied in high-end\nmanufacturing industries such as aerospace, biomedical, and energy sectors [3, 4]. During this process,\nthe formation, evolution, and \u0000nal solidi\u0000cation state of the melt pool play a decisive role in the\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nmicrostructure, mechanical properties, and surface quality of the deposited part. Therefore, accurately\npredicting and controlling melt pool behavior is crucial for optimizing the HW-LMD process.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nIn recent years, Machine Learning (ML) has been applied to solve the challenges of predicting melt pool\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.6**l== 0.0**r== 0.0**\ncharacteristics and process parameters due to its exceptional data analysis and mining capabilities.\nCaiazzo et al. [5] developed a unidirectional predictive model from melt pool geometric parameters to\nprocess parameters using a machine learning approach based on Arti\u0000cial Neural Networks (ANN). Cai\net al. [6] established a system combining a Support Vector Regression (SVR) model with the NSGA-II\nalgorithm to predict the optimal process parameters for desired deposition layer geometry. Deep\nLearning (DL), a sub\u0000eld of machine learning, also employs data-driven approaches that can be used for\nprocess parameter prediction. Petrik et al. [7] developed a MeltPoolGAN network based on Generative\nAdversarial Networks (GANs) to adjust process parameters using image classi\u0000cation results, while also\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\ngenerating credible melt pool images. However, machine learning typically requires large datasets for\ntraining [8], and insu\u0000cient data often leads to under\u0000tting, resulting in inaccurate predictions and low\nprediction accuracy.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nIn studies addressing welding issues through machine vision, researchers often employ transfer learning\ntechniques to mitigate the under\u0000tting problem caused by insu\u0000cient datasets [9, 10]. However, the pre-\ntrained datasets used for transfer learning in these studies are often large image datasets like ImageNet,\nwhich are not readily applicable to the \u0000eld of additive manufacturing. In this domain, publicly available\n**BLOCK**fs== 12.0**p== 2.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\ndatasets are scarce, and researchers typically need to create their own datasets. However, creating pre-\ntraining datasets based on actual experiments is often time-consuming and costly, making it impractical\nfor large-scale studies. Zhao et al. [11] trained a Multilayer Perceptron (MLP) using a combination of\nhigh-\u0000delity simulation datasets and experimental datasets, achieving signi\u0000cantly better predictive\nperformance than models trained solely on experimental data. Menon et al. [12] developed a multi-\n\u0000delity Gaussian Process (MFGP) framework to integrate experimental and simulation data, signi\u0000cantly\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nreducing the amount of experimental data needed without compromising accuracy. These studies\nindicate that simulation datasets can reduce the amount of data required for machine learning training\nto a certain extent.\n**BLOCK**fs== 12.0**p== 2.0**b== 0.5**t== 0.3**l== 0.0**r== 0.0**\nBased on the aforementioned issues, this study innovatively proposes a transfer learning strategy based\non simulation datasets to optimize process parameter prediction for Hot-Wire Laser Metal Deposition.\nFirst, a large amount of simulated data generated by a mechanistic model is used to pre-train a Deep\nNeural Network (DNN). Then, transfer learning is applied using experimental data. This approach\nsigni\u0000cantly improves the accuracy of the DNN model in predicting the process parameters required for\nthe desired melt pool dimensions. The experimental results show that, compared with models trained\nsolely on experimental datasets, the proposed method signi\u0000cantly reduces the amount of experimental\ndata required while also markedly lowering prediction errors. This is of great importance for accurately\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nThe diagram in Fig. 1(a) elucidates the operational concepts behind the HW-LMD technique. This method\ninvolves the application of a preheating power source between the wire feeding apparatus and the base\nmaterial. The current from the preheating stage produces substantial thermal energy within the \u0000ller\nwire, and when combined with laser power, it aids in the e\u0000cient melting of the wire. The experimental\n**BLOCK**fs== 12.0**p== 2.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nsetup, depicted in Fig. 1(b), encompasses several components: a laser cladding head, a wire preheating\npower supply, a wire feeding mechanism, a shielding gas delivery system, and a motion control system.\nThe laser apparatus employed here is the YLS-4000 IPG laser, which is \u0000tted with a 600 µm diameter\n\u0000ber and operates at a wavelength of 1.07 µm. This laser is capable of providing a peak power output of\n4000 W. By utilizing a 150 mm collimating lens combined with a 250 mm focal length lens, a focused\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.8**l== 0.0**r== 0.1**\nspot size of 3.0 mm is achieved. The JRS-400 wire feeder is tasked with guiding the \u0000ller wire into the\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nmolten pool, and the Panasonic YC-400TX4 digital power supply is responsible for heating the wire. This\npower supply operates in a constant voltage con\u0000guration, ensuring a stable voltage of 5 V with the\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\ncapacity to deliver up to 300 A of current. To shield against oxidation of both the melt pool and the \u0000ller\nwire, a \u0000ow of high-purity argon gas (99.999%) is employed. Furthermore, a four-axis motion system has\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.0**r== 0.1**\nbeen engineered and integrated to enable precise manipulation of the laser head along the x, y, and z\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nIn the research, a nickel-based alloy known as Inconel 718, with dimensions of 100 mm in length, 100\nmm in width, and 6 mm in thickness, was chosen for the substrate. The metal deposition material was\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nan Inconel 625 wire with a diameter of 1.2 mm, supplied by SMC. Throughout the experiments, the wire\nfeed rate and preheating current were maintained at a constant level to ensure a consistent deposition\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nrate and preheating temperature. The laser power and the welding speed were \u0000ne-tuned for single-layer\ndeposition on the substrate, with detailed parameters provided in Table 1. As depicted in Fig. 1(a), a\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\ntrailing wire feeding technique was implemented, positioning the \u0000ller wire at a 0 mm distance from the\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nlaser spot to guarantee thorough melting and a stable liquid bridge transition, which implies that the wire\nwas in continuous contact with the melt pool throughout the deposition [13]. The length of each\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\ndeposition layer was standardized to 70 mm. Further process parameters are outlined in Table 2.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.4**l== 0.0**r== 0.1**\nTo maintain precision in dimensions, the melt pool's height and width were measured at every 6 mm\ninterval, as indicated in Fig. 2(a), and the mean values were recorded. Cross-sectional samples were\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nextracted along the longitudinal axis at the locations marked by the dashed red lines in Fig. 2(a). These\nsamples underwent grinding, polishing, and etching with Aqua regia for 30 seconds to expose the cross-\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nsectional structure of the melt pool and to measure its depth, as shown in Fig. 2(b). The mean\ndimensions of the melt pool were then used to compile the experimental data set for the purpose of\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.7**\nGroups Welding speed\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.4**r== 0.5**\nLaser power\nP(W)\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nWire feed speed\nv(mm/s)\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.8**r== 0.1**\nPreheating current\nI(A)\n**BLOCK**fs== 12.0**p== 4.0**b== 0.9**t== 0.1**l== 0.4**r== 0.4**\nTable 1\nWelding parameters\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nTo balance computational accuracy and e\u0000ciency, the following assumptions were made for the Hot-\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\n(1) The \u0000uid \u0000ow within the melt pool is laminar [13], incompressible, and behaves as a Newtonian \u0000uid;\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.0**r== 0.2**\n(2) The in\u0000uence of shielding gas pressure on the melt pool surface contour is neglected;\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.0**r== 0.4**\n(3) The effect of the \u0000ller wire on melt pool \u0000uid \u0000ow is neglected;\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nConsidering factors such as free surface tracking, laser-material interaction, melting and solidi\u0000cation\nprocesses, convective driving forces, mass addition effects from the \u0000ller wire, and the preheating\n**BLOCK**fs== 12.0**p== 4.0**b== 0.0**t== 0.9**l== 0.0**r== 0.1**\nprocess, a three-dimensional transient multiphase \u0000ow and heat transfer model was constructed.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nIn the Eq. (1), ρ represents the material density, t is time, u, v and w are the velocity components of the\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.3**r== 0.0**\nin the x, y and z directions, respectively, and Smass is the mass source term.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nSince the model assumes that the melt pool \u0000uid is a Newtonian \u0000uid and the \u0000ow is laminar, its\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nthe surface of the element due to molecular viscosity, Smom is the momentum source term,\nare the gravitational force and external force, respectively.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.4**l== 0.5**r== 0.0**\nis the stress tensor representing the viscous stress on\n→\nF\n**BLOCK**fs== 14.3**p== 5.0**b== 0.4**t== 0.5**l== 0.4**r== 0.2**\n→\nv H) = ∇ ∙ (k∇ t) + Senergy (3)\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nIn Eq. (3), H represents enthalpy, k is the thermal conductivity, and Senergy is the energy source term.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nThe enthalpy-porosity technique [16] is used to simulate the melting and solidi\u0000cation processes of the\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nmaterial. In this model, the liquid volume fraction f is used to represent the fraction of the liquid cell\nvolume, with values ranging between 0 and 1. The formula for calculating the material's enthalpy is as\nfollows:\n**BLOCK**fs== 14.3**p== 5.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\nH = href + ∫ T\n**BLOCK**fs== 14.3**p== 5.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\nCpdT + fL (4)\n**BLOCK**fs== 12.0**p== 5.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nIn Eq. (4), href is the reference enthalpy, Tref is the reference temperature, Cp is the speci\u0000c heat capacity\nat constant pressure, and L is the latent heat of the material. The liquid volume fraction f can be\ncalculated using the following equation:\n**BLOCK**fs== 7.1**p== 5.0**b== 0.1**t== 0.8**l== 0.4**r== 0.5**\nT −Tsolid\nTliquid−Tsolid\n**BLOCK**fs== 14.3**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.4**\nif T ≤ Tsolid\n**BLOCK**fs== 10.1**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.3**\nif Tsolid < T < Tliquid\n**BLOCK**fs== 10.1**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.4**\nif T ≥ Tliquid\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.0**r== 0.1**\nIn Eq. (5), Tsolid and Tliquid represent the solid phase temperature and liquid phase temperature of the\nmaterial, respectively.\n2.2.2 Boundary conditions\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nIn this study, the critical importance of free surface tracking between the gas and substrate materials for\nthe accuracy of the entire simulation was considered. To this end, a computational domain was\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nconstructed as shown in Fig. 3. The model de\u0000nes two distinct phases and distinguishes between\nexternal and internal boundary conditions. While the internal boundary conditions relate to melt pool's\nfree surface, the external boundary conditions relate to the computational domain's outer limits.The\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nperipheral and basal surfaces of the substrate are treated as walls to delineate the outer limits of the\ncomputational domain. Heat transfer conditions involving conduction, convection, and radiation are\nimposed on these boundaries. For dealing with internal interfaces, a Volume of Fluid (VOF) model [17] is\nutilized to depict the boundary between the gaseous and metallic phases with precision. This method\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nallows for an effective simulation of the \u0000uid dynamics within the melt pool and its interaction with the\nbase material.\n2.2.3 Source term calculation equation\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nIn the laser hot-wire deposition process, the \u0000ller wire \u0000ows steadily into the melt pool, achieving a\nmaterial utilization rate of 100%. The addition of mass can be considered uniformly distributed, thus the\nmass source term can be expressed as [18]:\n**BLOCK**fs== 7.1**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.4**\nρ wire∗π r2\n**BLOCK**fs== 7.1**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.4**\nwire∗fwire\n**BLOCK**fs== 7.1**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nn∗Vcell\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nIn Eq. (6), ρwire is the density of the \u0000ller wire, rwire is the radius of the \u0000ller wire, and fwire is the feeding\nspeed. In this study, rwire is taken as 0.6 mm, fwire14 mm/s, n is 14 mm/s, and n is 3.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nIn the process of laser hot-wire metal deposition, there are two primary heat sources: (1) the laser beam\nheat source Qlaser, and (2) the \u0000ller wire preheating source Qmass. Taking into account the energy losses\nattributed to convection and thermal radiation, the term representing the external energy source can be\n**BLOCK**fs== 14.3**p== 6.0**b== 0.2**t== 0.8**l== 0.2**r== 0.4**\nSenergy = [Qlaser − Ah (T − T0) − σ ϵ (T 4 − T0\n**BLOCK**fs== 14.3**p== 6.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\n4)] ∙ δ (ϕ ) + Qmass (7)\n**BLOCK**fs== 12.0**p== 6.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\nThus, the laser beam heat source Qlaser and the \u0000ller wire preheating source Qmass are given by the\nfollowing equations:\n**BLOCK**fs== 10.1**p== 6.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\nQlaser =\n**BLOCK**fs== 10.1**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\nω P α\nπ R2\nb\n**BLOCK**fs== 10.1**p== 6.0**b== 0.1**t== 0.9**l== 0.4**r== 0.3**\nQmass = ρ cpTtip ∙ Smass (9)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.1**l== 0.0**r== 0.0**\nIn Eq. (7), the initial term signi\u0000es the energy contributed by the laser beam, along with the energy losses\nattributable to convection and radiation. Here, Ah denotes the heat transfer coe\u0000cient for the shielding\ngas in contrast to air, while σ and ε represent the Stefan-Boltzmann constant and the re\u0000ectivity of the\nmaterial, respectively. In Eq. (8), P is the laser power, Rb is the effective radius of the laser beam, ω is the\ndistribution coe\u0000cient, and α is the rate of energy absorption. For this study, Rb is assumed to be 1.5 mm\nand ω is taken as 3. In Eq. (9), cp is the speci\u0000c heat capacity of the \u0000ller wire, and Ttip is the preheating\ntemperature of the \u0000ller wire prior to its entry into the melt pool, which is determined by the parameters\nset for the \u0000ller wire preheating.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nThe convective driving forces in the melt pool mainly include the force fs caused by variations in surface\ntension and the buoyancy fρ, caused by density differences in the melt pool. Their calculation formulas\nare as follows:\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nEq. (10) captures the effect of buoyancy in the direction of gravitational force, employing the Boussinesq\napproximation. Here, qr is the density at the reference temperature Tr and β is the coe\u0000cient of thermal\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.0**r== 0.2**\nexpansion. Eq. (11) describes two forces acting on the free surface: (1) the capillary force\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.9**r== 0.0**\nacting\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\n, where the direction of the interface\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nand the curvature k are de\u0000ned in\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.4**r== 0.2**\nacting in the shear stress direction.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nIn this research, numerical simulations were carried out utilizing the commercial computational \u0000uid\ndynamics (CFD) software ANSYS FLUENT 2020 R2. The initial step involved creating a three-dimensional\ncomputational model with SpaceClaim 2020 R2 software, followed by mesh con\u0000guration. The\n**BLOCK**fs== 12.0**p== 7.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\ncomputational domain was de\u0000ned with dimensions of 80 mm in length, 20 mm in width, and 10 mm in\nheight. A uniform hexahedral mesh of 0.2 mm was applied, resulting in a total of 1,250,000 elements.\nOnce the model was established, it was imported into the FLUENT environment, where a pressure-based\ntransient solver was implemented. This solver operates on the SIMPLE (Semi-Implicit Method for\n**BLOCK**fs== 12.0**p== 7.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nPressure-Linked Equations) algorithm to address the governing equations alongside the de\u0000ned\nboundary conditions. To ensure the accuracy of computations and to mitigate numerical oscillations at\nthe interface, second-order spatial discretization was applied to both the velocity and temperature \u0000elds.\nThe simulation was run with a time step of 10− 4 seconds, ensuring that the free surface displacement\ndid not surpass the minimum mesh spacing during each time step. For the simulation, Inconel 718 was\n**BLOCK**fs== 12.0**p== 7.0**b== 0.0**t== 0.9**l== 0.0**r== 0.1**\nchosen as the substrate material, and Inconel 625 was designated as the deposition material. The\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nthermal and physical properties for Inconel 718 and Inconel 625, which were utilized in the simulation,\nare detailed in Tables 2 and 3, respectively. These properties are crucial for accurately modeling the heat\ntransfer and \u0000uid \u0000ow within the computational domain.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nTable 2\nPartial physical parameters of Inconel 718 alloy for simulation\n[20–24]\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.2**l== 0.2**r== 0.6**\nPhysical properties\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nDensity\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nSolidus temperature\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nLiquid temperature\n**BLOCK**fs== 12.0**p== 8.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\nVaporization temperature\n**BLOCK**fs== 12.0**p== 8.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\nLiquid thermal conductivity W/(m·K)\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.4**l== 0.2**r== 0.5**\nSolid thermal conductivity\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nLiquid speci\u0000c heat\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nSolid speci\u0000c heat,\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.5**l== 0.2**r== 0.6**\nLiquid viscosity\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nLatent heat\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nSurface tension coe\u0000cient\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\nSurface tension gradient\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nRadiation emissivity\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nLaser absorption\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.1**l== 0.2**r== 0.2**\nTable 3\nPartial physical parameters of Inconel 625 alloy for simulation\n[25–27]\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nPhysical properties\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nDensity\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nSolidus temperature\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nLiquid temperature\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nVaporization temperature\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.4**\nLiquid thermal conductivity W/(m·K)\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.3**l== 0.2**r== 0.5**\nSolid thermal conductivity\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nLiquid speci\u0000c heat\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nSolid speci\u0000c heat,\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nLiquid viscosity\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nThermal expansivity\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nLatent heat\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nSurface tension coe\u0000cient\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nSurface tension gradient\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nRadiation emissivity\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nLaser absorption\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nIn this research, the laser power was varied within the range of 1200 W to 2100 W, increasing in steps of\n50 W. The welding speed was also adjusted, spanning from 8 mm/s to 14 mm/s in increments of 2\nmm/s. By combining these two sets of process parameters, a comprehensive dataset of 76\nexperimental scenarios was generated. This dataset is ample to facilitate the training of a predictive\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nmodel that correlates process parameters with the dimensions of the melt pool. As depicted in Fig. 4(a),\nan example of the simulation training outcomes is presented. Figures 4(b) and (c) display the cross-\nsectional view of the deposited layer and the temperature distribution along the z-axis of the substrate,\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nrespectively. From the cross-sectional image, the width and height dimensions of the deposited layer\nwere extracted. The depth of the melt pool was ascertained by identifying the extent of the region above\nthe material's solidi\u0000cation temperature.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nTo ascertain the precision of the mechanistic model, a comparison was made between the outcomes of\nthe simulations and the corresponding experimental data, as illustrated in Fig. 5. The \u0000ndings reveal that\nwhile there are minor discrepancies between the melt pool characteristics forecasted by the mechanistic\nmodel and the actual experimental data, the overall patterns are consistent. Figures 5(a)-(c) individually\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.0**r== 0.1**\ndisplay the validation \u0000ndings for the width and height of the deposited layer and the melt pool depth\nacross various process parameters, with an average error rate of less than 10%.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nThe close alignment between the simulation and experimental data, despite minor variations, suggests\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nthat the mechanistic model is capturing the essential physical phenomena of the laser hot-wire metal\ndeposition process. Given these outcomes, the simulation data can be utilized, to a certain extent, as a\npre-training dataset for transfer learning. This approach can aid in the subsequent training and\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\noptimization of models, providing a foundation that can accelerate the learning process and improve the\nmodel's predictive capabilities.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nDeep learning networks typically require a large number of samples for training. However, the high cost\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nof obtaining actual experimental data and the lack of detailed internal information make it impractical to\nrely solely on experimental data to construct large-scale datasets. On the other hand, while simulation\ndata can generate a signi\u0000cant number of samples at a lower cost, there still exists a certain degree of\ndeviation between it and actual experimental data. To overcome these limitations, this study proposes a\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\ntransfer learning training strategy that integrates the advantages of both datasets, as illustrated in Fig. 6.\nThis strategy \u0000rst employs a low-\u0000delity dataset based on simulation data to train a preliminary\nknowledge model. It then enhances and optimizes the performance of this initial model by incorporating\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\na high-\u0000delity dataset derived from actual experimental data through transfer learning, ultimately\nachieving high-accuracy predictive outputs. This approach effectively utilizes limited experimental data\nresources while maintaining prediction accuracy.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nA DNN deep learning network architecture was constructed using Python 3.8 and PyTorch, as shown in\nFig. 7. Laser energy and welding speed are used as inputs, while the width, height of the deposited layer,\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nand depth of the melt pool are treated as outputs. The factors in\u0000uencing the prediction accuracy of the\ndeep learning model primarily depend on the number of hidden layers and neurons, the choice of\noptimization algorithm, and the selection of the loss function. In this study, based on the low-\u0000delity\n**BLOCK**fs== 12.0**p== 10.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\ndataset, different DNN models were established by modifying the number of hidden layers and neurons,\nfollowed by transfer learning. The speci\u0000c parameters are detailed in Table 4. Due to the highly nonlinear\nrelationship of the data, the Adam algorithm was chosen as the optimization algorithm, as it exhibits\nbetter adaptability to non-stationarity and noise. This study essentially constitutes a regression\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nprediction task, hence the mean squared error (MSE) loss function was selected as the loss function,\nand the model parameters were self-optimized based on the loss value. To intuitively represent the\nmodel's prediction performance, the mean absolute percentage error (MAPE) was chosen as the\nevaluation metric. The calculation formulas for the loss function MSE and the evaluation metric MAPE\n**BLOCK**fs== 14.3**p== 11.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\ni=1(yi − ˆyi)2 (13)\n**BLOCK**fs== 7.1**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\n∣∣(ˆyi −yi)∣∣\nyi\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.3**l== 0.0**r== 0.3**\nIn Eq. 13 and Eq. 14, n is the number of samples, yi is the true data value, and\nfrom the DNN model.\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.8**r== 0.0**\nis the predicted value\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\nTable 4\nDNN model parameters\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nHidden layers\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.3**r== 0.7**\nFirst layer\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.4**r== 0.5**\nSecond layer\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.5**r== 0.4**\nThird layer\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\nForth layer\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\nFifth layer\n**BLOCK**fs== 12.0**p== 11.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\nIn transfer learning, to retain the general features learned from the pre-trained model, a common\n**BLOCK**fs== 12.0**p== 11.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\napproach is to use layer freezing methods, allowing for \u0000ne-tuning of the model to adapt to new tasks.\nThe speci\u0000c method is illustrated in Fig. 8, where the primary hidden layers of the model are frozen to\npreserve the general features acquired during the pre-training phase on the simulation dataset. At the\nsame time, \u0000ne-tuning is performed on the deeper layers of the network, speci\u0000cally those closer to the\noutput layer, to adapt to the new task based on the actual experimental dataset. This study explores\ndifferent layer freezing strategies to optimize the transfer learning process, selecting Model 5 for\nexperimentation, as shown in Table 5. Four different layer freezing strategies were implemented to\n**BLOCK**fs== 12.0**p== 12.0**b== 0.9**t== 0.1**l== 0.0**r== 0.1**\nevaluate their performance in the context of transfer learning. Model 5 consists of an input layer, four\nhidden layers, and an output layer. This strategy begins by freezing the input layer and the \u0000rst hidden\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nlayer, progressively increasing the number of frozen layers until all hidden layers are completely frozen.\nThe optimal number of frozen layers is determined by comparing the performance of different strategies.\n**BLOCK**fs== 12.0**p== 12.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\nTable 5\nFrozen Layer Strategy\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.9**\nMethod\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.2**l== 0.2**r== 0.7**\nFrozen layer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.2**l== 0.6**r== 0.2**\nFine-tuned layer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nInput, First layer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nSecond layer, Third layer, Forth layer,\nOutput\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nInput, First layer, Second layer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nThird layer, Forth layer, Output\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.3**l== 0.2**r== 0.5**\nInput, First layer, Second layer, Third layer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.3**l== 0.6**r== 0.2**\nForth layer, Output\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\nInput, First layer, Second layer, Third layer, Forth\nlayer\n**BLOCK**fs== 12.0**p== 12.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nOutput\n**BLOCK**fs== 12.0**p== 12.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nTo meet the input requirements of the model, the data was normalized before the experiments. The\ntraining process was conducted on a graphical workstation running Windows 11, equipped with an\nIntel(R) Core(TM) i7-12700 processor and an Nvidia RTX A4500 graphics processing unit. The low-\u0000delity\ndataset consists of 76 sets of mechanistic model data, while the high-\u0000delity dataset comprises 16 sets\nof experimental data. These two datasets were divided into training, validation, and testing sets in a ratio\nof 6:2:2. The training set is used to train the DNN model, the validation set is used to evaluate the\n**BLOCK**fs== 12.0**p== 12.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nmodel's prediction accuracy and optimize the model's weight parameters, and the testing set is used to\nassess the \u0000nal prediction performance of the DNN model after iterative optimization. This allocation\nstrategy ensures the accuracy and generalization of model training and evaluation.\n**BLOCK**fs== 12.0**p== 12.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nThis study implemented four different layer freezing strategies on Model 5 and compared their\nperformance in transfer learning, focusing speci\u0000cally on two evaluation metrics: loss and mean\nabsolute percentage error (MAPE), as illustrated in Fig. 9(a) and Fig. 9(b). From the \u0000gures, it is evident\n**BLOCK**fs== 12.0**p== 12.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nthat the strategies of freezing one and two hidden layers (referred to as Method 1 and Method 2,\nrespectively) exhibited poor performance during the initial training phases. As training iterations\nprogressed, these strategies showed signi\u0000cant \u0000uctuations in their metrics, leading to a downward\ntrend in performance after 50 training epochs, indicated by increasing loss values and MAPE. In contrast,\nthe strategies that froze three and four hidden layers (Method 3 and Method 4) demonstrated more\nstable training outcomes, with no noticeable performance \u0000uctuations. Nonetheless, Method 3\nexperienced an increase in loss values after 100 training epochs, and MAPE showed an upward trend\n**BLOCK**fs== 12.0**p== 12.0**b== 0.0**t== 0.9**l== 0.0**r== 0.1**\nafter 50 epochs. In comparison, Method 4 exhibited a continuous decrease in both loss and MAPE\n**BLOCK**fs== 12.0**p== 13.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nthroughout the training process, suggesting that the model under this strategy effectively learned and\ntransferred features. These observations reveal that in transfer learning, \u0000ne-tuning only the last hidden\n**BLOCK**fs== 12.0**p== 13.0**b== 0.7**t== 0.1**l== 0.0**r== 0.0**\nlayer and the output layer of the model can yield superior performance. This \u0000nding indicates that during\nthe pre-training phase using the simulation dataset, the model's \u0000rst four hidden layers had already\ncaptured critical features. Consequently, \u0000ne-tuning these layers may lead to a decline in model\nperformance, suggesting that excessive adjustments could disrupt the useful information learned during\nthe pre-training stage.\n4.2 Training results of the DNN model\n**BLOCK**fs== 12.0**p== 13.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nTo ensure consistency during the model training process, we set a \u0000xed learning rate of 0.001 and\nconducted 200 iterations of training, using a strategy of freezing all hidden layers for transfer learning.\nAs shown in Fig. 10(a), the model trained on the actual experimental dataset performed poorly, with a\ntraining loss reaching 1.1118. In contrast, Fig. 10(b) indicates that the average absolute percentage error\n(MAPE) on the validation set was 21.16%. In comparison, the model trained on the simulated dataset\nachieved the best performance, with the optimal model's training loss at only 0.0276 and a MAPE on the\nvalidation set reduced to 2.03%. The model trained on the experimental dataset after pre-training with\n**BLOCK**fs== 12.0**p== 13.0**b== 0.4**t== 0.4**l== 0.0**r== 0.0**\nthe simulated dataset showed a signi\u0000cant performance improvement, closely related to the\nperformance of the pre-trained model, with its optimal training loss at 0.033 and a MAPE of 3.51% on the\nvalidation set. According to the analysis of the model parameters in Table 4, we found that increasing the\nnumber of hidden layers would improve performance up to a certain optimal point, after which further\nincreases would lead to a decline in performance. Similarly, reducing the number of neurons would also\nresult in decreased performance. Therefore, we identi\u0000ed Model 5 as the optimal deep neural network\n(DNN) architecture.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nFurthermore, this study evaluated the predictive performance of the optimal deep neural network (DNN)\nmodel using an independent test set, as shown in Fig. 11. The model demonstrated excellent\nperformance in predicting the height and width of the deposition layer, as well as the depth of the melt\npool, with average errors remaining below 2.5%. This indicates that the model possesses exceptional\ngeneralization capability. These results provide a solid theoretical foundation for the subsequent\noptimization of material processing parameters and process control.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nThis study constructed a deep neural network (DNN) that utilizes a simulation dataset for pre-training,\nfollowed by transfer learning using experimental data, to predict the relationship between process\nparameters and melt pool size information. The research \u0000ndings indicate that:\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\n(1) The model performance is closely related to the number of hidden layers and neurons; however, there\nexists an optimal parameter based on the sample size of the dataset. By comparing the training results\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.9**l== 0.0**r== 0.1**\nof the actual experimental dataset and the simulation dataset, it was found that the approach of pre-\n**BLOCK**fs== 12.0**p== 14.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\ntraining with the simulation dataset combined with transfer learning signi\u0000cantly enhances the model's\nperformance on the experimental dataset.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\n(2) In transfer learning, the choice of the number of frozen layers signi\u0000cantly affects the model's\nperformance. Pre-training the DNN with the simulation dataset showed that the hidden layers had\ncaptured valuable feature representations. Therefore, freezing all hidden layers and only \u0000ne-tuning the\noutput layer of the network achieves optimal transfer learning results.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\n(3) The model obtained through traditional training methods exhibited an error of 21.16%, while the error\nof the model optimized through transfer learning was signi\u0000cantly reduced to 2.03%. Furthermore, the\n**BLOCK**fs== 12.0**p== 14.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nerror of the transfer learning model on the independent test set remained below 2.5%, con\u0000rming the\nexcellent generalization capability of the transfer learning model.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nThis study veri\u0000ed the feasibility of a transfer learning strategy based on simulation datasets for\noptimizing the predictive model of the thermal wire laser metal deposition process. It also enables an\nunderstanding of the potential melt pool dimensions that can be achieved under speci\u0000c process\nparameter settings prior to actual thermal wire laser metal deposition, thereby enhancing deposition\n**BLOCK**fs== 12.0**p== 14.0**b== 0.5**t== 0.4**l== 0.0**r== 0.4**\ne\u0000ciency. Future work will focus on the applicability of the model:\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\n(1) Future work will focus on predicting process parameters based on melt pool size information. This\nwill involve using interpretability analysis to identify the size metrics that show the highest correlation\nwith the process parameters. Additionally, sensing methods will be employed to extract size information\nfor real-time adjustments of the process parameters.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\n(2) Efforts will be made to develop a simulation model that incorporates additional process parameters,\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.0**r== 0.2**\nsuch as wire feed speed and welding current, to enhance the simulation dataset.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\n(3) Integrating more measurable multidimensional data into the deep learning model will enable the\nmodel to capture a more comprehensive range of physical phenomena, thereby enhancing the accuracy\nand reliability of predictions and constructing a digital twin for the hot-wire laser metal deposition\nprocess.\n**BLOCK**fs== 12.0**p== 14.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nThe funding for this project is provided by the Major Cultivation Project of Scienti\u0000c Research Innovation\nPlatform for Colleges and Universities in Gansu Province (2024CXPT-06), the National Natural Science\nFoundation of China (52365048), and the Major Science and Technology Project of Gansu Province\n(22ZD6GA008). The funding bodies had no role in the design of the study, collection, analysis, and\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n1. Yang B, Liao Z, Wu S, Xiao S, Yang G, Zhu T, Wang M, Deng Y (2021) Development of additive\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\nmanufacturing technology and its application prospect in advanced rail transit equipment. J Tra\u0000c\nTransp Eng 21:132–153\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n2. Liu Y, Zhou J, Zhang X (2023) Application and prospect of additive manufacturing technology in\n**BLOCK**fs== 12.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nmanned space engineering. J Beijing Univ Aeronaut Astronaut 49:83–91\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\n3. Liu S, Liu W, Kovacevic R (2017) Experimental investigation of laser hot-wire cladding, Proceedings\nof the Institution of Mechanical Engineers Part B-Journal of Engineering Manufacture, 231 1007–\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n4. Su GX, Shi Y, Li G, Zhang G, Xu YW (2023) Improving the deposition e\u0000ciency and mechanical\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.3**l== 0.1**r== 0.0**\nproperties of additive manufactured Inconel 625 through hot wire laser metal deposition. J Mater\nProcess Technol, 322\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n5. Caiazzo F, Caggiano A (2018) Laser Direct Metal Deposition of 2024 Al Alloy: Trace Geometry\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nPrediction via Machine Learning, Materials, 11\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n\u0000. Cai Y, Wang Y, Chen H, Xiong J (2024) Searching optimal process parameters for desired layer\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\ngeometry in wire-laser directed energy deposition based on machine learning. Virtual Phys Prototyp,\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n7. Petrik J, Kavas B, Bambach M (2023) MeltPoolGAN: Auxiliary Classi\u0000er Generative Adversarial\n**BLOCK**fs== 12.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\nNetwork for melt pool classi\u0000cation and generation of laser power, scan speed and scan direction in\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nLaser Powder Bed Fusion, Addit. Manuf, 78\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n\u0000. Zhu X, Jiang F, Guo C, Wang Z, Dong T, Li H (2023) Prediction of melt pool shape in additive\n**BLOCK**fs== 12.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nmanufacturing based on machine learning methods. Opt Laser Technol, 159\n**BLOCK**fs== 12.0**p== 15.0**b== 0.3**t== 0.6**l== 0.1**r== 0.0**\n9. Lu X, Xie C, He X, Li S, Xu Y, He S, Fang J, Zhang M, Yang X (2023) Automatic Recognition of Multiple\nWeld Types Based on Structured Light Vision Sensor Using Deep Transfer Learning. IEEE Sens J\n23:7142–7152\n**BLOCK**fs== 12.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n10. Jiao W, Wang Q, Cheng Y, Zhang YM (2020) End-to-end prediction of weld penetration: A deep\n**BLOCK**fs== 12.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nlearning and transfer learning based method. J Manuf Process, 63\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.7**l== 0.1**r== 0.0**\n11. Zhao M, Wei H, Mao Y, Zhang C, Liu T, Liao W (2023) Predictions of Additive Manufacturing Process\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nParameters and Molten Pool Dimensions with a Physics-Informed Deep Learning Model,\nEngineering, 23 181–195\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.0**\n12. Menon N, Basak A (2024) Prediction of melt pool geometry by fusing experimental and simulation\n**BLOCK**fs== 12.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\ndata. Int J Mech Sci, 263\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n13. Chakraborty N (2007) Thermal Transport Regimes and Effects of Prandtl Number in Molten Pool\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.2**\nTransport in Laser Surface Melting Processes. Numer Heat Transf 53:273–294\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.3**\n14. Batchelor GK (1967) An Introduction To Fluid Dynamics. The University Pr\n**BLOCK**fs== 12.0**p== 15.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n15. Voller VR, Prakash C (1987) A \u0000xed grid numerical modelling methodology for convection-diffusion\n**BLOCK**fs== 12.0**p== 16.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n1\u0000. Voller VR, Brent AD, Prakash C (1989) The modelling of heat, mass and solute transport in\n**BLOCK**fs== 12.0**p== 16.0**b== 0.9**t== 0.1**l== 0.1**r== 0.4**\nsolidi\u0000cation systems. Int J Heat Mass Transf 32:1719–1731\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n17. Hirt CW, Nichols BD (1981) Volume of \u0000uid (VOF) method for the dynamics of free boundaries. J\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nComput Phys 39:201–225\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n1\u0000. Gu H, Li L (2019) Computational \u0000uid dynamic simulation of gravity and pressure effects in laser\n**BLOCK**fs== 12.0**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\nmetal deposition for potential additive manufacturing in space. Int J Heat Mass Transf 140:51–65\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.2**l== 0.1**r== 0.0**\n19. Wei S, Wang G, Shin YC, Rong Y (2018) Comprehensive modeling of transport phenomena in laser\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.3**\nhot-wire deposition process. Int J Heat Mass Transf 125:1356–1368\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\n20. Yuan W, Chen H, Li S, Heng Y, Yin S, Wei Q (2022) Understanding of adopting \u0000at-top laser in laser\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\npowder bed fusion processed Inconel 718 alloy: simulation of single-track scanning and experiment.\nJ Mater Res Technol 16:1388–1401\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n21. Hosaeus H, Seifter A, Kaschnitz E, Pottlacher G (2001) Thermophysical properties of solid and liquid\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\nInconel 718 alloy. High Temperatures-High Pressures, 33\n**BLOCK**fs== 12.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n22. Knapp GL, Raghavan N, Plotkowski A, Debroy T (2018) Experiments and simulations on solidi\u0000cation\nmicrostructure for Inconel 718 in powder bed fusion electron beam additive manufacturing. Addit\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\n23. Brooks R, Day A, Andon R, Chapman L, Quested P (2001) Measurement of viscosities of metals and\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nalloys with an oscillating viscometer. High Temperatures-High Pressures 33:73–82\n**BLOCK**fs== 12.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\n24. Zhang D, Zhang P, Liu Z, Feng Z, Guo Y (2018) Thermo\u0000uid \u0000eld of molten pool and its effects during\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.5**l== 0.1**r== 0.3**\nselective laser melting (SLM) of Inconel 718 alloy. Addit Manuf, 21\n**BLOCK**fs== 12.0**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.0**\n25. Xiong F, Gan Z, Chen J, Lian Y (2022) Evaluate the effect of melt pool convection on grain structure\nof IN625 in laser melting process using experimentally validated process-structure modeling. J\nMater Process Technol, 303\n**BLOCK**fs== 12.0**p== 16.0**b== 0.3**t== 0.6**l== 0.1**r== 0.0**\n2\u0000. Gan Z, Lian Y, Lin SE, Jones KK, Liu WK, Wagner GJ (2019) Benchmark Study of Thermal Behavior,\nSurface Topography, and Dendritic Microstructure in Selective Laser Melting of Inconel 625.\nIntegrating Materials and Manufacturing Innovation\n**BLOCK**fs== 12.0**p== 16.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n27. Pawel RE, Williams RK (1985) Survey of physical property data for several alloys. [Nitronic 33;\n**BLOCK**fs== 12.0**p== 16.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\ncopper C10400; copper C17510]\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nPrinciples and system of HW-LMD experiment: (a) experimental principles; (b) experimental system\n**BLOCK**fs== 12.0**p== 17.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nExperimental results: (a) morphology of the deposition layer of Inconel 625; (b) cross-section of the melt\npool\n**BLOCK**fs== 12.0**p== 18.0**b== 0.5**t== 0.5**l== 0.0**r== 0.2**\nDiagram illustrating the boundary conditions of the computational domain in the model\n**BLOCK**fs== 12.0**p== 19.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nGraph of simulation results: (a) sedimentary layer topography; (b) sedimentary layer cross-section and\nsize information extraction; (c) melt pool temperature \u0000eld and melt pool depth information extraction\n**BLOCK**fs== 12.0**p== 19.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nError in melt pool dimensions between the mechanistic model and experimental data: (a) error in\ndeposited layer width; (b) error in deposited layer height; (c) error in melt pool depth",
         "Optimization of Process Prediction Models for Hot- Wire Laser Metal Deposition Using Transfer Learning Strategies Based on Simulation Datasets Lanzhou University of Technology Lanzhou University of Technology Lanzhou University of Technology Lanzhou University of Technology Keywords: Laser deposition, mechanistic model, melt pool information, deep learning, transfer learning License:   This work is licensed under a Creative Commons Attribution 4.0 International License. Read Full License This study addresses the challenge of predicting and controlling melt pool behavior in Hot-Wire Laser Metal Deposition (HW-LMD) technology by proposing a transfer learning strategy based on simulation datasets to optimize process parameter prediction. First, a large amount of simulated data was generated using a mechanistic model to pre-train a deep neural network (DNN). Then, transfer learning was applied by incorporating actual experimental data to enhance the model's accuracy in predicting process parameters related to melt pool dimensions. The experimental results demonstrate that this method signi\u0000cantly reduces the demand for experimental data and lowers prediction errors. The model trained with traditional methods exhibited an error rate of 21.16%, whereas the error was signi\u0000cantly reduced to 2.03% after optimization using the transfer learning strategy based on the simulation dataset. The \u0000ndings offer a novel approach to process optimization and quality control in the \u0000eld of additive manufacturing. Hot-Wire Laser Metal Deposition (HW-LMD) technology, as a key technique in the \u0000eld of Additive Manufacturing (AM), has garnered signi\u0000cant attention in recent years [1, 2]. By combining laser energy with resistive heating, HW-LMD enables e\u0000cient metal deposition and is widely applied in high-end manufacturing industries such as aerospace, biomedical, and energy sectors [3, 4]. During this process, the formation, evolution, and \u0000nal solidi\u0000cation state of the melt pool play a decisive role in the microstructure, mechanical properties, and surface quality of the deposited part. Therefore, accurately predicting and controlling melt pool behavior is crucial for optimizing the HW-LMD process. In recent years, Machine Learning (ML) has been applied to solve the challenges of predicting melt pool characteristics and process parameters due to its exceptional data analysis and mining capabilities. Caiazzo et al. [5] developed a unidirectional predictive model from melt pool geometric parameters to process parameters using a machine learning approach based on Arti\u0000cial Neural Networks (ANN). Cai et al. [6] established a system combining a Support Vector Regression (SVR) model with the NSGA-II algorithm to predict the optimal process parameters for desired deposition layer geometry. Deep Learning (DL), a sub\u0000eld of machine learning, also employs data-driven approaches that can be used for process parameter prediction. Petrik et al. [7] developed a MeltPoolGAN network based on Generative Adversarial Networks (GANs) to adjust process parameters using image classi\u0000cation results, while also generating credible melt pool images. However, machine learning typically requires large datasets for training [8], and insu\u0000cient data often leads to under\u0000tting, resulting in inaccurate predictions and low prediction accuracy. In studies addressing welding issues through machine vision, researchers often employ transfer learning techniques to mitigate the under\u0000tting problem caused by insu\u0000cient datasets [9, 10]. However, the pre- trained datasets used for transfer learning in these studies are often large image datasets like ImageNet, which are not readily applicable to the \u0000eld of additive manufacturing. In this domain, publicly available datasets are scarce, and researchers typically need to create their own datasets. However, creating pre- training datasets based on actual experiments is often time-consuming and costly, making it impractical for large-scale studies. Zhao et al. [11] trained a Multilayer Perceptron (MLP) using a combination of high-\u0000delity simulation datasets and experimental datasets, achieving signi\u0000cantly better predictive performance than models trained solely on experimental data. Menon et al. [12] developed a multi- \u0000delity Gaussian Process (MFGP) framework to integrate experimental and simulation data, signi\u0000cantly reducing the amount of experimental data needed without compromising accuracy. These studies indicate that simulation datasets can reduce the amount of data required for machine learning training to a certain extent. Based on the aforementioned issues, this study innovatively proposes a transfer learning strategy based on simulation datasets to optimize process parameter prediction for Hot-Wire Laser Metal Deposition. First, a large amount of simulated data generated by a mechanistic model is used to pre-train a Deep Neural Network (DNN). Then, transfer learning is applied using experimental data. This approach signi\u0000cantly improves the accuracy of the DNN model in predicting the process parameters required for the desired melt pool dimensions. The experimental results show that, compared with models trained solely on experimental datasets, the proposed method signi\u0000cantly reduces the amount of experimental data required while also markedly lowering prediction errors. This is of great importance for accurately The diagram in Fig. 1(a) elucidates the operational concepts behind the HW-LMD technique. This method involves the application of a preheating power source between the wire feeding apparatus and the base material. The current from the preheating stage produces substantial thermal energy within the \u0000ller wire, and when combined with laser power, it aids in the e\u0000cient melting of the wire. The experimental setup, depicted in Fig. 1(b), encompasses several components: a laser cladding head, a wire preheating power supply, a wire feeding mechanism, a shielding gas delivery system, and a motion control system. The laser apparatus employed here is the YLS-4000 IPG laser, which is \u0000tted with a 600 µm diameter \u0000ber and operates at a wavelength of 1.07 µm. This laser is capable of providing a peak power output of 4000 W. By utilizing a 150 mm collimating lens combined with a 250 mm focal length lens, a focused spot size of 3.0 mm is achieved. The JRS-400 wire feeder is tasked with guiding the \u0000ller wire into the molten pool, and the Panasonic YC-400TX4 digital power supply is responsible for heating the wire. This power supply operates in a constant voltage con\u0000guration, ensuring a stable voltage of 5 V with the capacity to deliver up to 300 A of current. To shield against oxidation of both the melt pool and the \u0000ller wire, a \u0000ow of high-purity argon gas (99.999%) is employed. Furthermore, a four-axis motion system has been engineered and integrated to enable precise manipulation of the laser head along the x, y, and z In the research, a nickel-based alloy known as Inconel 718, with dimensions of 100 mm in length, 100 mm in width, and 6 mm in thickness, was chosen for the substrate. The metal deposition material was an Inconel 625 wire with a diameter of 1.2 mm, supplied by SMC. Throughout the experiments, the wire feed rate and preheating current were maintained at a constant level to ensure a consistent deposition rate and preheating temperature. The laser power and the welding speed were \u0000ne-tuned for single-layer deposition on the substrate, with detailed parameters provided in Table 1. As depicted in Fig. 1(a), a trailing wire feeding technique was implemented, positioning the \u0000ller wire at a 0 mm distance from the laser spot to guarantee thorough melting and a stable liquid bridge transition, which implies that the wire was in continuous contact with the melt pool throughout the deposition [13]. The length of each deposition layer was standardized to 70 mm. Further process parameters are outlined in Table 2. To maintain precision in dimensions, the melt pool's height and width were measured at every 6 mm interval, as indicated in Fig. 2(a), and the mean values were recorded. Cross-sectional samples were extracted along the longitudinal axis at the locations marked by the dashed red lines in Fig. 2(a). These samples underwent grinding, polishing, and etching with Aqua regia for 30 seconds to expose the cross- sectional structure of the melt pool and to measure its depth, as shown in Fig. 2(b). The mean dimensions of the melt pool were then used to compile the experimental data set for the purpose of Groups Welding speed Wire feed speed v(mm/s) Table 1 Welding parameters To balance computational accuracy and e\u0000ciency, the following assumptions were made for the Hot- (1) The \u0000uid \u0000ow within the melt pool is laminar [13], incompressible, and behaves as a Newtonian \u0000uid; (2) The in\u0000uence of shielding gas pressure on the melt pool surface contour is neglected; (3) The effect of the \u0000ller wire on melt pool \u0000uid \u0000ow is neglected; Considering factors such as free surface tracking, laser-material interaction, melting and solidi\u0000cation processes, convective driving forces, mass addition effects from the \u0000ller wire, and the preheating process, a three-dimensional transient multiphase \u0000ow and heat transfer model was constructed. In the Eq. (1), ρ represents the material density, t is time, u, v and w are the velocity components of the in the x, y and z directions, respectively, and Smass is the mass source term. Since the model assumes that the melt pool \u0000uid is a Newtonian \u0000uid and the \u0000ow is laminar, its the surface of the element due to molecular viscosity, Smom is the momentum source term, are the gravitational force and external force, respectively. is the stress tensor representing the viscous stress on → F → v H) = ∇ ∙ (k∇ t) + Senergy (3) In Eq. (3), H represents enthalpy, k is the thermal conductivity, and Senergy is the energy source term. The enthalpy-porosity technique [16] is used to simulate the melting and solidi\u0000cation processes of the material. In this model, the liquid volume fraction f is used to represent the fraction of the liquid cell volume, with values ranging between 0 and 1. The formula for calculating the material's enthalpy is as follows: H = href + ∫ T CpdT + fL (4) In Eq. (4), href is the reference enthalpy, Tref is the reference temperature, Cp is the speci\u0000c heat capacity at constant pressure, and L is the latent heat of the material. The liquid volume fraction f can be calculated using the following equation: if T ≤ Tsolid In Eq. (5), Tsolid and Tliquid represent the solid phase temperature and liquid phase temperature of the material, respectively. 2.2.2 Boundary conditions In this study, the critical importance of free surface tracking between the gas and substrate materials for the accuracy of the entire simulation was considered. To this end, a computational domain was constructed as shown in Fig. 3. The model de\u0000nes two distinct phases and distinguishes between external and internal boundary conditions. While the internal boundary conditions relate to melt pool's free surface, the external boundary conditions relate to the computational domain's outer limits.The peripheral and basal surfaces of the substrate are treated as walls to delineate the outer limits of the computational domain. Heat transfer conditions involving conduction, convection, and radiation are imposed on these boundaries. For dealing with internal interfaces, a Volume of Fluid (VOF) model [17] is utilized to depict the boundary between the gaseous and metallic phases with precision. This method allows for an effective simulation of the \u0000uid dynamics within the melt pool and its interaction with the base material. 2.2.3 Source term calculation equation In the laser hot-wire deposition process, the \u0000ller wire \u0000ows steadily into the melt pool, achieving a material utilization rate of 100%. The addition of mass can be considered uniformly distributed, thus the mass source term can be expressed as [18]: In Eq. (6), ρwire is the density of the \u0000ller wire, rwire is the radius of the \u0000ller wire, and fwire is the feeding speed. In this study, rwire is taken as 0.6 mm, fwire14 mm/s, n is 14 mm/s, and n is 3. In the process of laser hot-wire metal deposition, there are two primary heat sources: (1) the laser beam heat source Qlaser, and (2) the \u0000ller wire preheating source Qmass. Taking into account the energy losses attributed to convection and thermal radiation, the term representing the external energy source can be Senergy = [Qlaser − Ah (T − T0) − σ ϵ (T 4 − T0 4)] ∙ δ (ϕ ) + Qmass (7) Thus, the laser beam heat source Qlaser and the \u0000ller wire preheating source Qmass are given by the following equations: In Eq. (7), the initial term signi\u0000es the energy contributed by the laser beam, along with the energy losses attributable to convection and radiation. Here, Ah denotes the heat transfer coe\u0000cient for the shielding gas in contrast to air, while σ and ε represent the Stefan-Boltzmann constant and the re\u0000ectivity of the material, respectively. In Eq. (8), P is the laser power, Rb is the effective radius of the laser beam, ω is the distribution coe\u0000cient, and α is the rate of energy absorption. For this study, Rb is assumed to be 1.5 mm and ω is taken as 3. In Eq. (9), cp is the speci\u0000c heat capacity of the \u0000ller wire, and Ttip is the preheating temperature of the \u0000ller wire prior to its entry into the melt pool, which is determined by the parameters set for the \u0000ller wire preheating. The convective driving forces in the melt pool mainly include the force fs caused by variations in surface tension and the buoyancy fρ, caused by density differences in the melt pool. Their calculation formulas are as follows: Eq. (10) captures the effect of buoyancy in the direction of gravitational force, employing the Boussinesq approximation. Here, qr is the density at the reference temperature Tr and β is the coe\u0000cient of thermal expansion. Eq. (11) describes two forces acting on the free surface: (1) the capillary force acting , where the direction of the interface and the curvature k are de\u0000ned in acting in the shear stress direction. In this research, numerical simulations were carried out utilizing the commercial computational \u0000uid dynamics (CFD) software ANSYS FLUENT 2020 R2. The initial step involved creating a three-dimensional computational model with SpaceClaim 2020 R2 software, followed by mesh con\u0000guration. The computational domain was de\u0000ned with dimensions of 80 mm in length, 20 mm in width, and 10 mm in height. A uniform hexahedral mesh of 0.2 mm was applied, resulting in a total of 1,250,000 elements. Once the model was established, it was imported into the FLUENT environment, where a pressure-based transient solver was implemented. This solver operates on the SIMPLE (Semi-Implicit Method for Pressure-Linked Equations) algorithm to address the governing equations alongside the de\u0000ned boundary conditions. To ensure the accuracy of computations and to mitigate numerical oscillations at the interface, second-order spatial discretization was applied to both the velocity and temperature \u0000elds. The simulation was run with a time step of 10− 4 seconds, ensuring that the free surface displacement did not surpass the minimum mesh spacing during each time step. For the simulation, Inconel 718 was chosen as the substrate material, and Inconel 625 was designated as the deposition material. The thermal and physical properties for Inconel 718 and Inconel 625, which were utilized in the simulation, are detailed in Tables 2 and 3, respectively. These properties are crucial for accurately modeling the heat transfer and \u0000uid \u0000ow within the computational domain. Table 2 Partial physical parameters of Inconel 718 alloy for simulation [20–24] Physical properties Solidus temperature Liquid temperature Vaporization temperature Liquid thermal conductivity W/(m·K) Solid thermal conductivity Liquid speci\u0000c heat Solid speci\u0000c heat, Liquid viscosity Latent heat Surface tension coe\u0000cient Surface tension gradient Radiation emissivity Laser absorption Table 3 Partial physical parameters of Inconel 625 alloy for simulation [25–27] Physical properties Solidus temperature Liquid temperature Vaporization temperature Liquid thermal conductivity W/(m·K) Solid thermal conductivity Liquid speci\u0000c heat Solid speci\u0000c heat, Liquid viscosity Thermal expansivity Latent heat Surface tension coe\u0000cient Surface tension gradient Radiation emissivity Laser absorption In this research, the laser power was varied within the range of 1200 W to 2100 W, increasing in steps of 50 W. The welding speed was also adjusted, spanning from 8 mm/s to 14 mm/s in increments of 2 mm/s. By combining these two sets of process parameters, a comprehensive dataset of 76 experimental scenarios was generated. This dataset is ample to facilitate the training of a predictive model that correlates process parameters with the dimensions of the melt pool. As depicted in Fig. 4(a), an example of the simulation training outcomes is presented. Figures 4(b) and (c) display the cross- sectional view of the deposited layer and the temperature distribution along the z-axis of the substrate, respectively. From the cross-sectional image, the width and height dimensions of the deposited layer were extracted. The depth of the melt pool was ascertained by identifying the extent of the region above the material's solidi\u0000cation temperature. To ascertain the precision of the mechanistic model, a comparison was made between the outcomes of the simulations and the corresponding experimental data, as illustrated in Fig. 5. The \u0000ndings reveal that while there are minor discrepancies between the melt pool characteristics forecasted by the mechanistic model and the actual experimental data, the overall patterns are consistent. Figures 5(a)-(c) individually display the validation \u0000ndings for the width and height of the deposited layer and the melt pool depth across various process parameters, with an average error rate of less than 10%. The close alignment between the simulation and experimental data, despite minor variations, suggests that the mechanistic model is capturing the essential physical phenomena of the laser hot-wire metal deposition process. Given these outcomes, the simulation data can be utilized, to a certain extent, as a pre-training dataset for transfer learning. This approach can aid in the subsequent training and optimization of models, providing a foundation that can accelerate the learning process and improve the model's predictive capabilities. Deep learning networks typically require a large number of samples for training. However, the high cost of obtaining actual experimental data and the lack of detailed internal information make it impractical to rely solely on experimental data to construct large-scale datasets. On the other hand, while simulation data can generate a signi\u0000cant number of samples at a lower cost, there still exists a certain degree of deviation between it and actual experimental data. To overcome these limitations, this study proposes a transfer learning training strategy that integrates the advantages of both datasets, as illustrated in Fig. 6. This strategy \u0000rst employs a low-\u0000delity dataset based on simulation data to train a preliminary knowledge model. It then enhances and optimizes the performance of this initial model by incorporating a high-\u0000delity dataset derived from actual experimental data through transfer learning, ultimately achieving high-accuracy predictive outputs. This approach effectively utilizes limited experimental data resources while maintaining prediction accuracy. A DNN deep learning network architecture was constructed using Python 3.8 and PyTorch, as shown in Fig. 7. Laser energy and welding speed are used as inputs, while the width, height of the deposited layer, and depth of the melt pool are treated as outputs. The factors in\u0000uencing the prediction accuracy of the deep learning model primarily depend on the number of hidden layers and neurons, the choice of optimization algorithm, and the selection of the loss function. In this study, based on the low-\u0000delity dataset, different DNN models were established by modifying the number of hidden layers and neurons, followed by transfer learning. The speci\u0000c parameters are detailed in Table 4. Due to the highly nonlinear relationship of the data, the Adam algorithm was chosen as the optimization algorithm, as it exhibits better adaptability to non-stationarity and noise. This study essentially constitutes a regression prediction task, hence the mean squared error (MSE) loss function was selected as the loss function, and the model parameters were self-optimized based on the loss value. To intuitively represent the model's prediction performance, the mean absolute percentage error (MAPE) was chosen as the evaluation metric. The calculation formulas for the loss function MSE and the evaluation metric MAPE i=1(yi − ˆyi)2 (13) In Eq. 13 and Eq. 14, n is the number of samples, yi is the true data value, and from the DNN model. is the predicted value Table 4 DNN model parameters Hidden layers First layer Second layer Third layer Forth layer Fifth layer In transfer learning, to retain the general features learned from the pre-trained model, a common approach is to use layer freezing methods, allowing for \u0000ne-tuning of the model to adapt to new tasks. The speci\u0000c method is illustrated in Fig. 8, where the primary hidden layers of the model are frozen to preserve the general features acquired during the pre-training phase on the simulation dataset. At the same time, \u0000ne-tuning is performed on the deeper layers of the network, speci\u0000cally those closer to the output layer, to adapt to the new task based on the actual experimental dataset. This study explores different layer freezing strategies to optimize the transfer learning process, selecting Model 5 for experimentation, as shown in Table 5. Four different layer freezing strategies were implemented to evaluate their performance in the context of transfer learning. Model 5 consists of an input layer, four hidden layers, and an output layer. This strategy begins by freezing the input layer and the \u0000rst hidden layer, progressively increasing the number of frozen layers until all hidden layers are completely frozen. The optimal number of frozen layers is determined by comparing the performance of different strategies. Frozen layer Fine-tuned layer Input, First layer Second layer, Third layer, Forth layer, Output Input, First layer, Second layer Third layer, Forth layer, Output Input, First layer, Second layer, Third layer Forth layer, Output Input, First layer, Second layer, Third layer, Forth layer To meet the input requirements of the model, the data was normalized before the experiments. The training process was conducted on a graphical workstation running Windows 11, equipped with an Intel(R) Core(TM) i7-12700 processor and an Nvidia RTX A4500 graphics processing unit. The low-\u0000delity dataset consists of 76 sets of mechanistic model data, while the high-\u0000delity dataset comprises 16 sets of experimental data. These two datasets were divided into training, validation, and testing sets in a ratio of 6:2:2. The training set is used to train the DNN model, the validation set is used to evaluate the model's prediction accuracy and optimize the model's weight parameters, and the testing set is used to assess the \u0000nal prediction performance of the DNN model after iterative optimization. This allocation strategy ensures the accuracy and generalization of model training and evaluation. This study implemented four different layer freezing strategies on Model 5 and compared their performance in transfer learning, focusing speci\u0000cally on two evaluation metrics: loss and mean absolute percentage error (MAPE), as illustrated in Fig. 9(a) and Fig. 9(b). From the \u0000gures, it is evident that the strategies of freezing one and two hidden layers (referred to as Method 1 and Method 2, respectively) exhibited poor performance during the initial training phases. As training iterations progressed, these strategies showed signi\u0000cant \u0000uctuations in their metrics, leading to a downward trend in performance after 50 training epochs, indicated by increasing loss values and MAPE. In contrast, the strategies that froze three and four hidden layers (Method 3 and Method 4) demonstrated more stable training outcomes, with no noticeable performance \u0000uctuations. Nonetheless, Method 3 experienced an increase in loss values after 100 training epochs, and MAPE showed an upward trend after 50 epochs. In comparison, Method 4 exhibited a continuous decrease in both loss and MAPE throughout the training process, suggesting that the model under this strategy effectively learned and transferred features. These observations reveal that in transfer learning, \u0000ne-tuning only the last hidden layer and the output layer of the model can yield superior performance. This \u0000nding indicates that during the pre-training phase using the simulation dataset, the model's \u0000rst four hidden layers had already captured critical features. Consequently, \u0000ne-tuning these layers may lead to a decline in model performance, suggesting that excessive adjustments could disrupt the useful information learned during the pre-training stage. 4.2 Training results of the DNN model To ensure consistency during the model training process, we set a \u0000xed learning rate of 0.001 and conducted 200 iterations of training, using a strategy of freezing all hidden layers for transfer learning. As shown in Fig. 10(a), the model trained on the actual experimental dataset performed poorly, with a training loss reaching 1.1118. In contrast, Fig. 10(b) indicates that the average absolute percentage error (MAPE) on the validation set was 21.16%. In comparison, the model trained on the simulated dataset achieved the best performance, with the optimal model's training loss at only 0.0276 and a MAPE on the validation set reduced to 2.03%. The model trained on the experimental dataset after pre-training with the simulated dataset showed a signi\u0000cant performance improvement, closely related to the performance of the pre-trained model, with its optimal training loss at 0.033 and a MAPE of 3.51% on the validation set. According to the analysis of the model parameters in Table 4, we found that increasing the number of hidden layers would improve performance up to a certain optimal point, after which further increases would lead to a decline in performance. Similarly, reducing the number of neurons would also result in decreased performance. Therefore, we identi\u0000ed Model 5 as the optimal deep neural network (DNN) architecture. Furthermore, this study evaluated the predictive performance of the optimal deep neural network (DNN) model using an independent test set, as shown in Fig. 11. The model demonstrated excellent performance in predicting the height and width of the deposition layer, as well as the depth of the melt pool, with average errors remaining below 2.5%. This indicates that the model possesses exceptional generalization capability. These results provide a solid theoretical foundation for the subsequent optimization of material processing parameters and process control. This study constructed a deep neural network (DNN) that utilizes a simulation dataset for pre-training, followed by transfer learning using experimental data, to predict the relationship between process parameters and melt pool size information. The research \u0000ndings indicate that: (1) The model performance is closely related to the number of hidden layers and neurons; however, there exists an optimal parameter based on the sample size of the dataset. By comparing the training results of the actual experimental dataset and the simulation dataset, it was found that the approach of pre- training with the simulation dataset combined with transfer learning signi\u0000cantly enhances the model's performance on the experimental dataset. (2) In transfer learning, the choice of the number of frozen layers signi\u0000cantly affects the model's performance. Pre-training the DNN with the simulation dataset showed that the hidden layers had captured valuable feature representations. Therefore, freezing all hidden layers and only \u0000ne-tuning the output layer of the network achieves optimal transfer learning results. (3) The model obtained through traditional training methods exhibited an error of 21.16%, while the error of the model optimized through transfer learning was signi\u0000cantly reduced to 2.03%. Furthermore, the error of the transfer learning model on the independent test set remained below 2.5%, con\u0000rming the excellent generalization capability of the transfer learning model. This study veri\u0000ed the feasibility of a transfer learning strategy based on simulation datasets for optimizing the predictive model of the thermal wire laser metal deposition process. It also enables an understanding of the potential melt pool dimensions that can be achieved under speci\u0000c process parameter settings prior to actual thermal wire laser metal deposition, thereby enhancing deposition e\u0000ciency. Future work will focus on the applicability of the model: (1) Future work will focus on predicting process parameters based on melt pool size information. This will involve using interpretability analysis to identify the size metrics that show the highest correlation with the process parameters. Additionally, sensing methods will be employed to extract size information for real-time adjustments of the process parameters. (2) Efforts will be made to develop a simulation model that incorporates additional process parameters, such as wire feed speed and welding current, to enhance the simulation dataset. (3) Integrating more measurable multidimensional data into the deep learning model will enable the model to capture a more comprehensive range of physical phenomena, thereby enhancing the accuracy and reliability of predictions and constructing a digital twin for the hot-wire laser metal deposition process. The funding for this project is provided by the Major Cultivation Project of Scienti\u0000c Research Innovation Platform for Colleges and Universities in Gansu Province (2024CXPT-06), the National Natural Science Foundation of China (52365048), and the Major Science and Technology Project of Gansu Province (22ZD6GA008). The funding bodies had no role in the design of the study, collection, analysis, and 1. Yang B, Liao Z, Wu S, Xiao S, Yang G, Zhu T, Wang M, Deng Y (2021) Development of additive manufacturing technology and its application prospect in advanced rail transit equipment. J Tra\u0000c Transp Eng 21:132–153 2. Liu Y, Zhou J, Zhang X (2023) Application and prospect of additive manufacturing technology in manned space engineering. J Beijing Univ Aeronaut Astronaut 49:83–91 3. Liu S, Liu W, Kovacevic R (2017) Experimental investigation of laser hot-wire cladding, Proceedings of the Institution of Mechanical Engineers Part B-Journal of Engineering Manufacture, 231 1007– 4. Su GX, Shi Y, Li G, Zhang G, Xu YW (2023) Improving the deposition e\u0000ciency and mechanical properties of additive manufactured Inconel 625 through hot wire laser metal deposition. J Mater Process Technol, 322 5. Caiazzo F, Caggiano A (2018) Laser Direct Metal Deposition of 2024 Al Alloy: Trace Geometry Prediction via Machine Learning, Materials, 11 \u0000. Cai Y, Wang Y, Chen H, Xiong J (2024) Searching optimal process parameters for desired layer geometry in wire-laser directed energy deposition based on machine learning. Virtual Phys Prototyp, Network for melt pool classi\u0000cation and generation of laser power, scan speed and scan direction in \u0000. Zhu X, Jiang F, Guo C, Wang Z, Dong T, Li H (2023) Prediction of melt pool shape in additive manufacturing based on machine learning methods. Opt Laser Technol, 159 9. Lu X, Xie C, He X, Li S, Xu Y, He S, Fang J, Zhang M, Yang X (2023) Automatic Recognition of Multiple Weld Types Based on Structured Light Vision Sensor Using Deep Transfer Learning. IEEE Sens J 23:7142–7152 10. Jiao W, Wang Q, Cheng Y, Zhang YM (2020) End-to-end prediction of weld penetration: A deep learning and transfer learning based method. J Manuf Process, 63 11. Zhao M, Wei H, Mao Y, Zhang C, Liu T, Liao W (2023) Predictions of Additive Manufacturing Process Parameters and Molten Pool Dimensions with a Physics-Informed Deep Learning Model, Engineering, 23 181–195 12. Menon N, Basak A (2024) Prediction of melt pool geometry by fusing experimental and simulation data. Int J Mech Sci, 263 13. Chakraborty N (2007) Thermal Transport Regimes and Effects of Prandtl Number in Molten Pool Transport in Laser Surface Melting Processes. Numer Heat Transf 53:273–294 15. Voller VR, Prakash C (1987) A \u0000xed grid numerical modelling methodology for convection-diffusion 1\u0000. Voller VR, Brent AD, Prakash C (1989) The modelling of heat, mass and solute transport in solidi\u0000cation systems. Int J Heat Mass Transf 32:1719–1731 17. Hirt CW, Nichols BD (1981) Volume of \u0000uid (VOF) method for the dynamics of free boundaries. J 1\u0000. Gu H, Li L (2019) Computational \u0000uid dynamic simulation of gravity and pressure effects in laser metal deposition for potential additive manufacturing in space. Int J Heat Mass Transf 140:51–65 19. Wei S, Wang G, Shin YC, Rong Y (2018) Comprehensive modeling of transport phenomena in laser hot-wire deposition process. Int J Heat Mass Transf 125:1356–1368 20. Yuan W, Chen H, Li S, Heng Y, Yin S, Wei Q (2022) Understanding of adopting \u0000at-top laser in laser powder bed fusion processed Inconel 718 alloy: simulation of single-track scanning and experiment. J Mater Res Technol 16:1388–1401 21. Hosaeus H, Seifter A, Kaschnitz E, Pottlacher G (2001) Thermophysical properties of solid and liquid Inconel 718 alloy. High Temperatures-High Pressures, 33 22. Knapp GL, Raghavan N, Plotkowski A, Debroy T (2018) Experiments and simulations on solidi\u0000cation microstructure for Inconel 718 in powder bed fusion electron beam additive manufacturing. Addit 23. Brooks R, Day A, Andon R, Chapman L, Quested P (2001) Measurement of viscosities of metals and alloys with an oscillating viscometer. High Temperatures-High Pressures 33:73–82 24. Zhang D, Zhang P, Liu Z, Feng Z, Guo Y (2018) Thermo\u0000uid \u0000eld of molten pool and its effects during selective laser melting (SLM) of Inconel 718 alloy. Addit Manuf, 21 25. Xiong F, Gan Z, Chen J, Lian Y (2022) Evaluate the effect of melt pool convection on grain structure of IN625 in laser melting process using experimentally validated process-structure modeling. J Mater Process Technol, 303 2\u0000. Gan Z, Lian Y, Lin SE, Jones KK, Liu WK, Wagner GJ (2019) Benchmark Study of Thermal Behavior, Surface Topography, and Dendritic Microstructure in Selective Laser Melting of Inconel 625. Integrating Materials and Manufacturing Innovation 27. Pawel RE, Williams RK (1985) Survey of physical property data for several alloys. [Nitronic 33; copper C10400; copper C17510] Principles and system of HW-LMD experiment: (a) experimental principles; (b) experimental system Experimental results: (a) morphology of the deposition layer of Inconel 625; (b) cross-section of the melt pool Diagram illustrating the boundary conditions of the computational domain in the model Graph of simulation results: (a) sedimentary layer topography; (b) sedimentary layer cross-section and size information extraction; (c) melt pool temperature \u0000eld and melt pool depth information extraction Error in melt pool dimensions between the mechanistic model and experimental data: (a) error in deposited layer width; (b) error in deposited layer height; (c) error in melt pool depth",
         "https://www.researchsquare.com/article/rs-5274598/latest.pdf",
         "extracted",
         "None",
         "Searching optimal process parameters for desired layer geometry in wire-laser directed energy deposition based on machine learning;MeltPoolGAN: Auxiliary Classifier Generative Adversarial Network for melt pool classification and generation of laser power, scan speed and scan direction in Laser Powder Bed Fusion;Improving the deposition efficiency and mechanical properties of additive manufactured Inconel 625 through hot wire laser metal deposition;Prediction of melt pool geometry by fusing experimental and simulation data;Predictions of Additive Manufacturing Process Parameters and Molten Pool Dimensions with a Physics-Informed Deep Learning Model;Evaluate the effect of melt pool convection on grain structure of IN625 in laser melting process using experimentally validated process-structure modeling;End-to-end prediction of weld penetration: A deep learning and transfer learning based method;Computational fluid dynamic simulation of gravity and pressure effects in laser metal deposition for potential additive manufacturing in space;Benchmark Study of Thermal Behavior, Surface Topography, and Dendritic Microstructure in Selective Laser Melting of Inconel 625;Comprehensive modeling of transport phenomena in laser hot-wire deposition process;Laser Direct Metal Deposition of 2024 Al Alloy: Trace Geometry Prediction via Machine Learning;Experimental investigation of laser hot-wire cladding;Experimental study and modeling of H13 steel deposition using laser hot-wire additive manufacturing;Thermal Transport Regimes and Effects of Prandtl Number in Molten Pool Transport in Laser Surface Melting Processes;Thermophysical properties of solid and liquidInconel 718 Alloy;The modelling of heat, mass and solute transport in solidification systems;A fixed grid numerical modelling methodology for convection-diffusion mushy region phase-change problems;Prediction of Melt Pool Shape in Additive Manufacturing Based on Machine Learning Methods;Volume of fluid (VOF) method for the dynamics of free boundaries",
         "Optimization of process prediction models for hot-wire laser metal deposition using transfer learning strategies based on simulation datasets"
        ],
        [
         "33",
         "0173b93515e9956fc5942d3efeb00da8c5edb506",
         "None",
         "Kuan Cheng,Elena Grigorescu,Xin Li,Madhu Sudan,Minshen Zhu",
         "\n**BLOCK**fs== 17.2**p== 0.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nOn k-Mer-Based and Maximum Likelihood Estimation\nAlgorithms for Trace Reconstruction\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nKuan Cheng ∗\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nElena Grigorescu †\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nXin Li ‡ Madhu Sudan§ Minshen Zhu ¶\n**BLOCK**fs== 9.0**p== 0.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\nAbstract\n**BLOCK**fs== 9.0**p== 0.0**b== 0.7**t== 0.3**l== 0.2**r== 0.4**\nThe goal of the trace reconstruction problem is to recover a string x\n**BLOCK**fs== 9.0**p== 0.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nn given many independent\n}\ntraces of x, where a trace is a subsequence obtained from deleting bits of x independently with some\n[0, 1). A recent result of Chase (STOC 2021) shows how x can be determined\ngiven probability p\n(in exponential time) from exp(O(n1/5) log5 n) traces. This is the state-of-the-art result on the sample\ncomplexity of trace reconstruction.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.4**l== 0.2**r== 0.1**\nIn this paper we consider two kinds of algorithms for the trace reconstruction problem.\nWe ﬁrst observe that the bound of Chase, which is based on statistics of arbitrary length-k subse-\nquences, can also be obtained by considering the “k-mer statistics”, i.e., statistics regarding occurrences\nof contiguous k-bit strings (a.k.a, k-mers) in the initial string x, for k = 2n1/5. Mazooji and Shomorony\n(arXiv.2210.10917) show that such statistics (called k-mer density map) can be estimated within ε ac-\ncuracy from poly(n, 2k, 1/ε) traces. We call an algorithm to be k-mer-based if it reconstructs x given\nestimates of the k-mer density map. Such algorithms essentially capture all the analyses in the worst-case\nand smoothed-complexity models of the trace reconstruction problem we know of so far.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\nOur ﬁrst, and technically more involved, result shows that any k-mer-based algorithm for trace\nreconstruction must use exp(Ω(n1/5√log n)) traces, under the assumption that the estimator requires\npoly(2k, 1/ε) traces, thus establishing the optimality of this number of traces. The analysis of this result\nalso shows that the analysis technique used by Chase (STOC 2021) is essentially tight, and hence new\ntechniques are needed in order to improve the worst-case upper bound.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nThis result is shown by considering an appropriate class of real polynomials, that have been previously\nstudied in the context of trace estimation (De, O’Donnell, Servedio. Annals of Probability 2019; Nazarov,\nPeres. STOC 2017), and proving that two of these polynomials are very close to each other on an arc in\nthe complex plane. Our proof of the proximity of such polynomials uses new technical ingredients that\nallow us to focus on just a few coeﬃcients of these polynomials.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nOur second, simple, result considers the performance of the Maximum Likelihood Estimator (MLE),\nwhich speciﬁcally picks the source string that has the maximum likelihood to generate the samples\n(traces). We show that the MLE algorithm uses a nearly optimal number of traces, i.e., up to a factor\nof n in the number of samples needed for an optimal algorithm, and show that this factor of n loss may\nbe necessary under general “model estimation” settings.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n∗Peking University, Haidian, Beijing, China. Email: ckkcdh@pku.edu.cn.\n†Purdue University, West Lafayette, IN, USA. Supported in part by NSF CCF-1910411, and NSF CCF-2228814. Email:\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nelena-g@purdue.edu.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n‡Johns Hopkins University, Baltimore, MD, USA. Supported in part by NSF CAREER Award CCF-1845349 and NSF Award\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nCCF-2127575. Email: lixints@cs.jhu.edu.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n§School of Engineering and Applied Sciences, Harvard University, Cambridge, Massachusetts, USA. Supported in part by a\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.3**\nSimons Investigator Award and NSF Award CCF 2152413. Email: madhu@cs.harvard.edu.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n¶Most of the work was done as a PhD student at Purdue University. Supported in part by NSF CCF-1910411, and NSF\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nThe trace reconstruction problem is an infamous question introduced by Batu, Kannan, Khanna and Mc-\nGregor [BKKM04] in the context of computational biology. It asks to design algorithms that recover a string\nn given access to traces ˜x of x, obtained by deleting each bit independently with some given prob-\nx\n0, 1\n∈ {\nO(n1/5))\nability p\ntraces are suﬃcient for reconstruction [Cha21b] (improving upon the exp(O(n1/3)) of [NP17, DOS19]) and\nΩ(n3/2) [HL20, Cha21a] are necessary.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\n[0, 1). The best current upper and lower bounds are exponentially apart, namely exp(\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nThe problem has been recently studied in several variants so far [BKKM04, KM05, VS08, HMPW08,\nMPV14, PZ17, NP17, DOS19, GM17, HPP18, HL20, HHP18, GM19, CGMR20, KMMP21, BLS20, CDL+21b,\ne\nCha21b, CP21, NR21, SB21, GSZ22, Rub23] and it continues to elicit interest due to its deceptively simple\nformulation, as well as its motivating applications to DNA computing [YGM17].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nIn this paper, we focus on the worst-case formulation of the problem, which is equivalent from an\ninformation-theoretic point of view to the distinguishing variant. In this variant, the goal is to distinguish\nwhether the received traces come from string x\n0, 1\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.3**l== 0.7**r== 0.2**\nn, for some known x\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.3**l== 0.5**r== 0.4**\nn or from y\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nAlgorithms based on k-bit statistics A very natural kind of algorithms [HMPW08, NP17, DOS19]\n[n] (one may assume that traces of smaller\noperates using the mean of the received traces at each location i\nlength than n are padded with 0’s at the end). Indeed, let\nx be the distribution of the traces induced by\nthe deletion channel on input x. A mean/1-bit-statistics -based algorithm ﬁrst estimates from the received\ntraces the mean vector E(x) =\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[0, 1]n, where the j-th coordinate is deﬁned as\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nIt then may perform further post-processing without further inspection of the traces.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nSolving the distinguishing problem then reduces by standard arguments to understanding the ℓ1-norm\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nbetween the mean traces of x and y, namely the number T of traces satisﬁes\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[NP17, DOS19] related the ℓ1-norm above with the supremum of a certain real univariate polynomial over\nthe complex plane. Using techniques from complex analysis they proved that mean-based algorithms using\nexp(O(n1/3)) traces and outputting the string s\nwhose E(s) is closer in ℓ1-distance to the estimate\nx, y\nis a successful reconstruction algorithm. Furthermore, any mean-based algorithm needs exp(Ω(n1/3)) traces\nto succeed with high probability [NP17, DOS19].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\nA general class of algorithms may operate by using k-bit statistics [Cha21b], for k\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nw\n0, 1\n∈ {\nquantity\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.7**l== 0.2**r== 0.4**\nk, the algorithm estimates from the given traces, for tuples 0\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.8**r== 0.1**\n1. Speciﬁcally, for\n1, the\nn\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n\nAfter the estimation step, whose accuracy can be argued via standard Chernoﬀ bounds, the algorithm does\nnot need the traces anymore and may perform further post-processing in order to output the correct string.\nThe result of Chase follows from showing that for k = 2n1/5 there is a string w\nk for which the\nℓ1-distance between the corresponding k-bit statistics between x and y is large.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nAlgorithms based on k-mer statistics Another variant proposed by Mazooji and Shomorony [MS22]\nconsiders algorithms which operate using estimates of statistics regarding occurrences of contiguous k-bit\nstrings (a.k.a, k-mers) in the initial string x. We denote by 1\nthe indicator bit of\nwhether w\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.3**r== 0.4**\nk occurs as a subword in x from position j.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.9**l== 0.1**r== 0.3**\nIn particular, [MS22] made the following deﬁnition which is central to our paper.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.7**r== 0.2**\nk, for i = 0, 1, . . . , n\n}\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.8**r== 0.1**\n1 denote\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nThe vector Kx :=\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.5**r== 0.2**\nis called the k-mer density map of x.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nNote that the mean vector E(x) is, up to a factor of 1\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nfor k = 1 and w = 1 we have\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\np, equivalent to the 1-mer density map. Indeed,\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nxi comes from xj\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nAs noted in [MS22], the techniques of [CDL+21b] in the smoothed complexity model of trace reconstruc-\nk, the number of\n}\nn\ni=0 Kw,x[i]. They show that for\n−\nk) uniquely determines the source string, with high\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.3**\ntion can also be viewed as based on k-mer density maps. Indeed, for a ﬁxed w\nn\n\nits occurrences as a subword in x is\nj=0 1\n−\nk = O(log n), the subword vector (indexed by w\n\nprobability [CDL+21b, Lemma 1.1].\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nThe main result of [MS22] is that given access to T = ε−\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nan estimation ˆKx of the k-mer density map Kx which is entry-wise ε-accurate, i.e.,\nremark that by replacing ε with ε/(2kn), one gets an estimate which is ε-accurate in ℓ1-norm, while using\nasymptotically the same number of traces.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\n2O(k)poly(n) traces of x, one can recover\nˆKx\nε. We\n\n\n\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\nWe make the following deﬁnition generalizing mean-based algorithms ([DOS19, NP17]).\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nDeﬁnition 2. (Algorithms based on k-mer statistics) A trace reconstruction algorithm based on k-mer\nstatistics works in two steps as follows:\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\n1. Once the unknown source string x\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\n(0, 1]. It\nthen receives an ǫ-accurate estimate (in ℓ1-norm) of the k-mer density map Kx based on the traces.\nFrom here on the algorithm has no more access to the traces themselves. We deﬁne the cost of this part\nto be 2k/ε.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\nn is picked, it chooses an accuracy parameter ε\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n2. The algorithm may perform further post-processing and ﬁnish by outputting the source string.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nSince there is an algorithm to ε-estimate the k-mer density map with ε−\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n2O(k)poly(n) many traces\n[MS22], it follows that an algorithm deﬁned as in Deﬁnition 2 with cost T can be turned into a trace\nreconstruction algorithm with poly(T ) samples.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nWe note that the k-mer density map estimators of [MS22] only use k-bit statistics of the traces, in fact\nstatistics about contiguous k bits in the traces, and hence k-mer-based algorithms are a subclass of algorithms\nbased on k-bit statistics.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nIn this work, we ﬁrst observe that the upper bounds of Chase [Cha21b] can be in fact obtained via k-mer-\nbased algorithms (see the formal statement in Theorem 1), and hence by only using statistics of contiguous\nsubwords of the traces. Our main result says that k-mer-based algorithms require exp(Ω(n1/5)√n) many\ntraces (see Theorem 2). In addition, the analysis of this result implies that the proof technique in Chase\n[Cha21b] cannot lead to a better analysis of the sample complexity (up to log4.5 n factors in the exponent),\nand hence new techniques are needed to signiﬁcantly improve the current upper bound.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nThe Maximum Likelihood Estimator\nIn model estimation settings, a common tool for picking a\n“model” that best explains the observed data is the Maximum Likelihood Estimator (MLE). In the set-\nting of trace reconstruction, it is natural to ask: What is the most likely trace distribution\nx (and hence\nx) to have produced the given sample/trace(s)? We formalize MLE next.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\nDeﬁnition 3 (Maximum Likelihood Estimation). Let\n{\ndistributions over a common domain Ω. Given a sample x\nEstimation is (ties are broken arbitrarily)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\nbe a ﬁnite set of probability\nΩ, the output of the Maximum Likelihood\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\n) := arg max\n[m]\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nFor independently and identically distributed samples x1, x2, . . . , xk ∈\nhood Estimation is (ties are broken arbitrarily) is\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\nΩ the output of the Maximum Likeli-\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.3**r== 0.5**\nMLE(x1, x2, . . . xk;\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.5**r== 0.4**\n) := arg max\n[m]\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nWe present a simple proof that this algorithm (which takes exponential time, as it searches through all\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nn) is in fact optimal in the number of traces used, up to an O(n) factor blowup.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nWe also observe that in the average-case setting, where the source string is a uniformly random string\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nn, MLE is indeed optimal – without the O(n) factor blowup (see Remark 2.)\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\n1.1 Our Contributions\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nThe power of k-mer-based algorithms Our ﬁrst result shows that algorithms based on k-mer statistics\ncan reconstruct a source string using exp(\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.4**r== 0.1**\nO(n1/5)) many traces. This follows from the following theorem.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.3**\nTheorem 1 (Implied by [Cha21b]). Let x, y\ntheir k-mer density maps, respectively. Assuming k = 2n1/5, it holds that\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nn be two arbitrary distinct strings, and let Kx, Ky be\n}\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\nO(n1/5 log5 n)\n\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n\nBased on Theorem 1, the algorithm estimates ˆK within an accuracy of ε = exp(\n\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.8**r== 0.1**\nO(n1/5 log5 n)) and\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\noutputs the x that minimizes\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.4**r== 0.1**\n. The cost of this k-mer-based algorithm is exp(O(n1/5 log5 n)).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nOur main result regarding k-mer-based algorithms is the following theorem which shows the tightness of\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nthe bound in Theorem 1.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nTheorem 2. Fix any k\nstrings x, y\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\n≤\nn such that\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nn1/5. Suppose Kx stands for the k-mer density map of x. There exist distinct\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nHence, Theorem 2 implies that the cost of any k-mer-based algorithm for worst-case trace reconstruction\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nis exp(Ω(n1/5√log n)).\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nRemark 1. As one might expect, for k′ < k the k′-mers usually contain less information than k-mers. To\nsee this, observe that for a (k\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.4**r== 0.3**\n1)-mer w, we have the following relation\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n−\nprovided that j > 0. The same also holds for y. In fact, the strings x and y obtained via Theorem 2 share\na common preﬁx of length at least k (or one could prepend a preﬁx anyway), so x[0 : k′\n1]\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nfor any k′ < k, and one does not need to worry about the case j = 0. Plugging into the deﬁnition of k-mer\ndensity maps, we have\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nBy induction, for any k′ < k we have\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nTherefore, the bound in Theorem 2 indeed covers all k′-mers for k′\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nWe remark that the proof of Theorem 2 further implies that the analysis technique of [Cha21b] is essen-\ntially tight, in the sense that no better upper bound (up to log4.5 n factors in the exponent) can be obtained\nvia his analysis. We include further details about this implication in Remark 3.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nMaximum Likelihood Estimator: an optimal algorithm We next turn to analyzing the performance\nof the MLE algorithm in the setting of trace reconstruction. Our main result essentially shows that if there\nis an algorithm for trace reconstruction that uses T traces and succeeds with probability 3/4 then the MLE\nalgorithm using O(nT ) traces succeeds with probability 3/4. Hence, given that the current upper bounds for\nthe worst-case reconstruction problem are exponential in n, we may view the MLE as an optimal algorithm\nfor trace reconstruction.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\nTheorem 3. Suppose\nwe have\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.5**r== 0.3**\nis such that dTV (D0, Di)\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.7**r== 0.2**\nε for any 1\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nWe remark that the loss of a factor of m in Theorem 3 is generally inevitable. Here is a simple example: let\nD0 be the uniform distribution over [m], and for i = 1, 2, . . . , m, let Di be the point distribution supported on\n= 0.\n1/m))/2 = 1\nn, let Dx denote the trace distribution of x. Theorem 3 implies the following\n}\ncorollary, which implies that in some sense the Maximum Likelihood Estimation is a universal algorithm for\ntrace reconstruction.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\n. We have dTV (D0, Di) = ((m\n}\nFor a string x\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.6**r== 0.3**\n1/m. However, Prx\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nCorollary 1.1. Suppose T traces are suﬃcient for worst-case trace reconstruction with a success rate 3/4.\nnT traces solves worst-case trace\nThen for any ε > 0, Maximum Likelihood Estimation with 8 ln(1/ε)\nreconstruction with success rate 1\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nCorollary 1.1 incurs a factor of O(n) to the sample complexity. While we currently do not know whether\nthis blowup is necessary for trace reconstruction, the next result shows that it is inevitable for the more\ngeneral “model estimation” problem.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nTheorem 4. For any integer n\ncommon domain Ω of size\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.4**\nn\nn/4\n⌋\n\n1. There is a distinguisher A which given one sample x\n∼\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.3**r== 0.5**\n= m + n, where m =\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\nj with probability at least 2/3. In other words, for all j = 0, 1, . . . , m,\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\n1, there is a set of distributions\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.7**l== 0.6**r== 0.1**\n= 2Θ(n), satisfying the following conditions.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nAj for an unknown j\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\n, recovers\n}\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n2. MLE fails to distinguish D0 from other distributions with probability 1, even with T = n/4 samples.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.2**r== 0.7**\nIn other words,\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nRemark 2. Finally, we remark that in the average-case setting MLE is indeed optimal (with no factor of\nO(n) factor blowup in the number of traces). This is because maximizing the likelihood is equivalent to\nmaximizing the posterior probability under the uniform prior distribution (which is optimal), as can be seen\nvia the Bayes rule\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.3**\nTherefore maximizing both sides with respect to x yields the same result.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\n1.2 Overview of the techniques\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.4**l== 0.1**r== 0.1**\nLower bounds for k-mer-based algorithms\nIn recent development of the trace reconstruction problem,\nthe connection to various real and complex polynomials has been a recurring and intriguing theme [HMPW08,\nNP17, PZ17, HPP18, DOS19, CDL+21b, CDRV21, Cha21b, SB21, GSZ22, Rub23]. The starting point of\nthese techniques is to design a set of statistics that can be easily estimated from the traces (e.g., mean traces),\nwith the property that for diﬀerent source strings the corresponding statistics are somewhat “far apart”. To\nestablish this property, one key idea is to associate each source string x with a generating polynomial Px\nwhere the coeﬃcients are exactly the statistics of x. Due to the structure of the deletion channel, in many\ncases, this generating polynomial (under a change of variables) is identical to another polynomial Qx that\nis much easier to get a handle on. For example, the coeﬃcients of Qx are usually 0/1, and they are easily\ndetermined from x. To show that the statistics corresponding to x and y are far apart (say, in ℓ1-distance), it\nis large for an appropriate choice of w. This is the point where all\nis suﬃcient to show that\nsorts of analytical tools are ready to shine. For instance, the main technical result in [Cha21b] is a complex\nanalytical result that says that a certain family of polynomials cannot be uniformly small over a sub-arc of\nthe complex unit circle, which has applications beyond the trace reconstruction problem.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nThis analytical view of trace reconstruction can lead to a tight analysis of certain algorithms/statistics.\nThe best example would be mean-based algorithms, for which a tight bound of exp(Θ(n1/3)) traces is known\nto be suﬃcient and necessary for worst-case trace reconstruction [NP17, DOS19]. The tightness of the sample\ncomplexity is exactly due to the tightness of a complex analytical result by Borwein and Erdélyi [BE97].\nOur lower bound for k-mer-based algorithms is obtained in a similar fashion, via establishing a complex\nanalytical result complementary to that of [Cha21b] (See Lemma 3.1).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nOn the other hand, our argument takes a diﬀerent approach than that of [BE97]. At a high level, both\nresults use a Pigeonhole argument to show the existence of two univariate polynomials which are uniformly\nclose over a sub-arc Γ of the complex unit circle. The diﬀerence lies in the objects playing the role of\n“pigeons”. [BE97]’s argument can be viewed as two steps: (1) apply the Pigeonhole Principle to obtain two\npolynomials that have close evaluations over a discrete set of points in Γ, and (2) use a continuity argument\nto extend the closeness to the entire sub-arc. Here the roles of pigeons and holes are played by evaluation\nvectors, and Cartesian products of small intervals. Our approach considers the coordinates of a related\npolynomial in the Chebyshev basis, which play the roles of pigeons in place of the evaluation vector. The\nproperties of Chebyshev polynomials allow us to get rid of the continuity argument. Instead, we complete\nthe proof by leveraging rather standard tools from complex analysis (e.g., Theorem 5 and Theorem 6). We\nbelieve this approach has the advantage of being generalizable to multivariate polynomials over the product\nΓm via multivariate Chebyshev series (see, e.g., [Mas80, Tre17]), whereas the same\nof sub-arcs Γ = Γ1 × · · · ×\ngeneralization seems to be tricky for the continuity argument.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nFinally, the counting argument considers a special set of strings for which eﬀectively only one k-mer\ncontains meaningful information about the initial string. Since previous arguments did not exploit structural\nproperties of the strings, this is another technical novelty of our proof.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.1**l== 0.1**r== 0.1**\nMaximum Likelihood Estimation Most of our results regarding Maximum Likelihood Estimation hold\nunder the more general “model estimation” setting, where one is given a sample x drawn from an unknown\nand tries to recover D. Our main observation is that if such a distinguisher works in worst-\ndistribution D\nhave large pairwise statistical distances. The maximization characterization\ncase, then the distributions in\nD its likelihood is\nof statistical distance, in conjunction with a union bound, implies that for a sample x\nmaximized by D except with a small probability. The O(n) factor loss in the sample complexity is essentially\ndue to the union bound, and we show that this loss is tight in general by constructing a set of distributions\nwhich attains equality in the union bound.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n1.3 Related work\n**BLOCK**fs== 10.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nThe trace reconstruction problem was ﬁrst introduced and studied by Levenshtein [Lev01b][Lev01a]. The\noriginal question is that if a message is sent multiple times through the same channel with random inser-\ntion/deletion errors, then how to recover the message? [BKKM04] and [HMPW08] formalized the problem\nto the current version for which the channel only has random deletions. Their central motivation is actually\nfrom computational biology, i.e. how to reconstruct the whole DNA sequence from multiple related subse-\nquences. [CGMR20] and [BLS20] further extended the study to the “coded” version. That is, the string to\nreconstruct is not an arbitrary string but instead is a codeword from a code. A variant setting where the\nchannel has memoryless replication insertions was studied by [CDRV21].\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nThe average case version was studied in [HMPW08, PZ17, MPV14, HPP18]. For this case, the best\nΩ(log5/2 n) [HL20, Cha21a]. Building on Chase’s upper\nO(log1/5 n)) in the\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.2**\nknown lower bound on the number of traces is\nbound for the worst case, [Rub23] improved the sample complexity upper bound to exp(\naverage-case model.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.5**l== 0.1**r== 0.1**\n[CDL+21b] studied another variant of the problem which is called the smooth variant. It is an inter-\nmediate model between the worst-case and the average-case models, where the initial string is an arbitrary\nstring perturbed by replacing each coordinate by a uniformly random bit with some constant probability in\n[0, 1]. [CDL+21b] provided an eﬃcient reconstruction algorithm for this case. Other variants studied include\ntrace reconstruction from the multiset of substrings [GM17, GM19], population recovery variants [BCF+19],\nmatrix reconstruction and parameterized algorithms [KMMP21], circular trace reconstruction [NR21], re-\nconstruction from k-decks [KR97, Sco97, DS03, MPV14], and coded trace reconstruction[CGMR20, BLS20].\n[DRSR21] studied approximate trace reconstruction and showed eﬃcient algorithms. [CDL+21a], [CDK21],\nand [CP21] further proved that if the source is a random string, then an approximate solution can be found\nwith high probability using very few traces. Notice that approximate reconstructions imply distinguishers\nfor pairs of strings with large edit distances. [MPV14, SB21, GSZ22] study the complexity of the problem\n[GSZ22] also shows that the problem\nparameterized by the Hamming/edit distance between the strings.\nof exhibiting explicit strings that are hard to distinguish for mean-based algorithms is equivalent to the\nProuhet-Tarry-Escott problem, a diﬃcult problem in number theory.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\n1.4 Organization\n**BLOCK**fs== 10.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nIn Section 2 we prove Theorem 1, in Section 3 we prove our main result Theorem 2, and in Section 4 we\nprove Theorem 3.\n**BLOCK**fs== 14.3**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\n2 k-mer-based algorithms: the upper bound\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nWe prove Theorem 1 in this section.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nLet us start with a deﬁnition that is essential for the study of k-mer-based algorithms.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nDeﬁnition 4 (k-mer generating polynomial). Let x\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\nk. The k-mer generating\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.1**r== 0.4**\npolynomial Pw,x for string x and k-mer w is the following degree-(n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.1**l== 0.6**r== 0.2**\n1) polynomial in z:\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nWe have the following identity\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\n\nThe expression on the last line, under a change of variable z0 = p + (1\nstudied in [Cha21b].\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.7**r== 0.1**\np)z, is exactly the polynomial\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.1**r== 0.4**\nLemma 2.1. [Cha21b, Proposition 6.3] For distinct x, y\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.8**\nthen there are w\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nn, if xi = yi for all 0\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.6**r== 0.4**\n∈ {\n}\nsuch that\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nHere C > 0 is a constant depending only on the deletion probability p.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.8**r== 0.2**\nCn1/5 log5 n\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nWe will use Lemma 2.1 to show that the exp(\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nO(n1/5)) upper bound of [Cha21b] can be achieved by\nk-mer-based algorithms, rather than general algorithms based on k-bit statistics. Our main lower bound on\nthe number of traces implied by Theorem 2 will follow by showing an upper bound on the LHS in the lemma\nabove (see Lemma 3.1).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nRemark 3. We remark that the result of Chase is obtained by ﬁrst considering a corresponding multivariate\nchannel polynomial that encodes in its coeﬃcients the k-bit statistics of the traces. The upper bound on\nthe number of traces reduces to understanding the supremum of this polynomial over a certain region of\nk and z0\nthe complex plane. The crucial element of the proof is the reduction to the existence of w\nsatisfying Lemma 2.1, by appropriately making the remaining variables take value 0. We noticed that the\nresulting univariate polynomial is essentially the k-mer generating polynomial deﬁned in Deﬁnition 4, with an\np)k. Our result in Lemma 3.1 implies that no tighter lower bound (up to polylogarithmic\nextra factor of (1\nfactors in the exponent) is possible for this univariate polynomial, showing that the analysis technique used\nin [Cha21b] cannot give a better upper bound on worst-case trace complexity.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.2**t== 0.7**l== 0.1**r== 0.4**\n2.1 An upper bound for k-mer based algorithms\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nThe proof of Theorem 1 mainly uses Lemma 2.1. We will also make use of the following result.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nLemma 2.2. [BEK99, Theorem 5.1] There are absolute constants c1 > 0 and c2 > 0 such that\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.9**l== 0.1**r== 0.4**\nfor every analytic function f on the open unit disk that satisﬁes\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.7**\nProof of Theorem 1.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nThe proof deals with two cases.\nCase 1: xi = yi for all 0\nIn this case, x and y satisfy the premise of Lemma 2.1. It follows that there exist w\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nz0 = eiθ where\n**BLOCK**fs== 10.0**p== 8.0**b== 0.8**t== 0.2**l== 0.3**r== 0.5**\n2/5, satisfying the bound\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.2**l== 0.8**r== 0.2**\nCn1/5 log5 n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nHere C > 0 is a constant depending only on the deletion probability p. Rewriting in terms of the k-mer\ngenerating polynomials, we have\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nIt is easy to see that\n**BLOCK**fs== 10.0**p== 8.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\nCn1/5 log5 n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\n\n\n\n\n= 1. We also have the following upper bounds\n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.3**l== 0.4**r== 0.5**\n\nz0| −\n|\n|\n\np)2 + sin2 θ\n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.4**r== 0.5**\n−\n(1\n−\n4p sin2 θ\n\np)2 ≤\n(1\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\n2p cos θ + p2\np)2\n(1\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\nFrom here we can apply the triangle inequality and conclude that\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.4**r== 0.5**\n·\n\n\nXℓ=0\n\n\n\n\np\n\n\n\n2(1\n−\n−\nC′n1/5 log5 n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\nCn1/5 log5 n\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nHere C′ = p(1\n−\nCase 2: xi 6\n= yi for some 0\nIn this case, we are going to take w = x[0 : 2n1/5\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.3**r== 0.2**\n2/2 + C is a constant depending only on the deletion probability p.\n1, i.e., x[0 : 2n1/5\n**BLOCK**fs== 10.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n1] and show a much better bound\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nwhere C′′ > 0 is a constant depending only on p (hence certainly greater than exp(\nwhat we did in case 1, applying the triangle inequality to Eq. (2) gives the theorem.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nTo prove Eq. (2), we let\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\nO(n1/5))). Similar to\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nso that Q(p + (1\nQ(0) = 1.\nIf p\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.3**r== 0.6**\np)z) = Pw,x(z)\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.1**l== 0.4**r== 0.1**\nPw,y(z). Under our choice of w, the constant term of Q equals to 1, i.e.,\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\n(0, 1/2], the closed disk B(p; 1\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.6**r== 0.1**\ncontains the point 0. Therefore\n**BLOCK**fs== 10.0**p== 9.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\n\n\n(1/2, 1). Since Q is a polynomial with coeﬃcients absolutely bounded by 1, we\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.2**l== 0.1**r== 0.6**\n|\nWe are left with the case p\ncan apply Lemma 2.2 with a = 2(1\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.2**l== 0.4**r== 0.4**\n(0, 1) and obtain\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n\n\nfor constants c1, c2 > 0. Denoting t = (t0 −\np)/(1\nt is inside the closed unit disk B(0; 1). Therefore\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\n\n\n\n\np), we have t\n**BLOCK**fs== 10.0**p== 9.0**b== 0.7**t== 0.3**l== 0.8**r== 0.1**\na, 1]. In particular,\n**BLOCK**fs== 10.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\n\n\nTo conclude, we can take C′′ = min\n**BLOCK**fs== 14.3**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n3 A lower bound for k-mer based algorithms: Proof of Theorem 2\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nWe prove Theorem 2 in this section. The proof is based on the following lemma, which we will prove shortly.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nLemma 3.1. There exists x, y\n**BLOCK**fs== 10.0**p== 9.0**b== 0.5**t== 0.5**l== 0.4**r== 0.3**\nn such that for any k-mer w, it holds that\n**BLOCK**fs== 7.0**p== 9.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\ncn1/5√log n.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.4**\nProof of Theorem 2 using Lemma 3.1. We can extract Kw,x[ℓ]\n§4, Theorem 2.1])\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.5**l== 0.6**r== 0.1**\nKw,y[ℓ] by the contour integral (cf. [Lan13,\n**BLOCK**fs== 10.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nTherefore\n**BLOCK**fs== 7.0**p== 9.0**b== 0.3**t== 0.6**l== 0.7**r== 0.2**\ncn1/5√log n.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\n=1\nZ|\n|\nWe stress that the bound holds for any ℓ\nn\nKw,x[ℓ] = 0. It follows that\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.4**\nk + 1 diﬀerent k-mers w for which Kw,x[ℓ] > 0. Namely, if w /\n**BLOCK**fs== 10.0**p== 9.0**b== 0.3**t== 0.7**l== 0.4**r== 0.1**\n\n\n[n] and k-mer w. Note that for any ﬁxed ℓ, there are at most\nx[j : j + k\nthen\n**BLOCK**fs== 7.0**p== 9.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\ncn1/5 log2/5 n\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nNext, we prove Lemma 3.1 assuming the following result, which is our main technical lemma.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nLemma 3.2. Fix any k\nL1/3\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\n1, such that for any k-mer w, it holds that\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\nL1/3. There exist distinct x, y\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.6**r== 0.1**\nL both starting with a run of 0s of length\n}\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.9**l== 0.4**r== 0.5**\nPw,x(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nProof of Lemma 3.1 using Lemma 3.2. Let β\nWe have k\n≤\ndistinct x′, y′\nthat\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.4**r== 0.1**\n3/5 be a parameter to be decided later. Denote L := nβ.\nL1/3, so that the premise of Lemma 3.2 is satisﬁed. Therefore, there exist\n1, such that for any k-mer w, it holds\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.4**\nL both starting with a run of 0s of length L1/3\n}\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.2**l== 0.3**r== 0.5**\nPw,x′(eiθ)\n\n\n\nLy′. Since k\n≤\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.2**l== 0.4**r== 0.3**\nPw,y′(eiθ)\n\n\n\nL1/3, by construction we have x[j : j + k\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nL. Therefore, any k-mer w we have\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nLx′ and y = 0n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nLet x = 0n\nfor all 0\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.3**l== 0.2**r== 0.8**\nPw,x(eiθ)\nk\nn\n**BLOCK**fs== 7.0**p== 10.0**b== 0.7**t== 0.3**l== 0.3**r== 0.7**\nPw,y(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.5**l== 0.8**r== 0.2**\nPw,y′(eiθ)\n\n\n\nPw,x′(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.7**r== 0.3**\nPw,x′(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n(p + qeiθ)j\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n(p + qeiθ)j\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.6**r== 0.3**\n(p + qeiθ)j\n**BLOCK**fs== 7.0**p== 10.0**b== 0.5**t== 0.4**l== 0.3**r== 0.6**\nj=0 \nX\nPw,x′(eiθ)\n\nθ\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.4**l== 0.4**r== 0.5**\nPw,y′(eiθ)\n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.3**\nis large, we can upper bound the supremum as\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\nPw,x(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.4**t== 0.5**l== 0.3**r== 0.6**\nPw,y(eiθ)\n\n\n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.6**\nHere the ﬁrst inequality is due to\nWhen\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.2**r== 0.5**\n−\nis small, this is taken care of by Eq. (3):\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\n\n\nPw,x(eiθ)\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\n\n\nPw,y(eiθ)\n\n\n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nc1a2 for some constant c1 (depending on p) when\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\nPw,x′(eiθ)\n\n\n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\nPw,y′(eiθ)\n\n\n\n**BLOCK**fs== 7.0**p== 10.0**b== 0.2**t== 0.7**l== 0.6**r== 0.3**\nc3nβ/3 log1/2 n\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nFinally, the value of β is determined by balancing the two cases. Namely, we let 1\nwhich gives the bound 2−\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\ncn1/5√log n for both cases. Here c = min\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nIt remains to prove Lemma 3.2, which we do after some helpful preliminaries from complex analysis.\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.4**\n3.1 Some helpful results in complex analysis\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nIn this section, we introduce some results in complex analysis, which will be useful for proving Lemma 3.2.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nLet Td(x) denote the dth Chebyshev polynomial, i.e., a degree-d polynomial such that Td(cos θ) = cos(dθ).\n1, 1], it has a converging Chebyshev\n**BLOCK**fs== 10.0**p== 11.0**b== 0.8**t== 0.2**l== 0.4**r== 0.4**\n1, 1]. If a function f (z) is analytic on [\n**BLOCK**fs== 10.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nClearly, Td(x)\nexpansion\n**BLOCK**fs== 10.0**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nHere the ad’s are the Chebyshev coeﬃcients, and they can be extracted by the following integral\n**BLOCK**fs== 10.0**p== 11.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\nf (cos θ) cos(dθ) dθ,\n**BLOCK**fs== 10.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwhere π is replaced by 2π for d = 0. This immediately implies a uniform upper bound on Chebyshev\ncoeﬃcients.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nProposition 1. For all d\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nIn fact, if f is analytically continuable to a larger region, much better bounds can be obtained. For that\n\n\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nwe need the notion of Bernstein ellipse.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nDeﬁnition 5 (Bernstein Ellipse). Given ρ\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\n1, the boundary of the Bernstein Ellipse is deﬁned as\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\n: u = ρeiθ, θ\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nThe Bernstein Ellipse Eρ has the foci at\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n1 with the major and minor semi-axes given by (ρ + ρ−\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n1)/2, respectively. When ρ = 1, Eρ coincides with the interval [\nand (ρ\npurpose, we will also be working with aﬃne transformations of Eρ. More precisely, for a\nby\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nEa,ρ (the interior of) the following ellipse\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\n1)/2\n1, 1] on the real line. For our\n[0, 1/8] we denote\n**BLOCK**fs== 10.0**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\n: u = ρeiθ, θ\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nEa,ρ can be equivalently deﬁned as\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nBelow are some useful properties of\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nProposition 2. The following statements hold.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nEa,ρ. Then\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\n| ≤\nEa,ρ contains a disk centered at 1 with radius 2a(ρ\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\ne\nProof. Item (1):\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nWriting z = (1\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\n1)/2 where u = ρeiθ, we have\n**BLOCK**fs== 10.0**p== 11.0**b== 0.2**t== 0.7**l== 0.2**r== 0.6**\n4a + 2aρ cos θ + 2aρ−\n**BLOCK**fs== 10.0**p== 11.0**b== 0.2**t== 0.7**l== 0.5**r== 0.5**\n2aρ sin θ\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.1**l== 0.1**r== 0.8**\nTherefore\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\n−\nItem (2): Let z be such that\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nThis implies z\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nThe following result shows an exponential convergence rate of the Chebyshev expansion.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nTheorem 5 (Theorem 8.1, [Tre12]). Let a function f analytic on [\nopen Bernstein Ellipse Eρ, where it satisﬁes\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n1, 1] be analytically continuable to the\nM for some M . Then its Chebyshev coeﬃcients satisfy\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nProof. The Chebyshev coeﬃcients of f is given by\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nf (cos θ) Tk (cos θ) dθ =\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nf (cos θ) cos (kθ) dθ,\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\nwith π replaced by 2π for k = 0. Letting z = eiθ, one could write cos θ = (z + z−\nhence\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nDenote F (z) := f ((z + z−\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.4**r== 0.3**\n1). Note that we can substitute z−\n**BLOCK**fs== 10.0**p== 12.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\n1 for z and obtain\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nTherefore we arrived at the expression\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nSince f (z) is analytic in the open Bernstein Ellipse Eρ, we can conclude that F (z) is analytic in the annulus\n1, ρ) we have by Cauchy’s integral theorem (cf. [Lan13, §3,\nρ−\n|\nTheorem 5.1]) that\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.6**l== 0.2**r== 0.6**\n< ρ. That means, for any ρ0 ∈\n**BLOCK**fs== 10.0**p== 12.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nNow we have\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nFinally, since the bound holds for any ρ0 < ρ, it also holds for ρ0 = ρ.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nWe will also make use of the following theorem.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nTheorem 6 (Hadamard Three Circles Theorem). Suppose f is analytic inside and on\nFor r\n**BLOCK**fs== 10.0**p== 12.0**b== 0.1**t== 0.8**l== 0.2**r== 0.6**\n[r1, r2], let M (r) := sup\n|\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nsup\ne\nEa,2\n∂\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\n−\nProof. Let ρ1 = 1, ρ = 2, ρ2 = 22. Let g(z) := f (u) where u = (1\non and inside\nCircles Theorem to g gives\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\n1)/2. Since f is analytic\nEa,ρ2 , g is analytic inside the centered disk with radius ρ2. Applying the Hadamard Three\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\nsup\ne\nEa,ρ\n∂\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nsup\ne\nEa,ρ1\n∂\n\n\n\nEa,ρ1 coincides with the interval [1\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\nsup\ne\nEa,ρ2 \n∂\n\n8a, 1] on the real line. For z\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.3**l== 0.4**r== 0.4**\n−\nexp(5an). Therefore\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nsup\ne\nEa,2\n∂\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.3**l== 0.1**r== 0.8**\nWe note that\nimplies\nf (z)\n**BLOCK**fs== 10.0**p== 13.0**b== 0.7**t== 0.3**l== 0.8**r== 0.1**\nEa,ρ2 , Proposition 2\n**BLOCK**fs== 12.0**p== 13.0**b== 0.5**t== 0.4**l== 0.1**r== 0.4**\n3.2 Proof of Lemma 3.2: A Counting Argument\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nWe prove Lemma 3.2 in this section.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nWe ﬁrst prove a technical lemma lower bounding the number of binary strings in which all 1s are far\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\naway from each other.\nLemma 3.3. Let Sn,r ⊆ {\nseparated by at least r many 0’s. Then\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.5**l== 0.4**r== 0.1**\nn be the collection of all n-bit strings with the property that any two 1’s are\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nProof. For ease of notation we ﬁx r and denote f (n) :=\nrecurrence relation\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\n. We observe that f satisﬁes the following\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.6**r== 0.4**\nfor 0\nfor n\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\n≤\n≥\n1. The base case is trivial since (√r + 1)n/r\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\n1. This gives, for k = n, the following bound\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.6**l== 0.1**r== 0.6**\nWe prove by induction that f (n)\nn\n**BLOCK**fs== 10.0**p== 13.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nr.\nNow suppose f (k)\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.6**\nSince by the AM-GM inequality we have\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nor equivalently 1 + 1/√r + 1\n**BLOCK**fs== 10.0**p== 13.0**b== 0.2**t== 0.8**l== 0.4**r== 0.5**\n(√r + 1)1/r, we obtain\n|\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nIn the following, we ﬁx k := L1/3, and let S := 0k\n\n(k\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nthe set S. We have\n**BLOCK**fs== 7.0**p== 14.0**b== 0.8**t== 0.1**l== 0.5**r== 0.4**\nSL\n−\n2(L2/3 log2 L)/6.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nBelow we characterize some properties of k-mer generating polynomials of strings in S.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.1**l== 0.6**r== 0.1**\n1. The proof will focus on binary strings in\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nLemma 3.4. Let S be a set of strings deﬁned as above. For j = 1, 2, . . . , k, denote by ej the string with a\nsingle “1” located at index j\n**BLOCK**fs== 10.0**p== 14.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\n1 (indices begin with 0). The following properties hold.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.2**l== 0.1**r== 0.7**\n1. For any k-mer w /\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.2**l== 0.4**r== 0.3**\n, Pw,x(z) is the zero polynomial.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\n2. For any x\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n∈\n3. For any x, y\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nj < k, Pej ,x(z) = (p + (1\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nProof. Item 1: By deﬁnition of S, x[j : j + k\nif w contains at least two “1”s, then for any 0\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\n1] contains at most one “1” for any string x\nℓ < L\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.3**l== 0.8**r== 0.1**\nS. Therefore,\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nThis means all the coeﬃcients of Pw,x(z) is zero, and hence Pw,x(z) is the zero polynomial.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nItem 2: Since any two consecutive “1”s in x\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nS are separated by at least k\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.4**l== 0.3**r== 0.5**\n2] = ej+1. We thus have\n**BLOCK**fs== 10.0**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nItem 3: We observe that x[i : i + k\n**BLOCK**fs== 10.0**p== 14.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nx[0 : k\n1] = ej\n−\n0k, e1, . . . , ek }\n**BLOCK**fs== 10.0**p== 14.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\n−\n. That implies\n\n\n**BLOCK**fs== 7.0**p== 15.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nj=1\nX\n\n\nPek ,x(z)\nk\n\n**BLOCK**fs== 10.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nThe second last line is obtained by inductively applying Item 2.\n**BLOCK**fs== 10.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nBelow we give the proof of Lemma 3.2. We use the notations exp(x) := ex, and exp2(x) := 2x.\n**BLOCK**fs== 10.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nProof of Lemma 3.2. Let x\n∈\nﬁxed k-mer w = ek, where k\n≤\n**BLOCK**fs== 10.0**p== 15.0**b== 0.6**t== 0.4**l== 0.3**r== 0.1**\nS be a string of length L. In light of Lemma 3.4, we only need to consider a\nL1/3. Deﬁne\n**BLOCK**fs== 10.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.7**\nRecall that gx(p + qz) =\ncoeﬃcients of\n**BLOCK**fs== 7.0**p== 15.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nL\nj=0 Kek,x[j]\n−\n**BLOCK**fs== 10.0**p== 15.0**b== 0.5**t== 0.5**l== 0.4**r== 0.3**\nzj = Pek,x(z). Denote by a0(x), . . . , aL\n**BLOCK**fs== 10.0**p== 15.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nk(x) the Chebyshev\n**BLOCK**fs== 10.0**p== 15.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\nwhere a := L−\ncan write\n**BLOCK**fs== 10.0**p== 15.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\n2/3 log1/4 L (equivalently, the coordinates of fx in the Chebyshev basis). In other words, we\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nWe ﬁrst argue that only the ﬁrst few coeﬃcients are signiﬁcant. This can be done by applying Theorem 5 to\nfx(z), say, with ρ = 2. To that end, we ﬁrst upper bound\nz,\nwe have that z′\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.6**l== 0.7**r== 0.1**\n4a + 4a\n1 + a. It follows that\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.7**l== 0.4**r== 0.3**\nE2. By item (1) of Proposition 2, we have\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.6**l== 0.7**r== 0.2**\nE2. Denoting z′ = 1\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nEa,2 when z\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nsup\ne\nE2\nz\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\n= sup\ne\nz′\nEa,2\n**BLOCK**fs== 10.0**p== 15.0**b== 0.3**t== 0.7**l== 0.6**r== 0.2**\n\nL exp(aL) = L exp(L1/3 log1/4 L).\n\n**BLOCK**fs== 10.0**p== 15.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nTherefore, we can apply Theorem 5 to fx(z) with ρ = 2,M = L exp(L1/3 log1/4 L) and get (for large enough\nL)\n**BLOCK**fs== 10.0**p== 15.0**b== 0.2**t== 0.8**l== 0.4**r== 0.4**\nL exp(L1/3 log1/4 L)\n**BLOCK**fs== 10.0**p== 15.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\n≤\n\nL we associate a vector\n\n**BLOCK**fs== 10.0**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nTo each string x\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.1**l== 0.1**r== 0.4**\nProposition 1 implies each entry of φ(x) belongs to the interval [\nWe now partition [\nm = 4L\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\n2L1/3√log L/8. The vector φ(x) must fall into one of the sub-cubes of the form\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.2**l== 0.3**r== 0.3**\n2L, 2L] into m smaller intervals I1, . . . , Im, each of length 2−\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.1**l== 0.7**r== 0.1**\n2L, 2L].\n⊆\nL1/3√log L/8, meaning that\n**BLOCK**fs== 7.0**p== 16.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nj<L1/3√log L\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.2**l== 0.1**r== 0.7**\nwhere r : [L1/3√log L]\nnumber of such sub-cubes is\n**BLOCK**fs== 10.0**p== 16.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\n[m] is a mapping that uniquely identiﬁes the sub-cube. It follows that the total\n**BLOCK**fs== 7.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nmL1/3√log L =\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\n+ O(L1/3 log3/2 L)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nfor large enough L. By the Pigeonhole Principle, there must be two distinct strings x, y\nφ(x), φ(y) fall into the same sub-cube. In other words, we have\n**BLOCK**fs== 10.0**p== 16.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\nS such that\n**BLOCK**fs== 10.0**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nIt follows that\n**BLOCK**fs== 7.0**p== 16.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\nj=0\nX\nL1/3√log L/7.\n**BLOCK**fs== 7.0**p== 16.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\nXj=L1/3√log L\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\nApplying Corollary 3.1 to gx\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\ngy with a = L−\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\n2/3 log1/4 L gives (for large enough L)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nsup\ne\nEa,2\n∂\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.7**l== 0.1**r== 0.4**\nLet Γ be the sub-arc of the circle\nProposition 2 implies that the length of Γ is at least a = L−\nPrinciple implies\n**BLOCK**fs== 10.0**p== 16.0**b== 0.3**t== 0.7**l== 0.5**r== 0.2**\nwhich lies completely inside the ellipse\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\nEa,2. Item (2) of\n2/3 log1/4 L. Therefore the Maximum Modulus\n**BLOCK**fs== 7.0**p== 16.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nPek,x(eiθ)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nPek,y(eiθ)\n\n\n\n\n\n\nNow we have established the lemma for a ﬁxed k-mer w = ek. Since x, y\nother k-mer w\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nsup\ne\nEa,2\n**BLOCK**fs== 10.0**p== 16.0**b== 0.1**t== 0.8**l== 0.3**r== 0.3**\nk either both Pw,x(z) and Pw,y(z) are zero polynomials or w\n}\nPw,x(eiθ)\n\n\n\n**BLOCK**fs== 10.0**p== 16.0**b== 0.1**t== 0.9**l== 0.5**r== 0.4**\nPek,x(eiθ)\n**BLOCK**fs== 10.0**p== 16.0**b== 0.2**t== 0.8**l== 0.7**r== 0.1**\nS, Lemma 3.4 says that for any\nand\n**BLOCK**fs== 10.0**p== 17.0**b== 0.8**t== 0.1**l== 0.1**r== 0.3**\nFinally, we note that both x and y start with a run of 0’s of length k = L1/3.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nΩ(L1/3) is possible based on the complex\nRemark 4. A much simpler proof for the slightly weaker bound 2−\nanalytical result of Borwein and Erdelyi [BE97, Theorem 3.3] (see also [DOS19, NP17]): there exist strings\nx, y\n**BLOCK**fs== 10.0**p== 17.0**b== 0.8**t== 0.2**l== 0.3**r== 0.7**\nsuch that\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\n\n\nx\nj=0 xj zj, Γa stands for the sub-arc\n|\n|−\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nwhere Px(z) :=\nPx′ (z) where x′\nP\n∈ {\nis deﬁned similarly). Clearly, x′, y′\nTherefore, they enjoy the properties in Lemma 3.4, and Lemma 3.1 follows with a weaker bound.1\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.3**r== 0.4**\nL is the string obtained by inserting L1/3\n}\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.4**r== 0.2**\nS since any two 1’s are separated by at least L1/3\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.6**r== 0.1**\n\n\n\n. Now we observe that Px(zL1/3\n) =\n}\n1 many 0’s before every bit of x (y′\n1 many 0’s.\n**BLOCK**fs== 14.3**p== 17.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n4 Optimality of the Maximum Likelihood Estimation\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nProof of Theorem 3. For 1\nx\n∈\nBy deﬁnition of the total variation distance, we have\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nm deﬁne Si :=\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.5**r== 0.3**\nΩ : D0(x) > Di(x)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n, and let S := S1 ∩\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\ndTV (D0, Di) = D0(Si)\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nThe Union Bound thus implies D0(S)\n) = 0. Therefore\nMLE(x;\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\nmε. Moreover, by Deﬁnition 3, when x\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nS it must hold that\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nProof of Corollary 1.1. The Chernoﬀ bound implies that if we repeat the purported reconstruction algorithm\n8 ln(1/ε)n times and output the majority, it succeeds with probability at least 1\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n−\nLet A be such a (deterministic) reconstruction algorithm with T ′ = 8 ln(1/ε)\nnT traces described as\n·\nε/2n+1. Formally, for any\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nabove, which successfully outputs the source string x with probability at least 1\nsource string x\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nn, it holds that\n**BLOCK**fs== 7.0**p== 17.0**b== 0.3**t== 0.6**l== 0.3**r== 0.6**\nPr\nex1,...,exT\n′\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nbe exactly the collection of T ′-tuples of strings on which A outputs x. We thus have\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nwhere D⊗\nx\nthe other hand, for distinct strings x and y we have Rx ∩\nand y on the same input), and hence the bound\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\ndenotes the T ′-fold product of Dx with itself, capturing the distribution of (\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.7**l== 0.6**r== 0.1**\nxT ′ ). On\nRy = ∅ (by deﬁnition, A cannot output both x\n**BLOCK**fs== 10.0**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nThis implies\n**BLOCK**fs== 8.0**p== 17.0**b== 0.1**t== 0.9**l== 0.1**r== 0.4**\n1We thank an anonymous reviewer for pointing this observation out to us.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.8**t== 0.1**l== 0.1**r== 0.3**\nWe stress that the above bound holds for any pair of distinct strings x, y\nto\n**BLOCK**fs== 7.0**p== 18.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nPr\nex1,...,exT\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.2**l== 0.1**r== 0.4**\nProof of Theorem 4. The distributions are deﬁned as follows. Let t =\nΩ = Ω1 ∪\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\n. The domain\nis the collection of all subsets of [n] of size exactly t, and Ω2 = [n]. We have\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nΩ2 where Ω1 =\n**BLOCK**fs== 10.0**p== 18.0**b== 0.7**t== 0.2**l== 0.7**r== 0.2**\n, and so m =\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nWe ﬁrst deﬁne D0 to be the uniform distribution over Ω2, i.e., D0(s) = 1/n for any s\nFor each one of the remaining m distributions, we identify it with a t-subset S\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\ndeﬁnition of DS is as follows.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nΩ1, and s = S\nΩ2, and s\nS\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nif s\n∈\nif s\n∈\notherwise\n**BLOCK**fs== 10.0**p== 18.0**b== 0.6**t== 0.3**l== 0.8**r== 0.1**\n. The precise\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\nIn other words, s\nsupported on\nS\n{\nover S. Now we verify that\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nΩ1 occurs with probability 2/3, conditioned on which DS is the point distribution\nΩ2 occurs with probability 1/3, conditioned on which DS is the uniform distribution\nsatisﬁes the two conditions.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.1**r== 0.4**\n{\nFor Condition 1, consider a distinguisher A which on sample s\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nΩ, outputs S if s = S\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.8**r== 0.1**\nΩ1, and outputs\n**BLOCK**fs== 10.0**p== 18.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nΩ2. We have\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nTo see Condition 2, let s1, . . . , sT ∼\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nthe samples are all elements of [n], meaning that there is at least one S\nCalculating the likelihoods gives\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nsamples. Since D0 is supported on Ω2 = [n],\ncontaining all samples.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.3**t== 0.6**l== 0.1**r== 0.3**\n\nTherefore, the output of the Maximum Likelihood Estimation on s1, . . . , sT ∼\n**BLOCK**fs== 10.0**p== 18.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\nD0 will never be 0.\n**BLOCK**fs== 14.3**p== 18.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\n5 Acknowledgements\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\nWe are thankful to several anonymous reviewers for their valuable suggestions and comments.\n**BLOCK**fs== 14.3**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nReferences\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[BCF+19] Frank Ban, Xi Chen, Adam Freilich, Rocco A Servedio, and Sandip Sinha. Beyond trace recon-\nstruction: Population recovery from the deletion channel. In 60th IEEE Annual Symposium on\nFoundations of Computer Science, FOCS 2019, pages 745–768. IEEE, 2019.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.1**\nPeter Borwein and Tamás Erdélyi. Littlewood-type problems on subarcs of the unit circle.\nIndiana University mathematics journal, pages 1323–1346, 1997.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.1**l== 0.2**r== 0.1**\nPeter Borwein, Tamás Erdélyi, and Géza Kós. Littlewood-type problems on [0, 1]. Proceedings\nof the London Mathematical Society, 79(1):22–46, 1999.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n[BKKM04] Tugkan Batu, Sampath Kannan, Sanjeev Khanna, and Andrew McGregor. Reconstructing\nstrings from random traces. In J. Ian Munro, editor, Proceedings of the Fifteenth Annual ACM-\nSIAM Symposium on Discrete Algorithms, SODA 2004, New Orleans, Louisiana, USA, January\n11-14, 2004, pages 910–918. SIAM, 2004.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.7**t== 0.3**l== 0.2**r== 0.1**\nJoshua Brakensiek, Ray Li, and Bruce Spang. Coded trace reconstruction in a constant number\nof traces. In 61st IEEE Annual Symposium on Foundations of Computer Science, FOCS 2020,\npages 482–493. IEEE, 2020.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.6**t== 0.3**l== 0.2**r== 0.1**\nDiptarka Chakraborty, Debarati Das, and Robert Krauthgamer. Approximate trace reconstruc-\ntion via median string (in average-case). In 41st IARCS Annual Conference on Foundations of\nSoftware Technology and Theoretical Computer Science, FSTTCS 2021, volume 213 of LIPIcs,\npages 11:1–11:23, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n[CDL+21a] Xi Chen, Anindya De, Chin Ho Lee, Rocco A Servedio, and Sandip Sinha. Near-optimal average-\ncase approximate trace reconstruction from few traces. arXiv preprint arXiv:2107.11530, 2021.\n(To appear in SODA 2022).\n**BLOCK**fs== 10.0**p== 19.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n[CDL+21b] Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, and Sandip Sinha. Polynomial-time\ntrace reconstruction in the smoothed complexity model. In Proceedings of the 2021 ACM-SIAM\nSymposium on Discrete Algorithms, SODA 2021, pages 54–73. SIAM, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[CDRV21] Mahdi Cheraghchi, Joseph Downs, João L. Ribeiro, and Alexandra Veliche. Mean-based trace\nreconstruction over practically any replication-insertion channel. In IEEE International Sympo-\nsium on Information Theory, ISIT 2021, pages 2459–2464. IEEE, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[CGMR20] Mahdi Cheraghchi, Ryan Gabrys, Olgica Milenkovic, and João Ribeiro. Coded trace reconstruc-\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\ntion. IEEE Transactions on Information Theory, 66(10):6084–6103, 2020.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nIn Annales de l’Institut Henri\nZachary Chase. New lower bounds for trace reconstruction.\nPoincaré, Probabilités et Statistiques, volume 57, pages 627–643. Institut Henri Poincaré, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.1**\nZachary Chase. Separating words and trace reconstruction. In Proceedings of the 53rd Annual\nACM SIGACT Symposium on Theory of Computing, STOC 2021, pages 21–31. ACM, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.3**t== 0.6**l== 0.2**r== 0.1**\nZachary Chase and Yuval Peres. Approximate trace reconstruction of random strings from a\nconstant number of traces. arXiv preprint arXiv:2107.06454, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nAnindya De, Ryan O’Donnell, and Rocco A Servedio. Optimal mean-based algorithms for trace\nreconstruction. The Annals of Applied Probability, 29(2):851–874, 2019.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n[DRSR21] Sami Davies, Miklós Z Rácz, Benjamin G Schiﬀer, and Cyrus Rashtchian. Approximate trace\nreconstruction: Algorithms. In IEEE International Symposium on Information Theory, ISIT\n2021, pages 2525–2530. IEEE, 2021.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nMiroslav Dudık and Leonard J Schulman. Reconstruction from subsequences. Journal of Com-\nbinatorial Theory, Series A, 103(2):337–348, 2003.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.2**t== 0.8**l== 0.2**r== 0.1**\nRyan Gabrys and Olgica Milenkovic. The hybrid k-deck problem: Reconstructing sequences\nfrom short and long traces. In IEEE International Symposium on Information Theory, ISIT\n2017, pages 1306–1310. IEEE, 2017.\n**BLOCK**fs== 10.0**p== 19.0**b== 0.1**t== 0.9**l== 0.2**r== 0.1**\nRyan Gabrys and Olgica Milenkovic. Unique reconstruction of coded strings from multiset\nsubstring spectra. IEEE Transactions on Information Theory, 65(12):7682–7696, 2019.",
         "On k-Mer-Based and Maximum Likelihood Estimation Algorithms for Trace Reconstruction Kuan Cheng ∗ Elena Grigorescu † Xin Li ‡ Madhu Sudan§ Minshen Zhu ¶ The trace reconstruction problem is an infamous question introduced by Batu, Kannan, Khanna and Mc- Gregor [BKKM04] in the context of computational biology. It asks to design algorithms that recover a string n given access to traces ˜x of x, obtained by deleting each bit independently with some given prob- x 0, 1 ∈ { O(n1/5)) ability p traces are suﬃcient for reconstruction [Cha21b] (improving upon the exp(O(n1/3)) of [NP17, DOS19]) and Ω(n3/2) [HL20, Cha21a] are necessary. [0, 1). The best current upper and lower bounds are exponentially apart, namely exp( The problem has been recently studied in several variants so far [BKKM04, KM05, VS08, HMPW08, MPV14, PZ17, NP17, DOS19, GM17, HPP18, HL20, HHP18, GM19, CGMR20, KMMP21, BLS20, CDL+21b, e Cha21b, CP21, NR21, SB21, GSZ22, Rub23] and it continues to elicit interest due to its deceptively simple formulation, as well as its motivating applications to DNA computing [YGM17]. In this paper, we focus on the worst-case formulation of the problem, which is equivalent from an information-theoretic point of view to the distinguishing variant. In this variant, the goal is to distinguish whether the received traces come from string x 0, 1 n, for some known x n or from y Algorithms based on k-bit statistics A very natural kind of algorithms [HMPW08, NP17, DOS19] [n] (one may assume that traces of smaller operates using the mean of the received traces at each location i length than n are padded with 0’s at the end). Indeed, let x be the distribution of the traces induced by the deletion channel on input x. A mean/1-bit-statistics -based algorithm ﬁrst estimates from the received traces the mean vector E(x) = [0, 1]n, where the j-th coordinate is deﬁned as It then may perform further post-processing without further inspection of the traces. Solving the distinguishing problem then reduces by standard arguments to understanding the ℓ1-norm between the mean traces of x and y, namely the number T of traces satisﬁes [NP17, DOS19] related the ℓ1-norm above with the supremum of a certain real univariate polynomial over the complex plane. Using techniques from complex analysis they proved that mean-based algorithms using exp(O(n1/3)) traces and outputting the string s whose E(s) is closer in ℓ1-distance to the estimate x, y is a successful reconstruction algorithm. Furthermore, any mean-based algorithm needs exp(Ω(n1/3)) traces to succeed with high probability [NP17, DOS19]. A general class of algorithms may operate by using k-bit statistics [Cha21b], for k w 0, 1 ∈ { quantity k, the algorithm estimates from the given traces, for tuples 0 1. Speciﬁcally, for 1, the n After the estimation step, whose accuracy can be argued via standard Chernoﬀ bounds, the algorithm does not need the traces anymore and may perform further post-processing in order to output the correct string. The result of Chase follows from showing that for k = 2n1/5 there is a string w k for which the ℓ1-distance between the corresponding k-bit statistics between x and y is large. Algorithms based on k-mer statistics Another variant proposed by Mazooji and Shomorony [MS22] considers algorithms which operate using estimates of statistics regarding occurrences of contiguous k-bit strings (a.k.a, k-mers) in the initial string x. We denote by 1 the indicator bit of whether w k occurs as a subword in x from position j. In particular, [MS22] made the following deﬁnition which is central to our paper. k, for i = 0, 1, . . . , n } 1 denote The vector Kx := is called the k-mer density map of x. Note that the mean vector E(x) is, up to a factor of 1 for k = 1 and w = 1 we have p, equivalent to the 1-mer density map. Indeed, xi comes from xj As noted in [MS22], the techniques of [CDL+21b] in the smoothed complexity model of trace reconstruc- k, the number of } n i=0 Kw,x[i]. They show that for − k) uniquely determines the source string, with high tion can also be viewed as based on k-mer density maps. Indeed, for a ﬁxed w n  its occurrences as a subword in x is j=0 1 − k = O(log n), the subword vector (indexed by w  probability [CDL+21b, Lemma 1.1]. The main result of [MS22] is that given access to T = ε− an estimation ˆKx of the k-mer density map Kx which is entry-wise ε-accurate, i.e., remark that by replacing ε with ε/(2kn), one gets an estimate which is ε-accurate in ℓ1-norm, while using asymptotically the same number of traces. 2O(k)poly(n) traces of x, one can recover ˆKx ε. We We make the following deﬁnition generalizing mean-based algorithms ([DOS19, NP17]). Deﬁnition 2. (Algorithms based on k-mer statistics) A trace reconstruction algorithm based on k-mer statistics works in two steps as follows: 1. Once the unknown source string x (0, 1]. It then receives an ǫ-accurate estimate (in ℓ1-norm) of the k-mer density map Kx based on the traces. From here on the algorithm has no more access to the traces themselves. We deﬁne the cost of this part to be 2k/ε. n is picked, it chooses an accuracy parameter ε 2. The algorithm may perform further post-processing and ﬁnish by outputting the source string. Since there is an algorithm to ε-estimate the k-mer density map with ε− 2O(k)poly(n) many traces [MS22], it follows that an algorithm deﬁned as in Deﬁnition 2 with cost T can be turned into a trace reconstruction algorithm with poly(T ) samples. We note that the k-mer density map estimators of [MS22] only use k-bit statistics of the traces, in fact statistics about contiguous k bits in the traces, and hence k-mer-based algorithms are a subclass of algorithms based on k-bit statistics. In this work, we ﬁrst observe that the upper bounds of Chase [Cha21b] can be in fact obtained via k-mer- based algorithms (see the formal statement in Theorem 1), and hence by only using statistics of contiguous subwords of the traces. Our main result says that k-mer-based algorithms require exp(Ω(n1/5)√n) many traces (see Theorem 2). In addition, the analysis of this result implies that the proof technique in Chase [Cha21b] cannot lead to a better analysis of the sample complexity (up to log4.5 n factors in the exponent), and hence new techniques are needed to signiﬁcantly improve the current upper bound. The Maximum Likelihood Estimator In model estimation settings, a common tool for picking a “model” that best explains the observed data is the Maximum Likelihood Estimator (MLE). In the set- ting of trace reconstruction, it is natural to ask: What is the most likely trace distribution x (and hence x) to have produced the given sample/trace(s)? We formalize MLE next. Deﬁnition 3 (Maximum Likelihood Estimation). Let { distributions over a common domain Ω. Given a sample x Estimation is (ties are broken arbitrarily) be a ﬁnite set of probability Ω, the output of the Maximum Likelihood ) := arg max [m] For independently and identically distributed samples x1, x2, . . . , xk ∈ hood Estimation is (ties are broken arbitrarily) is Ω the output of the Maximum Likeli- MLE(x1, x2, . . . xk; ) := arg max [m] We present a simple proof that this algorithm (which takes exponential time, as it searches through all n) is in fact optimal in the number of traces used, up to an O(n) factor blowup. We also observe that in the average-case setting, where the source string is a uniformly random string n, MLE is indeed optimal – without the O(n) factor blowup (see Remark 2.) The power of k-mer-based algorithms Our ﬁrst result shows that algorithms based on k-mer statistics can reconstruct a source string using exp( O(n1/5)) many traces. This follows from the following theorem. Theorem 1 (Implied by [Cha21b]). Let x, y their k-mer density maps, respectively. Assuming k = 2n1/5, it holds that n be two arbitrary distinct strings, and let Kx, Ky be } O(n1/5 log5 n) Based on Theorem 1, the algorithm estimates ˆK within an accuracy of ε = exp( O(n1/5 log5 n)) and outputs the x that minimizes . The cost of this k-mer-based algorithm is exp(O(n1/5 log5 n)). Our main result regarding k-mer-based algorithms is the following theorem which shows the tightness of the bound in Theorem 1. Theorem 2. Fix any k strings x, y ≤ n such that n1/5. Suppose Kx stands for the k-mer density map of x. There exist distinct Hence, Theorem 2 implies that the cost of any k-mer-based algorithm for worst-case trace reconstruction is exp(Ω(n1/5√log n)). Remark 1. As one might expect, for k′ < k the k′-mers usually contain less information than k-mers. To see this, observe that for a (k 1)-mer w, we have the following relation − provided that j > 0. The same also holds for y. In fact, the strings x and y obtained via Theorem 2 share a common preﬁx of length at least k (or one could prepend a preﬁx anyway), so x[0 : k′ 1] for any k′ < k, and one does not need to worry about the case j = 0. Plugging into the deﬁnition of k-mer density maps, we have By induction, for any k′ < k we have Therefore, the bound in Theorem 2 indeed covers all k′-mers for k′ We remark that the proof of Theorem 2 further implies that the analysis technique of [Cha21b] is essen- tially tight, in the sense that no better upper bound (up to log4.5 n factors in the exponent) can be obtained via his analysis. We include further details about this implication in Remark 3. Maximum Likelihood Estimator: an optimal algorithm We next turn to analyzing the performance of the MLE algorithm in the setting of trace reconstruction. Our main result essentially shows that if there is an algorithm for trace reconstruction that uses T traces and succeeds with probability 3/4 then the MLE algorithm using O(nT ) traces succeeds with probability 3/4. Hence, given that the current upper bounds for the worst-case reconstruction problem are exponential in n, we may view the MLE as an optimal algorithm for trace reconstruction. Theorem 3. Suppose we have is such that dTV (D0, Di) ε for any 1 We remark that the loss of a factor of m in Theorem 3 is generally inevitable. Here is a simple example: let D0 be the uniform distribution over [m], and for i = 1, 2, . . . , m, let Di be the point distribution supported on = 0. 1/m))/2 = 1 n, let Dx denote the trace distribution of x. Theorem 3 implies the following } corollary, which implies that in some sense the Maximum Likelihood Estimation is a universal algorithm for trace reconstruction. . We have dTV (D0, Di) = ((m } For a string x Corollary 1.1. Suppose T traces are suﬃcient for worst-case trace reconstruction with a success rate 3/4. nT traces solves worst-case trace Then for any ε > 0, Maximum Likelihood Estimation with 8 ln(1/ε) reconstruction with success rate 1 Corollary 1.1 incurs a factor of O(n) to the sample complexity. While we currently do not know whether this blowup is necessary for trace reconstruction, the next result shows that it is inevitable for the more general “model estimation” problem. Theorem 4. For any integer n common domain Ω of size n n/4 ⌋  1. There is a distinguisher A which given one sample x ∼ = m + n, where m = j with probability at least 2/3. In other words, for all j = 0, 1, . . . , m, 1, there is a set of distributions = 2Θ(n), satisfying the following conditions. Aj for an unknown j , recovers } 2. MLE fails to distinguish D0 from other distributions with probability 1, even with T = n/4 samples. In other words, Remark 2. Finally, we remark that in the average-case setting MLE is indeed optimal (with no factor of O(n) factor blowup in the number of traces). This is because maximizing the likelihood is equivalent to maximizing the posterior probability under the uniform prior distribution (which is optimal), as can be seen via the Bayes rule Therefore maximizing both sides with respect to x yields the same result. 1.2 Overview of the techniques Lower bounds for k-mer-based algorithms In recent development of the trace reconstruction problem, the connection to various real and complex polynomials has been a recurring and intriguing theme [HMPW08, NP17, PZ17, HPP18, DOS19, CDL+21b, CDRV21, Cha21b, SB21, GSZ22, Rub23]. The starting point of these techniques is to design a set of statistics that can be easily estimated from the traces (e.g., mean traces), with the property that for diﬀerent source strings the corresponding statistics are somewhat “far apart”. To establish this property, one key idea is to associate each source string x with a generating polynomial Px where the coeﬃcients are exactly the statistics of x. Due to the structure of the deletion channel, in many cases, this generating polynomial (under a change of variables) is identical to another polynomial Qx that is much easier to get a handle on. For example, the coeﬃcients of Qx are usually 0/1, and they are easily determined from x. To show that the statistics corresponding to x and y are far apart (say, in ℓ1-distance), it is large for an appropriate choice of w. This is the point where all is suﬃcient to show that sorts of analytical tools are ready to shine. For instance, the main technical result in [Cha21b] is a complex analytical result that says that a certain family of polynomials cannot be uniformly small over a sub-arc of the complex unit circle, which has applications beyond the trace reconstruction problem. This analytical view of trace reconstruction can lead to a tight analysis of certain algorithms/statistics. The best example would be mean-based algorithms, for which a tight bound of exp(Θ(n1/3)) traces is known to be suﬃcient and necessary for worst-case trace reconstruction [NP17, DOS19]. The tightness of the sample complexity is exactly due to the tightness of a complex analytical result by Borwein and Erdélyi [BE97]. Our lower bound for k-mer-based algorithms is obtained in a similar fashion, via establishing a complex analytical result complementary to that of [Cha21b] (See Lemma 3.1). On the other hand, our argument takes a diﬀerent approach than that of [BE97]. At a high level, both results use a Pigeonhole argument to show the existence of two univariate polynomials which are uniformly close over a sub-arc Γ of the complex unit circle. The diﬀerence lies in the objects playing the role of “pigeons”. [BE97]’s argument can be viewed as two steps: (1) apply the Pigeonhole Principle to obtain two polynomials that have close evaluations over a discrete set of points in Γ, and (2) use a continuity argument to extend the closeness to the entire sub-arc. Here the roles of pigeons and holes are played by evaluation vectors, and Cartesian products of small intervals. Our approach considers the coordinates of a related polynomial in the Chebyshev basis, which play the roles of pigeons in place of the evaluation vector. The properties of Chebyshev polynomials allow us to get rid of the continuity argument. Instead, we complete the proof by leveraging rather standard tools from complex analysis (e.g., Theorem 5 and Theorem 6). We believe this approach has the advantage of being generalizable to multivariate polynomials over the product Γm via multivariate Chebyshev series (see, e.g., [Mas80, Tre17]), whereas the same of sub-arcs Γ = Γ1 × · · · × generalization seems to be tricky for the continuity argument. Finally, the counting argument considers a special set of strings for which eﬀectively only one k-mer contains meaningful information about the initial string. Since previous arguments did not exploit structural properties of the strings, this is another technical novelty of our proof. Maximum Likelihood Estimation Most of our results regarding Maximum Likelihood Estimation hold under the more general “model estimation” setting, where one is given a sample x drawn from an unknown and tries to recover D. Our main observation is that if such a distinguisher works in worst- distribution D have large pairwise statistical distances. The maximization characterization case, then the distributions in D its likelihood is of statistical distance, in conjunction with a union bound, implies that for a sample x maximized by D except with a small probability. The O(n) factor loss in the sample complexity is essentially due to the union bound, and we show that this loss is tight in general by constructing a set of distributions which attains equality in the union bound. 1.3 Related work The trace reconstruction problem was ﬁrst introduced and studied by Levenshtein [Lev01b][Lev01a]. The original question is that if a message is sent multiple times through the same channel with random inser- tion/deletion errors, then how to recover the message? [BKKM04] and [HMPW08] formalized the problem to the current version for which the channel only has random deletions. Their central motivation is actually from computational biology, i.e. how to reconstruct the whole DNA sequence from multiple related subse- quences. [CGMR20] and [BLS20] further extended the study to the “coded” version. That is, the string to reconstruct is not an arbitrary string but instead is a codeword from a code. A variant setting where the channel has memoryless replication insertions was studied by [CDRV21]. The average case version was studied in [HMPW08, PZ17, MPV14, HPP18]. For this case, the best Ω(log5/2 n) [HL20, Cha21a]. Building on Chase’s upper O(log1/5 n)) in the known lower bound on the number of traces is bound for the worst case, [Rub23] improved the sample complexity upper bound to exp( average-case model. [CDL+21b] studied another variant of the problem which is called the smooth variant. It is an inter- mediate model between the worst-case and the average-case models, where the initial string is an arbitrary string perturbed by replacing each coordinate by a uniformly random bit with some constant probability in [0, 1]. [CDL+21b] provided an eﬃcient reconstruction algorithm for this case. Other variants studied include trace reconstruction from the multiset of substrings [GM17, GM19], population recovery variants [BCF+19], matrix reconstruction and parameterized algorithms [KMMP21], circular trace reconstruction [NR21], re- construction from k-decks [KR97, Sco97, DS03, MPV14], and coded trace reconstruction[CGMR20, BLS20]. [DRSR21] studied approximate trace reconstruction and showed eﬃcient algorithms. [CDL+21a], [CDK21], and [CP21] further proved that if the source is a random string, then an approximate solution can be found with high probability using very few traces. Notice that approximate reconstructions imply distinguishers for pairs of strings with large edit distances. [MPV14, SB21, GSZ22] study the complexity of the problem [GSZ22] also shows that the problem parameterized by the Hamming/edit distance between the strings. of exhibiting explicit strings that are hard to distinguish for mean-based algorithms is equivalent to the Prouhet-Tarry-Escott problem, a diﬃcult problem in number theory. In Section 2 we prove Theorem 1, in Section 3 we prove our main result Theorem 2, and in Section 4 we prove Theorem 3. 2 k-mer-based algorithms: the upper bound We prove Theorem 1 in this section. Let us start with a deﬁnition that is essential for the study of k-mer-based algorithms. Deﬁnition 4 (k-mer generating polynomial). Let x k. The k-mer generating polynomial Pw,x for string x and k-mer w is the following degree-(n 1) polynomial in z: We have the following identity The expression on the last line, under a change of variable z0 = p + (1 studied in [Cha21b]. p)z, is exactly the polynomial Lemma 2.1. [Cha21b, Proposition 6.3] For distinct x, y then there are w n, if xi = yi for all 0 ∈ { } such that Here C > 0 is a constant depending only on the deletion probability p. Cn1/5 log5 n We will use Lemma 2.1 to show that the exp( O(n1/5)) upper bound of [Cha21b] can be achieved by k-mer-based algorithms, rather than general algorithms based on k-bit statistics. Our main lower bound on the number of traces implied by Theorem 2 will follow by showing an upper bound on the LHS in the lemma above (see Lemma 3.1). Remark 3. We remark that the result of Chase is obtained by ﬁrst considering a corresponding multivariate channel polynomial that encodes in its coeﬃcients the k-bit statistics of the traces. The upper bound on the number of traces reduces to understanding the supremum of this polynomial over a certain region of k and z0 the complex plane. The crucial element of the proof is the reduction to the existence of w satisfying Lemma 2.1, by appropriately making the remaining variables take value 0. We noticed that the resulting univariate polynomial is essentially the k-mer generating polynomial deﬁned in Deﬁnition 4, with an p)k. Our result in Lemma 3.1 implies that no tighter lower bound (up to polylogarithmic extra factor of (1 factors in the exponent) is possible for this univariate polynomial, showing that the analysis technique used in [Cha21b] cannot give a better upper bound on worst-case trace complexity. 2.1 An upper bound for k-mer based algorithms The proof of Theorem 1 mainly uses Lemma 2.1. We will also make use of the following result. Lemma 2.2. [BEK99, Theorem 5.1] There are absolute constants c1 > 0 and c2 > 0 such that for every analytic function f on the open unit disk that satisﬁes Proof of Theorem 1. The proof deals with two cases. Case 1: xi = yi for all 0 In this case, x and y satisfy the premise of Lemma 2.1. It follows that there exist w z0 = eiθ where 2/5, satisfying the bound Cn1/5 log5 n Here C > 0 is a constant depending only on the deletion probability p. Rewriting in terms of the k-mer generating polynomials, we have It is easy to see that Cn1/5 log5 n = 1. We also have the following upper bounds z0| − | |  p)2 + sin2 θ 2p cos θ + p2 p)2 (1 From here we can apply the triangle inequality and conclude that ·   Xℓ=0     p    2(1 − − C′n1/5 log5 n Cn1/5 log5 n Here C′ = p(1 − Case 2: xi 6 = yi for some 0 In this case, we are going to take w = x[0 : 2n1/5 2/2 + C is a constant depending only on the deletion probability p. 1, i.e., x[0 : 2n1/5 1] and show a much better bound where C′′ > 0 is a constant depending only on p (hence certainly greater than exp( what we did in case 1, applying the triangle inequality to Eq. (2) gives the theorem. To prove Eq. (2), we let O(n1/5))). Similar to so that Q(p + (1 Q(0) = 1. If p p)z) = Pw,x(z) Pw,y(z). Under our choice of w, the constant term of Q equals to 1, i.e., (0, 1/2], the closed disk B(p; 1 contains the point 0. Therefore (1/2, 1). Since Q is a polynomial with coeﬃcients absolutely bounded by 1, we | We are left with the case p can apply Lemma 2.2 with a = 2(1 (0, 1) and obtain for constants c1, c2 > 0. Denoting t = (t0 − p)/(1 t is inside the closed unit disk B(0; 1). Therefore p), we have t a, 1]. In particular, To conclude, we can take C′′ = min 3 A lower bound for k-mer based algorithms: Proof of Theorem 2 We prove Theorem 2 in this section. The proof is based on the following lemma, which we will prove shortly. Lemma 3.1. There exists x, y n such that for any k-mer w, it holds that Proof of Theorem 2 using Lemma 3.1. We can extract Kw,x[ℓ] §4, Theorem 2.1]) Kw,y[ℓ] by the contour integral (cf. [Lan13, =1 Z| | We stress that the bound holds for any ℓ n Kw,x[ℓ] = 0. It follows that k + 1 diﬀerent k-mers w for which Kw,x[ℓ] > 0. Namely, if w / [n] and k-mer w. Note that for any ﬁxed ℓ, there are at most x[j : j + k then Next, we prove Lemma 3.1 assuming the following result, which is our main technical lemma. Lemma 3.2. Fix any k L1/3 1, such that for any k-mer w, it holds that L1/3. There exist distinct x, y L both starting with a run of 0s of length } Proof of Lemma 3.1 using Lemma 3.2. Let β We have k ≤ distinct x′, y′ that 3/5 be a parameter to be decided later. Denote L := nβ. L1/3, so that the premise of Lemma 3.2 is satisﬁed. Therefore, there exist 1, such that for any k-mer w, it holds L both starting with a run of 0s of length L1/3 } Pw,x′(eiθ)    Ly′. Since k ≤ Pw,y′(eiθ)    L1/3, by construction we have x[j : j + k L. Therefore, any k-mer w we have Lx′ and y = 0n Let x = 0n for all 0 (p + qeiθ)j (p + qeiθ)j (p + qeiθ)j is large, we can upper bound the supremum as Here the ﬁrst inequality is due to When − is small, this is taken care of by Eq. (3): c1a2 for some constant c1 (depending on p) when Finally, the value of β is determined by balancing the two cases. Namely, we let 1 which gives the bound 2− cn1/5√log n for both cases. Here c = min It remains to prove Lemma 3.2, which we do after some helpful preliminaries from complex analysis. 3.1 Some helpful results in complex analysis In this section, we introduce some results in complex analysis, which will be useful for proving Lemma 3.2. Let Td(x) denote the dth Chebyshev polynomial, i.e., a degree-d polynomial such that Td(cos θ) = cos(dθ). 1, 1], it has a converging Chebyshev 1, 1]. If a function f (z) is analytic on [ Here the ad’s are the Chebyshev coeﬃcients, and they can be extracted by the following integral f (cos θ) cos(dθ) dθ, where π is replaced by 2π for d = 0. This immediately implies a uniform upper bound on Chebyshev coeﬃcients. Proposition 1. For all d In fact, if f is analytically continuable to a larger region, much better bounds can be obtained. For that we need the notion of Bernstein ellipse. Deﬁnition 5 (Bernstein Ellipse). Given ρ 1, the boundary of the Bernstein Ellipse is deﬁned as : u = ρeiθ, θ The Bernstein Ellipse Eρ has the foci at 1 with the major and minor semi-axes given by (ρ + ρ− 1)/2, respectively. When ρ = 1, Eρ coincides with the interval [ and (ρ purpose, we will also be working with aﬃne transformations of Eρ. More precisely, for a by Ea,ρ (the interior of) the following ellipse 1)/2 1, 1] on the real line. For our [0, 1/8] we denote : u = ρeiθ, θ Ea,ρ can be equivalently deﬁned as Below are some useful properties of Proposition 2. The following statements hold. | ≤ Ea,ρ contains a disk centered at 1 with radius 2a(ρ Writing z = (1 1)/2 where u = ρeiθ, we have 4a + 2aρ cos θ + 2aρ− 2aρ sin θ − Item (2): Let z be such that This implies z The following result shows an exponential convergence rate of the Chebyshev expansion. Theorem 5 (Theorem 8.1, [Tre12]). Let a function f analytic on [ open Bernstein Ellipse Eρ, where it satisﬁes 1, 1] be analytically continuable to the M for some M . Then its Chebyshev coeﬃcients satisfy Proof. The Chebyshev coeﬃcients of f is given by f (cos θ) Tk (cos θ) dθ = f (cos θ) cos (kθ) dθ, with π replaced by 2π for k = 0. Letting z = eiθ, one could write cos θ = (z + z− hence Denote F (z) := f ((z + z− 1). Note that we can substitute z− 1 for z and obtain Therefore we arrived at the expression Since f (z) is analytic in the open Bernstein Ellipse Eρ, we can conclude that F (z) is analytic in the annulus 1, ρ) we have by Cauchy’s integral theorem (cf. [Lan13, §3, ρ− | Theorem 5.1]) that < ρ. That means, for any ρ0 ∈ Now we have Finally, since the bound holds for any ρ0 < ρ, it also holds for ρ0 = ρ. We will also make use of the following theorem. Theorem 6 (Hadamard Three Circles Theorem). Suppose f is analytic inside and on For r [r1, r2], let M (r) := sup | − Proof. Let ρ1 = 1, ρ = 2, ρ2 = 22. Let g(z) := f (u) where u = (1 on and inside Circles Theorem to g gives 1)/2. Since f is analytic Ea,ρ2 , g is analytic inside the centered disk with radius ρ2. Applying the Hadamard Three sup e Ea,ρ1 ∂    Ea,ρ1 coincides with the interval [1 sup e Ea,ρ2  ∂  8a, 1] on the real line. For z We note that implies f (z) Ea,ρ2 , Proposition 2 3.2 Proof of Lemma 3.2: A Counting Argument We prove Lemma 3.2 in this section. We ﬁrst prove a technical lemma lower bounding the number of binary strings in which all 1s are far away from each other. Lemma 3.3. Let Sn,r ⊆ { separated by at least r many 0’s. Then n be the collection of all n-bit strings with the property that any two 1’s are Proof. For ease of notation we ﬁx r and denote f (n) := recurrence relation . We observe that f satisﬁes the following for 0 for n ≤ ≥ 1. The base case is trivial since (√r + 1)n/r 1. This gives, for k = n, the following bound We prove by induction that f (n) n r. Now suppose f (k) Since by the AM-GM inequality we have or equivalently 1 + 1/√r + 1 (√r + 1)1/r, we obtain | In the following, we ﬁx k := L1/3, and let S := 0k  (k the set S. We have Below we characterize some properties of k-mer generating polynomials of strings in S. 1. The proof will focus on binary strings in Lemma 3.4. Let S be a set of strings deﬁned as above. For j = 1, 2, . . . , k, denote by ej the string with a single “1” located at index j 1 (indices begin with 0). The following properties hold. 1. For any k-mer w / , Pw,x(z) is the zero polynomial. 2. For any x ∈ 3. For any x, y j < k, Pej ,x(z) = (p + (1 Proof. Item 1: By deﬁnition of S, x[j : j + k if w contains at least two “1”s, then for any 0 1] contains at most one “1” for any string x ℓ < L This means all the coeﬃcients of Pw,x(z) is zero, and hence Pw,x(z) is the zero polynomial. Item 2: Since any two consecutive “1”s in x S are separated by at least k 2] = ej+1. We thus have Item 3: We observe that x[i : i + k x[0 : k 1] = ej − 0k, e1, . . . , ek } − . That implies The second last line is obtained by inductively applying Item 2. Below we give the proof of Lemma 3.2. We use the notations exp(x) := ex, and exp2(x) := 2x. Proof of Lemma 3.2. Let x ∈ ﬁxed k-mer w = ek, where k ≤ S be a string of length L. In light of Lemma 3.4, we only need to consider a L1/3. Deﬁne Recall that gx(p + qz) = coeﬃcients of zj = Pek,x(z). Denote by a0(x), . . . , aL k(x) the Chebyshev where a := L− can write 2/3 log1/4 L (equivalently, the coordinates of fx in the Chebyshev basis). In other words, we We ﬁrst argue that only the ﬁrst few coeﬃcients are signiﬁcant. This can be done by applying Theorem 5 to fx(z), say, with ρ = 2. To that end, we ﬁrst upper bound z, we have that z′ 4a + 4a 1 + a. It follows that E2. By item (1) of Proposition 2, we have E2. Denoting z′ = 1 Ea,2 when z = sup e z′ Ea,2 L exp(aL) = L exp(L1/3 log1/4 L). Therefore, we can apply Theorem 5 to fx(z) with ρ = 2,M = L exp(L1/3 log1/4 L) and get (for large enough L) ≤  L we associate a vector To each string x Proposition 1 implies each entry of φ(x) belongs to the interval [ We now partition [ m = 4L 2L1/3√log L/8. The vector φ(x) must fall into one of the sub-cubes of the form 2L, 2L] into m smaller intervals I1, . . . , Im, each of length 2− 2L, 2L]. ⊆ L1/3√log L/8, meaning that where r : [L1/3√log L] number of such sub-cubes is [m] is a mapping that uniquely identiﬁes the sub-cube. It follows that the total + O(L1/3 log3/2 L) for large enough L. By the Pigeonhole Principle, there must be two distinct strings x, y φ(x), φ(y) fall into the same sub-cube. In other words, we have S such that It follows that Applying Corollary 3.1 to gx gy with a = L− 2/3 log1/4 L gives (for large enough L) Let Γ be the sub-arc of the circle Proposition 2 implies that the length of Γ is at least a = L− Principle implies which lies completely inside the ellipse Ea,2. Item (2) of 2/3 log1/4 L. Therefore the Maximum Modulus Pek,y(eiθ)       Now we have established the lemma for a ﬁxed k-mer w = ek. Since x, y other k-mer w k either both Pw,x(z) and Pw,y(z) are zero polynomials or w } Pw,x(eiθ) S, Lemma 3.4 says that for any and Finally, we note that both x and y start with a run of 0’s of length k = L1/3. Ω(L1/3) is possible based on the complex Remark 4. A much simpler proof for the slightly weaker bound 2− analytical result of Borwein and Erdelyi [BE97, Theorem 3.3] (see also [DOS19, NP17]): there exist strings x, y such that x j=0 xj zj, Γa stands for the sub-arc | |− where Px(z) := Px′ (z) where x′ P ∈ { is deﬁned similarly). Clearly, x′, y′ Therefore, they enjoy the properties in Lemma 3.4, and Lemma 3.1 follows with a weaker bound.1 L is the string obtained by inserting L1/3 } S since any two 1’s are separated by at least L1/3 . Now we observe that Px(zL1/3 ) = } 1 many 0’s before every bit of x (y′ 1 many 0’s. 4 Optimality of the Maximum Likelihood Estimation Proof of Theorem 3. For 1 x ∈ By deﬁnition of the total variation distance, we have m deﬁne Si := Ω : D0(x) > Di(x) , and let S := S1 ∩ dTV (D0, Di) = D0(Si) The Union Bound thus implies D0(S) ) = 0. Therefore MLE(x; mε. Moreover, by Deﬁnition 3, when x S it must hold that Proof of Corollary 1.1. The Chernoﬀ bound implies that if we repeat the purported reconstruction algorithm 8 ln(1/ε)n times and output the majority, it succeeds with probability at least 1 − Let A be such a (deterministic) reconstruction algorithm with T ′ = 8 ln(1/ε) nT traces described as · ε/2n+1. Formally, for any above, which successfully outputs the source string x with probability at least 1 source string x n, it holds that be exactly the collection of T ′-tuples of strings on which A outputs x. We thus have where D⊗ x the other hand, for distinct strings x and y we have Rx ∩ and y on the same input), and hence the bound denotes the T ′-fold product of Dx with itself, capturing the distribution of ( xT ′ ). On Ry = ∅ (by deﬁnition, A cannot output both x This implies We stress that the above bound holds for any pair of distinct strings x, y to Proof of Theorem 4. The distributions are deﬁned as follows. Let t = Ω = Ω1 ∪ . The domain is the collection of all subsets of [n] of size exactly t, and Ω2 = [n]. We have Ω2 where Ω1 = , and so m = We ﬁrst deﬁne D0 to be the uniform distribution over Ω2, i.e., D0(s) = 1/n for any s For each one of the remaining m distributions, we identify it with a t-subset S deﬁnition of DS is as follows. Ω1, and s = S Ω2, and s S if s ∈ if s ∈ otherwise . The precise In other words, s supported on S { over S. Now we verify that Ω1 occurs with probability 2/3, conditioned on which DS is the point distribution Ω2 occurs with probability 1/3, conditioned on which DS is the uniform distribution satisﬁes the two conditions. { For Condition 1, consider a distinguisher A which on sample s Ω, outputs S if s = S Ω1, and outputs Ω2. We have To see Condition 2, let s1, . . . , sT ∼ the samples are all elements of [n], meaning that there is at least one S Calculating the likelihoods gives samples. Since D0 is supported on Ω2 = [n], containing all samples. Therefore, the output of the Maximum Likelihood Estimation on s1, . . . , sT ∼ D0 will never be 0. We are thankful to several anonymous reviewers for their valuable suggestions and comments. [BCF+19] Frank Ban, Xi Chen, Adam Freilich, Rocco A Servedio, and Sandip Sinha. Beyond trace recon- struction: Population recovery from the deletion channel. In 60th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2019, pages 745–768. IEEE, 2019. Peter Borwein and Tamás Erdélyi. Littlewood-type problems on subarcs of the unit circle. Indiana University mathematics journal, pages 1323–1346, 1997. Peter Borwein, Tamás Erdélyi, and Géza Kós. Littlewood-type problems on [0, 1]. Proceedings of the London Mathematical Society, 79(1):22–46, 1999. [BKKM04] Tugkan Batu, Sampath Kannan, Sanjeev Khanna, and Andrew McGregor. Reconstructing strings from random traces. In J. Ian Munro, editor, Proceedings of the Fifteenth Annual ACM- SIAM Symposium on Discrete Algorithms, SODA 2004, New Orleans, Louisiana, USA, January 11-14, 2004, pages 910–918. SIAM, 2004. Joshua Brakensiek, Ray Li, and Bruce Spang. Coded trace reconstruction in a constant number of traces. In 61st IEEE Annual Symposium on Foundations of Computer Science, FOCS 2020, pages 482–493. IEEE, 2020. Diptarka Chakraborty, Debarati Das, and Robert Krauthgamer. Approximate trace reconstruc- tion via median string (in average-case). In 41st IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science, FSTTCS 2021, volume 213 of LIPIcs, pages 11:1–11:23, 2021. [CDL+21a] Xi Chen, Anindya De, Chin Ho Lee, Rocco A Servedio, and Sandip Sinha. Near-optimal average- case approximate trace reconstruction from few traces. arXiv preprint arXiv:2107.11530, 2021. (To appear in SODA 2022). [CDL+21b] Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, and Sandip Sinha. Polynomial-time trace reconstruction in the smoothed complexity model. In Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms, SODA 2021, pages 54–73. SIAM, 2021. [CDRV21] Mahdi Cheraghchi, Joseph Downs, João L. Ribeiro, and Alexandra Veliche. Mean-based trace reconstruction over practically any replication-insertion channel. In IEEE International Sympo- sium on Information Theory, ISIT 2021, pages 2459–2464. IEEE, 2021. [CGMR20] Mahdi Cheraghchi, Ryan Gabrys, Olgica Milenkovic, and João Ribeiro. Coded trace reconstruc- tion. IEEE Transactions on Information Theory, 66(10):6084–6103, 2020. In Annales de l’Institut Henri Zachary Chase. New lower bounds for trace reconstruction. Poincaré, Probabilités et Statistiques, volume 57, pages 627–643. Institut Henri Poincaré, 2021. Zachary Chase. Separating words and trace reconstruction. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, STOC 2021, pages 21–31. ACM, 2021. Zachary Chase and Yuval Peres. Approximate trace reconstruction of random strings from a constant number of traces. arXiv preprint arXiv:2107.06454, 2021. Anindya De, Ryan O’Donnell, and Rocco A Servedio. Optimal mean-based algorithms for trace reconstruction. The Annals of Applied Probability, 29(2):851–874, 2019. [DRSR21] Sami Davies, Miklós Z Rácz, Benjamin G Schiﬀer, and Cyrus Rashtchian. Approximate trace reconstruction: Algorithms. In IEEE International Symposium on Information Theory, ISIT 2021, pages 2525–2530. IEEE, 2021. Miroslav Dudık and Leonard J Schulman. Reconstruction from subsequences. Journal of Com- binatorial Theory, Series A, 103(2):337–348, 2003. Ryan Gabrys and Olgica Milenkovic. The hybrid k-deck problem: Reconstructing sequences from short and long traces. In IEEE International Symposium on Information Theory, ISIT 2017, pages 1306–1310. IEEE, 2017. Ryan Gabrys and Olgica Milenkovic. Unique reconstruction of coded strings from multiset substring spectra. IEEE Transactions on Information Theory, 65(12):7682–7696, 2019.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2308/2308.14993v2.pdf",
         "extracted",
         "None",
         "",
         "On k-Mer-Based and Maximum Likelihood Estimation Algorithms for Trace Reconstruction"
        ],
        [
         "34",
         "0183a6ebd27de31937b97dbed8d5736d0711d0cf",
         "None",
         "Diaa E. Habibi,Gert Aarts,L. Wang,Kai Zhou",
         "\n**BLOCK**fs== 16.2**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nDiffusion models learn distributions generated by\ncomplex Langevin dynamics\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.3**l== 0.1**r== 0.1**\nDiaa E. Habibi,𝑎,∗ Gert Aarts,𝑎 Lingxiao Wang𝑏 and Kai Zhou𝑐,𝑑\n𝑎Department of Physics, Swansea University, Swansea, SA2 8PP, United Kingdom\n𝑏Interdisciplinary Theoretical and Mathematical Sciences Program (iTHEMS), RIKEN, Wako, Saitama\n351-0198, Japan\n𝑐School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen),\nGuangdong, 518172, China\n𝑑Frankfurt Institute for Advanced Studies, Ruth Moufang Strasse 1, D-60438, Frankfurt am Main, Germany\n**BLOCK**fs== 10.0**p== 0.0**b== 0.5**t== 0.5**l== 0.2**r== 0.4**\nE-mail: n.e.habibi@swansea.ac.uk, g.aarts@swansea.ac.uk,\nlingxiao.wang@riken.jp, zhoukai@cuhk.edu.cn\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nThe probability distribution effectively sampled by a complex Langevin process for theories with\na sign problem is not known a priori and notoriously hard to understand. Diffusion models, a class\nof generative AI, can learn distributions from data. In this contribution, we explore the ability of\ndiffusion models to learn the distributions created by a complex Langevin process.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\nThe 41st International Symposium on Lattice Field Theory (Lattice 2024)\n28 July - 3 August, 2024\nLiverpool, UK\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\n∗Speaker\n**BLOCK**fs== 6.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n© Copyright owned by the author(s) under the terms of the Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0).\n**BLOCK**fs== 12.0**p== 1.0**b== 0.9**t== 0.1**l== 0.2**r== 0.7**\nIntroduction\n**BLOCK**fs== 10.9**p== 1.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nTheories with a complex Boltzmann weight are hard to simulate using conventional numerical\nmethods based on importance sampling, due to the sign and overlap problems [1]. A prime example\nis QCD at nonzero baryon density, in which the quark determinant is complex for real quark\nchemical potential [2, 3],\n**BLOCK**fs== 10.9**p== 1.0**b== 0.7**t== 0.2**l== 0.4**r== 0.4**\n[det 𝑀 (𝜇)]∗ = det 𝑀 (−𝜇∗) ∈ C.\n**BLOCK**fs== 10.9**p== 1.0**b== 0.5**t== 0.3**l== 0.1**r== 0.1**\nComplex Langevin (CL) dynamics, in which the degrees of freedom are analytically extended,\nprovides a potential solution, as it does not rely on importance sampling but explores a complexified\nmanifold via a stochastic process [4, 5]. It is an extension of stochastic quantisation [6, 7], which is\nequivalent to path integral quantisation. CL has been shown to work in lattice field theories in three\n[8] and four [9] Euclidean dimensions with a severe sign problem, including in QCD [10–14], but it\nmay also fail, even in simple models [15–17]. This situation was clarified a few years ago [18–20]\nby the derivation of the formal relation between the complex distribution on the real manifold and\nthe real and positive distribution on the complexified manifold, which is effectively sampled during\nthe CL process, leading to practical criteria for correctness which need to be verified a posteriori.\nNevertheless, issues remain and the reliability of the method depends on a precise understanding\nof the behaviour of the distribution at infinity and near poles in the CL drift. Recent work can be\nfound in e.g. Refs. [21–25].\n**BLOCK**fs== 10.9**p== 1.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nAs should be clear, a crucial role is played by the distribution on the complexified manifold.\nUnfortunately, this distribution turns out to be elusive, as the Fokker-Planck equation (FPE) linked\nto the CL process cannot be solved in general. In fact, even convergence is hard to understand,\nexcept in some simple cases, such as Gaussian models [26] and models in which one can prove the\ndynamics takes place in a strip (see below) [27]. A better characterisation of the distribution would\ntherefore be welcome.\n**BLOCK**fs== 10.9**p== 1.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nDiffusion models [28–34] are a class of generative AI, which learn distributions from data.\nThey are widely popular and used in e.g. DALL-E [35] and Stable Diffusion [36]. The methodology\nof diffusion models relies on a stochastic process, similar to stochastic quantisation, but instead\nof using a known drift term derived from the underlying distribution, it learns the drift from data\npreviously generated or collected. We have recently explored the relation between diffusion models\nand stochastic quantisation in scalar [37, 38] and U(1) gauge theories [39], and studied the evolution\nof higher-order cumulants in detail [40]. Further connections between diffusion models and field\ntheory are pointed out in Refs. [41, 42].\n**BLOCK**fs== 10.9**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nGiven the success of diffusion models to learn distributions and the elusiveness of the distri-\nbution sampled in the CL process, it makes sense to combine these two approaches to deepen our\nunderstanding of the latter. In the next two sections we first remind the reader of CL dynamics for\ntheories with a complex Boltzmann distribution and then briefly introduce diffusions models. In\nSec. 4 we then combine these in two simple cases with a single degree of freedom: the exactly\nsolvable Gaussian case with a complex mass parameter, and the quartic model with a complex mass\nparameter, for which the distribution can be proven to be confined to a strip in the complex plane.\n**BLOCK**fs== 12.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\n2. Complex Langevin dynamics\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.1**l== 0.2**r== 0.3**\nConsider one degree of freedom 𝑥, with a Boltzmann weight 𝜌(𝑥), such that\n∫\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\n𝑑𝑥 𝜌(𝑥)𝑂 (𝑥),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\n𝑍 exp[−𝑆(𝑥)],\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nThe Langevin process and drift read\n**BLOCK**fs== 10.9**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\n𝑥(𝑡) = 𝐾 [𝑥(𝑡)] + 𝜂(𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.7**t== 0.2**l== 0.6**r== 0.3**\n𝑑\n𝑑𝑥 log 𝜌(𝑥) = −\n**BLOCK**fs== 10.9**p== 2.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwhere the dot indicates the Langevin time derivative and the noise satisfies ⟨𝜂(𝑡)𝜂(𝑡′)⟩ = 2𝛿(𝑡 − 𝑡′).\nThe corresponding FPE is\n**BLOCK**fs== 10.9**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\n𝜕𝑡 𝜌(𝑥; 𝑡) = 𝜕𝑥 [𝜕𝑥 − 𝐾 (𝑥)] 𝜌(𝑥; 𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nand for a real Boltzmann weight and drift this process converges to the stationary solution 𝜌(𝑥),\ntypically exponentially fast [7].\n**BLOCK**fs== 10.9**p== 2.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nWhen the weight is complex, one may extend 𝑥 → 𝑧 = 𝑥 + 𝑖𝑦 into the complex plane and write\n**BLOCK**fs== 10.9**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\n𝑧(𝑡) = 𝐾 [𝑧(𝑡)] + 𝜂(𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\n𝑑\n𝑑𝑧 log 𝜌(𝑧) = −\n**BLOCK**fs== 10.9**p== 2.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nHowever, in this case the FPE cannot be used to show convergence as the corresponding Fokker-\nPlanck Hamiltonian is no longer semi-positive definite [7].\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nWe may consider the CL process,\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\n𝑥(𝑡) = 𝐾𝑥 + 𝜂𝑥 (𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\n𝑦(𝑡) = 𝐾𝑦 + 𝜂𝑦 (𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\n𝑑\n𝑑𝑧 log 𝜌(𝑧),\n𝑑\n𝑑𝑧 log 𝜌(𝑧),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\n⟨𝜂𝑥 (𝑡)𝜂𝑥 (𝑡′)⟩ = 2𝑁𝑥𝛿(𝑡 − 𝑡′),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\n⟨𝜂𝑦 (𝑡)𝜂𝑦 (𝑡′)⟩ = 2𝑁𝑦𝛿(𝑡 − 𝑡′),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.4**t== 0.5**l== 0.1**r== 0.3**\nwith noise satisfying 𝑁𝑥 − 𝑁𝑦 = 1. The FPE equation for this process reads\n**BLOCK**fs== 10.9**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.3**\n𝜕𝑡 𝑃(𝑥, 𝑦; 𝑡) = 𝜕𝑥 (𝑁𝑥 𝜕𝑥 − 𝐾𝑥) + 𝜕𝑦 𝑁𝑦𝜕𝑦 − 𝐾𝑦 𝑃(𝑥, 𝑦; 𝑡),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nsuch that\n**BLOCK**fs== 10.9**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\n⟨𝑂 [𝑥(𝑡) + 𝑖𝑦(𝑡)]⟩𝜂 =\n**BLOCK**fs== 10.9**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\n𝑑𝑥𝑑𝑦 𝑃(𝑥, 𝑦; 𝑡)𝑂 (𝑥 + 𝑖𝑦).\n**BLOCK**fs== 10.9**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.4**\nIt is preferable to consider real noise, 𝑁𝑥 = 1, 𝑁𝑦 = 0 [18].\n**BLOCK**fs== 10.9**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.1**\nThe CL process yields the correct answer if a stationary solution to this FPE exists, such that\n**BLOCK**fs== 10.9**p== 2.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\n𝑑𝑥𝑑𝑦 𝑃(𝑥, 𝑦)𝑂 (𝑥 + 𝑖𝑦) =\n**BLOCK**fs== 10.9**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\n𝑑𝑥 𝜌(𝑥)𝑂 (𝑥),\n**BLOCK**fs== 10.9**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nor, shifting the integration variables at a formal level,\n**BLOCK**fs== 10.9**p== 2.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\n𝑑𝑦 𝑃(𝑥 − 𝑖𝑦, 𝑦).\n**BLOCK**fs== 10.9**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nConsiderable effort has been invested in deriving criteria for correctness related to the behaviour\nof 𝑃(𝑥, 𝑦) at infinity and near poles of the drift (if there are any), which can be used a posteriori\nto justify the results [18–25]. A better understanding of 𝑃(𝑥, 𝑦) in the stationary limit would\ntherefore be very welcome. We emphasise that unlike the original weight 𝜌(𝑧), 𝑃(𝑥, 𝑦; 𝑡) is real\nand semi-positive definite, as it represents the real Langevin process in the two-dimensional plane.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\n3. Diffusion models\n**BLOCK**fs== 10.9**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nDiffusion models, as a class of probabilistic generative models, gradually corrupt data with\nincrementally increasing noise and are trained to reverse the process to build a generative model\nof the data [28–32]. We use the description in terms of stochastic differential equations (SDEs)\n[31, 33, 34] and follow the notation of Ref. [40].\n**BLOCK**fs== 10.9**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.1**\nThe diffusion process consists of two parts. The noise-injecting or forward process is described\n**BLOCK**fs== 10.9**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nby the following SDE,\n**BLOCK**fs== 10.9**p== 3.0**b== 0.7**t== 0.3**l== 0.4**r== 0.4**\n𝑥(𝑡) = 𝐾 (𝑥(𝑡), 𝑡) + 𝑔(𝑡)𝜂(𝑡),\n**BLOCK**fs== 10.9**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nwhere 𝐾 (𝑥(𝑡), 𝑡) is a drift term, 𝜂 ∼ N (0, 1) is Gaussian noise and 𝑔(𝑡), the diffusion coefficient,\nis the time-dependent noise strength. The initial conditions for this process are determined by the\ntarget distribution 𝑥(0) = 𝑥0 ∼ 𝑃0(𝑥0) and the process runs between 0 ≤ 𝑡 ≤ 𝑇. Properties of the\ndistribution at the end of this process, 𝑃(𝑥, 𝑇), have been studied in Ref. [40].\n**BLOCK**fs== 10.9**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.1**\nThe second part corresponds to the denoising or backward process. Written in terms of reverse\n**BLOCK**fs== 10.9**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\ntime 𝜏 = 𝑇 − 𝑡, the SDE reads [43]\n**BLOCK**fs== 10.9**p== 3.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\n𝑥′(𝜏) = −𝐾 (𝑥(𝜏), 𝑇 − 𝜏) + 𝑔2(𝑇 − 𝜏)𝜕𝑥 log 𝑃(𝑥, 𝑇 − 𝜏) + 𝑔(𝑇 − 𝜏)𝜂(𝜏),\n**BLOCK**fs== 10.9**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\nwith 0 ≤ 𝜏 ≤ 𝑇.\nInitial conditions are sampled from a normal distribution with a variance\ncomparable to the variance obtained at the end of the forward process. The so-called score,\n𝜕𝑥 log 𝑃(𝑥, 𝑡), is not known a priori and is approximated by a quantity 𝑠 𝜃 (𝑥, 𝑡), which is determined,\nor ‘learnt’, during the forward process via score matching [44]. Given a sample dataset of the target\ndistribution, a score-based model can be trained starting from the Fisher divergence [31],\n**BLOCK**fs== 8.0**p== 3.0**b== 0.4**t== 0.5**l== 0.4**r== 0.5**\n𝑑𝑡 E𝑃 ( 𝑥,𝑡 )\n**BLOCK**fs== 10.9**p== 3.0**b== 0.4**t== 0.5**l== 0.5**r== 0.3**\n𝑠 𝜃 (𝑥, 𝑡) − ∇ log 𝑃(𝑥, 𝑡)\n\n\n**BLOCK**fs== 10.9**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nwhere the weight 𝜆(𝑡) is chosen to be the variance of the noise at time 𝑡.\n**BLOCK**fs== 10.9**p== 3.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nAfter the diffusion model has been trained, new samples from the target distribution can be\ngenerated by numerically solving the backward stochastic process (13), substituting in the trained\nscore model 𝑠∗\n**BLOCK**fs== 10.9**p== 3.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\n𝜃 (𝑥, 𝑡). Using a simple discretisation with stepsize Δ𝜏 one solves, for 0 ≤ 𝜏 ≤ 𝑇,\n**BLOCK**fs== 10.9**p== 3.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\n𝑥 𝜏+Δ𝜏 = 𝑥 𝜏 + −𝐾 (𝑥 𝜏, 𝑇 − 𝜏) + 𝑔2(𝑇 − 𝜏)𝑠∗\n**BLOCK**fs== 10.9**p== 3.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\n𝜃 (𝑥 𝜏, 𝑇 − 𝜏) Δ𝜏 + 𝑔(𝑇 − 𝜏)\n**BLOCK**fs== 10.9**p== 3.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nwhere 𝜂𝜏 ∼ N (0, 1). This is indeed remarkably similar [37] to the formulation of stochastic\nquantisation, in which, however, the drift is time-independent and derived from a known distribution,\nas in Eq. (3), rather than being learnt from data.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n4. Application to complex Langevin dynamics\n**BLOCK**fs== 10.9**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nAs stated above, for complex actions CL dynamics is capable of generating configurations but\nthe corresponding probability distribution 𝑃(𝑥, 𝑦) is typically not available. This makes it hard to\nfully assess the reliability of the approach. A diffusion model, however, can learn (the log-derivative\nof) this distribution, in the form of the score ∇ log 𝑃(𝑥, 𝑦). Notably, for the diffusion model it is\n**BLOCK**fs== 10.9**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\nirrelevant what the origin of the configurations is. The learned score can subsequently be used to\nstudy aspects of convergence of the CL process or to generate additional configurations.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.7**t== 0.1**l== 0.1**r== 0.1**\nTo investigate the viability of this approach, we start with two simple models of one degree\nof freedom, the exactly solvable Gaussian case and a quartic model, both with a complex mass\nparameter.\nIn each case we have generated training data by solving the discretised CL process\nwith stepsize 𝜖 using the higher-order algorithm of Ref. [45], first applied to CL dynamics in\nRef. [8]. This algorithm improves stepsize corrections from O (𝜖) to O (𝜖 3/2). We have generated\nan ensemble of 106 configurations for training, which are preprocessed by scaling it to zero mean\nand unit variance.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nIn the diffusion model, we employ a variance-exploding scheme, in which the drift term in\nEq. (12) is put to zero, 𝐾 (𝑥, 𝑦; 𝑡) = 0. Note that due to the complexification, we have two degrees of\nfreedom to consider. We choose the diffusion coefficient 𝑔(𝑡) = 𝜎𝑡/𝑇 and pick 𝜎 = 10 and 𝑇 = 1.\nTo model the score as 𝑠 𝜃 (𝑥, 𝑦; 𝑡), we use a time-conditioned fully connected neural network using\nGaussian Fourier feature mapping [46]. We choose to run the backward process using 1000 steps\nfor 106 trajectories to obtain samples. Our choice of hyperparameters is summarised in table 1.\nMore details can be found in Ref. [40].\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.4**l== 0.2**r== 0.6**\nHyperparameter\n**BLOCK**fs== 10.9**p== 4.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nHyperparameter Value\n**BLOCK**fs== 10.9**p== 4.0**b== 0.5**t== 0.4**l== 0.2**r== 0.6**\nLayers\nTime Embedding dims\nActivation Function\nWeight Initialization\n**BLOCK**fs== 10.9**p== 4.0**b== 0.5**t== 0.4**l== 0.4**r== 0.3**\n[64, 64]\n\nLeakyReLU\nLeCun Uniform [47] Max Epochs\n**BLOCK**fs== 10.9**p== 4.0**b== 0.5**t== 0.4**l== 0.6**r== 0.3**\nLearning Rate\nBatch Size\nOptimizer\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nTable 1: Model and training hyperparameters used in training. We save the weights with the best loss during\nthe training process and employ early stopping.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\n4.1 Gaussian model\n**BLOCK**fs== 10.9**p== 4.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nAs a first example, we consider the Gaussian action with complex mass parameter\n**BLOCK**fs== 10.9**p== 4.0**b== 0.3**t== 0.7**l== 0.1**r== 0.3**\nThe CL dynamics with real noise is described by the system of equations,\n**BLOCK**fs== 10.9**p== 4.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\n𝐾𝑥 = −𝐴𝑥 + 𝐵𝑦,\n**BLOCK**fs== 10.9**p== 4.0**b== 0.3**t== 0.7**l== 0.7**r== 0.2**\n𝐾𝑦 = −𝐴𝑦 − 𝐵𝑥.\n**BLOCK**fs== 10.9**p== 4.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\n𝑃(𝑥, 𝑦) = 𝑁 exp −𝛼𝑥2 − 𝛽𝑦2 − 2𝛾𝑥𝑦 ,\n**BLOCK**fs== 10.9**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\nwith the coefficients 𝛼 = 𝐴, 𝛽 = 𝐴(1 + 2𝐴2/𝐵2), 𝛾 = 𝐴2/𝐵. This solution satisfies Eq. (11). With\nthis solution, the log derivatives of the probability distribution (18) sampled by the CL process can\nbe computed and the analytical score reads\n**BLOCK**fs== 10.0**p== 5.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure 1: Gaussian model with complex mass parameter 𝜎0 = 1 + 𝑖: vector field ∇ log 𝑃(𝑥, 𝑦) and lines of\nconstant 𝑃(𝑥, 𝑦) as given by the analytical results (18, 19) (left) and as learnt by the diffusion model (right).\n**BLOCK**fs== 10.9**p== 5.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nAs we see below, the learned score at the end of the backward process approximates this vector\nfield. It is important to note that this distribution and its derivatives are usually not available and in\nparticular not directly related to the CL drift (𝐾𝑥, 𝐾𝑦), since the latter cannot be integrated. This is\neasy to see, as 𝜕𝑦𝐾𝑥 ≠ 𝜕𝑥𝐾𝑦.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.4**t== 0.4**l== 0.1**r== 0.1**\nWe have trained the diffusion model on data generated using CL dynamics, as explained above.\nThe resulting score at the end of the backward process is shown in Fig. 1 (right). This score can be\ncompared with the analytical score (19), shown on the left. Contour lines of constant 𝑃(𝑥, 𝑦) are\nincluded as well. We observe that the model manages to capture the score from the data. To make\nthis more quantitative, we have computed the four lowest nonzero moments, 𝜇𝑛 = E[(𝑥 + 𝑖𝑦)𝑛] with\n𝑛 = 2, 4, 6, 8. The exact results are 𝜇𝑛 = (𝑛 − 1)!!/𝜎𝑛/2\nfor even 𝑛. Since the theory is Gaussian,\nall higher-order cumulants vanish. The results are shown in Table 2. Note that the diffusion model\nlearns from CL generated data, not from the exact distribution.\n**BLOCK**fs== 9.5**p== 5.0**b== 0.4**t== 0.6**l== 0.2**r== 0.7**\nre\n0.5\nExact\n0.4986(7)\nCL\nDM 0.497(1)\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nTable 2: Gaussian model with complex mass parameter 𝜎0 = 1 + 𝑖: first four non-vanishing moments 𝜇𝑛,\nas obtained from CL data and from diffusion model generated data, including exact values. Statistical errors\nare computed by a bootstrap resampling of the dataset with 106 configurations using 100 bins.\n**BLOCK**fs== 10.9**p== 5.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\n4.2 Quartic model\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\nWe now consider the quartic model with a complex mass parameter [27]\n**BLOCK**fs== 10.9**p== 5.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nExact results can be obtained by a direct evaluation of the partition function,\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure 2: Quartic model with parameters 𝜎0 = 1 + 𝑖, 𝜆 = 1: solution 𝑃(𝑥, 𝑦) of the FPE obtained by a double\nexpansion in Hermite functions [27] (left) and as learnt by the diffusion model (right).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nFigure 3: Distributions 𝑃(𝑥, 0) and 𝑃(0, 𝑦) created by collecting configurations during the CL process and\nfrom the trained diffusion model, using 106 samples in each case. Other parameters as above.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.2**\nwhere 𝜉 = 𝜎2\nmoments 𝜇𝑛 = E[𝑥𝑛] are obtained by differentiating with respect to 𝜎0. Odd moments vanish.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.4**t== 0.5**l== 0.2**r== 0.1**\n0 /(8𝜆) and 𝐾𝑞 (𝜉) is the modified Bessel function of the second kind. Subsequently,\n**BLOCK**fs== 10.9**p== 6.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\nProvided that 3𝐴2 − 𝐵2 > 0, the CL process is contained in a strip −𝑦− < 𝑦 < 𝑦−, with [27]\n**BLOCK**fs== 10.9**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nCL dynamics then yields the correct results [27].\n**BLOCK**fs== 10.9**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nWe have trained the diffusion model as above. In this case, no analytical expression for 𝑃(𝑥, 𝑦)\nor the score is available.\nIn Ref. [27] the FPE was solved by a double expansion in terms of\nHermite functions. The resulting stationary distribution is shown in Fig. 2 (left). The distribution\nis strictly zero when |𝑦| > 𝑦− ≃ 0.3029. The little ripples in the left plot are an artifact of the\nexpansion. Sampling from the trained diffusion model yields the distribution shown on the right.\nTwo cross sections of the distribution, 𝑃(𝑥, 0) and 𝑃(0, 𝑦), are shown in Fig. 3. We note that the\ntrained diffusion model manages to capture the two peaks characteristic of this model as well as the\nboundary restrictions from the training data, with some small deviations visible.\n**BLOCK**fs== 10.9**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\nThe analytical score is not available in this case. In Fig. 4 we show the CL drift (left) and\nthe score at the end of the backward process, as learnt by the diffusion model (right). The two\nvector fields are different, as they should be. Recall that the Langevin drift is used in the CL\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nFigure 4: Drift in complex Langevin dynamics (left) and the score as learnt by the diffusion model, including\ncontour lines (right). These vector fields are different, as they should be. Parameters as above.\n**BLOCK**fs== 9.5**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nre\nExact\n0.428142\nCL\n0.4277(5)\nDM 0.4267(6)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nTable 3: As in Table 2, cumulants 𝜅𝑛 for the quartic model with parameters 𝜎0 = 1 + 𝑖, 𝜆 = 1.\n**BLOCK**fs== 10.9**p== 7.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nequation with noise in the 𝑥 direction only and no time-dependent coefficients, whereas the score is\nused in the time-dependent stochastic equation with noise applied in both directions. Neverthless,\nboth processes yield (approximately) the same distribution, used for data generation. To make the\ncomparison quantitative, we have computed cumulants 𝜅𝑛 from the numerically estimated moments\n𝜇𝑛, using the standard relations. The results are presented in Table 3. We observe good agreement.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\n5. Outlook\n**BLOCK**fs== 10.9**p== 7.0**b== 0.1**t== 0.6**l== 0.1**r== 0.1**\nWe have demonstrated the diffusion model’s ability to capture the distributions from data\ngenerated by complex Langevin dynamics, using two simple models. The model reproduces\nstatistical properties of the data on which it is trained, as one would expect. The capability of\ndiffusion models to learn higher-order cumulants has also been shown in Ref. [40]. In the context\nof CL dynamics, a diffusion model will not solve the sign problem when CL fails. However, the\nscore learnt by the diffusion model is not related to the drift in the CL process, but is instead an\napproximation to the gradient of an effective action on the complexified space. This may open\nup new avenues to analyse the properties of CL generated distributions on the complexified space,\nwhich are worth exploring. Finally, there are no obstacles to extend this approach to two-dimensional\nlattice field theories [37, 39] and use it to generate additional configurations.\nAcknowledgements – DEH is supported by the UKRI AIMLAC CDT EP/S023992/1. GA is\nsupported by STFC Consolidated Grant ST/T000813/1. KZ is supported by the CUHK-Shenzhen\nUniversity development fund under grant No. UDF01003041 and UDF03003041, and Shenzhen\nPeacock fund under No. 2023TC0179.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nResearch Data and Code Access – The code and data used for this manuscript is a variation of the\ncode available in Ref. [48].\nOpen Access Statement – For the purpose of open access, the authors have applied a Creative\nCommons Attribution (CC BY) licence to any Author Accepted Manuscript version arising.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nReferences\n**BLOCK**fs== 10.9**p== 8.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\n[1] M. Troyer and U.-J. Wiese, Computational complexity and fundamental limitations to\nfermionic quantum Monte Carlo simulations, Phys. Rev. Lett. 94 (2005) 170201\n[cond-mat/0408370].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n[2] P. de Forcrand, Simulating QCD at finite density, PoS LAT2009 (2009) 010 [1005.0539].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n[3] G. Aarts, Introductory lectures on lattice QCD at nonzero baryon number, J. Phys. Conf.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.3**\n[4] G. Parisi, On complex probabilities, Physics Letters B 131 (1983) 393.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n[5] J.R. Klauder, Stochastic quantization, in Recent Developments in High-Energy Physics,\n**BLOCK**fs== 10.9**p== 8.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nH. Mitter and C.B. Lang, eds., (Vienna), pp. 251–281, Springer Vienna, 1983.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[6] G. Parisi and Y.S. Wu, Perturbation theory without gauge fixing, Sci. China, A 24 (1980) 483.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n[7] P.H. Damgaard and H. Hüffel, Stochastic quantization, Phys. Rept. 152 (1987) 227.\n**BLOCK**fs== 10.9**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n[8] G. Aarts and F.A. James, Complex Langevin dynamics in the SU(3) spin model at nonzero\n**BLOCK**fs== 10.9**p== 8.0**b== 0.5**t== 0.5**l== 0.2**r== 0.3**\nchemical potential revisited, JHEP 01 (2012) 118 [1112.4655].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n[9] G. Aarts, Can stochastic quantization evade the sign problem? The relativistic Bose gas at\n**BLOCK**fs== 10.9**p== 8.0**b== 0.4**t== 0.6**l== 0.2**r== 0.3**\nfinite chemical potential, Phys. Rev. Lett. 102 (2009) 131601 [0810.2089].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[10] E. Seiler, D. Sexty and I.-O. Stamatescu, Gauge cooling in complex Langevin for QCD with\n**BLOCK**fs== 10.9**p== 8.0**b== 0.4**t== 0.6**l== 0.2**r== 0.4**\nheavy quarks, Phys. Lett. B 723 (2013) 213 [1211.3709].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n[11] D. Sexty, Simulating full QCD at nonzero density using the complex Langevin equation,\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\nPhys. Lett. B 729 (2014) 108 [1307.7748].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n[12] G. Aarts, F. Attanasio, B. Jäger and D. Sexty, The QCD phase diagram in the limit of heavy\n**BLOCK**fs== 10.9**p== 8.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nquarks using complex Langevin dynamics, JHEP 09 (2016) 087 [1606.05561].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\n[13] D. Sexty, Calculating the equation of state of dense quark-gluon plasma using the complex\n**BLOCK**fs== 10.9**p== 8.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\nLangevin equation, Phys. Rev. D 100 (2019) 074503 [1907.08712].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\n[14] M. Scherzer, D. Sexty and I.O. Stamatescu, Deconfinement transition line with the complex\nLangevin equation up to 𝜇/𝑇 ∼ 5, Phys. Rev. D 102 (2020) 014515 [2004.05372].\n**BLOCK**fs== 10.9**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\n[15] J. Ambjorn and S.K. Yang, Numerical Problems in Applying the Langevin Equation to\n**BLOCK**fs== 10.9**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.4**\nComplex Effective Actions, Phys. Lett. B 165 (1985) 140.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\n[16] G. Aarts and F.A. James, On the convergence of complex Langevin dynamics: The\n**BLOCK**fs== 10.9**p== 9.0**b== 0.9**t== 0.1**l== 0.2**r== 0.1**\nThree-dimensional XY model at finite chemical potential, JHEP 08 (2010) 020 [1005.3468].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\n[17] G. Aarts, F.A. James, J.M. Pawlowski, E. Seiler, D. Sexty and I.-O. Stamatescu, Stability of\ncomplex Langevin dynamics in effective models, JHEP 03 (2013) 073 [1212.5231].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\n[18] G. Aarts, E. Seiler and I.-O. Stamatescu, Complex Langevin method: When can it be\n**BLOCK**fs== 10.9**p== 9.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\ntrusted?, Phys. Rev. D 81 (2010) 054508.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n[19] G. Aarts, F.A. James, E. Seiler and I.-O. Stamatescu, Complex Langevin: Etiology and\nDiagnostics of its Main Problem, Eur. Phys. J. C 71 (2011) 1756 [1101.3270].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n[20] J. Nishimura and S. Shimasaki, New Insights into the Problem with a Singular Drift Term in\n**BLOCK**fs== 10.9**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\nthe Complex Langevin Method, Phys. Rev. D 92 (2015) 011501 [1504.08359].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\n[21] M. Scherzer, E. Seiler, D. Sexty and I.-O. Stamatescu, Complex Langevin and boundary\n**BLOCK**fs== 10.9**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\nterms, Phys. Rev. D 99 (2019) 014512 [1808.05187].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n[22] M. Scherzer, E. Seiler, D. Sexty and I.O. Stamatescu, Controlling Complex Langevin\n**BLOCK**fs== 10.9**p== 9.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\nsimulations of lattice models by boundary term analysis, Phys. Rev. D 101 (2020) 014501\n[1910.09427].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n[23] D. Alvestad, R. Larsen and A. Rothkopf, Towards learning optimized kernels for complex\n**BLOCK**fs== 10.9**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nLangevin, JHEP 04 (2023) 057 [2211.15625].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n[24] E. Seiler, D. Sexty and I.-O. Stamatescu, Complex Langevin: Correctness criteria, boundary\n**BLOCK**fs== 10.9**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.3**\nterms, and spectrum, Phys. Rev. D 109 (2024) 014509 [2304.00563].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.2**\n[25] M.W. Hansen and D. Sexty, Testing dynamical stabilization of Complex Langevin\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nsimulations of QCD, 2405.20709.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n[26] G. Aarts, Complex Langevin dynamics at finite chemical potential: Mean field analysis in the\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.2**r== 0.4**\nrelativistic Bose gas, JHEP 05 (2009) 052 [0902.4686].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n[27] G. Aarts, P. Giudice and E. Seiler, Localised distributions and criteria for correctness in\n**BLOCK**fs== 10.9**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.3**\ncomplex Langevin dynamics, Annals Phys. 337 (2013) 238 [1306.3075].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n[28] J. Sohl-Dickstein, E.A. Weiss, N. Maheswaranathan and S. Ganguli, Deep unsupervised\n**BLOCK**fs== 10.9**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nlearning using nonequilibrium thermodynamics, in Proc. 32nd Int. Conf. Int. Conf. Mach.\nLearn. - Vol. 37, pp. 2256–2265, 2015 [1503.03585].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\n[29] J. Ho, A. Jain and P. Abbeel, Denoising diffusion probabilistic models, in Proc. 34th Int.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.3**\nConf. Neural Inf. Process. Syst., pp. 6840–6851, 2020 [2006.11239].\n**BLOCK**fs== 10.9**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\n[30] Y. Song and S. Ermon, Generative Modeling by Estimating Gradients of the Data\n**BLOCK**fs== 10.9**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nDistribution, 1907.05600.\n**BLOCK**fs== 10.9**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\n[31] Y. Song, J. Sohl-Dickstein, D.P. Kingma, A. Kumar, S. Ermon and B. Poole, Score-based\n**BLOCK**fs== 10.9**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.3**\ngenerative modeling through stochastic differential equations, 2011.13456.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.2**\n[32] L. Yang, Z. Zhang, S. Hong, R. Xu, Y. Zhao, Y. Shao et al., Diffusion Models: A\n**BLOCK**fs== 10.9**p== 10.0**b== 0.9**t== 0.1**l== 0.2**r== 0.3**\nComprehensive Survey of Methods and Applications, 2209.00796.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\n[33] Y. Song, C. Durkan, I. Murray and S. Ermon, Maximum likelihood training of score-based\n**BLOCK**fs== 10.9**p== 10.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\ndiffusion models, 2101.09258.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\n[34] T. Karras, M. Aittala, T. Aila and S. Laine, Elucidating the design space of diffusion-based\n**BLOCK**fs== 10.9**p== 10.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\ngenerative models, 2206.00364.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n[35] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu and M. Chen, Hierarchical Text-Conditional\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.2**r== 0.4**\nImage Generation with CLIP Latents, 2204.06125.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n[36] R. Rombach, A. Blattmann, D. Lorenz, P. Esser and B. Ommer, High-Resolution Image\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nSynthesis with Latent Diffusion Models, Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition (CVPR) (2022) 10684 [2112.10752].\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n[37] L. Wang, G. Aarts and K. Zhou, Diffusion models as stochastic quantization in lattice field\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.4**l== 0.2**r== 0.5**\ntheory, JHEP 05 (2024) 060 [2309.17082].\n**BLOCK**fs== 10.9**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\n[38] L. Wang, G. Aarts and K. Zhou, Generative Diffusion Models for Lattice Field Theory, in\n37th Conference on Neural Information Processing Systems, 2023 [2311.03578].\n**BLOCK**fs== 10.9**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\n[39] Q. Zhu, G. Aarts, W. Wang, K. Zhou and L. Wang, Diffusion models for lattice gauge field\n**BLOCK**fs== 10.9**p== 10.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\nsimulations, in 38th conference on Neural Information Processing Systems, 2024\n[2410.19602].\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.2**\n[40] G. Aarts, D.E. Habibi, L. Wang and K. Zhou, On learning higher-order cumulants in\ndiffusion models, in 38th conference on Neural Information Processing Systems, 2024\n[2410.21212].\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\n[41] Y. Hirono, A. Tanaka and K. Fukushima, Understanding Diffusion Models by Feynman’s\n**BLOCK**fs== 10.9**p== 10.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nPath Integral, 2403.11262.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\n[42] K. Fukushima and S. Kamata, Stochastic quantization and diffusion models, 2411.11297.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n[43] B.D.O. Anderson, Reverse-time diffusion equation models, Stochastic Processes and their\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nApplications 12 (1982) 313.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n[44] A. Hyvärinen, Estimation of Non-Normalized Statistical Models by Score Matching, Journal\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.7**l== 0.2**r== 0.5**\nof Machine Learning Research 6 (2005) 695.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\n[45] C.C. Chang, Numerical solution of stochastic differential equations with constant diffusion\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\ncoefficients, Math. Comp. 49 (1987) 523.\n**BLOCK**fs== 10.9**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n[46] M. Tancik, P.P. Srinivasan, B. Mildenhall, S. Fridovich-Keil, N. Raghavan, U. Singhal et al.,\n**BLOCK**fs== 10.9**p== 10.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nFourier features let networks learn high frequency functions in low dimensional domains,\n2006.10739.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.1**l== 0.1**r== 0.2**\n[47] Y. LeCun, L. Bottou, G.B. Orr and K.R. Müller, Efficient BackProp, in Neural Networks:\nTricks of the Trade, G.B. Orr and K.-R. Müller, eds., pp. 9–50, Springer Berlin Heidelberg\n(1998), DOI.\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[48] D.E. Habibi, G. Aarts, L. Wang and K. Zhou,\n**BLOCK**fs== 10.9**p== 11.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\n“DiaaEddinH/On-learning-higher-order-cumulants-in-diffusion-models: v1.0.2.”\n10.5281/zenodo.14041604.",
         "Diffusion models learn distributions generated by complex Langevin dynamics Theories with a complex Boltzmann weight are hard to simulate using conventional numerical methods based on importance sampling, due to the sign and overlap problems [1]. A prime example is QCD at nonzero baryon density, in which the quark determinant is complex for real quark chemical potential [2, 3], [det 𝑀 (𝜇)]∗ = det 𝑀 (−𝜇∗) ∈ C. Complex Langevin (CL) dynamics, in which the degrees of freedom are analytically extended, provides a potential solution, as it does not rely on importance sampling but explores a complexified manifold via a stochastic process [4, 5]. It is an extension of stochastic quantisation [6, 7], which is equivalent to path integral quantisation. CL has been shown to work in lattice field theories in three [8] and four [9] Euclidean dimensions with a severe sign problem, including in QCD [10–14], but it may also fail, even in simple models [15–17]. This situation was clarified a few years ago [18–20] by the derivation of the formal relation between the complex distribution on the real manifold and the real and positive distribution on the complexified manifold, which is effectively sampled during the CL process, leading to practical criteria for correctness which need to be verified a posteriori. Nevertheless, issues remain and the reliability of the method depends on a precise understanding of the behaviour of the distribution at infinity and near poles in the CL drift. Recent work can be found in e.g. Refs. [21–25]. As should be clear, a crucial role is played by the distribution on the complexified manifold. Unfortunately, this distribution turns out to be elusive, as the Fokker-Planck equation (FPE) linked to the CL process cannot be solved in general. In fact, even convergence is hard to understand, except in some simple cases, such as Gaussian models [26] and models in which one can prove the dynamics takes place in a strip (see below) [27]. A better characterisation of the distribution would therefore be welcome. Diffusion models [28–34] are a class of generative AI, which learn distributions from data. They are widely popular and used in e.g. DALL-E [35] and Stable Diffusion [36]. The methodology of diffusion models relies on a stochastic process, similar to stochastic quantisation, but instead of using a known drift term derived from the underlying distribution, it learns the drift from data previously generated or collected. We have recently explored the relation between diffusion models and stochastic quantisation in scalar [37, 38] and U(1) gauge theories [39], and studied the evolution of higher-order cumulants in detail [40]. Further connections between diffusion models and field theory are pointed out in Refs. [41, 42]. Given the success of diffusion models to learn distributions and the elusiveness of the distri- bution sampled in the CL process, it makes sense to combine these two approaches to deepen our understanding of the latter. In the next two sections we first remind the reader of CL dynamics for theories with a complex Boltzmann distribution and then briefly introduce diffusions models. In Sec. 4 we then combine these in two simple cases with a single degree of freedom: the exactly solvable Gaussian case with a complex mass parameter, and the quartic model with a complex mass parameter, for which the distribution can be proven to be confined to a strip in the complex plane. 2. Complex Langevin dynamics Consider one degree of freedom 𝑥, with a Boltzmann weight 𝜌(𝑥), such that ∫ 𝑑𝑥 𝜌(𝑥)𝑂 (𝑥), The Langevin process and drift read 𝑥(𝑡) = 𝐾 [𝑥(𝑡)] + 𝜂(𝑡), 𝑑 𝑑𝑥 log 𝜌(𝑥) = − where the dot indicates the Langevin time derivative and the noise satisfies ⟨𝜂(𝑡)𝜂(𝑡′)⟩ = 2𝛿(𝑡 − 𝑡′). The corresponding FPE is 𝜕𝑡 𝜌(𝑥; 𝑡) = 𝜕𝑥 [𝜕𝑥 − 𝐾 (𝑥)] 𝜌(𝑥; 𝑡), and for a real Boltzmann weight and drift this process converges to the stationary solution 𝜌(𝑥), typically exponentially fast [7]. When the weight is complex, one may extend 𝑥 → 𝑧 = 𝑥 + 𝑖𝑦 into the complex plane and write 𝑧(𝑡) = 𝐾 [𝑧(𝑡)] + 𝜂(𝑡), 𝑑 𝑑𝑧 log 𝜌(𝑧) = − However, in this case the FPE cannot be used to show convergence as the corresponding Fokker- Planck Hamiltonian is no longer semi-positive definite [7]. We may consider the CL process, 𝑥(𝑡) = 𝐾𝑥 + 𝜂𝑥 (𝑡), 𝑦(𝑡) = 𝐾𝑦 + 𝜂𝑦 (𝑡), 𝑑 𝑑𝑧 log 𝜌(𝑧), 𝑑 𝑑𝑧 log 𝜌(𝑧), ⟨𝜂𝑥 (𝑡)𝜂𝑥 (𝑡′)⟩ = 2𝑁𝑥𝛿(𝑡 − 𝑡′), ⟨𝜂𝑦 (𝑡)𝜂𝑦 (𝑡′)⟩ = 2𝑁𝑦𝛿(𝑡 − 𝑡′), with noise satisfying 𝑁𝑥 − 𝑁𝑦 = 1. The FPE equation for this process reads 𝜕𝑡 𝑃(𝑥, 𝑦; 𝑡) = 𝜕𝑥 (𝑁𝑥 𝜕𝑥 − 𝐾𝑥) + 𝜕𝑦 𝑁𝑦𝜕𝑦 − 𝐾𝑦 𝑃(𝑥, 𝑦; 𝑡), such that ⟨𝑂 [𝑥(𝑡) + 𝑖𝑦(𝑡)]⟩𝜂 = 𝑑𝑥𝑑𝑦 𝑃(𝑥, 𝑦; 𝑡)𝑂 (𝑥 + 𝑖𝑦). It is preferable to consider real noise, 𝑁𝑥 = 1, 𝑁𝑦 = 0 [18]. The CL process yields the correct answer if a stationary solution to this FPE exists, such that 𝑑𝑥𝑑𝑦 𝑃(𝑥, 𝑦)𝑂 (𝑥 + 𝑖𝑦) = 𝑑𝑥 𝜌(𝑥)𝑂 (𝑥), or, shifting the integration variables at a formal level, 𝑑𝑦 𝑃(𝑥 − 𝑖𝑦, 𝑦). Considerable effort has been invested in deriving criteria for correctness related to the behaviour of 𝑃(𝑥, 𝑦) at infinity and near poles of the drift (if there are any), which can be used a posteriori to justify the results [18–25]. A better understanding of 𝑃(𝑥, 𝑦) in the stationary limit would therefore be very welcome. We emphasise that unlike the original weight 𝜌(𝑧), 𝑃(𝑥, 𝑦; 𝑡) is real and semi-positive definite, as it represents the real Langevin process in the two-dimensional plane. 3. Diffusion models Diffusion models, as a class of probabilistic generative models, gradually corrupt data with incrementally increasing noise and are trained to reverse the process to build a generative model of the data [28–32]. We use the description in terms of stochastic differential equations (SDEs) [31, 33, 34] and follow the notation of Ref. [40]. The diffusion process consists of two parts. The noise-injecting or forward process is described by the following SDE, 𝑥(𝑡) = 𝐾 (𝑥(𝑡), 𝑡) + 𝑔(𝑡)𝜂(𝑡), where 𝐾 (𝑥(𝑡), 𝑡) is a drift term, 𝜂 ∼ N (0, 1) is Gaussian noise and 𝑔(𝑡), the diffusion coefficient, is the time-dependent noise strength. The initial conditions for this process are determined by the target distribution 𝑥(0) = 𝑥0 ∼ 𝑃0(𝑥0) and the process runs between 0 ≤ 𝑡 ≤ 𝑇. Properties of the distribution at the end of this process, 𝑃(𝑥, 𝑇), have been studied in Ref. [40]. The second part corresponds to the denoising or backward process. Written in terms of reverse time 𝜏 = 𝑇 − 𝑡, the SDE reads [43] 𝑥′(𝜏) = −𝐾 (𝑥(𝜏), 𝑇 − 𝜏) + 𝑔2(𝑇 − 𝜏)𝜕𝑥 log 𝑃(𝑥, 𝑇 − 𝜏) + 𝑔(𝑇 − 𝜏)𝜂(𝜏), with 0 ≤ 𝜏 ≤ 𝑇. Initial conditions are sampled from a normal distribution with a variance comparable to the variance obtained at the end of the forward process. The so-called score, 𝜕𝑥 log 𝑃(𝑥, 𝑡), is not known a priori and is approximated by a quantity 𝑠 𝜃 (𝑥, 𝑡), which is determined, or ‘learnt’, during the forward process via score matching [44]. Given a sample dataset of the target distribution, a score-based model can be trained starting from the Fisher divergence [31], 𝑠 𝜃 (𝑥, 𝑡) − ∇ log 𝑃(𝑥, 𝑡) where the weight 𝜆(𝑡) is chosen to be the variance of the noise at time 𝑡. After the diffusion model has been trained, new samples from the target distribution can be generated by numerically solving the backward stochastic process (13), substituting in the trained score model 𝑠∗ 𝜃 (𝑥, 𝑡). Using a simple discretisation with stepsize Δ𝜏 one solves, for 0 ≤ 𝜏 ≤ 𝑇, 𝑥 𝜏+Δ𝜏 = 𝑥 𝜏 + −𝐾 (𝑥 𝜏, 𝑇 − 𝜏) + 𝑔2(𝑇 − 𝜏)𝑠∗ 𝜃 (𝑥 𝜏, 𝑇 − 𝜏) Δ𝜏 + 𝑔(𝑇 − 𝜏) where 𝜂𝜏 ∼ N (0, 1). This is indeed remarkably similar [37] to the formulation of stochastic quantisation, in which, however, the drift is time-independent and derived from a known distribution, as in Eq. (3), rather than being learnt from data. 4. Application to complex Langevin dynamics As stated above, for complex actions CL dynamics is capable of generating configurations but the corresponding probability distribution 𝑃(𝑥, 𝑦) is typically not available. This makes it hard to fully assess the reliability of the approach. A diffusion model, however, can learn (the log-derivative of) this distribution, in the form of the score ∇ log 𝑃(𝑥, 𝑦). Notably, for the diffusion model it is irrelevant what the origin of the configurations is. The learned score can subsequently be used to study aspects of convergence of the CL process or to generate additional configurations. To investigate the viability of this approach, we start with two simple models of one degree of freedom, the exactly solvable Gaussian case and a quartic model, both with a complex mass parameter. In each case we have generated training data by solving the discretised CL process with stepsize 𝜖 using the higher-order algorithm of Ref. [45], first applied to CL dynamics in Ref. [8]. This algorithm improves stepsize corrections from O (𝜖) to O (𝜖 3/2). We have generated an ensemble of 106 configurations for training, which are preprocessed by scaling it to zero mean and unit variance. In the diffusion model, we employ a variance-exploding scheme, in which the drift term in Eq. (12) is put to zero, 𝐾 (𝑥, 𝑦; 𝑡) = 0. Note that due to the complexification, we have two degrees of freedom to consider. We choose the diffusion coefficient 𝑔(𝑡) = 𝜎𝑡/𝑇 and pick 𝜎 = 10 and 𝑇 = 1. To model the score as 𝑠 𝜃 (𝑥, 𝑦; 𝑡), we use a time-conditioned fully connected neural network using Gaussian Fourier feature mapping [46]. We choose to run the backward process using 1000 steps for 106 trajectories to obtain samples. Our choice of hyperparameters is summarised in table 1. More details can be found in Ref. [40]. 4.1 Gaussian model As a first example, we consider the Gaussian action with complex mass parameter The CL dynamics with real noise is described by the system of equations, 𝐾𝑥 = −𝐴𝑥 + 𝐵𝑦, 𝐾𝑦 = −𝐴𝑦 − 𝐵𝑥. 𝑃(𝑥, 𝑦) = 𝑁 exp −𝛼𝑥2 − 𝛽𝑦2 − 2𝛾𝑥𝑦 , with the coefficients 𝛼 = 𝐴, 𝛽 = 𝐴(1 + 2𝐴2/𝐵2), 𝛾 = 𝐴2/𝐵. This solution satisfies Eq. (11). With this solution, the log derivatives of the probability distribution (18) sampled by the CL process can be computed and the analytical score reads As we see below, the learned score at the end of the backward process approximates this vector field. It is important to note that this distribution and its derivatives are usually not available and in particular not directly related to the CL drift (𝐾𝑥, 𝐾𝑦), since the latter cannot be integrated. This is easy to see, as 𝜕𝑦𝐾𝑥 ≠ 𝜕𝑥𝐾𝑦. We have trained the diffusion model on data generated using CL dynamics, as explained above. The resulting score at the end of the backward process is shown in Fig. 1 (right). This score can be compared with the analytical score (19), shown on the left. Contour lines of constant 𝑃(𝑥, 𝑦) are included as well. We observe that the model manages to capture the score from the data. To make this more quantitative, we have computed the four lowest nonzero moments, 𝜇𝑛 = E[(𝑥 + 𝑖𝑦)𝑛] with 𝑛 = 2, 4, 6, 8. The exact results are 𝜇𝑛 = (𝑛 − 1)!!/𝜎𝑛/2 for even 𝑛. Since the theory is Gaussian, all higher-order cumulants vanish. The results are shown in Table 2. Note that the diffusion model learns from CL generated data, not from the exact distribution. 4.2 Quartic model We now consider the quartic model with a complex mass parameter [27] Exact results can be obtained by a direct evaluation of the partition function, where 𝜉 = 𝜎2 moments 𝜇𝑛 = E[𝑥𝑛] are obtained by differentiating with respect to 𝜎0. Odd moments vanish. 0 /(8𝜆) and 𝐾𝑞 (𝜉) is the modified Bessel function of the second kind. Subsequently, Provided that 3𝐴2 − 𝐵2 > 0, the CL process is contained in a strip −𝑦− < 𝑦 < 𝑦−, with [27] CL dynamics then yields the correct results [27]. We have trained the diffusion model as above. In this case, no analytical expression for 𝑃(𝑥, 𝑦) or the score is available. In Ref. [27] the FPE was solved by a double expansion in terms of Hermite functions. The resulting stationary distribution is shown in Fig. 2 (left). The distribution is strictly zero when |𝑦| > 𝑦− ≃ 0.3029. The little ripples in the left plot are an artifact of the expansion. Sampling from the trained diffusion model yields the distribution shown on the right. Two cross sections of the distribution, 𝑃(𝑥, 0) and 𝑃(0, 𝑦), are shown in Fig. 3. We note that the trained diffusion model manages to capture the two peaks characteristic of this model as well as the boundary restrictions from the training data, with some small deviations visible. The analytical score is not available in this case. In Fig. 4 we show the CL drift (left) and the score at the end of the backward process, as learnt by the diffusion model (right). The two vector fields are different, as they should be. Recall that the Langevin drift is used in the CL equation with noise in the 𝑥 direction only and no time-dependent coefficients, whereas the score is used in the time-dependent stochastic equation with noise applied in both directions. Neverthless, both processes yield (approximately) the same distribution, used for data generation. To make the comparison quantitative, we have computed cumulants 𝜅𝑛 from the numerically estimated moments 𝜇𝑛, using the standard relations. The results are presented in Table 3. We observe good agreement. We have demonstrated the diffusion model’s ability to capture the distributions from data generated by complex Langevin dynamics, using two simple models. The model reproduces statistical properties of the data on which it is trained, as one would expect. The capability of diffusion models to learn higher-order cumulants has also been shown in Ref. [40]. In the context of CL dynamics, a diffusion model will not solve the sign problem when CL fails. However, the score learnt by the diffusion model is not related to the drift in the CL process, but is instead an approximation to the gradient of an effective action on the complexified space. This may open up new avenues to analyse the properties of CL generated distributions on the complexified space, which are worth exploring. Finally, there are no obstacles to extend this approach to two-dimensional lattice field theories [37, 39] and use it to generate additional configurations. Acknowledgements – DEH is supported by the UKRI AIMLAC CDT EP/S023992/1. GA is supported by STFC Consolidated Grant ST/T000813/1. KZ is supported by the CUHK-Shenzhen University development fund under grant No. UDF01003041 and UDF03003041, and Shenzhen Peacock fund under No. 2023TC0179. Research Data and Code Access – The code and data used for this manuscript is a variation of the code available in Ref. [48]. Open Access Statement – For the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising. [1] M. Troyer and U.-J. Wiese, Computational complexity and fundamental limitations to fermionic quantum Monte Carlo simulations, Phys. Rev. Lett. 94 (2005) 170201 [cond-mat/0408370]. [2] P. de Forcrand, Simulating QCD at finite density, PoS LAT2009 (2009) 010 [1005.0539]. [3] G. Aarts, Introductory lectures on lattice QCD at nonzero baryon number, J. Phys. Conf. [4] G. Parisi, On complex probabilities, Physics Letters B 131 (1983) 393. [5] J.R. Klauder, Stochastic quantization, in Recent Developments in High-Energy Physics, H. Mitter and C.B. Lang, eds., (Vienna), pp. 251–281, Springer Vienna, 1983. [6] G. Parisi and Y.S. Wu, Perturbation theory without gauge fixing, Sci. China, A 24 (1980) 483. [7] P.H. Damgaard and H. Hüffel, Stochastic quantization, Phys. Rept. 152 (1987) 227. [8] G. Aarts and F.A. James, Complex Langevin dynamics in the SU(3) spin model at nonzero chemical potential revisited, JHEP 01 (2012) 118 [1112.4655]. [9] G. Aarts, Can stochastic quantization evade the sign problem? The relativistic Bose gas at finite chemical potential, Phys. Rev. Lett. 102 (2009) 131601 [0810.2089]. [10] E. Seiler, D. Sexty and I.-O. Stamatescu, Gauge cooling in complex Langevin for QCD with heavy quarks, Phys. Lett. B 723 (2013) 213 [1211.3709]. [11] D. Sexty, Simulating full QCD at nonzero density using the complex Langevin equation, [12] G. Aarts, F. Attanasio, B. Jäger and D. Sexty, The QCD phase diagram in the limit of heavy quarks using complex Langevin dynamics, JHEP 09 (2016) 087 [1606.05561]. [13] D. Sexty, Calculating the equation of state of dense quark-gluon plasma using the complex Langevin equation, Phys. Rev. D 100 (2019) 074503 [1907.08712]. [14] M. Scherzer, D. Sexty and I.O. Stamatescu, Deconfinement transition line with the complex Langevin equation up to 𝜇/𝑇 ∼ 5, Phys. Rev. D 102 (2020) 014515 [2004.05372]. [15] J. Ambjorn and S.K. Yang, Numerical Problems in Applying the Langevin Equation to [16] G. Aarts and F.A. James, On the convergence of complex Langevin dynamics: The Three-dimensional XY model at finite chemical potential, JHEP 08 (2010) 020 [1005.3468]. [17] G. Aarts, F.A. James, J.M. Pawlowski, E. Seiler, D. Sexty and I.-O. Stamatescu, Stability of complex Langevin dynamics in effective models, JHEP 03 (2013) 073 [1212.5231]. [18] G. Aarts, E. Seiler and I.-O. Stamatescu, Complex Langevin method: When can it be trusted?, Phys. Rev. D 81 (2010) 054508. [19] G. Aarts, F.A. James, E. Seiler and I.-O. Stamatescu, Complex Langevin: Etiology and Diagnostics of its Main Problem, Eur. Phys. J. C 71 (2011) 1756 [1101.3270]. [20] J. Nishimura and S. Shimasaki, New Insights into the Problem with a Singular Drift Term in the Complex Langevin Method, Phys. Rev. D 92 (2015) 011501 [1504.08359]. [21] M. Scherzer, E. Seiler, D. Sexty and I.-O. Stamatescu, Complex Langevin and boundary terms, Phys. Rev. D 99 (2019) 014512 [1808.05187]. [22] M. Scherzer, E. Seiler, D. Sexty and I.O. Stamatescu, Controlling Complex Langevin simulations of lattice models by boundary term analysis, Phys. Rev. D 101 (2020) 014501 [1910.09427]. [23] D. Alvestad, R. Larsen and A. Rothkopf, Towards learning optimized kernels for complex [24] E. Seiler, D. Sexty and I.-O. Stamatescu, Complex Langevin: Correctness criteria, boundary terms, and spectrum, Phys. Rev. D 109 (2024) 014509 [2304.00563]. [25] M.W. Hansen and D. Sexty, Testing dynamical stabilization of Complex Langevin simulations of QCD, 2405.20709. [26] G. Aarts, Complex Langevin dynamics at finite chemical potential: Mean field analysis in the relativistic Bose gas, JHEP 05 (2009) 052 [0902.4686]. [27] G. Aarts, P. Giudice and E. Seiler, Localised distributions and criteria for correctness in complex Langevin dynamics, Annals Phys. 337 (2013) 238 [1306.3075]. [28] J. Sohl-Dickstein, E.A. Weiss, N. Maheswaranathan and S. Ganguli, Deep unsupervised learning using nonequilibrium thermodynamics, in Proc. 32nd Int. Conf. Int. Conf. Mach. Learn. - Vol. 37, pp. 2256–2265, 2015 [1503.03585]. [29] J. Ho, A. Jain and P. Abbeel, Denoising diffusion probabilistic models, in Proc. 34th Int. Conf. Neural Inf. Process. Syst., pp. 6840–6851, 2020 [2006.11239]. [30] Y. Song and S. Ermon, Generative Modeling by Estimating Gradients of the Data [31] Y. Song, J. Sohl-Dickstein, D.P. Kingma, A. Kumar, S. Ermon and B. Poole, Score-based generative modeling through stochastic differential equations, 2011.13456. [32] L. Yang, Z. Zhang, S. Hong, R. Xu, Y. Zhao, Y. Shao et al., Diffusion Models: A Comprehensive Survey of Methods and Applications, 2209.00796. [33] Y. Song, C. Durkan, I. Murray and S. Ermon, Maximum likelihood training of score-based diffusion models, 2101.09258. [34] T. Karras, M. Aittala, T. Aila and S. Laine, Elucidating the design space of diffusion-based generative models, 2206.00364. [35] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu and M. Chen, Hierarchical Text-Conditional Image Generation with CLIP Latents, 2204.06125. [36] R. Rombach, A. Blattmann, D. Lorenz, P. Esser and B. Ommer, High-Resolution Image Synthesis with Latent Diffusion Models, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2022) 10684 [2112.10752]. [37] L. Wang, G. Aarts and K. Zhou, Diffusion models as stochastic quantization in lattice field theory, JHEP 05 (2024) 060 [2309.17082]. [38] L. Wang, G. Aarts and K. Zhou, Generative Diffusion Models for Lattice Field Theory, in 37th Conference on Neural Information Processing Systems, 2023 [2311.03578]. [39] Q. Zhu, G. Aarts, W. Wang, K. Zhou and L. Wang, Diffusion models for lattice gauge field simulations, in 38th conference on Neural Information Processing Systems, 2024 [2410.19602]. [40] G. Aarts, D.E. Habibi, L. Wang and K. Zhou, On learning higher-order cumulants in diffusion models, in 38th conference on Neural Information Processing Systems, 2024 [2410.21212]. [41] Y. Hirono, A. Tanaka and K. Fukushima, Understanding Diffusion Models by Feynman’s [42] K. Fukushima and S. Kamata, Stochastic quantization and diffusion models, 2411.11297. [43] B.D.O. Anderson, Reverse-time diffusion equation models, Stochastic Processes and their [44] A. Hyvärinen, Estimation of Non-Normalized Statistical Models by Score Matching, Journal of Machine Learning Research 6 (2005) 695. [45] C.C. Chang, Numerical solution of stochastic differential equations with constant diffusion coefficients, Math. Comp. 49 (1987) 523. [46] M. Tancik, P.P. Srinivasan, B. Mildenhall, S. Fridovich-Keil, N. Raghavan, U. Singhal et al., Fourier features let networks learn high frequency functions in low dimensional domains, 2006.10739. [47] Y. LeCun, L. Bottou, G.B. Orr and K.R. Müller, Efficient BackProp, in Neural Networks: Tricks of the Trade, G.B. Orr and K.-R. Müller, eds., pp. 9–50, Springer Berlin Heidelberg (1998), DOI. [48] D.E. Habibi, G. Aarts, L. Wang and K. Zhou,",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2412/2412.01919v1.pdf",
         "extracted",
         "None",
         "",
         "Diffusion models learn distributions generated by complex Langevin dynamics"
        ],
        [
         "35",
         "01891feafb883a81f4c532208e34dcb5806d8ca5",
         "Exopolysaccharides (EPSs) synthesized by thermophilic bacteria are natural biopolymers, that have recently garnered attention due to their potential applications in areas such as pharmaceuticals and biomedicine. In this study, EPSs produced by five distinct thermophilic bacterial isolates from hot springs in Turkey were purified using ion exchange and gel chromatography, and the larvicidal and cytotoxic effects of these EPSs were examined. While Geobacillus thermodenitrificans HBB111 produced the highest quantity (650.9 mg mL-1) of EPS, the protein content of crude EPS samples ranged from 0.3 to 1.5%. EPS111 and EPS261 showed the most effective larvicidal action, eliminating 72% and 62.7% of Ae. albopictus larvae after 48 h, respectively. Among the purified samples, EPS111 exhibited the most significant effect on the proliferation of PC3 cells, resulting in a 68% inhibition (IC50 of 0.23 mg mL-1) followed by EPS106 in 55% (IC50 of 0.45 mg mL-1). According to our study's results, thermophilic EPSs show promise because of their insecticidal and anticancer properties.",
         "Mehmet Aytar,Demet Yalçın Bingül,M. Touray,D. A. Uygun,Gamze Başbülbül",
         "\n**BLOCK**fs== 24.0**p== 0.0**b== 0.7**t== 0.2**l== 0.0**r== 0.1**\nLarvicidal and Cytotoxic Activities of\nExopolysaccharides Produced by Thermophilic\nBacteria\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.0**r== 0.8**\nMehmet AYTAR\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\nAydın Adnan Menderes University\n**BLOCK**fs== 12.0**p== 0.0**b== 0.7**t== 0.3**l== 0.0**r== 0.8**\nDemet Yalçın Bingül\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.6**\nAydın Adnan Menderes University\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nMustafa Touray\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nAydın Adnan Menderes University\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nDeniz Aktaş Uygun\n**BLOCK**fs== 12.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nAydın Adnan Menderes University\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.0**r== 0.8**\nGAMZE BAŞBÜLBÜL\n**BLOCK**fs== 12.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nAydın Adnan Menderes University\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.8**\nResearch Article\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nKeywords: Exopolysaccharides, Geobacillus, Anoxybacillus, Parageobacillus, thermophilic bacteria,\n**BLOCK**fs== 12.0**p== 0.0**b== 0.3**t== 0.6**l== 0.0**r== 0.7**\nlarvicidal activity, cytotoxicity\n**BLOCK**fs== 12.0**p== 0.0**b== 0.3**t== 0.7**l== 0.0**r== 0.7**\nPosted Date: November 4th, 2024\n**BLOCK**fs== 12.0**p== 0.0**b== 0.3**t== 0.7**l== 0.0**r== 0.5**\nDOI: https://doi.org/10.21203/rs.3.rs-5304452/v1\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.7**l== 0.0**r== 0.1**\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.\nRead Full License\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.8**l== 0.0**r== 0.4**\nAdditional Declarations: No competing interests reported.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nEPSs synthesized by thermophilic bacteria are natural biopolymers that have recently garnered attention\n**BLOCK**fs== 12.0**p== 1.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\ndue to their potential applications in areas such as pharmaceuticals and biomedicine. In this study, EPSs\nproduced by \u0000ve distinct thermophilic bacterial isolates from hot springs in Turkey were puri\u0000ed using\nion exchange and gel chromatography, and the larvicidal and cytotoxic effects of these EPSs were\nexamined. While Geobacillus thermodenitri\u0000cans HBB111 produces the highest quantity (650,9 µg/mL)\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.2**l== 0.0**r== 0.0**\nof EPS, the protein content of crude EPS samples ranges from 0.3–1.5%. EPS111 and EPS261 showed\nthe most effective larvicidal action, eliminating 72% and 62.7% of Ae. albopictus larvae after 48 hours,\nrespectively. Among the puri\u0000ed samples, EPS111 exhibited the most signi\u0000cant effect on the\nproliferation of PC3 cells, resulting in a 68% inhibition (IC50 of 0,23 mg/mL) followed by EPS106 in a 55%\n(IC50 of 0,45 mg/mL). According to the results of our study, thermophilic EPSs demonstrate potential due\nto their insecticidal and anticancer properties.\n**BLOCK**fs== 18.0**p== 1.0**b== 0.6**t== 0.4**l== 0.0**r== 0.7**\nINTRODUCTION\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nExopolysaccharides (EPSs) are high molecular weight carbohydrate biopolymers composed of sugar\nresidues [1]. They are secreted into the environment by producing microorganisms and can offer various\nbene\u0000cial properties and functions to these microorganisms, including protection against predation,\n**BLOCK**fs== 12.0**p== 1.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nbio\u0000lm formation, the creation of a biocompatible extracellular environment, adhesion, molecular\nrecognition, and intercellular signal transmission [2, 3, 4, 5].\n**BLOCK**fs== 12.0**p== 1.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nThermophilic microorganisms can thrive at elevated temperatures, and EPS production is proposed as\n**BLOCK**fs== 12.0**p== 1.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\none of their adaptation mechanisms for survival in extreme conditions. Thermophilic bacteria are\nparticularly bene\u0000cial for producing industrially signi\u0000cant EPSs, owing to their non-pathogenic nature\nand rapid growth rate [6]. EPSs synthesized by thermophiles are highly thermostable when compared to\nmesophilic ones and can display various biological activities, including antioxidant properties, non-\ncytotoxicity, anti-diabetic effects, prebiotic and \u0000brinolytic activities, as well as anti-viral and\nimmunostimulant effects [7, 8, 9, 10, 11].\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.7**l== 0.0**r== 0.1**\nMembers of the genera Geobacillus, Parageobacillus, and Anoxybacillus are natural inhabitants of\ngeothermal areas, such as hot springs and hydrothermal vents, and they typically grow rapidly in\nrelatively simple and cost-effective media [12, 10]. While numerous studies focus on mesophilic\nproducers, research on thermophilic exopolysaccharides is rarely reported in the literature. Therefore,\nstudies on the production and biological characterization of EPSs from thermophilic bacilli will yield\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.8**l== 0.0**r== 0.5**\nmore insights into their biotechnological applications.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nIn this study, EPSs produced by \u0000ve thermophilic bacterial strains were puri\u0000ed and assessed for their\n**BLOCK**fs== 12.0**p== 1.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nbiological characterization. The larvicidal activities and cytotoxic effects of thermophilic EPSs were\nexamined. To our knowledge, there are no studies in the literature regarding the larvicidal activity of EPSs\n**BLOCK**fs== 12.0**p== 2.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nproduced by species from the Geobacillus, Parageobacillus, and Anoxybacillus genera. Furthermore, our\nreport is the \u0000rst to evaluate thermophilic EPSs in the PC3 and RWPE1 cell lines.\n**BLOCK**fs== 18.0**p== 2.0**b== 0.8**t== 0.2**l== 0.0**r== 0.6**\nMATERIAL AND METHODS\n**BLOCK**fs== 21.0**p== 2.0**b== 0.8**t== 0.2**l== 0.0**r== 0.3**\nTaxonomic analysis of bacterial isolates\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nThermophilic bacterial strains, HBB-20, HBB-74, HBB-106, HBB-111 and HBB-261 were previously\nisolated from hot springs and sediment samples [13] and used for EPS production. 16S rRNA analysis\n**BLOCK**fs== 12.0**p== 2.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nbased molecular identi\u0000cation of isolates was done [9] and the sequence data were deposited in\nGenBank, under accession numbers OR896930, OR896946, OR896962, OR896966, OR897006 for HBB-\n20, HBB-74, HBB-106, HBB-111 and HBB-261, respectively.\n**BLOCK**fs== 12.0**p== 2.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nThe 16S rRNA gene sequences of strains HBB 20, 74, 106, 111, and 261, along with those of twenty-\u0000ve\nclosely related strains obtained from GenBank, were aligned using MUSCLE. A phylogenetic tree for the\nisolates was then constructed using the neighbor-joining method with 1000 bootstrap replicates in\nMEGA11: Molecular Evolutionary Genetics Analysis Version 11 software.\n**BLOCK**fs== 18.0**p== 2.0**b== 0.5**t== 0.5**l== 0.0**r== 0.3**\nExtraction and puri\u0000cation of exopolysaccharides\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.5**l== 0.0**r== 0.0**\nEPSs of \u0000ve thermophilic bacteria were extracted by the following method. Firstly, thermophilic bacteria\nwere cultured in basal media (0.1% (NH4)2HPO4, 0.01% MgSO4, 1% yeast extract, 0.02% KCl, 0.00001%\nthiamine, 2% sucrose, pH 7.2) at 55°C, 180 rpm for 18–24 h [14]. Then, cells were removed by\ncentrifugation at 5000 rpm for 10 min, and 10 mL of concentrated supernatants were treated with\ntrichloroacetic acid (4% w/v) to remove proteins. After shaking at 180 rpm for 30 min at room\ntemperature supernatants were precipitated by adding two volumes of ethanol (95%) at 4°C. The\nprecipitates were separated by centrifugation at 5000 rpm for 10 min and then dissolved in 10 mL of\ndistilled water. After the determination of total carbohydrates was completed, samples were lyophilized\nand stored at -80 ℃ [15, 16].\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nTo purify the EPSs ion exchange chromatography with the DEAE Cellulose (30477, Sigma-Aldrich) was\n**BLOCK**fs== 12.0**p== 2.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nused. The EPSs were eluted with a linear gradient of 0.1–1 mol/L NaCl with a \u0000ow rate of 1 mL/min. Both\nsize separation and desalination were applied to the fractions collected by gel \u0000ltration chromatography.\nFor this purpose, Sephadex G-100 column was used and the \u0000ow rate was set at 0.5 mL/min [17, 18].\n**BLOCK**fs== 18.0**p== 2.0**b== 0.1**t== 0.8**l== 0.0**r== 0.4**\nDetermination of protein and sugar content\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.9**l== 0.0**r== 0.1**\nThe Bradford method was used to determine the protein concentration in crude EPS samples [19].\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nBovine Serum Albumin (BSA) was prepared as a standard. Protein sample (25µL) was added into 1 mL\nBradford solution and, after mixing it was kept at room temperature for 10 min. Two hundred microliters\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\nof the mixture were transferred to the microplate and distilled water was added to the dye instead of the\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.0**r== 0.4**\nblank protein. Optical density (OD) was measured at 595 nm [20].\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nThe method for determining total carbohydrate amounts in the samples was adapted from Masuko et al.\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\n[21]. Brie\u0000y, 250 µL of the sample was mixed with 750 µL of concentrated sulfuric acid, followed by the\n**BLOCK**fs== 12.0**p== 3.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\naddition of 150 µL of phenol solution (5% w/v). After incubating the mixture at 90°C for 5 minutes, the\noptical density (OD) was measured at 491 nm. The total carbohydrate content was determined using a\n**BLOCK**fs== 12.0**p== 3.0**b== 0.7**t== 0.2**l== 0.0**r== 0.5**\nstandard calibration curve prepared with glucose.\n**BLOCK**fs== 18.0**p== 3.0**b== 0.7**t== 0.3**l== 0.0**r== 0.2**\nLarvicidal (Insecticidal) activities of exopolysaccharides\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.3**l== 0.0**r== 0.1**\nLarvicidal activities of EPSs extracted from thermophilic bacterial strains were investigated against\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nAedes albopictus in 24 well plates [22]. Eggs were collected from adult Ae. albopictus kept in cages (30\n**BLOCK**fs== 12.0**p== 3.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\n× 30 × 30 cm) in a controlled temperature room at 30°C and 12 h light: 12 h dark photoperiod and\nhatched in tap water. Larvae were fed on crushed ground \u0000sh food until they reached 3rd stage [23, 24].\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.4**l== 0.0**r== 0.1**\nIn the experiments, 3rd stage larvae were distributed into wells in 24-well plates and then one mL of\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nextracted EPS diluted in distilled water was added to wells. At \u0000rst the effects of the EPS at 100 µg/mL\nwere evaluated and then the most effective two EPSs were further diluted to concentrations of 50, 20\n**BLOCK**fs== 12.0**p== 3.0**b== 0.5**t== 0.5**l== 0.0**r== 0.1**\nand 10 µg/mL. Distilled water alone was used as a negative control. Larvae were fed with ground \u0000sh\nfood. The study was conducted twice with at least 10 replicates per treatment. The plates were\n**BLOCK**fs== 12.0**p== 3.0**b== 0.4**t== 0.5**l== 0.0**r== 0.2**\nincubated at 26 ± 1°C. Larval mortality was larvae after 24 and 48 h exposures [22].\n**BLOCK**fs== 18.0**p== 3.0**b== 0.4**t== 0.6**l== 0.0**r== 0.8**\nCell culture\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nHuman prostate cancer cell line (PC-3) (CRL-1435, ATCC) and the normal prostate epithelial cell line\n(RWPE1) (CRL-11609, ATCC) were kindly provided by Prof. Dr. Sarhan Sakarya. PC3 cells were cultured in\n**BLOCK**fs== 12.0**p== 3.0**b== 0.2**t== 0.7**l== 0.0**r== 0.0**\nDulbecco's Modi\u0000ed Eagle's Medium supplemented with 10% (v/v) heat-inactivated fetal bovine serum\n(FBS), 100 IU/mL penicillin and 100 µg/mL streptomycin in a humidi\u0000ed incubator (5% CO2 at 37 oC).\nRWPE1 cells were grown in Roswell Park Memorial Institute (RPMI) 1640 medium with 20% (v/v) FBS, 1%\npenicillin and streptomycin in a humidi\u0000ed atmosphere containing 5% CO2 at 37 oC. The cell lines were\ncultured in the culture plate, and the experiment was carried out when the cells entered the logarithmic\ngrowth period. H2O2 was dissolved in DMEM (serum-free) and stock solutions were prepared before\ntreatment.\n**BLOCK**fs== 21.0**p== 3.0**b== 0.1**t== 0.8**l== 0.0**r== 0.7**\nCytotoxicity test\n**BLOCK**fs== 12.0**p== 3.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nThe inhibitory effects of both crude and puri\u0000ed EPSs on normal and cancer cell lines were investigated\nusing the MTT assay. Both RWPE1 and PC3 (5x103 cells/well) were incubated in their own culture media\ndescribed above and in a humidi\u0000ed atmosphere containing 5% CO2 for 24 h at 37°C. The cytotoxic\n**BLOCK**fs== 12.0**p== 4.0**b== 0.9**t== 0.1**l== 0.0**r== 0.0**\neffect was determined using a 96 well microtiter plate assay with \u0000ve different EPS samples prepared at\n**BLOCK**fs== 12.0**p== 4.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\ndifferent concentrations (250, 500, 1000 and 2000 µg/mL) with serum-free medium [25]. The medium\nwas subsequently replaced with 100 µL of EPS added to each well and incubated at 37°C for 24 h. After\ntreatment, the cells were incubated with 10 µL MTT reagent (5 mg/mL) for 4 h at 37ºC under 5% CO2.\nSupernatants were removed and the formazan crystals were dissolved in 150 µL of DMSO. The mixture\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nwas shaken up in the dark for 15 min, the absorption value of each well was determined at 490 nm by\nmicroplate reader. DMSO was used as a control. All the experiments were performed three times and the\npercentage of cell viability is calculated by using the Eq. (1) [26].\n**BLOCK**fs== 12.0**p== 4.0**b== 0.7**t== 0.3**l== 0.0**r== 0.5**\nCell viability %= (ODsample / ODcontrol) × 100 (1)\nStatistical analysis\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nStatistical analyses were conducted in the SPSS software program. ANOVA was used to analyze data on\nthe effects of EPS on mosquito larvae and the differences among the averages were grouped using\n**BLOCK**fs== 12.0**p== 4.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nTukey’s test at the level of P = 0.05. Arcsine transformation was performed on larval mortality before\nstatistical analyses. Probit analysis was used to calculate LC50 values.\n**BLOCK**fs== 18.0**p== 4.0**b== 0.5**t== 0.5**l== 0.0**r== 0.8**\nRESULTS\n**BLOCK**fs== 21.0**p== 4.0**b== 0.5**t== 0.5**l== 0.0**r== 0.3**\nTaxonomic analysis of thermophilic isolates\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nAccording to 16S rDNA sequence analysis results, HBB-20, HBB-111 and HBB-261 showed the highest\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nhomology ratios (94,35%-100%) with Geobacillus thermodenitri\u0000cans strains. At the same time, HBB-74\n**BLOCK**fs== 12.0**p== 4.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nand HBB-106 were identi\u0000ed as Anoxybacillus suryakundensis and Parageobacillus thermoglucosidasius\nwith 100% and 99,21% similarity rates, respectively [8, 9].\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.6**l== 0.0**r== 0.1**\nNeighbor-joining method with 1000 bootstrap replicates in MEGA11 was applied to 16S rRNA gene\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nsequences of isolates and selected similar thermophilic sequences to construct a phylogenetic tree\n(Fig. 1). As can be seen from the phylogenetic tree, HBB-20, HBB-111 and HBB-261 constitute branches\n**BLOCK**fs== 12.0**p== 4.0**b== 0.3**t== 0.7**l== 0.0**r== 0.2**\nin G. thermodenitri\u0000cans cluster. On the other hand, while HBB-74 forms a branch with A.\nsuryakundensis, HBB-106 forms a branch with P. thermoglucosidasius.\n**BLOCK**fs== 21.0**p== 4.0**b== 0.2**t== 0.8**l== 0.0**r== 0.4**\nIsolation and puri\u0000cation of EPSs\n**BLOCK**fs== 12.0**p== 4.0**b== 0.2**t== 0.8**l== 0.0**r== 0.1**\nAmong the crude culture supernatants, the highest EPS content was detected in that of HBB-111 with\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\n650,9 mg/L, followed by HBB-20 (419,4 mg/L), HBB-261 (357,6 mg/L), HBB-106 (352,2 mg/L) and HBB-\n74 (269,7 mg/L). Puri\u0000cation percentages and plots of EPSs are detailed in publications of Aytar et al [8,\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\n9]. While the highest loss was recorded for EPS111 (37.1%), pure EPS concentrations ranged from 193.9\n**BLOCK**fs== 12.0**p== 4.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nto 377.3 mg/mL (Fig. 2). The protein content of crude EPS samples was found to vary between 1,3 and\n5,2 mg/L (Fig. 3).\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nSigni\u0000cant differences were observed in the larval susceptibility to EPSs extracted from different\nthermophilic bacteria. After 24h, EPS 111 and EPS 261 were the most effective, killing 67 and 56% of Ae.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nalbopictus larvae respectively, while the effects of the other EPSs varied between 5 and 41% (F = 22.401;\ndf = 5,102; P < 0.001). After 48 hours, effects of EPS111 and EPS261 increased to 72 and 62 percent up\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nfrom 67 and 56% respectively. EPS 111 and 261 were statistically more effective than those of EPS20,\nEPS74 and EPS106 (F = 29.126; df = 5,107; P < 0.001) (Fig. 4).\n**BLOCK**fs== 12.0**p== 5.0**b== 0.7**t== 0.3**l== 0.0**r== 0.1**\nA downward trend was noted in the mortality rate of Ae. albopictus larvae treated with different\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nconcentrations (100, 50, 20, and 10 µg/mL) of the two most effective EPSs, namely EPS111 and EPS261\n(Fig. 5). After 24 and 48 hours, 10 µg/mL EPS26 was notably less effective than higher concentrations\n(100, 50, and 20 µg/mL) (F24 h: =20.706, df = 3,50, P < 0.001; F48 h: =22.084, df = 3,50, P < 0.001).\nConversely, for EPS111, concentrations ranging from 20–100 µg/mL were signi\u0000cantly higher than the\n**BLOCK**fs== 12.0**p== 5.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\n10 µg/mL concentration after both 24 and 48 hours (P < 0.001) (Fig. 7). After 24-hours exposure, the\nLC50 of EPS261 and EPS111 were 38 µg/mL and 95,5 µg/mL.\n**BLOCK**fs== 21.0**p== 5.0**b== 0.5**t== 0.5**l== 0.0**r== 0.6**\nCytotoxicity of EPSs\n**BLOCK**fs== 12.0**p== 5.0**b== 0.5**t== 0.5**l== 0.0**r== 0.0**\nWhen crude EPSs were tested on RWPE1 and PC3 cell lines at concentrations ranging from 25 to 1000\nµg /ml, no signi\u0000cant inhibitory effect was observed in either cell line (Fig. 6). Among the EPS samples at\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\na concentration of 2000 µg/ml, the least cytotoxic to healthy RWPE1 cells are EPS111, EPS261, EPS74,\nEPS20, and EPS106, respectively. When EPSs were tested at the same concentration on the PC3 cell line,\n**BLOCK**fs== 12.0**p== 5.0**b== 0.4**t== 0.6**l== 0.0**r== 0.1**\nthe most signi\u0000cant inhibitory effect was observed for EPS20, while EPS111 showed the least\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\neffectiveness. At a concentration of 2000 mg/ml, EPS20 achieved a high kill percentage in PC3 cells,\nrecording 68% with an IC50 value of 1.28 mg/mL. The second most effective compound, EPS74, also\ndemonstrated 68% e\u0000cacy with an IC50 of 1.36 mg/mL. Since two of the crude EPSs tested, EPS20 and\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nEPS106, exhibited cytotoxicity in healthy RWPE1 cells (49% and 56%, respectively), the maximum\nconcentration to be tested in experiments with puri\u0000ed samples was established at 500 µg/ml.\n**BLOCK**fs== 12.0**p== 5.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nThe cell viability of RWPE1 cells exposed to puri\u0000ed EPSs in the concentration range of 3.9–500 µg/mL\n**BLOCK**fs== 12.0**p== 5.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nwas above 50% at all concentrations (Fig. 7). When raw EPS samples were applied at a concentration of\n500 mg/mL, cell viability ranged from 98–120% for RWPE1 cells, whereas this rate was 92–122% for PC3\ncells. There is a signi\u0000cant increase in inhibition when puri\u0000ed EPSs are tested at the same\nconcentration. Viability rates ranged from 54–97% for RWPE1 cells and 32–72% for PC3 cells. EPS111\n**BLOCK**fs== 12.0**p== 5.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nexhibited the most signi\u0000cant effect on the proliferation of PC3 cells, resulting in a 68% inhibition (IC50\nof 0,23 mg/mL) followed by EPS106 in a 55% (IC50 of 0,45 mg/mL).\n**BLOCK**fs== 18.0**p== 5.0**b== 0.1**t== 0.9**l== 0.0**r== 0.8**\nDISCUSSION\n**BLOCK**fs== 12.0**p== 6.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nPublications in the literature regarding EPSs produced by thermophilic bacteria and their biological\nactivities are relatively scarce compared to those from mesophilic producers. EPS production levels of\nsome thermophilic bacteria were given as follows; Geobacillus sp. TS3-9, 87 µg/mL [11], G.\nthermodenitrifcans ArzA-6, 76 µg/mL; G. toebii ArzA-8, 80 µg/mL [27], Geobacillus sp. strain WSUCF1,\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\n404 µg/mL [10], Bacillus licheniformis BITSL006, 45 µg/mL [28], Aeribacillus pallidus 418, 80 µg/mL [14],\nGeobacillus sp. 4004, 60 µg/mL [5], Parageobacillus thermantarcticus 400 µg/mL [29]. When we\nexamined the EPS production levels (269,7 to 650,9 µg/mL) of the isolates used in our study, we found\nthat they were comparable to those of other thermophilic Gram-positive producers. Considering the total\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nprotein content of EPSs, it is calculated to be 0.3%, 1.4%, 1.5%, 0.3%, and 1.2% for EPS20, EPS74,\nEPS106, EPS111, and EPS206, respectively. Similarly, the EPS produced by G. tepidamans V264 contains\n1.8% protein, whereas the EPS produced by thermophilic B. thermoantarcticus has 2% protein [30, 31].\n**BLOCK**fs== 12.0**p== 6.0**b== 0.6**t== 0.3**l== 0.0**r== 0.0**\nAccording to Genc et al. the amount of total protein in EPS solution obtained from Anoxybacillus\npushchinoensis G11 was determined as 1.08% [32]. Among the EPSs, only EPS111 was thoroughly\ncharacterized in our previous publication, which revealed that it consists of hexose (glucose, fructose,\ngalactose, and mannose) and pentose sugars [8]. Comprehensive chemical analyses of the remaining\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.4**l== 0.0**r== 0.0**\nfour EPSs are scheduled for future studies. Again, based on the \u0000ndings of our previous study [8] it was\ndemonstrated that none of the EPSs exhibited cytotoxic effects on blood cells, prompting us to explore\nthe larvicidal and anticancer activities of these metabolites.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nNovel strategies to reduce mosquito populations are an urgent priority. Applying EPS to mosquito\nbreeding sites could help mitigate the risks of mosquito-borne diseases. To our knowledge, there are\ncurrently no reports regarding the larvicidal activity of EPS derived from members of the Parageobacillus,\n**BLOCK**fs== 12.0**p== 6.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nor Anoxybacillus genera. In a study conducted by Siddharthan et al. the larvicidal bioactivity of\nGeobacillus thermodenitri\u0000cans PS41 was assessed, revealing insecticidal activity against third-instar\nlarvae of Spodoptera litura, which resulted in a mortality rate of 60.26 ± 1.5%. However, the trials utilized\nextracted secondary metabolites rather than EPS [33].\n**BLOCK**fs== 12.0**p== 6.0**b== 0.1**t== 0.7**l== 0.0**r== 0.0**\nOur study revealed the larvicidal effects of thermophilic EPSs against Aedes albopictus, a major vector\nof arboviral diseases such as Chikungunya, dengue fever, and yellow fever. Among the tested bacterial\nEPSs, 111 and EPS261 were the most effective with LC50 values after 24 hours were 38 µg/mL and 95.5\nµg/mL, respectively. The larvicidal activity of EPS obtained from Bacillus licheniformis was tested\nagainst the larvae of Anopheles stephensi, a vector for Plasmodium sp. parasites, and Ae. aegypti,\nwhich, like Ae. albopictus transmits arboviruses [34]. The LC50 and LC90 values of Bl-EPS against An.\nstephensi were 61.31 and 127.45 µg/mL, and against Ae. aegypti were 79.28 and 150.68 µg/mL,\nrespectively. These EPS exhibited maximum mortality against both vectors at 150 µg/mL. Similarly, EPS\nproduced by Pseudomonas aeruginosa B01 exhibited potent larvicidal activity against an unspeci\u0000ed\nmosquito species at a concentration of 10 mg/dL [35].\n**BLOCK**fs== 12.0**p== 6.0**b== 0.0**t== 0.9**l== 0.0**r== 0.0**\nWhen evaluating the antitumor effects of the thermophilic EPSs used in this study, puri\u0000ed samples\ndemonstrate a greater inhibitory effect on both healthy and cancerous cells compared to raw EPSs\n(Table 1). Several in vitro studies have demonstrated that puri\u0000ed polysaccharides are more functional\n**BLOCK**fs== 12.0**p== 7.0**b== 0.8**t== 0.1**l== 0.0**r== 0.0**\nthan crude polysaccharides [36, 37]. The anticancer properties of EPSs may result from other unwanted\ncomponents or impurities present in the samples examined. Therefore, to assert that the activity in the\nstudied material is attributable to EPS, the metabolite must be obtained and utilized in high purity. In our\nstudy, the reason pure samples exhibited superior results regarding anticancer activity may stem from\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nthe release of speci\u0000c functional groups, such as sulfate and uronic acid, which can be found in EPSs\nthrough puri\u0000cation. Additionally, the varying rates at which thermophilic EPSs exhibit anticancer effects\nmay be attributed to differences in their molecular weights and monosaccharide structures. However,\nmore detailed chemical and structural analyses are required to validate these assertions.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.3**l== 0.0**r== 0.0**\nTable 1\nViability percentages of RWPE1 and PC3 cell lines treated with crude and puri\u0000ed EPS at a concentration\nof 500 mg/mL, along with IC50 values of EPS.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nCRUDE SAMPLES\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.2**\nPURIFIED SAMPLES\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.2**r== 0.7**\nRWPE1 cell line\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\nPC3 cell line\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\nRWPE1 cell line\n**BLOCK**fs== 12.0**p== 7.0**b== 0.6**t== 0.4**l== 0.8**r== 0.1**\nPC3 cell line\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.2**r== 0.8**\nCell\nviability\n(%)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.3**r== 0.7**\nIC50\nvalue\n(mg/mL)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.4**r== 0.6**\nCell\nviability\n(%)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.5**r== 0.5**\nIC50\nvalue\n(mg/mL)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.6**r== 0.4**\nCell\nviability\n(%)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.7**r== 0.2**\nIC50\nvalue\n(mg/mL)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.8**r== 0.1**\nCell\nviability\n(%)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.9**r== 0.0**\nIC50\nvalue\n(mg/mL)\n**BLOCK**fs== 12.0**p== 7.0**b== 0.3**t== 0.6**l== 0.0**r== 0.0**\nIn our study, the sample exhibiting the most effective anticancer activity against PC3 while maintaining\nthe highest viability of RWPE1 cells is the puri\u0000ed form of EPS111, with an IC50 value of 0.23 mg/mL. It\nis followed by pure EPS106, which has an LC50 value of 0.45 mg/mL and inhibited PC3 cells by 55%.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.2**t== 0.7**l== 0.0**r== 0.1**\nIt was reported that EPS puri\u0000ed from Bacillus licheniformis AG-06, exhibited signi\u0000cant cytotoxic\nactivity (IC50 value of 37.5 ± 0.87 µg/mL) against human lung carcinoma cells (A549) and thus\ndemonstrates strong anticancer potential [38]. In another study, it was found that crude EPS derived\n**BLOCK**fs== 12.0**p== 7.0**b== 0.1**t== 0.8**l== 0.0**r== 0.0**\nfrom Anoxybacillus pushchinoensis G11 showed a cytotoxic effect on A-549 and colon cancer (Caco-2\nand HT-29) cell lines at a concentration of 2.5 mg/mL [32]. Wang et al. evaluated the antitumor activity of\npuri\u0000ed samples of EPS from Geobacillus sp. TS3-9 strain on hepatoma carcinoma cells (HepG2) using\nMTT analysis. The inhibitory effect of EPS on the proliferation of HepG2 was dose-dependent at\n**BLOCK**fs== 12.0**p== 7.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nconcentrations ranging from 4 µg/mL to 100 µg/mL, with the inhibition rate varying from 2.2–16.9%,\nrespectively [11]. Two exopolysaccharides (EPS-1 and EPS-2) puri\u0000ed from the Geobacillus sp. WSUCF1\nstrain exhibited no cytotoxicity against human embryonic kidney-293 (HEK-293) cells at concentrations\nof 2 and 3 mg/mL, respectively [10]. Arena et al. revealed that exopolysaccharide (EPS-2) produced by G.\n**BLOCK**fs== 12.0**p== 8.0**b== 0.9**t== 0.1**l== 0.0**r== 0.1**\nthermodenitri\u0000cans B3-72 strain inhibited HSV-2 replication in human peripheral blood mononuclear\ncells (PBMC), but not in WISH cells [7].\n**BLOCK**fs== 18.0**p== 8.0**b== 0.8**t== 0.2**l== 0.0**r== 0.8**\nCONCLUSION\n**BLOCK**fs== 12.0**p== 8.0**b== 0.8**t== 0.2**l== 0.0**r== 0.0**\nIn this study, we aimed to isolate and purify novel exopolysaccharides from thermophilic isolates and\ninvestigate their biological activities. Among the \u0000ve EPSs we tested, EPS111 and EPS261 distinguished\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.2**l== 0.0**r== 0.0**\nthemselves with their larvicidal activities, while EPS106 and EPS111 exhibited a notable inhibitory effect\non the proliferation of PC3 cells. Considering all this, among the EPSs we studied, especially EPS111,\nEPS106, and EPS261 stand out for their unique and valuable biological activities. However, in future\nstudies, these natural and potential exopolysaccharides must be analyzed in detail and tested in vivo and\n**BLOCK**fs== 12.0**p== 8.0**b== 0.7**t== 0.3**l== 0.0**r== 0.5**\nclinically to guarantee the e\u0000cacy of the EPSs.\n**BLOCK**fs== 18.0**p== 8.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nDeclarations\n**BLOCK**fs== 12.0**p== 8.0**b== 0.6**t== 0.4**l== 0.0**r== 0.8**\nCOI description\n**BLOCK**fs== 12.0**p== 8.0**b== 0.5**t== 0.4**l== 0.0**r== 0.5**\nThe authors have no con\u0000icts of interest to declare.\n**BLOCK**fs== 21.0**p== 8.0**b== 0.5**t== 0.5**l== 0.0**r== 0.6**\nAuthor Contribution\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.5**l== 0.0**r== 0.0**\nG.B. was responsible for the organization and coordination of the study. D.A.U., planned and performed\n**BLOCK**fs== 12.0**p== 8.0**b== 0.4**t== 0.6**l== 0.0**r== 0.0**\nEPS extraction and puri\u0000cation steps. M.A., D.Y.B and M.T. were the investigators and responsible for the\ndata collection and analysis. All authors contributed to the writing of the \u0000nal manuscript and reviewed\nthe manuscript.\n**BLOCK**fs== 21.0**p== 8.0**b== 0.3**t== 0.7**l== 0.0**r== 0.7**\nAcknowledgement\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nMehmet AYTAR and Demet YALÇIN BİNGÜL received funding from the Higher Education Council of\n**BLOCK**fs== 12.0**p== 8.0**b== 0.3**t== 0.7**l== 0.0**r== 0.4**\nTürkiye (YOK) as a participant of the 100/2000 PhD scholarship.\n**BLOCK**fs== 21.0**p== 8.0**b== 0.2**t== 0.8**l== 0.0**r== 0.7**\nData Availability\n**BLOCK**fs== 12.0**p== 8.0**b== 0.2**t== 0.8**l== 0.0**r== 0.0**\nSequence data were deposited in GenBank, under accession numbers OR896930, OR896946, OR896962,\nOR896966, OR897006 for HBB-20, HBB-74, HBB-106, HBB-111 and HBB-261, respectively.\n**BLOCK**fs== 18.0**p== 8.0**b== 0.1**t== 0.9**l== 0.0**r== 0.8**\nReferences\n**BLOCK**fs== 12.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n1. Wang J, Salem D, Sani R (2019b) Extremophilic exopolysaccharides: A review and new perspectives\n**BLOCK**fs== 12.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.0**\n2. Moriello V, Lama L, Poli A, Gugliandolo C, Maugeri T, Gambacorta A, Nicolaus B (2003) Production of\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nexopolysaccharides from a thermophilic microorganism isolated from a marine hot spring in\n\u0000egrean areas. J Ind Microbiol Biotechnol 30(2):95–101\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n3. Nicolaus B, Kambourova M, Oner E (2010) Exopolysaccharides from extremophiles: from\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nfundamentals to biotechnology. Environ Technol 31(10):1145–1158\n**BLOCK**fs== 12.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n4. Nicolaus B, Lama L, Esposito E, Manca M, Improta R, Bellitti M (1999) Haloarcula spp able to\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nbiosynthesize exo- and endopolymers. J Ind Microbiol Biotechnol 23(6):489–496\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\n5. Poli A, Anzelmo G, Nicolaus B (2010) Bacterial exopolysaccharides from extreme marine habitats:\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nproduction, characterization and biological activities. Mar Drugs 8(6):1779–1802\n**BLOCK**fs== 12.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n\u0000. Yasar Yildiz S, Anzelmo, Ozer T, Radchenkova N, Genç S, Di Donato P, .Kambourova M (2014)\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nBrevibacillus themoruber: a promising microbial cell factory for exopolysaccharide production. J\nAppl Microbiol 116(2):314–324\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n7. Arena A, Gugliandolo C, Stassi G, Pavone B, Iannello D, Bisignano G (2009) An exopolysaccharide\nproduced by Geobacillus thermodenitri\u0000cans strain B3-72: antiviral activity on immunocompetent\n**BLOCK**fs== 12.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\ncells. Immunol Lett 7 123:132\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n\u0000. Aytar M, Başbülbül G, Uygun DA (2024a) Characterization and biological activities of a novel\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\nexopolysaccharide produced from Geobacillus thermodenitri\u0000cans HBB 111 strain. Extremophiles\n**BLOCK**fs== 12.0**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.0**\n9. Aytar M, Uygun DA, Başbülbül G (2024b) Production and biological activities of exopolysaccharides\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nsynthesized by thermophilic bacilli isolated from hot springs in Türkiye. Int Microbiol 1–16\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n10. Wang J, Salem D, Sani R (2021) Two new exopolysaccharides from a thermophilic bacterium\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.2**\nGeobacillus sp. WSUCF1: Characterization and bioactivities. N Biotechnol 61:29–39\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n11. Wang L, Zhang, Yang L, Liang X, Zhang F, Linhardt RJ (2017) Structural characterization and\n**BLOCK**fs== 12.0**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\nbioactivity of exopolysaccharide synthesized by Geobacillus sp. TS3-9 isolated from radioactive\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nradon hot spring. Adv Biotechnol Microbiol 4:1–8\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.0**\n12. Gugliandolo C, Lentini V, Span`o A, Maugeri T (2012) New bacilli from shallow hydrothermal vents of\nPanarea Island (Italy) and their biotechnological potential. J Appl Microbiol 112(6):1102–1112\n**BLOCK**fs== 12.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.0**\n13. Başbülbül Özdemir G, Biyik HH (2012) Isolation and characterization of a bacteriocin-like substance\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.2**\nproduced by Geobacillus toebii strain HBB-247. Indian J Microbiol 52:104–108\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n14. Radchenkova N, Vassilev S, Panchev I, Anzelmo G, Tomova I, Nicolaus B, Kambourova M (2013)\nProduction and properties of two novel exopolysaccharides synthesized by a thermophilic\n**BLOCK**fs== 12.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.2**\nbacterium Aeribacillus pallidus 418. Appl Biochem Biotechnol 171(1):31–43\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.2**\n15. Bajpai V, Majumder R, Rather I, Kim K (2016) Extraction, isolation and puri\u0000cation of\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nexopolysaccharide from lactic acid bacteria using ethanol precipitation method. Bangladesh J\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\nPharmacol 11(3):573–576\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n1\u0000. Wang J, Zhao X, Yang Y, Zhao A, Yang Z (2015) Characterization and bioactivities of an\n**BLOCK**fs== 12.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nexopolysaccharide produced by Lactobacillus plantarum YW32. Int J Biol Macromol 74:119–126\n**BLOCK**fs== 12.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n17. Hu S, Zhou J, Zhou Q, Li P, Xie Y, Zhou, Gu Q (2021) Puri\u0000cation, characterization and biological\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nactivities of exopolysaccharides from Lactobacillus rhamnosus ZFM231 isolated from milk. LWT\n147:111561\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\n1\u0000. Ye S, Liu F, Wang J, Wang H, Zhang M (2012) Antioxidant activities of an exopolysaccharide isolated\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nand puri\u0000ed from marine Pseudomonas PF-6. Carbohydr Polym 87(1):764–770\n**BLOCK**fs== 12.0**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.0**\n19. Bradford MM (1976) A rapid and sensitive method for the quantitation of microgram quantities of\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.2**l== 0.1**r== 0.2**\nprotein utilizing the principle of protein-dye binding. Anal Biochem 72 (1–2): 248 – 25\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n20. Noble JE, Bailey MJ (2009) Quantitation of protein. Methods Enzymol 463:73–95\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\n21. Masuko T, Minami A, Iwasaki N, Majima T, Nishimura SI, Lee YC (2005) Carbohydrate analysis by a\n**BLOCK**fs== 12.0**p== 10.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\nphenol–sulfuric acid method in microplate format. Anal Biochem 339(1):69–72\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n22. Shah F, Abdoarrahem M, Berry C, Touray M, Hazir, Butt T (2021) Indiscriminate ingestion of\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nentomopathogenic nematodes and their symbiotic bacteria by Aedes aegypti larvae: a novel\nstrategy to control the vector of Chikungunya, dengue and yellow fever. Turk J Zool 45:372–383\n**BLOCK**fs== 12.0**p== 10.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n23. Bursalı F, Şahin Y, Aygün M, Sevincek R, Bıyık H, Özgener H, Gürbüz B (2024) 1, 2-Diboranes with\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.4**l== 0.1**r== 0.0**\nstrong donor substitutes: Synthesis, ovicidal and larvicidal effect on important vector species. Inorg\nChem Commun 162:112268\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n24. Bursalı F, Yavaşer Boncooğlu R, Fırıncı,Fırıncı E (2023) Synthesis, characterization, larvicidal and\n**BLOCK**fs== 12.0**p== 10.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nantioxidant activities of copper (II) complexes with barbiturate derivatives. Monatsh Chem\n154(7):793–799\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\n25. Mosmann T (1983) Rapid colorimetric assay for cellular growth and survival: application to\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nproliferation and cytotoxicity assays. J Immunol Methods 65(1–2):55–63\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.0**\n2\u0000. Zhang Y, Lv X, Hu Z, Ye X, Liu Q (2017) Protection of Mcc950 against high glucose- induced human\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.3**\nretinal endothelial cell dysfunction. Cell Death Discovery 8(7):e2941\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n27. Panosyan H, Di Donato P, Poli A, Nicolaus B (2018) Production and characterization of\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.0**\nexopolysaccharides by Geobacillus thermodenitri\u0000cans ArzA-6 and Geobacillus toebii ArzA-8 strains\nisolated from an Armenian geothermal spring. Extremophiles 22(5):725–737\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n2\u0000. Lakra U, Sharma SR (2024) Production of exopolysaccharides from Bacillus licheniformis, a\n**BLOCK**fs== 12.0**p== 10.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nthermophilic bacteria from hot spring of Jharkhand. Nat Prod Res 38(5):819–828\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n29. Aliyu H, Lebre P, Blom J, Cowan D, De Maayer P (2016) Phylogenomic re-assessment of the\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.3**\nthermophilic genus Geobacillus. Syst Appl Microbiol 39:527–533\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n30. Kambourova M, Mandeva R, Dimova D, Poli A, Nicolaus B, Tommonaro G (2009) Production and\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.8**l== 0.1**r== 0.0**\ncharacterization of a microbial glucan, synthesized by Geobacillus tepidamans V264 isolated from\nBulgarian hot spring. Carbohydr Polym 77(2):338–343\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\n31. Manca MC, Lama L, Improta R, Esposito E, Gambacorta A, Nicolaus B (1996) Chemical composition\n**BLOCK**fs== 12.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nof two exopolysaccharides from Bacillus thermoantarcticus. Appl Environ Microbiol 62(9):3265–\n**BLOCK**fs== 12.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.0**\n32. Genc B, Taskin M, Adiguzel A (2021) Exopolysaccharide of Anoxybacillus pushchinoensis G11 has\n**BLOCK**fs== 12.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.3**\nantitumor and antibio\u0000lm activities. Arch Microbiol 203:2101–2118\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n33. Siddharthan N, Balagurunathan R, Venkatesan S, Hemalatha N (2023) Bio-e\u0000cacy of Geobacillus\nthermodenitri\u0000cans PS41 against larvicidal, fungicidal, and plant growth-promoting activities.\n**BLOCK**fs== 12.0**p== 11.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nEnviron Sci Pollut Res Int 30(15):42596–42607\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n34. Abinaya M, Vaseeharan B, Divya M, Vijayakumar S, Govindarajan M, Alharbi N, Benelli G (2018)\nStructural characterization of Bacillus licheniformis Dahb1 exopolysaccharide-antimicrobial\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\npotential and larvicidal activity on malaria and Zika virus mosquito vectors. Environ Sci Pollut Res\n25:18604–18619\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n35. Benit N, Roslin A (2018) Isolation and characterization of larvicidal extracellular polysaccharide\n**BLOCK**fs== 12.0**p== 11.0**b== 0.7**t== 0.3**l== 0.1**r== 0.2**\n(EPS) from Pseudomonas aeruginosa B01. Int J Curr Microbiol App Sci 7:109–120\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n3\u0000. Asker MMS, Ahmet YM, Ramadan MF (2009) Chemical Characteristics and Antioxidant Activity of\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\nExopolysaccharide Fractions from Microbacterium Terregens. Carbohydr Polym 3:563–567\n**BLOCK**fs== 12.0**p== 11.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\n37. Selim S, Almuhayawi MS, Alharb MT, Nagshabandi MK, Alanazi A, Warrad M, Ali AS (2022) In vitro\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.4**l== 0.1**r== 0.0**\nassessment of antistaphylococci, antitumor, immunological and structural characterization of acidic\nbioactive exopolysaccharides from marine Bacillus cereus isolated from Saudi Arabia. Metabolites\n12(2):132\n**BLOCK**fs== 12.0**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n3\u0000. Vinothkanna A, Sathiyanarayanan G, Balaji P, Mathivanan K, Pugazhendhi A, Ma Y, RT (2021)\n**BLOCK**fs== 12.0**p== 11.0**b== 0.4**t== 0.5**l== 0.1**r== 0.0**\nStructural characterization, functional and biological activities of an exopolysaccharide produced by\nprobiotic Bacillus licheniformis AG-06 from Indian polyherbal fermented traditional medicine. Int J\nBiol Macromol 174:144–152\n**BLOCK**fs== 18.0**p== 11.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigures\n**BLOCK**fs== 12.0**p== 12.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigure 1\n**BLOCK**fs== 12.0**p== 12.0**b== 0.3**t== 0.7**l== 0.0**r== 0.1**\nThe phylogenetic tree based on 16S rRNA gene sequences was drawn using the neighbor-joining\nmethod, illustrating the relationships between strains HBB-20, 74, 106, 111, and 261, along with other\nclose relatives. Bootstrap values (in percentage) were calculated from 1000 resamplings and are\ndisplayed at the respective nodes.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.5**t== 0.5**l== 0.0**r== 0.9**\nFigure 2\n**BLOCK**fs== 12.0**p== 13.0**b== 0.5**t== 0.5**l== 0.0**r== 0.4**\nCrude and puri\u0000ed EPS contents of thermophilic isolates.\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.9**l== 0.0**r== 0.9**\nFigure 3\n**BLOCK**fs== 12.0**p== 13.0**b== 0.1**t== 0.9**l== 0.0**r== 0.5**\nProtein measurement data of crude EPS extracts\n**BLOCK**fs== 12.0**p== 14.0**b== 0.4**t== 0.6**l== 0.0**r== 0.9**\nFigure 4\n**BLOCK**fs== 12.0**p== 14.0**b== 0.3**t== 0.7**l== 0.0**r== 0.0**\nThe effects of exopolysaccharides from different thermophilic bacteria on Aedes albopictus larvae.\n(Means ± SE; columns with the same lowercase or uppercase letter do not differ signi\u0000cantly at P = 0.05\nafter 24 and 48 h, respectively)\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.4**l== 0.0**r== 0.9**\nFigure 5\n**BLOCK**fs== 12.0**p== 15.0**b== 0.6**t== 0.4**l== 0.0**r== 0.1**\nEffects of EPS concentration on Aedes albopictus larvae.  (Means ± SE; columns with the same\nlowercase or uppercase letter do not differ signi\u0000cantly at P = 0.05 after 24 and 48 h, respectively.)\n**BLOCK**fs== 12.0**p== 16.0**b== 0.2**t== 0.8**l== 0.0**r== 0.9**\nFigure 6\n**BLOCK**fs== 12.0**p== 16.0**b== 0.1**t== 0.9**l== 0.0**r== 0.0**\nThe effect of crude EPSs obtained from different thermophilic bacterial strains on cell viability (PC3:\nprostate cancer cell line, RWPE1: prostate normal cell line, respectively). Data are calculated as mean ±\nstandard deviation. p < 0.05)\n**BLOCK**fs== 12.0**p== 17.0**b== 0.7**t== 0.3**l== 0.0**r== 0.9**\nFigure 7\n**BLOCK**fs== 12.0**p== 17.0**b== 0.6**t== 0.4**l== 0.0**r== 0.0**\nEffect of puri\u0000ed EPSs obtained from different strains of thermophilic bacteria on cell viability (PC3:\nprostate cancer cell line, RWPE1: prostate normal cell line, respectively). Data are calculated as mean ±\nstandard deviation. p < 0.05).",
         "Larvicidal and Cytotoxic Activities of Exopolysaccharides Produced by Thermophilic Bacteria Keywords: Exopolysaccharides, Geobacillus, Anoxybacillus, Parageobacillus, thermophilic bacteria, larvicidal activity, cytotoxicity License:   This work is licensed under a Creative Commons Attribution 4.0 International License. Read Full License Additional Declarations: No competing interests reported. EPSs synthesized by thermophilic bacteria are natural biopolymers that have recently garnered attention due to their potential applications in areas such as pharmaceuticals and biomedicine. In this study, EPSs produced by \u0000ve distinct thermophilic bacterial isolates from hot springs in Turkey were puri\u0000ed using ion exchange and gel chromatography, and the larvicidal and cytotoxic effects of these EPSs were examined. While Geobacillus thermodenitri\u0000cans HBB111 produces the highest quantity (650,9 µg/mL) of EPS, the protein content of crude EPS samples ranges from 0.3–1.5%. EPS111 and EPS261 showed the most effective larvicidal action, eliminating 72% and 62.7% of Ae. albopictus larvae after 48 hours, respectively. Among the puri\u0000ed samples, EPS111 exhibited the most signi\u0000cant effect on the proliferation of PC3 cells, resulting in a 68% inhibition (IC50 of 0,23 mg/mL) followed by EPS106 in a 55% (IC50 of 0,45 mg/mL). According to the results of our study, thermophilic EPSs demonstrate potential due to their insecticidal and anticancer properties. Exopolysaccharides (EPSs) are high molecular weight carbohydrate biopolymers composed of sugar residues [1]. They are secreted into the environment by producing microorganisms and can offer various bene\u0000cial properties and functions to these microorganisms, including protection against predation, bio\u0000lm formation, the creation of a biocompatible extracellular environment, adhesion, molecular recognition, and intercellular signal transmission [2, 3, 4, 5]. Thermophilic microorganisms can thrive at elevated temperatures, and EPS production is proposed as one of their adaptation mechanisms for survival in extreme conditions. Thermophilic bacteria are particularly bene\u0000cial for producing industrially signi\u0000cant EPSs, owing to their non-pathogenic nature and rapid growth rate [6]. EPSs synthesized by thermophiles are highly thermostable when compared to mesophilic ones and can display various biological activities, including antioxidant properties, non- cytotoxicity, anti-diabetic effects, prebiotic and \u0000brinolytic activities, as well as anti-viral and immunostimulant effects [7, 8, 9, 10, 11]. Members of the genera Geobacillus, Parageobacillus, and Anoxybacillus are natural inhabitants of geothermal areas, such as hot springs and hydrothermal vents, and they typically grow rapidly in relatively simple and cost-effective media [12, 10]. While numerous studies focus on mesophilic producers, research on thermophilic exopolysaccharides is rarely reported in the literature. Therefore, studies on the production and biological characterization of EPSs from thermophilic bacilli will yield more insights into their biotechnological applications. In this study, EPSs produced by \u0000ve thermophilic bacterial strains were puri\u0000ed and assessed for their biological characterization. The larvicidal activities and cytotoxic effects of thermophilic EPSs were examined. To our knowledge, there are no studies in the literature regarding the larvicidal activity of EPSs produced by species from the Geobacillus, Parageobacillus, and Anoxybacillus genera. Furthermore, our report is the \u0000rst to evaluate thermophilic EPSs in the PC3 and RWPE1 cell lines. Taxonomic analysis of bacterial isolates Thermophilic bacterial strains, HBB-20, HBB-74, HBB-106, HBB-111 and HBB-261 were previously isolated from hot springs and sediment samples [13] and used for EPS production. 16S rRNA analysis based molecular identi\u0000cation of isolates was done [9] and the sequence data were deposited in GenBank, under accession numbers OR896930, OR896946, OR896962, OR896966, OR897006 for HBB- 20, HBB-74, HBB-106, HBB-111 and HBB-261, respectively. The 16S rRNA gene sequences of strains HBB 20, 74, 106, 111, and 261, along with those of twenty-\u0000ve closely related strains obtained from GenBank, were aligned using MUSCLE. A phylogenetic tree for the isolates was then constructed using the neighbor-joining method with 1000 bootstrap replicates in MEGA11: Molecular Evolutionary Genetics Analysis Version 11 software. Extraction and puri\u0000cation of exopolysaccharides EPSs of \u0000ve thermophilic bacteria were extracted by the following method. Firstly, thermophilic bacteria were cultured in basal media (0.1% (NH4)2HPO4, 0.01% MgSO4, 1% yeast extract, 0.02% KCl, 0.00001% thiamine, 2% sucrose, pH 7.2) at 55°C, 180 rpm for 18–24 h [14]. Then, cells were removed by centrifugation at 5000 rpm for 10 min, and 10 mL of concentrated supernatants were treated with trichloroacetic acid (4% w/v) to remove proteins. After shaking at 180 rpm for 30 min at room temperature supernatants were precipitated by adding two volumes of ethanol (95%) at 4°C. The precipitates were separated by centrifugation at 5000 rpm for 10 min and then dissolved in 10 mL of distilled water. After the determination of total carbohydrates was completed, samples were lyophilized and stored at -80 ℃ [15, 16]. To purify the EPSs ion exchange chromatography with the DEAE Cellulose (30477, Sigma-Aldrich) was used. The EPSs were eluted with a linear gradient of 0.1–1 mol/L NaCl with a \u0000ow rate of 1 mL/min. Both size separation and desalination were applied to the fractions collected by gel \u0000ltration chromatography. For this purpose, Sephadex G-100 column was used and the \u0000ow rate was set at 0.5 mL/min [17, 18]. Determination of protein and sugar content The Bradford method was used to determine the protein concentration in crude EPS samples [19]. Bovine Serum Albumin (BSA) was prepared as a standard. Protein sample (25µL) was added into 1 mL Bradford solution and, after mixing it was kept at room temperature for 10 min. Two hundred microliters of the mixture were transferred to the microplate and distilled water was added to the dye instead of the blank protein. Optical density (OD) was measured at 595 nm [20]. The method for determining total carbohydrate amounts in the samples was adapted from Masuko et al. [21]. Brie\u0000y, 250 µL of the sample was mixed with 750 µL of concentrated sulfuric acid, followed by the addition of 150 µL of phenol solution (5% w/v). After incubating the mixture at 90°C for 5 minutes, the optical density (OD) was measured at 491 nm. The total carbohydrate content was determined using a standard calibration curve prepared with glucose. Larvicidal (Insecticidal) activities of exopolysaccharides Larvicidal activities of EPSs extracted from thermophilic bacterial strains were investigated against Aedes albopictus in 24 well plates [22]. Eggs were collected from adult Ae. albopictus kept in cages (30 × 30 × 30 cm) in a controlled temperature room at 30°C and 12 h light: 12 h dark photoperiod and hatched in tap water. Larvae were fed on crushed ground \u0000sh food until they reached 3rd stage [23, 24]. In the experiments, 3rd stage larvae were distributed into wells in 24-well plates and then one mL of extracted EPS diluted in distilled water was added to wells. At \u0000rst the effects of the EPS at 100 µg/mL were evaluated and then the most effective two EPSs were further diluted to concentrations of 50, 20 and 10 µg/mL. Distilled water alone was used as a negative control. Larvae were fed with ground \u0000sh food. The study was conducted twice with at least 10 replicates per treatment. The plates were incubated at 26 ± 1°C. Larval mortality was larvae after 24 and 48 h exposures [22]. Cell culture Human prostate cancer cell line (PC-3) (CRL-1435, ATCC) and the normal prostate epithelial cell line (RWPE1) (CRL-11609, ATCC) were kindly provided by Prof. Dr. Sarhan Sakarya. PC3 cells were cultured in Dulbecco's Modi\u0000ed Eagle's Medium supplemented with 10% (v/v) heat-inactivated fetal bovine serum (FBS), 100 IU/mL penicillin and 100 µg/mL streptomycin in a humidi\u0000ed incubator (5% CO2 at 37 oC). RWPE1 cells were grown in Roswell Park Memorial Institute (RPMI) 1640 medium with 20% (v/v) FBS, 1% penicillin and streptomycin in a humidi\u0000ed atmosphere containing 5% CO2 at 37 oC. The cell lines were cultured in the culture plate, and the experiment was carried out when the cells entered the logarithmic growth period. H2O2 was dissolved in DMEM (serum-free) and stock solutions were prepared before treatment. Cytotoxicity test The inhibitory effects of both crude and puri\u0000ed EPSs on normal and cancer cell lines were investigated using the MTT assay. Both RWPE1 and PC3 (5x103 cells/well) were incubated in their own culture media described above and in a humidi\u0000ed atmosphere containing 5% CO2 for 24 h at 37°C. The cytotoxic effect was determined using a 96 well microtiter plate assay with \u0000ve different EPS samples prepared at different concentrations (250, 500, 1000 and 2000 µg/mL) with serum-free medium [25]. The medium was subsequently replaced with 100 µL of EPS added to each well and incubated at 37°C for 24 h. After treatment, the cells were incubated with 10 µL MTT reagent (5 mg/mL) for 4 h at 37ºC under 5% CO2. Supernatants were removed and the formazan crystals were dissolved in 150 µL of DMSO. The mixture was shaken up in the dark for 15 min, the absorption value of each well was determined at 490 nm by microplate reader. DMSO was used as a control. All the experiments were performed three times and the percentage of cell viability is calculated by using the Eq. (1) [26]. Cell viability %= (ODsample / ODcontrol) × 100 (1) Statistical analysis Statistical analyses were conducted in the SPSS software program. ANOVA was used to analyze data on the effects of EPS on mosquito larvae and the differences among the averages were grouped using Tukey’s test at the level of P = 0.05. Arcsine transformation was performed on larval mortality before statistical analyses. Probit analysis was used to calculate LC50 values. Taxonomic analysis of thermophilic isolates According to 16S rDNA sequence analysis results, HBB-20, HBB-111 and HBB-261 showed the highest homology ratios (94,35%-100%) with Geobacillus thermodenitri\u0000cans strains. At the same time, HBB-74 and HBB-106 were identi\u0000ed as Anoxybacillus suryakundensis and Parageobacillus thermoglucosidasius with 100% and 99,21% similarity rates, respectively [8, 9]. Neighbor-joining method with 1000 bootstrap replicates in MEGA11 was applied to 16S rRNA gene sequences of isolates and selected similar thermophilic sequences to construct a phylogenetic tree (Fig. 1). As can be seen from the phylogenetic tree, HBB-20, HBB-111 and HBB-261 constitute branches in G. thermodenitri\u0000cans cluster. On the other hand, while HBB-74 forms a branch with A. suryakundensis, HBB-106 forms a branch with P. thermoglucosidasius. Isolation and puri\u0000cation of EPSs Among the crude culture supernatants, the highest EPS content was detected in that of HBB-111 with 650,9 mg/L, followed by HBB-20 (419,4 mg/L), HBB-261 (357,6 mg/L), HBB-106 (352,2 mg/L) and HBB- 74 (269,7 mg/L). Puri\u0000cation percentages and plots of EPSs are detailed in publications of Aytar et al [8, 9]. While the highest loss was recorded for EPS111 (37.1%), pure EPS concentrations ranged from 193.9 to 377.3 mg/mL (Fig. 2). The protein content of crude EPS samples was found to vary between 1,3 and 5,2 mg/L (Fig. 3). Signi\u0000cant differences were observed in the larval susceptibility to EPSs extracted from different thermophilic bacteria. After 24h, EPS 111 and EPS 261 were the most effective, killing 67 and 56% of Ae. albopictus larvae respectively, while the effects of the other EPSs varied between 5 and 41% (F = 22.401; df = 5,102; P < 0.001). After 48 hours, effects of EPS111 and EPS261 increased to 72 and 62 percent up from 67 and 56% respectively. EPS 111 and 261 were statistically more effective than those of EPS20, EPS74 and EPS106 (F = 29.126; df = 5,107; P < 0.001) (Fig. 4). A downward trend was noted in the mortality rate of Ae. albopictus larvae treated with different concentrations (100, 50, 20, and 10 µg/mL) of the two most effective EPSs, namely EPS111 and EPS261 (Fig. 5). After 24 and 48 hours, 10 µg/mL EPS26 was notably less effective than higher concentrations (100, 50, and 20 µg/mL) (F24 h: =20.706, df = 3,50, P < 0.001; F48 h: =22.084, df = 3,50, P < 0.001). Conversely, for EPS111, concentrations ranging from 20–100 µg/mL were signi\u0000cantly higher than the 10 µg/mL concentration after both 24 and 48 hours (P < 0.001) (Fig. 7). After 24-hours exposure, the LC50 of EPS261 and EPS111 were 38 µg/mL and 95,5 µg/mL. Cytotoxicity of EPSs When crude EPSs were tested on RWPE1 and PC3 cell lines at concentrations ranging from 25 to 1000 µg /ml, no signi\u0000cant inhibitory effect was observed in either cell line (Fig. 6). Among the EPS samples at a concentration of 2000 µg/ml, the least cytotoxic to healthy RWPE1 cells are EPS111, EPS261, EPS74, EPS20, and EPS106, respectively. When EPSs were tested at the same concentration on the PC3 cell line, the most signi\u0000cant inhibitory effect was observed for EPS20, while EPS111 showed the least effectiveness. At a concentration of 2000 mg/ml, EPS20 achieved a high kill percentage in PC3 cells, recording 68% with an IC50 value of 1.28 mg/mL. The second most effective compound, EPS74, also demonstrated 68% e\u0000cacy with an IC50 of 1.36 mg/mL. Since two of the crude EPSs tested, EPS20 and EPS106, exhibited cytotoxicity in healthy RWPE1 cells (49% and 56%, respectively), the maximum concentration to be tested in experiments with puri\u0000ed samples was established at 500 µg/ml. The cell viability of RWPE1 cells exposed to puri\u0000ed EPSs in the concentration range of 3.9–500 µg/mL was above 50% at all concentrations (Fig. 7). When raw EPS samples were applied at a concentration of 500 mg/mL, cell viability ranged from 98–120% for RWPE1 cells, whereas this rate was 92–122% for PC3 cells. There is a signi\u0000cant increase in inhibition when puri\u0000ed EPSs are tested at the same concentration. Viability rates ranged from 54–97% for RWPE1 cells and 32–72% for PC3 cells. EPS111 exhibited the most signi\u0000cant effect on the proliferation of PC3 cells, resulting in a 68% inhibition (IC50 of 0,23 mg/mL) followed by EPS106 in a 55% (IC50 of 0,45 mg/mL). Publications in the literature regarding EPSs produced by thermophilic bacteria and their biological activities are relatively scarce compared to those from mesophilic producers. EPS production levels of some thermophilic bacteria were given as follows; Geobacillus sp. TS3-9, 87 µg/mL [11], G. thermodenitrifcans ArzA-6, 76 µg/mL; G. toebii ArzA-8, 80 µg/mL [27], Geobacillus sp. strain WSUCF1, 404 µg/mL [10], Bacillus licheniformis BITSL006, 45 µg/mL [28], Aeribacillus pallidus 418, 80 µg/mL [14], Geobacillus sp. 4004, 60 µg/mL [5], Parageobacillus thermantarcticus 400 µg/mL [29]. When we examined the EPS production levels (269,7 to 650,9 µg/mL) of the isolates used in our study, we found that they were comparable to those of other thermophilic Gram-positive producers. Considering the total protein content of EPSs, it is calculated to be 0.3%, 1.4%, 1.5%, 0.3%, and 1.2% for EPS20, EPS74, EPS106, EPS111, and EPS206, respectively. Similarly, the EPS produced by G. tepidamans V264 contains 1.8% protein, whereas the EPS produced by thermophilic B. thermoantarcticus has 2% protein [30, 31]. According to Genc et al. the amount of total protein in EPS solution obtained from Anoxybacillus pushchinoensis G11 was determined as 1.08% [32]. Among the EPSs, only EPS111 was thoroughly characterized in our previous publication, which revealed that it consists of hexose (glucose, fructose, galactose, and mannose) and pentose sugars [8]. Comprehensive chemical analyses of the remaining four EPSs are scheduled for future studies. Again, based on the \u0000ndings of our previous study [8] it was demonstrated that none of the EPSs exhibited cytotoxic effects on blood cells, prompting us to explore the larvicidal and anticancer activities of these metabolites. Novel strategies to reduce mosquito populations are an urgent priority. Applying EPS to mosquito breeding sites could help mitigate the risks of mosquito-borne diseases. To our knowledge, there are currently no reports regarding the larvicidal activity of EPS derived from members of the Parageobacillus, or Anoxybacillus genera. In a study conducted by Siddharthan et al. the larvicidal bioactivity of Geobacillus thermodenitri\u0000cans PS41 was assessed, revealing insecticidal activity against third-instar larvae of Spodoptera litura, which resulted in a mortality rate of 60.26 ± 1.5%. However, the trials utilized extracted secondary metabolites rather than EPS [33]. Our study revealed the larvicidal effects of thermophilic EPSs against Aedes albopictus, a major vector of arboviral diseases such as Chikungunya, dengue fever, and yellow fever. Among the tested bacterial EPSs, 111 and EPS261 were the most effective with LC50 values after 24 hours were 38 µg/mL and 95.5 µg/mL, respectively. The larvicidal activity of EPS obtained from Bacillus licheniformis was tested against the larvae of Anopheles stephensi, a vector for Plasmodium sp. parasites, and Ae. aegypti, which, like Ae. albopictus transmits arboviruses [34]. The LC50 and LC90 values of Bl-EPS against An. stephensi were 61.31 and 127.45 µg/mL, and against Ae. aegypti were 79.28 and 150.68 µg/mL, respectively. These EPS exhibited maximum mortality against both vectors at 150 µg/mL. Similarly, EPS produced by Pseudomonas aeruginosa B01 exhibited potent larvicidal activity against an unspeci\u0000ed mosquito species at a concentration of 10 mg/dL [35]. When evaluating the antitumor effects of the thermophilic EPSs used in this study, puri\u0000ed samples demonstrate a greater inhibitory effect on both healthy and cancerous cells compared to raw EPSs (Table 1). Several in vitro studies have demonstrated that puri\u0000ed polysaccharides are more functional than crude polysaccharides [36, 37]. The anticancer properties of EPSs may result from other unwanted components or impurities present in the samples examined. Therefore, to assert that the activity in the studied material is attributable to EPS, the metabolite must be obtained and utilized in high purity. In our study, the reason pure samples exhibited superior results regarding anticancer activity may stem from the release of speci\u0000c functional groups, such as sulfate and uronic acid, which can be found in EPSs through puri\u0000cation. Additionally, the varying rates at which thermophilic EPSs exhibit anticancer effects may be attributed to differences in their molecular weights and monosaccharide structures. However, more detailed chemical and structural analyses are required to validate these assertions. Table 1 Viability percentages of RWPE1 and PC3 cell lines treated with crude and puri\u0000ed EPS at a concentration of 500 mg/mL, along with IC50 values of EPS. RWPE1 cell line PC3 cell line RWPE1 cell line PC3 cell line In our study, the sample exhibiting the most effective anticancer activity against PC3 while maintaining the highest viability of RWPE1 cells is the puri\u0000ed form of EPS111, with an IC50 value of 0.23 mg/mL. It is followed by pure EPS106, which has an LC50 value of 0.45 mg/mL and inhibited PC3 cells by 55%. It was reported that EPS puri\u0000ed from Bacillus licheniformis AG-06, exhibited signi\u0000cant cytotoxic activity (IC50 value of 37.5 ± 0.87 µg/mL) against human lung carcinoma cells (A549) and thus demonstrates strong anticancer potential [38]. In another study, it was found that crude EPS derived from Anoxybacillus pushchinoensis G11 showed a cytotoxic effect on A-549 and colon cancer (Caco-2 and HT-29) cell lines at a concentration of 2.5 mg/mL [32]. Wang et al. evaluated the antitumor activity of puri\u0000ed samples of EPS from Geobacillus sp. TS3-9 strain on hepatoma carcinoma cells (HepG2) using MTT analysis. The inhibitory effect of EPS on the proliferation of HepG2 was dose-dependent at concentrations ranging from 4 µg/mL to 100 µg/mL, with the inhibition rate varying from 2.2–16.9%, respectively [11]. Two exopolysaccharides (EPS-1 and EPS-2) puri\u0000ed from the Geobacillus sp. WSUCF1 strain exhibited no cytotoxicity against human embryonic kidney-293 (HEK-293) cells at concentrations of 2 and 3 mg/mL, respectively [10]. Arena et al. revealed that exopolysaccharide (EPS-2) produced by G. thermodenitri\u0000cans B3-72 strain inhibited HSV-2 replication in human peripheral blood mononuclear cells (PBMC), but not in WISH cells [7]. In this study, we aimed to isolate and purify novel exopolysaccharides from thermophilic isolates and investigate their biological activities. Among the \u0000ve EPSs we tested, EPS111 and EPS261 distinguished themselves with their larvicidal activities, while EPS106 and EPS111 exhibited a notable inhibitory effect on the proliferation of PC3 cells. Considering all this, among the EPSs we studied, especially EPS111, EPS106, and EPS261 stand out for their unique and valuable biological activities. However, in future studies, these natural and potential exopolysaccharides must be analyzed in detail and tested in vivo and clinically to guarantee the e\u0000cacy of the EPSs. COI description The authors have no con\u0000icts of interest to declare. G.B. was responsible for the organization and coordination of the study. D.A.U., planned and performed EPS extraction and puri\u0000cation steps. M.A., D.Y.B and M.T. were the investigators and responsible for the data collection and analysis. All authors contributed to the writing of the \u0000nal manuscript and reviewed the manuscript. Mehmet AYTAR and Demet YALÇIN BİNGÜL received funding from the Higher Education Council of Türkiye (YOK) as a participant of the 100/2000 PhD scholarship. Sequence data were deposited in GenBank, under accession numbers OR896930, OR896946, OR896962, OR896966, OR897006 for HBB-20, HBB-74, HBB-106, HBB-111 and HBB-261, respectively. 1. Wang J, Salem D, Sani R (2019b) Extremophilic exopolysaccharides: A review and new perspectives 2. Moriello V, Lama L, Poli A, Gugliandolo C, Maugeri T, Gambacorta A, Nicolaus B (2003) Production of exopolysaccharides from a thermophilic microorganism isolated from a marine hot spring in \u0000egrean areas. J Ind Microbiol Biotechnol 30(2):95–101 3. Nicolaus B, Kambourova M, Oner E (2010) Exopolysaccharides from extremophiles: from fundamentals to biotechnology. Environ Technol 31(10):1145–1158 4. Nicolaus B, Lama L, Esposito E, Manca M, Improta R, Bellitti M (1999) Haloarcula spp able to biosynthesize exo- and endopolymers. J Ind Microbiol Biotechnol 23(6):489–496 5. Poli A, Anzelmo G, Nicolaus B (2010) Bacterial exopolysaccharides from extreme marine habitats: production, characterization and biological activities. Mar Drugs 8(6):1779–1802 \u0000. Yasar Yildiz S, Anzelmo, Ozer T, Radchenkova N, Genç S, Di Donato P, .Kambourova M (2014) Brevibacillus themoruber: a promising microbial cell factory for exopolysaccharide production. J Appl Microbiol 116(2):314–324 7. Arena A, Gugliandolo C, Stassi G, Pavone B, Iannello D, Bisignano G (2009) An exopolysaccharide produced by Geobacillus thermodenitri\u0000cans strain B3-72: antiviral activity on immunocompetent cells. Immunol Lett 7 123:132 \u0000. Aytar M, Başbülbül G, Uygun DA (2024a) Characterization and biological activities of a novel exopolysaccharide produced from Geobacillus thermodenitri\u0000cans HBB 111 strain. Extremophiles 9. Aytar M, Uygun DA, Başbülbül G (2024b) Production and biological activities of exopolysaccharides synthesized by thermophilic bacilli isolated from hot springs in Türkiye. Int Microbiol 1–16 10. Wang J, Salem D, Sani R (2021) Two new exopolysaccharides from a thermophilic bacterium Geobacillus sp. WSUCF1: Characterization and bioactivities. N Biotechnol 61:29–39 11. Wang L, Zhang, Yang L, Liang X, Zhang F, Linhardt RJ (2017) Structural characterization and bioactivity of exopolysaccharide synthesized by Geobacillus sp. TS3-9 isolated from radioactive radon hot spring. Adv Biotechnol Microbiol 4:1–8 12. Gugliandolo C, Lentini V, Span`o A, Maugeri T (2012) New bacilli from shallow hydrothermal vents of Panarea Island (Italy) and their biotechnological potential. J Appl Microbiol 112(6):1102–1112 13. Başbülbül Özdemir G, Biyik HH (2012) Isolation and characterization of a bacteriocin-like substance produced by Geobacillus toebii strain HBB-247. Indian J Microbiol 52:104–108 14. Radchenkova N, Vassilev S, Panchev I, Anzelmo G, Tomova I, Nicolaus B, Kambourova M (2013) Production and properties of two novel exopolysaccharides synthesized by a thermophilic bacterium Aeribacillus pallidus 418. Appl Biochem Biotechnol 171(1):31–43 15. Bajpai V, Majumder R, Rather I, Kim K (2016) Extraction, isolation and puri\u0000cation of exopolysaccharide from lactic acid bacteria using ethanol precipitation method. Bangladesh J 1\u0000. Wang J, Zhao X, Yang Y, Zhao A, Yang Z (2015) Characterization and bioactivities of an exopolysaccharide produced by Lactobacillus plantarum YW32. Int J Biol Macromol 74:119–126 17. Hu S, Zhou J, Zhou Q, Li P, Xie Y, Zhou, Gu Q (2021) Puri\u0000cation, characterization and biological activities of exopolysaccharides from Lactobacillus rhamnosus ZFM231 isolated from milk. LWT 147:111561 1\u0000. Ye S, Liu F, Wang J, Wang H, Zhang M (2012) Antioxidant activities of an exopolysaccharide isolated and puri\u0000ed from marine Pseudomonas PF-6. Carbohydr Polym 87(1):764–770 19. Bradford MM (1976) A rapid and sensitive method for the quantitation of microgram quantities of protein utilizing the principle of protein-dye binding. Anal Biochem 72 (1–2): 248 – 25 20. Noble JE, Bailey MJ (2009) Quantitation of protein. Methods Enzymol 463:73–95 21. Masuko T, Minami A, Iwasaki N, Majima T, Nishimura SI, Lee YC (2005) Carbohydrate analysis by a phenol–sulfuric acid method in microplate format. Anal Biochem 339(1):69–72 22. Shah F, Abdoarrahem M, Berry C, Touray M, Hazir, Butt T (2021) Indiscriminate ingestion of entomopathogenic nematodes and their symbiotic bacteria by Aedes aegypti larvae: a novel strategy to control the vector of Chikungunya, dengue and yellow fever. Turk J Zool 45:372–383 23. Bursalı F, Şahin Y, Aygün M, Sevincek R, Bıyık H, Özgener H, Gürbüz B (2024) 1, 2-Diboranes with strong donor substitutes: Synthesis, ovicidal and larvicidal effect on important vector species. Inorg Chem Commun 162:112268 24. Bursalı F, Yavaşer Boncooğlu R, Fırıncı,Fırıncı E (2023) Synthesis, characterization, larvicidal and antioxidant activities of copper (II) complexes with barbiturate derivatives. Monatsh Chem 154(7):793–799 25. Mosmann T (1983) Rapid colorimetric assay for cellular growth and survival: application to proliferation and cytotoxicity assays. J Immunol Methods 65(1–2):55–63 2\u0000. Zhang Y, Lv X, Hu Z, Ye X, Liu Q (2017) Protection of Mcc950 against high glucose- induced human retinal endothelial cell dysfunction. Cell Death Discovery 8(7):e2941 27. Panosyan H, Di Donato P, Poli A, Nicolaus B (2018) Production and characterization of exopolysaccharides by Geobacillus thermodenitri\u0000cans ArzA-6 and Geobacillus toebii ArzA-8 strains isolated from an Armenian geothermal spring. Extremophiles 22(5):725–737 2\u0000. Lakra U, Sharma SR (2024) Production of exopolysaccharides from Bacillus licheniformis, a thermophilic bacteria from hot spring of Jharkhand. Nat Prod Res 38(5):819–828 29. Aliyu H, Lebre P, Blom J, Cowan D, De Maayer P (2016) Phylogenomic re-assessment of the thermophilic genus Geobacillus. Syst Appl Microbiol 39:527–533 30. Kambourova M, Mandeva R, Dimova D, Poli A, Nicolaus B, Tommonaro G (2009) Production and characterization of a microbial glucan, synthesized by Geobacillus tepidamans V264 isolated from Bulgarian hot spring. Carbohydr Polym 77(2):338–343 31. Manca MC, Lama L, Improta R, Esposito E, Gambacorta A, Nicolaus B (1996) Chemical composition of two exopolysaccharides from Bacillus thermoantarcticus. Appl Environ Microbiol 62(9):3265– 32. Genc B, Taskin M, Adiguzel A (2021) Exopolysaccharide of Anoxybacillus pushchinoensis G11 has antitumor and antibio\u0000lm activities. Arch Microbiol 203:2101–2118 33. Siddharthan N, Balagurunathan R, Venkatesan S, Hemalatha N (2023) Bio-e\u0000cacy of Geobacillus thermodenitri\u0000cans PS41 against larvicidal, fungicidal, and plant growth-promoting activities. 34. Abinaya M, Vaseeharan B, Divya M, Vijayakumar S, Govindarajan M, Alharbi N, Benelli G (2018) Structural characterization of Bacillus licheniformis Dahb1 exopolysaccharide-antimicrobial potential and larvicidal activity on malaria and Zika virus mosquito vectors. Environ Sci Pollut Res 25:18604–18619 35. Benit N, Roslin A (2018) Isolation and characterization of larvicidal extracellular polysaccharide (EPS) from Pseudomonas aeruginosa B01. Int J Curr Microbiol App Sci 7:109–120 3\u0000. Asker MMS, Ahmet YM, Ramadan MF (2009) Chemical Characteristics and Antioxidant Activity of Exopolysaccharide Fractions from Microbacterium Terregens. Carbohydr Polym 3:563–567 37. Selim S, Almuhayawi MS, Alharb MT, Nagshabandi MK, Alanazi A, Warrad M, Ali AS (2022) In vitro assessment of antistaphylococci, antitumor, immunological and structural characterization of acidic bioactive exopolysaccharides from marine Bacillus cereus isolated from Saudi Arabia. Metabolites 12(2):132 Structural characterization, functional and biological activities of an exopolysaccharide produced by probiotic Bacillus licheniformis AG-06 from Indian polyherbal fermented traditional medicine. Int J Biol Macromol 174:144–152 The phylogenetic tree based on 16S rRNA gene sequences was drawn using the neighbor-joining method, illustrating the relationships between strains HBB-20, 74, 106, 111, and 261, along with other close relatives. Bootstrap values (in percentage) were calculated from 1000 resamplings and are displayed at the respective nodes. Crude and puri\u0000ed EPS contents of thermophilic isolates. Protein measurement data of crude EPS extracts The effects of exopolysaccharides from different thermophilic bacteria on Aedes albopictus larvae. (Means ± SE; columns with the same lowercase or uppercase letter do not differ signi\u0000cantly at P = 0.05 after 24 and 48 h, respectively) Effects of EPS concentration on Aedes albopictus larvae.  (Means ± SE; columns with the same lowercase or uppercase letter do not differ signi\u0000cantly at P = 0.05 after 24 and 48 h, respectively.) The effect of crude EPSs obtained from different thermophilic bacterial strains on cell viability (PC3: prostate cancer cell line, RWPE1: prostate normal cell line, respectively). Data are calculated as mean ± standard deviation. p < 0.05) Effect of puri\u0000ed EPSs obtained from different strains of thermophilic bacteria on cell viability (PC3: prostate cancer cell line, RWPE1: prostate normal cell line, respectively). Data are calculated as mean ± standard deviation. p < 0.05).",
         "https://www.researchsquare.com/article/rs-5304452/latest.pdf",
         "extracted",
         "None",
         "",
         "Larvicidal and cytotoxic activities of exopolysaccharides produced by thermophilic bacteria."
        ],
        [
         "36",
         "019ef776513d52beff1271152eb2b8c7890bb531",
         "MUS81 is a structure-specific endonuclease that processes DNA intermediates in mitosis and in S-phase following replication stress. MUS81 is crucial to cleave deprotected reversed forks in BRCA2-deficient cells. However, how MUS81 is regulated during replication stress in human cells remains unknown. Our study reveals that CHK2 binds the MUS81-EME2 complex and positively regulates formation of DSBs upon replication stress or in the absence of BRCA2. The association with MUS81 occurs through the FHA domain of CHK2 and is disabled by the I157T mutation but not by the R117A mutation. The CHK2-MUS81 complex forms downstream fork reversal and degradation, and phosphorylation of MUS81 at CHK2-targeted sites is crucial to introduce DSBs at deprotected replication forks ensuring the replication fork recovery in BRCA2-deficient cells. Collectively, our work sheds light into the regulation of the MUS81 complex and identifies a novel function of the ATM-CHK2 axis in the response to deprotected replication forks in the absence of BRCA2.",
         "Eva Malacaria,Carolina Figlioli,Anita Palma,S. Rinalducci,Maurizio Semproni,A. Franchitto,P. Pichierri",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2022/10/08/2022.10.08.511087.full.pdf",
         "None",
         "None",
         "The KU-PARP14 axis differentially regulates DNA resection at stalled replication forks by MRE11 and EXO1;Functional Analysis Identifies Damaging CHEK2 Missense Variants Associated with Increased Cancer Risk;Regulation of Mus81-Eme1 structure-specific endonuclease by Eme1 SUMO-binding and Rad3ATR kinase is essential in the absence of Rqh1BLM helicase;CHEK2 Germline Variants in Cancer Predisposition: Stalemate Rather than Checkmate;Physiological and Pathological Roles of RAD52 at DNA Replication Forks;Rad52 prevents excessive replication fork reversal and protects from nascent strand degradation;Advances in understanding DNA processing and protection at stalled replication forks;Phosphorylation by CK2 regulates MUS81/EME1 in mitosis and after replication stress;Replication Fork Reversal: Players and Guardians.;MRE11 and EXO1 nucleases degrade reversed forks and elicit MUS81-dependent fork rescue in BRCA2-deficient cells;EZH2 promotes degradation of stalled replication forks by recruiting MUS81 through histone H3 trimethylation;Replication fork reversal triggers fork degradation in BRCA2-defective cells;Smarcal1-Mediated Fork Reversal Triggers Mre11-Dependent Degradation of Nascent DNA in the Absence of Brca2 and Stable Rad51 Nucleofilaments;RADX Promotes Genome Stability and Modulates Chemosensitivity by Regulating RAD51 at Replication Forks.;FHA domains: Phosphopeptide binding and beyond.;MUS81 nuclease activity is essential for replication stress tolerance and chromosome segregation in BRCA2-deficient cells;Current perspectives on CHEK2 mutations in breast cancer;The SMX DNA Repair Tri-nuclease;Feedback regulation of methyl methanesulfonate and ultraviolet-sensitive gene clone 81 via ATM/Chk2 pathway contributes to the resistance of MCF-7 breast cancer cells to cisplatin;A Mechanism for Controlled Breakage of Under-replicated Chromosomes during Mitosis.;Small-molecule inhibitors identify the RAD52-ssDNA interaction as critical for recovery from replication stress and for survival of BRCA2 deficient cells;Cell cycle control of DNA joint molecule resolution.;Replication Fork Stability Confers Chemoresistance in BRCA-deficient Cells;Signaling from Mus81-Eme2-Dependent DNA Damage Elicited by Chk1 Deficiency Modulates Replication Fork Speed and Origin Usage.;Replication stress: getting back on track;BRCAness revisited;The WRN exonuclease domain protects nascent strands from pathological MRE11/EXO1-dependent degradation;Replication fork reversal in eukaryotes: from dead end to dynamic response;Holliday junction resolution: Regulation in space and time;DNA Replication and Oncogene-Induced Replicative Stress;MUS81-EME2 Promotes Replication Fork Restart;Substrate specificity of the MUS81-EME2 structure selective endonuclease;A Novel Non-canonical Forkhead-associated (FHA) Domain-binding Interface Mediates the Interaction between Rad53 and Dbf4 Proteins*;Survival of the Replication Checkpoint Deficient Cells Requires MUS81-RAD52 Function;Regulation of Mus81–Eme1 Holliday junction resolvase in response to DNA damage;Human RECQ1 promotes restart of replication forks reversed by DNA topoisomerase I inhibition;The WRN and MUS81 proteins limit cell death and genome instability following oncogene activation;THE RAD9-RAD1-HUS1 (9.1.1) COMPLEX INTERACTS WITH WRN AND IS CRUCIAL TO REGULATE ITS RESPONSE TO REPLICATION FORK STALLING;Structure-Specific DNA Endonuclease Mus81/Eme1 Generates DNA Damage Caused by Chk1 Inactivation;Double-Strand Break Repair-Independent Role for BRCA2 in Blocking Stalled Replication Fork Degradation by MRE11;The DNA damage response: making it safe to play with knives.;Homologous recombination restarts blocked replication forks at the expense of genome rearrangements by template exchange.;The checkpoint response to replication stress.;Replication fork stalling in WRN-deficient cells is overcome by prompt activation of a MUS81-dependent pathway;GPS 2.0, a Tool to Predict Kinase-specific Phosphorylation Sites in Hierarchy *S;ATR: an essential regulator of genome integrity;Mechanism of eukaryotic homologous recombination.;The structure-specific endonuclease Mus81 contributes to replication restart by generating double-strand DNA breaks;Replication checkpoint kinase Cds1 regulates Mus81 to preserve genome integrity during replication stress.;Molecular mechanisms of mammalian DNA repair and the DNA damage checkpoints.;The relationship between the roles of BRCA genes in DNA repair and cancer predisposition.;Checking on the fork: the DNA-replication stress-response pathway.;Mus81-Eme1 and Rqh1 Involvement in Processing Stalled and Collapsed Replication Forks*;Structural and functional versatility of the FHA domain in DNA-damage signaling by the tumor suppressor kinase Chk2.;Damage Tolerance Protein Mus81 Associates with the FHA1 Domain of Checkpoint Kinase Cds1;The molecular basis of FHA domain:phosphopeptide binding specificity and implications for phospho-dependent signaling mechanisms.;Heterozygous germ line hCHK2 mutations in Li-Fraumeni syndrome.;Crystal Structure of the Human MUS81-EME2 Complex;Identification and characterization of MUS81 point mutations that abolish interaction with the SLX4 scaffold protein;(2023) Phosphorylation status of MUS81 is a modifier of Olaparib sensitivity in BRCA2-deficient cells",
         "CHK2 regulates MUS81-dependent DSBs in response to replication stress and BRCA2 deficiency"
        ],
        [
         "37",
         "01ae220b363f9f67e47ae800d8483b5b34ecb1d8",
         "Ecology is an essential discipline for understanding the biology and behavior of organisms. This study increased knowledge of three sympatric species of ground wētā (Hemiandrus spp.). Hemiandrus ground wētā are nocturnal Ensifera that live in burrows during the day, and for these reasons, there is limited knowledge of their activity, development, and diet. We examined the diet of Hemiandrus electra, Hemiandrus ‘disparalis’, and Hemiandrus nox by examining the crop contents of specimens caught in malaise traps set in a native forest (St Arnaud) over seven months during two spring-summer-autumn seasons (2004/2005 and 2005/2006). The three species investigated varied in the plant and invertebrate fragment proportions in their diets. Hemiandrus electra and H. ‘disparalis’ were predominantly herbivores, while H. nox was primarily carnivorous, although plant matter constituted 20% of its diet. We identified the species and sex of 966 Hemiandrus wētā that were intercepted by the same malaise traps. Our results showed that H. electra was the most abundant species, with 701 individuals, while 157 and 109 were identified as H. ‘disparalis’ and H. nox, respectively. Surprisingly, the species with maternal care (H. electra) was the only one of the three sympatric Hemiandrus to have an even sex ratio; for the other two species, more males were caught in the traps. Using hind leg dimensions, we categorized each female H. electra specimen using naïve Gaussian mixture model clustering, which identified five size clusters (putatively corresponding to instars). Based on the month of collection and the growth category, we observed no seasonality in the development of this species of ground wētā, as almost all instars were found in each month of the sampling period. This study found no evidence that these nocturnal forest species synchronize their growth or reproduction with seasons.",
         "Nyasha Chikwature,M. Morgan‐Richards,Jessica Vereijssen,S. Trewick",
         "\n**BLOCK**fs== 15.4**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nComparison of growth, relative abundance, and diet of three sympatric\nHemiandrus ground wētā (Orthoptera, Anostostomatidae) in\na New Zealand Forest\n**BLOCK**fs== 7.9**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.3**\nnyasha chikwature1, Mary Morgan-richards1, Jessica VereiJssen2, steVen a. trewick1\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\n1 Massey University, Wildlife & Ecology, Private Bag 11-222, Palmerston North, New Zealand.\n2 The New Zealand Institute for Plant and Food Research Limited, Adaptive Entomology, Private Bag 4704, Christchurch Mail Centre, Christchurch\n8140, New Zealand.\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nCorresponding author: Nyasha Chikwature (n.chikwature@massey.ac.nz)\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.2**\nAcademic editor: Klaus-Gerhard Heller | Received 24 March 2024 | Accepted 21 May 2024 | Published 7 January 2025\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.6**\nhttps://zoobank.org/B9F5ADFE-9512-4F03-BB5C-EE36A82E57EA\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.1**r== 0.0**\nCitation: Chikwature N, Morgan-Richards M, Vereijssen J, Trewick SA (2025) Comparison of growth, relative abundance, and diet of three sympatric\nHemiandrus ground wētā (Orthoptera, Anostostomatidae) in a New Zealand Forest. Journal of Orthoptera Research 34(1): 1–10. https://doi.org/10.3897/\njor.34.123860\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\nAbstract\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nIntroduction\n**BLOCK**fs== 8.0**p== 0.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\nEcology is an essential discipline for understanding the biology and\nbehavior of organisms. This study increased knowledge of three sympatric\nspecies  of  ground  wētā  (Hemiandrus  spp.).  Hemiandrus  ground  wētā  are\nnocturnal Ensifera that live in burrows during the day, and for these rea-\nsons, there is limited knowledge of their activity, development, and diet.\nWe examined the diet of Hemiandrus electra, Hemiandrus ‘disparalis’, and\nHemiandrus  nox  by  examining  the  crop  contents  of  specimens  caught  in\nmalaise traps set in a native forest (St Arnaud) over seven months during\ntwo  spring-summer-autumn  seasons  (2004/2005  and  2005/2006).  The\nthree  species  investigated  varied  in  the  plant  and  invertebrate  fragment\nproportions in their diets. Hemiandrus electra and H. ‘disparalis’ were pre-\ndominantly herbivores, while H. nox was primarily carnivorous, although\nplant matter constituted 20% of its diet. We identified the species and sex\nof 966 Hemiandrus wētā that were intercepted by the same malaise traps.\nOur  results  showed  that  H.  electra  was  the  most  abundant  species,  with\n701 individuals, while 157 and 109 were identified as H. ‘disparalis’ and\nH. nox, respectively. Surprisingly, the species with maternal care (H. elec-\ntra) was the only one of the three sympatric Hemiandrus to have an even\nsex ratio; for the other two species, more males were caught in the traps.\nUsing  hind  leg  dimensions,  we  categorized  each  female  H.  electra  speci-\nmen using naïve Gaussian mixture model clustering, which identified five\nsize clusters (putatively corresponding to instars). Based on the month of\ncollection and the growth category, we observed no seasonality in the de-\nvelopment of this species of ground wētā, as almost all instars were found\nin each month of the sampling period. This study found no evidence that\nthese  nocturnal  forest  species  synchronize  their  growth  or  reproduction\nwith seasons.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nKeywords\n**BLOCK**fs== 8.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nH. ‘disparalis’ morphometrics, H. electra, H. nox, natural habitats, seasonal-\nity, sex, and species abundance\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.5**l== 0.5**r== 0.0**\nIn New Zealand, 19 described species of flightless Orthoptera\nare in the genus Hemiandrus Ander, 1938 (Anostostomatidae). All\nare active at night, using burrows in the soil during the day to hide\nfrom predators, from where their common name, ground wētā, is\nderived. There is limited knowledge of wētā ecology in relation to\nactivity, growth and development, and diet because of the insect’s\nnocturnal behavior, but diet is known to vary within the Anostos-\ntomatidae family in New Zealand and elsewhere. At the genus level,\nHemiandrus in New Zealand are mostly omnivores (Wahid 1979,\nButts 1983, Van Wyngaarden 1995), but where data are available,\nthere  is  evidence  that  individual  species  differ  in  diet.  For  exam-\nple, H. maculifrons (Walker 1869) has been found to be primarily\ncarnivorous  (Cary  1983),  while  H.  maia  Taylor  Smith,  Morgan-\nRichards, Trewick 2013 has been observed to consume fruit, inver-\ntebrates, and seeds (Taylor Smith et al. 2013). Similarly, diet varies\nin the related genus of endemic Hemideina White 1846 tree wētā.\nHemideina maori (Pictet & Saussure, 1891) feeds on invertebrates,\nplants, and lichen (Wilson and Jamieson 2005), while Hemideina\nthoracica  White  1846  is  primarily  herbivorous  (Wehi  and  Hicks\n2010, Brown 2013). It has been concluded that H. crassidens (Blan-\nchard  1851)  is  opportunistic  in  dietary  choice,  although  plants\nmake up a major part of the food of this species (Griffin et al. 2011,\nWyman et al. 2011, Dewhurst 2012). Deinacrida (White 1842) (gi-\nant wētā), such as D. rugosa (Buller 1871), are primarily herbivores\n(Mcintyre  2001),  but  the  New  Zealand  tusked  wētā  Motuweta  ri-\nparia (Johns 1997) is predatory (Gibbs 2002, Trewick pers. obs.).\nOverseas, the South African species Libanasa vittatus (Kirby 1899)\nis considered omnivorous but can be predatory (Toms 2001), and\nthe  diet  of  Australian  Anostostomatidae  spans  invertebrates  and\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\nCopyright Nyasha Chikwature et al. This is an open access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0), which permits unrestricted\nuse, distribution, and reproduction in any medium, provided the original author and source are credited.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nfungi (Monteith and Field 2001). Variations in the feeding behav-\nior of wētā species occupying the same environment could be evi-\ndence of resource partitioning, a strategy that reduces competition\nfor limited resources. An equilibrium is unlikely when more than\none species share the same resources, and competitive exclusion is\nthought to eventually lead to either the extinction of all but one\nspecies or to resource partitioning (Vandermeer et al. 2002). Thus,\nsympatric  species  may  coexist  using  different  resources  (Agrawal\nand  Klein  2000,  Eubanks  and  Denno  2000,  Kaplan  and  Denno\n2007). Diet is often linked to relative abundance, with predatory\nspecies often occurring at lower densities than related herbivores\nin the same ecosystem (Turney et al. 2018).\n**BLOCK**fs== 9.0**p== 1.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nDifferences  in  diet  due  to  sex  and  developmental  stage  have\nbeen observed in Hemiandrus ground wētā. Studies of Hemiandrus\nceleano  Trewick,  Taylor-Smith,  Morgan-Richards  2020  showed\ndiet differences between the sexes (Wahid 1979), while H. subant-\narcticus (Salmon 1950) differed among age classes (Butts 1983).\nHowever, neither H. maculifrons nor the undescribed Hemiandrus\nspecies collected from Tekapo showed sex or size variations in their\ndiet (Cary 1983, Van Wyngaarden 1995). Research gaps remain re-\ngarding what determines diet variation in Anostostomatidae.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nIn contrast to diet, reproduction and seasonality have been well\nstudied in the Anostostomatidae family (Field and Jarman 2001,\nGwynne 2004, Wehi et al. 2012). Current knowledge of Hemian-\ndrus ground wētā reproduction suggests that all species have over-\nlapping generations with mating and egg laying between January\nand March (summer, autumn) (Gwynne 2004), although there is\nthe possibility of females laying eggs in other months (Nboyine et\nal. 2018). Most arthropods show seasonal variation in reproduc-\ntion,  which  may  be  controlled  by  different  factors  (Ribeiro  and\nFreitas  2011).  For  example,  optimum  temperature  and  humidity\nfavor  some  species  to  mate  and  oviposit,  and  some  insects  may\navoid emerging when parasitoids (Barbosa et al. 2007) or preda-\ntion  threaten  their  survival  (Torres-Vila  and  Rodríguez-Molina\n2002). One aspect that could affect seasonal variation in insects\nis  the  availability  of  vital  resources  that  should  be  in  synchrony\nwith the larval or adult phase, and fewer of these resources could\ncompromise the fitness of organisms (Torres-Vila and Rodríguez-\nMolina 2002, Kursar et al. 2006). In some forests, resources could\nbe available all year round (Cary 1983), but the quality of these\nresources may vary (Lawrence et al. 1997). For instance, when new\nleaves emerge in forests, this could mean that the leaves are highly\nnutritious, with higher nitrogen, sugars, and amino acid contents\nthan  older  leaves  (Hamer  et  al.  2006).  Therefore,  such  seasonal\nresource availability could affect mating or oviposition, and thus\ninfluence insect seasonality.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nThis study gleaned new ecological information about three en-\ndemic ground wētā species that co-occur in the same temperate rain\nforest: Hemiandrus electra Taylor Smith, Morgan-Richards & Trewick,\n2013, H. nox Taylor-Smith, Trewick & Morgan-Richards, 2016, and\nan  undescribed  Hemiandrus  species  (Johns  2001).  We  addressed\nfour  main  questions:  1)  What  are  the  main  constituents  of  their\ndiet? We expected all three wētā species to be omnivores, but the\nrelative proportions of plant and animal matter might differ among\nspecies and sexes. As some Hemiandrus species are pests of economic\nimportance in New Zealand (Nboyine et al. 2016), understanding\nthe natural diet of related taxa could affect management decisions.\n2) What are the relative abundances and sex ratios of these three\nsympatric  species  based  on  intercept  trapping?  Some  Hemiandrus\nspecies show maternal care, and females are less active when attend-\ning to eggs and nymphs within soil burrows (Gwynne 2004). We\nexpected that H. electra would have fewer active adult females than\n**BLOCK**fs== 9.0**p== 1.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nmales, compared with the other two Hemiandrus species. 3) What\nis the size distribution of the common Hemiandrus species caught\nin malaise traps? Are these species univoltine or multivoltine, as are\nother members of this insect family (Godfrey et al. 2023)?\n**BLOCK**fs== 9.0**p== 1.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nMaterials and methods\n**BLOCK**fs== 9.0**p== 1.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\nStudy site.—The three species of Hemiandrus were sampled as by-\ncatch in a long-running Vespula wasp management program in Ro-\ntoiti Mainland Island near St Arnaud South Island, New Zealand\n(-41°53'59.99\"S, 172°51'59.99\"E) (Paton et al. 2007). Groups of\nmalaise traps were set in the mature temperate native forest domi-\nnated by evergreen beech (Fuscospora) species. Each malaise trap\nwas positioned at ground level and fitted with glycol and detergent\ncollection  bottles  to  preserve  invertebrates  that  climbed  or  flew\nto  the  apex  of  the  trap.  Traps  were  cleared  weekly,  and  samples\nwere sorted and transferred to 75–99% ethanol for storage. Hemi-\nandrus wētā for the present study came from traps operating from\nNovember to May in 2004/2005 and 2005/2006 at two locations\nreferred  to  as  Lake  Head  Track  (6  traps)  and  Rotoiti  (20  traps)\n(Fig. 1). Weekly samples at each location were pooled by month to\nmaximize the representation of taxa and size classes.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.2**t== 0.4**l== 0.5**r== 0.1**\nSpecimen identification.—All malaise traps intercepted individuals\nof all three Hemiandrus species. Each wētā specimen was identi-\nfied to species using reproductive and other morphological traits\n(Fig. 2). In short, adult H. nox females have dark, patched, strong-\nly curved, long ovipositors in proportion to body length, and this\nspecies is sister to H. maculifrons (Taylor-Smith et al. 2016), which\nhas been studied in some detail as the synonym Zealandosandrus\ngracilis  (Cary  1981).  Male  H.  nox  have  a  short  sub-genital  plate\nwith a narrow apex with a U-shaped distal margin that may ex-\ntend  beyond  the  styles  (Taylor-Smith  et  al.  2016,  Trewick  et  al.\n2021). Adult H. electra females have moderately short ovipositors,\nand this species shows maternal care, as also seen in Hemiandrus\nbilobatus  Ander,  1938.  Male  H.  electra  have  blunt  cerci,  and  the\nsubgenital  plate  is  slightly  concave  at  the  margins  with  pointed\ndark  styli  (Taylor  Smith  et  al.  2013).  The  third  species  is  unde-\nscribed  but  included  in  a  list  of  possible  species  by  the  infor-\nmal  ‘tag’  name  H.  ‘disparalis’  (Johns  2001)  and  is  a  genetically\ndistinct  lineage  (Pratt  et  al.  2008).  Adult  H.  ‘disparalis’  females\nhave a long ovipositor. Categorising young nymphs into species\nlevel  using  only  their  reproductive  traits  was  challenging.  Thus,\ntwo further morphological characteristics were used (Fig. 2). The\nhairs on the maxillary palps can distinguish H. nox from the other\ntwo species (Johns 2001), and the presence or absence of a pro-\nlateral  spine  on  the  hind  femur  can  distinguish  H.  electra  from\nH. ‘disparalis’ (Fig. 2).\n**BLOCK**fs== 9.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nDiet  of  three  sympatric  ground  wētā  species.—We  targeted  the  crop\ncontent, not the midgut and hindgut, because food passes through\nthe  proventricular  and  is  partially  digested.  Therefore,  it  is  diffi-\ncult to identify food categories from these sections (Cary 1983).\nSixty-six adult wētā specimens (11 females and 11 males of each\nspecies)  were  randomly  selected.  The  crop  membrane  was  cut\nfrom  each  wētā  using  fine  tweezers;  care  was  taken  to  remove\nany broken membrane and fat. The crop contents were placed in\na beaker with household bleach (~5% sodium hypochlorite) for\ntwo minutes, then rinsed with running water for two minutes in\na 70-micron (uM) nylon cell strainer (Falcon brand). The collect-\ned crop content of one individual was mounted on a glass slide\nand  stained  using  a  frass-cuticle  stain  containing  basic  fuchsin.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nSlides were examined under an Olympus SZX7 stereomicroscope\n(Olympus Corporation, Tokyo, Japan). Each slide was systemati-\ncally scanned, and every fragment of food that could be identified\nwas recorded as either plant (e.g., phloem vessels, grass cells, leaf\ncuticle) or invertebrate fragments (insect exoskeleton, chitin, cu-\nticle,  antenna,  insect  leg,  mandible).  Fragments  not  identifiable\nas  plant  or  invertebrate  fragments  were  considered  uncommon\nand ignored. We did not try to further analyze the diet variation\nbetween the different months because no diet differences were vis-\nible  during  slide  scanning.  The  minimum  number  of  food  frag-\nments identified was 19, and the maximum was 81. From this, the\nmean proportion of the two food types eaten was calculated for\neach wētā and compared between the sexes and species. Images of\nthe crop content remains were taken using an Olympus SZX7 ster-\neomicroscope with an Olympus SC100 image capture (Olympus\nCorporation, Tokyo, Japan).\n**BLOCK**fs== 9.0**p== 2.0**b== 0.8**t== 0.1**l== 0.5**r== 0.0**\nfemur  length  (femur  length),  hind  femur  width  at  widest  point\n(femur width), and tibia length (Fig. 3). These metrics provide a\ngood guide of body size in hemimetabolous insects such as wētā\n(Bulgarella et al. 2014) and grasshoppers (Meza-Joya et al. 2022)\nand form the basis for analysis of insect size trends (Horne et al.\n2018, Meza-Joya et al. 2022).\n**BLOCK**fs== 9.0**p== 2.0**b== 0.7**t== 0.2**l== 0.5**r== 0.0**\nData analysis for diets of three sympatric ground wētā species.—Data\nwere  analyzed  using  R  v4.0.2  (R  Core  Team  2023)  with  the  R\npackage  multcomp,  and  graphs  were  generated  using  ggplot2\n(Wickham  2016).  We  used  the  linear  model  (lm  function  with\nfactors:  species,  sex,  diet  type  (plant  or  invertebrate),  and  pos-\nsible  interactions).  Residual  plots  and  Shapiro–Wilk  normality\ntests were used to confirm that the model assumptions were not\nviolated.  Significant  differences  were  determined  using  Tukey’s\nHSD test at p < 0.05.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nBody measurements and sex ratios.—A total of 966 insect specimens\nof the three wētā species caught from the malaise traps were used\nfor body measurements and sex ratio quantification. To evaluate\nthe relative abundance of males and females of each species, we\nused  the  morphological  and  sex  categorization  indicated  above.\nAn  Olympus  SZX7  Zoom  Stereomicroscope  with  an  attached\nSC100  digital  camera  image  capture  and  Olympus  CellSens  Di-\nmensions v1.6 software (Olympus Corporation Tokyo, Japan) was\nused to measure specimens. The right hind leg was removed from\neach wētā specimen, and the following items were measured: hind\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.4**l== 0.5**r== 0.0**\nData analysis for body size clusters.—For each of the three species, a\nsummary of statistics was generated using R v4.0.2 (R Core Team\n2023).  Body  size  distribution  was  analyzed  separately  for  the\nthree species because of the differences in body size. For example,\nH. ‘disparalis’ is larger than the other two species, while H. nox is\nthe smallest. Additionally, males and females were analyzed sepa-\nrately because females tend to be larger than males. Cluster classifi-\ncation analysis of body size measurements was conducted for only\nthe species with a large sample size (H. electra; n = 701), allowing\nmales  and  females  to  be  analyzed  separately.  Gaussian  mixture\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\nFig. 1. Location of two malaise trap sites east of Lake Rotoiti, South Island, New Zealand, in which samples of three species of Hemian-\ndrus ground wētā were collected. New Zealand Grid coordinates are shown on contour map (www.topomap.con.nz).\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nmodels  were  used  to  impartially  examine  size  distributions  of\nfemur length, femur width, and tibia length variation to find the\noptimal number of groups (using R package MCLUST). MCLUST\nis  a  model-based  clustering  tool  that  groups  data  with  similar\nproperties  and  automatically  determines  optimal  cluster  num-\nbers  in  the  analyzed  data  without  having  a  priori  labels  (Fraley\nand Raftery 2002). Bayesian information criteria (BIC) was used\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nto determine the optimal number of clusters. Scales R package was\nused to normalize the data because the data contained variation\nin specimen abundance, and this was to ensure that each measure-\nment  contributed  equally  to  the  clustering  process.  Cluster  data\nwere  generated  in  R  and  summarized  with  stacked  bars  plots  to\nillustrate the numbers of individuals in each cluster of each size\ncaught per month using Microsoft Excel®.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nFig. 2. Preserved ground wētā specimens from malaise traps deployed in St Arnaud Forest, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E)\nwere identified using morphological traits: A. Hemiandrus electra and H. ‘disparalis’ have fine hairs on segments of maxillary palp 5\n(mp5) and part of (mp4). B. Pilosity on maxillary palps extends to mp3 in H. nox. C. H. electra has few or no prolateral apical spines\non the hind femur. D. H. ‘disparalis’ has a stout spine apical spine on the hind femur. E. Male H. electra have a short, stout subgenital\nplate with shallow posterior dip and widely spaced short styli. F. Male H. ‘disparalis’ have a long, forked subgenital plate with long styli.\nG. Male H. nox have a relatively long, narrow, blunt subgenital plate with short styli. H–I. The sex of all instars can be determined by\nthe subgenital plate, with two styli in males (H) and four incipient ovipositor valves in females (I).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.7**t== 0.3**l== 0.1**r== 0.0**\nFig. 3. Hemiandrus specimens collected from native forest at St Arnaud, New Zealand were used for size dimension analysis. A. Hind leg\nmeasurements used for size analysis are femur length, femur width, and tibia length. B. This is an example of the size range identified\nwithin a single species of H. electra males.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.9**\nResults\n**BLOCK**fs== 9.0**p== 4.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nThis research aimed to understand the ecology of three Hemian-\ndrus species that co-occur in the same forest. The study focused on\nunderstanding the dietary compositions, relative abundances, and\nsex ratios of the three sympatric Hemiandrus species, as well as the\nsize distribution of the most common species (H. electra).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.4**l== 0.1**r== 0.5**\nDiet  of  three  sympatric  wētā  species.—All  66  specimens  examined\n(male  and  female)  contained  food  fragments  identified  as  being\nof plant and invertebrate origin, although this differed in propor-\ntion among the species. Overall, crop content analysis showed that\nH. nox had fed significantly more on invertebrates than the other\ntwo species (Fig. 4). Approximately 80% of crop contents from H.\nnox were fragments from the remains of prey animals, whereas H.\nelectra and H. ‘disparalis’ each had less than 20% of crop fragments\nidentified  as  invertebrate.  There  was  no  significant  difference  be-\ntween the diets of males and females in any of the three species (p\n= 0.646). Visual identification of the species of invertebrates and\nplants  each  fragment  represented  was  not  possible;  however,  the\nphysical form was diverse. The invertebrate remains included an-\ntennae, exoskeletons, spider legs, cuticle of a caterpillar, and man-\ndibles  (Fig.  5).  The  plant  fragments  showed  that  these  sympatric\nwētā species were polyphagous, as structures representing various\nplant types, including dicots and monocots, were observed (Fig. 6).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nRelative  abundance  and  sex  ratio  of  the  three  sympatric  Hemiandrus\nspecies.—A total of 966 wētā specimens were sorted from the ma-\nlaise traps. Of these, 701 specimens were identified as H. electra, and\n157 and 108 were identified as H. ‘disparalis’ and H. nox, respec-\ntively (Table 1). More individuals were trapped in January, February,\nand March (216, 268, and 170, respectively) than in November (56)\nand December (28). A higher abundance of males than females was\nobserved  during  the  study  period  (females  =  419,  males  =  547).\nHemiandrus  electra  had  an  almost  equal  sex  ratio  (355  males  and\n346 females), but males were more than twice as common in the\ntraps as females for H. ‘disparalis’ (118 males and 39 females) and\nH. nox (74 males and 34 females). Ratios in March had the highest\ndeviation from a 1:1 sex ratio, when 109 males were caught in the\nmalaise traps but only 61 females (Table 1).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nSize distribution of H. electra females.—The optimal number of clus-\nters identified by Gaussian mixture models allowed each specimen\nto be classified into one of five groups, with 1 being the smallest\nand 5 being the largest individuals. These clusters may represent\nthe different developmental growth stages (instars). Cluster 3 had\n**BLOCK**fs== 9.0**p== 4.0**b== 0.5**t== 0.3**l== 0.5**r== 0.0**\nthe most abundant specimens, while cluster 1 had the fewest speci-\nmens (Table 2). Cluster classifications based on the three variables\nmeasured  (tibia  length,  tibia  width,  and  femur  length)  showed\nthat the insects measured followed a linear growth pattern (Fig. 7).\nThe first cluster consisted of the smallest instars (nymphs), while\nthe largest specimens (cluster 5) were identified as adults. Individ-\nuals of H. electra for each of the five size clusters (putative instars)\nwere caught in traps in each month, with the exception of cluster\n1 (nymphs), which were absent in November (spring), December,\nand April (autumn; Fig. 8). Cluster 3 individuals were most abun-\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.0**\nFig. 4. Proportion (%) of food fragments in the crop of adult fe-\nmale (n = 11 for each species) and male (n = 11 for each species)\nwētā  that  derived  from  invertebrates.  All  other  food  particles  in\ntheir diet were identified as of plant origin. Hemiandrus ‘dispara-\nlis’ (n = 22), H. electra (n = 22), and H. nox (n = 22) collected in\nmalaise  traps  at  the  same  time  of  the  year  in  a  native  forest  in\nSt Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E). Data\nwere  analyzed  for  significant  differences  using  a  Tukey’s  (HSD)\ntest at the 5% level. Error bars indicate the standard errors from a\nlinear model.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\nFig. 5. Examples of food particles identified as invertebrate fragments, retrieved from the crop contents of three sympatric ground wētā spe-\ncies (Hemiandrus) caught in malaise traps from St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E), native forest. Scale bar: 200 µm.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nFig. 6. Examples of food particles identified as plant fragments retrieved from the crop contents of three sympatric ground wētā species\ncaught in malaise traps from St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E), native forest. Scale bar: 200 µm.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nTable 1. Abundance of three Hemiandrus wētā species caught in ma-\nlaise traps in native forest in St Arnaud, New Zealand, and the num-\nber of each species and each sex in respective months of sampling.\nData are combined for the 2004/2005 and 2005/2006 seasons.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.0**\ndant in January and February (summer). Although adult H. electra\n(cluster 5) were uncommon in November, some were present in\neach month sampled (Fig. 8).\n**BLOCK**fs== 8.0**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nSex H. ‘disparalis’ H. electra H. nox Total\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.2**l== 0.1**r== 0.9**\nMonth\nNovember\nNovember\nDecember\nDecember\nJanuary\nJanuary\nFebruary\nFebruary\nMarch\nMarch\nApril\nApril\nMay\nMay\nTotal\nTotal\nGrand\nTotal\n**BLOCK**fs== 8.0**p== 6.0**b== 0.6**t== 0.2**l== 0.2**r== 0.7**\nSeason\nFemale\nSpring\nSpring\nMale\nSummer Female\nSummer Male\nSummer Female\nSummer Male\nSummer Female\nSummer Male\nAutumn Female\nAutumn Male\nAutumn Female\nAutumn Male\nAutumn Female\nAutumn Male\nFemale\nMale\nFemale\n+ Male\n**BLOCK**fs== 9.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nTable 2. The numbers of insect specimens in each size cluster iden-\ntified  using  Gaussian  mixture  models  with  hind  leg  dimensions\nfor  Hemiandrus  electra  females  caught  in  malaise  traps  in  native\nforest in St Arnaud, New Zealand. Cluster 1 contains the smallest\nindividuals, and cluster 5 contains adults.\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\nClusters\nNumber of\nspecimens\n**BLOCK**fs== 8.0**p== 6.0**b== 0.4**t== 0.5**l== 0.2**r== 0.5**\nCluster 1 Cluster 2 Cluster 3 Cluster 4 Cluster 5 Total\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nDiscussion\n**BLOCK**fs== 9.0**p== 6.0**b== 0.7**t== 0.2**l== 0.5**r== 0.0**\nNew Zealand has a high diversity of nocturnal Orthoptera in\nthe  family  Anostostomatidae.  These  insects  are  likely  to  be  eco-\nlogically  important  in  natural  habitats  (Griffin  et  al.  2011)  and,\nin  some  modified  areas,  are  recognized  as  horticultural  pests\n(Nboyine et al. 2016, Trewick et al. 2021). However, there is still\nmuch to be learnt about their basic biology. This study obtained\nbaseline  ecological  knowledge  of  three  sympatric  wētā  species,\nH.  electra,  H.  ‘disparalis’,  and  H.  nox,  about  their  diet,  relative\nabundance, and life cycle patterns.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.4**t== 0.3**l== 0.5**r== 0.0**\nDiet of three sympatric Hemiandrus species.—Insects are categorized\nbased on their dietary specializations, ranging from monophagous\nto polyphagous (Agrawal and Klein 2000). This study showed that\nHemiandrus species feed on diverse plants (e.g., evidence of different\nplant epidermal cells, stoma, Fig. 6) and arthropod families (Fig. 5).\nOur observations are similar to those of other authors (Butts 1983,\nVan Wyngaarden 1995, Wahid 1979), confirming that ground wētā\nare omnivores. Diet proportions varied among the three sympatric\nHemiandrus species studied. Hemiandrus electra and H. ‘disparalis’\nfed more on plants than on invertebrates in contrast to H. nox. Vari-\nous explanations have been offered for why omnivores select food\nspecies and quantities. Trade-offs probably exist between nutrient\ncontent, plant secondary metabolites, species abundance, physical\ntraits, and opportunities. However, even at the coarse level of rela-\ntive dietary components, we found that H. nox fed more on inverte-\nbrates, which accounted for up to approximately 80% of their diet.\nThe diet of the closely related forest species H. maculifrons is almost\nentirely invertebrate (Cary 1983), similar to that of H. nox. A small\n**BLOCK**fs== 9.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.0**\nFig. 7. Gaussian mixture models produced 5 cluster classifications using size of Hemiandrus electra female specimens collected over\nseven months (November–May) from malaise traps in native forest in St Arnaud, New Zealand. Models are based on tibia length,\nfemur length, and femur width. (Purple = cluster 1, orange = cluster 2, blue = cluster 3, red = cluster 4 and green = cluster 5 (adults).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nH. pallitarsis (Walker 1869) prefers to climb beech trees rather than\nother adjacent tree species (Moeed and Meads 1983). Very probably,\nbehavior,  size,  reproductive  strategy,  diet,  and  other  biological  at-\ntributes can all be linked to the abundance variation of these three\nspecies,  which  may  be  phylogenetically  constrained.  However,  the\ncurrent study cannot determine the drivers of these differences.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.5**t== 0.2**l== 0.5**r== 0.1**\nSome previous studies of wētā in the family Anostostomatidae\nhave  found  population  samples  to  be  either  male-  or  female-bi-\nased; presumably, this is the result of using different survey meth-\nods. For example, stone wētā Hemideina maori (Joyce et al. 2004)\nand the tusk wētā Motuweta riparia (Gibbs 2002, McCartney et al.\n2006)  have  been  recorded  as  female-biased  populations,  while\nsome  studies  of  the  ground  wētā  Hemiandrus  found  the  sampled\npopulations  to  be  male-biased  (Chappell  et  al.  2014).  Sex  ratio\nvariation  may  be  subject  to  data  bias.  Thus,  factors  such  as  sam-\npling method and season must be considered. For example, during\nmating periods, ground wētā exit their burrows in search of mates,\nmaking 50:50 sex representations in traps likely during this period.\nAfter mating, females of some species with short ovipositors pro-\nvide maternal care (H. electra, H. bilobatus) in their burrows. After\nmating, males exit their burrows in search of food and mates, while\nfemales are brooding. Thus, sampling during this period may show\nmale-biased activity because females may rarely exit their burrows\nwhile  caring  for  eggs  and  nymphs  (Nboyine  et  al.  2016,  Browne\nand Gwynne 2023). The sex ratio of the Hemiandrus species studied\nhere and caught in the same malaise traps was biased in favor of\nmales for H. ‘disparalis’ and H. nox, with male numbers double that\nof females (118:39 and 74:34, respectively). Surprisingly, the spe-\ncies with maternal care, H. electra, had equal numbers of males and\nfemales caught in traps in all seven months sampled (355:346).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.2**t== 0.5**l== 0.5**r== 0.1**\nSize distribution of H. electra females.—Several studies of wētā size\ndistribution have suggested that the number of instars may range\nfrom  5  to  11,  for  example,  8  instars  in  Hemiandrus  celeano  (Wa-\nhid, 1979) and 10 or 11 in Deinacrida fallai Salmon, 1950 and D.\nheteracantha White 1842 (Richards 1973). Our Gaussian mixture\nmodel cluster classification of size measurements of H. electra fe-\nmales produced five size clusters of individuals. These five clusters\nmight represent five instars. The adult specimens were all assigned\nto cluster 5, but the smallest specimens (cluster 1) might not rep-\nresent  first  instar  nymphs.  Newly  hatched  (first  instar)  ground\nwētā might be too small to be trapped or to feed from the ground.\nOur  study  found  no  evidence  of  seasonality  in  the  growth\nand  development  of  H.  electra  based  on  the  population  sample\nintercepted in malaise traps, as almost every size class was found\nin each month, with the absence of the most undersized individu-\nals in November, December, and April. Similar to Leisnham et al.’s\n(2003) study of H. maori, we found that the smallest instars were\nmost  common  from  January  to  March.  During  this  time,  Leisn-\nham et al. (2003) also observed gravid females in H. maori; this is\npresumable when wētā oviposit.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\nConclusion\n**BLOCK**fs== 9.0**p== 7.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nThis  study  showed  that  ground  wētā  are  omnivorous  insects\nthat feed on both plants and invertebrates. This knowledge is vital\nfor understanding the ecology of wētā. Some wētā species have be-\ncome pests of economic importance in crops such as grapevines.\nThus, understanding the diet and plant species that wētā feed on\nin their natural habitats can help develop integrated pest manage-\nment options with plant species mostly favored in natural habi-\ntats. We found that the three sympatric species of Hemiandrus vary\n**BLOCK**fs== 9.0**p== 7.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nFig.  8.  Variation  in  size  class  abundance  of  female  Hemiandrus\nelectra collected over seven months (November–April) in malaise\ntraps in native forest in St Arnaud, New Zealand (-41°53'59.99\"S,\n172°51'59.99\"E).  Size  cluster  classification  using  the  Gaussian\nmixture model (n = 346).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nproportion  of  the  diet  of  H.  nox  was  plant  fragments  (10–20%),\nwhich  might  be  the  result  of  preying  on  invertebrates  with  plant\nfragments  in  their  guts  (Cary  1983).  During  opportunistic  night\nobservations, many species of Hemiandrus have been seen scaveng-\ning (Cary 1983), but observing the hunting and capture of live prey\nwould be much more challenging. The size of insect fragments in\nthe crop could suggest that H. nox are scavengers, although H. mac-\nulifrons is considered an active predator (Cary 1983).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\nUnlike other studies of ground wētā that found differences in\nthe diets of males and females (Wahid 1978), our study showed\nno  diet  differences  between  sexes  at  this  coarse  level,  and  these\nresults are similar to observations of other species (Ramsay 1955,\nRichards 1953, 1962, 1973). This is unexpected, as males and fe-\nmales are often thought to have different nutrient requirements.\nFor example, females are larger than males and require resources\nfor egg production. However, males may also require more nutri-\nents to present as nuptial gifts for females during mating, which\nmay justify the similarities in the diets of these males and females\n(Gwynne 2004, Browne and Gwynne 2022). The current study in-\nvestigated the dietary differences of adults and did not attempt to\ninvestigate the diet changes between successive instars. Most hem-\nimetabolous  insects  do  not  show  changes  in  diet  between  con-\nsecutive  stages  (Cary  1983).  However,  there  is  a  possibility  that\nadult  Hemiandrus  spp.  feed  on  larger  prey  that  they  can  subdue,\nwhile small instars may feed on smaller insects from Diptera and\nDiapriidae (Butts 1983, Cary 1983). Thus, further research on dif-\nferent life stages could reveal interesting dietary differences.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nRelative abundance and sex ratio.—Three species of Hemiandrus were\ncaught in the same malaise traps in a forest. We expected carnivo-\nrous species to be relatively less common than herbivorous species\nbecause,  in  general,  biomass  decreases  for  higher  trophic  levels  in\nfood webs. Although all three species had mixed diets (omnivores),\nthe species with the highest proportion of invertebrates in its diet (H.\nnox) was the least common in the traps. However, as we intercepted\nonly insects that climbed the malaise traps, it is possible the variation\nin  abundance  was  the  result  of  behavioral  differences  rather  than\nrelative population sizes in this forest habitat. Few data exist about\nthe activity of Hemiandrus species in forests. However, we know that\nmost species can be observed at night off the ground on foliage, and\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nin  abundance,  with  H.  electra  having  the  highest  relative  abun-\ndance when intercepted in malaise traps. Additionally, we found\nthat females of H. ‘disparalis’ and H. nox were not caught as often\nas males, but H. electra had an even sex ratio of trapped specimens.\nThis was somewhat surprising because H. electra is the only one of\nthe three Hemiandrus species studied here with maternal care be-\nhavior. Thus, adult males were expected to be more common than\nadult  females.  Distinct  sex  ratios,  diets,  and  abundance  suggest\nthat these three species are ecologically distinct. Given the ecologi-\ncal diversity we detected in sympatry, to understand the ecology of\nrelated Hemiandrus species, it is necessary to study populations in\ntheir natural habitats and not just extrapolate from related taxa.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\nAcknowledgements\n**BLOCK**fs== 9.0**p== 8.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nSpecial  thanks  to  the  Bragato  Research  Institute  (BRI),  Con-\nstellation  Brands,  Indevin,  Pernod-Ricard,  Yealands,  and  Hortus\nfor funding the studentship that produced this publication. Our\ngratitude  goes  to  Melisa  Griffin,  who  provided  access  to  the  in-\nsect  samples  and  information  on  the  locations  of  malaise  traps.\nWe would like to thank Plant and Food internal reviewers Abby\nAlbright,  Mette  Nielsen,  Lisa  Watkins,  and  Dave  Bellamy.  Many\nthanks to Sigfrid Ingrisch for reviewing this paper. Our gratitude\ngoes to Sinclair Chinyoka, who guided us with data analysis. We\nare grateful for the support and contributions of the Phoenix Lab\nmembers (www.evolves.massey.ac.nz/).\n**BLOCK**fs== 9.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nReferences\n**BLOCK**fs== 8.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nAnder  (1938)  Diagnosen  neuer  Laubheuschrecken.  Opuscula  Entomo-\n**BLOCK**fs== 8.0**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nlogica, 50–56.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nAgrawal  AA,  Klein  CN  (2000)  What  omnivores  eat:  Direct  effects  of  in-\nduced plant resistance on herbivores and indirect consequences for\ndiet selection by omnivores. Journal of Animal Ecology 69: 525–535.\nhttps://doi.org/10.1046/j.1365-2656.2000.00416.x\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nBarbosa P, Caldas A, Godfray HCJ (2007) Comparative food web structure\nof larval macrolepidoptera and their parasitoids on two riparian tree\nspecies.  Ecological  Research  22:  756–766.  https://doi.org/10.1007/\ns11284-006-0316-1\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nBlanchard E (1851) Fauna Chilena. Insectos. Orden IV. Ortoperos. In: Gay\nC (Ed.) Historiajsica y politica de Chile. Zoologia Vol. 6 & Atlas Zoo-\nlogico-Entomologia, Ortopteros. Chilean Government, Paris, 41–42.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nBrown M (2013) the diet and nutritional ecology of the auckland tree wētā\nHemideina thoracica. Thesis, Master of Science, University of Waikato,\nHamilton, New Zealand.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nBrowne  JH,  Gwynne  DT  (2022)  Paternity  sharing  in  insects  with  female\ncompetition  for  nuptial  gifts.  Ecology  and  Evolution  12:  e9463.\nhttps://doi.org/10.1002/ece3.9463\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nBrowne JH, Gwynne DT (2023) Sexual selection on a female copulatory\ndevice in an insect with nuptial gifts. Behavioral Ecology and Sociobi-\nology 77: 7–9. https://doi.org/10.1007/s00265-023-03415-6\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nBuller (1871) Notes on the genus Deinacrida in New Zealand. Transactions\nof the New Zealand Institute 3: 34–37. http://rsnz.natlib.govt.nz/vol-\nume/rsnz_03/rsnz_03_00_002320.html\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nBulgarella  M,  Trewick  SA,  Minards  NA,  Jacobson  MJ,  Morgan-Richards\nM (2014) Shifting ranges of two tree weta species (Hemideina spp.):\nCompetitive  exclusion  and  changing  climate.  Journal  of  Biogeogra-\nphy 41: 524–535. https://doi.org/10.1111/jbi.12224\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nButts  CA  (1983)  The  biologies  of  two  species  of  weta  endemic  to  the\nSnares  Island  Zealandosandrus  subantarcticus  Salmon  (Orthoptera:\nStenopelmatidae)  and  Insulanoplectron  spinosum  Richards  (Orthop-\ntera: Rhaphidophoridae). University of Canterbury.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nCary PRL (1981) The biology of the weta Zealandosandrus gracilis (Orthop-\ntera: Stenopelmatidae) from the Cass region [M.Sc thesis]. University\nof Canterbury, Christchurch (New Zealand).\n**BLOCK**fs== 8.0**p== 8.0**b== 0.8**t== 0.1**l== 0.5**r== 0.0**\nCary PRL (1983) Diet of the ground weta Zealandosandrus gracilis (Orthop-\ntera:  Stenopelmatidae).  New  Zealand  Journal  of  Zoology  10:  295–\n298. https://doi.org/10.1080/03014223.1983.10423918\n**BLOCK**fs== 8.0**p== 8.0**b== 0.8**t== 0.2**l== 0.5**r== 0.0**\nChappell  EM,  Webb  DS,  Tonkin  JD  (2014)  Notes  on  sexual  size  dimor-\nphism,  sex  ratio  and  movements  of  adult  ground  weta  Hemiandrus\nmaculifrons  (Walker)  (Orthoptera: Anostostomatidae). New  Zealand\nEntomologist 37: 83–92. https://doi.org/10.1080/00779962.2013.85\n**BLOCK**fs== 8.0**p== 8.0**b== 0.7**t== 0.2**l== 0.5**r== 0.0**\nDewhurst R (2012) The diet of tree weta: natural and captive folivory pref-\nerences of Hemideina crassidens and Hemideina thoracica. Massey Uni-\nversity.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.7**t== 0.3**l== 0.5**r== 0.0**\nEubanks MD, Denno RF (2000) Host plants mediate omnivore-herbivore\ninteractions  and  influence  prey  suppression.  Ecology  81:  936–947.\nhttps://doi.org/10.1890/0012-9658(2000)081[0936:HPMOHI]2.0.\nCO;2\n**BLOCK**fs== 8.0**p== 8.0**b== 0.6**t== 0.3**l== 0.5**r== 0.0**\nField  LH,  Jarman  TH  (2001)  Mating  Behaviours.  In:  Field  LH  (Ed.)  The\nBiology  of  Wetas,  King  Crickets  and  their  Allies.  CABI  Publishing,\nOxford UK, 317–332. https://doi.org/10.1079/9780851994086.0317\nFraley  C,  Raftery  AE  (2002)  Model-Based  Clustering,  Discri-\nminant  Analysis,  and  Density  Estimation.\nthe\nAmerican  Statistical  Association  97:  611–631.  https://doi.\norg/10.1198/016214502760047131\n**BLOCK**fs== 8.0**p== 8.0**b== 0.6**t== 0.4**l== 0.9**r== 0.1**\nJournal  of\n**BLOCK**fs== 8.0**p== 8.0**b== 0.6**t== 0.4**l== 0.5**r== 0.0**\nGibbs  GW  (2002)  A  new  species  of  tusked  weta  from  the  Raukumara\nRange,  North  Island,  New  Zealand  (Orthoptera:  Anostostomatidae:\nMotuweta).  New  Zealand  Journal  of  Zoology  29:  293–301.  https://\ndoi.org/10.1080/03014223.2002.9518313\n**BLOCK**fs== 8.0**p== 8.0**b== 0.5**t== 0.4**l== 0.5**r== 0.0**\nGodfrey  AJR,  McKenzie  AO,  Morgan-Richards  M  (2023)  Recommenda-\ntions for non-lethal monitoring of tree wētā (Hemideina spp.) using\nartificial  galleries.  New  Zealand  Journal  of  Zoology  50:  381–393.\nhttps://doi.org/10.1080/03014223.2022.2076704\n**BLOCK**fs== 8.0**p== 8.0**b== 0.5**t== 0.5**l== 0.5**r== 0.0**\nGriffin MJ, Morgan-Richards M, Trewick SA (2011) Is the tree weta Hemidei-\nna crassidens an obligate herbivore? In New Zealand Natural Sciences\n36: 11–19. https://www.nznaturalsciences.org.nz\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.5**l== 0.5**r== 0.0**\nGwynne  DT  (2004)  Reproductive  behavior  of  ground  weta  (Orthoptera:\nAnostostomatidae): Drumming behavior, nuptial feeding, post-cop-\nulatory guarding, and maternal care. Journal of the Kansas Entomo-\nlogical Society 77: 414–428. https://doi.org/10.2317/E-34.1\n**BLOCK**fs== 8.0**p== 8.0**b== 0.4**t== 0.6**l== 0.5**r== 0.0**\nHamer KC, Hill JK, Benedick S, Mustaffa N, Chey VK, Maryati M (2006)\nDiversity  and  ecology  of  carrion-  and  fruit-feeding  butterflies  in\nBornean rain forest. Journal of Tropical Ecology 22: 25–33. https://\ndoi.org/10.1017/S0266467405002750\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.6**l== 0.5**r== 0.0**\nHorne  CR,  Hirst  AG,  Atkinson  D  (2018)  Insect  temperature–body  size\ntrends common to laboratory, latitudinal and seasonal gradients are\nnot found across altitudes. Functional Ecology 32: 948–957. https://\ndoi.org/10.1111/1365-2435.13031\n**BLOCK**fs== 8.0**p== 8.0**b== 0.3**t== 0.7**l== 0.5**r== 0.0**\nJohns  PM  (1997)  The  Gondwanaland  Weta:  Family  Anostostomati-\ndae  (formerly  in  Stenopelmatidae,  Henicidae  or  Mimnermidae):\nNomenclatural  Problems,  World  Checklist,  New  Genera  and  Spe-\ncies.  In  Journal  of  Orthoptera  Research  6:  125–138.  https://doi.\norg/10.2307/3503546\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.7**l== 0.5**r== 0.0**\nJohns  PM  (2001)  Distribution  and  conservation  status  of  ground  weta,\nHemiandrus  species  (Orthoptera:  Anostostomatidae).  Science  for\nConservation 180: 8–12.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.0**\nJoyce SJ, Jamieson IG, Barker R (2004) Mark-recapture. New Zealand Jour-\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nnal of Ecology 28: 57–59.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.2**t== 0.8**l== 0.5**r== 0.0**\nKaplan  I,  Denno  RF  (2007)  Interspecific  interactions  in  phytophagous\ninsects  revisited:  A  quantitative  assessment  of  competition  theo-\nry.  Ecology  Letters  10:  977–994.  https://doi.org/10.1111/j.1461-\n0248.2007.01093.x\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.8**l== 0.5**r== 0.0**\nKirby  WF  (1899)  Notes  on  a  collection  of  Gryllidae,  Stenopelmatidae;\nGryllacridae, and Hetrodidae formed by Mr. W.L. Distant in the Trans-\nvaal and other South- and East-African localities. Annals and Maga-\nzine  of  Natural  History  3:  475–480.  http://www.biodiversitylibrary.\norg/item/63341#page/515/mode/1up\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.0**\nKursar  TA,  Wolfe  B  T,  Epps  M  J,  Coley  PD  (2006)  Food  quality,  compe-\ntition,  and  parasitism  influence  feeding  preference  in  a  neotropical\nlepidopteran. Ecology 87: 3058–3069. https://doi.org/10.1890/0012-\n9658(2006)87[3058:FQCAPI]2.0.CO;2\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nLawrence RK, Mattson WJ, Haack RA (1997) White spruce and the spruce\nbudworm: Defining the phenological window of susceptibility. Canadi-\nan Entomologist 129: 291–318. https://doi.org/10.4039/Ent129291-2\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nLeisnham PT, Cameron C, Jamieson IG (2003) Life cycle, survival rates and\nlongevity  of  an  alpine  weta  Hemideina  maori  (Orthoptera:  Anostos-\ntomatidae) determined using mark-recapture analysis. New Zealand\nJournal  of  Ecology  27:  193–197.  http://www.phidot.org/software/\nmark/docs/book/\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nMcCartney  J,  Armstrong  DP,  Gwynne  DT,  Kelly  CD,  Barker  RJ  (2006)\nEstimating abundance, age structure and sex ratio of a recently discov-\nered New Zealand tusked weta Motuweta riparia (Orthoptera, Anosto-\nstomatidae), using mark-recapture analysis. New Zealand Journal of\nEcology 30. http://www.nzes.org.nz/nzje\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nfrom  New  Zealand.  Journal  of  Zoology  169:  195–236.  https://doi.\norg/10.1111/j.1469-7998.1973.tb04554.x\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nSalmon JT (1950) A revision of the New Zealand wetas Anostostominae\n(Orthoptera: Stenopelmatidae). Dom Mus Rec Entomology 1: 121–\n177.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nTaylor  Smith  BL,  Morgan-Richards  M,  Trewick  SA  (2013)  New  Zealand\nground  wētā  (Anostostomatidae:  Hemiandrus):  Descriptions  of  two\nspecies with notes on their biology. New Zealand Journal of Zoology\n40: 314–329. https://doi.org/10.1080/03014223.2013.804422\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nTaylor-Smith  BL,  Trewick  SA,  Morgan-Richards  M  (2016)  Three  new\nground  wētā  species  and  a  redescription  of  Hemiandrus  maculifrons.\nNew Zealand Journal of Zoology 43: 363–383. https://doi.org/10.108\n0/03014223.2016.1205109\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nMcintyre  M  (2001)  The  Ecology  of  Some  Large  Weta  Species  in  New\nZealand. Chapter 12. In: Field LH (Ed.) The Biology of Wetas, King\nCrickets and their Allies. CABI publishing, 12: 229–233. https://doi.\norg/10.1079/9780851994086.0225\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nToms  RB  (2001)  South  African  King  Crickets  (Anostostomatidae).\nIn:  Field  LH  (Ed.)  The  Biology  of  Wetas,  King  Crickets  and\nTheir  Allies.  CABI  Publishing,  Oxford  UK,  73–79.  https://doi.\norg/10.1079/9780851994086.0073\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nMeza-Joya  FL,  Morgan-Richards  M,  Trewick  SA  (2022)  Relationships\namong body size components of three flightless New Zealand grass-\nhopper  species  (Orthoptera,  Acrididae)  and  their  ecological  ap-\nplications.  Journal  of  Orthoptera  Research  31:  91–103.  https://doi.\norg/10.3897/jor.31.79819\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nMoeed  A,  Meads  MJ  (1983)  Invertebrate  fauna  of  four  tree  species  in\nOrongorongo valley, New Zealand, as revealed by trunk traps. New\nZealand Ecological Society 6: 39–53. https://newzealandecology.org/\nnzje/1570\n**BLOCK**fs== 8.0**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nMonteith GB, Field LH (2001) The Biology of Wetas, King Crickets and Their\nAllies. In: Field LH (Ed.) Australian king crickets: distribution, habi-\ntats and biology (Orthoptera: Anostostomatidae). CABI Publishing,\nOxford, UK, 285–291. https://doi.org/10.1079/9780851994086.0079\nNboyine JA, Boyer S, Saville DJ, Wratten SD (2018) Agroecological man-\nagement of a soil-dwelling orthopteran pest in vineyards. Insect Sci-\nence 25: 475–486. https://doi.org/10.1111/1744-7917.12425\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nTorres-Vila  LM,  Rodríguez-Molina  MC  (2002)  Egg  size  variation  and  its\nrelationship with larval performance in the Lepidoptera: The case of\nthe  European  grapevine  moth  Lobesia  botrana.  Oikos  99:  272–283.\nhttps://doi.org/10.1034/j.1600-0706.2002.990207.x\n**BLOCK**fs== 8.0**p== 9.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nTrewick SA, Taylor-Smith B, Morgan-Richards M (2021) Ecology and sys-\ntematics of the wine wētā and allied species, with description of four\nnew Hemiandrus species. New Zealand Journal of Zoology 48: 47–80.\nhttps://doi.org/10.1080/03014223.2020.1790396\n**BLOCK**fs== 8.0**p== 9.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nTurney S, Altshuler I, Whyte LG, Buddle CM (2018) Macroinvertebrate and\nsoil prokaryote communities in the forest–tundra ecotone of the Sub-\narctic Yukon. Polar Biology 41: 1619–1633. https://doi.org/10.1007/\ns00300-018-2330-5\n**BLOCK**fs== 8.0**p== 9.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nVandermeer  J,  Evans  MA,  Foster  P,  Hö  T,  Reiskind  M,  Wund  M  (2002)\nIncreased  competition  may  promote  species  coexistence.  Proceed-\nings of the National Academy of Science 99: 8731–8736. https://doi.\norg/10.1073/pnas.142073599\n**BLOCK**fs== 8.0**p== 9.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nNboyine JA, Boyer S, Saville D, Smith MJ, Wratten SD (2016) Ground wētā\nin vines of the Awatere Valley, Marlborough: biology, density and dis-\ntribution. New Zealand Journal of Zoology 43: 336–350. https://doi.\norg/10.1080/03014223.2016.1193548\n**BLOCK**fs== 8.0**p== 9.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nVan Wyngaarden F (1995) The ecology of the Tekapo ground weta (Hemian-\ndrus new sp.; Orthoptera: Anostostomatidae) and recommendations\nfor the conservation of a threatened close relative. Unpublished MSc\nthesis. University of Canterbury.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nPaton BR, Maitland MJ, Taylor GE, Knevel AWJ, Parlane K, Wotherspoon JA,\nGasson P (2004) Rotoiti Nature Recovery Project annual report July\n2003–June 2004: St Arnaud’s mainland island, Nelson Lakes Nation-\nal  Park.  Dept  of  Conservation,  Nelson/Marlborough  Conservancy.\nhttps://www.doc.govt.nz/globalassets/documents/conservation/\nland-and-freshwater/land/rotoiti-annual-report-2003-2004.pdf\nPratt RC, Morgan-Richards M, Trewick SA (2008) Diversification of New\nZealand weta (Orthoptera: Ensifera: Anostostomatidae) and their re-\nlationships in Australasia. Philosophical Transactions of the Royal So-\nciety B: Biological Sciences 363: 3427–3437. https://doi.org/10.1098/\nrstb.2008.0112\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nRamsay GW (1955) The exoskeleton and musculature of the head, and the\nlife cycle of Deinacrida rugosa Buller, 1870. Unpublished MSc thesis.\nVictoria University of Wellington.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nR Core Team (2023) R: A Language and Environment for Statistical Com-\nputing.  R  Foundation  for  Statistical  Computing,  Vienna,  Austria.\nhttps://www.R-project.org/\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nRibeiro DB, Freitas AVL (2011) Large-sized insects show stronger season-\nality than small-sized ones: A case study of fruit-feeding butterflies.\nBiological Journal of the Linnean Society 104: 820–827. https://doi.\norg/10.1111/j.1095-8312.2011.01771.x\n**BLOCK**fs== 8.0**p== 9.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nWahid MB (1979) The biology and economic impact of the weta, Hemian-\ndrus sp. (Orthoptera: Stenopelmatidae) in an apricot orchard, Horo-\ntane Valley. MSc thesis. University of Canterbury, Lincoln College.\nWalker F (1869) In Catalogue of the Specimens of Dermaptera Salta toria\nin  the  Collection  of  the  British  Museum.  London,  Vol.  1,  1–224.\nhttp://www.archive.org/details/catalogueofspeci01britrich\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nWehi  PM,  Hicks  BJ  (2010)  Isotopic  fractionation  in  a  large  herbivorous\ninsect, the Auckland tree weta. Journal of Insect Physiology 56: 1877–\n1882. https://doi.org/10.1016/j.jinsphys.2010.08.005\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nWehi  PM,  Jorgensen  M,  Morgan-Richards  M  (2012)  Sex-and  season-\ndependent  behaviour  in  a  flightless  insect,  the  Auckland  tree  weta\n(Hemideina  thoracica).  New  Zealand  Journal  of  Ecology  37:  75–82.\nhttp://www.newzealandecology.org/nzje/\n**BLOCK**fs== 8.0**p== 9.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nWhite A (1842) Description of an orthopterous insect from New Zealand.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.7**l== 0.5**r== 0.2**\nThe Zoological Miscellany [Gray, J.E.], 78.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nWhite A (1846) Insects of New Zealand. In: Richardson J, Gray JE (Eds)\nThe zoology of the voyage of H.M.S. Erebus & Terror under command\nof Captain Sir J. C. Ross, during the years 1839–1843. London: E. W.\nJanson, 1–51.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nWickham  H  (2016)  ggplot2.  Springer  International  Publishing.  https://\n**BLOCK**fs== 8.0**p== 9.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\ndoi.org/10.1007/978-3-319-24277-4\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nRichards AM (1953) The anatomy, morphology, and habits of Pachyrhamma\nfascifer  (Walker,  1869)  (Orthoptera,  Rhaphidophoridae).  Victoria\nUniversity of Wellington.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nRichards AM (1962) Feeding behaviour and enemies of Rhaphidophori-\ndae (Orthoptera) from Waitomo Caves, New Zealand. Transactions of\nthe Royal Society of New Zealand: Zoology 2: 121–129.\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nRichards AM (1973) A comparative study of the biology of the giant we-\ntas  Deinaarida  heteracantha  and  D.  fallai  (Orthoptera:  Henicinae)\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nWilson GC, Jamieson IG (2005) Does melanism influence the diet of the\nmountain  stone  weta  Hemideina  maori  (Orthoptera:  Anostostoma-\ntidae)?  New  Zealand  Journal  of  Ecology  29:  149–152.  http://www.\nnzes.org.nz/nzje\n**BLOCK**fs== 8.0**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWyman TE, Trewick SA, Morgan-Richards M, Noble ADL (2011) Mutual-\nism or opportunism? Tree fuchsia (Fuchsia excorticata) and tree weta\n(Hemideina)  interactions.  Austral  Ecology  36:  261–268.  https://doi.\norg/10.1111/j.1442-9993.2010.02146.x",
         "Comparison of growth, relative abundance, and diet of three sympatric Hemiandrus ground wētā (Orthoptera, Anostostomatidae) in a New Zealand Forest In New Zealand, 19 described species of flightless Orthoptera are in the genus Hemiandrus Ander, 1938 (Anostostomatidae). All are active at night, using burrows in the soil during the day to hide from predators, from where their common name, ground wētā, is derived. There is limited knowledge of wētā ecology in relation to activity, growth and development, and diet because of the insect’s nocturnal behavior, but diet is known to vary within the Anostos- tomatidae family in New Zealand and elsewhere. At the genus level, Hemiandrus in New Zealand are mostly omnivores (Wahid 1979, Butts 1983, Van Wyngaarden 1995), but where data are available, there  is  evidence  that  individual  species  differ  in  diet.  For  exam- ple, H. maculifrons (Walker 1869) has been found to be primarily carnivorous  (Cary  1983),  while  H.  maia  Taylor  Smith,  Morgan- Richards, Trewick 2013 has been observed to consume fruit, inver- tebrates, and seeds (Taylor Smith et al. 2013). Similarly, diet varies in the related genus of endemic Hemideina White 1846 tree wētā. Hemideina maori (Pictet & Saussure, 1891) feeds on invertebrates, plants, and lichen (Wilson and Jamieson 2005), while Hemideina thoracica  White  1846  is  primarily  herbivorous  (Wehi  and  Hicks 2010, Brown 2013). It has been concluded that H. crassidens (Blan- chard  1851)  is  opportunistic  in  dietary  choice,  although  plants make up a major part of the food of this species (Griffin et al. 2011, Wyman et al. 2011, Dewhurst 2012). Deinacrida (White 1842) (gi- ant wētā), such as D. rugosa (Buller 1871), are primarily herbivores (Mcintyre  2001),  but  the  New  Zealand  tusked  wētā  Motuweta  ri- paria (Johns 1997) is predatory (Gibbs 2002, Trewick pers. obs.). Overseas, the South African species Libanasa vittatus (Kirby 1899) is considered omnivorous but can be predatory (Toms 2001), and the  diet  of  Australian  Anostostomatidae  spans  invertebrates  and fungi (Monteith and Field 2001). Variations in the feeding behav- ior of wētā species occupying the same environment could be evi- dence of resource partitioning, a strategy that reduces competition for limited resources. An equilibrium is unlikely when more than one species share the same resources, and competitive exclusion is thought to eventually lead to either the extinction of all but one species or to resource partitioning (Vandermeer et al. 2002). Thus, sympatric  species  may  coexist  using  different  resources  (Agrawal and  Klein  2000,  Eubanks  and  Denno  2000,  Kaplan  and  Denno 2007). Diet is often linked to relative abundance, with predatory species often occurring at lower densities than related herbivores in the same ecosystem (Turney et al. 2018). Differences  in  diet  due  to  sex  and  developmental  stage  have been observed in Hemiandrus ground wētā. Studies of Hemiandrus celeano  Trewick,  Taylor-Smith,  Morgan-Richards  2020  showed diet differences between the sexes (Wahid 1979), while H. subant- arcticus (Salmon 1950) differed among age classes (Butts 1983). However, neither H. maculifrons nor the undescribed Hemiandrus species collected from Tekapo showed sex or size variations in their diet (Cary 1983, Van Wyngaarden 1995). Research gaps remain re- garding what determines diet variation in Anostostomatidae. In contrast to diet, reproduction and seasonality have been well studied in the Anostostomatidae family (Field and Jarman 2001, Gwynne 2004, Wehi et al. 2012). Current knowledge of Hemian- drus ground wētā reproduction suggests that all species have over- lapping generations with mating and egg laying between January and March (summer, autumn) (Gwynne 2004), although there is the possibility of females laying eggs in other months (Nboyine et al. 2018). Most arthropods show seasonal variation in reproduc- tion,  which  may  be  controlled  by  different  factors  (Ribeiro  and Freitas  2011).  For  example,  optimum  temperature  and  humidity favor  some  species  to  mate  and  oviposit,  and  some  insects  may avoid emerging when parasitoids (Barbosa et al. 2007) or preda- tion  threaten  their  survival  (Torres-Vila  and  Rodríguez-Molina 2002). One aspect that could affect seasonal variation in insects is  the  availability  of  vital  resources  that  should  be  in  synchrony with the larval or adult phase, and fewer of these resources could compromise the fitness of organisms (Torres-Vila and Rodríguez- Molina 2002, Kursar et al. 2006). In some forests, resources could be available all year round (Cary 1983), but the quality of these resources may vary (Lawrence et al. 1997). For instance, when new leaves emerge in forests, this could mean that the leaves are highly nutritious, with higher nitrogen, sugars, and amino acid contents than  older  leaves  (Hamer  et  al.  2006).  Therefore,  such  seasonal resource availability could affect mating or oviposition, and thus influence insect seasonality. This study gleaned new ecological information about three en- demic ground wētā species that co-occur in the same temperate rain forest: Hemiandrus electra Taylor Smith, Morgan-Richards & Trewick, 2013, H. nox Taylor-Smith, Trewick & Morgan-Richards, 2016, and an  undescribed  Hemiandrus  species  (Johns  2001).  We  addressed four  main  questions:  1)  What  are  the  main  constituents  of  their diet? We expected all three wētā species to be omnivores, but the relative proportions of plant and animal matter might differ among species and sexes. As some Hemiandrus species are pests of economic importance in New Zealand (Nboyine et al. 2016), understanding the natural diet of related taxa could affect management decisions. 2) What are the relative abundances and sex ratios of these three sympatric  species  based  on  intercept  trapping?  Some  Hemiandrus species show maternal care, and females are less active when attend- ing to eggs and nymphs within soil burrows (Gwynne 2004). We expected that H. electra would have fewer active adult females than males, compared with the other two Hemiandrus species. 3) What is the size distribution of the common Hemiandrus species caught in malaise traps? Are these species univoltine or multivoltine, as are other members of this insect family (Godfrey et al. 2023)? Materials and methods Study site.—The three species of Hemiandrus were sampled as by- catch in a long-running Vespula wasp management program in Ro- toiti Mainland Island near St Arnaud South Island, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E) (Paton et al. 2007). Groups of malaise traps were set in the mature temperate native forest domi- nated by evergreen beech (Fuscospora) species. Each malaise trap was positioned at ground level and fitted with glycol and detergent collection  bottles  to  preserve  invertebrates  that  climbed  or  flew to  the  apex  of  the  trap.  Traps  were  cleared  weekly,  and  samples were sorted and transferred to 75–99% ethanol for storage. Hemi- andrus wētā for the present study came from traps operating from November to May in 2004/2005 and 2005/2006 at two locations referred  to  as  Lake  Head  Track  (6  traps)  and  Rotoiti  (20  traps) (Fig. 1). Weekly samples at each location were pooled by month to maximize the representation of taxa and size classes. Specimen identification.—All malaise traps intercepted individuals of all three Hemiandrus species. Each wētā specimen was identi- fied to species using reproductive and other morphological traits (Fig. 2). In short, adult H. nox females have dark, patched, strong- ly curved, long ovipositors in proportion to body length, and this species is sister to H. maculifrons (Taylor-Smith et al. 2016), which has been studied in some detail as the synonym Zealandosandrus gracilis  (Cary  1981).  Male  H.  nox  have  a  short  sub-genital  plate with a narrow apex with a U-shaped distal margin that may ex- tend  beyond  the  styles  (Taylor-Smith  et  al.  2016,  Trewick  et  al. 2021). Adult H. electra females have moderately short ovipositors, and this species shows maternal care, as also seen in Hemiandrus bilobatus  Ander,  1938.  Male  H.  electra  have  blunt  cerci,  and  the subgenital  plate  is  slightly  concave  at  the  margins  with  pointed dark  styli  (Taylor  Smith  et  al.  2013).  The  third  species  is  unde- scribed  but  included  in  a  list  of  possible  species  by  the  infor- mal  ‘tag’  name  H.  ‘disparalis’  (Johns  2001)  and  is  a  genetically distinct  lineage  (Pratt  et  al.  2008).  Adult  H.  ‘disparalis’  females have a long ovipositor. Categorising young nymphs into species level  using  only  their  reproductive  traits  was  challenging.  Thus, two further morphological characteristics were used (Fig. 2). The hairs on the maxillary palps can distinguish H. nox from the other two species (Johns 2001), and the presence or absence of a pro- lateral  spine  on  the  hind  femur  can  distinguish  H.  electra  from H. ‘disparalis’ (Fig. 2). Diet  of  three  sympatric  ground  wētā  species.—We  targeted  the  crop content, not the midgut and hindgut, because food passes through the  proventricular  and  is  partially  digested.  Therefore,  it  is  diffi- cult to identify food categories from these sections (Cary 1983). Sixty-six adult wētā specimens (11 females and 11 males of each species)  were  randomly  selected.  The  crop  membrane  was  cut from  each  wētā  using  fine  tweezers;  care  was  taken  to  remove any broken membrane and fat. The crop contents were placed in a beaker with household bleach (~5% sodium hypochlorite) for two minutes, then rinsed with running water for two minutes in a 70-micron (uM) nylon cell strainer (Falcon brand). The collect- ed crop content of one individual was mounted on a glass slide and  stained  using  a  frass-cuticle  stain  containing  basic  fuchsin. Slides were examined under an Olympus SZX7 stereomicroscope (Olympus Corporation, Tokyo, Japan). Each slide was systemati- cally scanned, and every fragment of food that could be identified was recorded as either plant (e.g., phloem vessels, grass cells, leaf cuticle) or invertebrate fragments (insect exoskeleton, chitin, cu- ticle,  antenna,  insect  leg,  mandible).  Fragments  not  identifiable as  plant  or  invertebrate  fragments  were  considered  uncommon and ignored. We did not try to further analyze the diet variation between the different months because no diet differences were vis- ible  during  slide  scanning.  The  minimum  number  of  food  frag- ments identified was 19, and the maximum was 81. From this, the mean proportion of the two food types eaten was calculated for each wētā and compared between the sexes and species. Images of the crop content remains were taken using an Olympus SZX7 ster- eomicroscope with an Olympus SC100 image capture (Olympus Corporation, Tokyo, Japan). femur  length  (femur  length),  hind  femur  width  at  widest  point (femur width), and tibia length (Fig. 3). These metrics provide a good guide of body size in hemimetabolous insects such as wētā (Bulgarella et al. 2014) and grasshoppers (Meza-Joya et al. 2022) and form the basis for analysis of insect size trends (Horne et al. 2018, Meza-Joya et al. 2022). Data analysis for diets of three sympatric ground wētā species.—Data were  analyzed  using  R  v4.0.2  (R  Core  Team  2023)  with  the  R package  multcomp,  and  graphs  were  generated  using  ggplot2 (Wickham  2016).  We  used  the  linear  model  (lm  function  with factors:  species,  sex,  diet  type  (plant  or  invertebrate),  and  pos- sible  interactions).  Residual  plots  and  Shapiro–Wilk  normality tests were used to confirm that the model assumptions were not violated.  Significant  differences  were  determined  using  Tukey’s HSD test at p < 0.05. Body measurements and sex ratios.—A total of 966 insect specimens of the three wētā species caught from the malaise traps were used for body measurements and sex ratio quantification. To evaluate the relative abundance of males and females of each species, we used  the  morphological  and  sex  categorization  indicated  above. An  Olympus  SZX7  Zoom  Stereomicroscope  with  an  attached SC100  digital  camera  image  capture  and  Olympus  CellSens  Di- mensions v1.6 software (Olympus Corporation Tokyo, Japan) was used to measure specimens. The right hind leg was removed from each wētā specimen, and the following items were measured: hind Data analysis for body size clusters.—For each of the three species, a summary of statistics was generated using R v4.0.2 (R Core Team 2023).  Body  size  distribution  was  analyzed  separately  for  the three species because of the differences in body size. For example, H. ‘disparalis’ is larger than the other two species, while H. nox is the smallest. Additionally, males and females were analyzed sepa- rately because females tend to be larger than males. Cluster classifi- cation analysis of body size measurements was conducted for only the species with a large sample size (H. electra; n = 701), allowing males  and  females  to  be  analyzed  separately.  Gaussian  mixture Fig. 1. Location of two malaise trap sites east of Lake Rotoiti, South Island, New Zealand, in which samples of three species of Hemian- drus ground wētā were collected. New Zealand Grid coordinates are shown on contour map (www.topomap.con.nz). models  were  used  to  impartially  examine  size  distributions  of femur length, femur width, and tibia length variation to find the optimal number of groups (using R package MCLUST). MCLUST is  a  model-based  clustering  tool  that  groups  data  with  similar properties  and  automatically  determines  optimal  cluster  num- bers  in  the  analyzed  data  without  having  a  priori  labels  (Fraley and Raftery 2002). Bayesian information criteria (BIC) was used to determine the optimal number of clusters. Scales R package was used to normalize the data because the data contained variation in specimen abundance, and this was to ensure that each measure- ment  contributed  equally  to  the  clustering  process.  Cluster  data were  generated  in  R  and  summarized  with  stacked  bars  plots  to illustrate the numbers of individuals in each cluster of each size caught per month using Microsoft Excel®. Fig. 2. Preserved ground wētā specimens from malaise traps deployed in St Arnaud Forest, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E) were identified using morphological traits: A. Hemiandrus electra and H. ‘disparalis’ have fine hairs on segments of maxillary palp 5 (mp5) and part of (mp4). B. Pilosity on maxillary palps extends to mp3 in H. nox. C. H. electra has few or no prolateral apical spines on the hind femur. D. H. ‘disparalis’ has a stout spine apical spine on the hind femur. E. Male H. electra have a short, stout subgenital plate with shallow posterior dip and widely spaced short styli. F. Male H. ‘disparalis’ have a long, forked subgenital plate with long styli. G. Male H. nox have a relatively long, narrow, blunt subgenital plate with short styli. H–I. The sex of all instars can be determined by the subgenital plate, with two styli in males (H) and four incipient ovipositor valves in females (I). Fig. 3. Hemiandrus specimens collected from native forest at St Arnaud, New Zealand were used for size dimension analysis. A. Hind leg measurements used for size analysis are femur length, femur width, and tibia length. B. This is an example of the size range identified within a single species of H. electra males. This research aimed to understand the ecology of three Hemian- drus species that co-occur in the same forest. The study focused on understanding the dietary compositions, relative abundances, and sex ratios of the three sympatric Hemiandrus species, as well as the size distribution of the most common species (H. electra). Diet  of  three  sympatric  wētā  species.—All  66  specimens  examined (male  and  female)  contained  food  fragments  identified  as  being of plant and invertebrate origin, although this differed in propor- tion among the species. Overall, crop content analysis showed that H. nox had fed significantly more on invertebrates than the other two species (Fig. 4). Approximately 80% of crop contents from H. nox were fragments from the remains of prey animals, whereas H. electra and H. ‘disparalis’ each had less than 20% of crop fragments identified  as  invertebrate.  There  was  no  significant  difference  be- tween the diets of males and females in any of the three species (p = 0.646). Visual identification of the species of invertebrates and plants  each  fragment  represented  was  not  possible;  however,  the physical form was diverse. The invertebrate remains included an- tennae, exoskeletons, spider legs, cuticle of a caterpillar, and man- dibles  (Fig.  5).  The  plant  fragments  showed  that  these  sympatric wētā species were polyphagous, as structures representing various plant types, including dicots and monocots, were observed (Fig. 6). Relative  abundance  and  sex  ratio  of  the  three  sympatric  Hemiandrus species.—A total of 966 wētā specimens were sorted from the ma- laise traps. Of these, 701 specimens were identified as H. electra, and 157 and 108 were identified as H. ‘disparalis’ and H. nox, respec- tively (Table 1). More individuals were trapped in January, February, and March (216, 268, and 170, respectively) than in November (56) and December (28). A higher abundance of males than females was observed  during  the  study  period  (females  =  419,  males  =  547). Hemiandrus  electra  had  an  almost  equal  sex  ratio  (355  males  and 346 females), but males were more than twice as common in the traps as females for H. ‘disparalis’ (118 males and 39 females) and H. nox (74 males and 34 females). Ratios in March had the highest deviation from a 1:1 sex ratio, when 109 males were caught in the malaise traps but only 61 females (Table 1). Size distribution of H. electra females.—The optimal number of clus- ters identified by Gaussian mixture models allowed each specimen to be classified into one of five groups, with 1 being the smallest and 5 being the largest individuals. These clusters may represent the different developmental growth stages (instars). Cluster 3 had the most abundant specimens, while cluster 1 had the fewest speci- mens (Table 2). Cluster classifications based on the three variables measured  (tibia  length,  tibia  width,  and  femur  length)  showed that the insects measured followed a linear growth pattern (Fig. 7). The first cluster consisted of the smallest instars (nymphs), while the largest specimens (cluster 5) were identified as adults. Individ- uals of H. electra for each of the five size clusters (putative instars) were caught in traps in each month, with the exception of cluster 1 (nymphs), which were absent in November (spring), December, and April (autumn; Fig. 8). Cluster 3 individuals were most abun- Fig. 4. Proportion (%) of food fragments in the crop of adult fe- male (n = 11 for each species) and male (n = 11 for each species) wētā  that  derived  from  invertebrates.  All  other  food  particles  in their diet were identified as of plant origin. Hemiandrus ‘dispara- lis’ (n = 22), H. electra (n = 22), and H. nox (n = 22) collected in malaise  traps  at  the  same  time  of  the  year  in  a  native  forest  in St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E). Data were  analyzed  for  significant  differences  using  a  Tukey’s  (HSD) test at the 5% level. Error bars indicate the standard errors from a linear model. Fig. 5. Examples of food particles identified as invertebrate fragments, retrieved from the crop contents of three sympatric ground wētā spe- cies (Hemiandrus) caught in malaise traps from St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E), native forest. Scale bar: 200 µm. Fig. 6. Examples of food particles identified as plant fragments retrieved from the crop contents of three sympatric ground wētā species caught in malaise traps from St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E), native forest. Scale bar: 200 µm. Table 1. Abundance of three Hemiandrus wētā species caught in ma- laise traps in native forest in St Arnaud, New Zealand, and the num- ber of each species and each sex in respective months of sampling. Data are combined for the 2004/2005 and 2005/2006 seasons. dant in January and February (summer). Although adult H. electra (cluster 5) were uncommon in November, some were present in each month sampled (Fig. 8). Table 2. The numbers of insect specimens in each size cluster iden- tified  using  Gaussian  mixture  models  with  hind  leg  dimensions for  Hemiandrus  electra  females  caught  in  malaise  traps  in  native forest in St Arnaud, New Zealand. Cluster 1 contains the smallest individuals, and cluster 5 contains adults. New Zealand has a high diversity of nocturnal Orthoptera in the  family  Anostostomatidae.  These  insects  are  likely  to  be  eco- logically  important  in  natural  habitats  (Griffin  et  al.  2011)  and, in  some  modified  areas,  are  recognized  as  horticultural  pests (Nboyine et al. 2016, Trewick et al. 2021). However, there is still much to be learnt about their basic biology. This study obtained baseline  ecological  knowledge  of  three  sympatric  wētā  species, H.  electra,  H.  ‘disparalis’,  and  H.  nox,  about  their  diet,  relative abundance, and life cycle patterns. Diet of three sympatric Hemiandrus species.—Insects are categorized based on their dietary specializations, ranging from monophagous to polyphagous (Agrawal and Klein 2000). This study showed that Hemiandrus species feed on diverse plants (e.g., evidence of different plant epidermal cells, stoma, Fig. 6) and arthropod families (Fig. 5). Our observations are similar to those of other authors (Butts 1983, Van Wyngaarden 1995, Wahid 1979), confirming that ground wētā are omnivores. Diet proportions varied among the three sympatric Hemiandrus species studied. Hemiandrus electra and H. ‘disparalis’ fed more on plants than on invertebrates in contrast to H. nox. Vari- ous explanations have been offered for why omnivores select food species and quantities. Trade-offs probably exist between nutrient content, plant secondary metabolites, species abundance, physical traits, and opportunities. However, even at the coarse level of rela- tive dietary components, we found that H. nox fed more on inverte- brates, which accounted for up to approximately 80% of their diet. The diet of the closely related forest species H. maculifrons is almost entirely invertebrate (Cary 1983), similar to that of H. nox. A small Fig. 7. Gaussian mixture models produced 5 cluster classifications using size of Hemiandrus electra female specimens collected over seven months (November–May) from malaise traps in native forest in St Arnaud, New Zealand. Models are based on tibia length, femur length, and femur width. (Purple = cluster 1, orange = cluster 2, blue = cluster 3, red = cluster 4 and green = cluster 5 (adults). H. pallitarsis (Walker 1869) prefers to climb beech trees rather than other adjacent tree species (Moeed and Meads 1983). Very probably, behavior,  size,  reproductive  strategy,  diet,  and  other  biological  at- tributes can all be linked to the abundance variation of these three species,  which  may  be  phylogenetically  constrained.  However,  the current study cannot determine the drivers of these differences. Some previous studies of wētā in the family Anostostomatidae have  found  population  samples  to  be  either  male-  or  female-bi- ased; presumably, this is the result of using different survey meth- ods. For example, stone wētā Hemideina maori (Joyce et al. 2004) and the tusk wētā Motuweta riparia (Gibbs 2002, McCartney et al. 2006)  have  been  recorded  as  female-biased  populations,  while some  studies  of  the  ground  wētā  Hemiandrus  found  the  sampled populations  to  be  male-biased  (Chappell  et  al.  2014).  Sex  ratio variation  may  be  subject  to  data  bias.  Thus,  factors  such  as  sam- pling method and season must be considered. For example, during mating periods, ground wētā exit their burrows in search of mates, making 50:50 sex representations in traps likely during this period. After mating, females of some species with short ovipositors pro- vide maternal care (H. electra, H. bilobatus) in their burrows. After mating, males exit their burrows in search of food and mates, while females are brooding. Thus, sampling during this period may show male-biased activity because females may rarely exit their burrows while  caring  for  eggs  and  nymphs  (Nboyine  et  al.  2016,  Browne and Gwynne 2023). The sex ratio of the Hemiandrus species studied here and caught in the same malaise traps was biased in favor of males for H. ‘disparalis’ and H. nox, with male numbers double that of females (118:39 and 74:34, respectively). Surprisingly, the spe- cies with maternal care, H. electra, had equal numbers of males and females caught in traps in all seven months sampled (355:346). Size distribution of H. electra females.—Several studies of wētā size distribution have suggested that the number of instars may range from  5  to  11,  for  example,  8  instars  in  Hemiandrus  celeano  (Wa- hid, 1979) and 10 or 11 in Deinacrida fallai Salmon, 1950 and D. heteracantha White 1842 (Richards 1973). Our Gaussian mixture model cluster classification of size measurements of H. electra fe- males produced five size clusters of individuals. These five clusters might represent five instars. The adult specimens were all assigned to cluster 5, but the smallest specimens (cluster 1) might not rep- resent  first  instar  nymphs.  Newly  hatched  (first  instar)  ground wētā might be too small to be trapped or to feed from the ground. Our  study  found  no  evidence  of  seasonality  in  the  growth and  development  of  H.  electra  based  on  the  population  sample intercepted in malaise traps, as almost every size class was found in each month, with the absence of the most undersized individu- als in November, December, and April. Similar to Leisnham et al.’s (2003) study of H. maori, we found that the smallest instars were most  common  from  January  to  March.  During  this  time,  Leisn- ham et al. (2003) also observed gravid females in H. maori; this is presumable when wētā oviposit. This  study  showed  that  ground  wētā  are  omnivorous  insects that feed on both plants and invertebrates. This knowledge is vital for understanding the ecology of wētā. Some wētā species have be- come pests of economic importance in crops such as grapevines. Thus, understanding the diet and plant species that wētā feed on in their natural habitats can help develop integrated pest manage- ment options with plant species mostly favored in natural habi- tats. We found that the three sympatric species of Hemiandrus vary Fig.  8.  Variation  in  size  class  abundance  of  female  Hemiandrus electra collected over seven months (November–April) in malaise traps in native forest in St Arnaud, New Zealand (-41°53'59.99\"S, 172°51'59.99\"E).  Size  cluster  classification  using  the  Gaussian mixture model (n = 346). proportion  of  the  diet  of  H.  nox  was  plant  fragments  (10–20%), which  might  be  the  result  of  preying  on  invertebrates  with  plant fragments  in  their  guts  (Cary  1983).  During  opportunistic  night observations, many species of Hemiandrus have been seen scaveng- ing (Cary 1983), but observing the hunting and capture of live prey would be much more challenging. The size of insect fragments in the crop could suggest that H. nox are scavengers, although H. mac- ulifrons is considered an active predator (Cary 1983). Unlike other studies of ground wētā that found differences in the diets of males and females (Wahid 1978), our study showed no  diet  differences  between  sexes  at  this  coarse  level,  and  these results are similar to observations of other species (Ramsay 1955, Richards 1953, 1962, 1973). This is unexpected, as males and fe- males are often thought to have different nutrient requirements. For example, females are larger than males and require resources for egg production. However, males may also require more nutri- ents to present as nuptial gifts for females during mating, which may justify the similarities in the diets of these males and females (Gwynne 2004, Browne and Gwynne 2022). The current study in- vestigated the dietary differences of adults and did not attempt to investigate the diet changes between successive instars. Most hem- imetabolous  insects  do  not  show  changes  in  diet  between  con- secutive  stages  (Cary  1983).  However,  there  is  a  possibility  that adult  Hemiandrus  spp.  feed  on  larger  prey  that  they  can  subdue, while small instars may feed on smaller insects from Diptera and Diapriidae (Butts 1983, Cary 1983). Thus, further research on dif- ferent life stages could reveal interesting dietary differences. Relative abundance and sex ratio.—Three species of Hemiandrus were caught in the same malaise traps in a forest. We expected carnivo- rous species to be relatively less common than herbivorous species because,  in  general,  biomass  decreases  for  higher  trophic  levels  in food webs. Although all three species had mixed diets (omnivores), the species with the highest proportion of invertebrates in its diet (H. nox) was the least common in the traps. However, as we intercepted only insects that climbed the malaise traps, it is possible the variation in  abundance  was  the  result  of  behavioral  differences  rather  than relative population sizes in this forest habitat. Few data exist about the activity of Hemiandrus species in forests. However, we know that most species can be observed at night off the ground on foliage, and in  abundance,  with  H.  electra  having  the  highest  relative  abun- dance when intercepted in malaise traps. Additionally, we found that females of H. ‘disparalis’ and H. nox were not caught as often as males, but H. electra had an even sex ratio of trapped specimens. This was somewhat surprising because H. electra is the only one of the three Hemiandrus species studied here with maternal care be- havior. Thus, adult males were expected to be more common than adult  females.  Distinct  sex  ratios,  diets,  and  abundance  suggest that these three species are ecologically distinct. Given the ecologi- cal diversity we detected in sympatry, to understand the ecology of related Hemiandrus species, it is necessary to study populations in their natural habitats and not just extrapolate from related taxa. Special  thanks  to  the  Bragato  Research  Institute  (BRI),  Con- stellation  Brands,  Indevin,  Pernod-Ricard,  Yealands,  and  Hortus for funding the studentship that produced this publication. Our gratitude  goes  to  Melisa  Griffin,  who  provided  access  to  the  in- sect  samples  and  information  on  the  locations  of  malaise  traps. We would like to thank Plant and Food internal reviewers Abby Albright,  Mette  Nielsen,  Lisa  Watkins,  and  Dave  Bellamy.  Many thanks to Sigfrid Ingrisch for reviewing this paper. Our gratitude goes to Sinclair Chinyoka, who guided us with data analysis. We are grateful for the support and contributions of the Phoenix Lab members (www.evolves.massey.ac.nz/).",
         "https://jor.pensoft.net/article/123860/download/pdf/",
         "extracted",
         "None",
         "Sexual selection on a female copulatory device in an insect with nuptial gifts;﻿Relationships among body size components of three flightless New Zealand grasshopper species (Orthoptera, Acrididae) and their ecological applications;Paternity sharing in insects with female competition for nuptial gifts;Recommendations for non-lethal monitoring of tree wētā (Hemideina spp.) using artificial galleries;Ecology and systematics of the wine wētā and allied species, with description of four new Hemiandrus species;ggplot2;Agroecological management of a soil‐dwelling orthopteran pest in vineyards;Macroinvertebrate and soil prokaryote communities in the forest–tundra ecotone of the Subarctic Yukon;Insect temperature-body size trends common to laboratory, latitudinal and seasonal gradients are not found across altitudes;Three new ground wētā species and a redescription of Hemiandrus maculifrons;Ground wētā in vines of the Awatere Valley, Marlborough: biology, density and distribution;Notes on sexual size dimorphism, sex ratio and movements of adult ground weta Hemiandrus maculifrons (Walker) (Orthoptera: Anostostomatidae);Shifting ranges of two tree weta species (Hemideina spp.): competitive exclusion and changing climate;New Zealand ground wētā (Anostostomatidae: Hemiandrus): descriptions of two species with notes on their biology;Large-sized insects show stronger seasonality than small-sized ones: a case study of fruit-feeding butterflies;Mutualism or opportunism? Tree fuchsia (Fuchsia excorticata) and tree weta (Hemideina) interactions;Isotopic fractionation in a large herbivorous insect, the Auckland tree weta.;A comparative study of the biology of the Giant wetas Deinacrida heteracantha and D. fallai (Orthoptera : Henicidae) from New Zealand;Diversification of New Zealand weta (Orthoptera: Ensifera: Anostostomatidae) and their relationships in Australasia;Interspecific interactions in phytophagous insects revisited: a quantitative assessment of competition theory.;Comparative food web structure of larval macrolepidoptera and their parasitoids on two riparian tree species;Egg size variation and its relationship with larval performance in the Lepidoptera: the case of the European grapevine moth Lobesia botrana;Increased competition may promote species coexistence;Model-Based Clustering, Discriminant Analysis, and Density Estimation;A new species of tusked weta from the Raukumara Range, North Island, New Zealand (Orthoptera: Anostostomatidae: Motuweta);What omnivores eat: direct effects of induced plant resistance on herbivores and indirect consequences for diet selection by omnivores.;The Gondwanaland Weta: Family Anostostomatidae (formerly in Stenopelmatidae, Henicidae or Mimnermidae): Nomenclatural Problems, World Checklist, New Genera and Species;Diet of the ground weta Zealandosandrus gracilis (Orthoptera: Stenopelmatidae);LXIV.—Notes on a collection of Gryllidæ, Stenopelmatidæ, Gryllacridæ, and Hetrodidæ formed by Mr. W. L. Distant in the Transvaal and other South- and East-African localities;Sex- and season-dependent behaviour in a flightless insect, the Auckland tree weta (Hemideina thoracica);Mark-recapture.;Life cycle , survival rates and longevity of an alpine weta Hemideina maori ( Orthoptera : Anostostomatidae ) determined using mark-recapture analysis;Distribution and conservation status of ground weta, Hemiandrus species (Orthoptera: Anostostomatidae);Invertebrate fauna of four tree species in Orongorongo valley, New Zealand, as revealed by trunk traps;Feeding behaviour and enemies of Rhaphidophoridae (Orthoptera) from Waitomo Caves, New Zealand.;Notes on the genus Deinacrida in New Zealand.;Fauna Chilena. Insectos. Orden IV. Ortoperos.;Insects of New Zealand.",
         "Comparison of growth, relative abundance, and diet of three sympatric Hemiandrus ground wētā (Orthoptera, Anostostomatidae) in a New Zealand Forest"
        ],
        [
         "38",
         "01ae6d81c72cb5b14ae95519f29011609a777351",
         "Vegetation and its modification by humans can shape wildlife habitat selection and movement. A better understanding of how wolves select and move through natural and human modified vegetative cover can be used to implement forest management that considers impacts on wolves and their prey. We analyzed fine-scale wolf habitat selection and movement in a coastal temperate rainforest (Prince of Wales Island, Alaska, USA) in relation to: (1) young (≤ 30 years) and old (> 30 years) logged areas, (2) continuous measures of vegetative cover (as estimated via LiDAR), and (3) distance to roads, using integrated step-selection analysis (iSSA). Wolves selected areas with less forest canopy and understory cover at the population level, although they switched to selecting understory when within logged forest stands. The continuous canopy and understory measures vary at a fine spatial scale and thus appear to better explain fine-scale wolf selection and movement than categorical landcover classes representing the age of logged stands. Wolf selection of young (≤ 30 years) and old (> 30 years) successional logged areas, and areas near roads, was mixed across individuals. All individual wolves avoided canopy cover, but varied in their selection of logged stands, understory, and roads. Similarly, there was variability in movement rate response across individual wolves, although at the population level wolves moved faster through old (> 30 years) logged areas and through areas with less understory vegetation. Open vegetation including that present recently after logging is selected by wolves, and facilitates wolf movement, but this effect may be ephemeral as vegetation undergoes succession. Supplementary Information The online version contains supplementary material available at 10.1007/s00442-025-05677-5.",
         "David P Gregovich,Gretchen H. Roffler,Christina M. Prokopenko",
         "\n**BLOCK**fs== 9.5**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.7**\nORIGINAL RESEARCH\n**BLOCK**fs== 16.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.2**\nVegetation influences wolf fine‑scale habitat selection and movement\nrate in a logged coastal rainforest\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nDavid P. Gregovich1\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.2**r== 0.4**\n· Gretchen H. Roffler1 · Christina M. Prokopenko2\n**BLOCK**fs== 8.5**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.4**\nReceived: 17 June 2024 / Accepted: 6 February 2025 / Published online: 27 February 2025\n© The Author(s) 2025\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.3**l== 0.1**r== 0.1**\nAbstract\nVegetation and its modification by humans can shape wildlife habitat selection and movement. A better understanding of how\nwolves select and move through natural and human modified vegetative cover can be used to implement forest management\nthat considers impacts on wolves and their prey. We analyzed fine-scale wolf habitat selection and movement in a coastal\ntemperate rainforest (Prince of Wales Island, Alaska, USA) in relation to: (1) young (≤ 30 years) and old (> 30 years) logged\nareas, (2) continuous measures of vegetative cover (as estimated via LiDAR), and (3) distance to roads, using integrated\nstep-selection analysis (iSSA). Wolves selected areas with less forest canopy and understory cover at the population level,\nalthough they switched to selecting understory when within logged forest stands. The continuous canopy and understory\nmeasures vary at a fine spatial scale and thus appear to better explain fine-scale wolf selection and movement than categorical\nlandcover classes representing the age of logged stands. Wolf selection of young (≤ 30 years) and old (> 30 years) succes-\nsional logged areas, and areas near roads, was mixed across individuals. All individual wolves avoided canopy cover, but\nvaried in their selection of logged stands, understory, and roads. Similarly, there was variability in movement rate response\nacross individual wolves, although at the population level wolves moved faster through old (> 30 years) logged areas and\nthrough areas with less understory vegetation. Open vegetation including that present recently after logging is selected by\nwolves, and facilitates wolf movement, but this effect may be ephemeral as vegetation undergoes succession.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nKeywords  Canis lupus · Roads · Habitat selection · iSSA · Rainforest\n**BLOCK**fs== 12.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nIntroduction\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nWhere animals live and how they move across the landscape\nare shaped by biotic and abiotic factors that vary spatially\n(Guisan and Zimmerman 2000; Kearney and Porter 2009).\nVegetation is salient among these factors, because it governs\navailable food in the form of forage or, in the case of sec-\nondary consumers, herbivorous prey (Smith et al. 2019), as\nwell as cover from predators, including humans (Suraci et al.\n2020). Nutritional intake, efficient movement, and predator\navoidance are animal fitness requirements that affect survival\n**BLOCK**fs== 8.5**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nCommunicated by John Loehr.\n**BLOCK**fs== 8.5**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.7**\ndave.gregovich@alaska.gov\n**BLOCK**fs== 8.5**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n1  Alaska Department of Fish and Game, Division of Wildlife\nConservation, 802 3rdStreet, Douglas, AK 99824, USA\n2  Natural Resources Institute, University of Manitoba, 119\nSt. Paul’s College 70, Winnipeg, MB R3T 2M6, Canada\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\nrate, and hence population dynamics (Plard et al. 2019), and\nare influenced by landscape vegetation patterns (Losier et al.\n2015; Kane et al. 2017). Humans modify natural vegetation\npatterns (e.g., via infrastructure development, agriculture,\nand timber harvest), and this modification in turn affects eco-\nsystems and the species within them, including by shaping\nanimal habitat selection (Suraci et al. 2020; Northrup et al.\n2021) and movement patterns (Plante et al. 2018; Quiles\nQuiles and Barrientos 2024). Here, we model the response\nof an apex predator, Canis lupus, to modification of natural\nvegetation by timber harvest and associated roads.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nHuman alteration of vegetation includes extensive tim-\nber harvest in temperate forests (Kennedy and Spies 2004;\nKnorn et al. 2013) which affects wildlife space use (Lesmer-\nises et al. 2012; Pinard et al. 2012) and movement (Boucher\net al. 2022; Gagnon et al. 2024). Logged stands in temper-\nate, coniferous rainforests undergo succession from initially\nopen vegetation, through a stage of productive understory, to\na long-lasting (from 30 to 200 years post-logging) densely\ncanopied forest with little understory production (Alaback\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\n1984). The impact of the post-logging successional trajec-\ntory on wildlife varies depending on individual species’\nenvironmental niche and life history (Jones et al. 2024).\nSpecies favored initially post-logging may be disadvantaged\nlater in the second-growth successional trajectory (Schloss-\nberg & King 2009; Le Borgne et al. 2018).\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.2**l== 0.1**r== 0.5**\nThe ability of wolves (Canis lupus) to hunt effectively\nis influenced by spatial patterns of vegetation (Dickie et al.\n2017).  Areas  devoid  of  thick  vegetation  are  associated\nwith longer sight distance and increased movement rates\nand hence increased prey encounter rates (McPhee et al.\n2012; Toretta et al. 2018). Wolf prey encounter rates may\nbe greater in areas with greater ungulate prey density (Kittle\net al. 2017; but see Zabihi-Seissan et al. 2022), which is pro-\nmoted by abundant ungulate plant forage (Potvin et al. 2005;\nGagnon et al. 2024), which is often present in early suc-\ncessional forests (Fisher and Wilkinson 2005; Hayes et al.\n2022) but may diminish through time. Hence, timber harvest\ncould initially benefit wolves by resulting in increased forage\nattractive to ungulate prey species (Farmer et al. 2006; Kittle\net al. 2017). Similarly, logging roads are initially devoid of\nvegetation and may facilitate wolf hunting but often become\nrevegetated over time (Waga et al. 2020). These initially\nunvegetated roads promote wolf prey detection and ease\nof travel but expose wolves to risk in the form of human\nhunters and trappers (Zimmerman et al. 2014) and vehicles\n(Dennehy et al. 2021). Logging roads may alternatively be\nmaintained for continued use for logging or for other pur-\nposes, including as recreational trails or eventual upgrade for\npassenger vehicle use, thereby constituting risk avoided by\nwolves (Gurarie et al. 2011; Dennehy et al. 2021). Hence,\nthere are conflicting forces that may result in wolf selection\n(Houle et al. 2010; Dickie et al. 2020) or avoidance (Whit-\ntington et al. 2005; Lesmerises et al. 2013) of roads, depend-\ning on revegetation and other road characteristics.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nCoastal temperate rainforests, including those of South-\neast Alaska, have been the target of industrial timber harvest\nthat occurs to the present and has drastically reduced the\ncoverage of old-growth forests (Albert and Schoen 2013).\nPrince of Wales Island (POW) in Southeast Alaska has been\nparticularly targeted by the timber industry due to a high\ndensity of large trees, and now holds < 6% of the contiguous\nhigh-volume forest that existed before large-scale logging\nbegan in the 1950s (Albert and Schoen 2013). Wolves are of\nconservation concern in the region and have been petitioned\nfor listing under the U.S. Endangered Species Act (ESA)\nthree times in the past 30 years. The impacts of logging\non these wolves and their Sitka black-tailed deer (Odocoi-\nleus hemionus sitkensis) prey are a focus of conservation\nand management policy. Recently, the U.S. Forest Service\n(USFS) stated they will transition away from old-growth\ntimber harvest to rotational harvest of second-growth for-\nest (USFS 2016). The 2020 repeal of the Tongass National\n**BLOCK**fs== 10.0**p== 1.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nForest (TNF) exemption of the Roadless Area Conservation\nRule (Executive Office of the President, Roadless Rule Revi-\nsion 2021) further increases the focus of future logging in\nareas that have experienced previous harvest. The effect of\nhistoric timber harvest patterns and future harvest strategies\non wolves and their ecosystem remains unclear.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\nBuilding on previous work studying the effects of log-\nging on wildlife on POW (Farmer et al. 2006; Person and\nRussell 2008; Pyare et al. 2010; Porter et al. 2021; Roffler\net al. 2023), we modeled fine-scale selection and movement\nof wolves in relation to spatial patterns of vegetation, log-\nging, and roads. Based on our knowledge of wolf biology\nand with support from previous literature (including that\npresented above) we formulated hypotheses regarding wolf\nhabitat selection and movement rate in relation to environ-\nmental covariates representing logging, vegetation, and road\nproximity (Table 1) to be tested via integrated step selection\nanalysis (iSSA) model coefficients.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\nMethods\n**BLOCK**fs== 11.0**p== 1.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nStudy area\n**BLOCK**fs== 10.0**p== 1.0**b== 0.2**t== 0.5**l== 0.5**r== 0.1**\nWe  studied  wolves  on  POW  in  the  coastal  rainforest  of\nSoutheast  Alaska  (Fig.  1).  POW  is  the  largest  island  in\nan extensive archipelago and has a maritime climate with\nhigh precipitation (> 200 cm/year) and moderate tempera-\ntures—daily mean ranging from 1.3 °C (January) to 57.4 °C\n(August)—though cooler at elevation. The forest is domi-\nnated by Sitka spruce (Picea sitchensis) and western hem-\nlock (Tsuga heterophylla), with Alaska yellow cedar (Cal-\nlitropsis nootkatensis) and western redcedar (Thuja plicata)\nalso  common.  Some  common  understory  woody  plants\ninclude  devil’s  club  (Oplopanax  horridus),  blueberries\n(Vaccinium spp.), and salal (Gaultheria shallon), and ground\ncover species include bunchberry (Cornus unalaschkensis),\nfoamflower (Tiarella trifoliata) and twisted stalk (Streptopus\nspp.). Wolves on POW co-occur with American black bear\n(Ursus americanus) and Sitka black-tailed deer. Seasonal\nanadromous runs of Pacific salmon (Onchorynchus spp.)\nprovide large subsidies of marine-derived nutrients to the\nterrestrial ecosystem.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nLogging on POW started in the early 1900s but became\nmuch larger in scale in the 1950s and continued through\nthe time of the study. Logging has focused on high-volume\nconiferous forests (Albert & Schoen 2013), resulting in a\nmosaic of old- and second-growth forests interspersed with\nless productive forests and unforested lands. Logged areas\nvary in age and condition from initially open vegetation,\ntransitioning to a mix of dense understory and young coni-\nfers, and followed (~ 30 year post-logging) by a longer last-\ning, ‘stem-exclusion’ phase of dense conifer canopy and\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\nd\ne\nt\na\ni\nc\no\ns\ns\na\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.4**\ns\ne\nd\ni\nv\no\nr\np\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\ng\nn\ni\nt\ns\ne\nr\n**BLOCK**fs== 2.4**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nf\nl\no\nw\nh\nt\ni\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\ny\nt\ni\ns\nn\ne\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.5**r== 0.5**\ny\ne\nr\np\nw\no\nl\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\n)\nd\no\no\nw\nn\nw\no\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.5**r== 0.5**\nt\nn\ne\nm\ne\nv\no\nm\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\nf\nl\no\nw\ne\nt\no\nm\no\nr\np\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\ng\nn\ni\nd\ne\np\nm\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.4**r== 0.6**\ns\ni\nr\nb\ne\nd\ng\nn\ni\ng\ng\no\nl\nd\nn\na\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\ns\nb\nu\nr\nh\ns\n**BLOCK**fs== 2.4**p== 2.0**b== 0.3**t== 0.6**l== 0.4**r== 0.6**\nt\nc\na\nr\nt\nt\na\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.4**r== 0.6**\ns\nr\ne\nt\nn\nu\no\nc\nn\ne\n**BLOCK**fs== 3.8**p== 2.0**b== 0.2**t== 0.7**l== 0.4**r== 0.6**\nd\ne\ns\na\ne\nr\nc\nn\ni\n**BLOCK**fs== 3.8**p== 2.0**b== 0.8**t== 0.1**l== 0.4**r== 0.6**\ne\ni\nr\na\nr\nu\nG\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.2**l== 0.4**r== 0.6**\nl\nl\ne\ns\ns\nu\nR\nd\nn\na\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\nn\no\ns\nr\ne\nP\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\nn\ni\na\nt\nn\no\nc\n**BLOCK**fs== 3.3**p== 2.0**b== 0.6**t== 0.3**l== 0.4**r== 0.6**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\n:\nr\ne\nw\no\nl\nS\n**BLOCK**fs== 3.8**p== 2.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\na\nk\ns\nr\na\nj\no\nP\n**BLOCK**fs== 2.8**p== 2.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\nr\ne\nm\nr\na\nF\n**BLOCK**fs== 2.4**p== 2.0**b== 0.3**t== 0.6**l== 0.4**r== 0.6**\nt\na\nt\ni\nb\na\nh\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.4**r== 0.6**\nr\ne\nh\ng\ni\nh\n**BLOCK**fs== 3.8**p== 2.0**b== 0.2**t== 0.7**l== 0.4**r== 0.6**\n:\nt\nc\ne\nl\ne\nS\n**BLOCK**fs== 3.3**p== 2.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 2.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\nt\nn\ne\nm\ne\nv\no\nm\n**BLOCK**fs== 4.2**p== 2.0**b== 0.2**t== 0.7**l== 0.4**r== 0.6**\ns\ne\nv\nl\no\nw\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.4**r== 0.5**\nd\nn\na\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n(\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\ne\nr\nu\nt\nc\nu\nr\nt\ns\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\ne\nv\ni\nt\na\nt\ne\ng\ne\nv\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.4**r== 0.5**\ns\nr\ne\nt\nn\nu\no\nc\nn\ne\n**BLOCK**fs== 3.8**p== 2.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\nd\ne\ns\na\ne\nr\nc\ne\nd\n**BLOCK**fs== 3.8**p== 2.0**b== 0.8**t== 0.2**l== 0.4**r== 0.6**\na\nk\ns\nr\na\nj\no\nP\n**BLOCK**fs== 2.8**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\nr\ne\nm\nr\na\nF\n**BLOCK**fs== 2.4**p== 2.0**b== 0.7**t== 0.3**l== 0.4**r== 0.6**\ne\nl\nt\nt\ni\nl\n**BLOCK**fs== 3.3**p== 2.0**b== 0.6**t== 0.3**l== 0.4**r== 0.6**\nw\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 2.4**p== 2.0**b== 0.6**t== 0.4**l== 0.4**r== 0.6**\n:\nr\ne\nt\ns\na\nF\n**BLOCK**fs== 4.2**p== 2.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\nh\nc\ni\nv\no\ng\ne\nr\nG\n**BLOCK**fs== 2.8**p== 2.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\nr\ne\nffl\no\nR\n**BLOCK**fs== 3.3**p== 2.0**b== 0.2**t== 0.8**l== 0.4**r== 0.6**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.8**l== 0.4**r== 0.6**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 4.2**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nt\nr\no\np\np\nu\ns\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.2**l== 0.3**r== 0.6**\ne\nr\nu\nt\na\nr\ne\nt\ni\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.3**r== 0.6**\ns\ni\ns\ne\nh\nt\no\np\ny\nh\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\nr\no\ni\nv\na\nh\ne\nb\n**BLOCK**fs== 4.2**p== 2.0**b== 0.4**t== 0.5**l== 0.3**r== 0.6**\nt\nr\no\np\np\nu\ns\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\ne\nr\nu\nt\na\nr\ne\nt\ni\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\ns\ni\ns\ne\nh\nt\no\np\ny\nh\nr\no\ni\nv\na\nh\ne\nb\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.3**l== 0.3**r== 0.7**\n,\na\nk\ns\na\nl\nA\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nd\nn\na\nl\ns\nI\n**BLOCK**fs== 3.8**p== 2.0**b== 0.5**t== 0.4**l== 0.3**r== 0.7**\ne\nc\nn\ni\nr\nP\n**BLOCK**fs== 3.8**p== 2.0**b== 0.5**t== 0.5**l== 0.3**r== 0.7**\n,\ns\ne\nt\na\ni\nr\na\nv\no\nc\n**BLOCK**fs== 4.2**p== 2.0**b== 0.4**t== 0.5**l== 0.3**r== 0.7**\nl\na\nt\nn\ne\nm\nn\no\nr\ni\nv\nn\ne\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.7**\ne\nv\ni\nt\na\nl\ne\nr\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.3**r== 0.7**\nt\nn\ne\nm\ne\nv\no\nm\nd\nn\na\n**BLOCK**fs== 2.4**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nn\no\ni\nt\nc\ne\nl\ne\ns\n**BLOCK**fs== 2.4**p== 2.0**b== 0.2**t== 0.7**l== 0.3**r== 0.7**\nt\na\nt\ni\nb\na\nh\n**BLOCK**fs== 2.4**p== 2.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\nf\nl\no\nw\no\nt\n**BLOCK**fs== 3.8**p== 2.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\nd\ne\nt\na\nl\ne\nr\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\ns\ne\ns\ne\nh\nt\no\np\ny\nH\n**BLOCK**fs== 2.8**p== 2.0**b== 0.7**t== 0.3**l== 0.3**r== 0.7**\n)\nr\ne\nw\no\nl\ns\n**BLOCK**fs== 2.8**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nr\ne\nt\ns\na\nf\n(\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\nt\nn\ne\nm\ne\nv\no\nM\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.3**r== 0.7**\n)\ne\nc\nn\na\nd\ni\no\nv\na\n**BLOCK**fs== 2.4**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nn\no\ni\nt\nc\ne\nl\ne\ns\n(\n**BLOCK**fs== 2.4**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nn\no\ni\nt\nc\ne\nl\ne\ns\n**BLOCK**fs== 2.4**p== 2.0**b== 0.2**t== 0.7**l== 0.3**r== 0.7**\nt\na\nt\ni\nb\na\nH\n**BLOCK**fs== 3.8**p== 2.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\ne\nt\na\ni\nr\na\nv\no\nc\n**BLOCK**fs== 2.4**p== 2.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nt\na\nt\ni\nb\na\nH\n**BLOCK**fs== 2.8**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\n-\nl\ne\nv\na\nr\nt\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.3**l== 0.5**r== 0.5**\ne\nl\ni\nh\nw\nd\ne\ne\np\ns\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\nf\nl\no\nw\nn\no\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\nt\nc\ne\nff\ne\n**BLOCK**fs== 4.2**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\nh\nc\ni\nv\no\ng\ne\nr\nG\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.5**r== 0.5**\ns\nr\ne\nt\nn\nu\no\nc\nn\ne\n**BLOCK**fs== 3.8**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.5**\nd\ne\ns\na\ne\nr\nc\ne\nd\n**BLOCK**fs== 3.8**p== 2.0**b== 0.8**t== 0.2**l== 0.5**r== 0.5**\na\nz\ne\nn\na\nl\nL\n**BLOCK**fs== 2.4**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\ni\nn\na\nt\ni\np\na\nC\n**BLOCK**fs== 2.4**p== 2.0**b== 0.7**t== 0.3**l== 0.5**r== 0.5**\nt\nc\ne\nr\ni\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\ny\np\no\nn\na\nc\n**BLOCK**fs== 2.4**p== 2.0**b== 0.6**t== 0.4**l== 0.5**r== 0.5**\n:\nr\ne\nw\no\nl\nS\n**BLOCK**fs== 3.3**p== 2.0**b== 0.5**t== 0.5**l== 0.5**r== 0.5**\ns\ne\ns\ni\nr\ne\nm\ns\ne\nL\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.5**r== 0.5**\ne\ne\nh\nP\nc\nM\n**BLOCK**fs== 2.8**p== 2.0**b== 0.1**t== 0.8**l== 0.5**r== 0.5**\n)\nd\ne\ns\na\nb\n-\nR\nA\nD\nL\n(\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\ny\np\no\nn\na\nc\n**BLOCK**fs== 2.4**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\nt\ns\ne\nr\no\nF\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\nt\nn\ne\nm\ne\nv\no\nm\n**BLOCK**fs== 4.2**p== 2.0**b== 0.7**t== 0.3**l== 0.7**r== 0.3**\ng\nn\ni\ns\na\ne\nr\nc\nn\ni\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\n,\ns\nn\na\nm\nu\nh\nm\no\nr\nf\n**BLOCK**fs== 3.8**p== 2.0**b== 0.8**t== 0.2**l== 0.7**r== 0.3**\ne\ni\nk\nc\ni\nD\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.3**l== 0.7**r== 0.3**\nt\nn\ne\ns\ne\nr\np\ne\nr\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\n,\ne\nc\na\nf\nr\nu\ns\n**BLOCK**fs== 2.8**p== 2.0**b== 0.6**t== 0.4**l== 0.7**r== 0.3**\ne\ne\nr\nf\n-\nr\ne\ni\nr\nr\na\nb\n**BLOCK**fs== 3.8**p== 2.0**b== 0.5**t== 0.5**l== 0.7**r== 0.3**\ne\ni\nk\nc\ni\nD\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.7**r== 0.3**\nn\no\ni\nt\nc\ne\nt\ne\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.2**t== 0.7**l== 0.7**r== 0.3**\nf\nl\no\nw\nd\nn\na\n**BLOCK**fs== 6.6**p== 2.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nn\na\nm\nr\ne\nm\nm\nZ\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.2**l== 0.6**r== 0.3**\ne\ni\nz\nn\ne\nK\nc\nM\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.6**r== 0.3**\ne\nd\ni\nv\no\nr\np\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\ny\nl\nl\na\nr\ne\nn\ne\ng\ns\nd\na\no\nr\n**BLOCK**fs== 3.3**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.3**\n:\nr\ne\nt\ns\na\nF\n**BLOCK**fs== 6.6**p== 2.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\nn\na\nm\nr\ne\nm\nm\nZ\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\ne\ni\nz\nn\ne\nK\nc\nM\n**BLOCK**fs== 3.8**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.3**\ne\ng\na\nr\no\nf\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\ne\nt\na\nl\nu\ng\nn\nu\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\ne\nt\no\nm\no\nr\np\n**BLOCK**fs== 3.8**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.3**\n:\nt\nc\ne\nl\ne\nS\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.8**l== 0.6**r== 0.3**\ng\nn\ni\ng\ng\no\nl\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\nm\ni\nx\no\nr\nP\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.3**l== 0.6**r== 0.4**\n,\ne\ng\na\nr\no\nf\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\ne\nt\na\nl\nu\ng\nn\nu\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nr\ne\nh\ng\ni\nh\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.3**l== 0.6**r== 0.4**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nr\ne\ns\nn\ne\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\n,\ny\nt\ni\ns\nn\ne\nd\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nt\nn\ne\nm\ne\nv\no\nm\ns\ne\nd\ne\np\nm\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.6**r== 0.4**\ng\nn\ni\nt\nn\nu\nh\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.4**\nf\nl\no\nw\nd\nn\na\n**BLOCK**fs== 3.8**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.4**\ne\ng\na\nr\no\nf\n**BLOCK**fs== 4.2**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.4**\ns\ne\ni\nt\ni\nn\nu\nt\nr\no\np\np\no\n**BLOCK**fs== 3.8**p== 2.0**b== 0.7**t== 0.3**l== 0.6**r== 0.4**\ne\ni\nk\nc\ni\nD\n**BLOCK**fs== 3.8**p== 2.0**b== 0.6**t== 0.3**l== 0.6**r== 0.4**\nw\ns\na\ne\nr\na\n**BLOCK**fs== 2.4**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\nt\ne\ng\nr\na\nt\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\ns\ne\nv\nl\no\nw\n**BLOCK**fs== 4.2**p== 2.0**b== 0.6**t== 0.4**l== 0.6**r== 0.4**\n:\nr\ne\nw\no\nl\nS\n**BLOCK**fs== 4.2**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.4**\nn\no\ns\nn\ni\nk\nl\ni\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.6**l== 0.6**r== 0.4**\n-\nu\ng\nn\nu\ns\nt\nn\ne\ns\ne\nr\np\ne\nr\n**BLOCK**fs== 4.2**p== 2.0**b== 0.3**t== 0.7**l== 0.6**r== 0.4**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n**BLOCK**fs== 3.8**p== 2.0**b== 0.2**t== 0.7**l== 0.6**r== 0.4**\n:\nt\nc\ne\nl\ne\nS\n**BLOCK**fs== 2.8**p== 2.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\n)\nd\ne\ns\na\nb\n-\nR\nA\nD\nL\n(\n**BLOCK**fs== 4.2**p== 2.0**b== 0.1**t== 0.8**l== 0.6**r== 0.4**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n**BLOCK**fs== 2.4**p== 2.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\nt\ns\ne\nr\no\nF\n**BLOCK**fs== 8.5**p== 3.0**b== 0.8**t== 0.1**l== 0.1**r== 0.7**\nFig. 1   Study area for fine-scale\nhabitat selection analysis of\nwolves, showing autocorrelated\nkernel density estimate (AKDE)\npack home ranges, Prince of\nWales Island (POW), Alaska,\nUSA, 2012–2017\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nrelatively little understory (Alaback 1984). The focus of the\ntimber industry on larger tree stands has reduced contigu-\nous patches of highly productive old-growth forest present\nbefore 1954 by 94% (Albert & Schoen 2013). Most of the\nexisting roads (> 5000 km in length; USFS 2019a) were\ninitially built to access timber but ranged in current status\nfrom revegetated (undrivable), to accessible only by off-road\nvehicles, to improve for passenger vehicle use. Road densi-\nties ranged from 0 to 0.44 km/km2 (Roffler et al. 2018). The\nresulting landscape is thus fragmented by logged areas and\nroads of various condition, with consequences for wildlife\nspecies (Pyare et al. 2010; Smith and Flaherty 2023).\n**BLOCK**fs== 11.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nWolf captures\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nWe  captured  and  radiocollared  wolves  (n = 13)  from\n2012 to 2017 using modified padded long spring (Easy-\nGrip®  #7,  Livestock  Protection  Company,  Alpine,  TX)\nand unpadded coil spring foothold traps (MB750, Minne-\nsota Brand Inc.) set along logging roads and baited with\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.6**l== 0.5**r== 0.1**\ncommercially-produced lures and canid urine. We checked\nwolf traps daily. We immobilized captured wolves using\neither tiletamine HCl and zolazepam HCl, or a combination\nof ketamine and medetomidine. Capture and handling pro-\ncedures conformed to guidelines established by the ADF&G\nAnimal Care and Use Committee (ACUC #2012–028 and\n#2014–15) and the American Society of  Mammalogists\n(Sikes and Gannon 2011). We fit each captured wolf with\na spread-spectrum, Global Positioning System (GPS) radio\ncollar (Mod 4500, Telonics, Inc.) programmed to obtain a\nlocation every 6 h. We programmed collars to automatically\nrelease after 24 months, and they included a VHF compo-\nnent for radiotelemetry and collar recovery after release.\n**BLOCK**fs== 11.0**p== 3.0**b== 0.2**t== 0.8**l== 0.5**r== 0.2**\nHabitat and disturbance covariates\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nWe  analyzed  the  effects  of  two  main  features  of  timber\nharvest,  logged  forest  stands  and  associated  roads,  on\nwolf habitat selection and movement rate. We calculated\nthe distance to roads in two categories: open and closed\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nto vehicle traffic. We separated logged stands into young\n(≤ 30 years) and old (> 30 years) successional categories. As\na contrast to these logging age categories, we used airborne\nLight detection and ranging (LiDAR)-derived vegetative\ncover  metrics  affected  by  timber  harvest  but  varying\ncontinuously across the landscape (both inside and outside\nof logged areas).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.2**l== 0.1**r== 0.5**\nInitial models using the categorical logged stand covari-\nates failed to converge. This led us to explore the use of\ncontinuous covariates representing the proportion of logged\nstands within buffers of increasing radius (50–1000 m in\nincrements of 50) around each wolf location and available\npoint, and contrasted these with the unbuffered (binary)\nlandcover classes, choosing the optimum representation\n(ultimately, 50-m radius) via model concordance scores\n(Therneau 2024; Online Resource Fig. S1). The model used\nfor this purpose was based on model 1 (Table 2), but with\nlandcover covariate mean values calculated within buffers\nof the varying radii. Often, coefficients derived from binary\nlandcover classes used in habitat selection models refer to a\n‘reference category’ not included in the model against which\ncoefficients are contrasted. In our models, proportions of\nthese binary landcover types within a 50-m radius of wolf\nlocations were calculated, and the concept of a reference\ncategory is not relevant. However, the covariate for the pro-\nportion of noncommercial forest within a 50-m buffer of\nlocations was excluded from models due to a high variance\ninflation factor (VIF; 8.42) when included in models with\nthe other landcover covariates. For consistency, we also cal-\nculated the mean values of LiDAR-derived vegetation cover\nwithin a 50-m radius of used and available points.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nWe obtained landcover classes from USFS databases of\ntimber harvest and associated roads in the study area (Online\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.1**l== 0.5**r== 0.1**\nResource Table S1). We defined young logged stands as\nthose where logging occurred ≤ 30 years prior to 2014, the\nmedian year of wolf data collection, and old logged stands\nthose harvested > 30 years prior. We refer to these classes as\nyoung and old logged stands, respectively, although some of\nthe youngest (i.e., < 10 years) did not always harbor stands of\ntrees. Distance to roads was log-transformed, as we expected\na stronger effect near roads to diminish with distance. All\nother covariates were derived from LiDAR point cloud data\ncollected in 2017 and 2018 under U.S Geological Survey\nQL1 specifications (point density = 8/m2; Heidemann 2014),\nand further processed to calculate vegetation structural met-\nrics at a 30-m pixel resolution via LiDAR FUSION software\n(McGaughey 2008). The suite of LiDAR-derived vegeta-\ntion metrics processed by the FUSION software available\nto us included many strongly correlated, difficult to inter-\npret covariates. We chose two metrics representing canopy\nand understory cover due to their ease of interpretation\nand ecological relevance. Canopy cover was defined as the\nproportion of LiDAR returns > 2 m above ground; above a\nheight which might impede wolf travel but low enough to\naccount for nearly all existing forest canopy. Forest canopy is\nassociated with light penetration, density of trees, and snow\ninterception, measures that plausibly affect wolves and their\nSitka black-tailed deer prey. We defined understory cover\nas the proportion of LiDAR returns in the range 0.5–1.0 m\nabove ground relative to all points below that stratum. This\ncorresponds roughly to the height distribution of Vaccinium\nspp. (‘blueberries’) important as food for wolf deer prey and\nother woody plants—e.g., salal (Gaultheria shallon) and\nfalse azalea (Menziesia ferruginea)—that potentially restrict\nwolf movement (see Dickie et al. 2017). We use the term\nunderstory here realizing that other plants conventionally\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.2**\nTable 2   Models and covariates used for fine-scale wolf habitat selection on Prince of Wales Island (POW), Alaska, USA, 2012–2017\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nModel name\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nCovariate groups included in model (in addition to core covariates)\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nLogging\nVegetative cover\nLogging:vegetation interaction\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nCategorical land cover classes\nCanopy and understory cover (%) as measured by LiDAR\nCategorical land cover classes + vegetative cover + (Logging age):(vegetative\n**BLOCK**fs== 8.5**p== 4.0**b== 0.3**t== 0.7**l== 0.5**r== 0.4**\ncover) interactions\n**BLOCK**fs== 8.5**p== 4.0**b== 0.2**t== 0.7**l== 0.2**r== 0.6**\nMovement rate versus logged stand age\nMovement rate versus vegetative cover\n**BLOCK**fs== 8.5**p== 4.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nCategorical land cover classes + (Movement rate):(logged stand) interactions\nVegetative cover + (Movement rate):(vegetative cover) interactions\n**BLOCK**fs== 8.5**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nCovariate group\n**BLOCK**fs== 8.5**p== 4.0**b== 0.2**t== 0.8**l== 0.4**r== 0.4**\nCovariates included in group\n**BLOCK**fs== 8.5**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.7**\nCore covariates\nCategorical land cover classes\nVegetative cover\n(Logging age):(vegetative cover) interactions\n**BLOCK**fs== 8.5**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\n(Movement rate):(logged stand) interactions\n**BLOCK**fs== 8.5**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.6**\n(Movement rate):(vegetative cover) interactions\n**BLOCK**fs== 8.5**p== 4.0**b== 0.1**t== 0.8**l== 0.4**r== 0.1**\nln(step length) + slope + elevation + ln(distance to road)\nYoung logged stands + old logged stands + unharvested commercial forest + open terrain\nLiDAR derived canopy and understory (%)\nyoung_logged_stands:canopy + young_logged_stands:understory +\nold_logged_stands:canopy + old_logged_stands:understory\nln(step length):young_logged_stands + ln(step length):old_logged_stands +\nln(step length):ln(distance to road)\nln(step length):canopy + ln(step length):understory\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nreferred to as ‘understory’ (shorter ground-cover plants and\ntaller shrubs) likely fall outside this 0.5–1.0 m height stra-\ntum. However, similar available measures of LiDAR returns\nin the 0.0–0.5 and 1.0–2.0 m range were strongly correlated\nwith the 0.5–1.0 m vegetation stratum (r = 0.77 and 0.81,\nrespectively), and so are represented in models to some\nextent by proxy.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nWe did not know the LiDAR-derived structural attrib-\nutes of historically logged forests prior to logging, as the\nLiDAR data were not collected until 2017–2018. Therefore,\nunharvested commercial forest was defined as that with a\nmean canopy height equal to the  25th-percentile of timber\nlogged, since LiDAR data were collected in the study area\nin 2017–2018 (18.6 m). We believe that this threshold bal-\nances the fact that historic timber harvest targeted large trees\n(Albert & Schoen 2013) but that even within stands of trees\ntargeted by logging there existed a wide range of canopy\nheights previous to logging. We defined an open vegetation\nclass as lands with < 25% canopy coverage, and all remain-\ning land—canopy cover ≥ 25% with tree height > 18.6 m (the\nthreshold we used for commercial timber)—as noncommer-\ncial forest.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nOpen  and  closed  road  classes  were  delineated  using\ntwo USFS roads databases (USFS 2019a; , b): (1) a main\ndatabase including all USFS ‘system’ (permanent) roads\n(though many of these are in various stages of disrepair and\nvegetated to some extent), and (2) an ancillary database of\ndecommissioned and non-USFS roads of varying character-\nistics, although most are closed to vehicle traffic. The system\nroads are further classed as (1) closed to vehicle traffic, (2)\naccessible to high-clearance vehicles, or (3) accessible to\npassenger vehicles. We defined closed roads as the combi-\nnation of those system roads closed to any vehicles and all\nnon-system roads, and open roads as all roads with at least\nsome vehicle access per the USFS system roads database.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nThe road system on POW is extensive, discontinuous,\nand partially inaccessible to vehicles, which made ground-\ntruthing site-specific road characteristics (vegetation, level\nof human use) not feasible for this study. Generally, the\nclosed road class was in some state of revegetation, but this\nvaried depending on site characteristics (Online Resource\nAppendix  S1,  Fig.  1).  For  instance,  some  closed  roads\nexperience foot traffic from human hunters and fishers, and\nso, although the road surface is vegetated, a foot trail is\nmaintained, which may facilitate wolf movement and human\nuse. Although an exhaustive characterization of roads was\nnot possible, to understand the existing variability in road\nrevegetation, we photo-interpreted road conditions at random\npoints along open and closed roads (n = 200) and along both\nclasses combined (n = 400), and categorized the surrounding\nroad (100 m in each direction of a random point) into one of\nfour classes: (1) Road paved and with no vegetation on road\nsurface, (2) < 50% of road surface vegetated, (3) > 50% of\n**BLOCK**fs== 10.0**p== 5.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nexposed road surface vegetated with herbs, shrubs, or trees,\nand, (4) 100% of road surface vegetated with trees (Online\nResource Appendix S1, Table 1).\n**BLOCK**fs== 11.0**p== 5.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nModeling\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.2**l== 0.5**r== 0.1**\nWe  performed  integrated  step-selection  analysis  (iSSA;\nAvgar et al. 2016) to study the fine-scale influence of the\nvegetation and logging-related covariates on wolf habitat\nselection and movement rate. iSSAs contrast the environ-\nmental attributes of each animal location with a set of ran-\ndom locations drawn from the overall distribution of steps\nthe animal took (Avgar et al. 2016), and availability is thus\nconstrained to a localized area near the starting position\nof each step. We drew available points generated from the\ngamma distribution of step lengths of each wolf in each sea-\nson. The distribution of turn angles of wolves did not show\nany deviation from random, and so was not used to con-\nstrain the location of available points as often done in iSSAs\n(Fieberg et al. 2021). We estimated coefficients of habitat\nselection via the main effects of environmental covariates,\nand movement via interactions of ln(step length) and the\nenvironmental covariates (Avgar et al. 2016). We generated\n10 available points from a gamma distribution based on the\nstep lengths each wolf took in an individual season using\nthe amt package (Signer et al. 2019) and attributed these and\nthe used locations with environmental (GIS) covariate data.\nWe then built iSSA models using Cox proportional hazards\nmodels with the fit_issa function in amt, a wrapper for the\nclogit (R package survival) function. We used the covariate\nvalue at the end point of each step to describe wolf habitat\nselection and at the start point of each step to interact with\nstep length to describe wolf movement (Avgar et al. 2016).\nWe used R package targets to create a reproducible modeling\nworkflow.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nWe included specific covariates in each of the 5 mod-\nels built to ask different questions (Table 2). One excep-\ntion to this conceptually was ln(distance to road), which\nwe included in all models, as we thought it may influence\nboth habitat selection and movement, but was not strongly\nrelated to other covariates. We chose to use the coefficients\nfor  ln(distance  to  road)  and  its  interaction  with  ln(step\nlength) from Model 5 to calculate predictions of movement\nrate, although the sign and magnitude of the coefficient for\nln(distance to road) and the ln(step length):ln(distance to\nroad) interaction did not vary greatly between models.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nWe  modeled  wolf  step  selection  across  the  year,  but\nalso built seasonal models corresponding to environmental\nand wolf life-history transitions (Roffler et al. 2018): late\nwinter (1 Jan–14 Apr), denning season (15 Apr–31 Jul), late\nsummer (1 Aug–14 Oct), and fall (15 Oct–31 Dec). There\nwere  several  preliminary  analytical  steps  we  performed\n(Online Resource Appendix S2) that resulted in our final\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.1**l== 0.1**r== 0.5**\nmodel specifications. We built simple, plausible base models\nto which covariates of interest were added. Specifically,\nwe included a core group of covariates—ln(step length),\nln(distance to road), elevation, and slope—in all models\n(Table  2).  In  models  built  to  assess  the  effects  of  the\ncategorical landcover classes or continuous LiDAR-derived\ncovariates on wolf habitat selection, we did not include the\ntwo types together in the same model, as they were often\nstrongly correlated (r > 0.7).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.3**l== 0.1**r== 0.5**\nTo estimate the effect size of model coefficients, we cal-\nculated wolf relative strength of selection (RSS) and move-\nment rate predictions across the typical range of covariate\nvalues experienced by wolves. We made predictions of log-\nRSS (Avgar et al. 2017) to assess the relative likelihood of\nwolf habitat selection across a range of values of covariates\nof interest as the ratio x2/x1, where x1 and x2 are calculated\nfrom model coefficients β across a range of target covari-\nate values x and holding all other covariate values at their\nmean (zero for scaled covariates), where x2 = β1x1 + β2x2 + …\nβnxn (Avgar et al. 2017). The denominator x1 was similarly\ncalculated but with all covariates set to their mean, includ-\ning the target covariate. We predicted log-RSS across the\nrange of values each covariate of interest took in the wolf\nlocation data except for distance to road, as distances from\nroads > 5 km were rare, and we did not have an ecological\nrationale for an effect beyond this distance. Movement rate\npredictions were calculated by multiplying the shape and\nmodified scale parameters of the gamma distribution used\nto generate the available step lengths (Avgar et al. 2016;\nProkopenko et al. 2017).\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nWe  used  the  two-stage  (sensu  Fieberg  et  al.  2021)\napproach of constructing models for each individual wolf\nand  calculating  population-level  coefficients  using  the\ninverse-weighted means of the coefficients from each indi-\nvidual wolf model (Murtaugh 2007). While these popula-\ntion-level coefficients are useful in summary, they obscure\nindividual variability in habitat selection and movement.\nHence, we also reported the proportion of individuals shar-\ning direction (sign) of selection with the population-level\ncoefficient, as well as the proportion of individuals for which\ncoefficients excluded zero. To investigate the biological basis\nfor individual differences in response, we classed individuals\naccording to their life history attributes: (1) sex, (2) breeding\nstatus (breeding versus nonbreeding), and (3) residency—\nmember of pack (resident) versus disperser (nonresident).\nIndividual wolves switched breeding and residency classes\nduring the study, and so we summarized year-round and sea-\nsonal results using the majority of time an individual spent\nin one of the two classes, although this led to some classes\nnot being represented in some seasons. When > 1 individual\nwas present in each class in a season, we tested for statisti-\ncal differences in class response to environmental covari-\nates with univariate linear models run iteratively with the\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nselection coefficient for each step-selection model covariate\nas the response and class membership as the independent\nvariable (1 = male, 0 = female; 1 = breeding, 0 = nonbreed-\ning; 1 = resident, 0 = nonresident). We also plotted RSS for\nwolves belonging to each life history class across the typical\nrange of covariate values experienced by wolves.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.7**t== 0.2**l== 0.5**r== 0.4**\nResults\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nWe  analyzed  data  from  13  wolves,  for  which  the  mean\nnumber  of  year-round  GPS  locations  was  1024  (range:\n355–2279). Within seasons, the mean number of analyzed\nwolf locations was 292 (range: 250–355). Some wolves did\nnot have locations for all seasons; therefore, the number of\nwolves included in each season was as follows: late winter,\nn = 10; denning season, n = 12; late summer, n = 12; and fall,\nn = 12. We classified wolves by breeding status, determined\nfrom field data and observations, and by resident status (i.e.,\nresident wolves are members of a pack with a well-defined\nhome range, and nonresident wolves are dispersers, or extra-\nterritorial wolves, as defined in Roffler et al. 2018) and sum-\nmarized the data in Online Resource Table S3.\n**BLOCK**fs== 11.0**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.3**\nWolf habitat selection\n**BLOCK**fs== 10.0**p== 6.0**b== 0.1**t== 0.5**l== 0.5**r== 0.1**\nWolf population-level response to young (≤ 30 years) logged\nstands was mixed across individuals (population-level confi-\ndence interval included 0; β = 0.050, 95% CI −0.029, 0.130;\nFig. 2a, Table 3) except in fall (β = 0.117, 95% CI 0.007,\n0.197; Table 3). Individual wolf coefficients for selection of\nyoung logged stands tended to be positive across the entire\nyear (77% of individuals) and in each season (58–83% sea-\nsonally; Table 4), with the greatest percentage of individual\nwolves selecting young logged stands occurring in the fall.\nWolf population-level response to old (> 30 years) stands\nwas mixed across individuals (population-level CI included\n0; β = −0.057, 95% CI −0.201, 0.071; Table 3) over the\nentire year (Fig. 2b), reflecting variability in individual wolf\nresponse (Fig. 2b, Table 4). Seasonally, the maximum per-\ncentage of individuals with a positive selection coefficient\nfor old logged stands (70%; Table 4) occurred in late winter.\nWolf response to the LiDAR-derived vegetative cover\nmetrics  was  stronger  than  in  relation  to  the  categorical\nlogged-stand covariates. Wolves consistently avoided can-\nopy cover over the entire year (β = −0.450, 95% CI −0.534,\n−0.269;  Table  3,  Fig.  2c)  and  in  each  season  (Online\nResource Appendix S3, Fig. 1c) at the population level, and\nall individual wolves avoided canopy cover over the entire\nyear (Table 4). In addition, in no season did more than one\nindividual wolf display positive selection for canopy cover\n(Table 4). Wolves also avoided understory cover over the\nentire year at the population (β = −0.086, 95% CI −0.174,\n**BLOCK**fs== 8.5**p== 7.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFig. 2   Modeled  wolf  population-level  and  individual  selection  (log-\nRSS) versus percent cover (0–100%) of A young (≤ 30 years) logged\nstands,  B  old  (> 30  years)  logged  stands,  C  canopy  cover,  and  D\n**BLOCK**fs== 8.5**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nunderstory  cover,  Prince  of  Wales  Island  (POW),  Alaska,  USA,\n2012–2017.  Black  dashed  line  (log-RSS = 0)  indicates  neutral  selec-\ntion\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n−0.025; Fig. 2d) and individual level (85% of individuals;\nTable  4).  Wolves  tended  to  avoid  understory  seasonally\nat the population level, although confidence intervals for\neach season included 0 (Table 3). Individual wolves tended\n(50–80%) to avoid understory seasonally, with the maximum\npercentage occurring in late summer (Table 4). Wolves also\navoided canopy cover within logged stands over the entire\nyear at the population level (Fig. 3a, b), as indicated by the\ninteraction coefficients between canopy and logged stands.\nContrary to their general response to understory (irrespec-\ntive of location), wolves selected understory cover within\nlogged stands (Fig. 3c, d).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.7**l== 0.1**r== 0.5**\nRoads displayed wide variability in their individual char-\nacteristics (Online Resource Appendix S1, Fig. 1, Table 1),\nthe potential cause of wide variability in wolf individual\nwolf response to roads. Over the entire year, wolf individual\nresponse to roads was mixed (population-level β = 0.043,\n95% CI −0.061, 0.211; Fig. 4), although wolves avoided\nroads  in  late  summer  at  the  population  level  (Table  3,\nOnline Resource Appendix S3, Fig. 2) and across every\nindividual (Table 4). Wolves selected areas of less slope\nand lower elevation across the entire year at the population\nlevel (Table 3). Wolves also selected areas of less slope and\nlower elevation in each season over the entire year at the\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.6**l== 0.5**r== 0.1**\npopulation level, although elevation coefficient confidence\nintervals only excluded 0 in fall (Table 3). Wolves avoided\nunharvested commercial forest over the entire year and sea-\nsonally (although late-winter and late-summer coefficient\nconfidence intervals included 0; Table 3) and selected unfor-\nested areas over the entire year and seasonally (although the\ndenning season coefficient confidence interval included 0).\nLife history status (sex, breeding status, or residency) did\nnot affect selection patterns of wolves. In linear models of\nstep-selection model coefficients versus wolf status, no sig-\nnificant (p ≤ 0.05) differences were observed in wolf habitat\nselection between classes in any season (Online Resource\nAppendix S4, Fig. 1a–c), despite 36 total linear models—4\ncovariates X 3 life history classes X 4 seasons (but excluding\ncombinations for which < 2 individuals were represented in\na class)—used to detect differences (1–2 comparisons would\nbe expected to yield p-values ≤ 0.05 by random chance).\nHowever, the lowest two p-values (p = 0.07) indicated a\npotential tendency for males to avoid young logged stands\nand understory relative to females in late winter.\n**BLOCK**fs== 3.8**p== 8.0**b== 0.7**t== 0.3**l== 0.1**r== 0.9**\n,\na\nk\ns\na\nl\nA\n**BLOCK**fs== 4.2**p== 8.0**b== 0.6**t== 0.4**l== 0.1**r== 0.9**\nd\nn\na\nl\ns\nI\n**BLOCK**fs== 3.8**p== 8.0**b== 0.5**t== 0.4**l== 0.1**r== 0.9**\ne\nc\nn\ni\nr\nP\n**BLOCK**fs== 3.8**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\n,\nl\na\nn\no\ns\na\ne\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.4**t== 0.5**l== 0.1**r== 0.9**\nd\ne\nn\ni\nb\nm\no\nc\n**BLOCK**fs== 3.3**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.9**\ns\nn\no\ns\na\ne\ns\n**BLOCK**fs== 2.4**p== 8.0**b== 0.3**t== 0.6**l== 0.1**r== 0.9**\n,\ns\nl\ne\nd\no\nm\nn\no\ni\nt\nc\ne\nl\ne\ns\n**BLOCK**fs== 2.4**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.9**\nt\na\nt\ni\nb\na\nh\n**BLOCK**fs== 3.8**p== 8.0**b== 0.2**t== 0.7**l== 0.1**r== 0.9**\nf\nl\no\nw\ne\nl\na\nc\ns\n-\ne\nn\nfi\n**BLOCK**fs== 3.8**p== 8.0**b== 0.2**t== 0.8**l== 0.1**r== 0.9**\nh\nc\na\ne\nm\no\nr\nf\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.8**l== 0.1**r== 0.9**\ns\nt\nn\ne\ni\nc\nffi\ne\no\nC\n**BLOCK**fs== 6.6**p== 8.0**b== 0.6**t== 0.3**l== 0.1**r== 0.9**\nr\ne\nm\nm\nu\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.5**t== 0.4**l== 0.1**r== 0.9**\nn\no\ns\na\ne\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\ng\nn\ni\nn\nn\ne\nD\n**BLOCK**fs== 3.8**p== 8.0**b== 0.4**t== 0.6**l== 0.1**r== 0.9**\nr\ne\nt\nn\ni\nw\ne\nt\na\nL\n**BLOCK**fs== 3.3**p== 8.0**b== 0.3**t== 0.7**l== 0.1**r== 0.9**\ns\nn\no\ns\na\ne\ns\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.9**l== 0.1**r== 0.9**\ne\nt\na\ni\nr\na\nv\no\nC\n**BLOCK**fs== 2.8**p== 8.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\nt\ns\ne\nr\no\nf\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nl\na\ni\nc\nr\ne\nm\nm\no\nc\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nd\ne\nt\ns\ne\nv\nr\na\nh\nn\nU\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.2**r== 0.8**\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nn\no\ni\nt\na\nv\ne\nl\nE\n**BLOCK**fs== 3.3**p== 8.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 3.3**p== 8.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.4**r== 0.6**\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\nn\no\ni\nt\na\nv\ne\nl\nE\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\nd\ne\nt\ns\ne\nr\no\nf\nn\nU\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\ny\np\no\nn\na\nC\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\ny\nr\no\nt\ns\nr\ne\nd\nn\nU\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.5**r== 0.5**\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\nn\no\ni\nt\na\nv\ne\nl\nE\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\ny\np\no\nn\na\nC\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\ny\nr\no\nt\ns\nr\ne\nd\nn\nU\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.8**r== 0.2**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n:\nd\ne\ng\ng\no\nl\n_\ng\nn\nu\no\ny\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.7**r== 0.2**\nr\ne\nv\no\nc\n:\nd\ne\ng\ng\no\nl\n_\ng\nn\nu\no\ny\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.8**r== 0.2**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n:\nd\ne\ng\ng\no\nl\n_\nd\nl\no\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.8**r== 0.2**\ny\np\no\nn\na\nc\n:\nd\ne\ng\ng\no\nl\n_\nd\nl\no\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.7**r== 0.3**\nd\ne\nt\ns\ne\nr\no\nf\nn\nU\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.9**l== 0.9**r== 0.1**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.8**r== 0.1**\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.8**r== 0.1**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 3.3**p== 8.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.8**l== 0.7**r== 0.3**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 3.3**p== 8.0**b== 0.1**t== 0.8**l== 0.7**r== 0.3**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.7**r== 0.3**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 2.8**p== 8.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\nt\ns\ne\nr\no\nf\n**BLOCK**fs== 3.8**p== 8.0**b== 0.1**t== 0.8**l== 0.7**r== 0.3**\nl\na\ni\nc\nr\ne\nm\nm\no\nc\n**BLOCK**fs== 4.2**p== 8.0**b== 0.1**t== 0.9**l== 0.7**r== 0.3**\nd\ne\nt\ns\ne\nv\nr\na\nh\nn\nU\n**BLOCK**fs== 6.6**p== 9.0**b== 0.6**t== 0.3**l== 0.1**r== 0.9**\nr\ne\nm\nm\nu\ns\n**BLOCK**fs== 4.2**p== 9.0**b== 0.5**t== 0.4**l== 0.1**r== 0.9**\nn\no\ns\na\ne\ns\n**BLOCK**fs== 4.2**p== 9.0**b== 0.5**t== 0.5**l== 0.1**r== 0.9**\ng\nn\ni\nn\nn\ne\nD\n**BLOCK**fs== 3.8**p== 9.0**b== 0.4**t== 0.6**l== 0.1**r== 0.9**\nr\ne\nt\nn\ni\nw\ne\nt\na\nL\n**BLOCK**fs== 3.3**p== 9.0**b== 0.3**t== 0.7**l== 0.1**r== 0.9**\ns\nn\no\ns\na\ne\ns\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.6**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nd\ne\ng\ng\no\nl\n_\nd\nl\no\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nd\ne\ng\ng\no\nl\n_\ng\nn\nu\no\ny\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 2.8**p== 9.0**b== 0.2**t== 0.8**l== 0.3**r== 0.7**\nt\ns\ne\nr\no\nf\n**BLOCK**fs== 3.8**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nl\na\ni\nc\nr\ne\nm\nm\no\nc\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nd\ne\nt\ns\ne\nv\nr\na\nh\nn\nU\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.3**r== 0.7**\nd\ne\nt\ns\ne\nr\no\nf\nn\nU\n**BLOCK**fs== 3.3**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.8**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.2**r== 0.8**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 3.3**p== 9.0**b== 0.1**t== 0.8**l== 0.2**r== 0.7**\ns\nd\nn\na\nt\ns\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nd\ne\ng\ng\no\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\nn\no\ni\nt\na\nv\ne\nl\nE\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.1**r== 0.9**\n)\nd\ne\nu\nn\ni\nt\nn\no\nc\n(\n**BLOCK**fs== 3.8**p== 9.0**b== 0.1**t== 0.9**l== 0.1**r== 0.9**\ne\nt\na\ni\nr\na\nv\no\nC\n**BLOCK**fs== 3.8**p== 9.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.4**r== 0.6**\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.4**r== 0.6**\nn\no\ni\nt\na\nv\ne\nl\nE\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\ny\np\no\nn\na\nC\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\ny\nr\no\nt\ns\nr\ne\nd\nn\nU\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.5**\ny\np\no\nn\na\nc\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.5**r== 0.5**\ny\nr\no\nt\ns\nr\ne\nd\nn\nu\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.5**r== 0.5**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.8**l== 0.6**r== 0.4**\ne\nc\nn\na\nt\ns\ni\nd\n(\nn\nl\n:\n)\nh\nt\ng\nn\ne\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\np\ne\nt\ns\n(\nn\nl\n**BLOCK**fs== 4.2**p== 9.0**b== 0.3**t== 0.7**l== 0.6**r== 0.4**\ng\nn\ni\nd\nu\nl\nc\nn\ni\n**BLOCK**fs== 2.4**p== 9.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nl\na\nv\nr\ne\nt\nn\ni\n**BLOCK**fs== 3.8**p== 9.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\ne\nc\nn\ne\nd\nfi\nn\no\nc\n**BLOCK**fs== 3.8**p== 9.0**b== 0.1**t== 0.9**l== 0.6**r== 0.4**\nw\ns\nt\nn\ne\ni\nc\nffi\ne\no\nC\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nTable 4   Proportion  of  individual  wolves  with  model  coefficient  sign\nconcordant  (Conc.)  with  the  sign  of  the  population-level  coefficient\n(Sign), and with confidence interval of random coefficient excluding\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\n0 (CI 0), in fine-scale habitat selection models, Prince of Wales Island\n(POW), Alaska, USA, 2012–2017\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.1**r== 0.9**\nCovariate\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.7**\nAll seasons\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nLate winter\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nDenning season\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.7**r== 0.3**\nLate summer\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\nSign Conc CI 0\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nSign Conc CI 0\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.3**\nSign Conc CI 0\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.7**r== 0.2**\nSign Conc CI 0\n**BLOCK**fs== 8.5**p== 10.0**b== 0.8**t== 0.2**l== 0.8**r== 0.1**\nSign Conc CI 0\n**BLOCK**fs== 8.5**p== 10.0**b== 0.4**t== 0.2**l== 0.1**r== 0.7**\nModel 1\nYoung logged stands\n+\nOld logged stands\n−\nUnharv. commercial forest\n−\nUnforested\n−\nModel 2\n−\nln(distance to road)\n+\nElevation (m)\n−\nSlope (°)\n−\nCanopy\n+\nUnderstory\n+\nModel 3\n+\nYoung_logged:canopy\n−\nYoung_logged:understory\n+\nOld_logged:canopy\n−\nOld_logged:understory\n−\n−\nModel 4\nln(step length):young_logged −\n−\nln(step length):old_logged\n−\nModel 5\n−\nln(step length):canopy\nln(step length):understory\n−\nln(step length):ln(dist to road) −\n**BLOCK**fs== 8.5**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.6**\nCovariates shared by multiple models not shown\n**BLOCK**fs== 11.0**p== 10.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nWolf movement rate\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nWolf movement rate was not influenced by young logged\nstands over the entire year at the population level (Fig. 5a)\nbut slowed in old logged stands (Fig. 5b). In each individual\nseason, the confidence intervals for ln(step length) interac-\ntions with young and old logged stands included 0 (Table 3;\nOnline Resource Appendix S3, Fig. 3a, b), indicating no\nsignificant effect on movement rate. There was a tendency\nfor wolves to move more slowly in old logged stands in\neach season, as the ln(step length):old logged stand interac-\ntion coefficient was consistently negative across seasons at\nthe population level (but with confidence interval includ-\ning 0; Table 3). In addition, 85% of individuals tended to\nmove more slowly in old logged stands over the entire year\n(Table 4). Seasonally, the percentage of individuals display-\ning a tendency for slower movement in old logged stands\nwas at its maximum in late summer (80%).\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nCanopy cover tended to slow wolf movement rates at\nthe population level over the entire year (Fig. 5c) and in\neach  season  (Online  Resource  Appendix  S3,  Fig.  3c),\n**BLOCK**fs== 10.0**p== 10.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nalthough seasonal confidence intervals included 0. Indi-\nvidual wolves corroborated this tendency for slower move-\nment in old logged stands; 75% of individuals over the\nentire year, and 67–80% seasonally, displayed negative\ncoefficients for ln(step length):old logged stand interac-\ntions. Compared to canopy cover, understory slowed wolf\nmovement to a greater extent at the population level over\nthe  entire  year  (Fig.  5d),  seasonally  (Online  Resource\nAppendix S3, Fig. 3d), and across individuals (Table 4).\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nContrary to our expectations, we did not observe an\neffect of roads on wolf movement rate at the population\nlevel (β = −0.008, 95% CI −0.033, 0.012) over the entire\nyear (Fig. 6), although 69% of individuals moved faster\nnear roads (Table 4). Wolves did, however, move faster\nnear roads in the denning season at the population level\n(β = −0.025, 95% CI −0.060, -0.014), and in the denning\nseason, all but one wolf moved faster near roads (Table 4).\nAs with wolf selection patterns, we saw no significant\neffect of different wolf life history classes (sex, breeding\nstatus, or residency) on seasonal wolf movement rate. In\nlinear models of step-selection model coefficients versus\n**BLOCK**fs== 8.5**p== 11.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFig. 3   Modeled  wolf  population-level  selection  (log-RSS)  ver-\nsus  percent  canopy  cover  (0–100%)  inside  and  outside  of  A  young\n(≤ 30 years) logged stands and B old (> 30 years) logged stands, and\n**BLOCK**fs== 8.5**p== 11.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nversus percent understory cover in C young and D old logged stands,\nPrince  of  Wales  Island  (POW),  Alaska,  USA,  2012–2017.  Black\ndashed line (log-RSS = 0) indicates neutral selection\n**BLOCK**fs== 8.5**p== 11.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nFig. 4   Modeled wolf year-\nround, population-level and\nindividual selection (log-RSS)\nversus distance to nearest road,\nPrince of Wales Island (POW),\nAlaska, USA, 2012–2017.\nBlack dashed line (log-RSS = 0)\nindicates neutral selection\n**BLOCK**fs== 8.5**p== 12.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFig. 5   Modeled  wolf  population-level  and  individual  movement\nrate  versus  percent  cover  (0–100%)  of  A  young  (≤ 30  years)  logged\nstands, B old (> 30 years) logged stands, C canopy cover, and Dun-\n**BLOCK**fs== 8.5**p== 12.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nderstory  cover,  Prince  of  Wales  Island  (POW),  Alaska,  USA,  2012–\n2017. Black dashed line (log-RSS = 0) indicates the mean wolf popu-\nlation movement rate (274 m/h−1)\n**BLOCK**fs== 8.5**p== 12.0**b== 0.3**t== 0.6**l== 0.1**r== 0.7**\nFig. 6   Modeled wolf popu-\nlation-level and individual\nmovement rate versus dis-\ntance to road, Prince of Wales\nIsland (POW), Alaska, USA,\n2012–2017. Black dashed line\n(log-RSS = 0) indicates the wolf\nmean population movement rate\n(274 m/h−1)\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nwolf  status,  no  significant  (p ≤ 0.05)  differences  were\nobserved  in  wolf  movement  rate  relative  to  covariates\nbetween classes in any season (Online Resource Appen-\ndix S4, Fig. 2a–c).\n**BLOCK**fs== 12.0**p== 13.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nDiscussion\n**BLOCK**fs== 10.0**p== 13.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nWe found that wolves respond to continuous vegetative\ncover (measured by LiDAR) that captures fine-scale vari-\nability not reflected in ‘all-or-nothing’ categorical repre-\nsentations of logged stands. Contrary to our predictions,\nwolves did not select young (≤ 30 years) logged stands,\nnor avoid old (> 30 years) stands. Unexpectedly, wolves\ndid not move faster through young logged stands, and their\nmovement was slowed by old logged stands. In contrast,\nin accordance with our predictions, wolves selected and\nmoved faster through areas of less canopy and understory\ncover (although the effect of canopy on movement rate was\nnot significant). Modeling animal selection of one discrete\nlandcover class over another is appealing in its simplicity,\nbut the continuous covariates used for vegetative cover in\nthis study captured gradients in vegetation lost in homoge-\nneous logged stand classes (see Boyce et al. 2017).\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.5**l== 0.1**r== 0.5**\nThe wolves we studied selected and moved through areas\nof less vegetative cover that potentially promote efficient\nhunting by wolves (Dickie et al. 2017; Finnegan et al. 2018).\nThe ability of wolves to visually detect prey (Kauffman\net al. 2007; Boucher et al. 2022), and to move efficiently\n(Dickie et al. 2017, 2020) can be reduced in heavy vegeta-\ntion, potentially leading to decreased prey encounter rates.\nAt the same time, wolves may perceive greater risk due to\nthe presence of human deer hunters and wolf trappers vis-\nible in open terrain lacking cover (Person and Russell 2008)\nsuch as results from logging. In addition, in some cases,\nyoung seral forests resulting from logging are preferred by\nungulate species preyed on by wolves (Boucher et al. 2022),\nand wolves with greater coverage of recently logged stands\nin their home range have a greater proportion of deer in their\ndiet (Roffler et al. 2023). These factors that potentially affect\nwolf fitness may exert opposing forces on wolf habitat selec-\ntion and could result in individual wolves’ mixed selection\ntoward logged stands in this study. While we did not find\nstrong direct evidence for the influence of timber harvest on\nwolves, the vegetative cover metrics correlated with wolf\nhabitat selection and movement are strongly affected by log-\nging (Gregovich et al. 2024) and undergo a trajectory of\nreestablishment post-logging. Generally, forest canopy cover\nremoved by logging increases in the period 0–30 year post-\nlogging and then plateaus at percentages greater than that\nof the original old-growth forest for > 150 years (Alaback\n1984). Understory that initially increases 0–30 year post\nlogging is suppressed concurrent with the establishment\n**BLOCK**fs== 10.0**p== 13.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nof dense conifer canopy. Despite these general trajectories,\nthere is likely fine-scale variability in post-logging vegeta-\ntion that is dependent on site-specific conditions (Banner\nand LePage 2008) and influences wolf habitat selection and\nmovement.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.2**l== 0.5**r== 0.1**\nAlthough wolves generally avoided understory cover, they\nselected understory when in logged areas; the underlying\nmechanism for this is not clear from our analysis. A peak\nin understory cover is observed in the study area 10 years\nafter logging which is a time when canopy cover is sparse.\nWe suspect wolves are attracted to these recently logged\nareas with relatively open canopy that potentially provide\nforage for their Sitka black-tailed deer prey (see Boucher\net al. 2022). By around 30 years after logging understory\ndecreases and canopy increases, and so this situation favored\nby wolves post-logging appears short-lived.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nSitka black-tailed deer are wolves’ main prey in our study\narea (Roffler et al. 2023), and vegetation patterns influence\nthe risk of wolf predation to which deer are exposed in the\nregion of this study (Farmer et al. 2006). Farmer et al. (2006)\nidentify areas of open vegetation as high-risk for deer and\nhighlight the importance of thick understory as cover from\nwolf predation. While vegetative cover undergoes rapid\nchanges after logging occurs, natural areas not targeted by\nlogging (e.g., wet bogs, forested wetlands, alpine meadows)\nare relatively stable in their characteristics through time.\nSuch areas of little vegetative cover are selected by wolves,\npromote their movement, and are associated with increased\nmortality risk for deer (Farmer et al. 2006). In addition,\nFarmer et al. (2006) found deer more exposed to wolf preda-\ntion in flat areas that wolves strongly selected in the current\nstudy. The configuration of natural features and vegetation\noutside the matrix of logged stands represents a temporally\nstable yet spatially variable landscape of risk for deer that is\nlargely unaffected by land management.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\nThe  use  of  LiDAR  to  measure  and  map  landscape\nvegetation patterns to describe wildlife-habitat relationships\nis becoming more common (Shanley et al. 2021; Sergeyev\net al. 2024), and in this study, LiDAR-derived, continuous\nmeasures  of  vegetation  better  explained  wolf  selection\nbehavior  than  categorical  land  classes.  iSSAs  contrast\nenvironmental covariates within clusters consisting of a\nsingle used location and multiple (here, 10) random points.\nContinuous covariate values are likely to vary at the fine\nscale  of  these  data  clusters,  but  land  classes  may  not,\ndepending on their spatial distribution (see Boyce et al.\n2017). Wolves are likely responding to fine-scale variability\nin three-dimensional vegetative structure as captured by\nLiDAR (Davies and Asner 2014) but lost in monolithic,\ncategorical representation.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nA limitation of the current study is that the canopy and\nunderstory measures we used have not been validated on-\nthe-ground. We recommend collection of vegetation plot\n**BLOCK**fs== 10.0**p== 14.0**b== 0.6**t== 0.1**l== 0.1**r== 0.5**\ndata to validate LiDAR-derived cover measures to on-the-\nground measurements of vegetative characteristics in any\nfuture studies. In addition, the aerial collection of LiDAR\nmeasurements took place in 2017–2018, at the tail end of\nwolf GPS location collection, and 5 years after the first\nwolf GPS locations were obtained in 2012. The maximum\nmismatch between vegetation as it existed at the beginning\nof the study and when LiDAR was collected likely occurs\nin recently logged stands, as the greatest rate of change\nin canopy cover and understory occurs within 0–10 years\n(see Gregovich et al. 2024) after logging. Logged areas this\nrecent are not prevalent in the study area, and so our results\nmay not be greatly affected. Outside of logged areas, natu-\nral catastrophes (e.g., fire, large-scale windthrow) affecting\nvegetation are rare in the study area, and climax vegetation\ncommunities likely did not change appreciably during the\n6 years of the study.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.1**t== 0.4**l== 0.1**r== 0.5**\nOverall, the population of wolves in this study did not\nbehaviorally respond to roads, counter to our predictions.\nWe expected roads would be associated with increased wolf\nmovement (Zimmerman et al. 2014; Dickie et al. 2020),\navoidance of risky areas (Gurarie et al. 2011), or selection\nas movement corridors (Boucher et al. 2022). In this study,\nwe did not detect a difference in wolf response to roads open\nand closed (as classified via a USFS GIS database) to vehi-\ncle traffic. Roads (including within these two classes) vary\nwidely in characteristics influential to wolves, and this may\nhave led to the mixed response we observed. Roads in the\nstudy area exist in various combinations of human accessi-\nbility and revegetation, likely affecting wolf behavior in ways\nthat are ambiguous and site dependent. For instance, roughly\n1/3 of roads in the study area are fully revegetated with trees,\nwhich likely impedes both human and wolf use, while we\nestimated 4% of roads are paved and receive high-speed pas-\nsenger use, and thus may be risky and avoided by wolves.\nThe remainder of roads are gravel and in varying stages of\nrevegetation, and hence vary widely in use by humans and\npotential effect on wolf behavior. However, while we did not\nobserve significant overall effects of roads on wolf habitat\nselection there was some evidence for selection of roads as\nmovement corridors. Wolves selected areas near roads dur-\ning late summer at the population level, and in each season\nthere were individuals that selected areas closer to roads. It\nis possible that snow deposition on roads in winter impedes\nwolf movement rate, though some individual wolves moved\nfaster near roads year-round. Roads in the study area might\nbenefit from a thorough description (perhaps via LiDAR,\nsee Waga et al. 2020) and accurate classification based on\ncharacteristics relevant to wolf behavior.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nIn future studies, a shorter GPS fix interval than the 6-h\nrate used here may also reveal patterns of road use not evi-\ndent in the current study. Greater spatio-temporal resolu-\ntion of wolf locations could allow identification of wolf\n**BLOCK**fs== 10.0**p== 14.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nbehavioral states (e.g., encamped, traveling; Zimmerman\net al. 2014), that are difficult to obtain from data collected at\nthis coarse, 6-h time interval (see Creel et al. 2013; Cristecu\net al. 2015). Discerning behavioral states may help reveal\nroad influence not evident in this study. For instance, the\neffect of roads on wolf movement rate may be confounded\nif wolves move faster on or near roads while hunting, but\nalso stop to kill and consume prey there. Finally, a shorter\nGPS fix interval would more generally elucidate wolf habitat\nselection and movement behavior at a finer spatial scale;\nthe combination of 6-h GPS fixes and the high mobility of\nwolves in this study resulted in a spatial scale of analysis\non the larger end of that considered in most step selection\nanalyses.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.3**l== 0.5**r== 0.1**\nWolves have long been recognized for their behavioral\nplasticity, which has facilitated adaptation to a variety of\nhabitats worldwide (Boyd et al. 2023), differences in prey\navailability (Newsome et al. 2016), and varying effects of\nanthropogenic  disturbance  (Ferreiro-Arias  et  al. 2024).\nAlthough individual differences in behavior have been attrib-\nuted to breeding status (Gable et al. 2023), sex (Eriksson\net al. 2024), and resident status (Thompson et al. 2024),\nwe did not find clear patterns in our study system. Wolf\nresponse to logging-related disturbance and vegetation pat-\nterns varied across individuals in this study, but we likely\ndid not have enough data from different population seg-\nments (e.g., packs, sexes, residents versus non-residents)\nto determine a basis for this variability in individual wolf\nresponse. Individual variation in behavior may be the result\nof differences in personality (Bump et al. 2022), defined as\nconsistent differences in individual behaviors across time,\nspace, and ecological contexts (Young et al. 2015), which\nmay be influenced by the individual’s experiences early in\nlife, or due to neuroendocrine activities (Packard 2003). In\naddition, individual personality may be altered by individual\ndiet specialization (Toscano et al. 2016) as specific behav-\niors including boldness and innovation may be associated\nwith foraging strategies (Parsons et al. 2022). In this study,\nindividual wolves displayed a range of responses in differ-\nent forest habitats exemplified by the percentage of wolves\nsharing behavior (avoidance or selection) toward covariates,\nwhich ranged from ~ 50% (expected by random chance) in\nrelation to old logged stands to 100% avoidance of canopy\ncover. This suggests lack of a one-size-fits-all view of wolf\nhabitat selection, and the potential that management actions\nmay not affect all individuals in the same way.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nLogging has resulted in a mosaic of natural habitat and\nsecond-growth  forest  in  various  stages  of  succession  in\ncoastal temperate rainforests (Albert and Schoen 2013).\nWhile natural vegetation patterns in areas not targeted for\ntimber harvest are relatively stable through time, succession\nof  previously  logged  forests,  future  timber  harvest,  and\nsecond-growth remediation (e.g., precommercial thinning)\n**BLOCK**fs== 10.0**p== 15.0**b== 0.6**t== 0.1**l== 0.1**r== 0.5**\nwill  influence  forest  vegetative  cover  and,  in  turn,  wolf\nhabitat selection and movement rate. Wolves in this study\ngenerally  selected  and  moved  faster  through  areas  of\nless  canopy  and  understory  cover  present  in  unforested\nwetlands,  alpine  areas,  and  recently  logged  forests,  the\nlatter of which is a short-lived successional stage giving\nway (~ 30 year post-logging) to heavier vegetative cover\nwolves avoid. Forest precommercial thinning can decrease\ncanopy cover but increase understory (Crotteau et al. 2020),\nwith potentially opposing effects on wolf habitat selection.\nIt is not clear how long these changes last after thinning\noccurs (Cole et al. 2010). Forest management activities may\ninitially benefit wolves by providing open habitat they select,\nbut this successional stage is short-lived, and as these stands\ntransition to closed-canopy stages avoided by wolves, there\nmay be negative consequences for wolf populations.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nSupplementary Information  The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s00442- 025- 05677-5.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nAcknowledgements  We  thank  Lavern  Beier,  Stephen  Bethune,\nMichael Kampnich, Boyd Porter, Ray Slayton, and Jack Whitman for\nassistance with fieldwork, and Grey Pendleton for statistical advice.\nReviews by Anthony Crupi, John Loehr and two anonymous reviewers\ngreatly strengthened the manuscript.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nAuthor contribution statement  GHR conceived the study. DPG and\nCMP performed all analyses. DPG led the writing of the manuscript.\nAll writers provided comments on earlier drafts of the manuscript. All\nauthors have read and approve the manuscript.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nFunding  This study was funded by the Pittman-Robertson Federal Aid\nin Wildlife Restoration Program, the State of Alaska general funds,\nCooperative Endangered Species Conservation Fund (Section 6 of the\nEndangered Species Act) Grant Program, and the U.S. Forest Service,\nTongass National Forest.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nData availability  The data are the property of the State of Alaska. AS\n16.05.815(d) mandates confidentiality of the specific location of fish\nand wildlife species, we, therefore, do not have authority to publicly\nshare them.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nCode availability  The code is available on GitHub: (https:// github. com/\nsculp in99/ POW- wolf- iSSA).\n**BLOCK**fs== 11.0**p== 15.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nDeclarations\n**BLOCK**fs== 8.5**p== 15.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nConflicts of interest  The authors declare that they have no conflict of\ninterest.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nEthical approval  This study followed the guidelines established by the\nADF&G Animal Care and Use Committee (ACUC #2012–028 and\n#2014–15) and the American Society of Mammalogists.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nOpen Access  This  article  is  licensed  under  a  Creative  Commons\nAttribution-NonCommercial-NoDerivatives  4.0  International\nLicense, which permits any non-commercial use, sharing, distribution\nand  reproduction  in  any  medium  or  format,  as  long  as  you  give\nappropriate credit to the original author(s) and the source, provide a\nlink to the Creative Commons licence, and indicate if you modified\nthe licensed material. You do not have permission under this licence\n**BLOCK**fs== 8.5**p== 15.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nto share adapted material derived from this article or parts of it. The\nimages or other third party material in this article are included in the\narticle’s Creative Commons licence, unless indicated otherwise in a\ncredit line to the material. If material is not included in the article’s\nCreative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy\nof this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.\n**BLOCK**fs== 12.0**p== 15.0**b== 0.7**t== 0.3**l== 0.5**r== 0.4**\nReferences\n**BLOCK**fs== 8.5**p== 15.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nAlaback PB (1984) Plant succession following logging in the Sitka\nspruce-western hemlock forests of Southeast Alaska: implications\nfor management. USDA Forest Service Gen. Tech. Report PNW-\nGTR-173. 26\n**BLOCK**fs== 8.5**p== 15.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nAlbert DM, Schoen JW (2013) Use of historical logging patterns to\nidentify disproportionately logged ecosystems within temperate\nrainforests of Southeastern Alaska. Conserv Biol 27:774–784.\nhttps:// doi. org/ 10. 1111/ cobi. 12109\n**BLOCK**fs== 8.5**p== 15.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nAvgar T, Potts R, Lewis MA, Boyce MS (2016) Integrated step selec-\ntion analysis: bridging the gap between resource selection and\nanimal movement. Methods Ecol Evol 7:619–630. https:// doi.\norg/ 10. 1111/ 2041- 210X. 12528\n**BLOCK**fs== 8.5**p== 15.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nAvgar  T,  Lele  SR,  Keim  J,  Boyce  MS  (2017)  Relative  selection\nstrength: quantifying effect size in habitat- and step selection\ninference. Ecol Evol 7:5322–5330. https:// doi. org/ 10. 1002/ ece3.\n**BLOCK**fs== 8.5**p== 15.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nBanner A, Lepage P (2008) Long-term recovery of vegetation com-\nmunities after harvesting in the coastal temperate rainforests of\nnorther British Columbia. Can J for Res 38:3098–3111. https://\ndoi. org/ 10. 1139/ X08- 145\n**BLOCK**fs== 8.5**p== 15.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nBoucher NP, Anderson M, Ladle A, Procter C, Marshall S, Kuzyk G,\nStarzomski BM, Fisher JT (2022) Cumulative effects of wide-\nspread landscape change alter predator-prey dynamics. Sci Rep\n12:11692. https:// doi. org/ 10. 1038/ s41598- 022- 15001-3\n**BLOCK**fs== 8.5**p== 15.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nBoyce MS, Mallory CD, Morehouse AT, Prokopenko CM, Scrafford\nMA, Warbington CH (2017) Defining landscapes and scales to\nmodel landscape-organism interactions. Curr Landsc Ecol Rep\n2:89–95. https:// doi. org/ 10. 1007/ s40823- 017- 0027-z\n**BLOCK**fs== 8.5**p== 15.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nBoyd DK, Ausband DE, Cluff HD, Hefflefinger JR, Hinton JW, Pat-\nterson BR, Wydeven AP (2023) North American wolves. In:\nHiller TL, Applegate RD, Bluett RD et al (eds) Wild furbearer\nmanagement and conservation in North America. Wildlife Ecol-\nogy Institute, Helena, p 32.1-32.68\n**BLOCK**fs== 8.5**p== 15.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nBump J, Gable T, Johnson-Bice S, Homkes A, Freund D, Windels\nS, Shakrabarti S (2022) Predator personalities alter ecosystem\nservices. Front Ecol Environ 20:275–277. https:// doi. org/ 10.\n1002/ fee. 2512\n**BLOCK**fs== 8.5**p== 15.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nCapitani C, Mattioli L, Avanzinelli E, Gazzola A, Lamberti P, Mauri\nL, Scandura M, Viviani A, Apollonio M (2006) Selection of\nrendezvous sites and reuse of pup raising areas among wolves\nCanis lupus of north-eastern Apennines, Italy. Acta Theriol\n51:395–404. https:// doi. org/ 10. 1007/ BF031 95186\n**BLOCK**fs== 8.5**p== 15.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nCole EC, Hanley TA, Newton M (2010) Influence of precommercial\nthinning on understory vegetation of young-growth Sitka spruce\nforests  in  southeastern  Alaska.  Can  J  for  Res  40:619–628.\nhttps:// doi. org/ 10. 1139/ X10- 009\n**BLOCK**fs== 8.5**p== 15.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nCreel S, Winnie JA Jr, Christianson D (2013) Underestimating the\nfrequency, strength and cost of antipredator responses with data\nfrom GPS collars: an example with wolves and elk. Ecol Evol\n3:5189–5200. https:// doi. org/ 10. 1002/ ece3. 896\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nCristecu  B,  Stenhouse  GB,  Boyce  MS  (2015)  Predicting  multi-\nple behaviors from GPS radiocollar cluster data. Behav Ecol\n26:452–464. https:// doi. org/ 10. 1093/ beheco/ aru214\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nCrotteau JS, Rue-Johns AZ, Barnard JC (2020) Effects on understory\nbiomass and forage 8–10 years after precommercial thinning of\nSitka spruce - western hemlock stands in southeast Alaska. Can\nJ for Res 50:215–225. https:// doi. org/ 10. 1139/ cjfr- 2019- 0268\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nDavies AB, Asner GP (2014) Advances in animal ecology from\n3D-LiDAR ecosystem mapping. Trends Ecol Evol 29:681–691.\nhttps:// doi. org/ 10. 1016/j. tree. 2014. 10. 005\n**BLOCK**fs== 8.5**p== 16.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nDennehy E, Llaneza L, Vicente López-Bao J (2021) Contrasting\nwolf responses to different paved roads and traffic volume lev-\nels. Biodivers Conserv 30:3133–3150. https:// doi. org/ 10. 1007/\ns10531- 021- 02239-y\n**BLOCK**fs== 8.5**p== 16.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nDickie M, Serrouya R, McNay RS, Boutin S (2017) Faster and far-\nther: wolf movement on linear features. J Appl Ecol 54:253–\n263. https:// doi. org/ 10. 1111/ 1365- 2664. 12732\n**BLOCK**fs== 8.5**p== 16.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nDickie M, McNay SR, Sutherland GD, Cody M, Avgar T (2020)\nCorridors or risk? Movement along, and use of, linear features\nvaries predictably among large mammal predator and prey spe-\ncies. J Anim Ecol 89:623–634. https:// doi. org/ 10. 1111/ 1365-\n2656. 13130\n**BLOCK**fs== 8.5**p== 16.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nEriksson CE, Roffler GH, Allen JM, Lewis A, Levi T (2024) The ori-\ngin, connectivity, and individual specialization of island wolves\nafter deer extirpation. Ecol Evol 14:11266. https:// doi. org/ 10.\n1002/ ece3. 11266\n**BLOCK**fs== 8.5**p== 16.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nExecutive Office of the President. Roadless Rule Revision (2021)\nhttps:// www. regin fo. gov/ public/ do/ eAgen daVie  wRule? pubId=\n20210 4& RIN= 0596- AD51 Accessed 3 Jan 2024\n**BLOCK**fs== 8.5**p== 16.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nFarmer CJ, Person DK, Bowyer RT (2006) Risk factors and mortal-\nity of black-tailed deer in a managed forest landscape. J Wildl\nManag 70:1403–1415. https:// doi. org/ 10. 2193/ 0022- 541X(2006)\n70[1403: RFAMOB] 2.0. CO;2\n**BLOCK**fs== 8.5**p== 16.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nFerreiro-Arias I, Garcia EJ, Palacios V, Sazatornil V, Rodriquez A,\nLópez-Bao JV, Llaneza L (2024) Drivers of wolf activity in a\nhuman-dominated landscape and its individual variability toward\nanthropogenic disturbance. Ecol Evol 14:e70397. https:// doi. org/\n10. 1002/ ece3. 70397\n**BLOCK**fs== 8.5**p== 16.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nFieberg J, Signer J, Smith B, Avgar T (2021) A ‘How to’ guide for\ninterpreting parameters in habitat-selection analyses. J Anim Ecol\n90:1027–1043. https:// doi. org/ 10. 1111/ 1365- 2656. 13441\n**BLOCK**fs== 8.5**p== 16.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nFinnegan L, Pigeon KE, Cranston J, Hebblewhite M, Musiani M, Neu-\nfeld L, Schmiegelow F, Duval J, Stenhouse GB (2018) Natural\nregeneration on seismic lines influences movement behaviour of\nwolves and grizzly bears. PLoS ONE 13:e0195480. https:// doi.\norg/ 10. 1371/ journ al. pone. 01954 80\n**BLOCK**fs== 8.5**p== 16.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nFisher JT, Wilkinson L (2005) The response of mammals to forest fire\nand timber harvest in the North American boreal forest. Mamm\nRev 35:51–81. https:// doi. org/ 10. 1111/j. 1365- 2907. 2005. 00053.x\nGable TD, Johson-Bice SM, Homkes AT, Bump JK (2023) Differen-\ntial provisioning roles, prey size, and prey abundance shape the\ndynamic feeding behavior of gray wolves. Commun Biol 6:1–12.\nhttps:// doi. org/ 10. 1038/ s42003- 023- 05419-4\n**BLOCK**fs== 8.5**p== 16.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nGagnon M, Lesmerises FL, St-Laurent MH (2024) Temporal variations\nin female moose responses to roads and logging in the absence of\nwolves. Ecol Evol 14:e10909. https:// doi. org/ 10. 1002/ ece3. 10909\nGregovich DP, Roffler GH, Prokopenko CM, Gilbert SL (2024) Sitka\nblack-tailed deer habitat selection in relation to logging and veg-\netation in a temperate rainforest. For Ecol Manag 568:122134.\nhttps:// doi. org/ 10. 1016/j. foreco. 2024. 122134\n**BLOCK**fs== 8.5**p== 16.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nGuisan A, Zimmerman NE (2000) Predictive habitat distribution mod-\nels in ecology. Ecol Modell 135:147–186. https:// doi. org/ 10. 1016/\nS0304- 3800(00) 00354-9\n**BLOCK**fs== 8.5**p== 16.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nGurarie E, Suutarinen J, Kojola I, Ovaskainen O (2011) Summer move-\nments, predation and habitat use of wolves in human modified\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nboreal forests. Oecologia 165:801–903. https:// doi. org/ 10. 1007/\ns00442- 010- 1883-y\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nHayes TA, DeCesare NJ, Peterson CJ, Bishop CJ, Mitchell S (2022)\nTrade-offs in forest disturbance management for plant communi-\nties and ungulates. For Ecol Manag 506:119972. https:// doi. org/\n10. 1016/j. foreco. 2021. 119972\n**BLOCK**fs== 8.5**p== 16.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nHeidemann HK (2014) Lidar Base Specification (Version 1.2, Novem-\nber 2014): U.S. Geological Survey Techniques and Methods.\nhttps:// doi. org/ 10. 1017/ CBO97 80511 546013\n**BLOCK**fs== 8.5**p== 16.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nHoule M, Fortin D, Dussault C, Courtois R, Ouellet J (2010) Cumula-\ntive effects of forestry on habitat use by gray wolf (Canis lupus)\nin the boreal forest. Landsc Ecol 25:419–433. https:// doi. org/ 10.\n1007/ s10980- 009- 9420-2\n**BLOCK**fs== 8.5**p== 16.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\nJones EM (2024) A systematic global review of mammalian carnivore\nresponses to production forests. Mammal Rev 54:133–149. https://\ndoi. org/ 10. 1111/ mam. 12333\n**BLOCK**fs== 8.5**p== 16.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nKane K, Sedinger JS, Gibson D, Blomberg E, Atamian M (2017) Fit-\nness landscapes and life-table response experiments predict the\nimportance of local areas to population dynamics. Ecosphere\n8:e01869. https:// doi. org/ 10. 1002/ ecs2. 1869\n**BLOCK**fs== 8.5**p== 16.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nKauffman MJ, Varley N, Smith DW, Stahler DR, MacNulty DR, Boyce\nMS (2007) Landscape heterogeneity shapes predation in a newly\nrestored predator-prey system. Ecol Lett 10:690–700. https:// doi.\norg/ 10. 1111/j. 1461- 0248. 2007. 01059.x\n**BLOCK**fs== 8.5**p== 16.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nKearney M, Porter WP (2009) Mechanistic niche modelling: com-\nbining physiological and spatial data to predict species’ ranges.\nEcol Lett 12:335–350. https:// doi. org/ 10. 1111/j. 1461- 0248. 2008.\n01277.x\n**BLOCK**fs== 8.5**p== 16.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nKennedy RSH, Spies TA (2004) Forest cover changes in the Oregon\nCoast Range from 1939 to 1993. For Ecol Manag 200:129–147.\nhttps:// doi. org/ 10. 1016/j. foreco. 2003. 12. 022\n**BLOCK**fs== 8.5**p== 16.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nKittle AM, Anderson M, Avgar T, Baker JA, Brown GS, Hagens J,\nIwachewski E, Moffatt S, Mosser A, Patterson BR, Reid DEB,\nRodgers AR, Shuter J, Street GM, Thompson ID, Vander Ven-\nnen LM, Fryxell JM (2017) Landscape-level wolf space use is\ncorrelated with prey abundance, easy of mobility, and the distri-\nbution of prey habitat. Ecosphere 8:e01783. https:// doi. org/ 10.\n1002/ ecs2. 1783\n**BLOCK**fs== 8.5**p== 16.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nKnorn J, Kuemmerle T, Radeloff VC, Keeton WS, Gancz V, Biriş I,\nSvoboda M, Griffiths P, Hagatis A, Hostert P (2013) Continued\nloss of temperate old-growth forests in the Romanian Carpathians\ndespite an increasing protected area network. Environ Conserv\n40:182–193. https:// doi. org/ 10. 1017/ S0376 89291 20003 55\nLe Borgne H, Hebert C, Dupuch A, Bichet O, Pinaud D, Fortin D\n(2018) Temporal dynamics in animal community assembly during\npost-logging succession in boreal forest. PLoS ONE 13:e0204445.\nhttps:// doi. org/ 10. 1371/ journ al. pone. 02044 45\n**BLOCK**fs== 8.5**p== 16.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nLesmerises F, Dussault C, St-Laurent M (2012) Wolf habitat selection\nis shaped by human activities in a highly managed boreal forest.\nFor Ecol Manag 276:125–131. https:// doi. org/ 10. 1016/j. foreco.\n2012. 03. 025\n**BLOCK**fs== 8.5**p== 16.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nLesmerises  F,  Dussault  C,  St-Laurent  M  (2013)  Major  roadwork\nimpacts the space use behaviour of gray wolf. Landsc Urban Plan\n112:18–25. https:// doi. org/ 10. 1016/j. landu rbplan. 2012. 12. 011\nLlaneza L, García EJ, Palacios V, Sanatornil V, López-Bao JV (2016)\nResting in risky environments: the importance of cover for wolves\nto  cope  with  exposure  risk  in  human-dominated  landscapes.\nBiodivers  Conserv  25:1515–1528.  https:// doi. org/ 10. 1007/\ns10531- 016- 1134-6\n**BLOCK**fs== 8.5**p== 16.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nLosier CL, Couturier S, St-Laurent M, Drapeau P, Dussault C, Rudolph\nT, Brodeur V, Merkle JA, Fortin D (2015) Adjustments in habitat\nselectin to changing availability induce fitness costs for a threat-\nened ungulate. J Appl Ecol 52:496–504. https:// doi. org/ 10. 1111/\n1365- 2664. 12400\n**BLOCK**fs== 8.5**p== 17.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nMcGaughey RJ (2008) FUSION/LDV LIDAR analysis and visualiza-\ntion software. Version 3.80. Pacific Northwest Research Station.\nUSDA Forest Service. http:// forsys. cfr. washi ngton. edu/ fusion/\nfusion_ overv iew. html. Accessed 10 January 2020.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nMcKenzie HW, Merrill EH, Spiteri RJ, Lewis MA (2012) How linear\nfeatures alter predator movement and the functional response.\nInterface Focus 2:205–216. https:// doi. org/ 10. 1098/ rsfs. 2011.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nMcPhee HM, Webb NF, Merrill EH (2012) Hierarchical predation:\nwolf (Canis lupus) selection along hunt paths and at kill sites. Can\nJ Zool 90:555–563. https:// doi. org/ 10. 1139/ z2012- 021\n**BLOCK**fs== 8.5**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nMurtaugh PA (2007) Simplicity and complexity in ecological data anal-\nysis. Ecology 88:56–62. https:// doi. org/ 10. 1890/ 0012- 9658(2007)\n88[56: SACIED] 2.0. CO;2\n**BLOCK**fs== 8.5**p== 17.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\nNewsome TM, Boitani L, Chapron G, Ciucci P, Dickman CR, Dellinger\nJA, López-Bao JV, Peterson RO, Shores CR, Wirsing AJ, Ripple\nWJ (2016) Food habits of the world’s grey wolves. Mamm Rev\n46:255–269. https:// doi. org/ 10. 1111/ mam. 12067\n**BLOCK**fs== 8.5**p== 17.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nNorthrup JM, Anderson CR, Gerber BD (2021) Behavioral and demo-\ngraphic responses of mule deer to energy development on winter\nrange. Wildl Monogr 208:1–37. https:// doi. org/ 10. 1002/ wmon.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\nPackard JM (2003) Wolf behavior: reproductive, social, and intelligent.\nIn: Mech LD, Boitani L (eds) Wolves: behavior, ecology, and\nconservation. University of Chicago Press, Chicago, pp 35–65\nParsons MA, Garcia A, Young JK (2022) Scavenging vs hunting affects\nbehavioral traits of an opportunistic carnivore. PeerJ 10:1–27.\nhttps:// doi. org/ 10. 7717/ peerj. 13366\n**BLOCK**fs== 8.5**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nPerson DK, Russell AL (2008) Correlates of mortality in an exploited\nwolf population. J Wildl Manag 72:1540–1549. https:// doi. org/\n10. 2193/ 2007- 520\n**BLOCK**fs== 8.5**p== 17.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nPinard V, Dussault C, Ouellet J, Fortin D, Courtois R (2012) Calving\nrate, calf survival rate, and habitat selection of forest-dwelling\ncaribou in a highly managed landscape. J Wildl Manage 76:189–\n199. https:// doi. org/ 10. 1002/ jwmg. 217\n**BLOCK**fs== 8.5**p== 17.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nPlante S, Dussault C, Richard JH, Côté SD (2018) Human disturbance\neffects and cumulative habitat loss in endangered migratory cari-\nbou. Biol Conserv 224:129–143. https:// doi. org/ 10. 1016/j. biocon.\n2018. 05. 022\n**BLOCK**fs== 8.5**p== 17.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nPlard F, Fay R, Kéry M, Cohas A, Schaub M (2019) Integrated popula-\ntion models: powerful methods to embed individual processes in\npopulation dynamics models. Ecology 100:e02715. https:// doi.\norg/ 10. 1002/ ecy. 2715\n**BLOCK**fs== 8.5**p== 17.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nPojarska K, Kwiatkowska M, Skórka P, Gula R, Theuerkauf J, Okarma\nH (2017) Anthropogenic environmental traps: where do wolves\nkill their prey in a commercial forest? For Ecol Manag 397:117–\n125. https:// doi. org/ 10. 1016/j. foreco. 2017. 04. 013\n**BLOCK**fs== 8.5**p== 17.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nPorter B, Gregovich DP, Crupi AP, Pendleton GW, Bethune SW (2021)\nBlack bears select large woody structures for dens in Southeast\nAlaska. J Wildl Manag 85:1450–1461. https:// doi. org/ 10. 1002/\njwmg. 22097\n**BLOCK**fs== 8.5**p== 17.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\nPotvin F, Bertrand N, Ferron J (2005) Attributes of forest strips used by\nsnowshoe hare in winter within clear-cut boreal landscapes. Can J\nfor Res 35:2521–2527. https:// doi. org/ 10. 1139/ x05- 163\n**BLOCK**fs== 8.5**p== 17.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nProkopenko CM, Boyce MS, Avgar T (2017) Characterizing wildlife\nbehavioural response to roads using integrated step selection\nanalysis. J Appl Ecol 52:470–479. https:// doi. org/ 10. 1111/ 1365-\n2664. 12768\n**BLOCK**fs== 8.5**p== 17.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nPyare S, Smith WP, Shanley CS (2010) Den use and selection by\nnorthern flying squirrels in fragmented landscapes. J Mammal\n91:886–896. https:// doi. org/ 10. 1644/ 09- MAMM-A- 179.1\n**BLOCK**fs== 8.5**p== 17.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nQuiles P, Barrientos R (2024) Interspecific interactions disrupted by\nroads. Biol Rev 99:1121–1139. https:// doi. org/ 10. 1111/ brv. 13061\nRoffler GH, Gregovich DP, Larson KR (2018) Resource selection by\ncoastal wolves reveals the seasonal importance of seral forest and\n**BLOCK**fs== 8.5**p== 17.0**b== 0.8**t== 0.1**l== 0.5**r== 0.1**\nsuitable prey habitat. For Ecol Manag 409:190–201. https:// doi.\norg/ 10. 1016/j. foreco. 2017. 11. 025\n**BLOCK**fs== 8.5**p== 17.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nRoffler GH, Pilgrim KL, Zarn KE, Schwartz MK, Levi T (2023) Vari-\nation in adult and pup wolf diets at natal den sites is influenced by\nforest composition and configuration. Ecol Evol 13:e9648. https://\ndoi. org/ 10. 1002/ ece3. 9648\n**BLOCK**fs== 8.5**p== 17.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nSchlossberg S, King DI (2009) Post-logging succession and habitat\nusage of shrubland birds. J Wildl Manag 73:226–231. https:// doi.\norg/ 10. 2193/ 2007- 518\n**BLOCK**fs== 8.5**p== 17.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nSergeyev M, Crawford DA, Holbrook JD, Lombardi JV, Tewes ME,\nCampbell  TA  (2024)  Selection  in  the  third  dimension:  using\nLiDAR derived canopy metrics to assess individual and popu-\nlation-level habitat partitioning of ocelots, bobcats, and coyotes.\nRemote Sens Ecol Conserv 10:264–278. https:// doi. org/ 10. 1002/\nrse2. 369\n**BLOCK**fs== 8.5**p== 17.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nShanley  CS,  Eacker  DR,  Reynolds  CP,  Bennetsen  BMB,  Gilbert\nSL (2021) Using LiDAR and Random Forest to improve deer\nhabitat models in a managed forest landscape. For Ecol Manag\n499:119580. https:// doi. org/ 10. 1016/j. foreco. 2021. 119580\nSigner J, Fieberg J, Avgar T (2019) Animal movement tools (amt): R\npackage for managing and tracking data and conducting habitat\nselection analyses. Ecol Evol 9:880–890. https:// doi. org/ 10. 1002/\nece3. 4823\n**BLOCK**fs== 8.5**p== 17.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\nSikes RS, Gannon WL (2011) Guidelines of the American Society of\nMammalogists for the use of wild mammals in research. J Mam-\nmal 92:235–253. https:// doi. org/ 10. 1093/ jmamm al/ gyw078\nSmith  WP,  Flaherty  EA  (2023)  Wildlife  studies  on  the  Tongass\nNational Forest challenge essential assumptions of its wildlife\nconservation strategy. J Wildl Manag 87:e22450. https:// doi. org/\n10. 1002/ jwmg. 2245\n**BLOCK**fs== 8.5**p== 17.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nSmith JA, Donadio E, Pauli JN, Sheriff MJ, Bidder OW, Middleton AD\n(2019) Habitat complexity mediates the predator–prey space race.\nEcology 100:e02724. https:// doi. org/ 10. 1002/ ecy. 2724\n**BLOCK**fs== 8.5**p== 17.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nSuraci JP, Nickel BA, Wilmers CC (2020) Fine-scale movement deci-\nsions by a large carnivore inform conservation planning in human-\ndominated landscapes. Landsc Ecol 35:1635–1649. https:// doi.\norg/ 10. 1007/ s10980- 020- 01052-2\n**BLOCK**fs== 8.5**p== 17.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\nTherneau TM (2024) survival: a package for survival analysis in R. R\n**BLOCK**fs== 8.5**p== 17.0**b== 0.4**t== 0.6**l== 0.5**r== 0.3**\npackage version 3.6–4.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nThompson CA, Benson JF, Patterson BR (2024) Risk avoidance dur-\ning dispersal: temporal and behavioral shifts in selection by non-\nresident and eastern wolves (Canis c. f. lycaon). Biol Conserv\n300:110879. https:// doi. org/ 10. 1016/j. biocon. 2024. 110879\nToretta E, Caviglia L, Serafini M, Meriggi A (2018) Wolf predation on\nwild ungulates: how slope and habitat cover influence the localiza-\ntion of kill sites. Curr Zool 64:271–275. https:// doi. org/ 10. 1093/\ncz/ zox031\n**BLOCK**fs== 8.5**p== 17.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\nToscano BJ, Gownaris NJ, Heerhartz SM, Monaco CJ (2016) Personal-\nity, foraging behavior, and specialization: integrating behavioral\nand food web ecology at the individual level. Oecologia 182:55–\n69. https:// doi. org/ 10. 1007/ s00442- 016- 3648-8\n**BLOCK**fs== 8.5**p== 17.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\nU.S. Forest Service [USFS] (2016) Tongass National Forest Land and\nResource Plan Amendment. https:// www. fs. usda. gov/ Inter  net/\nFSE_ DOCUM ENTS/ fsepr d5268 94. pdf. Accessed 3 Jan 2024.\nU.S. Forest Service [USFS] (2019) Tongass National Forest roads with\ncore attributes. Southeast Alaska GIS Library. https:// data- seakg\nis. opend ata. arcgis. com. Accessed 22 Oct 2019.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nU.S. Forest Service [USFS] (2019) Tongass National Forest Cover-\nType database. Southeast Alaska GIS Library. https:// data- seakg\nis. opend ata. arcgis. com. Accessed 22 Oct 2019.\n**BLOCK**fs== 8.5**p== 17.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nWaga K, Tompalski P, Coops NC, White JC, Wulder M, Malinen J,\nTokola T (2020) Forest road status assessment using airborne\nlaser  scanning.  For  Sci  66:501–508.  https:// doi. org/ 10. 1093/\nforsci/ fxz053\n**BLOCK**fs== 8.5**p== 18.0**b== 0.8**t== 0.1**l== 0.1**r== 0.5**\nWhittington J, St C, Clair C, Mercer G (2005) Spatial responses of\nwolves to roads and trails in mountain valleys. Ecol Appl 15:543–\n553. https:// doi. org/ 10. 1890/ 03- 5317\n**BLOCK**fs== 8.5**p== 18.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nYoung JK, Mahe M, Breck S (2015) Evaluating behavioral syndromes\nin coyotes (Canis latrans). J Ethol 33:137–144. https:// doi. org/ 10.\n1007/ s10164- 015- 0422-z\n**BLOCK**fs== 8.5**p== 18.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nZabihi-Seissan S, Prokopenko CM, Vander Wal E (2022) Wolf spatial\nbehavior promotes encounters and kills of abundant prey. Oeco-\nlogia 200:11–22. https:// doi. org/ 10. 1007/ s00442- 022- 05218-4\nZimmerman B, Nelson L, Wabakken P, Sand H, Liberg O (2014)\nBehavioral responses of wolves to roads: scaledependent ambiva-\nlence. Behav Ecol 25:1353–1364. https:// doi. org/ 10. 1093/ beheco/\naru134",
         "Vegetation influences wolf fine‑scale habitat selection and movement rate in a logged coastal rainforest · Gretchen H. Roffler1 · Christina M. Prokopenko2 Abstract Vegetation and its modification by humans can shape wildlife habitat selection and movement. A better understanding of how wolves select and move through natural and human modified vegetative cover can be used to implement forest management that considers impacts on wolves and their prey. We analyzed fine-scale wolf habitat selection and movement in a coastal temperate rainforest (Prince of Wales Island, Alaska, USA) in relation to: (1) young (≤ 30 years) and old (> 30 years) logged areas, (2) continuous measures of vegetative cover (as estimated via LiDAR), and (3) distance to roads, using integrated step-selection analysis (iSSA). Wolves selected areas with less forest canopy and understory cover at the population level, although they switched to selecting understory when within logged forest stands. The continuous canopy and understory measures vary at a fine spatial scale and thus appear to better explain fine-scale wolf selection and movement than categorical landcover classes representing the age of logged stands. Wolf selection of young (≤ 30 years) and old (> 30 years) succes- sional logged areas, and areas near roads, was mixed across individuals. All individual wolves avoided canopy cover, but varied in their selection of logged stands, understory, and roads. Similarly, there was variability in movement rate response across individual wolves, although at the population level wolves moved faster through old (> 30 years) logged areas and through areas with less understory vegetation. Open vegetation including that present recently after logging is selected by wolves, and facilitates wolf movement, but this effect may be ephemeral as vegetation undergoes succession. Keywords  Canis lupus · Roads · Habitat selection · iSSA · Rainforest Where animals live and how they move across the landscape are shaped by biotic and abiotic factors that vary spatially (Guisan and Zimmerman 2000; Kearney and Porter 2009). Vegetation is salient among these factors, because it governs available food in the form of forage or, in the case of sec- ondary consumers, herbivorous prey (Smith et al. 2019), as well as cover from predators, including humans (Suraci et al. 2020). Nutritional intake, efficient movement, and predator avoidance are animal fitness requirements that affect survival rate, and hence population dynamics (Plard et al. 2019), and are influenced by landscape vegetation patterns (Losier et al. 2015; Kane et al. 2017). Humans modify natural vegetation patterns (e.g., via infrastructure development, agriculture, and timber harvest), and this modification in turn affects eco- systems and the species within them, including by shaping animal habitat selection (Suraci et al. 2020; Northrup et al. 2021) and movement patterns (Plante et al. 2018; Quiles Quiles and Barrientos 2024). Here, we model the response of an apex predator, Canis lupus, to modification of natural vegetation by timber harvest and associated roads. Human alteration of vegetation includes extensive tim- ber harvest in temperate forests (Kennedy and Spies 2004; Knorn et al. 2013) which affects wildlife space use (Lesmer- ises et al. 2012; Pinard et al. 2012) and movement (Boucher et al. 2022; Gagnon et al. 2024). Logged stands in temper- ate, coniferous rainforests undergo succession from initially open vegetation, through a stage of productive understory, to a long-lasting (from 30 to 200 years post-logging) densely canopied forest with little understory production (Alaback 1984). The impact of the post-logging successional trajec- tory on wildlife varies depending on individual species’ environmental niche and life history (Jones et al. 2024). Species favored initially post-logging may be disadvantaged later in the second-growth successional trajectory (Schloss- berg & King 2009; Le Borgne et al. 2018). The ability of wolves (Canis lupus) to hunt effectively is influenced by spatial patterns of vegetation (Dickie et al. 2017).  Areas  devoid  of  thick  vegetation  are  associated with longer sight distance and increased movement rates and hence increased prey encounter rates (McPhee et al. 2012; Toretta et al. 2018). Wolf prey encounter rates may be greater in areas with greater ungulate prey density (Kittle et al. 2017; but see Zabihi-Seissan et al. 2022), which is pro- moted by abundant ungulate plant forage (Potvin et al. 2005; Gagnon et al. 2024), which is often present in early suc- cessional forests (Fisher and Wilkinson 2005; Hayes et al. 2022) but may diminish through time. Hence, timber harvest could initially benefit wolves by resulting in increased forage attractive to ungulate prey species (Farmer et al. 2006; Kittle et al. 2017). Similarly, logging roads are initially devoid of vegetation and may facilitate wolf hunting but often become revegetated over time (Waga et al. 2020). These initially unvegetated roads promote wolf prey detection and ease of travel but expose wolves to risk in the form of human hunters and trappers (Zimmerman et al. 2014) and vehicles (Dennehy et al. 2021). Logging roads may alternatively be maintained for continued use for logging or for other pur- poses, including as recreational trails or eventual upgrade for passenger vehicle use, thereby constituting risk avoided by wolves (Gurarie et al. 2011; Dennehy et al. 2021). Hence, there are conflicting forces that may result in wolf selection (Houle et al. 2010; Dickie et al. 2020) or avoidance (Whit- tington et al. 2005; Lesmerises et al. 2013) of roads, depend- ing on revegetation and other road characteristics. Coastal temperate rainforests, including those of South- east Alaska, have been the target of industrial timber harvest that occurs to the present and has drastically reduced the coverage of old-growth forests (Albert and Schoen 2013). Prince of Wales Island (POW) in Southeast Alaska has been particularly targeted by the timber industry due to a high density of large trees, and now holds < 6% of the contiguous high-volume forest that existed before large-scale logging began in the 1950s (Albert and Schoen 2013). Wolves are of conservation concern in the region and have been petitioned for listing under the U.S. Endangered Species Act (ESA) three times in the past 30 years. The impacts of logging on these wolves and their Sitka black-tailed deer (Odocoi- leus hemionus sitkensis) prey are a focus of conservation and management policy. Recently, the U.S. Forest Service (USFS) stated they will transition away from old-growth timber harvest to rotational harvest of second-growth for- est (USFS 2016). The 2020 repeal of the Tongass National Forest (TNF) exemption of the Roadless Area Conservation Rule (Executive Office of the President, Roadless Rule Revi- sion 2021) further increases the focus of future logging in areas that have experienced previous harvest. The effect of historic timber harvest patterns and future harvest strategies on wolves and their ecosystem remains unclear. Building on previous work studying the effects of log- ging on wildlife on POW (Farmer et al. 2006; Person and Russell 2008; Pyare et al. 2010; Porter et al. 2021; Roffler et al. 2023), we modeled fine-scale selection and movement of wolves in relation to spatial patterns of vegetation, log- ging, and roads. Based on our knowledge of wolf biology and with support from previous literature (including that presented above) we formulated hypotheses regarding wolf habitat selection and movement rate in relation to environ- mental covariates representing logging, vegetation, and road proximity (Table 1) to be tested via integrated step selection analysis (iSSA) model coefficients. Study area We  studied  wolves  on  POW  in  the  coastal  rainforest  of Southeast  Alaska  (Fig.  1).  POW  is  the  largest  island  in an extensive archipelago and has a maritime climate with high precipitation (> 200 cm/year) and moderate tempera- tures—daily mean ranging from 1.3 °C (January) to 57.4 °C (August)—though cooler at elevation. The forest is domi- nated by Sitka spruce (Picea sitchensis) and western hem- lock (Tsuga heterophylla), with Alaska yellow cedar (Cal- litropsis nootkatensis) and western redcedar (Thuja plicata) also  common.  Some  common  understory  woody  plants include  devil’s  club  (Oplopanax  horridus),  blueberries (Vaccinium spp.), and salal (Gaultheria shallon), and ground cover species include bunchberry (Cornus unalaschkensis), foamflower (Tiarella trifoliata) and twisted stalk (Streptopus spp.). Wolves on POW co-occur with American black bear (Ursus americanus) and Sitka black-tailed deer. Seasonal anadromous runs of Pacific salmon (Onchorynchus spp.) provide large subsidies of marine-derived nutrients to the terrestrial ecosystem. Logging on POW started in the early 1900s but became much larger in scale in the 1950s and continued through the time of the study. Logging has focused on high-volume coniferous forests (Albert & Schoen 2013), resulting in a mosaic of old- and second-growth forests interspersed with less productive forests and unforested lands. Logged areas vary in age and condition from initially open vegetation, transitioning to a mix of dense understory and young coni- fers, and followed (~ 30 year post-logging) by a longer last- ing, ‘stem-exclusion’ phase of dense conifer canopy and relatively little understory (Alaback 1984). The focus of the timber industry on larger tree stands has reduced contigu- ous patches of highly productive old-growth forest present before 1954 by 94% (Albert & Schoen 2013). Most of the existing roads (> 5000 km in length; USFS 2019a) were initially built to access timber but ranged in current status from revegetated (undrivable), to accessible only by off-road vehicles, to improve for passenger vehicle use. Road densi- ties ranged from 0 to 0.44 km/km2 (Roffler et al. 2018). The resulting landscape is thus fragmented by logged areas and roads of various condition, with consequences for wildlife species (Pyare et al. 2010; Smith and Flaherty 2023). Wolf captures We  captured  and  radiocollared  wolves  (n = 13)  from 2012 to 2017 using modified padded long spring (Easy- Grip®  #7,  Livestock  Protection  Company,  Alpine,  TX) and unpadded coil spring foothold traps (MB750, Minne- sota Brand Inc.) set along logging roads and baited with commercially-produced lures and canid urine. We checked wolf traps daily. We immobilized captured wolves using either tiletamine HCl and zolazepam HCl, or a combination of ketamine and medetomidine. Capture and handling pro- cedures conformed to guidelines established by the ADF&G Animal Care and Use Committee (ACUC #2012–028 and #2014–15) and the American Society of  Mammalogists (Sikes and Gannon 2011). We fit each captured wolf with a spread-spectrum, Global Positioning System (GPS) radio collar (Mod 4500, Telonics, Inc.) programmed to obtain a location every 6 h. We programmed collars to automatically release after 24 months, and they included a VHF compo- nent for radiotelemetry and collar recovery after release. Habitat and disturbance covariates We  analyzed  the  effects  of  two  main  features  of  timber harvest,  logged  forest  stands  and  associated  roads,  on wolf habitat selection and movement rate. We calculated the distance to roads in two categories: open and closed to vehicle traffic. We separated logged stands into young (≤ 30 years) and old (> 30 years) successional categories. As a contrast to these logging age categories, we used airborne Light detection and ranging (LiDAR)-derived vegetative cover  metrics  affected  by  timber  harvest  but  varying continuously across the landscape (both inside and outside of logged areas). Initial models using the categorical logged stand covari- ates failed to converge. This led us to explore the use of continuous covariates representing the proportion of logged stands within buffers of increasing radius (50–1000 m in increments of 50) around each wolf location and available point, and contrasted these with the unbuffered (binary) landcover classes, choosing the optimum representation (ultimately, 50-m radius) via model concordance scores (Therneau 2024; Online Resource Fig. S1). The model used for this purpose was based on model 1 (Table 2), but with landcover covariate mean values calculated within buffers of the varying radii. Often, coefficients derived from binary landcover classes used in habitat selection models refer to a ‘reference category’ not included in the model against which coefficients are contrasted. In our models, proportions of these binary landcover types within a 50-m radius of wolf locations were calculated, and the concept of a reference category is not relevant. However, the covariate for the pro- portion of noncommercial forest within a 50-m buffer of locations was excluded from models due to a high variance inflation factor (VIF; 8.42) when included in models with the other landcover covariates. For consistency, we also cal- culated the mean values of LiDAR-derived vegetation cover within a 50-m radius of used and available points. We obtained landcover classes from USFS databases of timber harvest and associated roads in the study area (Online Resource Table S1). We defined young logged stands as those where logging occurred ≤ 30 years prior to 2014, the median year of wolf data collection, and old logged stands those harvested > 30 years prior. We refer to these classes as young and old logged stands, respectively, although some of the youngest (i.e., < 10 years) did not always harbor stands of trees. Distance to roads was log-transformed, as we expected a stronger effect near roads to diminish with distance. All other covariates were derived from LiDAR point cloud data collected in 2017 and 2018 under U.S Geological Survey QL1 specifications (point density = 8/m2; Heidemann 2014), and further processed to calculate vegetation structural met- rics at a 30-m pixel resolution via LiDAR FUSION software (McGaughey 2008). The suite of LiDAR-derived vegeta- tion metrics processed by the FUSION software available to us included many strongly correlated, difficult to inter- pret covariates. We chose two metrics representing canopy and understory cover due to their ease of interpretation and ecological relevance. Canopy cover was defined as the proportion of LiDAR returns > 2 m above ground; above a height which might impede wolf travel but low enough to account for nearly all existing forest canopy. Forest canopy is associated with light penetration, density of trees, and snow interception, measures that plausibly affect wolves and their Sitka black-tailed deer prey. We defined understory cover as the proportion of LiDAR returns in the range 0.5–1.0 m above ground relative to all points below that stratum. This corresponds roughly to the height distribution of Vaccinium spp. (‘blueberries’) important as food for wolf deer prey and other woody plants—e.g., salal (Gaultheria shallon) and false azalea (Menziesia ferruginea)—that potentially restrict wolf movement (see Dickie et al. 2017). We use the term understory here realizing that other plants conventionally referred to as ‘understory’ (shorter ground-cover plants and taller shrubs) likely fall outside this 0.5–1.0 m height stra- tum. However, similar available measures of LiDAR returns in the 0.0–0.5 and 1.0–2.0 m range were strongly correlated with the 0.5–1.0 m vegetation stratum (r = 0.77 and 0.81, respectively), and so are represented in models to some extent by proxy. We did not know the LiDAR-derived structural attrib- utes of historically logged forests prior to logging, as the LiDAR data were not collected until 2017–2018. Therefore, unharvested commercial forest was defined as that with a mean canopy height equal to the  25th-percentile of timber logged, since LiDAR data were collected in the study area in 2017–2018 (18.6 m). We believe that this threshold bal- ances the fact that historic timber harvest targeted large trees (Albert & Schoen 2013) but that even within stands of trees targeted by logging there existed a wide range of canopy heights previous to logging. We defined an open vegetation class as lands with < 25% canopy coverage, and all remain- ing land—canopy cover ≥ 25% with tree height > 18.6 m (the threshold we used for commercial timber)—as noncommer- cial forest. Open  and  closed  road  classes  were  delineated  using two USFS roads databases (USFS 2019a; , b): (1) a main database including all USFS ‘system’ (permanent) roads (though many of these are in various stages of disrepair and vegetated to some extent), and (2) an ancillary database of decommissioned and non-USFS roads of varying character- istics, although most are closed to vehicle traffic. The system roads are further classed as (1) closed to vehicle traffic, (2) accessible to high-clearance vehicles, or (3) accessible to passenger vehicles. We defined closed roads as the combi- nation of those system roads closed to any vehicles and all non-system roads, and open roads as all roads with at least some vehicle access per the USFS system roads database. The road system on POW is extensive, discontinuous, and partially inaccessible to vehicles, which made ground- truthing site-specific road characteristics (vegetation, level of human use) not feasible for this study. Generally, the closed road class was in some state of revegetation, but this varied depending on site characteristics (Online Resource Appendix  S1,  Fig.  1).  For  instance,  some  closed  roads experience foot traffic from human hunters and fishers, and so, although the road surface is vegetated, a foot trail is maintained, which may facilitate wolf movement and human use. Although an exhaustive characterization of roads was not possible, to understand the existing variability in road revegetation, we photo-interpreted road conditions at random points along open and closed roads (n = 200) and along both classes combined (n = 400), and categorized the surrounding road (100 m in each direction of a random point) into one of four classes: (1) Road paved and with no vegetation on road surface, (2) < 50% of road surface vegetated, (3) > 50% of exposed road surface vegetated with herbs, shrubs, or trees, and, (4) 100% of road surface vegetated with trees (Online Resource Appendix S1, Table 1). We  performed  integrated  step-selection  analysis  (iSSA; Avgar et al. 2016) to study the fine-scale influence of the vegetation and logging-related covariates on wolf habitat selection and movement rate. iSSAs contrast the environ- mental attributes of each animal location with a set of ran- dom locations drawn from the overall distribution of steps the animal took (Avgar et al. 2016), and availability is thus constrained to a localized area near the starting position of each step. We drew available points generated from the gamma distribution of step lengths of each wolf in each sea- son. The distribution of turn angles of wolves did not show any deviation from random, and so was not used to con- strain the location of available points as often done in iSSAs (Fieberg et al. 2021). We estimated coefficients of habitat selection via the main effects of environmental covariates, and movement via interactions of ln(step length) and the environmental covariates (Avgar et al. 2016). We generated 10 available points from a gamma distribution based on the step lengths each wolf took in an individual season using the amt package (Signer et al. 2019) and attributed these and the used locations with environmental (GIS) covariate data. We then built iSSA models using Cox proportional hazards models with the fit_issa function in amt, a wrapper for the clogit (R package survival) function. We used the covariate value at the end point of each step to describe wolf habitat selection and at the start point of each step to interact with step length to describe wolf movement (Avgar et al. 2016). We used R package targets to create a reproducible modeling workflow. We included specific covariates in each of the 5 mod- els built to ask different questions (Table 2). One excep- tion to this conceptually was ln(distance to road), which we included in all models, as we thought it may influence both habitat selection and movement, but was not strongly related to other covariates. We chose to use the coefficients for  ln(distance  to  road)  and  its  interaction  with  ln(step length) from Model 5 to calculate predictions of movement rate, although the sign and magnitude of the coefficient for ln(distance to road) and the ln(step length):ln(distance to road) interaction did not vary greatly between models. We  modeled  wolf  step  selection  across  the  year,  but also built seasonal models corresponding to environmental and wolf life-history transitions (Roffler et al. 2018): late winter (1 Jan–14 Apr), denning season (15 Apr–31 Jul), late summer (1 Aug–14 Oct), and fall (15 Oct–31 Dec). There were  several  preliminary  analytical  steps  we  performed (Online Resource Appendix S2) that resulted in our final model specifications. We built simple, plausible base models to which covariates of interest were added. Specifically, we included a core group of covariates—ln(step length), ln(distance to road), elevation, and slope—in all models (Table  2).  In  models  built  to  assess  the  effects  of  the categorical landcover classes or continuous LiDAR-derived covariates on wolf habitat selection, we did not include the two types together in the same model, as they were often strongly correlated (r > 0.7). To estimate the effect size of model coefficients, we cal- culated wolf relative strength of selection (RSS) and move- ment rate predictions across the typical range of covariate values experienced by wolves. We made predictions of log- RSS (Avgar et al. 2017) to assess the relative likelihood of wolf habitat selection across a range of values of covariates of interest as the ratio x2/x1, where x1 and x2 are calculated from model coefficients β across a range of target covari- ate values x and holding all other covariate values at their mean (zero for scaled covariates), where x2 = β1x1 + β2x2 + … βnxn (Avgar et al. 2017). The denominator x1 was similarly calculated but with all covariates set to their mean, includ- ing the target covariate. We predicted log-RSS across the range of values each covariate of interest took in the wolf location data except for distance to road, as distances from roads > 5 km were rare, and we did not have an ecological rationale for an effect beyond this distance. Movement rate predictions were calculated by multiplying the shape and modified scale parameters of the gamma distribution used to generate the available step lengths (Avgar et al. 2016; Prokopenko et al. 2017). We  used  the  two-stage  (sensu  Fieberg  et  al.  2021) approach of constructing models for each individual wolf and  calculating  population-level  coefficients  using  the inverse-weighted means of the coefficients from each indi- vidual wolf model (Murtaugh 2007). While these popula- tion-level coefficients are useful in summary, they obscure individual variability in habitat selection and movement. Hence, we also reported the proportion of individuals shar- ing direction (sign) of selection with the population-level coefficient, as well as the proportion of individuals for which coefficients excluded zero. To investigate the biological basis for individual differences in response, we classed individuals according to their life history attributes: (1) sex, (2) breeding status (breeding versus nonbreeding), and (3) residency— member of pack (resident) versus disperser (nonresident). Individual wolves switched breeding and residency classes during the study, and so we summarized year-round and sea- sonal results using the majority of time an individual spent in one of the two classes, although this led to some classes not being represented in some seasons. When > 1 individual was present in each class in a season, we tested for statisti- cal differences in class response to environmental covari- ates with univariate linear models run iteratively with the selection coefficient for each step-selection model covariate as the response and class membership as the independent variable (1 = male, 0 = female; 1 = breeding, 0 = nonbreed- ing; 1 = resident, 0 = nonresident). We also plotted RSS for wolves belonging to each life history class across the typical range of covariate values experienced by wolves. We  analyzed  data  from  13  wolves,  for  which  the  mean number  of  year-round  GPS  locations  was  1024  (range: 355–2279). Within seasons, the mean number of analyzed wolf locations was 292 (range: 250–355). Some wolves did not have locations for all seasons; therefore, the number of wolves included in each season was as follows: late winter, n = 10; denning season, n = 12; late summer, n = 12; and fall, n = 12. We classified wolves by breeding status, determined from field data and observations, and by resident status (i.e., resident wolves are members of a pack with a well-defined home range, and nonresident wolves are dispersers, or extra- territorial wolves, as defined in Roffler et al. 2018) and sum- marized the data in Online Resource Table S3. Wolf habitat selection Wolf population-level response to young (≤ 30 years) logged stands was mixed across individuals (population-level confi- dence interval included 0; β = 0.050, 95% CI −0.029, 0.130; Fig. 2a, Table 3) except in fall (β = 0.117, 95% CI 0.007, 0.197; Table 3). Individual wolf coefficients for selection of young logged stands tended to be positive across the entire year (77% of individuals) and in each season (58–83% sea- sonally; Table 4), with the greatest percentage of individual wolves selecting young logged stands occurring in the fall. Wolf population-level response to old (> 30 years) stands was mixed across individuals (population-level CI included 0; β = −0.057, 95% CI −0.201, 0.071; Table 3) over the entire year (Fig. 2b), reflecting variability in individual wolf response (Fig. 2b, Table 4). Seasonally, the maximum per- centage of individuals with a positive selection coefficient for old logged stands (70%; Table 4) occurred in late winter. Wolf response to the LiDAR-derived vegetative cover metrics  was  stronger  than  in  relation  to  the  categorical logged-stand covariates. Wolves consistently avoided can- opy cover over the entire year (β = −0.450, 95% CI −0.534, −0.269;  Table  3,  Fig.  2c)  and  in  each  season  (Online Resource Appendix S3, Fig. 1c) at the population level, and all individual wolves avoided canopy cover over the entire year (Table 4). In addition, in no season did more than one individual wolf display positive selection for canopy cover (Table 4). Wolves also avoided understory cover over the entire year at the population (β = −0.086, 95% CI −0.174, −0.025; Fig. 2d) and individual level (85% of individuals; Table  4).  Wolves  tended  to  avoid  understory  seasonally at the population level, although confidence intervals for each season included 0 (Table 3). Individual wolves tended (50–80%) to avoid understory seasonally, with the maximum percentage occurring in late summer (Table 4). Wolves also avoided canopy cover within logged stands over the entire year at the population level (Fig. 3a, b), as indicated by the interaction coefficients between canopy and logged stands. Contrary to their general response to understory (irrespec- tive of location), wolves selected understory cover within logged stands (Fig. 3c, d). Roads displayed wide variability in their individual char- acteristics (Online Resource Appendix S1, Fig. 1, Table 1), the potential cause of wide variability in wolf individual wolf response to roads. Over the entire year, wolf individual response to roads was mixed (population-level β = 0.043, 95% CI −0.061, 0.211; Fig. 4), although wolves avoided roads  in  late  summer  at  the  population  level  (Table  3, Online Resource Appendix S3, Fig. 2) and across every individual (Table 4). Wolves selected areas of less slope and lower elevation across the entire year at the population level (Table 3). Wolves also selected areas of less slope and lower elevation in each season over the entire year at the population level, although elevation coefficient confidence intervals only excluded 0 in fall (Table 3). Wolves avoided unharvested commercial forest over the entire year and sea- sonally (although late-winter and late-summer coefficient confidence intervals included 0; Table 3) and selected unfor- ested areas over the entire year and seasonally (although the denning season coefficient confidence interval included 0). Life history status (sex, breeding status, or residency) did not affect selection patterns of wolves. In linear models of step-selection model coefficients versus wolf status, no sig- nificant (p ≤ 0.05) differences were observed in wolf habitat selection between classes in any season (Online Resource Appendix S4, Fig. 1a–c), despite 36 total linear models—4 covariates X 3 life history classes X 4 seasons (but excluding combinations for which < 2 individuals were represented in a class)—used to detect differences (1–2 comparisons would be expected to yield p-values ≤ 0.05 by random chance). However, the lowest two p-values (p = 0.07) indicated a potential tendency for males to avoid young logged stands and understory relative to females in late winter. Wolf movement rate Wolf movement rate was not influenced by young logged stands over the entire year at the population level (Fig. 5a) but slowed in old logged stands (Fig. 5b). In each individual season, the confidence intervals for ln(step length) interac- tions with young and old logged stands included 0 (Table 3; Online Resource Appendix S3, Fig. 3a, b), indicating no significant effect on movement rate. There was a tendency for wolves to move more slowly in old logged stands in each season, as the ln(step length):old logged stand interac- tion coefficient was consistently negative across seasons at the population level (but with confidence interval includ- ing 0; Table 3). In addition, 85% of individuals tended to move more slowly in old logged stands over the entire year (Table 4). Seasonally, the percentage of individuals display- ing a tendency for slower movement in old logged stands was at its maximum in late summer (80%). Canopy cover tended to slow wolf movement rates at the population level over the entire year (Fig. 5c) and in each  season  (Online  Resource  Appendix  S3,  Fig.  3c), although seasonal confidence intervals included 0. Indi- vidual wolves corroborated this tendency for slower move- ment in old logged stands; 75% of individuals over the entire year, and 67–80% seasonally, displayed negative coefficients for ln(step length):old logged stand interac- tions. Compared to canopy cover, understory slowed wolf movement to a greater extent at the population level over the  entire  year  (Fig.  5d),  seasonally  (Online  Resource Appendix S3, Fig. 3d), and across individuals (Table 4). Contrary to our expectations, we did not observe an effect of roads on wolf movement rate at the population level (β = −0.008, 95% CI −0.033, 0.012) over the entire year (Fig. 6), although 69% of individuals moved faster near roads (Table 4). Wolves did, however, move faster near roads in the denning season at the population level (β = −0.025, 95% CI −0.060, -0.014), and in the denning season, all but one wolf moved faster near roads (Table 4). As with wolf selection patterns, we saw no significant effect of different wolf life history classes (sex, breeding status, or residency) on seasonal wolf movement rate. In linear models of step-selection model coefficients versus wolf  status,  no  significant  (p ≤ 0.05)  differences  were observed  in  wolf  movement  rate  relative  to  covariates between classes in any season (Online Resource Appen- dix S4, Fig. 2a–c). We found that wolves respond to continuous vegetative cover (measured by LiDAR) that captures fine-scale vari- ability not reflected in ‘all-or-nothing’ categorical repre- sentations of logged stands. Contrary to our predictions, wolves did not select young (≤ 30 years) logged stands, nor avoid old (> 30 years) stands. Unexpectedly, wolves did not move faster through young logged stands, and their movement was slowed by old logged stands. In contrast, in accordance with our predictions, wolves selected and moved faster through areas of less canopy and understory cover (although the effect of canopy on movement rate was not significant). Modeling animal selection of one discrete landcover class over another is appealing in its simplicity, but the continuous covariates used for vegetative cover in this study captured gradients in vegetation lost in homoge- neous logged stand classes (see Boyce et al. 2017). The wolves we studied selected and moved through areas of less vegetative cover that potentially promote efficient hunting by wolves (Dickie et al. 2017; Finnegan et al. 2018). The ability of wolves to visually detect prey (Kauffman et al. 2007; Boucher et al. 2022), and to move efficiently (Dickie et al. 2017, 2020) can be reduced in heavy vegeta- tion, potentially leading to decreased prey encounter rates. At the same time, wolves may perceive greater risk due to the presence of human deer hunters and wolf trappers vis- ible in open terrain lacking cover (Person and Russell 2008) such as results from logging. In addition, in some cases, young seral forests resulting from logging are preferred by ungulate species preyed on by wolves (Boucher et al. 2022), and wolves with greater coverage of recently logged stands in their home range have a greater proportion of deer in their diet (Roffler et al. 2023). These factors that potentially affect wolf fitness may exert opposing forces on wolf habitat selec- tion and could result in individual wolves’ mixed selection toward logged stands in this study. While we did not find strong direct evidence for the influence of timber harvest on wolves, the vegetative cover metrics correlated with wolf habitat selection and movement are strongly affected by log- ging (Gregovich et al. 2024) and undergo a trajectory of reestablishment post-logging. Generally, forest canopy cover removed by logging increases in the period 0–30 year post- logging and then plateaus at percentages greater than that of the original old-growth forest for > 150 years (Alaback 1984). Understory that initially increases 0–30 year post logging is suppressed concurrent with the establishment of dense conifer canopy. Despite these general trajectories, there is likely fine-scale variability in post-logging vegeta- tion that is dependent on site-specific conditions (Banner and LePage 2008) and influences wolf habitat selection and movement. Although wolves generally avoided understory cover, they selected understory when in logged areas; the underlying mechanism for this is not clear from our analysis. A peak in understory cover is observed in the study area 10 years after logging which is a time when canopy cover is sparse. We suspect wolves are attracted to these recently logged areas with relatively open canopy that potentially provide forage for their Sitka black-tailed deer prey (see Boucher et al. 2022). By around 30 years after logging understory decreases and canopy increases, and so this situation favored by wolves post-logging appears short-lived. Sitka black-tailed deer are wolves’ main prey in our study area (Roffler et al. 2023), and vegetation patterns influence the risk of wolf predation to which deer are exposed in the region of this study (Farmer et al. 2006). Farmer et al. (2006) identify areas of open vegetation as high-risk for deer and highlight the importance of thick understory as cover from wolf predation. While vegetative cover undergoes rapid changes after logging occurs, natural areas not targeted by logging (e.g., wet bogs, forested wetlands, alpine meadows) are relatively stable in their characteristics through time. Such areas of little vegetative cover are selected by wolves, promote their movement, and are associated with increased mortality risk for deer (Farmer et al. 2006). In addition, Farmer et al. (2006) found deer more exposed to wolf preda- tion in flat areas that wolves strongly selected in the current study. The configuration of natural features and vegetation outside the matrix of logged stands represents a temporally stable yet spatially variable landscape of risk for deer that is largely unaffected by land management. The  use  of  LiDAR  to  measure  and  map  landscape vegetation patterns to describe wildlife-habitat relationships is becoming more common (Shanley et al. 2021; Sergeyev et al. 2024), and in this study, LiDAR-derived, continuous measures  of  vegetation  better  explained  wolf  selection behavior  than  categorical  land  classes.  iSSAs  contrast environmental covariates within clusters consisting of a single used location and multiple (here, 10) random points. Continuous covariate values are likely to vary at the fine scale  of  these  data  clusters,  but  land  classes  may  not, depending on their spatial distribution (see Boyce et al. 2017). Wolves are likely responding to fine-scale variability in three-dimensional vegetative structure as captured by LiDAR (Davies and Asner 2014) but lost in monolithic, categorical representation. A limitation of the current study is that the canopy and understory measures we used have not been validated on- the-ground. We recommend collection of vegetation plot data to validate LiDAR-derived cover measures to on-the- ground measurements of vegetative characteristics in any future studies. In addition, the aerial collection of LiDAR measurements took place in 2017–2018, at the tail end of wolf GPS location collection, and 5 years after the first wolf GPS locations were obtained in 2012. The maximum mismatch between vegetation as it existed at the beginning of the study and when LiDAR was collected likely occurs in recently logged stands, as the greatest rate of change in canopy cover and understory occurs within 0–10 years (see Gregovich et al. 2024) after logging. Logged areas this recent are not prevalent in the study area, and so our results may not be greatly affected. Outside of logged areas, natu- ral catastrophes (e.g., fire, large-scale windthrow) affecting vegetation are rare in the study area, and climax vegetation communities likely did not change appreciably during the 6 years of the study. Overall, the population of wolves in this study did not behaviorally respond to roads, counter to our predictions. We expected roads would be associated with increased wolf movement (Zimmerman et al. 2014; Dickie et al. 2020), avoidance of risky areas (Gurarie et al. 2011), or selection as movement corridors (Boucher et al. 2022). In this study, we did not detect a difference in wolf response to roads open and closed (as classified via a USFS GIS database) to vehi- cle traffic. Roads (including within these two classes) vary widely in characteristics influential to wolves, and this may have led to the mixed response we observed. Roads in the study area exist in various combinations of human accessi- bility and revegetation, likely affecting wolf behavior in ways that are ambiguous and site dependent. For instance, roughly 1/3 of roads in the study area are fully revegetated with trees, which likely impedes both human and wolf use, while we estimated 4% of roads are paved and receive high-speed pas- senger use, and thus may be risky and avoided by wolves. The remainder of roads are gravel and in varying stages of revegetation, and hence vary widely in use by humans and potential effect on wolf behavior. However, while we did not observe significant overall effects of roads on wolf habitat selection there was some evidence for selection of roads as movement corridors. Wolves selected areas near roads dur- ing late summer at the population level, and in each season there were individuals that selected areas closer to roads. It is possible that snow deposition on roads in winter impedes wolf movement rate, though some individual wolves moved faster near roads year-round. Roads in the study area might benefit from a thorough description (perhaps via LiDAR, see Waga et al. 2020) and accurate classification based on characteristics relevant to wolf behavior. In future studies, a shorter GPS fix interval than the 6-h rate used here may also reveal patterns of road use not evi- dent in the current study. Greater spatio-temporal resolu- tion of wolf locations could allow identification of wolf behavioral states (e.g., encamped, traveling; Zimmerman et al. 2014), that are difficult to obtain from data collected at this coarse, 6-h time interval (see Creel et al. 2013; Cristecu et al. 2015). Discerning behavioral states may help reveal road influence not evident in this study. For instance, the effect of roads on wolf movement rate may be confounded if wolves move faster on or near roads while hunting, but also stop to kill and consume prey there. Finally, a shorter GPS fix interval would more generally elucidate wolf habitat selection and movement behavior at a finer spatial scale; the combination of 6-h GPS fixes and the high mobility of wolves in this study resulted in a spatial scale of analysis on the larger end of that considered in most step selection analyses. Wolves have long been recognized for their behavioral plasticity, which has facilitated adaptation to a variety of habitats worldwide (Boyd et al. 2023), differences in prey availability (Newsome et al. 2016), and varying effects of anthropogenic  disturbance  (Ferreiro-Arias  et  al. 2024). Although individual differences in behavior have been attrib- uted to breeding status (Gable et al. 2023), sex (Eriksson et al. 2024), and resident status (Thompson et al. 2024), we did not find clear patterns in our study system. Wolf response to logging-related disturbance and vegetation pat- terns varied across individuals in this study, but we likely did not have enough data from different population seg- ments (e.g., packs, sexes, residents versus non-residents) to determine a basis for this variability in individual wolf response. Individual variation in behavior may be the result of differences in personality (Bump et al. 2022), defined as consistent differences in individual behaviors across time, space, and ecological contexts (Young et al. 2015), which may be influenced by the individual’s experiences early in life, or due to neuroendocrine activities (Packard 2003). In addition, individual personality may be altered by individual diet specialization (Toscano et al. 2016) as specific behav- iors including boldness and innovation may be associated with foraging strategies (Parsons et al. 2022). In this study, individual wolves displayed a range of responses in differ- ent forest habitats exemplified by the percentage of wolves sharing behavior (avoidance or selection) toward covariates, which ranged from ~ 50% (expected by random chance) in relation to old logged stands to 100% avoidance of canopy cover. This suggests lack of a one-size-fits-all view of wolf habitat selection, and the potential that management actions may not affect all individuals in the same way. Logging has resulted in a mosaic of natural habitat and second-growth  forest  in  various  stages  of  succession  in coastal temperate rainforests (Albert and Schoen 2013). While natural vegetation patterns in areas not targeted for timber harvest are relatively stable through time, succession of  previously  logged  forests,  future  timber  harvest,  and second-growth remediation (e.g., precommercial thinning) will  influence  forest  vegetative  cover  and,  in  turn,  wolf habitat selection and movement rate. Wolves in this study generally  selected  and  moved  faster  through  areas  of less  canopy  and  understory  cover  present  in  unforested wetlands,  alpine  areas,  and  recently  logged  forests,  the latter of which is a short-lived successional stage giving way (~ 30 year post-logging) to heavier vegetative cover wolves avoid. Forest precommercial thinning can decrease canopy cover but increase understory (Crotteau et al. 2020), with potentially opposing effects on wolf habitat selection. It is not clear how long these changes last after thinning occurs (Cole et al. 2010). Forest management activities may initially benefit wolves by providing open habitat they select, but this successional stage is short-lived, and as these stands transition to closed-canopy stages avoided by wolves, there may be negative consequences for wolf populations.",
         "https://link.springer.com/content/pdf/10.1007/s00442-025-05677-5.pdf",
         "extracted",
         "None",
         "",
         "Vegetation influences wolf fine-scale habitat selection and movement rate in a logged coastal rainforest"
        ],
        [
         "39",
         "01aec6fc8b33f731d3fdb3f878f36e6ba44f9975",
         "Single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) data analysis are pivotal for advancing biological research, enabling precise characterization of cellular heterogeneity. However, existing analysis approaches require extensive manual programming and tool manipulation, posing significant challenges for researchers. To address this, we introduce CellAgent, an autonomous, LLM-driven approach that performs end-to-end scRNA-seq and spatial transcriptomics data analysis through natural language interactions. CellAgent employs a multi-agent hierarchical decision-making framework, simulating a “deep-thinking” workflow to ensure that each analytical step remains consistent with the overall task objective. To further enhance its capabilities, we developed sc-Omni, a high-performance, expert-curated toolkit that consolidates essential tools for scRNA-seq and spatial transcriptomics analysis. Additionally, we introduce a self-reflective optimization mechanism, enabling automated, iterative refinement of results through specialized evaluation methods, effectively replacing traditional manual assessments. Benchmarking against human experts demonstrates that CellAgent achieves approximately 60% improvement in efficiency across multiple downstream applications. In terms of accuracy, it maintains performance comparable to existing approaches while preserving natural language interactions. By translating natural language interactions into optimized analytical workflows, CellAgent establishes a scalable paradigm for LLM-driven scientific discovery, bridging the gap between experimental biologists and complex data analytics. This framework minimizes reliance on manual coding and exhaustive deliberation, ushering in the era of the “AI Agent for Science.”",
         "Yihang Xiao,Jinyi Liu,Yan Zheng,Shaoqing Jiao,Jianye Hao,Xiaohan Xie,Mingzhi Li,Ruitao Wang,Fei Ni,Yuxiao Li,Zhen Wang,Xuequn Shang,Zhijie Bao,Changxiao Yang,Jiajie Peng",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/05/15/2024.05.13.593861.full.pdf",
         "None",
         "None",
         "",
         "CellAgent: LLM-Driven Multi-Agent Framework for Natural Language-Based Single-Cell Analysis"
        ],
        [
         "40",
         "01c145dd6f03ad1e93829d3f9f477ac9166ef6ab",
         "None",
         "Jyotirmoy Basak,Kaushik Chakraborty",
         "None",
         "None",
         "https://www.aimsciences.org/data/article/export-pdf?id=65f29c2dc26d215a60510a56",
         "None",
         "None",
         "Device-independent oblivious transfer from the bounded-quantum-storage-model and computational assumptions;A device-independent protocol for XOR oblivious transfer;Self-testing nonprojective quantum measurements in prepare-and-measure experiments;Clauser–Horne–Shimony–Holt versus three-party pseudo-telepathy: on the optimal number of samples in device-independent quantum private query;Device-independent two-party cryptography secure against sequential attacks;Device-independent bit commitment based on the CHSH inequality;Quantum cryptography: Public key distribution and coin tossing;Flexible protocol for quantum private query based on B92 protocol;Protecting data privacy in private information retrieval schemes;How to differentiate between non-orthogonal states;Probability Inequalities for Sums of Bounded Random Variables",
         "Fully device independent quantum private query"
        ],
        [
         "41",
         "01c65b584d35362abc5f2425273ec2eefc579594",
         "Autophagy plays a key role in the responses to different stress condition in plants. Reactive oxygen species (ROS) are common modulators of stress responses, having both toxic and signaling functions. In this context, the relationship between ROS and autophagy regulation remains unclear, and in some aspects, contradictory. In this study, we employed pharmacological and genetic approaches to investigate the effects of different ROS on the cytoplastic redox state and autophagic flux in Arabidopsis thaliana. Ours results demonstrated that oxidative treatments with H2O2 and MV, which drastically increased the oxidized state of the cytoplasm, reduced the autophagic flux. Conversely, singlet oxygen, which did not have significant effects on the cytoplasmic redox state, increased the autophagic flux. Additionally, our findings indicated that after H2O2 and high light treatments and during the recovery period, the cytoplasm returned to its reduced state, while autophagy was markedly induced. In summary, our study unveils the differential effects of ROS on the autophagic flux, establishing a correlation with the redox state of the cytoplasm. Moreover, it emphasizes the dynamic nature of autophagy in response to oxidative stress and the subsequent recovery period. HIGHLIGHTS This research shows the differential effects of reactive oxygen species on autophagic modulation, highlighting their impact on the cytoplasmic redox state. The relationship between ROS and autophagy regulation remains unclear, and in some aspect’s contradictory. Here, we present a comprehensive investigation characterizing the effects of different ROS, such as hydrogen peroxide and singlet oxygen, on the modulation of autophagy in Arabidopsis. In brief, our findings reveal differential impacts on cytoplasmic redox states and autophagic flux, providing insight into the dynamic nature of autophagy, especially in stress and post-stress conditions. To the best of our knowledge, our work is the first to evaluate autophagic flux both during and after oxidative stress in plants. Our results indicate that this differentiation is crucial when analyzing the effects of oxidative stress on autophagy.",
         "Germán Robert,Alejandro Enet,Laura Saavedra,R. Lascano",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2023/08/19/2023.08.11.552961.full.pdf",
         "None",
         "None",
         "Contrasting cytosolic glutathione redox dynamics under abiotic and biotic stress in barley as revealed by the biosensor Grx1-roGFP2.;New Insights into Plant Autophagy: Molecular Mechanisms and Roles in Development and Stress Responses.;Redox-mediated activation of ATG3 promotes ATG8 lipidation and autophagy progression in Chlamydomonas reinhardtii;Transcriptional and post-translational regulation of plant autophagy;Pexophagy suppresses ROS-induced damage in leaf cells under high-intensity light;ROS and redox regulation of cell-to-cell and systemic signaling in plants during stress.;ROS production and signalling in chloroplasts: cornerstones and evolving concepts;Understanding paraquat resistance mechanisms in Arabidopsis thaliana to facilitate the development of paraquat-resistant crops;Plant Autophagy: An Intricate Process Controlled by Various Signaling Pathways;The core autophagy machinery is not required for chloroplast singlet oxygen-mediated cell death in the Arabidopsis thaliana plastid ferrochelatase two mutant;Superoxide radical scavenging by sodium 4,5-dihydroxybenzene-1,3-disulfonate dissolved in water: Experimental and quantum chemical studies;Autophagy Contributes to the Quality Control of Leaf Mitochondria;Ammonium stress increases micro-autophagic activity while impairing macro-autophagic flux in Arabidopsis roots.;Singlet Oxygen in Plants: Generation, Detection, and Signaling Roles;Autophagy in plants: Physiological roles and post-translational regulation.;Autophagy: An Intracellular Degradation Pathway Regulating Plant Survival and Stress Response;Rapid systemic signaling during abiotic and biotic stresses: Is the ROS wave master of all trades?;The protease activity of human ATG4B is regulated by reversible oxidative modification;Chloroplast stress signals: regulation of cellular degradation and chloroplast turnover.;Linking Autophagy to Abiotic and Biotic Stress Responses.;Multiple Regulatory Levels Shape Autophagy Activity in Plants;Redox Systemic Signaling and Induced Tolerance Responses During Soybean–Bradyrhizobium japonicum Interaction: Involvement of Nod Factor Receptor and Autoregulation of Nodulation;The fluorescent protein sensor roGFP2-Orp1 monitors in vivo H2 O2 and thiol redox integration and elucidates intracellular H2 O2 dynamics during elicitor-induced oxidative burst in Arabidopsis.;Selective Elimination of Membrane-Damaged Chloroplasts via Microautophagy1[OPEN];Phosphatidylinositol 3-kinase function at very early symbiont perception: a local nodulation control under stress conditions?;Oxidation of Atg3 and Atg7 mediates inhibition of autophagy;Reactive oxygen species, abiotic stress and stress combination.;Entire Photodamaged Chloroplasts Are Transported to the Central Vacuole by Autophagy[OPEN];Control of Autophagy in Chlamydomonas Is Mediated through Redox-Dependent Inactivation of the ATG4 Protease1;The ROS Wheel: Refining ROS Transcriptional Footprints1[OPEN];Dissecting Redox Biology Using Fluorescent Protein Sensors.;Learning the Languages of the Chloroplast: Retrograde Signaling and Beyond.;Endocytic and autophagic pathways crosstalk in plants.;How to control self-digestion: transcriptional, post-transcriptional, and post-translational regulation of autophagy.;Functional characterization of the two ferrochelatases in Arabidopsis thaliana.;The yeast autophagy protease Atg4 is regulated by thioredoxin;Expression of Animal Anti-Apoptotic Gene Ced-9 Enhances Tolerance during Glycine max L.–Bradyrhizobium japonicum Interaction under Saline Stress but Reduces Nodule Formation;Autophagy deficiency leads to accumulation of ubiquitinated proteins, ER stress, and cell death in Arabidopsis;Stitching together the Multiple Dimensions of Autophagy Using Metabolomics and Transcriptomics Reveals Impacts on Metabolism, Development, and Plant Responses to the Environment in Arabidopsis[C][W];ROS as key players in plant stress signalling.;Development of roGFP2-derived redox probes for measurement of the glutathione redox potential in the cytosol of severely glutathione-deficient rml1 seedlings;Highly Oxidized Peroxisomes Are Selectively Degraded via Autophagy in Arabidopsis[C][W];A Mediator of Singlet Oxygen Responses in Chlamydomonas reinhardtii and Arabidopsis Identified by a Luciferase-Based Genetic Screen in Algal Cells[W];1O2-mediated and EXECUTER-dependent retrograde plastid-to-nucleus signaling in norflurazon-treated seedlings of Arabidopsis thaliana.;NBR1-Mediated Selective Autophagy Targets Insoluble Ubiquitinated Protein Aggregates in Plant Stress Responses;Antioxidant properties of benzoic acid derivatives against superoxide radical;Reactive Oxygen Species and Autophagy in Plants and Algae1;Carotenoid deficiency triggers autophagy in the model green alga Chlamydomonas reinhardtii;High-Resolution Temporal Profiling of Transcripts during Arabidopsis Leaf Senescence Reveals a Distinct Chronology of Processes and Regulation[C][W][OA];Ascorbate and Glutathione: The Heart of the Redox Hub1;Members of the LBD Family of Transcription Factors Repress Anthocyanin Synthesis and Affect Additional Nitrogen Responses in Arabidopsis[W][OA];Autophagy is required for tolerance of drought and salt stress in plants;Apoplastic superoxide level in wheat protoplast under photooxidative stress is regulated by chloroplast redox signals: Effects on the antioxidant system;Autophagy Negatively Regulates Cell Death by Controlling NPR1-Dependent Salicylic Acid Signaling during Senescence and the Innate Immune Response in Arabidopsis[W][OA];Monitoring the in vivo redox state of plant mitochondria: effect of respiratory inhibitors, abiotic stress and assessment of recovery from oxidative challenge.;Redox regulation in photosynthetic organisms: signaling, acclimation, and practical implications.;Confocal imaging of glutathione redox potential in living plant cells;Singlet Oxygen Is the Major Reactive Oxygen Species Involved in Photooxidative Damage to Plants1[W];Impact of chloroplastic- and extracellular-sourced ROS on high light-responsive gene expression in Arabidopsis.;Generation of superoxide anion in chloroplasts of Arabidopsis thaliana during active photosynthesis: a focus on rapidly induced genes;A reporter system for the individual detection of hydrogen peroxide and singlet oxygen: its use for the assay of reactive oxygen species produced in vivo.;Disruption of Autophagy Results in Constitutive Oxidative Stress in Arabidopsis;Cross-talk between singlet oxygen- and hydrogen peroxide-dependent signaling of stress responses in Arabidopsis thaliana;Degradation of Oxidized Proteins by Autophagy during Oxidative Stress in Arabidopsis1[W][OA];Reactive Oxygen Species in Plant Cell Death1;Imaging the production of singlet oxygen in vivo using a new fluorescent sensor, Singlet Oxygen Sensor Green.;Autophagy in Development and Stress Responses of Plants;Determination of hydrogen peroxide scavenging activity of cinnamic and benzoic acids employing a highly sensitive peroxyoxalate chemiluminescence-based assay: structure-activity relationships.;Processing of ATG8s, Ubiquitin-Like Proteins, and Their Deconjugation by ATG4s Are Essential for Plant Autophagy;Reactive oxygen species: metabolism, oxidative stress, and signal transduction.;Rapid Induction of Distinct Stress Responses after the Release of Singlet Oxygen in Arabidopsis Online version contains Web-only data. Article, publication date, and citation information can be found at www.plantcell.org/cgi/doi/10.1105/tpc.014662.;Expression of senescence-enhanced genes in response to oxidative stress.;Singlet oxygen production in herbicide‐treated photosystem II;The APG8/12-activating Enzyme APG7 Is Required for Proper Nutrient Recycling and Senescence in Arabidopsis thaliana *;Leaf Senescence and Starvation-Induced Chlorosis Are Accelerated by the Disruption of an Arabidopsis Autophagy Gene1;A multiple-comparisons method based on the distribution of the root node distance of a binary tree;Analysis of relative gene expression data using real-time quantitative PCR and the 2(-Delta Delta C(T)) Method.;FLU: A negative regulator of chlorophyll biosynthesis in Arabidopsis thaliana;The role of active oxygen species in plant signal transduction;Antagonistic Effects of Hydrogen Peroxide and Glutathione on Acclimation to Excess Excitation Energy in Arabidopsis;Systemic signaling and acclimation in response to excess excitation energy in Arabidopsis.;Bipyridylium quaternary salts and related compounds. V. Pulse radiolysis studies of the reaction of paraquat radical with oxygen. Implications for the mode of action of bipyridyl herbicides.;Photoperoxidation in isolated chloroplasts. I. Kinetics and stoichiometry of fatty acid peroxidation.;Spectrophotometric characteristics of chlorophylls a and b and their phenophytins in ethanol;Studies on reactions of illuminated chloroplasts. II. Stimulation and inhibition of the reaction with molecular oxygen.;The assimilation and degradation of carbohydrates by yeast cells.;Hypothesis: Increase of the ratio singlet oxygen plus superoxide radical to hydrogen peroxide changes stress defense response to programmed leaf death;Plant senescence: a self-induced process.;Superoxide dismutase and glutathione reductase overexpression in wheat protoplast: photooxidative stress tolerance and changes in cellular redox state",
         "Redox regulation of autophagy in Arabidopsis: differential effects of reactive oxygen species"
        ],
        [
         "42",
         "01e2c0cb2a8adced75528452c58dc12ae704f755",
         "None",
         "Kevin Lopez,Amin Rezaei",
         "\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nKevin Lopez\nComputer Engineering & Computer Science Department\nCalifornia State University, Long Beach\nKevin.LopezChavez01@student.csulb.edu\n**BLOCK**fs== 10.0**p== 0.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nAmin Rezaei\nComputer Engineering & Computer Science Department\nCalifornia State University, Long Beach\nAmin.Rezaei@csulb.edu\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\nABSTRACT\nLogic locking has emerged to prevent piracy and overproduction\nof integrated circuits ever since the split of the design house and\nmanufacturing foundry was established. While there has been a lot\nof research using a single global key to lock the circuit, even the\nmost sophisticated single-key locking methods have been shown to\nbe vulnerable to powerful SAT-based oracle-guided attacks that can\nextract the correct key with the help of an activated chip bought off\nthe market and the locked netlist leaked from the untrusted foundry.\nTo address this challenge, we propose, implement, and evaluate a\nnovel logic locking method called K-Gate Lock that encodes input\npatterns using multiple keys that are applied to one set of key inputs\nat different operational times. Our comprehensive experimental\nresults confirm that using multiple keys will make the circuit secure\nagainst oracle-guided attacks and increase attacker efforts to an\nexponentially time-consuming brute force search. K-Gate Lock has\nreasonable power and performance overheads, making it a practical\nsolution for real-world hardware intellectual property protection.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.5**l== 0.1**r== 0.6**\nCCS CONCEPTS\n• Security and privacy → Security in hardware.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\nKEYWORDS\nLogic Locking, Logic Encryption, Logic Obfuscation, SAT Attack,\nMulti-Key Locking, Dynamic Locking, Input Encoding\n**BLOCK**fs== 8.0**p== 0.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\nACM Reference Format:\nKevin Lopez and Amin Rezaei . 2025. K-Gate Lock: Multi-Key Logic Locking\nUsing Input Encoding Against Oracle-Guided Attacks. In 30th Asia and\nSouth Pacific Design Automation Conference (ASPDAC ’25), January 20–23,\n2025, Tokyo, Japan. ACM, New York, NY, USA, 7 pages. https://doi.org/10.\n1145/3658617.3697764\n**BLOCK**fs== 9.0**p== 0.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n1 INTRODUCTION\nIn this split of design and manufacturing, one company designs the\ndigital design, while another handles the physical fabrication of the\nIntegrated Circuit (IC). While this separation of tasks poses a threat\nto chip security, logic locking [1, 2] has emerged as a promising\nsolution to prevent piracy and overproduction of hardware Intellec-\ntual Properties (IPs). Formally speaking, logic locking is the process\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nASPDAC ’25, January 20–23, 2025, Tokyo, Japan\n© 2025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0635-6/25/01.\nhttps://doi.org/10.1145/3658617.3697764\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\nof adding additional inputs to an IC, called key bits, to prevent the\ncorrect operation of the IC when the incorrect key is provided to\nthe circuit. Traditionally, locking has been done using only one\nglobal key, which made it susceptible to the SAT-based attack [3]\nthat extracts the key using an oracle (i.e., a working chip bought\noff the market) and a locked netlist leaked from an untrustworthy\nfoundry. While there have been attempts to reduce the success of\nthe SAT-based attack to brute-force [4, 5], sophisticated attacks\nhave been proposed to find out the correct key of these methods.\nWe believe that the vulnerabilities associated with a single static\nkey can be effectively mitigated through multi-key logic locking. In\nthis paper, we introduce an advanced multi-key approach called K-\nGate Lock where the inputs of each gate are encoded with different\nkey values. To activate the circuit correctly, these values must be\nprovided in the specific sequence used during the encoding process.\nIn this paper, we present the following contributions:\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\n• Proposing a robust multi-key logic locking based on input\n**BLOCK**fs== 9.0**p== 0.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nencoding, implemented fully in combinational logic;\n**BLOCK**fs== 9.0**p== 0.0**b== 0.4**t== 0.5**l== 0.6**r== 0.1**\n• Implementing an efficient algorithm to lock a circuit with\nmultiple user-defined keys with tunable time complexity;\n• Generating more than 40 benchmarks based on the proposed\nmethod, measuring the overhead, and evaluating its security\nagainst state-of-the-art oracle-guided attacks.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n2 BACKGROUND AND RELATED WORK\nIn this section, we first consider the evolution of logic locking\ntechniques as well as oracle-guided attacks, and then review the\nexisting efforts in multi-key logic locking.\n**BLOCK**fs== 9.0**p== 0.0**b== 0.1**t== 0.7**l== 0.5**r== 0.1**\n2.1 Logic Locking Techniques\nInitial techniques of logic locking rely on single-key schemes, pri-\nmarily employing xor-based and mux-based mechanisms [1, 2].\nIn xor-based logic locking, the key bits are matched with random\ninverters and buffers. Then, the xor gates controlled by key bits\nare used to replace selected buffers and inverters. Additionally,\nmux-based logic locking selects random wires and substitutes them\nwith 2-1 muxs whose inputs are real signals and random dummy\nones, and selectors are the key bits. However, advancements in SAT\nsolvers have been utilized to expose vulnerabilities in these meth-\nods [3], leading to the development of more robust techniques such\nas Anti-SAT [4], SAR-Lock [5], TT-Lock [6], CAS-lock [7], BLE [8],\nDLE [9], Full-Lock [10], Cross-Lock [11], HLock [12], TraceLL [13],\nTriLock [14], and others [15–27] that increase the time complexity\nof attacks. Obfus-Lock [28] is proposed to leverage the skewness of\nnodes to construct a locked circuit and obfuscate the circuit using\nre-write rules. Furthermore, a theoretical method has been pro-\nposed to achieve both high query complexity and key error rates\n**BLOCK**fs== 9.0**p== 1.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\nbased on quasi-universal circuits, including convolutional biased\ntarget circuits [29]. In addition, recently, a sequential obfuscation\nsolution called STATION [30] has been proposed by leveraging\ndisjoint encoding and combinational logic locking techniques. A\ncomprehensive overhead and security analysis of state-of-the-art\nlogic locking methods is also done in [31]. Despite the mentioned\nefforts, single-key solutions remain susceptible once the key is com-\npromised, endangering the entire security of the hardware IPs.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.3**l== 0.1**r== 0.5**\n2.2 Oracle-Guided Attacks\nBoolean SAT solvers are used to reveal the correct key of logic-\nlocked circuits using an oracle (i.e., an activated IC bought off the\nmarket) and a locked netlist to prune out the wrong key values [32–\n35]. The SAT-based attack [3] uses Distinguishing Input Patterns\n(DIPs) that are specifically designed to exploit the discrepancies be-\ntween the locked circuit and the oracle by targeting and identifying\nincorrect key values. The more incorrect key values the SAT solver\neliminates in one iteration, the faster the attack can find the correct\nkey. Then on, each attack has been strategically designed to target\na specific defense mechanism; for example, Double DIP [36] is used\nfor attacking ICs locked with SAR-Lock [5], where using two DIPs\ninstead of one helps find the correct key faster. AppSAT [37] uses\nan approximate flow to find the probably-approximate-correct key\nin Anti-SAT [4] method. Fa-SAT [38] inserts a single stuck-at fault\nat each signal of the locked circuit iteratively to find the correct\nkey of BLE [8]. The assumption in all the above attacks is that there\nis a single static key in the logic-locked circuit to be deciphered.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.2**t== 0.5**l== 0.1**r== 0.5**\n2.3 Multi-Key Approaches\nRecent works have brought the possibility of multi-key solutions.\nSpecifically, DK-Lock [39] is a sequential locking method where\none must provide two keys to a circuit; the first key is the activa-\ntion key, which must be provided for a constant amount of time\nto activate the circuit, and then a functional key right after. DK-\nLock may be susceptible to unrolling attacks [32] that can expand\nthe key size to reverse the method back to a single-key solution.\nSLED [40] is another multi-key sequential solution but requires\nlatches that operate on a clock, introducing additional complexity\nfor combinational circuits. In addition, it depends on a seed value\n(i.e., a primary key) to operate, which can eventually be reduced to\na single-key model since the attacker only needs to find out the seed\nvalue. Both of the mentioned multi-key logic locking methods may\nstill be reverted back to a single-key model and thus susceptible to\ntraditional SAT-based oracle-guided attacks. In addition, they depend\non sequential components to be implemented.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nAnother multi-key logic locking solution, Gate-Lock [41], uses\nan approach focused on locking gates, resulting in circuits that are\nresilient to SAT attacks. In Gate-Lock, the truth table has a height\nof 2𝑛+𝑘 while our proposed method maintains the same input size\nheight of 2𝑛 and only locks the outcomes within the truth table that\nare true. This allowed us to implement a more efficient algorithm.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n3 MULTI-KEY LOGIC LOCKING\nIn this section, after explaining the terminology, we discuss our\nproposed methods of locking a circuit with multiple keys; the first\none locks the whole circuit, and it needs to generate a truth table for\n**BLOCK**fs== 9.0**p== 1.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nall the input combinations on the circuit, which may not be efficient\nin terms of space and time complexity. The second method, called\nK-Gate Lock, is a derivation but more optimized than the first\none to focus on encoding the input combinations of the gates with\nspecific key values. We also thoroughly discuss the implementation\nof the K-Gate Lock and evaluate the theoretical time complexity\nfor any future oracle-guided attack to find the correct keys. An\nimplementation example of K-Gate Lock on the c17 circuit from\nISCAS 85 benchmarks [42] is shown in Figure 1. You may refer to\nTable 1 which contains the sequence of keys necessary to operate\nthis locked circuit.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\n3.1 Terminology\nIn the context of K-Gate Lock, it is crucial to understand the\nterminology used to describe the various components and concepts:\nn: The total number of inputs to the original circuit.\ng: The maximum number of gates to be locked within a circuit.\nk: The number of inputs to a gate is often called the level of locking.\ngate key: Each gate in a locked circuit has a specific key that\ncontrols its operation based on the input combination.\nkey bit: The individual binary elements that constitute a key.\nm: The total number of bits in a key, aggregated from all key bits\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nassociated with each locked gate.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\nkeys: Our approach uses keys derived from gate key combinations,\n**BLOCK**fs== 9.0**p== 1.0**b== 0.5**t== 0.5**l== 0.6**r== 0.1**\nwith the specific key depending on the input.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.3**t== 0.5**l== 0.5**r== 0.1**\n3.2 Locking the Whole Circuit\nThe brute force method of locking a combinational circuit using\nmultiple keys requires expanding the logic table of all the circuit’s\npossible input/output combinations. Multiple keys can be inserted\ninto each input/output combination when all the inputs and outputs\nare expanded. The truth table will maintain a size of 2𝑛 since it does\nnot create every combination of keys; it only adds the desired keys\nto an input combination. This brute force approach to locking a\nwhole circuit is impractical because it would lead to an exponential-\nsize truth table, and the implementation of locking a circuit would\nbe time-consuming. For example, the C432 circuit in ISCAS 85\nproduces a truth table of 68,719 million rows, which is extremely\nlarge for one of the smallest benchmarks in ISCAS 85 suite. This\nmotivated us to introduce K-Gate Lock.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n3.3 K-Gate Lock Algorithm\nK-Gate Lock operates by locking specific gates within the circuit\nrather than the entire IC. This method utilizes the truth table of a\ngate or a more complex expression (i.e., a deep gate), encoding key\nbits directly into it. To operate the circuit, the user must provide\na combination of inputs along with the corresponding keys in the\ncorrect sequence.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nNow, we discuss the steps for locking a circuit based on the\ncircuit example in Figure 1, which is locked at 𝑘 = 2 with the key\nvalues of 01, 11, 10, and 11.\n**BLOCK**fs== 9.0**p== 1.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n1. Inputs: The algorithm requires an input of the original cir-\ncuit, unique keys, the maximum number of gates to lock (i.e., 𝑔),\nand a chosen level of gate locking (i.e., 𝑘). It is worth noting that\nthe height of the truth table must be greater than the number of\nkeys.\n**BLOCK**fs== 7.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nK-Gate Lock: Multi-Key Logic Locking Using Input Encoding Against Oracle-Guided Attacks\n**BLOCK**fs== 9.0**p== 2.0**b== 0.4**t== 0.5**l== 0.4**r== 0.4**\nFigure 1: K-Gate Lock Example\n**BLOCK**fs== 9.0**p== 2.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n2. Gate Selection: In the second phase of the process, the main\ntask is determining which gates to lock, using the variable 𝑘 as a\nguide. The gates needed to be locked are those that have the number\nof absolute inputs equal to the input value 𝑘. For example, while\nlocking the C17 benchmark shown in Figure 1:\n**BLOCK**fs== 9.0**p== 2.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n• G10 has two absolute inputs (𝑘 = 2), G1 and G3.\n• G11 has two absolute inputs (𝑘 = 2), G3 and G6.\n• G19 contains three absolute inputs (𝑘 = 3), which are G7,\n**BLOCK**fs== 9.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n• G16 contains three absolute inputs (𝑘 = 3), which are G2,\n**BLOCK**fs== 9.0**p== 2.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\nSince the initial constraint is to lock at 𝑘 = 2, only G10 and G11\n**BLOCK**fs== 9.0**p== 2.0**b== 0.2**t== 0.7**l== 0.1**r== 0.8**\nare selected.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n3. Key Insertion: Up to this point, the algorithm has selected\nwhat gates to lock. In this step, the keys are inserted into the gate\nlogic. For the C17 benchmark, as shown in Figure 1, truth tables\nare expanded for the expressions (𝐺1 ∧ 𝐺3) and (𝐺3 ∧ 𝐺6), and\nthe key bits are added as defined in the initial contains.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nFor deeper gates (i.e., 𝑘 > 2), it is necessary to have the absolute\ninput to know when each key should be applied. It is also possible\nto maintain the original connections to the gate by using the inputs\nto the logic gate and adding them to the truth table. After the keys\nare added to the truth table, the expression can be extracted and\nsimplified using any simplification method, like Karnaugh maps.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.4**t== 0.6**l== 0.6**r== 0.1**\nTable 1: Circuit Operation of Figure 1\n**BLOCK**fs== 9.0**p== 2.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n4. Circuit Update: In this step, the algorithm updates the orig-\ninal circuit with the new locked gates. As shown by step 4 of Fig 1,\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nAlgorithm 1 Circuit Locking\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n1: Input: Circuit 𝑓 (𝑥), keys, g (max gates to lock), level 𝑘 (default\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n2: Output: Locked circuit ℎ(𝑥, 𝑘)\n3: 𝑔𝑎𝑡𝑒𝑠_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 ← 𝑔𝑒𝑡_𝑔𝑎𝑡𝑒𝑠_𝑤𝑖𝑡ℎ_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 (𝑓 (𝑥), 𝑘, 𝑔)\n4: ℎ(𝑥, 𝑘) ← 𝑓 (𝑥)\n5: for each gate in 𝑔𝑎𝑡𝑒𝑠_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 do\n6:\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\n𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← 𝑙𝑜𝑐𝑘_𝑔𝑎𝑡𝑒_𝑤𝑖𝑡ℎ_𝑘𝑒𝑦 (𝑔𝑎𝑡𝑒, 𝑘𝑒𝑦𝑠)\nℎ(𝑥, 𝑘).𝑟𝑒𝑝𝑙𝑎𝑐𝑒 (𝑔𝑎𝑡𝑒, 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒)\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\n7:\n8: end for\n9: return ℎ(𝑥, 𝑘)\n**BLOCK**fs== 9.0**p== 3.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\nAlgorithm 2 Gate Locking\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\n1: Function lock_gate_with_key (gate, keys)\n2: Input: 𝑔𝑎𝑡𝑒, 𝑘𝑒𝑦𝑠\n3: Output: 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒\n4: 𝑡𝑎𝑏𝑙𝑒 ← 𝑔𝑒𝑛𝑒𝑟𝑎𝑡𝑒_𝑙𝑜𝑔𝑖𝑐_𝑡𝑎𝑏𝑙𝑒 (𝑔𝑎𝑡𝑒.𝑖𝑛𝑝𝑢𝑡𝑠, 𝑔𝑎𝑡𝑒.𝑜𝑢𝑡𝑝𝑢𝑡)\n5: 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← ()\n6: for each (𝑖𝑛𝑝𝑢𝑡𝑠, 𝑜𝑢𝑡𝑝𝑢𝑡) in 𝑡𝑎𝑏𝑙𝑒 do\n7:\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.4**l== 0.1**r== 0.7**\nfor each 𝑘𝑒𝑦 in 𝑘𝑒𝑦𝑠 do\n**BLOCK**fs== 9.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n𝑙𝑜𝑔𝑖𝑐_𝑐𝑜𝑚𝑏𝑖𝑛𝑎𝑡𝑖𝑜𝑛 ← ((𝑘𝑒𝑦 + 𝑖𝑛𝑝𝑢𝑡𝑠) → 𝑜𝑢𝑡𝑝𝑢𝑡)\n𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← 𝑙𝑜𝑔𝑖𝑐_𝑐𝑜𝑚𝑏𝑖𝑛𝑎𝑡𝑖𝑜𝑛\n**BLOCK**fs== 9.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\nend for\n**BLOCK**fs== 9.0**p== 3.0**b== 0.5**t== 0.5**l== 0.1**r== 0.8**\n10:\n11: end for\n12: return 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒\n13: End Function\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.6**l== 0.1**r== 0.5**\nthe locked G10 and G11 are placed instead of the original gates.\nGates can be connected to the absolute inputs or the original inputs.\n5. Circuit Operation: To operate the locked circuit, one must\ninput the correct keys used to encode the gates. For the example\nshown in Figure 1, the truth table is shown in Table 1, where G1,\nG2, G3, G6, and G7 are the inputs and G22 and G23 are the outputs.\nThe K-Gate lock implementation is shown in Algorithms 1 and\n2; it relies on two functions: one to lock an individual gate and\nanother to lock the entire circuit. In other words, the main focus of\nAlgorithm 1 is to find the gates to lock based on the given 𝑘 and\nreplace the gates with the locked ones generated from Algorithm 2.\nThe main focus of Algorithm 2 is to lock an individual gate with\na given set of dynamic keys. To attach the keys, it is necessary\nto generate the truth table of the gate’s absolute inputs and then\nattach the given dynamic key.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n3.4 Time Complexity\nNow, we explain the time complexity of K-Gate Lock, which de-\npends on the following:\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nNumber of Gates to Lock (min{ 𝑛\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n𝑘 , 𝑔}): This number represents\nhow many gates the algorithm aims to lock, determined by 𝑔 and\n𝑘. The gates are chosen based on the level or absolute inputs they\nhandle, as specified by 𝑘. This is demonstrated by line 3 of Algorithm\n1, which identifies the gates to be locked.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\nGate Locking Complexity (2𝑘 ): The locking mechanism for\neach gate involves encoding the gate key into the gate’s logic. This\n**BLOCK**fs== 9.0**p== 3.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nTable 2: Number of Keys for the Height of 2𝑛 and 𝑔 Gates\n**BLOCK**fs== 7.0**p== 3.0**b== 0.7**t== 0.2**l== 0.6**r== 0.4**\nkey 1\nkey 2\nkey 3\n.\n.\nkey 2𝑛\n**BLOCK**fs== 7.0**p== 3.0**b== 0.7**t== 0.2**l== 0.7**r== 0.2**\n𝑔 ... 𝑘 |𝑘𝑒𝑦𝑔 |\nx\nx\nx\n.\n.\nx\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nrequires creating a truth table for the gate with all possible combi-\nnations of inputs, resulting in 2𝑘 combinations. This step is shown\nin line 4 of Algorithm 2, which generates the truth table for the gate,\nand line 6, which encodes the gate key into the input combination.\nConsidering the above, the total time complexity can be repre-\n𝑘 , 𝑔} × 2𝑘 ). It is practical to fix 𝑘 at 2, leading to\n**BLOCK**fs== 9.0**p== 3.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nsented as 𝑂 (min{ 𝑛\na linear time complexity for locking a circuit.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n3.5 Attack Analysis\nFor attack analysis, we show how the time complexity increases\nfor SAT-based oracle-guided attacks to find the correct keys in a\ncircuit locked with K-Gate Lock. We explore the idea of traditional\nsingle-key SAT solvers and future multi-key SAT attacks that are\naware of the K-Gate Lock method.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\nSingle-Key SAT Attack: Traditional SAT-based oracle-guided\nattacks are configured to find one correct key for a given circuit.\nTheoretically, such solvers are not suitable for finding multiple\nkeys of the K-Gate Lock and in the best scenario, they will end\nup finding the first key of the sequence. We evaluate this with\nexperimental results in Section 4.\n**BLOCK**fs== 9.0**p== 3.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nMulti-Key SAT Attack: In this case, the attacker is aware the\ncircuit is locked with K-Gate lock and needs to explore the keys\nfor every input combination as follows:\nI) All input combinations: 2𝑛 possibilities (where 𝑛 is the number\nof inputs) as shown by the height of Table 2.\nII) All potential values for each key: 2𝑚 possibilities (where m is the\nnumber of key bits). As shown in Table 2, the size of keys depends\non the number of gates locked and the size of each gate key. The\ncircuit designer has control over the total number of bits used and\nthe number of gates. The 𝑚 parameter that depends on the number\nof locked gates 𝑔 and the key size for each gate is determined by\nthe following equation:\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\nAlthough current SAT-based attacks implement optimizations to\nprune several values of the global key, these optimizations cannot be\napplied to K-Gate Lock because it uses a different key at every DIP.\nConsequently, SAT-based attacks are forced to perform a brute-force\nsearch for every key, resulting in a time complexity of 𝑂 (2𝑚+𝑛).\n**BLOCK**fs== 9.0**p== 3.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n4 EXPERIMENTAL RESULTS\nWe conduct experiments on a Windows 11 machine, which accesses\nLinux Ubuntu 22.04 via WSL2. The machine is a Ryzen 7940HS with\n8 cores and 16 threads at 4.0 GHz and 32 GB of DDR5 RAM. The\n**BLOCK**fs== 7.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nK-Gate Lock: Multi-Key Logic Locking Using Input Encoding Against Oracle-Guided Attacks\n**BLOCK**fs== 9.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nTable 3: Attack Results on Benchmarks with Static Keys\n**BLOCK**fs== 9.0**p== 4.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nBenchmark\niscas85/c1355\niscas85/c17\niscas85/c1908\niscas85/c3540\niscas85/c432\niscas85/c499\niscas85/c5315\niscas85/c7552\niscas85/c880\n**BLOCK**fs== 9.0**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nGates Time (S) Reported Key\n**BLOCK**fs== 9.0**p== 4.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\nsource codes and created benchmarks of K-Gate Lock are publicly\navailable on our GitHub repository1.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n4.1 Algorithm Validation\nThe algorithm validation is done in Python along with pyEDA [43],\na tool used for electronic design automation. In this case, 2 gates of\nthe c17 benchmark are locked with 4 different key combinations: 01,\n11, 10, and 11. The truth tables are generated for the whole circuit\nshown in Table 1 along with adding the correct key values; in this\ncase, the original circuit and the locked circuit output the same\nvalue when the correct keys are fed in.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\nAnother set of tests is done using Netlist Encryption and Obfus-\ncation Suite (NEOS) [44], where circuits from ISCAS 85 [42] are\nlocked using multiple keys that remain the same value: 101, 101, 101.\nWhen multiple constant keys are provided, the SAT-based attack\n[3] is able to find out the correct key, meaning it is also possible to\nachieve the level of locking based on the traditional logic locking\nmethods. The results are shown in Table 3.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n4.2 Security Evaluation\nThe main objective of K-Gate Lock is to generate a locking mech-\nanism that powerful SAT-based oracle-guided attacks will not be\nable to decrypt. We use combinational benchmarks of ISCAS 85\n[42] and EPFL Benchmarks [45] as well as sequential benchmarks\nof ISCAS 89 [46]. Even though our proposed solution is based on\ncombinational circuits, it is also possible to lock sequential circuits,\nlocking portions of the circuit before including the flip-flops.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n4.2.1 Three Dynamic Keys. Now, we perform SAT-based oracle-\nguided attacks against the benchmarks locked with K-Gate Lock.\nWe use NEOS [44] and RANE [47] tools to run the attacks. The\nencryption for each circuit is done in .bench files with our Python\nimplementation of K-Gate Lock.\n**BLOCK**fs== 9.0**p== 4.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nThe goal of this experiment is to demonstrate that with even a\nminimal number of keys, SAT-based attacks are unable to determine\nthe correct keys. This limitation comes from their inherent design,\nwhich is to find only one key. The results are shown in Table 4 in\nwhich the circuits are locked with the following gate key values:\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.8**l== 0.1**r== 0.7**\n• b’011 - decimal value 3\n• b’100 - decimal value 4\n• b’101 - decimal value 5\n**BLOCK**fs== 7.0**p== 4.0**b== 0.1**t== 0.9**l== 0.1**r== 0.7**\n1https://github.com/cars-lab-repo/KGL\n**BLOCK**fs== 9.0**p== 4.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\nTable 4: Attack Results on Benchmarks with 3 Small Dynamic\nKeys\n**BLOCK**fs== 7.0**p== 4.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nBenchmark\n**BLOCK**fs== 7.0**p== 4.0**b== 0.6**t== 0.2**l== 0.5**r== 0.4**\niscas85/c1355\niscas85/c17\niscas85/c1908\niscas85/c3540\niscas85/c432\niscas85/c499\niscas85/c5315\niscas85/c6288\niscas85/c7552\niscas85/c880\niscas89/s1196\niscas89/s15850\niscas89/s5378\niscas89/s641\niscas89/s713\niscas89/s832\n**BLOCK**fs== 7.0**p== 4.0**b== 0.6**t== 0.2**l== 0.7**r== 0.3**\nReported Key\n\n\n\n\n\n\n\n\n\n\n\n\nCNS\n**BLOCK**fs== 7.0**p== 4.0**b== 0.6**t== 0.2**l== 0.8**r== 0.1**\nKey Found\nCNS\n**BLOCK**fs== 9.0**p== 4.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\nTable 5: Attack Results on Benchmarks with Dynamic Key\nSizes Scalable to the Input Sizes\n**BLOCK**fs== 8.0**p== 4.0**b== 0.2**t== 0.4**l== 0.5**r== 0.3**\nBenchmark\niscas85/c1355\niscas85/c17\niscas85/c1908\niscas85/c3540\niscas85/c432\niscas85/c499\niscas85/c5315\niscas85/c6288\niscas85/c7552\niscas85/c880\nEPFL/adder\nEPFL/bar\nEPFL/div\nEPFL/hyp\nEPFL/log2\nEPFL/max\nEPFL/multiplier\nEPFL/sin\nEPFL/sqrt\nEPFL/adder_depth_2023\nEPFL/arbiter_depth_2022\nEPFL/bar_depth_2015\nEPFL/cavlc_depth_2022\nEPFL/div_depth_2023\nEPFL/adder_size_2022\nEPFL/arbiter_size_2023\nEPFL/bar_size_2015\nEPFL/cavlc_size_2023\nEPFL/div_size_2023\n**BLOCK**fs== 8.0**p== 4.0**b== 0.2**t== 0.4**l== 0.9**r== 0.1**\n3.08\n0.05\n0.47\n0.52\n0.14\n0.45\n3.46\n2.77\n1.32\n0.22\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\nFAIL\n**BLOCK**fs== 9.0**p== 4.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nIn the tables, different colors are used to indicate specific condi-\ntions. The color light red1 represents the “Condition Not Solvable”\nstatus. A deeper red2 signifies a wrong key, while the darkest red3\nindicates that the attack failed. Finally, green4 denotes that the\ncorrect key has been found.\n**BLOCK**fs== 7.0**p== 5.0**b== 0.7**t== 0.3**l== 0.3**r== 0.7**\n(a) Power (W)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.7**t== 0.3**l== 0.7**r== 0.2**\n(b) Number of Cells\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.4**l== 0.3**r== 0.7**\n(c) Area (𝜇𝑚2)\n**BLOCK**fs== 7.0**p== 5.0**b== 0.6**t== 0.4**l== 0.7**r== 0.2**\n(d) Number of IOs\n**BLOCK**fs== 9.0**p== 5.0**b== 0.6**t== 0.4**l== 0.4**r== 0.4**\nFigure 2: Overhead Measurements\n**BLOCK**fs== 9.0**p== 5.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nThis experiment shows that SAT-based attacks are not able to\nfind the sequences of the keys but only to find the first one. The\nkey found by the SAT solvers is a combination of the keys for the\nlocked gates, as we see in the first test for Table 4, the key value\n100 is repeated three times, which is only one of the combinations\nof the keys that are used to lock the gates.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n4.2.2 Dynamic Key based on Input Size. For the second security\nexperiment shown in Table 5, we explore scaling key sizes to input\nsizes. Specifically, for ISCAS 85 benchmarks, the gate key size is\ncalculated using  𝑛\n with 10 gates locked, resulting in a floor value\n\nof 10 compared to the input size. In addition, we use a logarithmic\nscaling formula to deal with the high number of inputs in the EPFL\nbenchmarks. While the EPFL benchmarks [45] are in .blif format,\nwe use the ABC tool [48] to convert them to .bench files and perform\nthe attack. The key values are generated randomly within the range\ndictated by the key input size for both benchmark suites. To simplify\nthe testing process, we limit the number of gates locked to 10. This\naims to approximate the size of the key as closely as possible to the\ninput size. The experimental results highlight the challenges faced\nby SAT-based attacks in thwarting dynamic key locking.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n4.3 Overhead Analysis\nNow, we analyze the overhead of K-Gate Lock. The experimental\nsetup utilizes Cadence Genus, using low mapping and optimization\neffort. Circuit locking is executed using .bench files and these are\nconverted to Verilog with the ABC tool [48]. Power measurements,\nas shown in Figure 2, are performed on various ISCAS 85 [42]\nbenchmarks with the following locking parameters.\n• Test Run 1 : 𝑘 = 2, 𝑔 = 3, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 𝑛\n\n• Test Run 2 : 𝑘 = 3, 𝑔 = 10, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 5\n• Test Run 3 : 𝑘 = 4, 𝑔 = 10, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 5\n• Test Run 4 : 𝑘 = 6, 𝑔 = 𝑎𝑙𝑙, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 1\n**BLOCK**fs== 9.0**p== 5.0**b== 0.5**t== 0.5**l== 0.6**r== 0.2**\nTable 6: Average Overhead\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.6**r== 0.4**\nTest Name\n**BLOCK**fs== 8.0**p== 5.0**b== 0.5**t== 0.5**l== 0.7**r== 0.1**\nPower % Cells % Area % I/O %\n**BLOCK**fs== 8.0**p== 5.0**b== 0.4**t== 0.5**l== 0.6**r== 0.3**\nK=2, g=3, key bit=n/3\nK=3, g=10, key bit=5 bits\nK=4, g=10, key bit=5 bits\nK=6, g=All, key bit=1 bit\n**BLOCK**fs== 9.0**p== 5.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\nAs shown in Figure 2, power consumption does not increase\nmuch, and the area increases only slightly, correlated with the num-\nber of inputs and the gates locked. The missing data in the area, I/O\nmeasurements, along with power and temperature, means that the\ncircuit is unable to lock any gates given the specific specifications,\nleading to the failure of the locked circuit creation. We calculated\nthe average percentage increase using the sum of the whole test\nrun and compared it with the original sum. These values are shown\nin Table 6. The highest jump in terms of power is 25.62% in Test\nRun 4, while the smallest jump is less than 1% in Test Run 1.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.2**t== 0.7**l== 0.5**r== 0.1**\n5 CONCLUSION\nIn this paper, we proposed a novel multi-key logic locking solution\ncalled K-Gate Lock that is based on input encoding and can be\nfully implemented using combinational logic without the need for\nstate-holder components. Experimental results showed that K-Gate\nLock is resilient against state-of-the-art SAT-based oracle-guided\nattacks with minimal overhead. This offers the potential of multi-\nkey logic locking schemes for robust hardware IP protection with\nreasonable overhead.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\nACKNOWLEDGMENT\nThis material is based upon work supported by the National Science\nFoundation under Award No. 2245247.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nK-Gate Lock: Multi-Key Logic Locking Using Input Encoding Against Oracle-Guided Attacks\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\nREFERENCES\n[1] Jarrod A. Roy, Farinaz Koushanfar, and Igor L. Markov. Ending piracy of inte-\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\ngrated circuits. Computer, 43(10):30–38, 2010.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.1**r== 0.5**\n[2] Jeyavijayan Rajendran, Huan Zhang, Chi Zhang, Garrett S. Rose, Youngok Pino,\nOzgur Sinanoglu, and Ramesh Karri. Fault analysis-based logic encryption. IEEE\nTransactions on Computers, 64(2):410–424, 2015.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.2**l== 0.1**r== 0.5**\n[3] Pramod Subramanyan, Sayak Ray, and Sharad Malik. Evaluating the security\nof logic encryption algorithms. In IEEE International Symposium on Hardware\nOriented Security and Trust (HOST), pages 137–143, 2015.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[4] Yang Xie and Ankur Srivastava. Anti-sat: Mitigating sat attack on logic locking.\nIEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,\n38(2):199–207, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.1**r== 0.5**\n[5] Muhammad Yasin, Bodhisatwa Mazumdar, Jeyavijayan Rajendran, and Ozgur\nSinanoglu. Sarlock: Sat attack resistant logic locking.\nIn IEEE International\nSymposium on Hardware Oriented Security and Trust (HOST), pages 236–241,\n2016.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.3**l== 0.1**r== 0.5**\n[6] Muhammad Yasin, Bodhisatwa Mazumdar, Jeyavijayan J V Rajendran, and Ozgur\nSinanoglu. Ttlock: Tenacious and traceless logic locking. In IEEE International\nSymposium on Hardware Oriented Security and Trust (HOST), pages 166–166, 2017.\n[7] Bicky Shakya, Xiaolin Xu, Mark Tehranipoor, and Domenic Forte. Cas-lock: A\nsecurity-corruptibility trade-off resilient logic locking scheme. IACR Transactions\non Cryptographic Hardware and Embedded Systems, 2020(1):175–202, 2020.\n[8] Amin Rezaei, Yuanqi Shen, and Hai Zhou. Rescuing logic encryption in post-sat\nera by locking & obfuscation. In Design Automation & Test in Europe Conference\n& Exhibition (DATE), pages 13–18, 2020.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.4**l== 0.1**r== 0.5**\n[9] Raheel Afsharmazayejani, Hossein Sayadi, and Amin Rezaei. Distributed logic\nencryption: Essential security requirements and low-overhead implementation.\nIn Proceedings of Great Lakes Symposium on VLSI (GLSVLSI), pages 127–131, 2022.\n[10] Hadi Mardani Kamali, Kimia Zamiri Azar, Houman Homayoun, and Avesta Sasan.\nFull-lock: Hard distributions of sat instances for obfuscating circuits using fully\nIn Proceedings of Design Automation\nconfigurable logic and routing blocks.\nConference (DAC), pages 1–6, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[11] Kaveh Shamsi, Meng Li, David Z. Pan, and Yier Jin. Cross-lock: Dense layout-level\ninterconnect locking using cross-bar architectures. In Proceedings of the Great\nLakes Symposium on VLSI (GLSVLSI), pages 147–152, 2018.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\n[12] Md Rafid Muttaki, Roshanak Mohammadivojdan, Mark Tehranipoor, and Farimah\nFarahmandi. Hlock: Locking ips at the high-level language. In Design Automation\nConference (DAC), pages 79–84, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.4**t== 0.5**l== 0.1**r== 0.5**\n[13] Michael Zuzak, Yuntao Liu, and Ankur Srivastava. Trace logic locking: Improving\nthe parametric space of logic locking. IEEE Transactions on Computer-Aided Design\nof Integrated Circuits and Systems, 40(8):1531–1544, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[14] Yuke Zhang, Yinghua Hu, Pierluigi Nuzzo, and Peter A. Beerel. Trilock: Ic\nprotection with tunable corruptibility and resilience to sat and removal attacks.\nIn 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE),\npages 1329–1334, 2022.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.4**t== 0.6**l== 0.1**r== 0.5**\n[15] Amin Rezaei, Ava Hedayatipour, Hossein Sayadi, Mehrdad Aliasgari, and Hai\nZhou. Global attack and remedy on ic-specific logic encryption. In IEEE In-\nternational Symposium on Hardware Oriented Security and Trust (HOST), pages\n145–148, 2022.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.6**l== 0.1**r== 0.5**\n[16] Amin Rezaei, Jie Gu, and Hai Zhou. Hybrid memristor-cmos obfuscation against\nuntrusted foundries. In IEEE Computer Society Annual Symposium on VLSI (ISVLSI),\npages 535–540, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[17] Amin Rezaei and Hai Zhou. Sequential logic encryption against model checking\nattack. In Design Automation & Test in Europe Conference & Exhibition (DATE),\npages 1178–1181, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.1**r== 0.5**\n[18] Yeganeh Aghamohammadi and Amin Rezaei. Cola: Convolutional neural net-\nwork model for secure low overhead logic locking assignment. In Great Lakes\nSymposium on VLSI 2023 (GLSVLSI), pages 339–344, 2023.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.7**l== 0.1**r== 0.5**\n[19] Amin Rezaei, You Li, Yuanqi Shen, Shuyu Kong, and Hai Zhou. Cycsat-\nunresolvable cyclic logic encryption using unreachable states. In Proceedings\nof the 24th Asia and South Pacific Design Automation Conference, page 358–363,\n2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[20] Amin Rezaei, Yuanqi Shen, Shuyu Kong, Jie Gu, and Hai Zhou. Cyclic locking\nand memristor-based obfuscation against cycsat and inside foundry attacks. In\n2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), pages\n85–90, 2018.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\n[21] Pei-Pei Chen, Xiang-Min Yang, Yu-Cheng He, Yung-Chih Chen, Yi-Ting Li, and\nChun-Yao Wang. Looplock 3.0: A robust cyclic logic locking approach. In 2024\n29th Asia and South Pacific Design Automation Conference (ASP-DAC), pages\n594–599, 2024.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\n[22] Michaela Brunner, Tarik Ibrahimpasic, Bing Li, Grace Li Zhang, Ulf Schlichtmann,\nand Georg Sigl. Timing camouflage enabled state machine obfuscation. In 2022\nIEEE Physical Assurance and Inspection of Electronics (PAINE), pages 1–7, 2022.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.9**l== 0.1**r== 0.5**\n[23] Seetal Potluri, Aydin Aysu, and Akash Kumar. Seql: Secure scan-locking for ip\nprotection. In 2020 21st International Symposium on Quality Electronic Design\n(ISQED), pages 7–13, 2020.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[24] Ujjwal Guin, Ziqi Zhou, and Adit Singh. Robust design-for-security architecture\nfor enabling trust in ic manufacturing and test. IEEE Transactions on Very Large\nScale Integration (VLSI) Systems, 26(5):818–830, 2018.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.8**t== 0.2**l== 0.5**r== 0.1**\n[25] Xiang-Min Yang, Pei-Pei Chen, Hsiao-Yu Chiang, Chia-Chun Lin, Yung-Chih\nChen, and Chun-Yao Wang. Looplock 2.0: An enhanced cyclic logic locking\napproach. IEEE Transactions on CAD of Integrated Circuits and Systems, 41(1):29–\n34, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n[26] Subhajit Dutta Chowdhury, Gengyu Zhang, Yinghua Hu, and Pierluigi Nuzzo.\nEnhancing sat-attack resiliency and cost-effectiveness of reconfigurable-logic-\nbased circuit obfuscation. In 2021 IEEE International Symposium on Circuits and\nSystems (ISCAS), pages 1–5, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[27] Rajit Karmakar, Harshit Kumar, and Santanu Chattopadhyay. Efficient key-gate\nplacement and dynamic scan obfuscation towards robust logic encryption. IEEE\nTransactions on Emerging Topics in Computing, 9(4):2109–2124, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[28] You Li, Guannan Zhao, Yunqi He, and Hai Zhou. Obfuslock: An efficient obfus-\ncated locking framework for circuit ip protection†. In 2023 Design, Automation\n& Test in Europe Conference & Exhibition, pages 1–6, 2023.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.1**\n[29] Hai Zhou, Amin Rezaei, and Yuanqi Shen. Resolving the trilemma in logic\nIn International Conference on Computer Aided Design (ICCAD),\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.3**l== 0.6**r== 0.4**\nencryption.\npages 1–8, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[30] Zhaokun Han, Aneesh Dixit, Satwik Patnaik, and Jeyavijayan Rajendran. Station:\nState encoding-based attack-resilient sequential obfuscation. IEEE Transactions\non Computer-Aided Design of Integrated Circuits and Systems, pages 1–1, 2024.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[31] Yeganeh Aghamohammadi and Amin Rezaei. Machine learning-based security\nevaluation and overhead analysis of logic locking. Journal of Hardware and\nSystems Security, 8:25–43, 2024.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.6**t== 0.4**l== 0.5**r== 0.1**\n[32] Amin Rezaei, Raheel Afsharmazayejani, and Jordan Maynard. Evaluating the se-\ncurity of efpga-based redaction algorithms. In IEEE/ACM International Conference\non Computer-Aided Design (ICCAD), pages 1–7, 2022.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.4**l== 0.5**r== 0.1**\n[33] Yuanqi Shen, You Li, Shuyu Kong, Amin Rezaei, and Hai Zhou. Sigattack: New\nhigh-level sat-based attack on logic encryptions. In 2019 Design, Automation &\nTest in Europe Conference & Exhibition (DATE), pages 940–943, 2019.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[34] Yuanqi Shen, Amin Rezaei, and Hai Zhou. Sat-based bit-flipping attack on logic\nencryptions. In 2018 Design, Automation & Test in Europe Conference & Exhibition\n(DATE), pages 629–632, 2018.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.5**t== 0.5**l== 0.5**r== 0.1**\n[35] Yinghua Hu, Yuke Zhang, Kaixin Yang, Dake Chen, Peter A. Beerel, and Pierluigi\nNuzzo. Fun-sat: Functional corruptibility-guided sat-based attack on sequential\nlogic encryption. In 2021 IEEE International Symposium on Hardware Oriented\nSecurity and Trust (HOST), pages 281–291, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.4**t== 0.5**l== 0.5**r== 0.1**\n[36] Yuanqi Shen and Hai Zhou. Double dip: re-evaluating security of logic encryption\nalgorithms. In Great Lakes Symposium on VLSI (GLSVLSI), pages 179–184, 2017.\n[37] Kaveh Shamsi, Meng Li, Travis Meade, Zheng Zhao, David Z. Pan, and Yier\nJin. App-sat: approximately deobfuscating integrated circuits. In International\nSymposium on Hardware Oriented Security and Trust (HOST), pages 95–100, 2017.\n[38] Nimisha Limaye, Satwik Patnaik, and Ozgur Sinanoglu. Fa-sat: Fault-aided sat-\nbased attack on compound logic locking techniques. In Design, Automation &\nTest in Europe Conference & Exhibition (DATE), pages 1166–1171, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.4**t== 0.6**l== 0.5**r== 0.1**\n[39] Jordan Maynard and Amin Rezaei. Dk lock: Dual key logic locking against\noracle-guided attacks. In 2023 24th International Symposium on Quality Electronic\nDesign (ISQED), pages 1–7, 2023.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.6**l== 0.5**r== 0.1**\n[40] Yasaswy Kasarabada, Vaishali Muralidharan, and Ranga Vemuri. Sled: Sequential\nlogic encryption using dynamic keys. In 2020 IEEE 63rd International Midwest\nSymposium on Circuits and Systems (MWSCAS), pages 844–847, 2020.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[41] Vijaypal Singh Rathor, Munesh Singh, Kshira Sagar Sahoo, and Saraju P. Mohanty.\nGatelock: Input-dependent key-based locked gates for sat resistant logic locking.\nIEEE Transactions on Very Large Scale Integration (VLSI) Systems, 32(2):361–372,\n2024.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[42] Mark C. Hansen, Hakan Yalcin, and John P. Hayes. Unveiling the iscas-85\nbenchmarks: a case study in reverse engineering. IEEE Design & Test of Computers,\n16(3):72–80, 1999.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.5**r== 0.1**\n[43] Chris Drake. PyEDA: Python electronic design automation. https://github.com/\n**BLOCK**fs== 7.0**p== 6.0**b== 0.3**t== 0.7**l== 0.6**r== 0.3**\ncjdrake/pyeda, 2023.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[44] Kaveh Shamsi. Attack tool and benchmarks. https://bitbucket.org/kavehshm/\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[45] Luca Amarú, Pierre-Emmanuel Gaillardon, and Giovanni De Micheli. The epfl\nIntegrated Systems Laboratory (LSI), EPFL,\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\ncombinational benchmark suite.\nSwitzerland, 2015.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.1**\n[46] Franc Brglez, David Bryan, and Krzysztof Kozminski. Combinational profiles of\nsequential benchmark circuits. In 1989 IEEE International Symposium on Circuits\nand Systems (ISCAS), volume 3, pages 1929–1934, 1989.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\n[47] Shervin Roshanisefat, Hadi Mardani Kamali, Houman Homayoun, and Avesta\nSasan. Rane: An open-source formal de-obfuscation attack for reverse engineering\nof logic encrypted circuits. Great Lakes Symposium on VLSI, 2021.\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.9**l== 0.5**r== 0.1**\n[48] Berkeley Logic Synthesis and Verification Group. ABC: A System for Sequential\n**BLOCK**fs== 7.0**p== 6.0**b== 0.1**t== 0.9**l== 0.6**r== 0.1**\nSynthesis and Verification. http://www.eecs.berkeley.edu/~alanmi/abc.",
         "Kevin Lopez Computer Engineering & Computer Science Department California State University, Long Beach Kevin.LopezChavez01@student.csulb.edu Amin Rezaei Computer Engineering & Computer Science Department California State University, Long Beach Amin.Rezaei@csulb.edu ABSTRACT Logic locking has emerged to prevent piracy and overproduction of integrated circuits ever since the split of the design house and manufacturing foundry was established. While there has been a lot of research using a single global key to lock the circuit, even the most sophisticated single-key locking methods have been shown to be vulnerable to powerful SAT-based oracle-guided attacks that can extract the correct key with the help of an activated chip bought off the market and the locked netlist leaked from the untrusted foundry. To address this challenge, we propose, implement, and evaluate a novel logic locking method called K-Gate Lock that encodes input patterns using multiple keys that are applied to one set of key inputs at different operational times. Our comprehensive experimental results confirm that using multiple keys will make the circuit secure against oracle-guided attacks and increase attacker efforts to an exponentially time-consuming brute force search. K-Gate Lock has reasonable power and performance overheads, making it a practical solution for real-world hardware intellectual property protection. CCS CONCEPTS • Security and privacy → Security in hardware. 1 INTRODUCTION In this split of design and manufacturing, one company designs the digital design, while another handles the physical fabrication of the Integrated Circuit (IC). While this separation of tasks poses a threat to chip security, logic locking [1, 2] has emerged as a promising solution to prevent piracy and overproduction of hardware Intellec- tual Properties (IPs). Formally speaking, logic locking is the process of adding additional inputs to an IC, called key bits, to prevent the correct operation of the IC when the incorrect key is provided to the circuit. Traditionally, locking has been done using only one global key, which made it susceptible to the SAT-based attack [3] that extracts the key using an oracle (i.e., a working chip bought off the market) and a locked netlist leaked from an untrustworthy foundry. While there have been attempts to reduce the success of the SAT-based attack to brute-force [4, 5], sophisticated attacks have been proposed to find out the correct key of these methods. We believe that the vulnerabilities associated with a single static key can be effectively mitigated through multi-key logic locking. In this paper, we introduce an advanced multi-key approach called K- Gate Lock where the inputs of each gate are encoded with different key values. To activate the circuit correctly, these values must be provided in the specific sequence used during the encoding process. In this paper, we present the following contributions: • Proposing a robust multi-key logic locking based on input encoding, implemented fully in combinational logic; • Implementing an efficient algorithm to lock a circuit with multiple user-defined keys with tunable time complexity; • Generating more than 40 benchmarks based on the proposed method, measuring the overhead, and evaluating its security against state-of-the-art oracle-guided attacks. 2 BACKGROUND AND RELATED WORK In this section, we first consider the evolution of logic locking techniques as well as oracle-guided attacks, and then review the existing efforts in multi-key logic locking. 2.1 Logic Locking Techniques Initial techniques of logic locking rely on single-key schemes, pri- marily employing xor-based and mux-based mechanisms [1, 2]. In xor-based logic locking, the key bits are matched with random inverters and buffers. Then, the xor gates controlled by key bits are used to replace selected buffers and inverters. Additionally, mux-based logic locking selects random wires and substitutes them with 2-1 muxs whose inputs are real signals and random dummy ones, and selectors are the key bits. However, advancements in SAT solvers have been utilized to expose vulnerabilities in these meth- ods [3], leading to the development of more robust techniques such as Anti-SAT [4], SAR-Lock [5], TT-Lock [6], CAS-lock [7], BLE [8], DLE [9], Full-Lock [10], Cross-Lock [11], HLock [12], TraceLL [13], TriLock [14], and others [15–27] that increase the time complexity of attacks. Obfus-Lock [28] is proposed to leverage the skewness of nodes to construct a locked circuit and obfuscate the circuit using re-write rules. Furthermore, a theoretical method has been pro- posed to achieve both high query complexity and key error rates based on quasi-universal circuits, including convolutional biased target circuits [29]. In addition, recently, a sequential obfuscation solution called STATION [30] has been proposed by leveraging disjoint encoding and combinational logic locking techniques. A comprehensive overhead and security analysis of state-of-the-art logic locking methods is also done in [31]. Despite the mentioned efforts, single-key solutions remain susceptible once the key is com- promised, endangering the entire security of the hardware IPs. 2.2 Oracle-Guided Attacks Boolean SAT solvers are used to reveal the correct key of logic- locked circuits using an oracle (i.e., an activated IC bought off the market) and a locked netlist to prune out the wrong key values [32– 35]. The SAT-based attack [3] uses Distinguishing Input Patterns (DIPs) that are specifically designed to exploit the discrepancies be- tween the locked circuit and the oracle by targeting and identifying incorrect key values. The more incorrect key values the SAT solver eliminates in one iteration, the faster the attack can find the correct key. Then on, each attack has been strategically designed to target a specific defense mechanism; for example, Double DIP [36] is used for attacking ICs locked with SAR-Lock [5], where using two DIPs instead of one helps find the correct key faster. AppSAT [37] uses an approximate flow to find the probably-approximate-correct key in Anti-SAT [4] method. Fa-SAT [38] inserts a single stuck-at fault at each signal of the locked circuit iteratively to find the correct key of BLE [8]. The assumption in all the above attacks is that there is a single static key in the logic-locked circuit to be deciphered. 2.3 Multi-Key Approaches Recent works have brought the possibility of multi-key solutions. Specifically, DK-Lock [39] is a sequential locking method where one must provide two keys to a circuit; the first key is the activa- tion key, which must be provided for a constant amount of time to activate the circuit, and then a functional key right after. DK- Lock may be susceptible to unrolling attacks [32] that can expand the key size to reverse the method back to a single-key solution. SLED [40] is another multi-key sequential solution but requires latches that operate on a clock, introducing additional complexity for combinational circuits. In addition, it depends on a seed value (i.e., a primary key) to operate, which can eventually be reduced to a single-key model since the attacker only needs to find out the seed value. Both of the mentioned multi-key logic locking methods may still be reverted back to a single-key model and thus susceptible to traditional SAT-based oracle-guided attacks. In addition, they depend on sequential components to be implemented. Another multi-key logic locking solution, Gate-Lock [41], uses an approach focused on locking gates, resulting in circuits that are resilient to SAT attacks. In Gate-Lock, the truth table has a height of 2𝑛+𝑘 while our proposed method maintains the same input size height of 2𝑛 and only locks the outcomes within the truth table that are true. This allowed us to implement a more efficient algorithm. 3 MULTI-KEY LOGIC LOCKING In this section, after explaining the terminology, we discuss our proposed methods of locking a circuit with multiple keys; the first one locks the whole circuit, and it needs to generate a truth table for all the input combinations on the circuit, which may not be efficient in terms of space and time complexity. The second method, called K-Gate Lock, is a derivation but more optimized than the first one to focus on encoding the input combinations of the gates with specific key values. We also thoroughly discuss the implementation of the K-Gate Lock and evaluate the theoretical time complexity for any future oracle-guided attack to find the correct keys. An implementation example of K-Gate Lock on the c17 circuit from ISCAS 85 benchmarks [42] is shown in Figure 1. You may refer to Table 1 which contains the sequence of keys necessary to operate this locked circuit. 3.1 Terminology In the context of K-Gate Lock, it is crucial to understand the terminology used to describe the various components and concepts: n: The total number of inputs to the original circuit. g: The maximum number of gates to be locked within a circuit. k: The number of inputs to a gate is often called the level of locking. gate key: Each gate in a locked circuit has a specific key that controls its operation based on the input combination. key bit: The individual binary elements that constitute a key. m: The total number of bits in a key, aggregated from all key bits associated with each locked gate. keys: Our approach uses keys derived from gate key combinations, with the specific key depending on the input. 3.2 Locking the Whole Circuit The brute force method of locking a combinational circuit using multiple keys requires expanding the logic table of all the circuit’s possible input/output combinations. Multiple keys can be inserted into each input/output combination when all the inputs and outputs are expanded. The truth table will maintain a size of 2𝑛 since it does not create every combination of keys; it only adds the desired keys to an input combination. This brute force approach to locking a whole circuit is impractical because it would lead to an exponential- size truth table, and the implementation of locking a circuit would be time-consuming. For example, the C432 circuit in ISCAS 85 produces a truth table of 68,719 million rows, which is extremely large for one of the smallest benchmarks in ISCAS 85 suite. This motivated us to introduce K-Gate Lock. 3.3 K-Gate Lock Algorithm K-Gate Lock operates by locking specific gates within the circuit rather than the entire IC. This method utilizes the truth table of a gate or a more complex expression (i.e., a deep gate), encoding key bits directly into it. To operate the circuit, the user must provide a combination of inputs along with the corresponding keys in the correct sequence. Now, we discuss the steps for locking a circuit based on the circuit example in Figure 1, which is locked at 𝑘 = 2 with the key values of 01, 11, 10, and 11. 1. Inputs: The algorithm requires an input of the original cir- cuit, unique keys, the maximum number of gates to lock (i.e., 𝑔), and a chosen level of gate locking (i.e., 𝑘). It is worth noting that the height of the truth table must be greater than the number of keys. 2. Gate Selection: In the second phase of the process, the main task is determining which gates to lock, using the variable 𝑘 as a guide. The gates needed to be locked are those that have the number of absolute inputs equal to the input value 𝑘. For example, while locking the C17 benchmark shown in Figure 1: • G10 has two absolute inputs (𝑘 = 2), G1 and G3. • G11 has two absolute inputs (𝑘 = 2), G3 and G6. • G19 contains three absolute inputs (𝑘 = 3), which are G7, • G16 contains three absolute inputs (𝑘 = 3), which are G2, Since the initial constraint is to lock at 𝑘 = 2, only G10 and G11 are selected. 3. Key Insertion: Up to this point, the algorithm has selected what gates to lock. In this step, the keys are inserted into the gate logic. For the C17 benchmark, as shown in Figure 1, truth tables are expanded for the expressions (𝐺1 ∧ 𝐺3) and (𝐺3 ∧ 𝐺6), and the key bits are added as defined in the initial contains. For deeper gates (i.e., 𝑘 > 2), it is necessary to have the absolute input to know when each key should be applied. It is also possible to maintain the original connections to the gate by using the inputs to the logic gate and adding them to the truth table. After the keys are added to the truth table, the expression can be extracted and simplified using any simplification method, like Karnaugh maps. Table 1: Circuit Operation of Figure 1 4. Circuit Update: In this step, the algorithm updates the orig- inal circuit with the new locked gates. As shown by step 4 of Fig 1, 1: Input: Circuit 𝑓 (𝑥), keys, g (max gates to lock), level 𝑘 (default 2: Output: Locked circuit ℎ(𝑥, 𝑘) 3: 𝑔𝑎𝑡𝑒𝑠_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 ← 𝑔𝑒𝑡_𝑔𝑎𝑡𝑒𝑠_𝑤𝑖𝑡ℎ_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 (𝑓 (𝑥), 𝑘, 𝑔) 4: ℎ(𝑥, 𝑘) ← 𝑓 (𝑥) 5: for each gate in 𝑔𝑎𝑡𝑒𝑠_𝑘_𝑖𝑛𝑝𝑢𝑡𝑠 do 6: 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← 𝑙𝑜𝑐𝑘_𝑔𝑎𝑡𝑒_𝑤𝑖𝑡ℎ_𝑘𝑒𝑦 (𝑔𝑎𝑡𝑒, 𝑘𝑒𝑦𝑠) ℎ(𝑥, 𝑘).𝑟𝑒𝑝𝑙𝑎𝑐𝑒 (𝑔𝑎𝑡𝑒, 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒) 7: 8: end for 9: return ℎ(𝑥, 𝑘) 1: Function lock_gate_with_key (gate, keys) 2: Input: 𝑔𝑎𝑡𝑒, 𝑘𝑒𝑦𝑠 3: Output: 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 4: 𝑡𝑎𝑏𝑙𝑒 ← 𝑔𝑒𝑛𝑒𝑟𝑎𝑡𝑒_𝑙𝑜𝑔𝑖𝑐_𝑡𝑎𝑏𝑙𝑒 (𝑔𝑎𝑡𝑒.𝑖𝑛𝑝𝑢𝑡𝑠, 𝑔𝑎𝑡𝑒.𝑜𝑢𝑡𝑝𝑢𝑡) 5: 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← () 6: for each (𝑖𝑛𝑝𝑢𝑡𝑠, 𝑜𝑢𝑡𝑝𝑢𝑡) in 𝑡𝑎𝑏𝑙𝑒 do 7: for each 𝑘𝑒𝑦 in 𝑘𝑒𝑦𝑠 do 𝑙𝑜𝑔𝑖𝑐_𝑐𝑜𝑚𝑏𝑖𝑛𝑎𝑡𝑖𝑜𝑛 ← ((𝑘𝑒𝑦 + 𝑖𝑛𝑝𝑢𝑡𝑠) → 𝑜𝑢𝑡𝑝𝑢𝑡) 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 ← 𝑙𝑜𝑔𝑖𝑐_𝑐𝑜𝑚𝑏𝑖𝑛𝑎𝑡𝑖𝑜𝑛 end for 10: 11: end for 12: return 𝑙𝑜𝑐𝑘𝑒𝑑_𝑔𝑎𝑡𝑒 13: End Function the locked G10 and G11 are placed instead of the original gates. Gates can be connected to the absolute inputs or the original inputs. 5. Circuit Operation: To operate the locked circuit, one must input the correct keys used to encode the gates. For the example shown in Figure 1, the truth table is shown in Table 1, where G1, G2, G3, G6, and G7 are the inputs and G22 and G23 are the outputs. The K-Gate lock implementation is shown in Algorithms 1 and 2; it relies on two functions: one to lock an individual gate and another to lock the entire circuit. In other words, the main focus of Algorithm 1 is to find the gates to lock based on the given 𝑘 and replace the gates with the locked ones generated from Algorithm 2. The main focus of Algorithm 2 is to lock an individual gate with a given set of dynamic keys. To attach the keys, it is necessary to generate the truth table of the gate’s absolute inputs and then attach the given dynamic key. 3.4 Time Complexity Now, we explain the time complexity of K-Gate Lock, which de- pends on the following: Number of Gates to Lock (min{ 𝑛 𝑘 , 𝑔}): This number represents how many gates the algorithm aims to lock, determined by 𝑔 and 𝑘. The gates are chosen based on the level or absolute inputs they handle, as specified by 𝑘. This is demonstrated by line 3 of Algorithm 1, which identifies the gates to be locked. Gate Locking Complexity (2𝑘 ): The locking mechanism for each gate involves encoding the gate key into the gate’s logic. This Table 2: Number of Keys for the Height of 2𝑛 and 𝑔 Gates requires creating a truth table for the gate with all possible combi- nations of inputs, resulting in 2𝑘 combinations. This step is shown in line 4 of Algorithm 2, which generates the truth table for the gate, and line 6, which encodes the gate key into the input combination. Considering the above, the total time complexity can be repre- 𝑘 , 𝑔} × 2𝑘 ). It is practical to fix 𝑘 at 2, leading to sented as 𝑂 (min{ 𝑛 a linear time complexity for locking a circuit. 3.5 Attack Analysis For attack analysis, we show how the time complexity increases for SAT-based oracle-guided attacks to find the correct keys in a circuit locked with K-Gate Lock. We explore the idea of traditional single-key SAT solvers and future multi-key SAT attacks that are aware of the K-Gate Lock method. Single-Key SAT Attack: Traditional SAT-based oracle-guided attacks are configured to find one correct key for a given circuit. Theoretically, such solvers are not suitable for finding multiple keys of the K-Gate Lock and in the best scenario, they will end up finding the first key of the sequence. We evaluate this with experimental results in Section 4. Multi-Key SAT Attack: In this case, the attacker is aware the circuit is locked with K-Gate lock and needs to explore the keys for every input combination as follows: I) All input combinations: 2𝑛 possibilities (where 𝑛 is the number of inputs) as shown by the height of Table 2. II) All potential values for each key: 2𝑚 possibilities (where m is the number of key bits). As shown in Table 2, the size of keys depends on the number of gates locked and the size of each gate key. The circuit designer has control over the total number of bits used and the number of gates. The 𝑚 parameter that depends on the number of locked gates 𝑔 and the key size for each gate is determined by the following equation: Although current SAT-based attacks implement optimizations to prune several values of the global key, these optimizations cannot be applied to K-Gate Lock because it uses a different key at every DIP. Consequently, SAT-based attacks are forced to perform a brute-force search for every key, resulting in a time complexity of 𝑂 (2𝑚+𝑛). 4 EXPERIMENTAL RESULTS We conduct experiments on a Windows 11 machine, which accesses Linux Ubuntu 22.04 via WSL2. The machine is a Ryzen 7940HS with 8 cores and 16 threads at 4.0 GHz and 32 GB of DDR5 RAM. The Table 3: Attack Results on Benchmarks with Static Keys source codes and created benchmarks of K-Gate Lock are publicly available on our GitHub repository1. 4.1 Algorithm Validation The algorithm validation is done in Python along with pyEDA [43], a tool used for electronic design automation. In this case, 2 gates of the c17 benchmark are locked with 4 different key combinations: 01, 11, 10, and 11. The truth tables are generated for the whole circuit shown in Table 1 along with adding the correct key values; in this case, the original circuit and the locked circuit output the same value when the correct keys are fed in. Another set of tests is done using Netlist Encryption and Obfus- cation Suite (NEOS) [44], where circuits from ISCAS 85 [42] are locked using multiple keys that remain the same value: 101, 101, 101. When multiple constant keys are provided, the SAT-based attack [3] is able to find out the correct key, meaning it is also possible to achieve the level of locking based on the traditional logic locking methods. The results are shown in Table 3. 4.2 Security Evaluation The main objective of K-Gate Lock is to generate a locking mech- anism that powerful SAT-based oracle-guided attacks will not be able to decrypt. We use combinational benchmarks of ISCAS 85 [42] and EPFL Benchmarks [45] as well as sequential benchmarks of ISCAS 89 [46]. Even though our proposed solution is based on combinational circuits, it is also possible to lock sequential circuits, locking portions of the circuit before including the flip-flops. 4.2.1 Three Dynamic Keys. Now, we perform SAT-based oracle- guided attacks against the benchmarks locked with K-Gate Lock. We use NEOS [44] and RANE [47] tools to run the attacks. The encryption for each circuit is done in .bench files with our Python implementation of K-Gate Lock. The goal of this experiment is to demonstrate that with even a minimal number of keys, SAT-based attacks are unable to determine the correct keys. This limitation comes from their inherent design, which is to find only one key. The results are shown in Table 4 in which the circuits are locked with the following gate key values: • b’011 - decimal value 3 • b’100 - decimal value 4 • b’101 - decimal value 5 Table 4: Attack Results on Benchmarks with 3 Small Dynamic Keys Table 5: Attack Results on Benchmarks with Dynamic Key Sizes Scalable to the Input Sizes In the tables, different colors are used to indicate specific condi- tions. The color light red1 represents the “Condition Not Solvable” status. A deeper red2 signifies a wrong key, while the darkest red3 indicates that the attack failed. Finally, green4 denotes that the correct key has been found. This experiment shows that SAT-based attacks are not able to find the sequences of the keys but only to find the first one. The key found by the SAT solvers is a combination of the keys for the locked gates, as we see in the first test for Table 4, the key value 100 is repeated three times, which is only one of the combinations of the keys that are used to lock the gates. 4.2.2 Dynamic Key based on Input Size. For the second security experiment shown in Table 5, we explore scaling key sizes to input sizes. Specifically, for ISCAS 85 benchmarks, the gate key size is calculated using  𝑛  with 10 gates locked, resulting in a floor value  of 10 compared to the input size. In addition, we use a logarithmic scaling formula to deal with the high number of inputs in the EPFL benchmarks. While the EPFL benchmarks [45] are in .blif format, we use the ABC tool [48] to convert them to .bench files and perform the attack. The key values are generated randomly within the range dictated by the key input size for both benchmark suites. To simplify the testing process, we limit the number of gates locked to 10. This aims to approximate the size of the key as closely as possible to the input size. The experimental results highlight the challenges faced by SAT-based attacks in thwarting dynamic key locking. 4.3 Overhead Analysis Now, we analyze the overhead of K-Gate Lock. The experimental setup utilizes Cadence Genus, using low mapping and optimization effort. Circuit locking is executed using .bench files and these are converted to Verilog with the ABC tool [48]. Power measurements, as shown in Figure 2, are performed on various ISCAS 85 [42] benchmarks with the following locking parameters. • Test Run 1 : 𝑘 = 2, 𝑔 = 3, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 𝑛  • Test Run 2 : 𝑘 = 3, 𝑔 = 10, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 5 • Test Run 3 : 𝑘 = 4, 𝑔 = 10, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 5 • Test Run 4 : 𝑘 = 6, 𝑔 = 𝑎𝑙𝑙, 𝑘𝑒𝑦 𝑏𝑖𝑡 = 1 As shown in Figure 2, power consumption does not increase much, and the area increases only slightly, correlated with the num- ber of inputs and the gates locked. The missing data in the area, I/O measurements, along with power and temperature, means that the circuit is unable to lock any gates given the specific specifications, leading to the failure of the locked circuit creation. We calculated the average percentage increase using the sum of the whole test run and compared it with the original sum. These values are shown in Table 6. The highest jump in terms of power is 25.62% in Test Run 4, while the smallest jump is less than 1% in Test Run 1. 5 CONCLUSION In this paper, we proposed a novel multi-key logic locking solution called K-Gate Lock that is based on input encoding and can be fully implemented using combinational logic without the need for state-holder components. Experimental results showed that K-Gate Lock is resilient against state-of-the-art SAT-based oracle-guided attacks with minimal overhead. This offers the potential of multi- key logic locking schemes for robust hardware IP protection with reasonable overhead. ACKNOWLEDGMENT This material is based upon work supported by the National Science Foundation under Award No. 2245247.",
         "gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.02118v1.pdf",
         "extracted",
         "None",
         "STATION: State Encoding-Based Attack-Resilient Sequential Obfuscation;Machine Learning-Based Security Evaluation and Overhead Analysis of Logic Locking;CoLA: Convolutional Neural Network Model for Secure Low Overhead Logic Locking Assignment;CAS-Lock: A Security-Corruptibility Trade-off Resilient Logic Locking Scheme;Anti-SAT: Mitigating SAT Attack on Logic Locking;CycSAT-Unresolvable Cyclic Logic Encryption Using Unreachable States;Unveiling the ISCAS-85 Benchmarks: A Case Study in Reverse Engineering",
         "K-Gate Lock: Multi-Key Logic Locking Using Input Encoding Against Oracle-Guided Attacks"
        ],
        [
         "43",
         "01ec6f5401532872db572a31b5db1ca14bbb904f",
         "Gene Transfer Agents (GTAs) are mobile genetic elements derived from bacteriophages that mediate genome-wide horizontal gene transfer (HGT) in diverse groups of prokaryotes. BaGTA, encoded by all the pathogens of the genus Bartonella, is a chimeric GTA that evolved by the domestication of two phages. The run-off-replication module ROR of one phage is integrated with the capsid production, DNA packaging and lysis machinery Bgt of a second phage. Restricted to a self-sacrificing subset of the bacterial population, the position-specific DNA amplification and packaging of a genomic plasticity region enriched for genes involved in host interaction and adaptation selectively enhances the HGT frequency of these pathogenicity genes. This feature of BaGTA is considered a key innovation underlying the evolutionary success of Bartonella. Little is known, however, about the mechanism mediating the coordinated expression of the ror and bgt loci. Here, we established the regulatory hierarchy, with ror acting upstream of the capsid gene cluster bgtA-K. BrrG, encoded by the ror locus, controls the transcription of the bgtA-K operon by functioning as a processive antiterminator. This study provides the first insights into the mechanism controlling the coordinated expression of the two BaGTA modules of divergent phage origin. Beyond BaGTA, we propose that antitermination is a broadly relevant mechanism for controlling HGT by GTAs of the Alphaproteobacteria.",
         "Aleksandr Korotaev,Quirin Niggli,Valeria Congedi,C. Dehio",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/11/20/2024.11.20.624540.full.pdf",
         "None",
         "None",
         "The phage λ Q gene product: Activity of a transcription antiterminator in vitro;expression marker;*To whom correspondence should be addressed at:;experiments and Dr. Jaroslaw Sedzicki for analysis for the structural preparation of the structure models. This work was supported by the Foundation (SNSF, www.snf.ch) grant 310030B_201273 (to C.D.;conditions. This suggests that the identified conserved site is a functional -10-like element 217 essential for the BrrG-mediated antitermination;of the two BaGTA modules of divergent phage origin",
         "Transcriptional antitermination integrates the expression of loci of diverse phage origin in the chimeric Bartonella Gene Transfer Agent BaGTA"
        ],
        [
         "44",
         "01ee76d50524c8842f3ce68ef656f630485cbec1",
         "Street vendors in developing regions often lack access to portable and affordable cold storage, leading to accelerated food spoilage, financial losses, and health risks. Traditional refrigeration solutions are bulky and costly, while manual freshness assessment is error-prone. This study proposes a smart vending cart integrating IoT sensors and federated learning (FL) to address these challenges, offering real-time environmental monitoring, freshness classification, and privacy-preserving data handling. The smart vending cart incorporates IoT sensors to monitor temperature, humidity, and gas emissions. A Peltier cooling module and a humidifier maintain optimal conditions. Machine learning models classify food freshness, while federated learning ensures vendor privacy by training models locally on each cart. The study explores nine federated learning approaches to train machine learning models across multiple carts without sharing raw data, thus preserving vendor privacy. The Stacking Ensemble approach outperformed all other methods, achieving the highest accuracy, F1-Score, and Cohen’s Kappa (0.99964), with the lowest log loss (0.0022). MetaLearning and Weighted Aggregation also demonstrated high performance but with marginally higher log loss values. Personalized models performed well in heterogeneous data environments but were less effective than ensemble methods. The developed smart vending cart system effectively reduces food spoilage and enhances vendor profitability through automated freshness classification and real-time environmental control. The integration of federated learning ensures privacy, while ensemble techniques improve robustness in resource-constrained settings, offering a scalable solution for street vendors.",
         "Thompson Stephan,Padma Priya Dharishini Paramana,Chia-Chen Lin,Saurabh Agarwal,Rajan Verma",
         "\n**BLOCK**fs== 8.0**p== 0.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\nhttps://doi.org/10.1186/s40537-025-01063-3\n**BLOCK**fs== 13.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nRESEARCH\n**BLOCK**fs== 13.0**p== 0.0**b== 0.8**t== 0.2**l== 0.8**r== 0.1**\nOpen Access\n**BLOCK**fs== 11.0**p== 0.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\nThompson Stephan1, Padma Priya Dharishini Paramana2, Chia‑Chen Lin3*, Saurabh Agarwal4* and Rajan Verma5\n**BLOCK**fs== 7.5**p== 0.0**b== 0.3**t== 0.4**l== 0.1**r== 0.7**\n1 Thumbay College\nof Management and AI\nin Healthcare, Gulf Medical\nUniversity, Ajman, United Arab\nEmirates\n2 Department of Computer\nScience and Engineering, Faculty\nof Engineering and Technology,\nM. S. Ramaiah University\nof Applied Sciences, Bangalore,\nKarnataka, India\n3 Department of Computer\nScience and Information\nEngineering, National Chin‑Yi\nUniversity of Technology,\nTaichung 411, Taiwan\n4 Department of Information\nand Communication\nEngineering, Yeungnam\nUniversity, Gyeongsan 38541,\nRepublic of Korea\n5 University Centre for Research\nand Development, Chandigarh\nUniversity, Mohali, Punjab\n140413, India\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.4**l== 0.3**r== 0.1**\nAbstract\nStreet vendors in developing regions often lack access to portable and affordable\ncold storage, leading to accelerated food spoilage, financial losses, and health risks.\nTraditional refrigeration solutions are bulky and costly, while manual freshness assess‑\nment is error‑prone. This study proposes a smart vending cart integrating IoT sensors\nand federated learning (FL) to address these challenges, offering real‑time environmen‑\ntal monitoring, freshness classification, and privacy‑preserving data handling. The smart\nvending cart incorporates IoT sensors to monitor temperature, humidity, and gas emis‑\nsions. A Peltier cooling module and a humidifier maintain optimal conditions. Machine\nlearning models classify food freshness, while federated learning ensures vendor pri‑\nvacy by training models locally on each cart. The study explores nine federated learn‑\ning approaches to train machine learning models across multiple carts without sharing\nraw data, thus preserving vendor privacy. The Stacking Ensemble approach outper‑\nformed all other methods, achieving the highest accuracy, F1‑Score, and Cohen’s\nKappa (0.99964), with the lowest log loss (0.0022). MetaLearning and Weighted Aggre‑\ngation also demonstrated high performance but with marginally higher log loss values.\nPersonalized models performed well in heterogeneous data environments but were\nless effective than ensemble methods. The developed smart vending cart system\neffectively reduces food spoilage and enhances vendor profitability through auto‑\nmated freshness classification and real‑time environmental control. The integration\nof federated learning ensures privacy, while ensemble techniques improve robustness\nin resource‑constrained settings, offering a scalable solution for street vendors.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nKeywords:  Smart vending cart, Federated learning, IoT‑based freshness detection,\nData privacy, Machine learning classification, Cold storage solutions\n**BLOCK**fs== 10.3**p== 0.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nIntroduction\n**BLOCK**fs== 9.8**p== 0.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\nThe preservation of perishable goods is a critical concern in the supply chain, particu-\nlarly for street vendors who often lack access to affordable and portable cold storage\nsolutions.  In  many  developing  regions,  street  vendors  play  a  vital  role  in  providing\nfresh produce to urban populations. However, the inability to maintain optimal stor-\nage  conditions  leads  to  accelerated  spoilage  of  food  items,  resulting  in  significant\nfinancial  losses  and  potential  health  risks  to  consumers.  Traditional  refrigeration\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits\nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original\nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third\nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate‑\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or\nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://\ncreat iveco mmons. org/ licen ses/ by/4. 0/.\n**BLOCK**fs== 8.0**p== 1.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 1.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 2 of 34\n**BLOCK**fs== 9.8**p== 1.0**b== 0.5**t== 0.2**l== 0.2**r== 0.2**\nsystems  are  typically  expensive,  bulky,  and  energy-intensive,  making  them  impracti-\ncal for mobile vending operations [1]. The advent of the Internet of Things (IoT) offers\npromising opportunities to address these challenges by enabling real-time monitoring\nand control of environmental conditions. IoT-based systems can collect data on tem-\nperature,  humidity,  and  gas  emissions  within  storage  units,  allowing  for  automated\nadjustments to preserve freshness [2, 3]. However, deploying such technologies in the\ncontext of street vending requires solutions that are not only effective but also cost-\nefficient, portable, and user-friendly. Moreover, manual assessment of food freshness\nis subjective and prone to errors, underscoring the need for automated freshness clas-\nsification systems. Machine learning algorithms have demonstrated high accuracy in\ndetecting spoilage patterns based on sensor data [2, 4]. Yet, implementing centralized\nmachine learning models raises concerns about data privacy, as vendors may be reluc-\ntant to share sensitive data with external servers. Federated learning (FL) emerges as\na  pivotal  technology  that  enables  collaborative  model  training  without  the  need  to\ntransmit raw data to a central server, thereby preserving privacy [5, 6]. FL allows each\ndevice  to  train  a  local  model  on  its  data  and  share  only  model  updates,  which  are\naggregated to improve the global model. This approach is particularly suitable for IoT\napplications where data privacy and communication efficiency are paramount.\n**BLOCK**fs== 9.8**p== 1.0**b== 0.2**t== 0.5**l== 0.2**r== 0.2**\nHowever,  federated  learning  faces  challenges  in  handling  non-independent  and\nidentically  distributed  (non-IID)  data,  which  is  common  in  scenarios  where  devices\ncollect  data  under  varying  conditions  [7,  8].  Data  heterogeneity  can  lead  to  perfor-\nmance  degradation  in  the  global  model,  necessitating  advanced  aggregation  and\npersonalization  techniques  to  enhance  model  accuracy  [9].  Additionally,  resource\nconstraints on edge devices like smart vending carts require lightweight and efficient\nmodels  that  do  not  compromise  performance.  Ensemble  learning  and  meta-learn-\ning  have  shown  promise  in  improving  model  robustness  and  accuracy  in  federated\nsettings.  These  techniques  combine  multiple  models  to  leverage  their  individual\nstrengths,  mitigating  the  impact  of  data  heterogeneity  and  enhancing  generaliza-\ntion  [10].  However,  their  application  in  resource-constrained  environments  remains\nlimited  due  to  computational  demands  and  communication  overhead.  Address-\ning  imbalanced  data  is  another  critical  aspect,  especially  in  freshness  classification,\nwhere certain spoilage states may be underrepresented. Techniques like the Synthetic\nMinority Oversampling Technique (SMOTE) have been used to balance datasets and\nimprove classifier performance [11, 12]. Advanced variants of SMOTE have been pro-\nposed  to  enhance  its  effectiveness,  but  their  practicality  in  low-resource  settings  is\nstill a challenge.\n**BLOCK**fs== 9.2**p== 1.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nResearch objectives\n**BLOCK**fs== 9.8**p== 1.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nThis research aims to develop an affordable and portable smart vending cart equipped\nwith cold storage and an automated freshness classification system. The proposed solu-\ntion integrates IoT sensors for environmental monitoring, a Peltier cooling module for\ntemperature control, and a humidifier for humidity regulation. Federated learning tech-\nniques  will  be  employed  to  enhance  the  accuracy  of  freshness  classification  while  pre-\nserving data privacy. Specifically, the research will address the following objectives:\n**BLOCK**fs== 8.0**p== 2.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 2.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 3 of 34\n**BLOCK**fs== 9.8**p== 2.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\n•  Develop a cost-effective and portable cold storage system using components suit-\nable for street vending operations. The system should maintain optimal tempera-\nture and humidity levels to preserve the quality of perishable goods.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\n•  Utilize IoT sensors to collect environmental data and gas emissions indicative of\nspoilage. Implement machine learning models capable of accurately classifying the\nfreshness of perishable goods without human intervention.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\n•  Employ federated learning to train machine learning models across multiple carts\nwithout sharing raw data, thus preserving vendor privacy. Explore various feder-\nated learning approaches to handle data heterogeneity and improve model perfor-\nmance.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\n•  Investigate  ensemble  learning  and  meta-learning  methods  to  enhance  model\nrobustness  and  accuracy  in  the  federated  setting.  Assess  the  feasibility  of  these\ntechniques in resource-constrained environments.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.6**t== 0.4**l== 0.2**r== 0.2**\n•  Implement strategies such as SMOTE to handle imbalanced datasets and improve\n**BLOCK**fs== 9.8**p== 2.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\nthe classification of minority classes in freshness states.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\n•  Tackle challenges related to communication efficiency, scalability, and security to\nensure the system’s feasibility in real-world deployments. Optimize the system for\nlow computational overhead that is suitable for edge devices.\n**BLOCK**fs== 9.2**p== 2.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nSignificance of the research\n**BLOCK**fs== 9.8**p== 2.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\nBy integrating these components, the research seeks to provide a viable solution for\nstreet vendors to maintain the freshness and hygiene of perishable goods, reduce food\nspoilage,  and  minimize  financial  losses.  The  development  of  such  a  system  has  the\npotential to:\n**BLOCK**fs== 9.8**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.2**\n•  Automated  freshness  classification  ensures  that  only  consumable  goods  are  sold,\n**BLOCK**fs== 9.8**p== 2.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nprotecting public health.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\n•  Reducing  spoilage  translates  to  lower  financial  losses,  increasing  the  profitability\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nof street vending operations.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\n•  Utilizing energy-efficient components like Peltier modules and solar panels aligns\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.4**\nwith sustainability goals and reduces environmental impact.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\n•  The research contributes to the body of knowledge in IoT and federated learning,\n**BLOCK**fs== 9.8**p== 2.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\nparticularly in resource-constrained settings.\n**BLOCK**fs== 9.8**p== 2.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nWe  customized  federated  learning  algorithms  to  operate  efficiently  on  low-power\nmobile devices like smart vending carts, which is less explored in the existing litera-\nture.  Our  approach  addresses  the  challenges  of  non-IID  data  resulting  from  diverse\nenvironmental  conditions  and  product  types  across  different  carts.  Techniques  like\nmeta-learning  and  stacking  ensembles  were  explored  to  improve  model  perfor-\nmance  in  such  heterogeneous  settings. The  system  ensures  vendor  privacy  by  keep-\ning raw data localized on the carts while still benefiting from collective learning. This\naddresses privacy concerns that were not adequately handled in prior studies involv-\ning centralized data aggregation. Unlike previous work that often remains theoretical,\n**BLOCK**fs== 8.0**p== 3.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 3.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 4 of 34\n**BLOCK**fs== 9.8**p== 3.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nwe  implemented  and  tested  the  system  in  real-world  simulated  conditions  with\nresource-constrained settings. Our system demonstrates how federated learning can\nbe scaled and applied in practical scenarios, offering a feasible solution for street ven-\ndors in developing regions.\n**BLOCK**fs== 9.2**p== 3.0**b== 0.7**t== 0.3**l== 0.2**r== 0.7**\nOrganization\n**BLOCK**fs== 9.8**p== 3.0**b== 0.5**t== 0.3**l== 0.2**r== 0.2**\nThe  remainder  of  this  manuscript  is  organized  into  several  sections,  each  focusing  on\nkey aspects of the smart vending cart system and its implementation. “Literature review”\nsection  provides  a  comprehensive  literature  review,  outlining  the  current  challenges\nin  freshness  monitoring,  the  role  of  IoT  in  enhancing  vending  systems,  and  federated\nlearning’s  contribution  to  data  privacy.  “Methodology”  section  describes  the  method-\nology  adopted  for  developing  and  testing  the  smart  vending  cart,  covering  hardware\nconfiguration, data collection, and model training. It also details the federated learning\nalgorithms implemented and the experimental setup. “Integration of federated learning\nfor  the  smart  vending  cart”  section  focuses  on  the  results  obtained  from  the  system’s\ndeployment,  including  performance  metrics  for  various  machine  learning  models  and\nfederated learning approaches. In “Results and discussion” section, we present a detailed\ndiscussion comparing the effectiveness of the proposed approaches and provide insights\ninto  the  system’s  real-world  applicability.  Finally,  “  Conclusion”  section  concludes  the\nmanuscript by summarizing the key findings and proposing future research directions.\n**BLOCK**fs== 10.3**p== 3.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nLiterature review\n**BLOCK**fs== 9.8**p== 3.0**b== 0.3**t== 0.5**l== 0.2**r== 0.2**\nThe  preservation  of  perishable  goods  in  the  supply  chain,  particularly  at  the  level  of\nstreet  vendors,  poses  significant  challenges  due  to  the  lack  of  affordable  and  portable\ncold  storage  solutions.  This  issue  is  compounded  by  the  need  for  real-time  freshness\ndetection to minimize food spoilage and ensure consumer safety. Recent advancements\nin  IoT  technologies  and  federated  learning  offer  promising  avenues  to  address  these\nchallenges.  This  literature  review  explores  existing  research  on  portable  cold  storage\ntechnologies, IoT applications in freshness detection, and the role of federated learning\nin enhancing model accuracy while preserving data privacy. The review identifies gaps in\nthe current literature that the proposed research aims to fill, particularly the integration\nof these technologies into a cost-effective smart vending cart for street vendors.\n**BLOCK**fs== 9.2**p== 3.0**b== 0.3**t== 0.7**l== 0.2**r== 0.6**\nPortable cold storage technologies\n**BLOCK**fs== 9.8**p== 3.0**b== 0.1**t== 0.7**l== 0.2**r== 0.2**\nPortable  cold  storage  plays  a  crucial  role  in  preserving  the  quality  of  perishable  goods\nacross various sectors. Raju et al. [1] provide a comprehensive review of portable cold\nstorage technologies, highlighting their applications in industries such as food and bev-\nerage,  pharmaceuticals,  and  medical  sectors.  They  discuss  various  cooling  methods,\nincluding compression refrigeration, absorption refrigeration, and thermoelectric cool-\ning, emphasizing the operational efficiency and environmental impact of each method.\nThe integration of phase change materials (PCMs) [13] is also explored for stable tem-\nperature control [1]. However, the review focuses primarily on large-scale applications\nand does not address the specific needs of street vendors, such as portability, cost-effec-\ntiveness, and ease of use. Our work addresses this gap by developing a cost-effective and\nportable solution tailored for mobile vending operations.\n**BLOCK**fs== 8.0**p== 4.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 4.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 5 of 34\n**BLOCK**fs== 9.2**p== 4.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nIoT‑based freshness detection\n**BLOCK**fs== 9.8**p== 4.0**b== 0.6**t== 0.2**l== 0.2**r== 0.2**\nThe application of IoT in freshness detection has gained significant attention in recent\nyears.  Hebbar  [2]  demonstrates  the  use  of  IoT  sensors  to  collect  environmental  data\nlike  temperature,  humidity,  and  gas  emissions,  which  are  indicators  of  food  freshness\n[14, 15]. Machine learning algorithms analyze this data to detect spoilage patterns [16],\nachieving high accuracy rates. Similarly, Wahidul et al. [3] discuss the implementation\nof IoT-based smart vending machines that integrate mobile applications and cloud com-\nputing  for  real-time  inventory  management  and  user  convenience.  While  these  stud-\nies  showcase  the  potential  of  IoT  in  enhancing  operational  efficiency  and  freshness\ndetection,  they  often  overlook  the  challenges  faced  by  street  vendors,  such  as  limited\nresources and the need for affordable solutions. Studies have demonstrated the potential\nof  IoT  sensors  in  monitoring  environmental  conditions  for  freshness  detection.  How-\never,  these  solutions  often  overlook  data  privacy  concerns  and  are  not  optimized  for\nresource-constrained environments. Our system integrates IoT with federated learning\nto overcome these limitations.\n**BLOCK**fs== 9.2**p== 4.0**b== 0.5**t== 0.4**l== 0.2**r== 0.6**\nFederated learning in IoT applications\n**BLOCK**fs== 9.8**p== 4.0**b== 0.3**t== 0.5**l== 0.2**r== 0.2**\nFederated  learning  emerges  as  a  pivotal  technology  for  privacy-preserving  machine\nlearning in IoT environments. Briggs et al. [4] review federated learning as an approach\nto  perform  machine  learning  on  distributed  data  without  compromising  user  privacy\n[17]. They highlight challenges such as communication costs, data heterogeneity, and the\nneed for additional privacy protections [18]. Alam and Gupta [5] further explore feder-\nated  learning’s  role  in  the  privacy  preservation  of  IoT  devices,  emphasizing  its  ability\nto  create  robust  classifiers  without  requiring  data  disclosure.  They  provide  a  compre-\nhensive overview of federated learning mechanisms and applications, advocating for its\nadoption in IoT contexts [19]. In the context of Industrial IoT, Senthil Kumar et al. [6]\naddress the need for trustworthy federated learning frameworks that balance interpret-\nability and robustness. They propose incorporating metrics like privacy, robustness, and\nexplainability  to  ensure  secure  communication  among  devices.  However,  these  studies\nprimarily focus on industrial applications and do not consider the constraints of mobile\nand resource-limited environments like street vending carts. We extend this concept to\nlow-power devices in mobile contexts, introducing novel adaptations to handle non-IID\ndata and computational constraints.\n**BLOCK**fs== 9.2**p== 4.0**b== 0.2**t== 0.8**l== 0.2**r== 0.5**\nChallenges of data heterogeneity and non‑IID data\n**BLOCK**fs== 9.8**p== 4.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nOne of the significant challenges in federated learning is handling non-independent and\nidentically  distributed  (non-IID)  data  across  clients.  Wang  and  Li  [7]  introduce  FedS-\nmooth,  an  aggregation  algorithm  designed  to  improve  federated  learning  efficiency  in\nnon-IID  environments  by  mitigating  the  impact  of  redundant  local  models.  Similarly,\nKushwaha et al. [8] propose a Data Distribution-Aware Aggregation method that adjusts\nlocal  model  weights  based  on  deviations  from  global  data  distributions,  enhancing\nclassification  accuracy. These  approaches  aim  to  address  the  performance  degradation\ncaused by data heterogeneity, which is prevalent in real-world IoT applications. Non-IID\ndata is a significant challenge in federated learning due to diverse environmental factors\n**BLOCK**fs== 8.0**p== 5.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 5.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 6 of 34\n**BLOCK**fs== 9.8**p== 5.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nacross vending carts. While techniques like FedSmooth and data-aware aggregation have\nbeen used to manage such heterogeneity, our research introduces specific adaptations to\nenhance model performance in highly variable environments.\n**BLOCK**fs== 9.2**p== 5.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nModel aggregation and personalization techniques\n**BLOCK**fs== 9.8**p== 5.0**b== 0.5**t== 0.3**l== 0.2**r== 0.2**\nVarious  model  aggregation  and  personalization  techniques  have  been  proposed  to\nimprove  federated  learning  outcomes.  Xing  et  al.  [9]  present  a  personalized  federated\nlearning  approach  based  on  feature  fusion,  which  reduces  communication  costs  and\naccommodates  heterogeneous  client  models.  Peng  and  Long  [10]  propose  a  client-\nsupervised  federated  learning  framework  that  develops  a  single  robust  global  model\ncapable  of  effectively  personalizing  for  diverse  clients  without  extensive  adaptation.\nWhile these methods enhance model performance and adaptability, they often involve\nincreased computational complexity and may not be suitable for environments with lim-\nited resources [20, 21], such as street vending carts. Previous personalization approaches\nhave  been  effective  in  heterogeneous  IoT  environments,  but  they  often  require  high\ncomputational power. Our study adapts personalization techniques for use in low-power\nmobile devices, ensuring that computational complexity remains manageable for street\nvendors.\n**BLOCK**fs== 9.2**p== 5.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nEnsemble learning and meta‑learning approaches\n**BLOCK**fs== 9.8**p== 5.0**b== 0.3**t== 0.5**l== 0.2**r== 0.2**\nEnsemble learning and meta-learning have shown promise in improving model accuracy\nand robustness. Ensemble methods combine multiple models to enhance predictive per-\nformance, as demonstrated by Ansari Khoushabar and Ghafariasl [11] in the context of\nearly sepsis prediction. In federated learning, ensemble methods can mitigate the impact\nof  data  heterogeneity  and  improve  generalization  [22],  as  shown  by  Huang  et  al.  [23].\nHowever,  the  application  of  ensemble  and  meta-learning  approaches  in  resource-con-\nstrained  settings  remains  limited  due  to  computational  demands  and  communication\noverhead [24]. Ensemble and meta-learning methods have improved predictive perfor-\nmance in machine learning. However, their application in resource-constrained settings\nhas been limited due to computational and communication overhead. We adapted these\nmethods to work effectively in the street vending context, reducing the demands on sys-\ntem resources while maintaining high model performance.\n**BLOCK**fs== 9.2**p== 5.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\nHandling imbalanced data with SMOTE\n**BLOCK**fs== 9.8**p== 5.0**b== 0.1**t== 0.7**l== 0.2**r== 0.2**\nImbalanced  data  is  a  common  issue  in  machine  learning,  affecting  model  perfor-\nmance, particularly in minority class prediction. The Synthetic Minority Oversampling\nTechnique  (SMOTE)  [25]  is  widely  used  to  address  this  challenge.  Mohanty  et  al.  [12]\nintroduce  Quantum-SMOTE,  leveraging  quantum  computing  to  enhance  SMOTE’s\neffectiveness.  Shen  et  al.  [26]  propose  BO-SMOTE,  a  Bayesian  optimization-based\nSMOTE  variant  that  improves  synthetic  sample  generation.  These  advanced  SMOTE\ntechniques  enhance  classifier  performance  but  may  not  be  practical  for  deployment\nin  environments  with  limited  computational  capabilities.  Imbalanced  data  poses  sig-\nnificant  challenges  for  machine  learning,  particularly  for  the  accurate  prediction  of\nminority classes. While advanced SMOTE techniques exist, they may be too computa-\ntionally intensive for street vending applications. Instead, we apply a simplified version\n**BLOCK**fs== 8.0**p== 6.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 6.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 7 of 34\n**BLOCK**fs== 9.8**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nof SMOTE, suitable for resource-limited environments, to balance data effectively with-\nout overwhelming computational resources.\n**BLOCK**fs== 9.2**p== 6.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nGaps in the existing literature\n**BLOCK**fs== 9.8**p== 6.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nThe review of current literature reveals several gaps that the proposed research aims to\naddress:\n**BLOCK**fs== 9.8**p== 6.0**b== 0.7**t== 0.3**l== 0.2**r== 0.2**\n•  While portable cold storage technologies exist, there is a scarcity of solutions tailored\nto the specific needs of street vendors. Existing studies focus on large-scale applica-\ntions and do not consider constraints like cost, portability, and ease of use [1].\n**BLOCK**fs== 9.8**p== 6.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\n•  Most IoT and federated learning applications target industrial settings with substan-\ntial resources [4–6]. There is a lack of research on implementing these technologies\nin mobile, resource-limited contexts like street vending carts.\n**BLOCK**fs== 9.8**p== 6.0**b== 0.5**t== 0.4**l== 0.2**r== 0.2**\n•  While IoT-based freshness detection systems exist [2, 3], they often do not incorpo-\nrate privacy-preserving techniques like federated learning. Additionally, existing fed-\nerated learning studies do not focus on freshness classification in perishable goods.\n•  The  challenge  of  non-IID  data  is  well-documented  [7,  8],  but  solutions  are  often\ncomputationally  intensive  and  not  suitable  for  deployment  on  devices  with  limited\nprocessing power.\n**BLOCK**fs== 9.8**p== 6.0**b== 0.5**t== 0.5**l== 0.2**r== 0.2**\n•  Although  ensemble  and  meta-learning  methods  improve  model  performance  [10],\ntheir  application  in  federated  learning  for  edge  devices  like  smart  vending  carts\nremains underexplored.\n**BLOCK**fs== 9.8**p== 6.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\n•  Studies  that  propose  advanced  federated  learning  techniques  often  overlook  prac-\ntical issues such as communication efficiency, scalability, and security in real-world\ndeployments [9, 10].\n**BLOCK**fs== 9.2**p== 6.0**b== 0.3**t== 0.6**l== 0.2**r== 0.6**\nMethodology\nStudy design and setup\n**BLOCK**fs== 9.8**p== 6.0**b== 0.1**t== 0.7**l== 0.2**r== 0.2**\nThe objective of this study was to develop and assess a smart vending cart system inte-\ngrating  IoT  sensors  and  federated  learning  for  automated  freshness  monitoring  in\nresource-constrained environments. The system was evaluated using a simulated envi-\nronment  designed  to  replicate  the  diverse  conditions  encountered  by  street  vendors,\nparticularly in developing regions. Ten identical smart vending carts equipped with IoT\nsensors acted as clients within the federated learning framework. These carts were simu-\nlated to operate in different virtual locations, introducing the necessary heterogeneity in\ndata collection to mimic variability in environmental conditions across different areas.\nData collection occurred over a continuous seven-day period in the simulation, during\nwhich environmental factors were recorded at five-minute intervals, resulting in approx-\nimately 2016 instances per cart. The carts were equipped with virtual sensors for moni-\ntoring  temperature  (DHT11),  humidity,  and  gas  emissions  (MQ2  for  Hydrogen,  MQ9\nfor Carbon Monoxide, MQ135 for Ammonia, and MQ138 for Toluene), all indicative of\nfood freshness. Actuators such as Peltier cooling modules and humidifier modules were\nsimulated to control the temperature and humidity based on sensor data. In the feder-\nated learning setup, each simulated cart functioned as an individual client, training local\n**BLOCK**fs== 8.0**p== 7.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 7.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 8 of 34\n**BLOCK**fs== 9.8**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nmodels  on  its  data.  The  local  models  were  periodically  updated  and  sent  to  a  central\nserver  for  aggregation.  This  approach  ensured  data  privacy  and  allowed  us  to  test  the\nsystem’s performance in a controlled yet realistic virtual environment.\n**BLOCK**fs== 9.2**p== 7.0**b== 0.8**t== 0.2**l== 0.2**r== 0.7**\nControl variables\n**BLOCK**fs== 9.8**p== 7.0**b== 0.5**t== 0.3**l== 0.2**r== 0.2**\nTo ensure consistency and validity in the experimental design, several control variables\nwere maintained across all smart vending carts. All carts were equipped with the same\nhardware  configuration,  including  identical  sensors  (temperature,  humidity,  and  gas),\nmicrocontrollers  (NodeMCU),  and  cooling  components  (Peltier  modules  and  humidi-\nfiers), ensuring that hardware variability did not influence the results. All sensors under-\nwent  a  uniform  calibration  process  using  known  standards  to  guarantee  accurate  and\nconsistent data collection across the carts. The carts were configured to operate from 8\nAM to 6 PM daily, capturing customer interactions and environmental data. However,\nsensors continued to monitor environmental changes over 24 h to ensure data collection\nreflected spoilage processes even outside operational hours. The data collection interval\nwas set to five minutes across all carts to maintain temporal consistency. Product types\nand quantities were varied intentionally across carts to introduce diversity and simulate\nreal-world conditions encountered by street vendors. Furthermore, placing carts in dif-\nferent city locations allowed for exposure to varying environmental conditions such as\ntemperature fluctuations, humidity, and air quality, ensuring the data reflected the het-\nerogeneity found in real-world street vending scenarios.\n**BLOCK**fs== 9.2**p== 7.0**b== 0.5**t== 0.5**l== 0.2**r== 0.6**\nOverview of the smart vending cart\n**BLOCK**fs== 9.8**p== 7.0**b== 0.3**t== 0.6**l== 0.2**r== 0.2**\nThe transformation of a traditional vending cart into a smart vending cart with cold\nstorage  was  achieved  by  regulating  the  temperature  and  humidity  inside  the  cart.\nFigure 1 illustrates the overall system design, including the temperature and humid-\nity  sensors,  gas  sensors,  Peltier  cooling  module,  humidifier,  and  machine  learning\nmodel  for  classifying  freshness.  In  summer  conditions,  solar  panels  provide  power\nto the cart, supported by batteries, to ensure continuous operation. Sensor data was\n**BLOCK**fs== 8.0**p== 7.0**b== 0.1**t== 0.9**l== 0.2**r== 0.5**\nFig. 1  Overall block diagram of the smart vending cart\n**BLOCK**fs== 8.0**p== 8.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 8.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 9 of 34\n**BLOCK**fs== 9.8**p== 8.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\ncontinuously fed into the Peltier cooling and humidifier modules, adjusting tempera-\nture and humidity levels accordingly. The freshness of perishable items was classified\nsuch  as  Excellent,  Good,  Average,  Bad,  or  Poor,  using  a  machine  learning  classifica-\ntion model. Control actions, whether manual or automatic, were taken based on these\nclassifications to ensure optimal conditions were maintained within the cart.\n**BLOCK**fs== 9.2**p== 8.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nComponents of the smart vending cart\n**BLOCK**fs== 9.8**p== 8.0**b== 0.5**t== 0.3**l== 0.2**r== 0.2**\nThe  physical  parameters  critical  to  maintaining  the  freshness  of  perishable  goods\nwere monitored using a series of sensors and control modules. The different views of\nthe smart vending cart with cold storage are shown in Fig. 2. On sunny days, the carts\nare  powered  directly  by  solar  panels  mounted  on  the  canopy,  which  simultaneously\ncharge the batteries. Under cloudy conditions, the carts rely on both solar power and\nbattery backup as needed. This adaptive power management system enables the carts\nto respond effectively to varying weather conditions, ensuring efficient energy usage\nthrough seamless switching between power sources. The gas sensor, temperature sen-\nsor,  and  humidity  sensor  are  factory-calibrated  prior  to  installation  using  standard\nreference  materials  and  controlled  conditions.  Recalibration  of  the  sensors  is  con-\nducted quarterly or upon detection of any discrepancies. Additionally, the sensor sur-\nfaces are cleaned on a weekly basis using suitable materials to remove dust and debris,\nensuring  accurate  and  reliable  performance.  Physical  stress  testing  has  not  yet  been\nconducted on the vending cart. However, the design prioritizes durability intended to\nhandle diverse environmental conditions.\n**BLOCK**fs== 8.0**p== 8.0**b== 0.1**t== 0.9**l== 0.2**r== 0.4**\nFig. 2  Different views of the smart vending cart with cold storage\n**BLOCK**fs== 8.0**p== 9.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 9.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 10 of 34\n**BLOCK**fs== 8.0**p== 9.0**b== 0.7**t== 0.3**l== 0.2**r== 0.6**\nFig. 3  Peltier cooling module\n**BLOCK**fs== 8.0**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nFig. 4  Humidifier module\n**BLOCK**fs== 9.2**p== 9.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nPeltier cooling module\n**BLOCK**fs== 9.8**p== 9.0**b== 0.3**t== 0.5**l== 0.2**r== 0.2**\nMaintaining  an  optimal  temperature  is  essential  for  preventing  spoilage.  The  Pel-\ntier  cooling  module,  shown  in  Fig.  3,  was  selected  for  its  advantages  over  traditional\ncompressor-based  systems,  which  use  harmful  chemicals. The  Peltier  module  is  small,\nportable, and requires minimal maintenance, making it ideal for use in mobile vending\ncarts. The Peltier module is well-suited for small-scale cooling applications, offering an\neco-friendly  solution  with  minimal  maintenance  needs.  Its  overall  costs  are  lower  for\nsmaller  applications,  and  maintenance  expenses  are  significantly  reduced  compared  to\ntraditional cooling methods. Additionally, it delivers direct spot cooling with low power\nconsumption.\n**BLOCK**fs== 9.2**p== 9.0**b== 0.3**t== 0.7**l== 0.2**r== 0.7**\nHumidifier module\n**BLOCK**fs== 9.8**p== 9.0**b== 0.2**t== 0.7**l== 0.2**r== 0.2**\nExcess moisture can lead to bacterial growth, compromising the freshness of goods. The\nhumidifier  module,  depicted  in  Fig.  4,  regulated  the  humidity  level  by  dispersing  fine\nwater particles, ensuring a moisture-controlled environment without wetness.\n**BLOCK**fs== 9.2**p== 9.0**b== 0.2**t== 0.8**l== 0.2**r== 0.7**\nMicrocontroller unit\n**BLOCK**fs== 9.8**p== 9.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nThe  NodeMCU  microcontroller,  shown  in  Fig.  5,  acted  as  the  processing  hub  for  the\nsmart vending cart. It was responsible for acquiring sensor data, processing it, and send-\ning updates to the cloud, enabling real-time freshness monitoring and control actions.\n**BLOCK**fs== 9.2**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nGas sensors\n**BLOCK**fs== 9.8**p== 9.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nThe MQ2, MQ9, MQ135, and MQ138 gas sensors were used to detect gases such as\nhydrogen, carbon monoxide, ammonia, and toluene, which are key indicators of food\n**BLOCK**fs== 8.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 10.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 11 of 34\n**BLOCK**fs== 8.0**p== 10.0**b== 0.6**t== 0.4**l== 0.2**r== 0.4**\nFig. 5  Interconnection of components in the smart vending cart\n**BLOCK**fs== 8.0**p== 10.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nFig. 6  MQ2, MQ9, MQ135, and MQ138 gas sensors\n**BLOCK**fs== 9.8**p== 10.0**b== 0.3**t== 0.7**l== 0.2**r== 0.2**\nspoilage. Figure 6 shows these sensors, which provide real-time feedback to the sys-\ntem for freshness classification.\n**BLOCK**fs== 9.2**p== 10.0**b== 0.2**t== 0.8**l== 0.2**r== 0.6**\nWorking of the smart vending cart\n**BLOCK**fs== 9.8**p== 10.0**b== 0.1**t== 0.8**l== 0.2**r== 0.2**\nThe  system’s  operation  relied  on  continuous  feedback  from  the  sensors  to  regulate\ntemperature  and  humidity  levels.  The  DHT11  sensor  measured  temperature  and\nhumidity, while the gas sensors (MQ2, MQ9, MQ135, and MQ138) monitored spoil-\nage-related  gases.  The  machine  learning  classification  model  processed  this  sensor\ndata to determine the freshness state of items in the cart. The system communicated\nwith  the  cloud  for  centralized  control  actions  based  on  the  state  of  the  fresh  items.\nFour possible actions were performed depending on the temperature, humidity, and\nfreshness state, as described in Algorithm 1.\n**BLOCK**fs== 8.0**p== 11.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 11.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 12 of 34\n**BLOCK**fs== 8.0**p== 11.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nAlgorithm 1  Automated Smart Vending Cart Control System\n**BLOCK**fs== 9.2**p== 11.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nCommunication and power management\n**BLOCK**fs== 9.8**p== 11.0**b== 0.1**t== 0.6**l== 0.2**r== 0.2**\nEffective  communication  and  power  management  were  critical  considerations  in  the\ndesign  and  operation  of  the  smart  vending  carts,  given  their  resource  constraints  and\nthe  need  for  reliable  data  transmission.  To  manage  communication  delays,  we  utilized\nthe  existing  Wi-Fi  capabilities  of  the  NodeMCU  microcontrollers  to  establish  stable\nconnections  with  the  central  server.  To  optimize  performance,  we  implemented  data\ncompression  techniques  for  model  updates  and  minimized  the  size  of  data  packets  by\ntransmitting only essential information required for the federated learning process. The\ncarts were equipped with solar panels mounted on the canopy, which provided power\nduring  daylight  hours  and  simultaneously  charged  the  batteries.  Under  cloudy  con-\nditions or at night, the carts switched seamlessly to battery power. This setup ensured\ncontinuous operation while maximizing the use of renewable energy sources. Addition-\nally, we incorporated power-efficient programming practices for the NodeMCU micro-\ncontrollers.  The  devices  were  programmed  to  perform  necessary  computations  and\ndata transmissions efficiently, avoiding unnecessary processing that could drain power.\nThe  Peltier  cooling  modules  and  humidifiers  operated  based  on  the  control  algorithm\ndetailed  in  Algorithm  1,  which  already  includes  turning  off  these  modules  when  opti-\nmal conditions are met to conserve energy. By maintaining consistent data transmission\n**BLOCK**fs== 8.0**p== 12.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 12.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 13 of 34\n**BLOCK**fs== 9.8**p== 12.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nintervals  and  integrating  these  power  management  strategies,  we  ensured  that  com-\nmunication delays were minimized and power consumption was kept within the opera-\ntional capabilities of the carts.\n**BLOCK**fs== 10.3**p== 12.0**b== 0.7**t== 0.2**l== 0.2**r== 0.3**\nIntegration of federated learning for the smart vending cart\n**BLOCK**fs== 9.8**p== 12.0**b== 0.6**t== 0.3**l== 0.2**r== 0.2**\nFederated learning enables collaboration among multiple parties to train a shared model\nwithout sharing their data. It is a privacy-preserving machine learning approach that is\nwell-suited  for  scenarios  where  data  privacy  and  security  are  essential,  such  as  in  the\ncontext of smart vending carts connected via the Internet of Vehicles (IoV). The smart\nvending cart is connected to a network of other smart carts through the IoV. This con-\nnection allows for federated learning to take place among the carts. The federated learn-\ning  process  involves  each  cart  training  its  classification  model  on  its  local  dataset  and\nthen sharing the model updates with a central server. The shared models are then aggre-\ngated to select the best model, which is further used to improve the accuracy of the clas-\nsification  of  the  freshness  of  food  items.  The  federated  learning  process  is  performed\nperiodically to improve the accuracy of the model continuously.\n**BLOCK**fs== 9.8**p== 12.0**b== 0.4**t== 0.4**l== 0.2**r== 0.2**\nThe integration of federated learning is a key component of the proposed solution. It\nenables the smart carts to improve their classification accuracy while preserving the pri-\nvacy of the vendors’ data. This collective intelligence allows the carts to learn from each\nother’s experiences and data, resulting in a more accurate classification of the freshness\nand hygiene of the food sold in the vending carts. Moreover, the use of federated learning\nand the IoV can lead to more efficient power usage and longer battery life for the smart\ncarts. By sharing resources and models, smart carts can optimize their power usage and\nminimize unnecessary communication, leading to more efficient use of energy.\n**BLOCK**fs== 9.2**p== 12.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nFederated learning approaches\n**BLOCK**fs== 9.8**p== 12.0**b== 0.1**t== 0.6**l== 0.2**r== 0.2**\nThis research implements nine federated learning algorithms, each specifically tailored\nfor the smart vending cart network. This section explains how each approach optimizes\nthe classification of food freshness and contributes to enhancing the overall performance\nof  the  smart  vending  cart  system.  The  common  parameters  for  the  federated  learning\nalgorithms  used  in  this  study  were  kept  consistent  across  all  methods  to  ensure  a  fair\ncomparison. The number of clients, denoted by K , represents the number of participat-\ning smart vending carts, which was set to 10 clients. Each client independently trained\nits  local  model  and  contributed  to  the  global  model  through  periodic  communication\nwith the central server. The number of communication rounds, denoted by T , refers to\nhow many times the local models communicate with the central server for aggregation\nand  update  purposes.  In  this  case,  7  communication  rounds  were  conducted  between\nthe clients and the server, ensuring sufficient interaction for model improvement. Each\nclient  trained  its  model  over  a  set  number  of  local  epochs,  denoted  by  E .  The  local\nepochs  represent  the  number  of  times  the  model  trains  on  its  local  data  before  send-\ning  updates  to  the  server.  In  this  study,  each  client  was  configured  to  perform  5  local\nepochs during each round of training, allowing sufficient local learning before the global\nmodel aggregation. The learning rate, denoted by η , controls the rate at which the model\nweights are updated during the training process. For all the algorithms, the learning rate\n**BLOCK**fs== 8.0**p== 13.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 13.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 14 of 34\n**BLOCK**fs== 9.8**p== 13.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nwas set to η = 0.01\n, ensuring gradual and stable model updates throughout the training\nprocess. These  parameter  settings  formed  the  basis  for  comparing  the  performance  of\nthe federated learning algorithms in this study.\n**BLOCK**fs== 9.8**p== 13.0**b== 0.6**t== 0.2**l== 0.2**r== 0.2**\nThe Federated Averaging (FedAvg) approach shown in Fig. 7a involves a server coor-\ndinating with two clients for distributed model training, where the server sends a global\nmodel to each client, who performs local training and subsequently sends model updates\nback  to  the  server,  preserving  data  privacy  by  allowing  clients  to  train  independently\nwithout  sharing  raw  data.  In  the  Weighted  Aggregation  approach  depicted  in  Fig.  7b,\na  server  communicates  with  two  clients,  with  each  client  receiving  the  global  model,\nperforming  local  training,  and  then  sending  back  a  weighted  update  based  on  their\nperformance  to  ensure  that  contributions  are  proportional  to  their  local  model’s  qual-\nity, thereby improving the accuracy of the aggregated model. Figure 7c shows the Meta-\nLearning (Stacking the Models) approach, where a server distributes a global model to\ntwo clients, who generate predictions based on local data, which are then sent to a meta-\nmodel for stacking, producing a more robust final model by leveraging individual client\n**BLOCK**fs== 8.0**p== 13.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nFig. 7  Different approaches used in the study. a Federated Averaging (FedAvg), b Weighted Aggregation,\nc Meta‑Learning (Stacking the Models), d Model Personalization (Global), e Model Personalization\n(Personalized), f Federated Stochastic Gradient Descent (FedSGD), g Ensemble of Global Models, h Handling\nData Imbalance with SMOTE, i Stacking Ensemble Approach\n**BLOCK**fs== 8.0**p== 14.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 14.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 15 of 34\n**BLOCK**fs== 9.8**p== 14.0**b== 0.4**t== 0.2**l== 0.2**r== 0.2**\nmodel  strengths  to  enhance  overall  performance.  The  Model  Personalization  (Global)\napproach  illustrated  in  Fig.  7d  shows  a  server  distributing  a  global  model  to  each  cli-\nent, who then locally personalizes it while still contributing updates back to the server,\nthereby balancing a general global model with adaptations to local data for better per-\nformance.  In  the  Model  Personalization  (Personalized)  approach  shown  in  Fig.  7e,  the\nserver sends a global model to two clients, who fine-tune it locally based on their own\nunique datasets, creating personalized models that cater specifically to the requirements\nof each client and improving relevance in heterogeneous environments. Figure 7f depicts\nthe  Federated  Stochastic  Gradient  Descent  (FedSGD)  approach,  where  a  server  shares\nthe global model with two clients, who compute gradients based on local data and send\nthese gradients back to the server for updating the global model, maintaining local data\nprivacy while enabling collaborative learning. The Ensemble of Global Models approach\ndepicted in Fig. 7g illustrates multiple server models trained and updated independently\nby different clients, with results aggregated through an ensemble voting mechanism to\nleverage diverse model perspectives, enhancing robustness and accuracy. In Fig. 7h, the\nHandling Data Imbalance with SMOTE approach shows a server sending a global model\nto  clients,  who  apply  the  SMOTE  technique  locally  to  balance  their  datasets  before\ntraining,  thus  improving  model  performance  by  ensuring  adequate  representation  of\nminority  classes  and  aggregating  these  updates  to  form  a  better  global  model.  Finally,\nthe Stacking Ensemble approach shown in Fig. 7i demonstrates the server distributing\na global model to two clients, who generate local predictions that are aggregated by an\naggregator,  which  serves  as  input  to  a  meta-model  to  produce  a  final  stacked  model,\neffectively optimizing predictive performance by combining individual model outputs.\n**BLOCK**fs== 9.2**p== 14.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nFederated averaging (FedAvg)\n**BLOCK**fs== 9.8**p== 14.0**b== 0.2**t== 0.6**l== 0.2**r== 0.2**\nFederated Averaging (FedAvg) is one of the foundational federated learning algorithms.\nIn  this  approach,  multiple  clients  independently  train  models  on  their  local  datasets.\nAfter a predefined number of training iterations, the local model updates are sent to a\ncentral  server.  The  server  averages  these  updates  to  produce  a  global  model,  which  is\nthen  distributed  back  to  the  clients  for  further  training.  This  process  is  detailed  in\nAlgorithm 2. For the Federated Averaging (FedAvg) algorithm, the initial global model\nparameters, denoted as θ0 , were initialized at the central server. Each client had its local\nmodel parameters, θk , which were updated locally at each client based on the data avail-\n∇Lk (θk ) , was computed\nable. The gradient of the loss function for client k , denoted as\nusing  Stochastic  Gradient  Descent  (SGD).  After  the  local  updates,  the  global  model\nparameters, θt , were aggregated by averaging the local models from all clients.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 15.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 16 of 34\n**BLOCK**fs== 8.0**p== 15.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nAlgorithm 2  Federated Averaging (FedAvg)\n**BLOCK**fs== 9.2**p== 15.0**b== 0.5**t== 0.5**l== 0.2**r== 0.7**\nWeighted aggregation\n**BLOCK**fs== 9.8**p== 15.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\nWeighted Aggregation is an advanced variant of FedAvg. Instead of simply averaging\nthe model parameters from all clients, each client’s contribution to the global model\nis weighted based on its performance. Clients that achieve higher validation metrics\non  their  local  datasets  contribute  more  to  the  global  model.  The  detailed  process  is\nshown in Algorithm 3. For the Weighted Aggregation approach, each client computed\na  validation  metric,  denoted  as  Mk ,  based  on  the  local  validation  data.  The  weight\nassigned  to  each  client,  wk ,  was  proportional  to  its  validation  metric  Mk .  The  total\nweight accumulated from all clients was represented by Wtotal , which was the sum of\nall  client  weights.  The  local  model  parameters, θk ,  were  the  same  as  in  FedAvg,  but\nduring  aggregation,  they  were  weighted  based  on  the  client  validation  metrics.  The\naggregated global model parameters, θt , were adjusted accordingly.\n**BLOCK**fs== 8.0**p== 15.0**b== 0.3**t== 0.7**l== 0.2**r== 0.5**\nAlgorithm 3  Weighted Aggregation in Federated Learning\n**BLOCK**fs== 8.0**p== 16.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 16.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 17 of 34\n**BLOCK**fs== 9.2**p== 16.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nMeta‑learning (stacking the models)\n**BLOCK**fs== 9.8**p== 16.0**b== 0.7**t== 0.2**l== 0.2**r== 0.2**\nMeta-Learning  involves  stacking  the  outputs  of  multiple  local  models  to  create  a  meta-\nmodel. The meta-model learns how to best combine the predictions from the local models\nto make a final prediction. This approach leverages the strengths of individual models and\ncan significantly improve overall performance. The process is detailed in Algorithm 4. In\nthe Meta-Learning (Stacking) approach, each client generated predictions, Pk , from its local\nmodel after training. These predictions from all clients were stacked into one meta-data-\nset, denoted as Pstack . The meta-model parameters, θmeta , were then learned by training on\nthe stacked predictions, allowing the combination of client predictions for more accurate\nresults.\n**BLOCK**fs== 8.0**p== 16.0**b== 0.7**t== 0.3**l== 0.2**r== 0.5**\nAlgorithm 4  Meta‑Learning with Stacking in Federated Learning\n**BLOCK**fs== 9.2**p== 16.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nModel personalization (global)\n**BLOCK**fs== 9.8**p== 16.0**b== 0.2**t== 0.6**l== 0.2**r== 0.2**\nIn this approach, a global model is trained by aggregating the local models from all the cli-\nents. However, unlike standard federated learning, where the global model is used as-is by\nall clients, this global model represents a generalized version that attempts to capture the\ncommon characteristics across all clients’ datasets. This model is the same for all clients,\nmeaning  it  does  not  account  for  the  unique  characteristics  or  data  distributions  of  indi-\nvidual  clients.  It  is  effective  when  the  data  across  clients  is  somewhat  homogeneous  but\nmay not perform as well in cases where the data distributions are very different. The entire\nprocess is outlined in Algorithm 5. Model Personalization (Global) started with the initial-\nization  of  global  model  parameters, θ0 ,  at  the  server,  similar  to  FedAvg.  The  local  model\nparameters, θk , were updated locally for each client. The gradient of the loss function for\n∇Lk (θk ) , was calculated similarly to FedAvg. The global model parameters, θt , were\nclient k ,\naggregated, remaining the same for all clients.\n**BLOCK**fs== 8.0**p== 17.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 17.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 18 of 34\n**BLOCK**fs== 8.0**p== 17.0**b== 0.8**t== 0.2**l== 0.2**r== 0.6**\nAlgorithm 5  Model Personalization (Global)\n**BLOCK**fs== 9.2**p== 17.0**b== 0.5**t== 0.4**l== 0.2**r== 0.6**\nModel personalization (personalized)\n**BLOCK**fs== 9.8**p== 17.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\nThis  approach  goes  one  step  further  than  the  global  model  by  fine-tuning  the  global\nmodel on each client’s local data after it has been aggregated. This creates a personalized\nmodel for each client. This personalized model is tailored to the specific data distribu-\ntion of each client, improving performance on that client’s dataset. It is particularly use-\nful in heterogeneous data environments where the data on each client is different, as the\npersonalized model can better adapt to the local characteristics of the client’s data. The\nentire process is outlined in Algorithm 6. For Model Personalization (Personalized), the\nglobal model parameters, θ0 , were initialized at the server, but each client had personal-\nized model parameters, θpk , which were fine-tuned on each client’s local data. The fine-\ntuning occurred for a set number of epochs, denoted as Ep , which was set to 3 epochs.\n**BLOCK**fs== 8.0**p== 18.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 18.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 19 of 34\n**BLOCK**fs== 8.0**p== 18.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nAlgorithm 6  Model Personalization in Federated Learning\n**BLOCK**fs== 9.2**p== 18.0**b== 0.5**t== 0.5**l== 0.2**r== 0.5**\nFederated stochastic gradient descent (FedSGD)\n**BLOCK**fs== 9.8**p== 18.0**b== 0.4**t== 0.5**l== 0.2**r== 0.2**\nFederated Stochastic Gradient Descent focuses on averaging the gradients computed by\neach client. Clients send their gradients to the central server, which averages them and\nupdates  the  global  model.  The  detailed  steps  are  outlined  in  Algorithm  7.  The  Feder-\nated SGD (FedSGD) algorithm focused on computing the gradient of the loss function\n∇Lk (θk ) , at the client level. These gradients were then sent to the server,\nfor each client,\nwhere the global model parameters, θt , were updated by aggregating the gradients from\nall clients.\n**BLOCK**fs== 8.0**p== 18.0**b== 0.4**t== 0.6**l== 0.2**r== 0.5**\nAlgorithm 7  Federated Stochastic Gradient Descent (FedSGD)\n**BLOCK**fs== 9.2**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.6**\nEnsemble of global models\n**BLOCK**fs== 9.8**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.2**\nMultiple global models, trained independently, are combined to form an ensemble. This\napproach leverages the strengths of different models to improve overall performance, as\ndescribed in Algorithm 8. In the Ensemble of Global Models approach, multiple global\n**BLOCK**fs== 8.0**p== 19.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nStephan et al. Journal of Big Data           (2025) 12:33\n**BLOCK**fs== 8.0**p== 19.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nPage 20 of 34\n**BLOCK**fs== 9.8**p== 19.0**b== 0.8**t== 0.2**l== 0.2**r== 0.2**\nmodels  were  trained  independently.  The  number  of  global  models  was  represented  by\nM . Each global model had its parameters, θm , with separate parameters for each model.\nThe final ensemble model predictions, Pensemble , were aggregated using majority voting\nacross the multiple models.\n**BLOCK**fs== 8.0**p== 19.0**b== 0.8**t== 0.2**l== 0.2**r== 0.5**\nAlgorithm 8  Ensemble of Global Models in Federated Learning\n**BLOCK**fs== 9.2**p== 19.0**b== 0.4**t== 0.6**l== 0.2**r== 0.6**\nHandling data imbalance with SMOTE\n**BLOCK**fs== 9.8**p== 19.0**b== 0.3**t== 0.6**l== 0.2**r== 0.2**\nSMOTE  (Synthetic  Minority  Over-sampling  Technique)  addresses  class  imbalance  by\ngenerating synthetic examples for the minority class. In federated learning, SMOTE is\napplied locally on each client’s dataset to balance the classes before training. The proce-\ndure for applying SMOTE in federated learning is outlined in Algorithm 9. The Handling\nData Imbalance (SMOTE) approach used synthetic examples generated for underrepre-\nsented classes. These synthetic examples were locally applied to the client datasets using\nspecific SMOTE parameters. The local model parameters, θk , were then updated on the\nbalanced data. This ensured that the model could effectively handle imbalanced datasets\nduring training.",
         "Thompson Stephan1, Padma Priya Dharishini Paramana2, Chia‑Chen Lin3*, Saurabh Agarwal4* and Rajan Verma5 Abstract Street vendors in developing regions often lack access to portable and affordable cold storage, leading to accelerated food spoilage, financial losses, and health risks. Traditional refrigeration solutions are bulky and costly, while manual freshness assess‑ ment is error‑prone. This study proposes a smart vending cart integrating IoT sensors and federated learning (FL) to address these challenges, offering real‑time environmen‑ tal monitoring, freshness classification, and privacy‑preserving data handling. The smart vending cart incorporates IoT sensors to monitor temperature, humidity, and gas emis‑ sions. A Peltier cooling module and a humidifier maintain optimal conditions. Machine learning models classify food freshness, while federated learning ensures vendor pri‑ vacy by training models locally on each cart. The study explores nine federated learn‑ ing approaches to train machine learning models across multiple carts without sharing raw data, thus preserving vendor privacy. The Stacking Ensemble approach outper‑ formed all other methods, achieving the highest accuracy, F1‑Score, and Cohen’s Kappa (0.99964), with the lowest log loss (0.0022). MetaLearning and Weighted Aggre‑ gation also demonstrated high performance but with marginally higher log loss values. Personalized models performed well in heterogeneous data environments but were less effective than ensemble methods. The developed smart vending cart system effectively reduces food spoilage and enhances vendor profitability through auto‑ mated freshness classification and real‑time environmental control. The integration of federated learning ensures privacy, while ensemble techniques improve robustness in resource‑constrained settings, offering a scalable solution for street vendors. Keywords:  Smart vending cart, Federated learning, IoT‑based freshness detection, Data privacy, Machine learning classification, Cold storage solutions The preservation of perishable goods is a critical concern in the supply chain, particu- larly for street vendors who often lack access to affordable and portable cold storage solutions.  In  many  developing  regions,  street  vendors  play  a  vital  role  in  providing fresh produce to urban populations. However, the inability to maintain optimal stor- age  conditions  leads  to  accelerated  spoilage  of  food  items,  resulting  in  significant financial  losses  and  potential  health  risks  to  consumers.  Traditional  refrigeration systems  are  typically  expensive,  bulky,  and  energy-intensive,  making  them  impracti- cal for mobile vending operations [1]. The advent of the Internet of Things (IoT) offers promising opportunities to address these challenges by enabling real-time monitoring and control of environmental conditions. IoT-based systems can collect data on tem- perature,  humidity,  and  gas  emissions  within  storage  units,  allowing  for  automated adjustments to preserve freshness [2, 3]. However, deploying such technologies in the context of street vending requires solutions that are not only effective but also cost- efficient, portable, and user-friendly. Moreover, manual assessment of food freshness is subjective and prone to errors, underscoring the need for automated freshness clas- sification systems. Machine learning algorithms have demonstrated high accuracy in detecting spoilage patterns based on sensor data [2, 4]. Yet, implementing centralized machine learning models raises concerns about data privacy, as vendors may be reluc- tant to share sensitive data with external servers. Federated learning (FL) emerges as a  pivotal  technology  that  enables  collaborative  model  training  without  the  need  to transmit raw data to a central server, thereby preserving privacy [5, 6]. FL allows each device  to  train  a  local  model  on  its  data  and  share  only  model  updates,  which  are aggregated to improve the global model. This approach is particularly suitable for IoT applications where data privacy and communication efficiency are paramount. However,  federated  learning  faces  challenges  in  handling  non-independent  and identically  distributed  (non-IID)  data,  which  is  common  in  scenarios  where  devices collect  data  under  varying  conditions  [7,  8].  Data  heterogeneity  can  lead  to  perfor- mance  degradation  in  the  global  model,  necessitating  advanced  aggregation  and personalization  techniques  to  enhance  model  accuracy  [9].  Additionally,  resource constraints on edge devices like smart vending carts require lightweight and efficient models  that  do  not  compromise  performance.  Ensemble  learning  and  meta-learn- ing  have  shown  promise  in  improving  model  robustness  and  accuracy  in  federated settings.  These  techniques  combine  multiple  models  to  leverage  their  individual strengths,  mitigating  the  impact  of  data  heterogeneity  and  enhancing  generaliza- tion  [10].  However,  their  application  in  resource-constrained  environments  remains limited  due  to  computational  demands  and  communication  overhead.  Address- ing  imbalanced  data  is  another  critical  aspect,  especially  in  freshness  classification, where certain spoilage states may be underrepresented. Techniques like the Synthetic Minority Oversampling Technique (SMOTE) have been used to balance datasets and improve classifier performance [11, 12]. Advanced variants of SMOTE have been pro- posed  to  enhance  its  effectiveness,  but  their  practicality  in  low-resource  settings  is still a challenge. This research aims to develop an affordable and portable smart vending cart equipped with cold storage and an automated freshness classification system. The proposed solu- tion integrates IoT sensors for environmental monitoring, a Peltier cooling module for temperature control, and a humidifier for humidity regulation. Federated learning tech- niques  will  be  employed  to  enhance  the  accuracy  of  freshness  classification  while  pre- serving data privacy. Specifically, the research will address the following objectives: •  Develop a cost-effective and portable cold storage system using components suit- able for street vending operations. The system should maintain optimal tempera- ture and humidity levels to preserve the quality of perishable goods. •  Utilize IoT sensors to collect environmental data and gas emissions indicative of spoilage. Implement machine learning models capable of accurately classifying the freshness of perishable goods without human intervention. •  Employ federated learning to train machine learning models across multiple carts without sharing raw data, thus preserving vendor privacy. Explore various feder- ated learning approaches to handle data heterogeneity and improve model perfor- mance. •  Investigate  ensemble  learning  and  meta-learning  methods  to  enhance  model robustness  and  accuracy  in  the  federated  setting.  Assess  the  feasibility  of  these techniques in resource-constrained environments. •  Implement strategies such as SMOTE to handle imbalanced datasets and improve the classification of minority classes in freshness states. •  Tackle challenges related to communication efficiency, scalability, and security to ensure the system’s feasibility in real-world deployments. Optimize the system for low computational overhead that is suitable for edge devices. By integrating these components, the research seeks to provide a viable solution for street vendors to maintain the freshness and hygiene of perishable goods, reduce food spoilage,  and  minimize  financial  losses.  The  development  of  such  a  system  has  the potential to: •  Automated  freshness  classification  ensures  that  only  consumable  goods  are  sold, protecting public health. •  Reducing  spoilage  translates  to  lower  financial  losses,  increasing  the  profitability of street vending operations. •  Utilizing energy-efficient components like Peltier modules and solar panels aligns with sustainability goals and reduces environmental impact. •  The research contributes to the body of knowledge in IoT and federated learning, particularly in resource-constrained settings. We  customized  federated  learning  algorithms  to  operate  efficiently  on  low-power mobile devices like smart vending carts, which is less explored in the existing litera- ture.  Our  approach  addresses  the  challenges  of  non-IID  data  resulting  from  diverse environmental  conditions  and  product  types  across  different  carts.  Techniques  like meta-learning  and  stacking  ensembles  were  explored  to  improve  model  perfor- mance  in  such  heterogeneous  settings. The  system  ensures  vendor  privacy  by  keep- ing raw data localized on the carts while still benefiting from collective learning. This addresses privacy concerns that were not adequately handled in prior studies involv- ing centralized data aggregation. Unlike previous work that often remains theoretical, we  implemented  and  tested  the  system  in  real-world  simulated  conditions  with resource-constrained settings. Our system demonstrates how federated learning can be scaled and applied in practical scenarios, offering a feasible solution for street ven- dors in developing regions. The  remainder  of  this  manuscript  is  organized  into  several  sections,  each  focusing  on key aspects of the smart vending cart system and its implementation. “Literature review” section  provides  a  comprehensive  literature  review,  outlining  the  current  challenges in  freshness  monitoring,  the  role  of  IoT  in  enhancing  vending  systems,  and  federated learning’s  contribution  to  data  privacy.  “Methodology”  section  describes  the  method- ology  adopted  for  developing  and  testing  the  smart  vending  cart,  covering  hardware configuration, data collection, and model training. It also details the federated learning algorithms implemented and the experimental setup. “Integration of federated learning for  the  smart  vending  cart”  section  focuses  on  the  results  obtained  from  the  system’s deployment,  including  performance  metrics  for  various  machine  learning  models  and federated learning approaches. In “Results and discussion” section, we present a detailed discussion comparing the effectiveness of the proposed approaches and provide insights into  the  system’s  real-world  applicability.  Finally,  “  Conclusion”  section  concludes  the manuscript by summarizing the key findings and proposing future research directions. Literature review The  preservation  of  perishable  goods  in  the  supply  chain,  particularly  at  the  level  of street  vendors,  poses  significant  challenges  due  to  the  lack  of  affordable  and  portable cold  storage  solutions.  This  issue  is  compounded  by  the  need  for  real-time  freshness detection to minimize food spoilage and ensure consumer safety. Recent advancements in  IoT  technologies  and  federated  learning  offer  promising  avenues  to  address  these challenges.  This  literature  review  explores  existing  research  on  portable  cold  storage technologies, IoT applications in freshness detection, and the role of federated learning in enhancing model accuracy while preserving data privacy. The review identifies gaps in the current literature that the proposed research aims to fill, particularly the integration of these technologies into a cost-effective smart vending cart for street vendors. Portable  cold  storage  plays  a  crucial  role  in  preserving  the  quality  of  perishable  goods across various sectors. Raju et al. [1] provide a comprehensive review of portable cold storage technologies, highlighting their applications in industries such as food and bev- erage,  pharmaceuticals,  and  medical  sectors.  They  discuss  various  cooling  methods, including compression refrigeration, absorption refrigeration, and thermoelectric cool- ing, emphasizing the operational efficiency and environmental impact of each method. The integration of phase change materials (PCMs) [13] is also explored for stable tem- perature control [1]. However, the review focuses primarily on large-scale applications and does not address the specific needs of street vendors, such as portability, cost-effec- tiveness, and ease of use. Our work addresses this gap by developing a cost-effective and portable solution tailored for mobile vending operations. The application of IoT in freshness detection has gained significant attention in recent years.  Hebbar  [2]  demonstrates  the  use  of  IoT  sensors  to  collect  environmental  data like  temperature,  humidity,  and  gas  emissions,  which  are  indicators  of  food  freshness [14, 15]. Machine learning algorithms analyze this data to detect spoilage patterns [16], achieving high accuracy rates. Similarly, Wahidul et al. [3] discuss the implementation of IoT-based smart vending machines that integrate mobile applications and cloud com- puting  for  real-time  inventory  management  and  user  convenience.  While  these  stud- ies  showcase  the  potential  of  IoT  in  enhancing  operational  efficiency  and  freshness detection,  they  often  overlook  the  challenges  faced  by  street  vendors,  such  as  limited resources and the need for affordable solutions. Studies have demonstrated the potential of  IoT  sensors  in  monitoring  environmental  conditions  for  freshness  detection.  How- ever,  these  solutions  often  overlook  data  privacy  concerns  and  are  not  optimized  for resource-constrained environments. Our system integrates IoT with federated learning to overcome these limitations. Federated  learning  emerges  as  a  pivotal  technology  for  privacy-preserving  machine learning in IoT environments. Briggs et al. [4] review federated learning as an approach to  perform  machine  learning  on  distributed  data  without  compromising  user  privacy [17]. They highlight challenges such as communication costs, data heterogeneity, and the need for additional privacy protections [18]. Alam and Gupta [5] further explore feder- ated  learning’s  role  in  the  privacy  preservation  of  IoT  devices,  emphasizing  its  ability to  create  robust  classifiers  without  requiring  data  disclosure.  They  provide  a  compre- hensive overview of federated learning mechanisms and applications, advocating for its adoption in IoT contexts [19]. In the context of Industrial IoT, Senthil Kumar et al. [6] address the need for trustworthy federated learning frameworks that balance interpret- ability and robustness. They propose incorporating metrics like privacy, robustness, and explainability  to  ensure  secure  communication  among  devices.  However,  these  studies primarily focus on industrial applications and do not consider the constraints of mobile and resource-limited environments like street vending carts. We extend this concept to low-power devices in mobile contexts, introducing novel adaptations to handle non-IID data and computational constraints. One of the significant challenges in federated learning is handling non-independent and identically  distributed  (non-IID)  data  across  clients.  Wang  and  Li  [7]  introduce  FedS- mooth,  an  aggregation  algorithm  designed  to  improve  federated  learning  efficiency  in non-IID  environments  by  mitigating  the  impact  of  redundant  local  models.  Similarly, Kushwaha et al. [8] propose a Data Distribution-Aware Aggregation method that adjusts local  model  weights  based  on  deviations  from  global  data  distributions,  enhancing classification  accuracy. These  approaches  aim  to  address  the  performance  degradation caused by data heterogeneity, which is prevalent in real-world IoT applications. Non-IID data is a significant challenge in federated learning due to diverse environmental factors across vending carts. While techniques like FedSmooth and data-aware aggregation have been used to manage such heterogeneity, our research introduces specific adaptations to enhance model performance in highly variable environments. Various  model  aggregation  and  personalization  techniques  have  been  proposed  to improve  federated  learning  outcomes.  Xing  et  al.  [9]  present  a  personalized  federated learning  approach  based  on  feature  fusion,  which  reduces  communication  costs  and accommodates  heterogeneous  client  models.  Peng  and  Long  [10]  propose  a  client- supervised  federated  learning  framework  that  develops  a  single  robust  global  model capable  of  effectively  personalizing  for  diverse  clients  without  extensive  adaptation. While these methods enhance model performance and adaptability, they often involve increased computational complexity and may not be suitable for environments with lim- ited resources [20, 21], such as street vending carts. Previous personalization approaches have  been  effective  in  heterogeneous  IoT  environments,  but  they  often  require  high computational power. Our study adapts personalization techniques for use in low-power mobile devices, ensuring that computational complexity remains manageable for street vendors. Ensemble learning and meta-learning have shown promise in improving model accuracy and robustness. Ensemble methods combine multiple models to enhance predictive per- formance, as demonstrated by Ansari Khoushabar and Ghafariasl [11] in the context of early sepsis prediction. In federated learning, ensemble methods can mitigate the impact of  data  heterogeneity  and  improve  generalization  [22],  as  shown  by  Huang  et  al.  [23]. However,  the  application  of  ensemble  and  meta-learning  approaches  in  resource-con- strained  settings  remains  limited  due  to  computational  demands  and  communication overhead [24]. Ensemble and meta-learning methods have improved predictive perfor- mance in machine learning. However, their application in resource-constrained settings has been limited due to computational and communication overhead. We adapted these methods to work effectively in the street vending context, reducing the demands on sys- tem resources while maintaining high model performance. Imbalanced  data  is  a  common  issue  in  machine  learning,  affecting  model  perfor- mance, particularly in minority class prediction. The Synthetic Minority Oversampling Technique  (SMOTE)  [25]  is  widely  used  to  address  this  challenge.  Mohanty  et  al.  [12] introduce  Quantum-SMOTE,  leveraging  quantum  computing  to  enhance  SMOTE’s effectiveness.  Shen  et  al.  [26]  propose  BO-SMOTE,  a  Bayesian  optimization-based SMOTE  variant  that  improves  synthetic  sample  generation.  These  advanced  SMOTE techniques  enhance  classifier  performance  but  may  not  be  practical  for  deployment in  environments  with  limited  computational  capabilities.  Imbalanced  data  poses  sig- nificant  challenges  for  machine  learning,  particularly  for  the  accurate  prediction  of minority classes. While advanced SMOTE techniques exist, they may be too computa- tionally intensive for street vending applications. Instead, we apply a simplified version of SMOTE, suitable for resource-limited environments, to balance data effectively with- out overwhelming computational resources. The review of current literature reveals several gaps that the proposed research aims to address: •  While portable cold storage technologies exist, there is a scarcity of solutions tailored to the specific needs of street vendors. Existing studies focus on large-scale applica- tions and do not consider constraints like cost, portability, and ease of use [1]. •  Most IoT and federated learning applications target industrial settings with substan- tial resources [4–6]. There is a lack of research on implementing these technologies in mobile, resource-limited contexts like street vending carts. •  While IoT-based freshness detection systems exist [2, 3], they often do not incorpo- rate privacy-preserving techniques like federated learning. Additionally, existing fed- erated learning studies do not focus on freshness classification in perishable goods. •  The  challenge  of  non-IID  data  is  well-documented  [7,  8],  but  solutions  are  often computationally  intensive  and  not  suitable  for  deployment  on  devices  with  limited processing power. •  Although  ensemble  and  meta-learning  methods  improve  model  performance  [10], their  application  in  federated  learning  for  edge  devices  like  smart  vending  carts remains underexplored. •  Studies  that  propose  advanced  federated  learning  techniques  often  overlook  prac- tical issues such as communication efficiency, scalability, and security in real-world deployments [9, 10]. The objective of this study was to develop and assess a smart vending cart system inte- grating  IoT  sensors  and  federated  learning  for  automated  freshness  monitoring  in resource-constrained environments. The system was evaluated using a simulated envi- ronment  designed  to  replicate  the  diverse  conditions  encountered  by  street  vendors, particularly in developing regions. Ten identical smart vending carts equipped with IoT sensors acted as clients within the federated learning framework. These carts were simu- lated to operate in different virtual locations, introducing the necessary heterogeneity in data collection to mimic variability in environmental conditions across different areas. Data collection occurred over a continuous seven-day period in the simulation, during which environmental factors were recorded at five-minute intervals, resulting in approx- imately 2016 instances per cart. The carts were equipped with virtual sensors for moni- toring  temperature  (DHT11),  humidity,  and  gas  emissions  (MQ2  for  Hydrogen,  MQ9 for Carbon Monoxide, MQ135 for Ammonia, and MQ138 for Toluene), all indicative of food freshness. Actuators such as Peltier cooling modules and humidifier modules were simulated to control the temperature and humidity based on sensor data. In the feder- ated learning setup, each simulated cart functioned as an individual client, training local models  on  its  data.  The  local  models  were  periodically  updated  and  sent  to  a  central server  for  aggregation.  This  approach  ensured  data  privacy  and  allowed  us  to  test  the system’s performance in a controlled yet realistic virtual environment. To ensure consistency and validity in the experimental design, several control variables were maintained across all smart vending carts. All carts were equipped with the same hardware  configuration,  including  identical  sensors  (temperature,  humidity,  and  gas), microcontrollers  (NodeMCU),  and  cooling  components  (Peltier  modules  and  humidi- fiers), ensuring that hardware variability did not influence the results. All sensors under- went  a  uniform  calibration  process  using  known  standards  to  guarantee  accurate  and consistent data collection across the carts. The carts were configured to operate from 8 AM to 6 PM daily, capturing customer interactions and environmental data. However, sensors continued to monitor environmental changes over 24 h to ensure data collection reflected spoilage processes even outside operational hours. The data collection interval was set to five minutes across all carts to maintain temporal consistency. Product types and quantities were varied intentionally across carts to introduce diversity and simulate real-world conditions encountered by street vendors. Furthermore, placing carts in dif- ferent city locations allowed for exposure to varying environmental conditions such as temperature fluctuations, humidity, and air quality, ensuring the data reflected the het- erogeneity found in real-world street vending scenarios. The transformation of a traditional vending cart into a smart vending cart with cold storage  was  achieved  by  regulating  the  temperature  and  humidity  inside  the  cart. Figure 1 illustrates the overall system design, including the temperature and humid- ity  sensors,  gas  sensors,  Peltier  cooling  module,  humidifier,  and  machine  learning model  for  classifying  freshness.  In  summer  conditions,  solar  panels  provide  power to the cart, supported by batteries, to ensure continuous operation. Sensor data was continuously fed into the Peltier cooling and humidifier modules, adjusting tempera- ture and humidity levels accordingly. The freshness of perishable items was classified such  as  Excellent,  Good,  Average,  Bad,  or  Poor,  using  a  machine  learning  classifica- tion model. Control actions, whether manual or automatic, were taken based on these classifications to ensure optimal conditions were maintained within the cart. The  physical  parameters  critical  to  maintaining  the  freshness  of  perishable  goods were monitored using a series of sensors and control modules. The different views of the smart vending cart with cold storage are shown in Fig. 2. On sunny days, the carts are  powered  directly  by  solar  panels  mounted  on  the  canopy,  which  simultaneously charge the batteries. Under cloudy conditions, the carts rely on both solar power and battery backup as needed. This adaptive power management system enables the carts to respond effectively to varying weather conditions, ensuring efficient energy usage through seamless switching between power sources. The gas sensor, temperature sen- sor,  and  humidity  sensor  are  factory-calibrated  prior  to  installation  using  standard reference  materials  and  controlled  conditions.  Recalibration  of  the  sensors  is  con- ducted quarterly or upon detection of any discrepancies. Additionally, the sensor sur- faces are cleaned on a weekly basis using suitable materials to remove dust and debris, ensuring  accurate  and  reliable  performance.  Physical  stress  testing  has  not  yet  been conducted on the vending cart. However, the design prioritizes durability intended to handle diverse environmental conditions. Maintaining  an  optimal  temperature  is  essential  for  preventing  spoilage.  The  Pel- tier  cooling  module,  shown  in  Fig.  3,  was  selected  for  its  advantages  over  traditional compressor-based  systems,  which  use  harmful  chemicals. The  Peltier  module  is  small, portable, and requires minimal maintenance, making it ideal for use in mobile vending carts. The Peltier module is well-suited for small-scale cooling applications, offering an eco-friendly  solution  with  minimal  maintenance  needs.  Its  overall  costs  are  lower  for smaller  applications,  and  maintenance  expenses  are  significantly  reduced  compared  to traditional cooling methods. Additionally, it delivers direct spot cooling with low power consumption. Excess moisture can lead to bacterial growth, compromising the freshness of goods. The humidifier  module,  depicted  in  Fig.  4,  regulated  the  humidity  level  by  dispersing  fine water particles, ensuring a moisture-controlled environment without wetness. The  NodeMCU  microcontroller,  shown  in  Fig.  5,  acted  as  the  processing  hub  for  the smart vending cart. It was responsible for acquiring sensor data, processing it, and send- ing updates to the cloud, enabling real-time freshness monitoring and control actions. The MQ2, MQ9, MQ135, and MQ138 gas sensors were used to detect gases such as hydrogen, carbon monoxide, ammonia, and toluene, which are key indicators of food spoilage. Figure 6 shows these sensors, which provide real-time feedback to the sys- tem for freshness classification. The  system’s  operation  relied  on  continuous  feedback  from  the  sensors  to  regulate temperature  and  humidity  levels.  The  DHT11  sensor  measured  temperature  and humidity, while the gas sensors (MQ2, MQ9, MQ135, and MQ138) monitored spoil- age-related  gases.  The  machine  learning  classification  model  processed  this  sensor data to determine the freshness state of items in the cart. The system communicated with  the  cloud  for  centralized  control  actions  based  on  the  state  of  the  fresh  items. Four possible actions were performed depending on the temperature, humidity, and freshness state, as described in Algorithm 1. Effective  communication  and  power  management  were  critical  considerations  in  the design  and  operation  of  the  smart  vending  carts,  given  their  resource  constraints  and the  need  for  reliable  data  transmission.  To  manage  communication  delays,  we  utilized the  existing  Wi-Fi  capabilities  of  the  NodeMCU  microcontrollers  to  establish  stable connections  with  the  central  server.  To  optimize  performance,  we  implemented  data compression  techniques  for  model  updates  and  minimized  the  size  of  data  packets  by transmitting only essential information required for the federated learning process. The carts were equipped with solar panels mounted on the canopy, which provided power during  daylight  hours  and  simultaneously  charged  the  batteries.  Under  cloudy  con- ditions or at night, the carts switched seamlessly to battery power. This setup ensured continuous operation while maximizing the use of renewable energy sources. Addition- ally, we incorporated power-efficient programming practices for the NodeMCU micro- controllers.  The  devices  were  programmed  to  perform  necessary  computations  and data transmissions efficiently, avoiding unnecessary processing that could drain power. The  Peltier  cooling  modules  and  humidifiers  operated  based  on  the  control  algorithm detailed  in  Algorithm  1,  which  already  includes  turning  off  these  modules  when  opti- mal conditions are met to conserve energy. By maintaining consistent data transmission intervals  and  integrating  these  power  management  strategies,  we  ensured  that  com- munication delays were minimized and power consumption was kept within the opera- tional capabilities of the carts. Integration of federated learning for the smart vending cart Federated learning enables collaboration among multiple parties to train a shared model without sharing their data. It is a privacy-preserving machine learning approach that is well-suited  for  scenarios  where  data  privacy  and  security  are  essential,  such  as  in  the context of smart vending carts connected via the Internet of Vehicles (IoV). The smart vending cart is connected to a network of other smart carts through the IoV. This con- nection allows for federated learning to take place among the carts. The federated learn- ing  process  involves  each  cart  training  its  classification  model  on  its  local  dataset  and then sharing the model updates with a central server. The shared models are then aggre- gated to select the best model, which is further used to improve the accuracy of the clas- sification  of  the  freshness  of  food  items.  The  federated  learning  process  is  performed periodically to improve the accuracy of the model continuously. The integration of federated learning is a key component of the proposed solution. It enables the smart carts to improve their classification accuracy while preserving the pri- vacy of the vendors’ data. This collective intelligence allows the carts to learn from each other’s experiences and data, resulting in a more accurate classification of the freshness and hygiene of the food sold in the vending carts. Moreover, the use of federated learning and the IoV can lead to more efficient power usage and longer battery life for the smart carts. By sharing resources and models, smart carts can optimize their power usage and minimize unnecessary communication, leading to more efficient use of energy. This research implements nine federated learning algorithms, each specifically tailored for the smart vending cart network. This section explains how each approach optimizes the classification of food freshness and contributes to enhancing the overall performance of  the  smart  vending  cart  system.  The  common  parameters  for  the  federated  learning algorithms  used  in  this  study  were  kept  consistent  across  all  methods  to  ensure  a  fair comparison. The number of clients, denoted by K , represents the number of participat- ing smart vending carts, which was set to 10 clients. Each client independently trained its  local  model  and  contributed  to  the  global  model  through  periodic  communication with the central server. The number of communication rounds, denoted by T , refers to how many times the local models communicate with the central server for aggregation and  update  purposes.  In  this  case,  7  communication  rounds  were  conducted  between the clients and the server, ensuring sufficient interaction for model improvement. Each client  trained  its  model  over  a  set  number  of  local  epochs,  denoted  by  E .  The  local epochs  represent  the  number  of  times  the  model  trains  on  its  local  data  before  send- ing  updates  to  the  server.  In  this  study,  each  client  was  configured  to  perform  5  local epochs during each round of training, allowing sufficient local learning before the global model aggregation. The learning rate, denoted by η , controls the rate at which the model weights are updated during the training process. For all the algorithms, the learning rate was set to η = 0.01 , ensuring gradual and stable model updates throughout the training process. These  parameter  settings  formed  the  basis  for  comparing  the  performance  of the federated learning algorithms in this study. The Federated Averaging (FedAvg) approach shown in Fig. 7a involves a server coor- dinating with two clients for distributed model training, where the server sends a global model to each client, who performs local training and subsequently sends model updates back  to  the  server,  preserving  data  privacy  by  allowing  clients  to  train  independently without  sharing  raw  data.  In  the  Weighted  Aggregation  approach  depicted  in  Fig.  7b, a  server  communicates  with  two  clients,  with  each  client  receiving  the  global  model, performing  local  training,  and  then  sending  back  a  weighted  update  based  on  their performance  to  ensure  that  contributions  are  proportional  to  their  local  model’s  qual- ity, thereby improving the accuracy of the aggregated model. Figure 7c shows the Meta- Learning (Stacking the Models) approach, where a server distributes a global model to two clients, who generate predictions based on local data, which are then sent to a meta- model for stacking, producing a more robust final model by leveraging individual client model  strengths  to  enhance  overall  performance.  The  Model  Personalization  (Global) approach  illustrated  in  Fig.  7d  shows  a  server  distributing  a  global  model  to  each  cli- ent, who then locally personalizes it while still contributing updates back to the server, thereby balancing a general global model with adaptations to local data for better per- formance.  In  the  Model  Personalization  (Personalized)  approach  shown  in  Fig.  7e,  the server sends a global model to two clients, who fine-tune it locally based on their own unique datasets, creating personalized models that cater specifically to the requirements of each client and improving relevance in heterogeneous environments. Figure 7f depicts the  Federated  Stochastic  Gradient  Descent  (FedSGD)  approach,  where  a  server  shares the global model with two clients, who compute gradients based on local data and send these gradients back to the server for updating the global model, maintaining local data privacy while enabling collaborative learning. The Ensemble of Global Models approach depicted in Fig. 7g illustrates multiple server models trained and updated independently by different clients, with results aggregated through an ensemble voting mechanism to leverage diverse model perspectives, enhancing robustness and accuracy. In Fig. 7h, the Handling Data Imbalance with SMOTE approach shows a server sending a global model to  clients,  who  apply  the  SMOTE  technique  locally  to  balance  their  datasets  before training,  thus  improving  model  performance  by  ensuring  adequate  representation  of minority  classes  and  aggregating  these  updates  to  form  a  better  global  model.  Finally, the Stacking Ensemble approach shown in Fig. 7i demonstrates the server distributing a global model to two clients, who generate local predictions that are aggregated by an aggregator,  which  serves  as  input  to  a  meta-model  to  produce  a  final  stacked  model, effectively optimizing predictive performance by combining individual model outputs. Federated Averaging (FedAvg) is one of the foundational federated learning algorithms. In  this  approach,  multiple  clients  independently  train  models  on  their  local  datasets. After a predefined number of training iterations, the local model updates are sent to a central  server.  The  server  averages  these  updates  to  produce  a  global  model,  which  is then  distributed  back  to  the  clients  for  further  training.  This  process  is  detailed  in Algorithm 2. For the Federated Averaging (FedAvg) algorithm, the initial global model parameters, denoted as θ0 , were initialized at the central server. Each client had its local model parameters, θk , which were updated locally at each client based on the data avail- ∇Lk (θk ) , was computed able. The gradient of the loss function for client k , denoted as using  Stochastic  Gradient  Descent  (SGD).  After  the  local  updates,  the  global  model parameters, θt , were aggregated by averaging the local models from all clients. Weighted Aggregation is an advanced variant of FedAvg. Instead of simply averaging the model parameters from all clients, each client’s contribution to the global model is weighted based on its performance. Clients that achieve higher validation metrics on  their  local  datasets  contribute  more  to  the  global  model.  The  detailed  process  is shown in Algorithm 3. For the Weighted Aggregation approach, each client computed a  validation  metric,  denoted  as  Mk ,  based  on  the  local  validation  data.  The  weight assigned  to  each  client,  wk ,  was  proportional  to  its  validation  metric  Mk .  The  total weight accumulated from all clients was represented by Wtotal , which was the sum of all  client  weights.  The  local  model  parameters, θk ,  were  the  same  as  in  FedAvg,  but during  aggregation,  they  were  weighted  based  on  the  client  validation  metrics.  The aggregated global model parameters, θt , were adjusted accordingly. Meta-Learning  involves  stacking  the  outputs  of  multiple  local  models  to  create  a  meta- model. The meta-model learns how to best combine the predictions from the local models to make a final prediction. This approach leverages the strengths of individual models and can significantly improve overall performance. The process is detailed in Algorithm 4. In the Meta-Learning (Stacking) approach, each client generated predictions, Pk , from its local model after training. These predictions from all clients were stacked into one meta-data- set, denoted as Pstack . The meta-model parameters, θmeta , were then learned by training on the stacked predictions, allowing the combination of client predictions for more accurate results. In this approach, a global model is trained by aggregating the local models from all the cli- ents. However, unlike standard federated learning, where the global model is used as-is by all clients, this global model represents a generalized version that attempts to capture the common characteristics across all clients’ datasets. This model is the same for all clients, meaning  it  does  not  account  for  the  unique  characteristics  or  data  distributions  of  indi- vidual  clients.  It  is  effective  when  the  data  across  clients  is  somewhat  homogeneous  but may not perform as well in cases where the data distributions are very different. The entire process is outlined in Algorithm 5. Model Personalization (Global) started with the initial- ization  of  global  model  parameters, θ0 ,  at  the  server,  similar  to  FedAvg.  The  local  model parameters, θk , were updated locally for each client. The gradient of the loss function for ∇Lk (θk ) , was calculated similarly to FedAvg. The global model parameters, θt , were client k , aggregated, remaining the same for all clients. This  approach  goes  one  step  further  than  the  global  model  by  fine-tuning  the  global model on each client’s local data after it has been aggregated. This creates a personalized model for each client. This personalized model is tailored to the specific data distribu- tion of each client, improving performance on that client’s dataset. It is particularly use- ful in heterogeneous data environments where the data on each client is different, as the personalized model can better adapt to the local characteristics of the client’s data. The entire process is outlined in Algorithm 6. For Model Personalization (Personalized), the global model parameters, θ0 , were initialized at the server, but each client had personal- ized model parameters, θpk , which were fine-tuned on each client’s local data. The fine- tuning occurred for a set number of epochs, denoted as Ep , which was set to 3 epochs. Federated Stochastic Gradient Descent focuses on averaging the gradients computed by each client. Clients send their gradients to the central server, which averages them and updates  the  global  model.  The  detailed  steps  are  outlined  in  Algorithm  7.  The  Feder- ated SGD (FedSGD) algorithm focused on computing the gradient of the loss function ∇Lk (θk ) , at the client level. These gradients were then sent to the server, for each client, where the global model parameters, θt , were updated by aggregating the gradients from all clients. Multiple global models, trained independently, are combined to form an ensemble. This approach leverages the strengths of different models to improve overall performance, as described in Algorithm 8. In the Ensemble of Global Models approach, multiple global models  were  trained  independently.  The  number  of  global  models  was  represented  by M . Each global model had its parameters, θm , with separate parameters for each model. The final ensemble model predictions, Pensemble , were aggregated using majority voting across the multiple models. SMOTE  (Synthetic  Minority  Over-sampling  Technique)  addresses  class  imbalance  by generating synthetic examples for the minority class. In federated learning, SMOTE is applied locally on each client’s dataset to balance the classes before training. The proce- dure for applying SMOTE in federated learning is outlined in Algorithm 9. The Handling Data Imbalance (SMOTE) approach used synthetic examples generated for underrepre- sented classes. These synthetic examples were locally applied to the client datasets using specific SMOTE parameters. The local model parameters, θk , were then updated on the balanced data. This ensured that the model could effectively handle imbalanced datasets during training.",
         "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-025-01063-3",
         "extracted",
         "None",
         "",
         "Federated learning-driven IoT system for automated freshness monitoring in resource-constrained vending carts"
        ],
        [
         "45",
         "01f696fabeb35d1337c5cb817ae43ffd30fcdf34",
         "Mastitis, a prevalent inflammatory disease in mammals, disrupts mammary gland function, compromises milk quality, and can contribute to increased offspring morbidity and mortality. Maintaining the health of porcine mammary epithelial cells (PMECs), the primary cell type in the mammary gland, is crucial for minimizing the adverse effects of this disease. Selenium yeast (SeY), an organic selenium compound known for its antioxidant and immune-enhancing properties, has yet to be fully understood in its role in modulating inflammation in mammary gland. In this study, lipopolysaccharide (LPS) (50 µg/mL, 24 h) significantly upregulated the expression of pro-inflammatory cytokines, including tumor necrosis factor-alpha (TNF-α), interleukin-6 (IL-6), interleukin-8 (IL-8), and interleukin-1β (IL-1β) (p < 0.05). Pretreatment with 1 µM SeY significantly attenuated the LPS-induced inflammatory response by reducing the levels of TNF-α, IL-6, IL-8, and IL-1β (p < 0.05). Additionally, SeY enhanced cellular antioxidant defenses by increasing total antioxidant capacity (T-AOC), superoxide dismutase (SOD) activity, glutathione (GSH) levels, and glutathione peroxidase (GSH-Px) activity, while concurrently decreasing malondialdehyde (MDA) accumulation (p < 0.05). SeY also restored both intracellular and extracellular triglyceride levels and rescued lipid droplet formation, which were disrupted by LPS treatment. Furthermore, SeY upregulated key regulators involved in milk synthesis (p < 0.05). These findings suggest that SeY effectively mitigates LPS-induced inflammation and oxidative stress while preserving critical pathways for milk fat and protein synthesis in PMECs.",
         "Zhenting He,Senlin Su,Bing Zhang,Dongpang Chen,Siyu Yuan,W. Guan,Shihai Zhang",
         "\n**BLOCK**fs== 17.9**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.2**\nArticle\nSelenium Yeast Attenuated Lipopolysaccharide-Induced\nInflammation in Porcine Mammary Epithelial Cells by\nModulating MAPK and NF-κB Signaling Pathways\n**BLOCK**fs== 10.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nZhenting He 1, Senlin Su 1, Bing Zhang 1, Dongpang Chen 1, Siyu Yuan 1, Wutai Guan 1,2,3 and Shihai Zhang 1,2,3,*\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n1 Guangdong Province Key Laboratory of Animal Nutrition Control, College of Animal Science, South China\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nAgricultural University, Guangzhou 510642, China; hezhenting@stu.scau.edu.cn (Z.H.);\nsusenlin@stu.scau.edu.cn (S.S.); 1760662690@stu.scau.edu.cn (B.Z.); dongpangchen@stu.scau.edu.cn (D.C.);\nyuansiyu@stu.scau.edu.cn (S.Y.); wtguan@scau.edu.cn (W.G.)\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n2 National Engineering Research Center for Breeding Swine Industry, South China Agricultural University,\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.5**\nGuangzhou 510642, China\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\n3 Guangdong Laboratory for Lingnan Modern Agriculture, South China Agricultural University,\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.3**r== 0.5**\nGuangzhou 510642, China\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.4**l== 0.3**r== 0.3**\n* Correspondence: zhangshihai@scau.edu.cn; Tel./Fax: +86-13660346296\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.4**l== 0.3**r== 0.1**\nAbstract: Mastitis, a prevalent inflammatory disease in mammals, disrupts mammary gland\nfunction, compromises milk quality, and can contribute to increased offspring morbidity\nand mortality. Maintaining the health of porcine mammary epithelial cells (PMECs), the\nprimary cell type in the mammary gland, is crucial for minimizing the adverse effects\nof this disease. Selenium yeast (SeY), an organic selenium compound known for its\nantioxidant and immune-enhancing properties, has yet to be fully understood in its role\nin modulating inflammation in mammary gland. In this study, lipopolysaccharide (LPS)\n(50 µg/mL, 24 h) significantly upregulated the expression of pro-inflammatory cytokines,\nincluding tumor necrosis factor-alpha (TNF-α), interleukin-6 (IL-6), interleukin-8 (IL-8),\nand interleukin-1β (IL-1β) (p < 0.05). Pretreatment with 1 µM SeY significantly attenuated\nthe LPS-induced inflammatory response by reducing the levels of TNF-α, IL-6, IL-8, and\nIL-1β (p < 0.05). Additionally, SeY enhanced cellular antioxidant defenses by increasing\ntotal antioxidant capacity (T-AOC), superoxide dismutase (SOD) activity, glutathione\n(GSH) levels, and glutathione peroxidase (GSH-Px) activity, while concurrently decreasing\nmalondialdehyde (MDA) accumulation (p < 0.05). SeY also restored both intracellular and\nextracellular triglyceride levels and rescued lipid droplet formation, which were disrupted\nby LPS treatment. Furthermore, SeY upregulated key regulators involved in milk synthesis\n(p < 0.05). These findings suggest that SeY effectively mitigates LPS-induced inflammation\nand oxidative stress while preserving critical pathways for milk fat and protein synthesis\nin PMECs.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nKeywords: porcine mammary epithelial cells; anti-inflammation; selenium yeast; milk\nsynthesis; lipopolysaccharide\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\n1. Introduction\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nMastitis is a prevalent and significant disease in animal production, often leading to\nreduced milk production or altered milk composition. This condition can severely affect\nthe growth of offspring, sometimes resulting in piglet mortality, and causing substantial\neconomic losses to the breeding industry [1–8]. Mammary epithelial cells, the primary\ncellular component of the mammary gland, play a crucial role in the inflammatory response,\n**BLOCK**fs== 7.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nAcademic Editor: Alessandra\n**BLOCK**fs== 7.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.9**\nNapolitano\n**BLOCK**fs== 7.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nReceived: 12 February 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.4**t== 0.6**l== 0.1**r== 0.8**\nRevised: 26 February 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nPublished: 12 March 2025\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nCitation: He, Z.; Su, S.; Zhang, B.;\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.7**\nChen, D.; Yuan, S.; Guan, W.; Zhang, S.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nSelenium Yeast Attenuated\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nLipopolysaccharide-Induced\n**BLOCK**fs== 7.0**p== 0.0**b== 0.3**t== 0.7**l== 0.1**r== 0.8**\nInflammation in Porcine Mammary\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.7**\nEpithelial Cells by Modulating MAPK\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nand NF-κB Signaling Pathways.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nAntioxidants 2025, 14, 334. https://\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\ndoi.org/10.3390/antiox14030334\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nCopyright: © 2025 by the authors.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.2**t== 0.8**l== 0.1**r== 0.8**\nLicensee MDPI, Basel, Switzerland.\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.8**\nThis article is an open access article\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\ndistributed under the terms and\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\nconditions of the Creative Commons\n**BLOCK**fs== 7.0**p== 0.0**b== 0.1**t== 0.9**l== 0.1**r== 0.8**\n(https://creativecommons.org/\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\nserving as both targets and mediators of infection-induced inflammation in mastitis [9–11].\nLipopolysaccharide (LPS), a key component of Gram-negative bacterial cell walls, triggers\nintracellular signaling cascades by binding to Toll-like receptor 4 (TLR4) on the cell surface,\nleading to the activation of pro-inflammatory pathways [12–14]. This activation initiates\nboth MyD88-dependent and MyD88-independent pathways, culminating in the activation\nof nuclear factor-kappa B (NF-κB) [15]. Once activated, NF-κB promotes the transcription\nand release of pro-inflammatory factors, including cytokines and chemokines [16], which or-\nchestrate immune responses and drive inflammation in mammary epithelial cells [7,17,18].\nGiven its pivotal role in inflammatory cascade, the LPS-induced signaling pathway rep-\nresents a critical target for identifying potential therapeutic agents to mitigate mammary\ngland inflammation.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.4**t== 0.3**l== 0.3**r== 0.1**\nSelenium, an essential trace element, plays a crucial role in various biological processes,\nparticularly as a component of antioxidant enzymes that neutralize reactive oxygen species\n(ROS) and enhance immune function [19–21]. Previous studies have demonstrated that se-\nlenium supplementation improves the reproductive performance and health status of sows\nand their offspring [22–24]. Increased maternal selenium intake has been shown to enhance\npiglet survival, colostrum and milk quality, maternal antioxidant status, and immunoglob-\nulin transfer [25]. Selenium also supports piglet growth during early lactation [26,27].\nIn animal feed, selenium is available in both inorganic and organic forms [28]. Organic\nselenium has been shown to provide several advantages over inorganic forms, including\nhigher absorption rates [29], enhanced antioxidant capacity [30], lower toxicity [31,32],\nand improved overall animal health and performance [33–37]. Among various organic\nselenium sources, selenium yeast (SeY) offers distinct advantages, including superior\nbioavailability and enhanced antioxidant capacity, whereas selenium methionine (Sel-Met),\ndespite its good absorption, exhibits relatively lower stability and bio-conversion efficiency.\nPrevious studies in our lab systematically compared the antioxidant efficacy of SeY and\nSel-Met in porcine mammary epithelial cells (PMECs), demonstrating that both enhance\nantioxidant capacity through activation of the p38/JNK signaling pathway, underscoring\nselenium’s critical role in mitigating oxidative stress in the mammary glands of sows and\ntheir offspring.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nDespite the well-documented benefits of SeY, most studies have primarily focused\non its general role in enhancing overall animal health. However, its specific protective\neffects against LPS-induced inflammation and oxidative stress in PMECs remain largely\nunexplored. This study provides novel insights into the potential of SeY in mitigating\nLPS-induced inflammatory responses and oxidative stress in PMECs. Additionally, we\nelucidate the underlying mechanisms by which SeY regulates key signaling pathways,\nincluding NF-κB and mitogen-activated protein kinase (MAPK) pathways, and its impact\non milk fat and protein synthesis pathways. These findings offer new perspectives on the\ntherapeutic potential of SeY for mastitis prevention and management, emphasizing its role\nin improving lactation and overall mammary gland health in livestock.\n**BLOCK**fs== 12.0**p== 1.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\n2. Materials and Methods\n2.1. Preparation of SeY\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nSeY from Sel-Plex™ 2000 (Alltech Inc., Lexington, KY, USA), containing 2000 mg/kg\nof selenium, was used in this study. To simulate the gastrointestinal digestion of SeY, SeY\nwas subjected to pretreatment with digestive enzymes in vitro. A protease solution was\nprepared by dissolving 2 mg of protease XIV (Sigma-Aldrich, Saint Louis, MO, USA) in\n0.5 mL of 10 mM Tris-HCl buffer (Sigma-Aldrich, Saint Louis, MO, USA). To this solution,\n40 mg of SeY was added and thoroughly mixed. The samples were disrupted using ultra-\nsound (25 s at 80% amplitude) on ice, followed by cleaning with ultrapure water (Sangon\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nBiotech, Shanghai, China). The ultrasonic power was set to 30 W, and the disruption lasted\nfor 15 min. The sample was then centrifuged at 14,000 rpm for 3 min, and the supernatant\nwas discarded. The pellet was washed, resuspended in ultrapure water (Sangon Biotech,\nShanghai, China), and centrifuged again under the same conditions to obtain the final\nsupernatant. The selenium concentration in the sample was determined by inductively\ncoupled plasma mass spectrometry (ICP-MS).\n**BLOCK**fs== 10.0**p== 2.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\n2.2. Cell Culture\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nPMECs were isolated from the mammary gland of a 9-month-old Large White sow [38].\nThe sow was selected based on her optimal health status and body condition. PMECs\nisolated from a lactating sow were cryopreserved in liquid nitrogen at −196 ◦C. For culture,\nthawed PMECs (1 mL, 37 ◦C) were maintained in DMEM/F12 medium supplemented with\n10% FBS, 1% antibiotic-antimycotic, 10 ng/mL IGF-1, 10 ng/mL EGF, 5 µg/mL ITS, and\n5 µg/mL hydrocortisone at 37 ◦C with 5% CO2. The cells were subsequently transferred to\nDIP medium supplemented with 1 µM dexamethasone, 5 µg/mL insulin, and 5 µg/mL\nprolactin to induce differentiation and stimulate milk production.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.4**l== 0.3**r== 0.6**\n2.3. Cell Viability Assay\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nCell viability was assessed using the CCK-8 assay (Nanjing Jiancheng Bioengineering\nInstitute, Nanjing, China). PMECs were seeded in 96-well plates at 1 × 105 cells/mL\n(100 µL medium/well) and incubated at 37 ◦C with 5% CO2 for 24 h. At 70–80% confluence,\ncells were treated as specified. Post-treatment, 10 µL of CCK-8 solution was added to each\nwell, incubated at 37 ◦C for 1–3 h, and the absorbance was measured at 450 nm using a\nmicroplate reader.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n2.4. Real-Time PCR\n**BLOCK**fs== 10.0**p== 2.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nTotal RNA was extracted from the cell samples using the EZ-press RNA purification\nkit (EZ-Bio, Shanghai, China). cDNA synthesis was performed using the RNA reverse\ntranscription kit (EZ-Bio, Shanghai, China). The cDNA was mixed with Color SYBR\nGreen qPCR Mix, target gene primers, and double-distilled water to prepare a 20 µL qPCR\nreaction system. The thermal cycling conditions were as follows: 95 ◦C for 1 min, followed\nby 40 cycles of 95 ◦C for 15 s, 59 ◦C for 15 s, and 72 ◦C for 40 s. Relative gene expression was\ncalculated using the 2−∆∆Ct method, with β-actin as the internal control. Primer sequences\nfor real-time PCR are listed in Table 1.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\nTable 1. Primer sequences for the mRNA.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.3**r== 0.7**\nAccession\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.5**r== 0.3**\nSequence Primers (5′–3′)\n**BLOCK**fs== 10.0**p== 2.0**b== 0.3**t== 0.7**l== 0.8**r== 0.1**\nSize (bp)\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.7**l== 0.4**r== 0.3**\nF-ATGGGCTGTACCTCATCTACTC\nR-GGCTCTTGATGGCAGAGAGG\nF-TGGCTACTGCCTTCCCTACC\nR-CAGAGATTTTGCCGAGGATG\nF-CCGAAGAGGGACATGGAGAA\nR-AGTTGGGGTACAGGGCAGAC\nF-AGGACCAGAGCCAGGAAGAGAC\nR-CACAGAGAGCTGCAGAAAGCAG\nF-CCTGGATGATGTTAGCAGCGATGG\nR-GACGAAGACTGGGTGAGGAATGAAC\nF-TTCTGATGGGCACCTGGAGAGAG\nR-CGTCTGGTCCATTGCTAGTGAACTC\nF-GGTGGAAGAGGAGGCTGAGGAG\nR-CGACGATCTGGGCAGCAATGG\n**BLOCK**fs== 9.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\nTable 1. Cont.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.7**\nAccession\n**BLOCK**fs== 10.0**p== 3.0**b== 0.9**t== 0.1**l== 0.5**r== 0.3**\nSequence Primers (5′–3′)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.9**t== 0.1**l== 0.8**r== 0.1**\nSize (bp)\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nβ-actin\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.1**l== 0.4**r== 0.3**\nF-CAGCCCTGTTGTTCACGTAGCC\nR-TTGATGAGCGACCCGTTTCTATTGG\nF-CAACAGCCAGAGGAAATCCGAGAC\nR-CACGCCACCTGCAAGAGAATACC\nF-TGCGGGACATCAAGGAGAAG\nR-AGTTGAAGGTGGTCTCGTGG\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.2**l== 0.3**r== 0.4**\n2.5. Measurement of Inflammatory Factor Levels\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nThe levels of tumor necrosis factor-alpha (TNF-α), interleukin-6 (IL-6), interleukin-\n8 (IL-8), and interleukin-1β (IL-1β) were quantified using pig-specific ELISA kits (mlbio,\nShanghai, China). PMECs were seeded in 12-well plates at 2.5 × 104 cells/mL (1 mL/well)\nand cultured at 37 ◦C with 5% CO2. After 48 h, cells were pretreated with 1 µM SeY for\n24 h, followed by 50 µg/mL LPS stimulation for 24 h. The cells were washed with PBS,\nlysed in 140 µL RIPA buffer (Beyotime, Shanghai, China), and centrifuged (10,000 rpm,\n10 min). Supernatants were collected for analysis.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.3**r== 0.5**\n2.6. Antioxidant Enzymes Assay\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nAntioxidant capacity was assessed using a commercial kit (Nanjing Jiancheng\nBioengineering Institute, Nanjing, China). PMECs were seeded in 12-well plates at\n2.5 × 104 cells/mL (1 mL/well) and cultured at 37 ◦C with 5% CO2. After 48 h, cells\nwere pretreated with 1 µM SeY for 24 h, followed by 50 µg/mL LPS stimulation for 24 h.\nThe LPS concentration (50 µg/mL) and exposure time (24 h) used in this study were de-\ntermined based on prior experiments conducted in our lab [39]. The cells were washed\nwith PBS, lysed in 140 µL RIPA buffer (Beyotime, China), and centrifuged (12,000 rpm,\n5 min). Supernatants were analyzed for total antioxidant capacity (T-AOC), superoxide\ndismutase (SOD), malondialdehyde (MDA), glutathione (GSH) and glutathione peroxidase\n(GSH-Px) levels.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\n2.7. Western Blot Analysis\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nPMECs were seeded in 12-well plates at 2.5 × 104 cells/mL (1 mL/well) and cultured\nat 37 ◦C with 5% CO2 for 48 h. Cells were treated with 1 µM SeY for 24 h, followed by\n50 µg/mL LPS for 24 h. After treatment, the cells were washed with PBS, and proteins\nwere extracted using RIPA buffer (Beyotime, Shanghai, China). Protein concentrations\nwere measured with a BCA Protein Assay Kit (Beyotime, Shanghai, China). Equal protein\n(10–20 µg) was separated by SDS-PAGE (Invitrogen, Carlsbad, CA, USA) and transferred\nto nitrocellulose membranes (Millipore, Bedford, MA, USA), followed by incubation with\nprimary antibodies (Table 2).\n**BLOCK**fs== 9.0**p== 3.0**b== 0.2**t== 0.8**l== 0.3**r== 0.2**\nTable 2. Information related to primary and secondary antibodies in the Western blot.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\nAntibody\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.6**\nTLR4\nNF-κB\np-NF-κB\nIκB\np-IκB\np38\np-P38\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nCompany\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.7**r== 0.2**\nCode No.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.9**r== 0.1**\nDilution\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.5**r== 0.3**\nProteintech (Rosemont, IL, USA)\nCST (Hong Kong, China)\nCST\nAbcam (Cambridge, UK)\nAbcam\nProteintech\nCST\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.7**r== 0.2**\n66350-1\n4764S\n3033S\nab32518\nab133462\n66234-1\n4092S\n**BLOCK**fs== 9.0**p== 4.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\nTable 2. Cont.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\nAntibody\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.6**r== 0.4**\nCompany\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.7**r== 0.2**\nCode No.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.9**t== 0.1**l== 0.9**r== 0.1**\nDilution\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.3**r== 0.5**\nJNK\np-JNK\nERK\np-ERK\nβ-actin\nGoat Anti-Rabbit IgG\nGoat Anti-Mous IgG\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.5**r== 0.3**\nCST\nCST\nCST\nCST\nAbcam\nZenbio (Durham, NC, USA)\nZenbio\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.8**r== 0.2**\n9252S\n4668S\n9102S\n9101S\nab8226\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\n2.8. Statistical Analysis\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nData were analyzed using IBM SPSS 26.0 with one-way ANOVA and LSD post-hoc\ntests for group comparisons. GraphPad Prism 8.0 was used for additional analyses and\nvisualizations. Significance was set at p < 0.05, with p < 0.01 indicating high significance.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.6**t== 0.3**l== 0.3**r== 0.6**\n3. Results\n3.1. Viability of PMECs\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nTo assess SeY’s effect on PMECs viability, cells were exposed to 0, 0.5, 1, 2, 4, or 8 µM\nSeY for 24 h, and their viability was assessed using the CCK-8 assay. As illustrated in\nFigure 1A, viability increased dose-dependently, peaking at 1 µM, which was selected as\nthe optimal pretreatment concentration. Figure 1B shows that LPS significantly reduced\nviability compared to the controls, but pretreatment with 1 µM SeY partially restored\nviability (p < 0.05).\n**BLOCK**fs== 9.0**p== 4.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nFigure 1. Effect of selenium yeast (SeY) on cell viability of porcine mammary epithelial cells (PMECs).\n(A) Viability of cells treated with varying concentrations of SeY (0, 0.5, 1, 2, 4, and 8 µM) for 24 h.\n(B) Cell viability was assessed using the CCK-8 assay. Bars labeled with different letters (a, b, and\nc) indicate significant differences between groups (p < 0.05). Data are presented as means ± SEM\n(n = 6). Experimental groups: CON (control, untreated cells), LPS (cells treated with 50 µg/mL LPS)\nand LPS + SeY (cells pretreated with 1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\n3.2. Inflammatory Factors\n**BLOCK**fs== 10.0**p== 4.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFigure 2 shows that LPS significantly upregulated the mRNA expression levels of\nTNF-α, IL-6, IL-1β, and IL-8 compared to the controls (p < 0.05). Consistently, ELISA results\nconfirmed that LPS also increased the levels of these inflammatory cytokines (p < 0.05).\nPretreatment with SeY significantly reduced both mRNA expression and concentrations of\nthese inflammatory cytokines, bringing levels close to the controls (p < 0.05).\n**BLOCK**fs== 9.0**p== 5.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nFigure 2. Effect of SeY on the mRNA expression and protein levels of inflammatory cytokines in\nLPS-induced PMECs. (A) mRNA expression levels of inflammatory cytokines. (B) Concentrations\nof inflammatory cytokines. Data are presented as means ± SEM (n = 6). Bars labeled with different\nletters (a, b) indicate significant differences between groups (p < 0.05). Experimental groups: CON\n(control, untreated cells), LPS (cells treated with 50 µg/mL LPS), and LPS + SeY (cells pretreated with\n1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\n3.3. Antioxidant Levels\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 3 shows that LPS treatment significantly decreased T-AOC, SOD, GSH, and\nGSH-Px, while markedly increasing MDA levels (p < 0.05). Pretreatment with SeY effec-\ntively restored T-AOC, SOD, and MDA levels to near-control values (p > 0.05). However,\nGSH and GSH-Px levels remained intermediate, showing significant differences from both\nthe LPS-only and control groups (p < 0.05), suggesting a partial but not complete recovery\nof antioxidant capacity.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.3**t== 0.7**l== 0.3**r== 0.4**\n3.4. NF-κB and MAPK Signaling Pathways\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nLPS treatment markedly enhanced the phosphorylation of key NF-κB (IκBα and\np65) and MAPK (JNK, ERK, and p38) signaling proteins compared to the control group\n(p < 0.05), indicating robust activation of these inflammatory pathways (Figure 4A–D).\nSeY pretreatment effectively suppressed this phosphorylation, restoring levels close to\nthose of the controls (p < 0.05), suggesting its inhibitory effect on LPS-induced NF-κB and\nMAPK activation (Figure 4A–D). Similarly, SeY pretreatment significantly attenuated the\nLPS-induced upregulation of Myd88, Irak4, Irak1, and Traf6 mRNA expression (p < 0.05),\nfurther demonstrating its regulatory role in suppressing TLR4-mediated inflammatory\nsignaling (Figure 4E).\n**BLOCK**fs== 9.0**p== 6.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nFigure 3. Effect of SeY on the antioxidant capacity of LPS-induced PMECs.\n(A) Levels of to-\ntal antioxidant capacity (T-AOC), (B) superoxide dismutase (SOD), (C) malondialdehyde (MDA),\n(D) glutathione (GSH), and (E) glutathione peroxidase (GSH-Px) were measured using antioxidant\ndetection kits. Data are presented as means ± SEM (n = 6). Bars labeled with different letters (a, b,\nand c) indicate significant differences between groups (p < 0.05). Experimental groups: CON (control,\nuntreated cells), LPS (cells treated with 50 µg/mL LPS), and LPS + SeY (cells pretreated with 1 µM\nSeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 9.0**p== 6.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\nFigure 4. Cont.\n**BLOCK**fs== 9.0**p== 7.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 4. Phosphorylation levels of NF-κB and MAPK signaling pathway proteins in PMECs.\n(A,B) Phosphorylation levels of key NF-κB signaling pathway proteins in PMECs. (C,D) Phospho-\nrylation levels of key MAPK signaling pathway proteins in PMECs. (E) mRNA expression levels\nof NF-κB pathway-related genes in PMECs. Data are presented as means ± SEM (n = 3). Different\nsuperscript letters (a, b) indicate significant differences between groups (p < 0.05). Experimental\ngroups: CON (control, untreated cells), LPS (cells treated with 50 µg/mL LPS), and LPS + SeY (cells\npretreated with 1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.7**l== 0.3**r== 0.3**\n3.5. Intracellular and Extracellular Triglyceride Levels in PMECs\n**BLOCK**fs== 10.0**p== 7.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nLPS treatment significantly decreased intracellular (Figure 5A) and extracellular triglyc-\neride levels (Figure 5B) compared to the controls (p < 0.05). However, in the LPS + SeY\ngroup, triglyceride levels were restored to near-control levels (p < 0.05). Oil Red O staining\n(Figure 5C) further confirmed that LPS exposure suppressed lipid droplet formation, while\nSeY pretreatment partially rescued this effect. These findings suggest that LPS disrupts\ntriglyceride synthesis and lipid storage in PMECs, whereas SeY pretreatment counteracts\nthese impairments, thereby promoting lipid accumulation.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nFigure 5. Effect of SeY on intracellular and extracellular triglyceride levels and lipid droplet formation\nin LPS-induced PMECs. (A) Extracellular triglyceride content in PMECs. (B) Intracellular triglyceride\n(TAG) content in PMECs. (C) Oil Red O staining showing lipid droplet formation in PMECs. Data\nare presented as means ± SEM (n = 3). Bars labeled with different letters (a, b) indicate significant\ndifferences between groups (p < 0.05). Experimental groups: CON (control, untreated cells), LPS\n(cells treated with 50 µg/mL LPS), and LPS + SeY (cells pretreated with 1 µM SeY followed by\n50 µg/mL LPS).\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\n3.6. mRNA and Protein Expression Related to Milk Fat and Protein Synthesis\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nLPS significantly downregulated the mRNA expression of key molecules involved in\nmilk fat and protein synthesis, including ACACA, DGAT1, SREBP1, FASN, WAP, α-casein\nand β-casein, compared to the control group (Figure 6, p < 0.05). In the LPS + SeY group,\nmRNA levels of these molecules were significantly higher than those in the LPS group\n(p < 0.05). Consistently, the protein expression of these molecules was also significantly\nhigher in the SeY-pretreated cells than in the LPS group (Figure 7A,B). These results suggest\nthat SeY effectively counteracts LPS-induced suppression of milk fat and protein synthesis.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFigure 6. Effect of SeY on the mRNA expression of genes related to milk fat and milk protein synthesis\nin LPS-induced PMECs. mRNA expression levels of acetyl-CoA carboxylase alpha (ACACA) (A),\ndiacylglycerol O-acyltransferase 1 (DGAT1) (B), sterol regulatory element-binding protein 1 (SREBP1)\n**BLOCK**fs== 9.0**p== 9.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\n(C), fatty acid synthase (FASN) (D), whey acidic protein (WAP) (E), alpha-casein (α-casein) (F), and\nbeta-casein (β-casein) (G) in PMECs. Data are presented as means ± SEM (n = 3). Bars labeled with\ndifferent letters (a, b, and c) indicate significant differences between groups (p < 0.05). Experimental\ngroups: CON (control, untreated cells), LPS (cells treated with 50 µg/mL LPS), and LPS + SeY (cells\npretreated with 1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 9.0**p== 9.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nFigure 7. Effect of SeY on the milk fat and milk protein synthesis in LPS-induced PMECs.\n(A,B) Protein expression levels of key regulators involved in milk fat in PMECs. (C,D) Protein\nexpression levels of key regulators involved in milk protein synthesis in PMECs. Data are presented\nas means ± SEM (n = 3). Bars labeled with different letters (a, b) indicate significant differences\nbetween groups (p < 0.05). Experimental groups: CON (control, untreated cells), LPS (cells treated\nwith 50 µg/mL LPS), and LPS + SeY (cells pretreated with 1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 10.0**p== 9.0**b== 0.2**t== 0.8**l== 0.3**r== 0.3**\n3.7. Pathways Related to Milk Fat and Protein Synthesis\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nTo further explore the regulatory mechanisms underlying milk fat and protein synthe-\nsis, we examined the mechanistic target of rapamycin (mTOR) and Janus kinase 2-signal\ntransducer and activator of transcription 5 (JAK2-STAT5) pathways. Western blot analysis\nshowed that LPS treatment significantly reduced phosphorylation levels of mTOR, S6K1,\n4EBP1, STAT5, and JAK2 compared to the control group (p < 0.05) (Figure 8A–D). However,\nSeY pretreatment significantly restored the phosphorylation of these proteins (p < 0.05),\nbringing them to levels comparable to those of the controls (Figure 8A–D).\n**BLOCK**fs== 9.0**p== 10.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 8.\nImpact of SeY on milk synthesis signaling pathways in LPS-induced PMECs.\n(A,B) Activation of the mechanistic target of rapamycin (mTOR) signaling pathway in PMECs.\n(C,D) Activation of the Janus kinase 2-signal transducer and activator of transcription 5 (JAK2-\nSTAT5) signaling pathway in PMECs. The data are the means ± SEM (n = 3). Bars labeled with\ndifferent letters (a, b) indicate significant differences between groups (p < 0.05). Experimental groups:\nCON (control, untreated cells), LPS (cells treated with 50 µg/mL LPS), and LPS + SeY (cells pretreated\nwith 1 µM SeY followed by 50 µg/mL LPS).\n**BLOCK**fs== 12.0**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\n4. Discussion\n**BLOCK**fs== 10.0**p== 10.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nMastitis is a significant concern in dairy cattle, as it directly impacts milk production\nand quality, leading to substantial economic losses in the dairy industry [40]. Extensive\nresearch has focused on anti-inflammatory strategies, such as vitamin E and selenium\nsupplementation, which have demonstrated beneficial effects in modulating immune re-\nsponses and alleviating oxidative and inflammatory stress in perinatal cows [41]. However,\ncompared to dairy cattle, mastitis in sows has received relatively less research attention,\ndespite its severe consequences, including maternal inflammation, impaired lactation, and\nincreased piglet mortality [42]. This underscores the urgent need for further research into\neffective preventive and therapeutic strategies for sow mastitis.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.1**l== 0.3**r== 0.1**\nInflammation is a complex and essential defense mechanism triggered by various\nstimuli, including microbial infection and tissue damage [43,44]. In the mammary gland, ex-\ncessive inflammatory responses can disrupt normal metabolic functions, compromise milk\nsynthesis, and negatively affect overall lactation performance. Enhancing immune function\nand anti-inflammatory capacity is therefore critical for maintaining mammary gland health\nand sustaining optimal milk production. LPS, a key component of Gram-negative bacterial\ncell walls, is a well-established inflammatory inducer that severely disrupts mammary\ngland homeostasis. LPS exposure impairs mammary epithelial cell function by triggering\noxidative stress, reducing antioxidant capacity, and negatively affecting milk yield and\ncomposition [4,11,45,46]. Mechanistically, LPS binds to TLR4 on the cell surface [47], initiat-\ning a cascade of inflammatory signaling events [39,48]. In this study, SeY was evaluated for\nits protective effects on PMECs. A dose-dependent response in cell viability was observed,\nwith the highest viability detected at 1 µM SeY after 24 h. Pretreatment with 1 µM SeY for\n24 h, followed by 50 µg/mL LPS exposure for 24 h, significantly improved cell viability\ncompared to the LPS group. These results suggest that SeY mitigates LPS-induced via-\nbility reduction, likely through its antioxidant and anti-inflammatory properties, thereby\nsupporting PMEC resilience under inflammatory conditions.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nOxidative stress results arises from an imbalance between reactive oxygen species\n(ROS) production and the body’s antioxidant defense mechanisms and is closely linked to\ninflammation [49,50]. Selenium plays a critical role in repairing oxidative stress-induced\ndamage and enhancing cellular antioxidant capacity [51]. Previous studies have shown\nthat SeY regulates selenoprotein expression and enhances antioxidant capacity in PMECs\nvia activation of the p38/JNK signaling pathway, thereby promoting cell viability [32,52].\nIn this study, SeY pretreatment significantly increased T-AOC, SOD, GSH, and GSH-Px\nlevels while reducing MDA accumulation in LPS-induced inflammatory cells. These results\nare consistent with those of Yang et al. [53], who reported that hydroxy-selenomethionine\n(HMSeBA) can help dairy cows overcome heat stress by enhancing antioxidant capacity.\nBy restoring redox balance, SeY not only mitigates oxidative stress-induced damage but\nalso suppresses inflammatory responses.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nEarlier research demonstrated that selenium pretreatment suppressed the expression\nof pro-inflammatory genes, such as TNF-α and COX-2, by inhibiting NF-κB p65, IκBα,\np38, ERK, and JNK phosphorylation in mammary epithelial cells [48]. Similarly, selenium\nreduced the gene expression of inflammatory cytokines (TNF-α, IL-6β, and IL-2) in Staphy-\nlococcus aureus-stimulated bovine mammary epithelial cells by modulating TLR4, NF-κB,\nand MAPK signaling pathways [54]. In alignment with previous findings, the present\nstudy demonstrates that pretreatment with SeY markedly decreased both the mRNA levels\nand protein expression of pro-inflammatory cytokines in PMECs subjected to LPS-induced\ninflammatory conditions.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nThe NF-κB signaling system is critical in cellular responses to stimuli such as stress,\npro-inflammatory cytokines, free radicals, and heavy metals. The dysregulation of this\npathway is closely associated with inflammatory diseases [55]. Additionally, the MAPK\nfamily serves as a critical downstream signaling hub for various growth factor receptors\nand pattern recognition receptors. These kinases are frequently hyperactivated during\ninflammation, leading to the amplification of pro-inflammatory signaling cascades [56].\nThe excessive production of inflammatory factors is a primary contributor to cell and tissue\ndamage during inflammation. Previous studies have shown that Se inhibited the LPS-\ninduced inflammatory response by suppressing NF-κB and MAPK in mammary epithelial\ncells and bovine endometrial epithelial cells [48,57]. In line with these findings, our study\ndemonstrates that SeY similarly exerts anti-inflammatory effects by targeting the NF-κB\nand MAPK signaling pathways in PMECs. Specifically, SeY reduced the mRNA expression\n**BLOCK**fs== 10.0**p== 12.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nof key NF-κB pathway genes, including Myd88, Irak1, Irak4, and Traf6, and restored phos-\nphorylation levels of NF-κB and MAPK pathway proteins (p65, IκBα, p38, ERK, and JNK)\nto levels comparable to the control group. These results not only confirm the conserved\nanti-inflammatory mechanism of selenium across different cell types but also provide novel\ninsights into the specific molecular targets of SeY in mammary epithelial cells.\n**BLOCK**fs== 10.0**p== 12.0**b== 0.6**t== 0.2**l== 0.3**r== 0.1**\nThe health and structural integrity of the mammary gland are essential for female\nlivestock to maintain optimal lactation performance. Lactation ability and milk quality\nare directly linked to the growth rate and survival of offspring [58]. Research has shown\nthat dietary supplementation with 0.3 mg/kg SeY enhances lactation performance in\nlactating donkeys and improves milk protein production efficiency [59]. Similarly, our\nlaboratory previously demonstrated that the addition of yeast culture combined with\norganic selenium increased the capacity for milk fat synthesis in lactating sows [32]. Milk\nfat and protein synthesis are critical physiological functions of mammary epithelial cells [60].\nInflammation can inhibit milk synthesis by disrupting related signaling pathways [61].\nIn this study, SeY alleviated inflammation and enhanced the expression of milk fat and\nprotein synthesis-related molecules. The mTOR and JAK2-STAT5 pathways are essential for\nmammary development and milk synthesis [62]. SeY pretreatment consistently alleviated\nthe inhibitory effects of LPS, significantly restoring the phosphorylation levels of the mTOR\nand JAK2-STAT5 signaling pathways. These results align with previous studies, which\ndemonstrated that organic selenium supplementation in goats notably increases milk fat\nand protein levels [63]. Together, these findings suggest that SeY influences milk fat and\nprotein synthesis by modulating key signaling pathways.\n**BLOCK**fs== 12.0**p== 12.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\n5. Conclusions\n**BLOCK**fs== 10.0**p== 12.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nIn this study, SeY effectively mitigated LPS-induced inflammation and oxidative stress\nin PMECs, as evidenced by reduced inflammatory cytokine expression and enhanced an-\ntioxidant defense. SeY also preserved milk fat and protein synthesis pathways, suggesting\nits potential to support lactation performance. However, this in vitro study has limitations,\nparticularly in its applicability to the complex in vivo environment, and further research\nis needed to confirm these findings in animal models. Future studies should explore\nthe molecular mechanisms underlying SeY’s effects, investigate its long-term impact on\nmammary gland health, and evaluate its potential in combination with other nutritional\ninterventions to optimize sow productivity and reduce mastitis incidence.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nAuthor Contributions: S.Z. and W.G. designed the research; Z.H., S.S. and B.Z. performed the\nresearch; D.C. and S.Y. analyzed the data; and Z.H. wrote the manuscript. All authors have read and\nagreed to the published version of the manuscript.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nFunding: This study was financially supported by the National Key R&D Program of China\n(2021YFD1300700 and 2024YFD1301004), the Guangdong Basic and Applied Basic Research Founda-\ntion (2023A1515012098), the Science and Technology Program of Guangzhou (202102020056), and the\nTalent Project of the Wen’s Science and Innovation Center (SCAU).\n**BLOCK**fs== 9.0**p== 12.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nInstitutional Review Board Statement: Not applicable.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nInformed Consent Statement: Not applicable.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\nData Availability Statement: The original contributions generated for this study are included in the\narticle; further inquiries can be directed to the corresponding author.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.1**t== 0.9**l== 0.3**r== 0.3**\nConflicts of Interest: The authors declare no conflicts of interest.\n**BLOCK**fs== 9.0**p== 13.0**b== 0.7**t== 0.1**l== 0.1**r== 0.1**\nSeegers, H.; Fourichon, C.; Beaudeau, F. Production effects related to mastitis and mastitis economics in dairy cattle herds.\nVet. Res. 2003, 34, 475–491. [CrossRef] [PubMed]\nCavaillon, J.M. Exotoxins and endotoxins: Inducers of inflammatory cytokines. Toxicon 2018, 149, 45–53. [CrossRef] [PubMed]\nNing, L.T.; Dong, G.Z.; Ao, C.; Zhang, D.G.; Erdene, K.; Zhang, F.Q.; Wen, J.; Zhang, T.L. Effects of continuous low dose infusion\nof lipopolysaccharide on inflammatory responses, milk production and milk quality in dairy cows. J. Anim. Physiol. Anim. Nutr.\n2018, 102, e262-e269. [CrossRef] [PubMed]\nZhang, K.; Chang, G.; Xu, T.; Xu, L.; Guo, J.; Jin, D.; Shen, X. Lipopolysaccharide derived from the digestive tract activates\ninflammatory gene expression and inhibits casein synthesis in the mammary glands of lactating dairy cows. Oncotarget 2016, 7,\n9652–9665. [CrossRef]\nLiu, L.; Zhang, L.I.; Lin, Y.E.; Bian, Y.; Gao, X.; Qu, B.O.; Li, Q. 14-3-3gamma regulates cell viability and milk fat synthesis in\nlipopolysaccharide-induced dairy cow mammary epithelial cells. Exp. Ther. Med. 2016, 11, 1279–1287. [CrossRef]\nBurvenich, C.; Van Merris, V.; Mehrzad, J.; Diez-Fraile, A.; Duchateau, L. Severity of E. coli mastitis is mainly determined by cow\nfactors. Vet. Res. 2003, 34, 521–564. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n7. Wenz, J.R.; Barrington, G.M.; Garry, F.B.; Ellis, R.P.; Magnuson, R.J. Escherichia coli isolates’ serotypes, genotypes, and virulence\n**BLOCK**fs== 9.0**p== 13.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\ngenes and clinical coliform mastitis severity. J. Dairy Sci. 2006, 89, 3408–3412. [CrossRef]\nHalasa, T.; Huijps, K.; Osteras, O.; Hogeveen, H. Economic effects of bovine mastitis and mastitis management: A review. Vet. Q.\n2007, 29, 18–31. [CrossRef]\nZhang, S.; Chen, F.; Zhang, Y.; Lv, Y.; Heng, J.; Min, T.; Li, L.; Guan, W. Recent progress of porcine milk components and mammary\ngland function. J. Anim. Sci. Biotechnol. 2018, 9, 77. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n10. Wu, Z.; Heng, J.; Tian, M.; Song, H.; Chen, F.; Guan, W.; Zhang, S. Amino acid transportation, sensing and signal transduction in\nthe mammary gland: Key molecular signalling pathways in the regulation of milk synthesis. Nutr. Res. Rev. 2020, 33, 287–297.\n[CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n11. Aitken, S.L.; Corl, C.M.; Sordillo, L.M. Immunopathology of mastitis: Insights into disease recognition and resolution. J. Mammary\n**BLOCK**fs== 9.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.5**\nGland Biol. Neoplasia 2011, 16, 291–304. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n12. Laflamme, N.; Soucy, G.; Rivest, S. Circulating cell wall components derived from gram-negative, not gram-positive, bacteria\ncause a profound induction of the gene-encoding Toll-like receptor 2 in the CNS. J. Neurochem. 2001, 79, 648–657. [CrossRef]\n[PubMed]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\n13. Wang, X.; Quinn, P.J. Endotoxins: Lipopolysaccharides of gram-negative bacteria. In Endotoxins: Structure, Function and Recognition;\nSubcellular Biochemistry Series; Springer Dordrecht: Dordrecht, The Netherlands, 2010; Volume 53, pp. 3–25. [CrossRef]\n14. Chow, J.C.; Young, D.W.; Golenbock, D.T.; Christ, W.J.; Gusovsky, F. Toll-like receptor-4 mediates lipopolysaccharide-induced\n**BLOCK**fs== 9.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.4**\nsignal transduction. J. Biol. Chem. 1999, 274, 10689–10692. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n15. Bandow, K.; Kusuyama, J.; Shamoto, M.; Kakimoto, K.; Ohnishi, T.; Matsuguchi, T. LPS-induced chemokine expression in\nboth MyD88-dependent and -independent manners is regulated by Cot/Tpl2-ERK axis in macrophages. FEBS Lett. 2012, 586,\n1540–1546. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n16. Kawai, T.; Akira, S. The role of pattern-recognition receptors in innate immunity: Update on Toll-like receptors. Nat. Immunol.\n**BLOCK**fs== 9.0**p== 13.0**b== 0.4**t== 0.6**l== 0.1**r== 0.7**\n2010, 11, 373–384. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n17. Milan Manani, S.; Virzi, G.M.; Giuliani, A.; Baretta, M.; Corradi, V.; De Cal, M.; Biasi, C.; Crepaldi, C.; Ronco, C. Lipopolysaccharide\n**BLOCK**fs== 9.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\nEvaluation in Peritoneal Dialysis Patients with Peritonitis. Blood Purif. 2020, 49, 434–439. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n18. Hung, Y.-L.; Suzuki, K. The pattern recognition receptors and lipopolysaccharides (LPS)-induced systemic inflammation. Int. J.\n**BLOCK**fs== 9.0**p== 13.0**b== 0.3**t== 0.7**l== 0.1**r== 0.6**\nRes. Stud. Med. Health Sci. 2017, 2, 1–7.\n**BLOCK**fs== 9.0**p== 13.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\n19. Burk, R.F. Selenium, an antioxidant nutrient. Nutr. Clin. Care 2002, 5, 75–79. [CrossRef]\n20. Avery, J.C.; Hoffmann, P.R. Selenium, selenoproteins, and immunity. Nutrients 2018, 10, 1203. [CrossRef]\n21. Huang, Z.; Rose, A.H.; Hoffmann, P.R. The role of selenium in inflammation and immunity: From molecular mechanisms to\n**BLOCK**fs== 9.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.4**\ntherapeutic opportunities. Antioxid. Redox Signal. 2012, 16, 705–743. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n22. Lv, C.H.; Wang, T.; Regmi, N.; Chen, X.; Huang, K.; Liao, S.F. Effects of dietary supplementation of selenium-enriched probiotics\non production performance and intestinal microbiota of weanling piglets raised under high ambient temperature. J. Anim. Physiol.\nAnim. Nutr. 2015, 99, 1161–1171. [CrossRef] [PubMed]\nSurai, P.; Fisinin, V. Selenium in sow nutrition. Anim. Feed Sci. Technol. 2016, 211, 18–30. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n23.\n24. Chen, J.; Han, J.; Guan, W.; Chen, F.; Wang, C.; Zhang, Y.; Lv, Y.; Lin, G. Selenium and vitamin E in sow diets: I. Effect on\n**BLOCK**fs== 9.0**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\nantioxidant status and reproductive performance in multiparous sows. Anim. Feed Sci. Technol. 2016, 221, 111–123. [CrossRef]\n**BLOCK**fs== 9.0**p== 13.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n25. Chen, J.; Zhang, F.; Guan, W.; Song, H.; Tian, M.; Cheng, L.; Shi, K.; Song, J.; Chen, F.; Zhang, S. Increasing selenium supply for\nheat-stressed or actively cooled sows improves piglet preweaning survival, colostrum and milk composition, as well as maternal\nselenium, antioxidant status and immunoglobulin transfer. J. Trace Elem. Med. Biol. 2019, 52, 89–99. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n26. Xiong, L.; Lin, T.; Yue, X.; Zhang, S.; Liu, X.; Chen, F.; Zhang, S.; Guan, W. Maternal Selenium-Enriched Yeast Supplementation\nin Sows Enhances Offspring Growth and Antioxidant Status through the Nrf2/Keap1 Pathway. Antioxidants 2023, 12, 2064.\n[CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n27. Chen, J.; Tian, M.; Guan, W.; Wen, T.; Yang, F.; Chen, F.; Zhang, S.; Song, J.; Ren, C.; Zhang, Y.; et al. Increasing selenium\nsupplementation to a moderately-reduced energy and protein diet improves antioxidant status and meat quality without affecting\ngrowth performance in finishing pigs. J. Trace Elem. Med. Biol. 2019, 56, 38–45. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n28. Mangiapane, E.; Pessione, A.; Pessione, E. Selenium and selenoproteins: An overview on different biological systems. Curr. Protein\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.6**\nPept. Sci. 2014, 15, 598–607. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n29. Calamari, L.; Petrera, F.; Bertin, G. Effects of either sodium selenite or Se yeast (Sc CNCM I-3060) supplementation on selenium\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\nstatus and milk characteristics in dairy cows. Livest. Sci. 2010, 128, 154–165. [CrossRef]\nJuniper, D.T.; Phipps, R.H.; Givens, D.I.; Jones, A.K.; Green, C.; Bertin, G. Tolerance of ruminant animals to high dose in-feed\nadministration of a selenium-enriched yeast. J. Anim. Sci. 2008, 86, 197–204. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n31. Mahan, D. Effect of organic and inorganic selenium sources and levels on sow colostrum and milk selenium content. J. Anim. Sci.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.7**\n2000, 78, 100–105. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n32. Zhang, S.; Wu, Z.; Heng, J.; Song, H.; Tian, M.; Chen, F.; Guan, W. Combined yeast culture and organic selenium supplementation\nduring late gestation and lactation improve preweaning piglet performance by enhancing the antioxidant capacity and milk\ncontent in nutrient-restricted sows. Anim. Nutr. 2020, 6, 160–167. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n33. Pecoraro, B.M.; Leal, D.F.; Frias-De-Diego, A.; Browning, M.; Odle, J.; Crisci, E. The health benefits of selenium in food animals: A\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.5**\nreview. J. Anim. Sci. Biotechnol. 2022, 13, 58. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n34. Khalili, M.; Chamani, M.; Amanlou, H.; Nikkhah, A.; Sadeghi, A.A.; Dehkordi, F.K.; Rafiei, M.; Shirani, V. The effect of feeding\ninorganic and organic selenium sources on the hematological blood parameters, reproduction and health of dairy cows in the\ntransition period. Acta Scientiarum Anim. Sci. 2019, 42, e45371. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n35. Al-Waeli, A.; Zoidis, E.; Pappas, A.; Demiris, N.; Zervas, G.; Fegeros, K. The role of organic selenium in cadmium toxicity: Effects\n**BLOCK**fs== 9.0**p== 14.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\non broiler performance and health status. Animal 2013, 7, 386–393. [CrossRef]\nFalk, M.; Bernhoft, A.; Framstad, T.; Salbu, B.; Wisløff, H.; Kortner, T.M.; Kristoffersen, A.B.; Oropeza-Moe, M. Effects of dietary\nsodium selenite and organic selenium sources on immune and inflammatory responses and selenium deposition in growing pigs.\nJ. Trace Elem. Med. Biol. 2018, 50, 527–536. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n37. Zavodnik, L.; Shimkus, A.; Belyavsky, V.; Voronov, D.; Shimkiene, A.; Voloshin, D.B. Effects of organic selenium yeast administra-\n**BLOCK**fs== 9.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.2**\ntion on perinatal performance, growth efficiency and health status in pigs. Arch. Zootech. 2011, 14, 5.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n38. Zheng, Y.M.; He, X.Y. Characteristics and EGFP expression of porcine mammary gland epithelial cells. Res. Vet. Sci. 2010, 89,\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.5**l== 0.1**r== 0.8**\n383–390. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n39. Zhang, W.; Xiong, L.; Chen, J.; Tian, Z.; Liu, J.; Chen, F.; Ren, M.; Guan, W.; Zhang, S. Artemisinin Protects Porcine Mammary\nEpithelial Cells against Lipopolysaccharide-Induced Inflammatory Injury by Regulating the NF-kappaB and MAPK Signaling\nPathways. Animals 2021, 11, 1528. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n40. Asfaw, M.; Negash, A. Review on impact of bovine mastitis in dairy production. Adv. Biol. Res. 2017, 11, 126–131.\n41. Khan, M.Z.; Ma, Y.; Xiao, J.; Chen, T.; Ma, J.; Liu, S.; Wang, Y.; Khan, A.; Alugongo, G.M.; Cao, Z. Role of Selenium and Vitamins E\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nand B9 in the Alleviation of Bovine Mastitis during the Periparturient Period. Antioxidants 2022, 11, 657. [CrossRef]\nFriendship, R.; O’sullivan, T. Sow health. In The Gestating and Lactating Sow; Wageningen Academic: Wageningen, The Netherlands,\n2015; pp. 409–421.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.2**\n43. Medzhitov, R. Origin and physiological roles of inflammation. Nature 2008, 454, 428–435. [CrossRef] [PubMed]\n44.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\nSherwood, E.R.; Toliver-Kinsky, T. Mechanisms of the inflammatory response. Best Pract. Res. Clin. Anaesthesiol. 2004, 18, 385–405.\n[CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.3**t== 0.7**l== 0.1**r== 0.1**\n45. Zheng, J.; Watson, A.D.; Kerr, D.E. Genome-wide expression analysis of lipopolysaccharide-induced mastitis in a mouse model.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.7**l== 0.1**r== 0.1**\nInfect. Immun. 2006, 74, 1907–1915. [CrossRef] [PubMed]\nJohnzon, C.-F.; Dahlberg, J.; Gustafson, A.-M.; Waern, I.; Moazzami, A.A.; Östensson, K.; Pejler, G. The effect of lipopolysaccharide-\ninduced experimental bovine mastitis on clinical parameters, inflammatory markers, and the metabolome: A kinetic approach.\nFront. Immunol. 2018, 9, 1487. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.1**\n47. Zhang, G.; Ghosh, S. Molecular mechanisms of NF-κB activation induced by bacterial lipopolysaccharide through Toll-like\n**BLOCK**fs== 9.0**p== 14.0**b== 0.2**t== 0.8**l== 0.1**r== 0.5**\nreceptors. J. Endotoxin Res. 2000, 6, 453–457. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.8**l== 0.1**r== 0.1**\n48. Zhang, W.; Zhang, R.; Wang, T.; Jiang, H.; Guo, M.; Zhou, E.; Sun, Y.; Yang, Z.; Xu, S.; Cao, Y. Selenium inhibits LPS-induced\npro-inflammatory gene expression by modulating MAPK and NF-κB signaling pathways in mouse mammary epithelial cells in\nprimary culture. Inflammation 2014, 37, 478–485. [CrossRef]\nˇDuraˇcková, Z. Some current insights into oxidative stress. Physiol. Res. 2010, 59, 4. [CrossRef]\n**BLOCK**fs== 9.0**p== 14.0**b== 0.1**t== 0.9**l== 0.1**r== 0.1**\n49.\n50. Mancini, A.; Di Segni, C.; Raimondo, S.; Olivieri, G.; Silvestrini, A.; Meucci, E.; Currò, D. Thyroid hormones, oxidative stress, and\n**BLOCK**fs== 9.0**p== 15.0**b== 0.9**t== 0.1**l== 0.1**r== 0.1**\n51. Aboul-Soud, M.A.; Al-Othman, A.M.; El-Desoky, G.E.; Al-Othman, Z.A.; Yusuf, K.; Ahmad, J.; Al-Khedhairy, A.A. Hepatopro-\ntective effects of vitamin E/selenium against malathion-induced injuries on the antioxidant status and apoptosis-related gene\nexpression in rats. J. Toxicol. Sci. 2011, 36, 285–296. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\n52. Wu, C.; Cui, C.; Zheng, X.; Wang, J.; Ma, Z.; Zhu, P.; Lin, G.; Zhang, S.; Guan, W.; Chen, F. The selenium yeast vs selenium\nmethionine on cell viability, selenoprotein profile and redox status via JNK/P38 pathway in porcine mammary epithelial cells.\nFront. Vet. Sci. 2022, 9, 850935. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\n53. Yang, Z.; Zheng, Y.; Ren, K.; Wang, W.; Li, S. Hydroxy-selenomethionine helps cows to overcome heat stress by enhancing\n**BLOCK**fs== 9.0**p== 15.0**b== 0.8**t== 0.2**l== 0.1**r== 0.1**\nantioxidant capacity and alleviating blood-milk barrier damage. Anim. Nutr. 2025, 20, 171–181. [CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.2**l== 0.1**r== 0.1**\n54. Wang, H.; Bi, C.; Wang, Y.; Sun, J.; Meng, X.; Li, J. Selenium ameliorates Staphylococcus aureus-induced inflammation in bovine\nmammary epithelial cells by inhibiting activation of TLR2, NF-κB and MAPK signaling pathways. BMC Vet. Res. 2018, 14, 1–8.\n[CrossRef] [PubMed]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n55. Mitchell, S.; Vargas, J.; Hoffmann, A. Signaling via the NFκB system. Wiley Interdiscip. Rev. Syst. Biol. Med. 2016, 8, 227–241.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.8**\n[CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.1**\n56. Kim, E.K.; Choi, E.-J. Pathological roles of MAPK signaling pathways in human diseases. Biochim. Biophys. Acta (BBA)—Mol.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.7**t== 0.3**l== 0.1**r== 0.6**\nBasis Dis. 2010, 1802, 396–405. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\n57. Liu, J.; Wang, J.; Xv, S.; Bi, C. Selenium Counteracts Tight Junction Disruption and Attenuates the NF-kappaB-Mediated\nInflammatory Response in Staphylococcus aureus-Infected Mouse Mammary Glands. Biol. Trace Elem. Res. 2025, 203, 963–972.\n[CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.1**\n58. Purba, F.Y.; Ueda, J.; Nii, T.; Yoshimura, Y.; Isobe, N. Effects of intrauterine infusion of bacterial lipopolysaccharides on the\n**BLOCK**fs== 9.0**p== 15.0**b== 0.6**t== 0.4**l== 0.1**r== 0.2**\nmammary gland inflammatory response in goats. Vet. Immunol. Immunopathol. 2020, 219, 109972. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.4**l== 0.1**r== 0.1**\n59. Tong, M.; Li, S.; Hui, F.; Meng, F.; Li, L.; Shi, B.; Zhao, Y.; Guo, X.; Guo, Y.; Yan, S. Effects of Dietary Selenium Yeast Supplementation\non Lactation Performance, Antioxidant Status, and Immune Responses in Lactating Donkeys. Antioxidants 2024, 13, 275. [CrossRef]\nSong, Y.; Weng, Y.; Liu, S.; Usman, M.; Loor, J.J.; Lin, G.; Hu, Q.; Luo, J.; Wang, P. Effects of reduced levels of organic trace\nminerals in proteinate forms and selenium yeast in the mineral mix on lactation performance, milk fatty acid composition,\nnutrient digestibility, and antioxidant status in dairy goats. J. Anim. Sci. 2024, 102, skae187. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\n61. Liu, L.; Chen, D.; Yu, B.; Luo, Y.; Huang, Z.; Zheng, P.; Mao, X.; Yu, J.; Luo, J.; Yan, H. Influences of selenium-enriched yeast on\ngrowth performance, immune function, and antioxidant capacity in weaned pigs exposure to oxidative stress. BioMed. Res. Int.\n2021, 2021, 5533210. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.4**t== 0.5**l== 0.1**r== 0.1**\n62. Xu, S.; Jiang, X.; Liu, Y.; Jiang, X.; Che, L.; Lin, Y.; Zhuo, Y.; Feng, B.; Fang, Z.; Hua, L. Silibinin Alleviates Lipopolysaccharide\nInduced Inflammation in Porcine Mammary Epithelial Cells via mTOR/NF-κB Signaling Pathway. Mol. Nutr. Food Res. 2023,\n67, 2200715. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.4**t== 0.6**l== 0.1**r== 0.1**\n63. Reczynska, D.; Witek, B.; Jarczak, J.; Czopowicz, M.; Mickiewicz, M.; Kaba, J.; Zwierzchowski, L.; Bagnicka, E. The impact of\norganic vs. inorganic selenium on dairy goat productivity and expression of selected genes in milk somatic cells. J. Dairy Res.\n2019, 86, 48–54. [CrossRef]\n**BLOCK**fs== 9.0**p== 15.0**b== 0.3**t== 0.6**l== 0.1**r== 0.1**\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.",
         "Article Selenium Yeast Attenuated Lipopolysaccharide-Induced Inflammation in Porcine Mammary Epithelial Cells by Modulating MAPK and NF-κB Signaling Pathways Zhenting He 1, Senlin Su 1, Bing Zhang 1, Dongpang Chen 1, Siyu Yuan 1, Wutai Guan 1,2,3 and Shihai Zhang 1,2,3,* Abstract: Mastitis, a prevalent inflammatory disease in mammals, disrupts mammary gland function, compromises milk quality, and can contribute to increased offspring morbidity and mortality. Maintaining the health of porcine mammary epithelial cells (PMECs), the primary cell type in the mammary gland, is crucial for minimizing the adverse effects of this disease. Selenium yeast (SeY), an organic selenium compound known for its antioxidant and immune-enhancing properties, has yet to be fully understood in its role in modulating inflammation in mammary gland. In this study, lipopolysaccharide (LPS) (50 µg/mL, 24 h) significantly upregulated the expression of pro-inflammatory cytokines, including tumor necrosis factor-alpha (TNF-α), interleukin-6 (IL-6), interleukin-8 (IL-8), and interleukin-1β (IL-1β) (p < 0.05). Pretreatment with 1 µM SeY significantly attenuated the LPS-induced inflammatory response by reducing the levels of TNF-α, IL-6, IL-8, and IL-1β (p < 0.05). Additionally, SeY enhanced cellular antioxidant defenses by increasing total antioxidant capacity (T-AOC), superoxide dismutase (SOD) activity, glutathione (GSH) levels, and glutathione peroxidase (GSH-Px) activity, while concurrently decreasing malondialdehyde (MDA) accumulation (p < 0.05). SeY also restored both intracellular and extracellular triglyceride levels and rescued lipid droplet formation, which were disrupted by LPS treatment. Furthermore, SeY upregulated key regulators involved in milk synthesis (p < 0.05). These findings suggest that SeY effectively mitigates LPS-induced inflammation and oxidative stress while preserving critical pathways for milk fat and protein synthesis in PMECs. Keywords: porcine mammary epithelial cells; anti-inflammation; selenium yeast; milk synthesis; lipopolysaccharide Mastitis is a prevalent and significant disease in animal production, often leading to reduced milk production or altered milk composition. This condition can severely affect the growth of offspring, sometimes resulting in piglet mortality, and causing substantial economic losses to the breeding industry [1–8]. Mammary epithelial cells, the primary cellular component of the mammary gland, play a crucial role in the inflammatory response, serving as both targets and mediators of infection-induced inflammation in mastitis [9–11]. Lipopolysaccharide (LPS), a key component of Gram-negative bacterial cell walls, triggers intracellular signaling cascades by binding to Toll-like receptor 4 (TLR4) on the cell surface, leading to the activation of pro-inflammatory pathways [12–14]. This activation initiates both MyD88-dependent and MyD88-independent pathways, culminating in the activation of nuclear factor-kappa B (NF-κB) [15]. Once activated, NF-κB promotes the transcription and release of pro-inflammatory factors, including cytokines and chemokines [16], which or- chestrate immune responses and drive inflammation in mammary epithelial cells [7,17,18]. Given its pivotal role in inflammatory cascade, the LPS-induced signaling pathway rep- resents a critical target for identifying potential therapeutic agents to mitigate mammary gland inflammation. Selenium, an essential trace element, plays a crucial role in various biological processes, particularly as a component of antioxidant enzymes that neutralize reactive oxygen species (ROS) and enhance immune function [19–21]. Previous studies have demonstrated that se- lenium supplementation improves the reproductive performance and health status of sows and their offspring [22–24]. Increased maternal selenium intake has been shown to enhance piglet survival, colostrum and milk quality, maternal antioxidant status, and immunoglob- ulin transfer [25]. Selenium also supports piglet growth during early lactation [26,27]. In animal feed, selenium is available in both inorganic and organic forms [28]. Organic selenium has been shown to provide several advantages over inorganic forms, including higher absorption rates [29], enhanced antioxidant capacity [30], lower toxicity [31,32], and improved overall animal health and performance [33–37]. Among various organic selenium sources, selenium yeast (SeY) offers distinct advantages, including superior bioavailability and enhanced antioxidant capacity, whereas selenium methionine (Sel-Met), despite its good absorption, exhibits relatively lower stability and bio-conversion efficiency. Previous studies in our lab systematically compared the antioxidant efficacy of SeY and Sel-Met in porcine mammary epithelial cells (PMECs), demonstrating that both enhance antioxidant capacity through activation of the p38/JNK signaling pathway, underscoring selenium’s critical role in mitigating oxidative stress in the mammary glands of sows and their offspring. Despite the well-documented benefits of SeY, most studies have primarily focused on its general role in enhancing overall animal health. However, its specific protective effects against LPS-induced inflammation and oxidative stress in PMECs remain largely unexplored. This study provides novel insights into the potential of SeY in mitigating LPS-induced inflammatory responses and oxidative stress in PMECs. Additionally, we elucidate the underlying mechanisms by which SeY regulates key signaling pathways, including NF-κB and mitogen-activated protein kinase (MAPK) pathways, and its impact on milk fat and protein synthesis pathways. These findings offer new perspectives on the therapeutic potential of SeY for mastitis prevention and management, emphasizing its role in improving lactation and overall mammary gland health in livestock. 2. Materials and Methods 2.1. Preparation of SeY SeY from Sel-Plex™ 2000 (Alltech Inc., Lexington, KY, USA), containing 2000 mg/kg of selenium, was used in this study. To simulate the gastrointestinal digestion of SeY, SeY was subjected to pretreatment with digestive enzymes in vitro. A protease solution was prepared by dissolving 2 mg of protease XIV (Sigma-Aldrich, Saint Louis, MO, USA) in 0.5 mL of 10 mM Tris-HCl buffer (Sigma-Aldrich, Saint Louis, MO, USA). To this solution, 40 mg of SeY was added and thoroughly mixed. The samples were disrupted using ultra- sound (25 s at 80% amplitude) on ice, followed by cleaning with ultrapure water (Sangon Biotech, Shanghai, China). The ultrasonic power was set to 30 W, and the disruption lasted for 15 min. The sample was then centrifuged at 14,000 rpm for 3 min, and the supernatant was discarded. The pellet was washed, resuspended in ultrapure water (Sangon Biotech, Shanghai, China), and centrifuged again under the same conditions to obtain the final supernatant. The selenium concentration in the sample was determined by inductively coupled plasma mass spectrometry (ICP-MS). PMECs were isolated from the mammary gland of a 9-month-old Large White sow [38]. The sow was selected based on her optimal health status and body condition. PMECs isolated from a lactating sow were cryopreserved in liquid nitrogen at −196 ◦C. For culture, thawed PMECs (1 mL, 37 ◦C) were maintained in DMEM/F12 medium supplemented with 10% FBS, 1% antibiotic-antimycotic, 10 ng/mL IGF-1, 10 ng/mL EGF, 5 µg/mL ITS, and 5 µg/mL hydrocortisone at 37 ◦C with 5% CO2. The cells were subsequently transferred to DIP medium supplemented with 1 µM dexamethasone, 5 µg/mL insulin, and 5 µg/mL prolactin to induce differentiation and stimulate milk production. Cell viability was assessed using the CCK-8 assay (Nanjing Jiancheng Bioengineering Institute, Nanjing, China). PMECs were seeded in 96-well plates at 1 × 105 cells/mL (100 µL medium/well) and incubated at 37 ◦C with 5% CO2 for 24 h. At 70–80% confluence, cells were treated as specified. Post-treatment, 10 µL of CCK-8 solution was added to each well, incubated at 37 ◦C for 1–3 h, and the absorbance was measured at 450 nm using a microplate reader. Total RNA was extracted from the cell samples using the EZ-press RNA purification kit (EZ-Bio, Shanghai, China). cDNA synthesis was performed using the RNA reverse transcription kit (EZ-Bio, Shanghai, China). The cDNA was mixed with Color SYBR Green qPCR Mix, target gene primers, and double-distilled water to prepare a 20 µL qPCR reaction system. The thermal cycling conditions were as follows: 95 ◦C for 1 min, followed by 40 cycles of 95 ◦C for 15 s, 59 ◦C for 15 s, and 72 ◦C for 40 s. Relative gene expression was calculated using the 2−∆∆Ct method, with β-actin as the internal control. Primer sequences for real-time PCR are listed in Table 1. Size (bp) Size (bp) β-actin 2.5. Measurement of Inflammatory Factor Levels The levels of tumor necrosis factor-alpha (TNF-α), interleukin-6 (IL-6), interleukin- 8 (IL-8), and interleukin-1β (IL-1β) were quantified using pig-specific ELISA kits (mlbio, Shanghai, China). PMECs were seeded in 12-well plates at 2.5 × 104 cells/mL (1 mL/well) and cultured at 37 ◦C with 5% CO2. After 48 h, cells were pretreated with 1 µM SeY for 24 h, followed by 50 µg/mL LPS stimulation for 24 h. The cells were washed with PBS, lysed in 140 µL RIPA buffer (Beyotime, Shanghai, China), and centrifuged (10,000 rpm, 10 min). Supernatants were collected for analysis. Antioxidant capacity was assessed using a commercial kit (Nanjing Jiancheng Bioengineering Institute, Nanjing, China). PMECs were seeded in 12-well plates at 2.5 × 104 cells/mL (1 mL/well) and cultured at 37 ◦C with 5% CO2. After 48 h, cells were pretreated with 1 µM SeY for 24 h, followed by 50 µg/mL LPS stimulation for 24 h. The LPS concentration (50 µg/mL) and exposure time (24 h) used in this study were de- termined based on prior experiments conducted in our lab [39]. The cells were washed with PBS, lysed in 140 µL RIPA buffer (Beyotime, China), and centrifuged (12,000 rpm, 5 min). Supernatants were analyzed for total antioxidant capacity (T-AOC), superoxide dismutase (SOD), malondialdehyde (MDA), glutathione (GSH) and glutathione peroxidase (GSH-Px) levels. PMECs were seeded in 12-well plates at 2.5 × 104 cells/mL (1 mL/well) and cultured at 37 ◦C with 5% CO2 for 48 h. Cells were treated with 1 µM SeY for 24 h, followed by 50 µg/mL LPS for 24 h. After treatment, the cells were washed with PBS, and proteins were extracted using RIPA buffer (Beyotime, Shanghai, China). Protein concentrations were measured with a BCA Protein Assay Kit (Beyotime, Shanghai, China). Equal protein (10–20 µg) was separated by SDS-PAGE (Invitrogen, Carlsbad, CA, USA) and transferred to nitrocellulose membranes (Millipore, Bedford, MA, USA), followed by incubation with primary antibodies (Table 2). Data were analyzed using IBM SPSS 26.0 with one-way ANOVA and LSD post-hoc tests for group comparisons. GraphPad Prism 8.0 was used for additional analyses and visualizations. Significance was set at p < 0.05, with p < 0.01 indicating high significance. 3. Results 3.1. Viability of PMECs To assess SeY’s effect on PMECs viability, cells were exposed to 0, 0.5, 1, 2, 4, or 8 µM SeY for 24 h, and their viability was assessed using the CCK-8 assay. As illustrated in Figure 1A, viability increased dose-dependently, peaking at 1 µM, which was selected as the optimal pretreatment concentration. Figure 1B shows that LPS significantly reduced viability compared to the controls, but pretreatment with 1 µM SeY partially restored viability (p < 0.05). Figure 2 shows that LPS significantly upregulated the mRNA expression levels of TNF-α, IL-6, IL-1β, and IL-8 compared to the controls (p < 0.05). Consistently, ELISA results confirmed that LPS also increased the levels of these inflammatory cytokines (p < 0.05). Pretreatment with SeY significantly reduced both mRNA expression and concentrations of these inflammatory cytokines, bringing levels close to the controls (p < 0.05). Figure 3 shows that LPS treatment significantly decreased T-AOC, SOD, GSH, and GSH-Px, while markedly increasing MDA levels (p < 0.05). Pretreatment with SeY effec- tively restored T-AOC, SOD, and MDA levels to near-control values (p > 0.05). However, GSH and GSH-Px levels remained intermediate, showing significant differences from both the LPS-only and control groups (p < 0.05), suggesting a partial but not complete recovery of antioxidant capacity. 3.4. NF-κB and MAPK Signaling Pathways LPS treatment markedly enhanced the phosphorylation of key NF-κB (IκBα and p65) and MAPK (JNK, ERK, and p38) signaling proteins compared to the control group (p < 0.05), indicating robust activation of these inflammatory pathways (Figure 4A–D). SeY pretreatment effectively suppressed this phosphorylation, restoring levels close to those of the controls (p < 0.05), suggesting its inhibitory effect on LPS-induced NF-κB and MAPK activation (Figure 4A–D). Similarly, SeY pretreatment significantly attenuated the LPS-induced upregulation of Myd88, Irak4, Irak1, and Traf6 mRNA expression (p < 0.05), further demonstrating its regulatory role in suppressing TLR4-mediated inflammatory signaling (Figure 4E). 3.5. Intracellular and Extracellular Triglyceride Levels in PMECs LPS treatment significantly decreased intracellular (Figure 5A) and extracellular triglyc- eride levels (Figure 5B) compared to the controls (p < 0.05). However, in the LPS + SeY group, triglyceride levels were restored to near-control levels (p < 0.05). Oil Red O staining (Figure 5C) further confirmed that LPS exposure suppressed lipid droplet formation, while SeY pretreatment partially rescued this effect. These findings suggest that LPS disrupts triglyceride synthesis and lipid storage in PMECs, whereas SeY pretreatment counteracts these impairments, thereby promoting lipid accumulation. 3.6. mRNA and Protein Expression Related to Milk Fat and Protein Synthesis LPS significantly downregulated the mRNA expression of key molecules involved in milk fat and protein synthesis, including ACACA, DGAT1, SREBP1, FASN, WAP, α-casein and β-casein, compared to the control group (Figure 6, p < 0.05). In the LPS + SeY group, mRNA levels of these molecules were significantly higher than those in the LPS group (p < 0.05). Consistently, the protein expression of these molecules was also significantly higher in the SeY-pretreated cells than in the LPS group (Figure 7A,B). These results suggest that SeY effectively counteracts LPS-induced suppression of milk fat and protein synthesis. 3.7. Pathways Related to Milk Fat and Protein Synthesis To further explore the regulatory mechanisms underlying milk fat and protein synthe- sis, we examined the mechanistic target of rapamycin (mTOR) and Janus kinase 2-signal transducer and activator of transcription 5 (JAK2-STAT5) pathways. Western blot analysis showed that LPS treatment significantly reduced phosphorylation levels of mTOR, S6K1, 4EBP1, STAT5, and JAK2 compared to the control group (p < 0.05) (Figure 8A–D). However, SeY pretreatment significantly restored the phosphorylation of these proteins (p < 0.05), bringing them to levels comparable to those of the controls (Figure 8A–D). Mastitis is a significant concern in dairy cattle, as it directly impacts milk production and quality, leading to substantial economic losses in the dairy industry [40]. Extensive research has focused on anti-inflammatory strategies, such as vitamin E and selenium supplementation, which have demonstrated beneficial effects in modulating immune re- sponses and alleviating oxidative and inflammatory stress in perinatal cows [41]. However, compared to dairy cattle, mastitis in sows has received relatively less research attention, despite its severe consequences, including maternal inflammation, impaired lactation, and increased piglet mortality [42]. This underscores the urgent need for further research into effective preventive and therapeutic strategies for sow mastitis. Inflammation is a complex and essential defense mechanism triggered by various stimuli, including microbial infection and tissue damage [43,44]. In the mammary gland, ex- cessive inflammatory responses can disrupt normal metabolic functions, compromise milk synthesis, and negatively affect overall lactation performance. Enhancing immune function and anti-inflammatory capacity is therefore critical for maintaining mammary gland health and sustaining optimal milk production. LPS, a key component of Gram-negative bacterial cell walls, is a well-established inflammatory inducer that severely disrupts mammary gland homeostasis. LPS exposure impairs mammary epithelial cell function by triggering oxidative stress, reducing antioxidant capacity, and negatively affecting milk yield and composition [4,11,45,46]. Mechanistically, LPS binds to TLR4 on the cell surface [47], initiat- ing a cascade of inflammatory signaling events [39,48]. In this study, SeY was evaluated for its protective effects on PMECs. A dose-dependent response in cell viability was observed, with the highest viability detected at 1 µM SeY after 24 h. Pretreatment with 1 µM SeY for 24 h, followed by 50 µg/mL LPS exposure for 24 h, significantly improved cell viability compared to the LPS group. These results suggest that SeY mitigates LPS-induced via- bility reduction, likely through its antioxidant and anti-inflammatory properties, thereby supporting PMEC resilience under inflammatory conditions. Oxidative stress results arises from an imbalance between reactive oxygen species (ROS) production and the body’s antioxidant defense mechanisms and is closely linked to inflammation [49,50]. Selenium plays a critical role in repairing oxidative stress-induced damage and enhancing cellular antioxidant capacity [51]. Previous studies have shown that SeY regulates selenoprotein expression and enhances antioxidant capacity in PMECs via activation of the p38/JNK signaling pathway, thereby promoting cell viability [32,52]. In this study, SeY pretreatment significantly increased T-AOC, SOD, GSH, and GSH-Px levels while reducing MDA accumulation in LPS-induced inflammatory cells. These results are consistent with those of Yang et al. [53], who reported that hydroxy-selenomethionine (HMSeBA) can help dairy cows overcome heat stress by enhancing antioxidant capacity. By restoring redox balance, SeY not only mitigates oxidative stress-induced damage but also suppresses inflammatory responses. Earlier research demonstrated that selenium pretreatment suppressed the expression of pro-inflammatory genes, such as TNF-α and COX-2, by inhibiting NF-κB p65, IκBα, p38, ERK, and JNK phosphorylation in mammary epithelial cells [48]. Similarly, selenium reduced the gene expression of inflammatory cytokines (TNF-α, IL-6β, and IL-2) in Staphy- lococcus aureus-stimulated bovine mammary epithelial cells by modulating TLR4, NF-κB, and MAPK signaling pathways [54]. In alignment with previous findings, the present study demonstrates that pretreatment with SeY markedly decreased both the mRNA levels and protein expression of pro-inflammatory cytokines in PMECs subjected to LPS-induced inflammatory conditions. The NF-κB signaling system is critical in cellular responses to stimuli such as stress, pro-inflammatory cytokines, free radicals, and heavy metals. The dysregulation of this pathway is closely associated with inflammatory diseases [55]. Additionally, the MAPK family serves as a critical downstream signaling hub for various growth factor receptors and pattern recognition receptors. These kinases are frequently hyperactivated during inflammation, leading to the amplification of pro-inflammatory signaling cascades [56]. The excessive production of inflammatory factors is a primary contributor to cell and tissue damage during inflammation. Previous studies have shown that Se inhibited the LPS- induced inflammatory response by suppressing NF-κB and MAPK in mammary epithelial cells and bovine endometrial epithelial cells [48,57]. In line with these findings, our study demonstrates that SeY similarly exerts anti-inflammatory effects by targeting the NF-κB and MAPK signaling pathways in PMECs. Specifically, SeY reduced the mRNA expression of key NF-κB pathway genes, including Myd88, Irak1, Irak4, and Traf6, and restored phos- phorylation levels of NF-κB and MAPK pathway proteins (p65, IκBα, p38, ERK, and JNK) to levels comparable to the control group. These results not only confirm the conserved anti-inflammatory mechanism of selenium across different cell types but also provide novel insights into the specific molecular targets of SeY in mammary epithelial cells. The health and structural integrity of the mammary gland are essential for female livestock to maintain optimal lactation performance. Lactation ability and milk quality are directly linked to the growth rate and survival of offspring [58]. Research has shown that dietary supplementation with 0.3 mg/kg SeY enhances lactation performance in lactating donkeys and improves milk protein production efficiency [59]. Similarly, our laboratory previously demonstrated that the addition of yeast culture combined with organic selenium increased the capacity for milk fat synthesis in lactating sows [32]. Milk fat and protein synthesis are critical physiological functions of mammary epithelial cells [60]. Inflammation can inhibit milk synthesis by disrupting related signaling pathways [61]. In this study, SeY alleviated inflammation and enhanced the expression of milk fat and protein synthesis-related molecules. The mTOR and JAK2-STAT5 pathways are essential for mammary development and milk synthesis [62]. SeY pretreatment consistently alleviated the inhibitory effects of LPS, significantly restoring the phosphorylation levels of the mTOR and JAK2-STAT5 signaling pathways. These results align with previous studies, which demonstrated that organic selenium supplementation in goats notably increases milk fat and protein levels [63]. Together, these findings suggest that SeY influences milk fat and protein synthesis by modulating key signaling pathways. In this study, SeY effectively mitigated LPS-induced inflammation and oxidative stress in PMECs, as evidenced by reduced inflammatory cytokine expression and enhanced an- tioxidant defense. SeY also preserved milk fat and protein synthesis pathways, suggesting its potential to support lactation performance. However, this in vitro study has limitations, particularly in its applicability to the complex in vivo environment, and further research is needed to confirm these findings in animal models. Future studies should explore the molecular mechanisms underlying SeY’s effects, investigate its long-term impact on mammary gland health, and evaluate its potential in combination with other nutritional interventions to optimize sow productivity and reduce mastitis incidence.",
         "https://www.mdpi.com/2076-3921/14/3/334/pdf?version=1741832015",
         "extracted",
         "None",
         "",
         "Selenium Yeast Attenuated Lipopolysaccharide-Induced Inflammation in Porcine Mammary Epithelial Cells by Modulating MAPK and NF-κB Signaling Pathways"
        ],
        [
         "46",
         "02005c9e65bcf62c329533a372895f68b739c991",
         "None",
         "L. Manciocchi,A. Bianchi,Valérie Mazan,Mark Potapov,K. M. Fromm,M. Spichty",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2024/12/04/2024.11.28.625676.full.pdf",
         "None",
         "None",
         "Toward predicting silver ion binding in proteins;Thermodynamics of Metal-Acetate Interactions.;The battle for silver binding: How the interplay between the SilE, SilF, and SilB proteins contributes to the silver efflux pump mechanism;Accurate Metal-Imidazole Interactions.;Constant pH molecular dynamics simulations: Current status and recent applications.;Re-sensitization of mcr carrying multidrug resistant bacteria to colistin by silver;Scalable Constant pH Molecular Dynamics in GROMACS;Computational strategies to model the interaction and the reactivity of biologically-relevant transition metal complexes;Alpha-helical folding of SilE models upon Ag(His)(Met) motif formation.;Configuration-Sampling-Based Surrogate Models for Rapid Parameterization of Non-Bonded Interactions.;Model peptide studies of Ag+ binding sites from the silver resistance protein SilE.;CHARMM36m: an improved force field for folded and intrinsically disordered proteins;SilE is an intrinsically disordered periplasmic “molecular sponge” involved in bacterial silver resistance;CHARMM TIP3P Water Model Suppresses Peptide Folding by Solvating the Unfolded State.;Enhanced sampling techniques in molecular dynamics simulations of biological systems.;Systematic Parameterization of Monovalent Ions Employing the Nonbonded Model.;Recent Advances in Polarizable Force Fields for Macromolecules: Microsecond Simulations of Proteins Using the Classical Drude Oscillator Model;Force Field Independent Metal Parameters Using a Nonbonded Dummy Model;Nanobio silver: its interactions with peptides and bacteria, and its uses in medicine.;Force field for monovalent, divalent, and trivalent cations developed under the solvent boundary potential.;Syntheses, structures, and antimicrobial activities of remarkably light-stable and water-soluble silver complexes with amino acid derivatives, silver(I) N-acetylmethioninates.;Constant pH Molecular Dynamics in Explicit Solvent with λ-Dynamics;Current status of the AMOEBA polarizable force field.;Antibacterial Activity and Mechanism of Action of the Silver Ion in Staphylococcus aureus and Escherichia coli;Atomistic Simulation Studies of Polymers and Water;The Simple Yet Elusive Crystal Structure of Silver Acetate and the Role of the Ag−Ag Bond in the Formation of Silver Nanoparticles during the Thermally Induced Reduction of Silver Carboxylates;Calculation of absolute protein-ligand binding free energy from computer simulations.;Bacterial silver resistance: molecular biology and uses and misuses of silver compounds.;A mechanistic study of the antibacterial effect of silver ions on Escherichia coli and Staphylococcus aureus.;Synthesis and characterization of water-soluble silver(I) complexes with L-histidine (H2his) and (S)-(-)-2-pyrrolidone-5-carboxylic acid (H2pyrrld) showing a wide spectrum of effective antibacterial and antifungal activities. Crystal structures of chiral helical polymers [Ag(Hhis)]n and ([Ag(Hpyrrld;Critical evaluation of stability constants of metal-imidazole and metal-histamine systems (Technical Report);THE weighted histogram analysis method for free‐energy calculations on biomolecules. I. The method;STEREOREGULAR COORDINATION POLYMERS FORMED ON BINDING OF PEPTIDE-BASED POLYDENTATE LIGANDS TO SILVER(I) AND COPPER(I) - X-RAY STRUCTURE OF ([AG(N-[N-((5-METHYL-2-THIENYL)METHYLIDENE)-L-METHIONYL]HISTAMINE)]+[O3SCF3]-.MEOH)INFINITY AND A SOLUTION STRUCTURE STUDY;Comparison of simple potential functions for simulating liquid water;Nonphysical sampling distributions in Monte Carlo free-energy estimation: Umbrella sampling;NIST SRD 46. Critically Selected Stability Constants of Metal Complexes: Version 8.0 for Windows;unpublished results;Theoretical Studies of Hydrogen Bonding;Comparison of the ligating properties of disulphides and thioethers: dimethyl disulphide, dimethyl sulphide, and related ligands;Sur Le Mélange Des Gaz;Ueber die Anwendung des Satzes vom Virial in der kinetischen Theorie der Gase;Using the procedure given in the section 2.2, the PMF and binding constant are calculated;We performed MD based Umbrella Sampling (US) simulations in explicit water to sample along the reaction coordinate of binding, i.e. the distance between silver(I) ion and the coordinated atom;The Potential of Mean Force (PMF) was determined along the binding reaction coordinate through WHAM;From the PMF, the binding constant log 10 ( K bind , calc ) was calculated (and, consequently, the binding free energy ∆ G bind,calc );If the minimum of the PMF matches the target distance",
         "Modelling the interaction between silver(I) ion and proteins with the 12-6 Lennard-Jones potential: a bottom-up parameterization approach"
        ],
        [
         "47",
         "021450a16398928333d110a0997a59a7a6061253",
         "None",
         "Primavera de Filippi,Sofia Cossar,M. Mannan,Kelsie Nabben,Tara Merk,Jamilya Kamalova",
         "\n**BLOCK**fs== 14.3**p== 0.0**b== 0.6**t== 0.3**l== 0.1**r== 0.1**\nReport on Blockchain Governance Dynamics\nPrimavera de Filippi, Sofia Cossar, Morshed Mannan, Tara Merk, Jamilya\n**BLOCK**fs== 14.3**p== 0.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\nKamalova, Kelsie Nabben\n**BLOCK**fs== 14.3**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.6**\nTo cite this version:\n**BLOCK**fs== 10.9**p== 0.0**b== 0.5**t== 0.5**l== 0.1**r== 0.1**\nPrimavera de Filippi, Sofia Cossar, Morshed Mannan, Tara Merk, Jamilya Kamalova, et al.. Report\non Blockchain Governance Dynamics. Project Liberty Institute. 2024. ￿hal-04855853￿\n**BLOCK**fs== 14.3**p== 0.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\nHAL Id: hal-04855853\n**BLOCK**fs== 14.3**p== 0.0**b== 0.3**t== 0.7**l== 0.3**r== 0.3**\nhttps://hal.science/hal-04855853v1\n**BLOCK**fs== 10.9**p== 0.0**b== 0.3**t== 0.7**l== 0.4**r== 0.4**\nSubmitted on 25 Dec 2024\n**BLOCK**fs== 10.9**p== 0.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci-\nentific research documents, whether they are pub-\nlished or not. The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\n**BLOCK**fs== 10.9**p== 0.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nL’archive ouverte pluridisciplinaire HAL, est\ndestinée au dépôt et à la diffusion de documents\nscientifiques de niveau recherche, publiés ou non,\némanant des établissements d’enseignement et de\nrecherche français ou étrangers, des laboratoires\npublics ou privés.\n**BLOCK**fs== 10.9**p== 0.0**b== 0.0**t== 0.9**l== 0.1**r== 0.1**\nDistributed under a Creative Commons Attribution - NonCommercial - NoDerivatives 4.0\nInternational License\n**BLOCK**fs== 14.0**p== 1.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nBlockchainGov // Project Liberty Institute\n**BLOCK**fs== 28.0**p== 1.0**b== 0.7**t== 0.2**l== 0.5**r== 0.2**\nReport on\nBlockchain\nGovernance\nDynamics\n**BLOCK**fs== 18.0**p== 2.0**b== 0.9**t== 0.1**l== 0.5**r== 0.1**\nBetter Web, Better World\n**BLOCK**fs== 12.0**p== 2.0**b== 0.3**t== 0.5**l== 0.1**r== 0.5**\nThis report is licensed under the terms\nand conditions of the Creative Commons\nAttribution - NonCommercial -\nNoDerivatives 4.0 International (CC BY-\nNC-ND 4.0) unless explicitly stated\notherwise (e.g. in the image description).\nTo view this license, visit\n(https://creativecommons.org/\nlicenses/by-nc-nd/4.0/deed.en). For re-\nuse or distribution, please include this\ncopyright notice.\n**BLOCK**fs== 12.0**p== 2.0**b== 0.1**t== 0.8**l== 0.1**r== 0.5**\nPlease quote as: De Filippi, Primavera,\nSofia Cossar, Morshed Mannan, Kelsie\nNabben, Tara Merk, and Jamilya\nKamalova. “Report on Blockchain\nGovernance Dynamics.” A collaborative\neffort between Project Liberty Institute and\nBlockchainGov, May 2004.\n**BLOCK**fs== 16.0**p== 3.0**b== 0.8**t== 0.2**l== 0.1**r== 0.8**\nImpressum\n**BLOCK**fs== 16.0**p== 3.0**b== 0.5**t== 0.4**l== 0.1**r== 0.7**\nThis report is jointly\nproduced by Project\nLiberty Institute and\nBlockchainGov.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.6**r== 0.3**\nresponsible\n**BLOCK**fs== 10.0**p== 3.0**b== 0.8**t== 0.2**l== 0.7**r== 0.1**\ntechnology  and  bringing\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.2**l== 0.4**r== 0.1**\nAbout Project Liberty Institute:\nProject Liberty Institute, 501(c)(3) founded by Frank McCourt, is building a\ntogether\nglobal  alliance\ntechnologists, academics, policymakers, civil society and citizens to build\na  safer,  healthier  tech  ecosystem.  The  Institute  has  an  international\npartner network that includes Georgetown University, Stanford University,\ninstitutions  and  civic\nSciences  Po,  and  other\norganizations; and is the steward of the Decentralized Social Networking\nProtocol  (DSNP)  which  is  available  as  a  public  utility  to  serve  as  the\nbedrock of a more equitable web and support a new era of innovation that\nempowers people over platforms and serves the common good.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.3**l== 0.6**r== 0.2**\nleading  academic\n**BLOCK**fs== 10.0**p== 3.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\nhttps://www.projectliberty.io/institute\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.4**l== 0.4**r== 0.1**\nAbout BlockchainGov:\nBlockchainGov  is  a  5-year  project  (2021-2026)  funded  by  the  European\nResearch  Council  (ERC  grant  of  €2M).  The  project  is  directed  by\nPrimavera  De  Filippi  and  hosted  at  the  Centre  National  de  Recherche\nScientifique  (France)  and  the  European  University  Institute  (Italy),  with\nPrincipal  Investigator  and  advisors  from  the  Berkman  Klein  Center  at\nHarvard University. As an interdisciplinary research team comprising legal\nscholars,  social  and  political  scientists,  computer  scientists,  and\nblockchain  engineers,  BlockchainGov  focuses  on  studying  the  impact  of\nfor\nblockchain\nlegitimacy and trust.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\ntechnology  on  governance  and\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.8**r== 0.1**\nits  consequences\n**BLOCK**fs== 10.0**p== 3.0**b== 0.4**t== 0.6**l== 0.4**r== 0.4**\nhttps://blockchaingov.eu/\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.7**l== 0.4**r== 0.3**\nContact: web3gov[at]projectliberty.io\n**BLOCK**fs== 24.0**p== 4.0**b== 0.8**t== 0.2**l== 0.1**r== 0.7**\nDisclaimer\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.4**r== 0.1**\nThis  report  has  been  developed  with  the  help  of  the  Governance  Multis-\ntakeholder Council (MSH Council). The views expressed in this report do\nnot reflect the views of the organizations with which Council members are\naffiliated. Any errors or omissions are those of the research team and not\nthe MSH Council members. MSH Council members might not necessarily\nendorse all views presented in the research report.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.6**t== 0.2**l== 0.1**r== 0.7**\nEric Alston is a Scholar in\nResidence in the Finance\nDivision at University of\nColorado Boulder. Eric’s\nresearch applies\nmethodologies and\nconcepts from institutional\n& organizational analysis\nand law & economics to\nstudies of constitutions,\neconomic rights on\nfrontiers, and digital\ngovernance. Eric is also\ncurrently engaged in\ngovernance design for\nseveral distributed network\nprojects.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.5**l== 0.1**r== 0.7**\nPierre Noro is a\nresearcher and lecturer in\ndecentralized governance,\nblockchain technologies\nand digital ethics. After\nseveral years designing\ninnovative blockchain-\nbased public services for\nFrance’s main public\nfinance institution, Pierre is\nnow building impact-\noriented decentralized\nprojects with startups and\nWeb3 communities, such\nas decentralized voting\n(Pebble. vote),\ndecentralized social\nnetworks (Frequency.xyz)\nor Regenerative Finance.\nPierre is a lecturer at\nSciencesPo Paris and at\nthe Learning Planet\nInstitute (Université Paris-\nCité).\n**BLOCK**fs== 9.0**p== 5.0**b== 0.4**t== 0.2**l== 0.3**r== 0.5**\nLaura E. De Nardis is a\nProfessor of Technology,\nEthics and Society at\nGeorgetown University in\nWashington, DC.\nWith a background in\ninformation engineering\nand a doctorate in Science\nand Technology Studies,\nshe has published seven\nbooks and numerous\narticles on the political and\nsocial implications of\nInternet technical\narchitecture and\ngovernance. Dr. DeNardis\nis a member of the Council\non Foreign Relations and\nan affiliated Fellow (and\npreviously Executive\nDirector) at the Information\nSociety Project at Yale Law\nSchool. Her book The\nInternet in Everything:\nFreedom and Security in a\nWorld with No Off Switch\n(Yale University Press) was\nrecognized as a Financial\nTimes Top Technology\nBook of 2020.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.7**l== 0.3**r== 0.5**\nFederico Ast graduated in\neconomics and philosophy\nand holds a PhD in\nmanagement. He is\npassionate about the use\nof technology for social\ninnovation. He is founder of\nKleros, a protocol using\ngame theory and\nblockchain technology in\ndispute resolution.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.5**t== 0.2**l== 0.5**r== 0.3**\nKaitlin Beegle is the Head\nof Protocol Governance at\nthe Filecoin Foundation.\nShe holds an MSc\nin Politics and Technology\nfrom the Technical\nUniversity of Munich,\nwhere her research\nfocused on on the political\ntheory of ‘openness’ in\ndemocracies and open-\nsource technologies. Prior\nto this, she was\na researcher in innovation\npolicies for various\nagencies in both the US\nand UK governments, as\nwell as an activist and\ncommunity organizer. She\nlives in San Francisco.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.5**t== 0.2**l== 0.8**r== 0.1**\nE. Glen Weyl is Founder\nand Research Lead of\nMicrosoft Research’s\nSpecial Project the Plural\nTechnology Collaboratory,\nFounder of the Plurality\nInstitute and\nRadicalxChange\nFoundation and co-author\nwith Audrey Tang of the\nforthcoming open,\ncollaborative book project,\nPlurality: The Future of\nCollaborative Technology\nand Democracy, and with\nEric Posner of Radical\nMarkets: Uprooting\nCapitalism and Democracy\nfor Just Society.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.2**t== 0.6**l== 0.5**r== 0.3**\nPhilippe Honigman is\na DAOist, a commoner, and\na former entrepreneur. As\nthe Governance Lead at\nMangrove DAO, he drives\nthe design and the\nimplementation of novel\nparticipation and governance\nmechanisms. PhilH is also\npart of dOrg (collective of\nWeb3 builders), a board\nmember of Ethereum France\n(organizer of the main\nEuropean crypto\nconference), and an advisor\nat Morpho and Usual.\n**BLOCK**fs== 9.0**p== 5.0**b== 0.1**t== 0.6**l== 0.7**r== 0.1**\nPindar Wong is an\nInternet pioneer, who co-\nfounded the first licensed\nInternet Service Provider\nin Hong Kong in 1993.\nPreviously, Pindar was the\nfirst Vice-Chairman of\nICANN, Chairman of the\nAsia Pacific Internet\nAssociation, alternate\nChairman of Asia Pacific\nNetwork Information\nCenter, Co- Public Lead of\nCreative Commons Hong\nKong, Chairman of\nAPRICOT, Commissioner\non the Global Commission\non Internet Governance\nand elected Trustee of the\nInternet Society. He\norganised Asia’s first\nBlockchainworkshops. org\nand ScalingBitcoin.org\n**BLOCK**fs== 9.0**p== 6.0**b== 0.8**t== 0.1**l== 0.7**r== 0.1**\nShe was a member of the\nExecutive Leadership\nTeam for the Centre for the\nFourth Industrial\nRevolution. She oversaw\ntech policy strategy across\n14 countries and regularly\nbriefed ministers, CEOs of\nthe Fortune 100 and Heads\nof State.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.2**t== 0.3**l== 0.7**r== 0.1**\nDavid Tomchak is\nthe founder of the Web3\nand AI coalition “Cogency”,\nwhose work focuses on\ndigital identity, trust and\nmedia. He is a multi-award-\nwinning journalist, editor\nand technology leader\nwhose experience over the\nlast 20 + years has ranged\nfrom organisations such as\nthe BBC and the London\nEvening Standard to start-\nups and the likes of JP\nMorgan. His career has\nalso included a spell in\ngovernment where he was\nthe Head of Digital and\nDeputy Director of\nCommunications for\nDowning Street in the UK.\nDavid founded the AI In\nMedia (AIIM) working\ngroup in 2016 which has\nnow been included in\nCogency. David is also a\nVisiting Policy Fellow at\nthe Oxford Internet\nInstitute, University of\nOxford.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.3**t== 0.2**l== 0.3**r== 0.5**\nDr. Joachim\nSchwerin is Principal\nEconomist in the unit\nresponsible for the Digital\nTransformation of Industry\nwithin the Directorate-\nGeneral Internal Market,\nIndustry, Entrepreneurship\nand SMEs (DG GROW) of\nthe European Commission.\nHe is responsible for\ndeveloping the policy\napproach of DG GROW\ntowards the Token\nEconomy and Distributed-\nLedger Technologies as\nwell as their applications\nfor industry and\nSMEs, with a current focus\non supporting the\nemergence of DAOs and a\ntruly decentralised Web3.\nIn 2020, he contributed\nto the Digital Finance\nStrategy, including\nthe MiCA Regulation.\nJoachim holds a PhD\nin economics from Dresden\nUniversity of Technology\nand was Post-Doc\nResearch Fellow at the\nEconomic History\nDepartment of the London\nSchool of Economist\nbefore he joined the\nEuropean Commission in\n2001.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.2**t== 0.2**l== 0.1**r== 0.7**\nSarah Roth-Gaudette,\nExecutive Director, Fight\nfor the Future. Over the\npast 25 years, Sarah has\nmanaged campaigns with\nsome of the largest\ngrassroots mobilizing\ngroups in the country,\nincluding U.S. PIRG\nand MoveOn PAC, and\nunderstands how to\nstimulate grassroots\nengagement and convert it\ninto effective political\nresults using the best\ntechnology,\ncommunications,\nand alliance building. She\nnow heads the digital rights\nadvocacy organization,\nFight for the Future. The\ngroup developed the\nstrategy and online tools\nthat have shaped policies\nto protect net neutrality,\nstop online censorship and\nsurveillance, and defend\nalternatives to Big Tech\nand Big Banks. Known for\nits massively viral effort at\ndontkillcrypto.com that\ndrove 40,000+ calls to\nsenators to oppose last\nminute additions to the\ninfrastructure bill, Fight has\nemerged as a leading\nhuman rights advocate in\nthe crypto space, opposing\nfinancial surveillance,\ndefending the right to code,\nand ensuring that\nlawmakers and consumers\nalike understand the stakes\nof these complex\ntechnologies.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.4**t== 0.2**l== 0.5**r== 0.3**\nDr. Paolo Tasca is a\nglobally renowned\nblockchain economist and\nProfessor at University\nCollege London, with a\nspecialization in distributed\nsystems. He is also the\nesteemed founder of the\naward-winning UCL Centre\nfor Blockchain\nTechnologies.\nComplementing his\nacademic\naccomplishments,\nDr. Tasca boasts an\nimpressive track record as\na seasoned blockchain\nentrepreneur, with multiple\nsuccessful exits. His\nextensive expertise in\nblockchain technologies\nhas led him to serve as a\nspecial advisor for an array\nof international\nstakeholders, including the\nUnited Nations, central\nbanks, and various\ngovernmental and industry\nentities.\n**BLOCK**fs== 9.0**p== 6.0**b== 0.1**t== 0.7**l== 0.5**r== 0.3**\nSheila Warren is the CEO\nof the Crypto Council for\nInnovation - the premier\nglobal alliance for\nadvancing the promise of\nthis new technology\nthrough research,\neducation and advocacy.\nSheila founded the World\nEconomic Forum’s\nblockchain and digital\nassets team.\n**BLOCK**fs== 12.0**p== 7.0**b== 0.7**t== 0.2**l== 0.1**r== 0.8**\nProject Liberty\nInstitute\n**BLOCK**fs== 12.0**p== 7.0**b== 0.5**t== 0.4**l== 0.1**r== 0.8**\nBlockchainGov\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.3**r== 0.5**\nPaul Fehlinger,\nDirector of Policy,\nGovernance Innovation\n& Impact\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.5**r== 0.3**\nSarah Nicole,\nPolicy & Research\nSenior Associate\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\nPrimavera de Filippi,\nProject Lead\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.4**\nSofía Cossar,\nProject Manager\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.8**r== 0.1**\nMorshed Mannan,\nLegal Researcher\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.3**r== 0.5**\nJamilya Kamalova,\nLegal Researcher\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.5**r== 0.4**\nTara Merk,\nEthnographer\n**BLOCK**fs== 10.0**p== 7.0**b== 0.2**t== 0.7**l== 0.8**r== 0.1**\nKelsie Nabben,\nEthnographer\n**BLOCK**fs== 24.0**p== 8.0**b== 0.9**t== 0.1**l== 0.1**r== 0.5**\nExecutive Summary\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.2**l== 0.3**r== 0.1**\nWhile the evolution of the World Wide Web has taken various turns\naway  from  its  original  vision,  the  advent  of  Web3  promises  a  new\nera  focused  on  user\n‘decentralization.’  The\n‘ownership’  and\nconcept of Web3, introduced in 2014 by Ethereum co-founder and\nPolkadot  creator  Gavin  Wood,  focuses  on  a  new  infrastructure\nbased  on  decentralized  networks  and  technologies.  This  new\ninfrastructure  enhances  user  ownership  and  autonomy  by  moving\naway from centralized operators and trusted intermediaries.\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.4**r== 0.5**\ntechnology\n**BLOCK**fs== 11.0**p== 9.0**b== 0.6**t== 0.4**l== 0.5**r== 0.2**\nis  a  cornerstone  of  Web3,\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\ninitially\nBlockchain\ndeveloped as an innovative means to record transactions digitally.\nThe  collective  choices  of  individuals  and  organizations  drive  the\nevolution  of  blockchain  technology  and  its  diverse  applications.\nThese  entities  form  what  are  known  as  ‘blockchain  systems’:\ncomplex  techno-social  structures  that  operate  across  multiple\nintertwined\nthe  capabilities  of  blockchain\ntechnology  to  store  data  across  multiple  nodes,  the  governance\ndynamics within blockchain systems are complex and nuanced. To\nfully grasp the opportunities and challenges of Web3, it is essential\nfundamental\nto  analyze\ncomponents, including blockchain networks.\n**BLOCK**fs== 11.0**p== 9.0**b== 0.4**t== 0.6**l== 0.4**r== 0.3**\nthe  governance  practices  of\n**BLOCK**fs== 11.0**p== 9.0**b== 0.5**t== 0.5**l== 0.4**r== 0.4**\nlayers.  Beyond\n**BLOCK**fs== 11.0**p== 9.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nThis  report  is  a  collaborative  effort  between  BlockchainGov  and\nProject  Liberty  Institute  to  analyze  the  governance  dynamics  of\nprominent  blockchain  networks  through  an  interdisciplinary  and\ncomparative  lens.  It  focuses  on  eleven  blockchain  networks:\nAvalanche,  Bitcoin,  Cardano,  Cosmos,  Ethereum,  Filecoin,\nOptimism,  Polygon,  Polkadot,  Tezos,  and  Zcash.  Through  a\ncomprehensive empirical analysis built on previous academic work\nand  practitioners’  insights,  the  report  offers  six  key  findings  about\nthe governance dynamics of these blockchain systems.\n**BLOCK**fs== 16.0**p== 10.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nLegal Entities\n**BLOCK**fs== 16.0**p== 10.0**b== 0.5**t== 0.5**l== 0.0**r== 0.7**\nPower Distribution\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.6**r== 0.4**\nfunctions,\n**BLOCK**fs== 11.0**p== 10.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\nfounder-led\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.4**r== 0.4**\nfor  engaging\n**BLOCK**fs== 11.0**p== 10.0**b== 0.9**t== 0.1**l== 0.7**r== 0.2**\nincluding  providing\n**BLOCK**fs== 11.0**p== 10.0**b== 0.6**t== 0.1**l== 0.3**r== 0.1**\nMost  blockchain  networks,  with  the  notable  exception  of  Bitcoin,\nhave  established  legal  entities  such  as  non-profit  foundations  or\ncorporations to manage various aspects of their operations. These\nentities  serve  several\nlegal\nrecognition\nin  off-chain  contracts,  navigating\nregulatory uncertainties, enhancing governance sustainability, and\nsupporting  ecosystem  growth  through  grants.  Although  forming\nthese  legal  entities  aims  to  create  greater  legal  certainty  for\nblockchain  networks,  this  is  not  always  achieved.  Such  entities,\nwhether\ncorporations  or  non-profit\nfoundations, often hold a significant minority stake in the network's\ngovernance  through  token  ownership.  However,  this  stake  does\nnot  grant  them  unilateral  control  over  the  networks.  Instead,  they\ninfluence  the  networks  in  other  ways.  Concern  arises  because\nthese  entities  typically\ninclusive\nmechanisms  for  appointing  and  holding  their  board  of  directors\naccountable,  leading  to  a  mismatch  between  the  public  and\npermissionless  nature  of  the  networks  and  the  opacity  of  the\nsupporting  legal  entities.  This  opacity  can  raise  issues  such  as\npotential  conflicts  of  interest  and  lack  of  disclosure  of  important\ninformation to the community.\n**BLOCK**fs== 11.0**p== 10.0**b== 0.7**t== 0.3**l== 0.5**r== 0.2**\nlack  open,  transparent,  and\n**BLOCK**fs== 11.0**p== 10.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nfor-profit\n**BLOCK**fs== 11.0**p== 10.0**b== 0.2**t== 0.5**l== 0.3**r== 0.1**\nWhile  no  blockchain  system  is  ‘centralized’  in  the  sense  that  it  is\ngoverned by one single person or entity, decision-making power is\nnot evenly distributed. The concrete power distribution within these\nsystems  varies  significantly  depending  on  the  specific  case.  This\nvariation  arises  due  to  factors  such  as  the  governance  areas  or\ntypes  of  decisions  being  made,  the  diverse  array  of  stakeholders\nin  the  governance\ninvolved,  and  the  mechanisms  employed\nprocess.  Recognizing  blockchain  systems'  nuanced  and\nmultifaceted  structure  is  essential  for  discerning  the  actors  who\nshape governance outcomes and the channels through which they\nexert  influence.  Blockchain  communities  can  identify  governance\npractices that stray from their foundational values or objectives by\ninterplay  among  governance  areas,\nexamining\nfor\ninsight\nstakeholders,  and  mechanisms.  This\ndeveloping rules, procedures, and mechanisms that better address\ncommunity  concerns  and  aspirations,  ultimately  creating\ngovernance  systems  that  align  more  closely  with  their  collective\nneeds.\n**BLOCK**fs== 11.0**p== 10.0**b== 0.3**t== 0.7**l== 0.4**r== 0.5**\nthe  complex\n**BLOCK**fs== 11.0**p== 10.0**b== 0.2**t== 0.7**l== 0.8**r== 0.2**\nis  crucial\n**BLOCK**fs== 16.0**p== 11.0**b== 0.9**t== 0.1**l== 0.0**r== 0.7**\nPlanned vs. Actual\n**BLOCK**fs== 16.0**p== 11.0**b== 0.9**t== 0.1**l== 0.0**r== 0.8**\nDecentralization\n**BLOCK**fs== 11.0**p== 11.0**b== 0.9**t== 0.1**l== 0.5**r== 0.2**\nthere  are  many  possible  approaches\n**BLOCK**fs== 11.0**p== 11.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\nAfter\nlaunching  a  blockchain  network,  community  members\ncommonly  pledge\nto  progressively  decentralize  governance.\nto\nHowever,  while\n‘decentralization’,  blockchain  communities  frequently  lack  public,\nclear,  and  operational  definitions.  Additionally,  several  factors\nimpede  the  actual  process  of  decentralization.  On-chain,  power\ntends\nto  consolidate  among  mining  and  validator  pools,\nexacerbated  by  plutocratic  token-weighted  voting  systems.  Off-\nchain,  the  challenges  include  escalating  governance  complexity,\nearly  entrenchment  of  power,  and  external  regulatory  pressures.\nBlockchain  communities  that  genuinely  seek  to  progressively\ndecentralize must adopt precise and operational definitions of what\ndecentralization  means  in  the  context  of  their  blockchain  system.\nAdditionally, they will need to recognize and address on-chain and\noff-chain challenges.\n**BLOCK**fs== 16.0**p== 11.0**b== 0.5**t== 0.5**l== 0.0**r== 0.8**\nGovernance\n**BLOCK**fs== 16.0**p== 11.0**b== 0.4**t== 0.5**l== 0.0**r== 0.8**\nFormalization\n**BLOCK**fs== 11.0**p== 11.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\ntermed\n**BLOCK**fs== 11.0**p== 11.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\n‘secondary  rules.’  However,  despite\n**BLOCK**fs== 11.0**p== 11.0**b== 0.1**t== 0.5**l== 0.3**r== 0.1**\nIn recent years, blockchain communities have experienced greater\n‘formalization,’  or  a  surge\nin  the  adoption  of  online  written\ndocuments  delineating  blockchain  rules  and  procedures.  These\ndocuments play a crucial role in establishing the framework for off-\nchain  and  on-chain  decision-making,  essentially  introducing  what\ncan  be\nthese\nadvancements, the blockchain governance landscape still grapples\nwith  a  significant  gap  between  these  formalized  rules  and  the\nimplicit,  often  undocumented,  practices  that  shape  governance\nwithin  many  blockchain  systems.  Governance  formalization  can\nbecome  an  important  opportunity  for  strengthening  the  legitimacy\nof  blockchain  systems.  Yet,  community  members  should  remain\naware of the delicate interplay between on-chain rules, expressed\nthrough blockchain code, and off-chain practices, which can never\nbe completely and fully expressed on-chain. Implementing a hybrid\nof on-chain and off-chain rules makes blockchain governance more\nflexible  and  adaptable  to  the  community’s  evolving  needs  while\npreserving\nreliability  and  accountability  of  code-based\nmechanisms.\n**BLOCK**fs== 16.0**p== 12.0**b== 0.9**t== 0.1**l== 0.0**r== 0.8**\nGovernance\n**BLOCK**fs== 16.0**p== 12.0**b== 0.9**t== 0.1**l== 0.0**r== 0.8**\nMechanisms\n**BLOCK**fs== 16.0**p== 12.0**b== 0.5**t== 0.5**l== 0.0**r== 0.7**\nSecurity Measures\n**BLOCK**fs== 16.0**p== 12.0**b== 0.4**t== 0.5**l== 0.0**r== 0.8**\nand Breaches\n**BLOCK**fs== 11.0**p== 12.0**b== 0.6**t== 0.1**l== 0.3**r== 0.1**\nCertain  governance  areas  within  blockchain  systems  welcome\ncontributions from various stakeholder groups. ‘Rough consensus’\nand  ‘signaling  and  voting’  represent  two  governance  mechanisms\nfor gathering input and making decisions. Blockchain communities\nutilize varying degrees of sophistication in these mechanisms and\nimplement  them  independently  or  in  conjunction,  resulting  in\ndiverse decision-making processes for each scenario. The distinct\ncharacteristics  of  these  mechanisms,  alongside  factors  like  the\nnature of the decision and the stakeholders involved, can give rise\nto  more\nto\ngovernance  design.  Blockchain  communities  must  thoughtfully\nweigh  the\nimplications  of  adopting  rough  consensus  versus\nsignaling and voting since these can create specific incentives that\nmay  either  promote  advantageous  or  detrimental  behaviors,  thus\ninfluencing  the  network’s  sustainability  and  resilience.  These\nthe\ndynamics\nlegitimacy of the blockchain system.\n**BLOCK**fs== 11.0**p== 12.0**b== 0.7**t== 0.3**l== 0.4**r== 0.2**\ninvariably  shape  stakeholders’  perceptions  of\n**BLOCK**fs== 11.0**p== 12.0**b== 0.8**t== 0.2**l== 0.6**r== 0.2**\n‘expedient’  approaches\n**BLOCK**fs== 11.0**p== 12.0**b== 0.8**t== 0.2**l== 0.4**r== 0.5**\n‘participatory’\n**BLOCK**fs== 11.0**p== 12.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nto  more\n**BLOCK**fs== 11.0**p== 12.0**b== 0.2**t== 0.5**l== 0.3**r== 0.1**\nPreventive  security  measures  in  blockchain  networks  involve  a\nrange  of  strategies  and  technologies  aimed  at  thwarting  potential\nthreats such as DDoS attacks, ‘51% attacks,’ and vulnerabilities in\nsmart contracts. These measures often rely on the expertise of in-\nhouse security teams or third-party contributors incentivized by bug\nbounty  programs.  Additionally,  third-party  security  audits  are\ncommonplace across various blockchain ecosystems, ensuring an\nextra layer of protection. While some blockchain communities have\nestablished  procedures  or  governance  bodies\nto  address\nunforeseen  events,  the  handling  of  ‘states  of  exception’  continues\nto  be  a  governance  area  that  sparks  controversy  within  these\ncommunities. To maintain community trust, ensuring the security of\nblockchain networks requires adopting formal and well-understood\nthe\nprocesses\nlikelihood  of  decision-making  centralization  for  personal  gain.\nAchieving  this  balance  demands  a  fusion  of  specialized  technical\nknowledge  and  an  understanding  of  stakeholders’  needs  and\nincentives  to  define  the  parameters  under  which\n‘states  of\nexception’ can, if any, be invoked within a blockchain ecosystem.\n**BLOCK**fs== 11.0**p== 12.0**b== 0.2**t== 0.7**l== 0.6**r== 0.2**\nthreats  while  reducing\n**BLOCK**fs== 11.0**p== 12.0**b== 0.2**t== 0.7**l== 0.4**r== 0.4**\nfor  handling  external\n**BLOCK**fs== 16.0**p== 13.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nTable of contents\n**BLOCK**fs== 16.0**p== 13.0**b== 0.6**t== 0.3**l== 0.6**r== 0.2**\nContributors\nExecutive Summary\nMethodology\nIntroduction\nFindings\n**BLOCK**fs== 16.0**p== 13.0**b== 0.4**t== 0.4**l== 0.6**r== 0.0**\nI. Legal Entities\nII.Power Distribution\nIII. Planned vs Actual\nDecentralization\nIV. Governance Formalization\nV. Governance Mechanisms\nVI. Security Measures and\nBreaches\n**BLOCK**fs== 16.0**p== 13.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\nConclusion\nBibliography\nAnnex\n**BLOCK**fs== 16.0**p== 14.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nMethodology\n**BLOCK**fs== 11.0**p== 14.0**b== 0.7**t== 0.1**l== 0.5**r== 0.1**\nThis report was produced jointly by Project\nLiberty Institute and BlockchainGov. It aims to\nprovide a rigorous and granular framework for\nunderstanding how governance decisions are\nmade and adopted within the rapidly evolving\nWeb3 ecosystem while helping foster a\nsustainable and responsible ecosystem for\ndecentralized technologies, ensuring that the\nbenefits of Web3 are accessible to all while\nminimizing potential risks and challenges.\n**BLOCK**fs== 11.0**p== 14.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nThis publication lays the foundation of a\nManual on Best Governance Practices for\nBlockchain and Decentralized Technologies\nwhich will highlight recommendations to build\na more responsible ecosystem. This manual\nwill be published in April 2024.\n**BLOCK**fs== 11.0**p== 14.0**b== 0.4**t== 0.4**l== 0.5**r== 0.1**\nThe Project Liberty Institute and\nBlockchainGov teams express their gratitude\nto the fifteen experts forming the Governance\nMultistakeholder Council for their valuable\ncontributions to our work. Their feedback\nduring this iterative process has been\ninstrumental in shaping the qualitative\noutcomes that can now be showcased\npublicly.\n**BLOCK**fs== 16.0**p== 15.0**b== 0.9**t== 0.1**l== 0.1**r== 0.7**\nIntroduction\n**BLOCK**fs== 11.0**p== 15.0**b== 0.4**t== 0.2**l== 0.1**r== 0.5**\nWhile the evolution of the World Wide Web\nhas taken various turns away from its\noriginal vision¹, the advent of Web3\npromises a new era focused on user\n‘ownership’ and ‘decentralization.’ Initially,\nWeb 1.0, often known as the ‘static web,’\nfeatured read-only pages with limited\ninteractivity or user-generated content. This\nphase progressed to Web 2.0, or the ‘social\nweb,’ which enhanced user participation by\nallowing users to consume (‘read’) and\nproduce (‘write’) content. Although they are\noften used interchangeably, the terms Web3\nand Web 3.0 each highlight distinct aspects\nof the web’s ongoing transformation. ‘Web\n3.0’ was used by Tim Berners-Lee, the\ncreator of the World Wide Web, in 2006 to\ndescribe a semantic, connected, and open\niteration of the web.\n**BLOCK**fs== 11.0**p== 15.0**b== 0.1**t== 0.6**l== 0.1**r== 0.5**\nThis phase envisioned utilizing smarter\ncomputer processing through machine-\nreadable data, improving data sharing and\nlinking across various platforms, and relying\non open-source standards to foster\ntransparency and inclusivity². In contrast,\nthe concept of Web3, introduced in 2014 by\nEthereum co-founder and Polkadot creator\nGavin Wood, focuses on a new\ninfrastructure based on decentralized\nnetworks and technologies. This new\ninfrastructure enhances user ownership and\nautonomy by moving away from centralized\noperators and trusted intermediaries.\nBlockchain technology is a cornerstone of\nWeb3, initially developed as an innovative\nmeans to record transactions digitally³.\nBlockchains and smart contracts have\nintroduced a fundamental shift, eliminating\nthe need for central authorities to facilitate all\nkinds of interactions.\n**BLOCK**fs== 10.5**p== 15.0**b== 0.2**t== 0.2**l== 0.5**r== 0.1**\nToday, public and permissionless blockchains\nare employed across various sectors,\nincluding finance, trading, gaming, art, supply\nchain management, and identity verification.\nThis ushers in an era marked by architectural\ndecentralization, censorship resistance,\ntransparency, and immutability, now\nconsidered critical technological infrastructure\nattributes. The collective choices of individuals\nand organizations drive the evolution of\nblockchain technology and its diverse\napplications. These entities form what are\nknown as ‘blockchain systems’ or complex\ntechno-social structures that operate across\nmultiple intertwined layers. Beyond the\ncapabilities of blockchain technology to store\ndata across multiple nodes, the governance\ndynamics within blockchain systems are\ncomplex and nuanced. To fully grasp the\nopportunities and challenges of Web3, it is\nessential to analyze the governance practices\nof its fundamental components, including\nblockchain networks. This report is a\ncollaborative effort between BlockchainGov\nand Project Liberty’s Institute to analyze the\ngovernance dynamics of prominent blockchain\nnetworks through an interdisciplinary and\ncomparative lens. Our research defines\n‘governance’ as the process through which\nmultiple actors’ diverging and sometimes\nconflicting interests are reconciled, leading to\ncollective action based on shared principles\nand agreed-upon procedures.\n**BLOCK**fs== 10.5**p== 15.0**b== 0.1**t== 0.8**l== 0.5**r== 0.1**\nOur analysis of governance processes within\nblockchain systems builds on our previous\nwork and integrates insights from academic\nresearch and practitioner experiences. These\ninsights shed light on the historical and\nideological, social and technical aspects, as\nwell as the on-chain and off-chain dynamics of\nblockchain systems.\n**BLOCK**fs== 11.0**p== 16.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nAlthough ‘decentralization’ is often\nhighlighted as a defining feature of this\necosystem, we aim to delve deeper. We\nmove beyond the common narrative that\nblockchain communities primarily seek to\nmaximize decentralization and consensus.\nInstead, we recognize and explore the\nexisting practices of ‘governance as conflict.’\nThis report adopts a descriptive (‘as is’)\napproach to blockchain governance rather\nthan a prescriptive (‘could be’ or ‘should be’)\nstance. Nevertheless, we hope the findings\npresented here serve as a reference point\nfor blockchain communities seeking to\ndesign governance frameworks that better\nsuit their interests and needs.\n**BLOCK**fs== 11.0**p== 16.0**b== 0.1**t== 0.5**l== 0.1**r== 0.5**\nBuilding on a substantial body of empirical\nresearch on blockchain governance, this\nreport introduces a multidisciplinary\ncomparative analysis of prominent\nblockchain networks: Avalanche, Bitcoin,\nCardano, Cosmos, Ethereum, Filecoin,\nOptimism, Polygon, Polkadot, Tezos,\nand Zcash. These networks were selected\nfor their technological innovation, adoption\nlevels, diversity in governance design and\noperational layers, and their relationships\nwith various legal entities within their\ncommunities. While additional networks\ncould have been included, our selection\naims to encapsulate the broadest spectrum\nof governance dynamics significant to the\nWeb3 ecosystem. Our methodology for data\ncollection combined desk research of\npublicly available materials with detailed\nsemi-structured interviews with key\nstakeholders from each network.\n**BLOCK**fs== 11.0**p== 16.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\nThis dual approach was crucial for gaining a\ncomprehensive understanding of the officially\ndocumented procedures and the informal\npractices vital to the governance of these\nblockchain networks.\n**BLOCK**fs== 11.0**p== 16.0**b== 0.6**t== 0.3**l== 0.5**r== 0.1**\nBased on this data, we developed a\ncomprehensive taxonomy for blockchain\ngovernance to structure our empirical data\ncollection and analysis. This taxonomy\nconsists of five key dimensions that aid in\nunderstanding the operation and evolution of\nblockchain system governance over time:\n**BLOCK**fs== 11.0**p== 16.0**b== 0.1**t== 0.5**l== 0.5**r== 0.1**\n// The ‘organizational profile’ dimension of our\nblockchain governance taxonomy includes\nseveral critical factors: the founding history,\npurpose, funding mechanisms, legal status,\nand market dynamics that influence a\nblockchain system. An essential aspect of this\ndimension is the technological layer to which\neach case study belongs. Projects associated\nwith layer 0 blockchains, such as Avalanche,\nCosmos, and Polkadot, provide the\nfoundational infrastructure necessary for\nhigher-level blockchains and their potential\ninteroperability. Layer 1 blockchains, including\nBitcoin, Cardano, Ethereum, Filecoin, Tezos,\nPolygon PoS Chain, and Zcash, form the\nprimary networks. These networks consist of\nthe blockchain protocol—the rules and\nprocedures that govern how data is\nexchanged, verified, and recorded—and the\nactual ledger of transactions. Layer 2\nblockchains, like Optimism and Polygon\nRollups, offer scaling solutions that enhance\nthe efficiency and speed of transactions on\nlayer 1 networks.\n**BLOCK**fs== 11.0**p== 17.0**b== 0.7**t== 0.2**l== 0.5**r== 0.1**\n// The ‘governance surfaces’ dimension refers\nto the ‘places’ where governance frameworks\nare implemented, which can be categorized as\neither on-chain or off-chain (written or\nunwritten).\n**BLOCK**fs== 11.0**p== 17.0**b== 0.5**t== 0.3**l== 0.5**r== 0.1**\n// Finally, the ‘governance trends’ dimension\nmonitors the evolution of governance\ndynamics over time. It focuses on trends of\npower distribution (i.e., who decides),\ngovernance scope (i.e., the breadth of\ngovernance areas), governance complexity\n(i.e., the depth and intricacy of governance\nframeworks), and governance formalization\n(i.e., changes to the governance surfaces\nwhere the governance framework is\ndeployed).\n**BLOCK**fs== 11.0**p== 17.0**b== 0.6**t== 0.2**l== 0.1**r== 0.5**\n// The ‘governance areas’ dimension\naddresses the various types of governance\ndecisions made within blockchain systems.\nThese include how to make rules or\n‘secondary rules,’ block production,\nmonetary policy, software updates, treasury\nallocation, rewards for contributors,\nstandards and interoperability, and security\nmeasures and responses to breaches.\n**BLOCK**fs== 11.0**p== 17.0**b== 0.4**t== 0.4**l== 0.1**r== 0.5**\n// The ‘governance frameworks’ dimension\nincludes all the rules, processes, and tools\nused to make decisions within various\ngovernance areas. It covers entry and exit\nrules and processes, distribution of decision-\nmaking power, the governance mechanisms\nthemselves, enforcement processes,\nincentives for participation, internal systems\nfor dispute resolution, and amendability\nrules and processes. The amendability\nprotocols are especially important, as they\ndictate how to modify or repeal previously\nestablished governance rules across\ndifferent governance areas.\n**BLOCK**fs== 11.0**p== 18.0**b== 0.5**t== 0.2**l== 0.1**r== 0.5**\nThe report reveals six key insights into the\ngovernance dynamics of blockchain\nnetworks supported by examples from all\nthe case studies we investigated. At the\nconclusion of each finding, we offer a\nsuccinct reflection on the implications for the\ndesign of blockchain governance. It is\nimportant to understand that while these\ninsights derive from separate dimensions of\nour governance taxonomy, they are not\nisolated. Instead, they are interconnected\nand mutually influential, shedding light on\nthe complex interactions that shape\ngovernance within the blockchain\necosystem.\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.7**l== 0.1**r== 0.7**\n1  The  World  Wide  Web  was  originally  conceived\nas  decentralized,  non-discriminating,  bottom-up,\nuniversal, and consensus-based. See: World Wide\nWeb  Foundation,  “History  of  the  Web,”  accessed\nApril\n2024,\n30,\nhttps://webfoundation.org/about/vision/history-of-\nthe-web/.\n2 Victoria Shannon, “A ‘more Revolutionary’ Web,”\nThe  New  York  Times,  May  23,  2006,  accessed\nApril\n2024,\n30,\nhttps://www.nytimes.com/2006/05/23/technology/\n23iht-web.html.\n3  Originally,  Wood  referred  to  ‘Web  3.0’  but  the\nterm  later  on  morphed  into  ‘Web3.’  See:  Gavin\nWood,  “ĐApps:  What  Web  3.0  Looks  Like,”\nInsights Into a Modern World Blog, April 17, 2014,\naccessed\n2024,\nhttps://gavwood.com/dappsweb3.html.\n4  See:  Primavera  De  Filippi  et  al.,  “Blockchain\nTechnology,  Trust  &  Confidence:  Reinterpreting\nTrust  in  a  Trustless  System?,”  Social  Science\nResearch\n2022,\nhttps://doi.org/10.2139/ssrn.4300486;  Primavera\nDe Filippi et al., “Report on Blockchain Technology\n& Legitimacy,” Social Science Research Network,\n2022,\nJanuary\nhttps://doi.org/10.2139/ssrn.4300502;\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.8**\nNetwork,\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.9**l== 0.2**r== 0.7**\nJanuary\n**BLOCK**fs== 6.0**p== 18.0**b== 0.3**t== 0.7**l== 0.9**r== 0.1**\nInformation\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.7**l== 0.8**r== 0.0**\nRowan  Van  Pelt  et  al.,  “Defining  Blockchain\nGovernance:  A  Framework  for  Analysis  and\nComparison,”\nSystems\nManagement 38, no. 1 (March 9, 2020): 21–\n41,  DOI:10.1080/10580530.2020.1720046;\n“The  Siren  Song:\nKevin  Werbach,\nAlgorithmic  Governance  by  Blockchain,”\nSocial\nNetwork,\nSeptember  24,  2018,  SSRN  Abstract  ID:\n3578610.\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.9**r== 0.1**\nResearch\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.8**r== 0.1**\nScience\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.7**l== 0.3**r== 0.5**\nPrimavera  De  Filippi  et  al.,\n“Blockchain\nConstitutionalism:  The  Role  of  Legitimacy  in\nPolycentric  Systems,”  EUI  Robert  Schuman\nCentre,\n2023,\nOctober\nhttps://blockchaingov.eu/wp-\ncontent/uploads/2023/11/EUI-Conference-\nJune-2023-FINAL.pdf;  Primavera  De  Filippi  et\nal.,  “Report  on  Blockchain  Technology  and\nPolycentricity,” forthcoming.\n“Cryptoeconomics  as\n5  Kelsie  Nabben,\nIntellectual  History  From\nGovernance:  An\n‘Cryptoeconomics,’”\nto\n‘Crypto  Anarchy’\nInternet  Histories  7,  no.  3  (March  3,  2023):\n254–76,\nhttps://doi.org/10.1080/24701475.2023.218364\n3.\n6  Michael  Zargham  and  Kelsie  Nabben,\n“Aligning\nAutonomous\nOrganization’  to  Precedents  in  Cybernetics,”\nSocial  Science  Research  Network,  January  1,\n2022, https://doi.org/10.2139/ssrn.4077358.\n7 Primavera De Filippi and Benjamin Loveluck,\n“The  Invisible  Politics  of  Bitcoin:  Governance\nCrisis  of  a  Decentralised\nInfrastructure,”\nInternet  Policy  Review,  September  29,  2016,\nhttps://hal.science/hal-01382007.\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.9**l== 0.4**r== 0.5**\n‘Decentralized\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.7**l== 0.6**r== 0.2**\n8  Jaya  Klara  Brekke,  Kate  Beecroft,  and\nFrancesca  Pick,  “The  Dissensus  Protocol:\nGoverning  Differences\nin  Online  Peer\nCommunities,” Frontiers in Human Dynamics\n\n(May  26,  2021),  5  Kelsie  Nabben,\n“Cryptoeconomics  as  Governance:  An\nIntellectual History; Eric Alston, “Governance\nas  Conflict:  Constitution  of  Shared  Values\nDefining  Future  Margins  of  Disagreement,”\nMIT  Computational  Law  Report  (2022),  5\nKelsie  Nabben,\nas\nGovernance: An Intellectual History.\n9  See:  Rafael  Ziolkowski  et  al.,  “Examining\nin\nGentle\nHawaii\nBlockchain\non  System\nInternational  Conference\nSciences\n2019,\nDOI:10.5167/uzh-160377;  Lukas  Schädler,\nFlorian\nMichael\nin\nSpychiger,  “Analyzing  Decision-making\nin\nBlockchain  Governance,”  Frontiers\nBlockchain\n2023),\n21,\nDOI:10.3389/fbloc.2023.1256651;\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\nDecision-Making\n52nd\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.7**r== 0.3**\n“Cryptoeconomics\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\nLustenberger,\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.6**r== 0.3**\nSystems,”\n**BLOCK**fs== 6.0**p== 18.0**b== 0.1**t== 0.9**l== 0.6**r== 0.3**\n(August\n**BLOCK**fs== 6.0**p== 18.0**b== 0.2**t== 0.8**l== 0.6**r== 0.4**\nRivalry:\n**BLOCK**fs== 24.0**p== 19.0**b== 0.9**t== 0.1**l== 0.1**r== 0.6**\nI. Legal Entities",
         "Report on Blockchain Governance Dynamics Primavera de Filippi, Sofia Cossar, Morshed Mannan, Tara Merk, Jamilya To cite this version: Primavera de Filippi, Sofia Cossar, Morshed Mannan, Tara Merk, Jamilya Kamalova, et al.. Report on Blockchain Governance Dynamics. Project Liberty Institute. 2024. ￿hal-04855853￿ Submitted on 25 Dec 2024 HAL is a multi-disciplinary open access archive for the deposit and dissemination of sci- entific research documents, whether they are pub- lished or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Distributed under a Creative Commons Attribution - NonCommercial - NoDerivatives 4.0 International License BlockchainGov // Project Liberty Institute This report is licensed under the terms and conditions of the Creative Commons Attribution - NonCommercial - NoDerivatives 4.0 International (CC BY- NC-ND 4.0) unless explicitly stated otherwise (e.g. in the image description). To view this license, visit (https://creativecommons.org/ licenses/by-nc-nd/4.0/deed.en). For re- use or distribution, please include this copyright notice. Please quote as: De Filippi, Primavera, Sofia Cossar, Morshed Mannan, Kelsie Nabben, Tara Merk, and Jamilya Kamalova. “Report on Blockchain Governance Dynamics.” A collaborative effort between Project Liberty Institute and BlockchainGov, May 2004. This report is jointly produced by Project Liberty Institute and BlockchainGov. responsible technology  and  bringing About Project Liberty Institute: Project Liberty Institute, 501(c)(3) founded by Frank McCourt, is building a together global  alliance technologists, academics, policymakers, civil society and citizens to build a  safer,  healthier  tech  ecosystem.  The  Institute  has  an  international partner network that includes Georgetown University, Stanford University, institutions  and  civic Sciences  Po,  and  other organizations; and is the steward of the Decentralized Social Networking Protocol  (DSNP)  which  is  available  as  a  public  utility  to  serve  as  the bedrock of a more equitable web and support a new era of innovation that empowers people over platforms and serves the common good. leading  academic https://www.projectliberty.io/institute About BlockchainGov: BlockchainGov  is  a  5-year  project  (2021-2026)  funded  by  the  European Research  Council  (ERC  grant  of  €2M).  The  project  is  directed  by Primavera  De  Filippi  and  hosted  at  the  Centre  National  de  Recherche Scientifique  (France)  and  the  European  University  Institute  (Italy),  with Principal  Investigator  and  advisors  from  the  Berkman  Klein  Center  at Harvard University. As an interdisciplinary research team comprising legal scholars,  social  and  political  scientists,  computer  scientists,  and blockchain  engineers,  BlockchainGov  focuses  on  studying  the  impact  of for blockchain legitimacy and trust. technology  on  governance  and its  consequences https://blockchaingov.eu/ This  report  has  been  developed  with  the  help  of  the  Governance  Multis- takeholder Council (MSH Council). The views expressed in this report do not reflect the views of the organizations with which Council members are affiliated. Any errors or omissions are those of the research team and not the MSH Council members. MSH Council members might not necessarily endorse all views presented in the research report. Eric Alston is a Scholar in Residence in the Finance Division at University of Colorado Boulder. Eric’s research applies methodologies and concepts from institutional & organizational analysis and law & economics to studies of constitutions, economic rights on frontiers, and digital governance. Eric is also currently engaged in governance design for several distributed network projects. Pierre Noro is a researcher and lecturer in decentralized governance, blockchain technologies and digital ethics. After several years designing innovative blockchain- based public services for France’s main public finance institution, Pierre is now building impact- oriented decentralized projects with startups and Web3 communities, such as decentralized voting (Pebble. vote), decentralized social networks (Frequency.xyz) or Regenerative Finance. Pierre is a lecturer at SciencesPo Paris and at the Learning Planet Institute (Université Paris- Cité). Laura E. De Nardis is a Professor of Technology, Ethics and Society at Georgetown University in Washington, DC. With a background in information engineering and a doctorate in Science and Technology Studies, she has published seven books and numerous articles on the political and social implications of Internet technical architecture and governance. Dr. DeNardis is a member of the Council on Foreign Relations and an affiliated Fellow (and previously Executive Director) at the Information Society Project at Yale Law School. Her book The Internet in Everything: Freedom and Security in a World with No Off Switch (Yale University Press) was recognized as a Financial Times Top Technology Book of 2020. Federico Ast graduated in economics and philosophy and holds a PhD in management. He is passionate about the use of technology for social innovation. He is founder of Kleros, a protocol using game theory and blockchain technology in dispute resolution. Kaitlin Beegle is the Head of Protocol Governance at the Filecoin Foundation. She holds an MSc in Politics and Technology from the Technical University of Munich, where her research focused on on the political theory of ‘openness’ in democracies and open- source technologies. Prior to this, she was a researcher in innovation policies for various agencies in both the US and UK governments, as well as an activist and community organizer. She lives in San Francisco. E. Glen Weyl is Founder and Research Lead of Microsoft Research’s Special Project the Plural Technology Collaboratory, Founder of the Plurality Institute and RadicalxChange Foundation and co-author with Audrey Tang of the forthcoming open, collaborative book project, Plurality: The Future of Collaborative Technology and Democracy, and with Eric Posner of Radical Markets: Uprooting Capitalism and Democracy for Just Society. Philippe Honigman is a DAOist, a commoner, and a former entrepreneur. As the Governance Lead at Mangrove DAO, he drives the design and the implementation of novel participation and governance mechanisms. PhilH is also part of dOrg (collective of Web3 builders), a board member of Ethereum France (organizer of the main European crypto conference), and an advisor at Morpho and Usual. Pindar Wong is an Internet pioneer, who co- founded the first licensed Internet Service Provider in Hong Kong in 1993. Previously, Pindar was the first Vice-Chairman of ICANN, Chairman of the Asia Pacific Internet Association, alternate Chairman of Asia Pacific Network Information Center, Co- Public Lead of Creative Commons Hong Kong, Chairman of APRICOT, Commissioner on the Global Commission on Internet Governance and elected Trustee of the Internet Society. He organised Asia’s first Blockchainworkshops. org and ScalingBitcoin.org She was a member of the Executive Leadership Team for the Centre for the Fourth Industrial Revolution. She oversaw tech policy strategy across 14 countries and regularly briefed ministers, CEOs of the Fortune 100 and Heads of State. David Tomchak is the founder of the Web3 and AI coalition “Cogency”, whose work focuses on digital identity, trust and media. He is a multi-award- winning journalist, editor and technology leader whose experience over the last 20 + years has ranged from organisations such as the BBC and the London Evening Standard to start- ups and the likes of JP Morgan. His career has also included a spell in government where he was the Head of Digital and Deputy Director of Communications for Downing Street in the UK. David founded the AI In Media (AIIM) working group in 2016 which has now been included in Cogency. David is also a Visiting Policy Fellow at the Oxford Internet Institute, University of Oxford. Dr. Joachim Schwerin is Principal Economist in the unit responsible for the Digital Transformation of Industry within the Directorate- General Internal Market, Industry, Entrepreneurship and SMEs (DG GROW) of the European Commission. He is responsible for developing the policy approach of DG GROW towards the Token Economy and Distributed- Ledger Technologies as well as their applications for industry and SMEs, with a current focus on supporting the emergence of DAOs and a truly decentralised Web3. In 2020, he contributed to the Digital Finance Strategy, including the MiCA Regulation. Joachim holds a PhD in economics from Dresden University of Technology and was Post-Doc Research Fellow at the Economic History Department of the London School of Economist before he joined the European Commission in 2001. Sarah Roth-Gaudette, Executive Director, Fight for the Future. Over the past 25 years, Sarah has managed campaigns with some of the largest grassroots mobilizing groups in the country, including U.S. PIRG and MoveOn PAC, and understands how to stimulate grassroots engagement and convert it into effective political results using the best technology, communications, and alliance building. She now heads the digital rights advocacy organization, Fight for the Future. The group developed the strategy and online tools that have shaped policies to protect net neutrality, stop online censorship and surveillance, and defend alternatives to Big Tech and Big Banks. Known for its massively viral effort at dontkillcrypto.com that drove 40,000+ calls to senators to oppose last minute additions to the infrastructure bill, Fight has emerged as a leading human rights advocate in the crypto space, opposing financial surveillance, defending the right to code, and ensuring that lawmakers and consumers alike understand the stakes of these complex technologies. Dr. Paolo Tasca is a globally renowned blockchain economist and Professor at University College London, with a specialization in distributed systems. He is also the esteemed founder of the award-winning UCL Centre for Blockchain Technologies. Complementing his academic accomplishments, Dr. Tasca boasts an impressive track record as a seasoned blockchain entrepreneur, with multiple successful exits. His extensive expertise in blockchain technologies has led him to serve as a special advisor for an array of international stakeholders, including the United Nations, central banks, and various governmental and industry entities. Sheila Warren is the CEO of the Crypto Council for Innovation - the premier global alliance for advancing the promise of this new technology through research, education and advocacy. Sheila founded the World Economic Forum’s blockchain and digital assets team. Paul Fehlinger, Director of Policy, Governance Innovation & Impact Sarah Nicole, Policy & Research Senior Associate Primavera de Filippi, Project Lead While the evolution of the World Wide Web has taken various turns away  from  its  original  vision,  the  advent  of  Web3  promises  a  new era  focused  on  user ‘decentralization.’  The ‘ownership’  and concept of Web3, introduced in 2014 by Ethereum co-founder and Polkadot  creator  Gavin  Wood,  focuses  on  a  new  infrastructure based  on  decentralized  networks  and  technologies.  This  new infrastructure  enhances  user  ownership  and  autonomy  by  moving away from centralized operators and trusted intermediaries. technology is  a  cornerstone  of  Web3, initially Blockchain developed as an innovative means to record transactions digitally. The  collective  choices  of  individuals  and  organizations  drive  the evolution  of  blockchain  technology  and  its  diverse  applications. These  entities  form  what  are  known  as  ‘blockchain  systems’: complex  techno-social  structures  that  operate  across  multiple intertwined the  capabilities  of  blockchain technology  to  store  data  across  multiple  nodes,  the  governance dynamics within blockchain systems are complex and nuanced. To fully grasp the opportunities and challenges of Web3, it is essential fundamental to  analyze components, including blockchain networks. the  governance  practices  of layers.  Beyond This  report  is  a  collaborative  effort  between  BlockchainGov  and Project  Liberty  Institute  to  analyze  the  governance  dynamics  of prominent  blockchain  networks  through  an  interdisciplinary  and comparative  lens.  It  focuses  on  eleven  blockchain  networks: Avalanche,  Bitcoin,  Cardano,  Cosmos,  Ethereum,  Filecoin, Optimism,  Polygon,  Polkadot,  Tezos,  and  Zcash.  Through  a comprehensive empirical analysis built on previous academic work and  practitioners’  insights,  the  report  offers  six  key  findings  about the governance dynamics of these blockchain systems. functions, founder-led for  engaging including  providing Most  blockchain  networks,  with  the  notable  exception  of  Bitcoin, have  established  legal  entities  such  as  non-profit  foundations  or corporations to manage various aspects of their operations. These entities  serve  several legal recognition in  off-chain  contracts,  navigating regulatory uncertainties, enhancing governance sustainability, and supporting  ecosystem  growth  through  grants.  Although  forming these  legal  entities  aims  to  create  greater  legal  certainty  for blockchain  networks,  this  is  not  always  achieved.  Such  entities, whether corporations  or  non-profit foundations, often hold a significant minority stake in the network's governance  through  token  ownership.  However,  this  stake  does not  grant  them  unilateral  control  over  the  networks.  Instead,  they influence  the  networks  in  other  ways.  Concern  arises  because these  entities  typically inclusive mechanisms  for  appointing  and  holding  their  board  of  directors accountable,  leading  to  a  mismatch  between  the  public  and permissionless  nature  of  the  networks  and  the  opacity  of  the supporting  legal  entities.  This  opacity  can  raise  issues  such  as potential  conflicts  of  interest  and  lack  of  disclosure  of  important information to the community. lack  open,  transparent,  and for-profit While  no  blockchain  system  is  ‘centralized’  in  the  sense  that  it  is governed by one single person or entity, decision-making power is not evenly distributed. The concrete power distribution within these systems  varies  significantly  depending  on  the  specific  case.  This variation  arises  due  to  factors  such  as  the  governance  areas  or types  of  decisions  being  made,  the  diverse  array  of  stakeholders in  the  governance involved,  and  the  mechanisms  employed process.  Recognizing  blockchain  systems'  nuanced  and multifaceted  structure  is  essential  for  discerning  the  actors  who shape governance outcomes and the channels through which they exert  influence.  Blockchain  communities  can  identify  governance practices that stray from their foundational values or objectives by interplay  among  governance  areas, examining for insight stakeholders,  and  mechanisms.  This developing rules, procedures, and mechanisms that better address community  concerns  and  aspirations,  ultimately  creating governance  systems  that  align  more  closely  with  their  collective needs. the  complex is  crucial Planned vs. Actual there  are  many  possible  approaches After launching  a  blockchain  network,  community  members commonly  pledge to  progressively  decentralize  governance. to However,  while ‘decentralization’,  blockchain  communities  frequently  lack  public, clear,  and  operational  definitions.  Additionally,  several  factors impede  the  actual  process  of  decentralization.  On-chain,  power tends to  consolidate  among  mining  and  validator  pools, exacerbated  by  plutocratic  token-weighted  voting  systems.  Off- chain,  the  challenges  include  escalating  governance  complexity, early  entrenchment  of  power,  and  external  regulatory  pressures. Blockchain  communities  that  genuinely  seek  to  progressively decentralize must adopt precise and operational definitions of what decentralization  means  in  the  context  of  their  blockchain  system. Additionally, they will need to recognize and address on-chain and off-chain challenges. termed ‘secondary  rules.’  However,  despite In recent years, blockchain communities have experienced greater ‘formalization,’  or  a  surge in  the  adoption  of  online  written documents  delineating  blockchain  rules  and  procedures.  These documents play a crucial role in establishing the framework for off- chain  and  on-chain  decision-making,  essentially  introducing  what can  be these advancements, the blockchain governance landscape still grapples with  a  significant  gap  between  these  formalized  rules  and  the implicit,  often  undocumented,  practices  that  shape  governance within  many  blockchain  systems.  Governance  formalization  can become  an  important  opportunity  for  strengthening  the  legitimacy of  blockchain  systems.  Yet,  community  members  should  remain aware of the delicate interplay between on-chain rules, expressed through blockchain code, and off-chain practices, which can never be completely and fully expressed on-chain. Implementing a hybrid of on-chain and off-chain rules makes blockchain governance more flexible  and  adaptable  to  the  community’s  evolving  needs  while preserving reliability  and  accountability  of  code-based mechanisms. and Breaches Certain  governance  areas  within  blockchain  systems  welcome contributions from various stakeholder groups. ‘Rough consensus’ and  ‘signaling  and  voting’  represent  two  governance  mechanisms for gathering input and making decisions. Blockchain communities utilize varying degrees of sophistication in these mechanisms and implement  them  independently  or  in  conjunction,  resulting  in diverse decision-making processes for each scenario. The distinct characteristics  of  these  mechanisms,  alongside  factors  like  the nature of the decision and the stakeholders involved, can give rise to  more to governance  design.  Blockchain  communities  must  thoughtfully weigh  the implications  of  adopting  rough  consensus  versus signaling and voting since these can create specific incentives that may  either  promote  advantageous  or  detrimental  behaviors,  thus influencing  the  network’s  sustainability  and  resilience.  These the dynamics legitimacy of the blockchain system. invariably  shape  stakeholders’  perceptions  of ‘expedient’  approaches ‘participatory’ to  more Preventive  security  measures  in  blockchain  networks  involve  a range  of  strategies  and  technologies  aimed  at  thwarting  potential threats such as DDoS attacks, ‘51% attacks,’ and vulnerabilities in smart contracts. These measures often rely on the expertise of in- house security teams or third-party contributors incentivized by bug bounty  programs.  Additionally,  third-party  security  audits  are commonplace across various blockchain ecosystems, ensuring an extra layer of protection. While some blockchain communities have established  procedures  or  governance  bodies to  address unforeseen  events,  the  handling  of  ‘states  of  exception’  continues to  be  a  governance  area  that  sparks  controversy  within  these communities. To maintain community trust, ensuring the security of blockchain networks requires adopting formal and well-understood the processes likelihood  of  decision-making  centralization  for  personal  gain. Achieving  this  balance  demands  a  fusion  of  specialized  technical knowledge  and  an  understanding  of  stakeholders’  needs  and incentives  to  define  the  parameters  under  which ‘states  of exception’ can, if any, be invoked within a blockchain ecosystem. threats  while  reducing for  handling  external Table of contents I. Legal Entities II.Power Distribution III. Planned vs Actual Decentralization IV. Governance Formalization V. Governance Mechanisms VI. Security Measures and Breaches This report was produced jointly by Project Liberty Institute and BlockchainGov. It aims to provide a rigorous and granular framework for understanding how governance decisions are made and adopted within the rapidly evolving Web3 ecosystem while helping foster a sustainable and responsible ecosystem for decentralized technologies, ensuring that the benefits of Web3 are accessible to all while minimizing potential risks and challenges. This publication lays the foundation of a Manual on Best Governance Practices for Blockchain and Decentralized Technologies which will highlight recommendations to build a more responsible ecosystem. This manual will be published in April 2024. The Project Liberty Institute and BlockchainGov teams express their gratitude to the fifteen experts forming the Governance Multistakeholder Council for their valuable contributions to our work. Their feedback during this iterative process has been instrumental in shaping the qualitative outcomes that can now be showcased publicly. While the evolution of the World Wide Web has taken various turns away from its original vision¹, the advent of Web3 promises a new era focused on user ‘ownership’ and ‘decentralization.’ Initially, Web 1.0, often known as the ‘static web,’ featured read-only pages with limited interactivity or user-generated content. This phase progressed to Web 2.0, or the ‘social web,’ which enhanced user participation by allowing users to consume (‘read’) and produce (‘write’) content. Although they are often used interchangeably, the terms Web3 and Web 3.0 each highlight distinct aspects of the web’s ongoing transformation. ‘Web 3.0’ was used by Tim Berners-Lee, the creator of the World Wide Web, in 2006 to describe a semantic, connected, and open iteration of the web. This phase envisioned utilizing smarter computer processing through machine- readable data, improving data sharing and linking across various platforms, and relying on open-source standards to foster transparency and inclusivity². In contrast, the concept of Web3, introduced in 2014 by Ethereum co-founder and Polkadot creator Gavin Wood, focuses on a new infrastructure based on decentralized networks and technologies. This new infrastructure enhances user ownership and autonomy by moving away from centralized operators and trusted intermediaries. Blockchain technology is a cornerstone of Web3, initially developed as an innovative means to record transactions digitally³. Blockchains and smart contracts have introduced a fundamental shift, eliminating the need for central authorities to facilitate all kinds of interactions. Today, public and permissionless blockchains are employed across various sectors, including finance, trading, gaming, art, supply chain management, and identity verification. This ushers in an era marked by architectural decentralization, censorship resistance, transparency, and immutability, now considered critical technological infrastructure attributes. The collective choices of individuals and organizations drive the evolution of blockchain technology and its diverse applications. These entities form what are known as ‘blockchain systems’ or complex techno-social structures that operate across multiple intertwined layers. Beyond the capabilities of blockchain technology to store data across multiple nodes, the governance dynamics within blockchain systems are complex and nuanced. To fully grasp the opportunities and challenges of Web3, it is essential to analyze the governance practices of its fundamental components, including blockchain networks. This report is a collaborative effort between BlockchainGov and Project Liberty’s Institute to analyze the governance dynamics of prominent blockchain networks through an interdisciplinary and comparative lens. Our research defines ‘governance’ as the process through which multiple actors’ diverging and sometimes conflicting interests are reconciled, leading to collective action based on shared principles and agreed-upon procedures. Our analysis of governance processes within blockchain systems builds on our previous work and integrates insights from academic research and practitioner experiences. These insights shed light on the historical and ideological, social and technical aspects, as well as the on-chain and off-chain dynamics of blockchain systems. Although ‘decentralization’ is often highlighted as a defining feature of this ecosystem, we aim to delve deeper. We move beyond the common narrative that blockchain communities primarily seek to maximize decentralization and consensus. Instead, we recognize and explore the existing practices of ‘governance as conflict.’ This report adopts a descriptive (‘as is’) approach to blockchain governance rather than a prescriptive (‘could be’ or ‘should be’) stance. Nevertheless, we hope the findings presented here serve as a reference point for blockchain communities seeking to design governance frameworks that better suit their interests and needs. Building on a substantial body of empirical research on blockchain governance, this report introduces a multidisciplinary comparative analysis of prominent blockchain networks: Avalanche, Bitcoin, Cardano, Cosmos, Ethereum, Filecoin, Optimism, Polygon, Polkadot, Tezos, and Zcash. These networks were selected for their technological innovation, adoption levels, diversity in governance design and operational layers, and their relationships with various legal entities within their communities. While additional networks could have been included, our selection aims to encapsulate the broadest spectrum of governance dynamics significant to the Web3 ecosystem. Our methodology for data collection combined desk research of publicly available materials with detailed semi-structured interviews with key stakeholders from each network. This dual approach was crucial for gaining a comprehensive understanding of the officially documented procedures and the informal practices vital to the governance of these blockchain networks. Based on this data, we developed a comprehensive taxonomy for blockchain governance to structure our empirical data collection and analysis. This taxonomy consists of five key dimensions that aid in understanding the operation and evolution of blockchain system governance over time: // The ‘organizational profile’ dimension of our blockchain governance taxonomy includes several critical factors: the founding history, purpose, funding mechanisms, legal status, and market dynamics that influence a blockchain system. An essential aspect of this dimension is the technological layer to which each case study belongs. Projects associated with layer 0 blockchains, such as Avalanche, Cosmos, and Polkadot, provide the foundational infrastructure necessary for higher-level blockchains and their potential interoperability. Layer 1 blockchains, including Bitcoin, Cardano, Ethereum, Filecoin, Tezos, Polygon PoS Chain, and Zcash, form the primary networks. These networks consist of the blockchain protocol—the rules and procedures that govern how data is exchanged, verified, and recorded—and the actual ledger of transactions. Layer 2 blockchains, like Optimism and Polygon Rollups, offer scaling solutions that enhance the efficiency and speed of transactions on layer 1 networks. // The ‘governance surfaces’ dimension refers to the ‘places’ where governance frameworks are implemented, which can be categorized as either on-chain or off-chain (written or unwritten). // Finally, the ‘governance trends’ dimension monitors the evolution of governance dynamics over time. It focuses on trends of power distribution (i.e., who decides), governance scope (i.e., the breadth of governance areas), governance complexity (i.e., the depth and intricacy of governance frameworks), and governance formalization (i.e., changes to the governance surfaces where the governance framework is deployed). // The ‘governance areas’ dimension addresses the various types of governance decisions made within blockchain systems. These include how to make rules or ‘secondary rules,’ block production, monetary policy, software updates, treasury allocation, rewards for contributors, standards and interoperability, and security measures and responses to breaches. // The ‘governance frameworks’ dimension includes all the rules, processes, and tools used to make decisions within various governance areas. It covers entry and exit rules and processes, distribution of decision- making power, the governance mechanisms themselves, enforcement processes, incentives for participation, internal systems for dispute resolution, and amendability rules and processes. The amendability protocols are especially important, as they dictate how to modify or repeal previously established governance rules across different governance areas. The report reveals six key insights into the governance dynamics of blockchain networks supported by examples from all the case studies we investigated. At the conclusion of each finding, we offer a succinct reflection on the implications for the design of blockchain governance. It is important to understand that while these insights derive from separate dimensions of our governance taxonomy, they are not isolated. Instead, they are interconnected and mutually influential, shedding light on the complex interactions that shape governance within the blockchain ecosystem.",
         "https://hal.science/hal-04855853v1/file/ssrn-5029113.pdf",
         "extracted",
         "None",
         "",
         "Report on Blockchain Governance Dynamics"
        ],
        [
         "48",
         "021475212b53ecfc81f49506378ee09635f43305",
         "The development of artificial intelligence (AI) game agents that use deep reinforcement learning (DRL) algorithms to process visual information for decision-making has emerged as a key research focus in both academia and industry. However, previous game agents have struggled to execute multiple commands simultaneously in a single decision, failing to accurately replicate the complex control patterns that characterize human gameplay. In this paper, we utilize the ViZDoom environment as the DRL research platform and transform the agent–environment interactions into a Partially Observable Markov Decision Process (POMDP). We introduce an advanced multi-agent deep reinforcement learning (DRL) framework, specifically a Multi-Agent Proximal Policy Optimization (MA-PPO), designed to optimize target acquisition while operating within defined ammunition and time constraints. In MA-PPO, each agent handles distinct parallel tasks with custom reward functions for performance evaluation. The agents make independent decisions while simultaneously executing multiple commands to mimic human-like gameplay behavior. Our evaluation compares MA-PPO against other DRL algorithms, showing a 30.67% performance improvement over the baseline algorithm.",
         "Zihao Cui,Kailian Deng,Hongtao Zhang,Zhongyi Zha,Sayed Jobaer",
         "\n**BLOCK**fs== 17.9**p== 0.0**b== 0.8**t== 0.1**l== 0.1**r== 0.1**\nArticle\nDeep Reinforcement Learning-Based Multi-Agent System with\nAdvanced Actor–Critic Framework for Complex Environment\n**BLOCK**fs== 10.0**p== 0.0**b== 0.8**t== 0.2**l== 0.1**r== 0.3**\nZihao Cui 1,2, Kailian Deng 1,2,*, Hongtao Zhang 1,2,†, Zhongyi Zha 1,3 and Sayed Jobaer 1,2\n**BLOCK**fs== 8.0**p== 0.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\n1 College of Information Science and Technology, Donghua University, Shanghai 201620, China;\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\n220995127@mail.dhu.edu.cn (Z.C.); 2201957@mail.dhu.edu.cn (H.Z.); m202072829@hust.edu.cn (Z.Z.);\n421015@mail.dhu.edu.cn (S.J.)\nEngineering Research Center of Digitized Textile and Apparel Technology, Ministry of Education,\nShanghai 201620, China\nSchool of Artificial Intelligence and Automation, Huazhong University of Science and Technology,\nWuhan 430074, China\n**BLOCK**fs== 8.0**p== 0.0**b== 0.7**t== 0.3**l== 0.3**r== 0.4**\n* Correspondence: dengkailian@dhu.edu.cn\n†\n**BLOCK**fs== 8.0**p== 0.0**b== 0.6**t== 0.3**l== 0.3**r== 0.4**\nThis author is second contribution to this work.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nAbstract: The development of artificial intelligence (AI) game agents that use deep rein-\nforcement learning (DRL) algorithms to process visual information for decision-making has\nemerged as a key research focus in both academia and industry. However, previous game\nagents have struggled to execute multiple commands simultaneously in a single decision,\nfailing to accurately replicate the complex control patterns that characterize human game-\nplay. In this paper, we utilize the ViZDoom environment as the DRL research platform and\ntransform the agent–environment interactions into a Partially Observable Markov Decision\nProcess (POMDP). We introduce an advanced multi-agent deep reinforcement learning (DRL)\nframework, specifically a Multi-Agent Proximal Policy Optimization (MA-PPO), designed to\noptimize target acquisition while operating within defined ammunition and time constraints.\nIn MA-PPO, each agent handles distinct parallel tasks with custom reward functions for per-\nformance evaluation. The agents make independent decisions while simultaneously executing\nmultiple commands to mimic human-like gameplay behavior. Our evaluation compares\nMA-PPO against other DRL algorithms, showing a 30.67% performance improvement over\nthe baseline algorithm.\n**BLOCK**fs== 10.0**p== 0.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nKeywords: deep reinforcement learning; convolution neural network; partially observable\nMarkov decision process; multi-agent system\n**BLOCK**fs== 12.0**p== 0.0**b== 0.2**t== 0.7**l== 0.3**r== 0.6**\n1. Introduction\n**BLOCK**fs== 10.0**p== 0.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nRecent advancements in fundamental physics have been facilitated by the implemen-\ntation of artificial neural networks and machine learning methodologies [1]. In parallel,\nAlphaFold, an innovative system integrating deep learning and reinforcement learning\nmethodologies, was honored with the Nobel Prize in Chemistry for its revolutionary ad-\nvancements in the field of protein structure prediction [2]. The progression from AlphaStar\nand AlphaGo’s notable successes in gaming to AlphaFold’s groundbreaking applications\nin biology exemplifies the versatility of deep reinforcement learning (DRL) technology [3].\nDRL, which integrates neural networks with reinforcement learning principles, has not only\ndemonstrated remarkable efficacy in gaming scenarios but also continues to significantly\nadvance various domains of scientific research [4,5].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\nDRL has achieved substantial attention across both industry and academia [6], demon-\nstrating its capability as a model-free methodology for addressing complex decision-making\nchallenges in industrial environments [7]. AlphaGo, an artificial intelligence (AI) system for\nthe ancient game of Go, achieved a historic milestone by defeating human Go champions [8].\nThe system utilizes a sophisticated dual-phase approach, initially employing supervised\nlearning on human data before transitioning to reinforcement learning through self-play\niterations. Leveraging the powerful function approximation capabilities of deep neural net-\nworks, DRL agents demonstrate remarkable proficiency in acquiring knowledge through\ninteractions with unknown, information-limited environments, ultimately leading to robust\nreal-time decision-making processes. Building upon the exceptional adaptability of DRL\nagents in complex environments, DRL-based algorithms have demonstrated significant value\nacross multiple domains, including intraday scheduling for home energy systems [9], flight\ntrajectory optimization for unmanned aerial vehicles [10], and energy trading between electric\nvehicles and power grids [11]. The foundation for these achievements stems is built on the\nextensive testing and validation of DRL frameworks through diverse gaming environments\nand simulators, establishing it as an advanced and effective paradigm [12,13].\n**BLOCK**fs== 10.0**p== 1.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nThe journey commenced with DeepMind’s groundbreaking implementation of DRL\ntechnology in Atari games [14], where artificial intelligence agents demonstrated exceptional\ncapabilities in mastering and subsequently surpassing human performance levels [15]. While\nAlphaStar showcased unprecedented mastery by outperforming 99.8% of human players in\nStarCraft through its precise real-time execution, it encountered limitations in certain scenar-\nios due to deficiencies in cognitive reasoning and strategic planning capabilities. Currently,\nOpenAI Gym provides a diverse range of game interfaces for training and evaluating DRL\nalgorithms, i.e., SC2LE [16], ViZDoom [17], and Mujoco [18], establishing a robust founda-\ntion for developing more sophisticated game AI [19]. Therefore, our research is focused on\noptimizing the implementation of advanced DRL frameworks within ViZDoom, a simulation\nenvironment that incorporates complex multi-dimensional action controls.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.3**t== 0.5**l== 0.3**r== 0.1**\nMoreover, collaborative interaction between multiple agents has been demonstrated to\nbe an effective approach for converging toward near-optimal solutions [20,21]. With the ad-\nvancement of single-agent DRL implementations, multi-agent DRL has sparked a wave of\nenthusiasm [22,23]. Multi-agent reinforcement learning enables collaboration by maximiz-\ning collective rewards, which expands traditional reinforcement learning from individual\nproblem-solving to cooperative achievement [24]. The methodology has shown remarkable\neffectiveness in advanced applications including multiplayer games [25], coordinated UAV\noperations [26], and robot swarm control systems [27]. Since real-world scenarios often\ninvolve multiple interacting agents, we incorporate a multi-agent framework into the DRL\nparadigm to improve agent performance in ViZDoom.\n**BLOCK**fs== 10.0**p== 1.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nIn reinforcement learning, developing sophisticated agents capable of replicating human-\nlike behavioral patterns within gaming environments remains a significant challenge. To\naddress this challenge, we introduce MA-PPO, an advanced reinforcement learning algorithm\nframework specifically designed for complex gaming scenarios. Using the first-person shooter\ngame ViZDoom as our experimental platform, we model environmental interactions as\na Partially Observable Markov Decision Process. Our MA-PPO algorithm incorporates an\nadvanced multi-agent architecture that overcomes a key limitation of traditional reinforcement\nlearning: instead of executing only one action per decision, it enables agents to perform\nmultiple commands simultaneously, much like human players. To ensure genuine intelligence\nrather than scripted behavior, we implement a distributed task allocation mechanism, where\nagents operate independently on parallel objectives, avoiding control conflicts. Through\ncomprehensive empirical evaluation against other reinforcement learning algorithms, our\nframework achieves superior performance in the ViZDoom environment.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.9**t== 0.1**l== 0.3**r== 0.2**\nThe main contributions of our work are summarized as follows:\n**BLOCK**fs== 10.0**p== 2.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\n• We transform the interactions between the ViZDoom environment and agents into a Par-\ntially Observable Markov Decision Process, and systematically define the corresponding\nstates, actions, and reward functions. The reward functions serve as key indicators for\nassessing the effectiveness of each agent in executing their designated specialized tasks.\n• We propose an innovative multi-agent reinforcement learning algorithm framework\nMA-PPO based on PPO. Our framework utilizes image information as input and\noutputs joint actions composed of multiple individual actions to interact with the\nViZDoom environment, achieving predefined objectives in a manner that better ap-\nproximates human players.\nSimulation experiments show that compared to original PPO, MA-PPO achieved a\n30.67% reward gain, while compared to three other benchmark algorithms including\nDQN, MA-PPO achieves at least 32.00% performance improvement. Visual analysis\nshows that MA-PPO achieves optimal task completion with minimal steps required,\nand parameter experiment results indicate that all selected parameters are optimal.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nThe reminder of this paper is organized as follows. Section 2 introduces the related\nwork. Section 3 first introduces the ViZDoom simulator and the multi-agent POMDP\nformulation. Section 4 describes the update process of the proposed MA-PPO algorithm and\nthe network architecture. Section 5 evaluates the performance of the proposed algorithm\nthrough simulations and conducts a parameter experiment. Finally Section 6 concludes the\npaper. The main symbols used in this paper are summarized in Table 1.\n**BLOCK**fs== 9.0**p== 2.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nTable 1. List of notations.\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\nSymbol\n**BLOCK**fs== 7.6**p== 2.0**b== 0.1**t== 0.5**l== 0.3**r== 0.6**\nP\nγ\nI, i\nT, t\nR, rt\nrmove, rshoot\nrhit\nS, st\nA, at\nAi\nastay, ale f t, aright\nahold, ashoot\nri\nt, si\nt, ai\nt\nτ\nVtarget\nΘ\nVΘ(st)\nLVF(Θ)\nˆAt\nδt\nθ\nθold\nπθ\nπθold\nπθ(at | st)\npt(θ)\nLclip (θ)\npclip (θ)\n**BLOCK**fs== 10.0**p== 2.0**b== 0.5**t== 0.5**l== 0.7**r== 0.2**\nDefinition\n**BLOCK**fs== 10.0**p== 2.0**b== 0.1**t== 0.5**l== 0.5**r== 0.1**\nState transition probability function\nDiscount factor\nSet of agents, agent number\nTermination time, time slot\nReward function, reward at time slot t\nPenalty of movement and shooting\nReward of hitting the target\nState space set, state at time slot t\nAction space set, action made by the agent at time slot t\nAction space set of agent i\nStay still, move to the left or right\nHold a weapon without firing, fire\nReward,state or action at time slot t of agent i\nTrajectory\nTarget value\nParameter of critic network\nValue calculated by critic network with Θ\nLoss function of critic network with Θ\nEstimated value of advantage function\nMeasurement of the loss estimated by critic network\nParameter of actor network\nOld parameter of actor network before updating\nPolicy of actor network\nOld policy of actor network before updating\nProbability of policy πθ taking action at at state st\nRatio of πθ to πθold in taking action at at state st\nLoss function for updating actor network\nValue of pt(θ) after clip operation\n**BLOCK**fs== 12.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\n2. Related Work\n**BLOCK**fs== 10.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.1**\nIn this section, we review the related works, including applications of the actor–critic\n**BLOCK**fs== 10.0**p== 3.0**b== 0.9**t== 0.1**l== 0.3**r== 0.6**\nframework in RL.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\nAlthough RL has demonstrated remarkable efficacy in practical applications, there\nremain several critical areas that need further exploration and research. Traditional tabular-\nbased RL methods, i.e., Q-learning and Sarsa, employ a tabular structure to maintain states\nand actions, facilitating value function retrieval through systematic table consultation. Li\net al. introduced Approximate Dynamic Programming (ADP) as an innovative methodol-\nogy for optimizing long-term operational costs in microgrid systems [28]. The real-time\nscheduling problem was modeled as a finite-horizon Markov decision process. Through the\nimplementation of neural networks for power generation forecasting, the ADP approach\ndemonstrated effectiveness when evaluated using authentic power grid data simulations.\nAnderson et al. conducted research on modeling player interactions in StarCraft through\nNash equilibrium theory, with findings indicating that the implementation of minimax-Q\nalgorithms led to enhanced performance for AI agents in StarCraft tournaments [29].\n**BLOCK**fs== 10.0**p== 3.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nHowever, value function-based tabular RL algorithms are limited to handling only\ndiscrete action and state spaces, and encounter the problem of decision fatigue. As a\nresult, the implementation of the actor–critic framework presents an effective solution to\naddress the operational limitations. Wang et al. implemented an actor–critic network in\nhome energy systems to deal with continuous battery charging and discharging actions [9].\nThe actor–critic-based RL scheme enhances the economic efficiency of battery scheduling,\nwhile maintaining safety constraints throughout daily operations. Zha et al. introduced an\nactor–critic algorithm named Advanced Actor–Critic (AAC) that trains agents to match\nhuman-level skill in the complex strategy game StarCraft II [30]. The AAC-based AI\ndemonstrates rapid convergence despite encountering vast state and action spaces.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.3**t== 0.5**l== 0.3**r== 0.1**\nAlthough reinforcement learning has advanced significantly across many fields, re-\nsearch has primarily focused on single-agent scenarios, even though real-world applications\noften involve multiple decision-makers working together [31]. Thus, multi-agent rein-\nforcement learning has emerged as a powerful approach for tackling complex real-world\nproblems [32]. Lowe et al. first introduced the multi-agent actor–critic framework, i.e.,\nmulti-agent deep deterministic policy gradient (MADDPG), which handles environmental\nnon-stationarity through a system of multiple trained sub-policies, with random policy\nselection during each episode [33]. MADDPG, as a versatile multi-agent reinforcement\nlearning framework, has made significant contributions through its centralized training and\ndistributed execution strategy in multi-robot collaborative systems [34], human behavior\nimitation [35], and Data Center Digital Twins [36].\n**BLOCK**fs== 12.0**p== 3.0**b== 0.3**t== 0.7**l== 0.3**r== 0.5**\n3. Modeling in ViZDoom\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nIn this section, we introduce the ViZDoom simulator, a gaming platform widely used\nfor training DRL agents. We then present the concept of Partially Observable Markov\nDecision Process (POMDP) and its extension to a multi-agent framework. Finally, we detail\nthe construction process and theoretical foundations of multi-agent POMDP.\n**BLOCK**fs== 10.0**p== 3.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\n3.1. Preliminaries\n3.1.1. ViZDoom\n**BLOCK**fs== 10.0**p== 3.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nViZDoom is a reinforcement learning research platform built on a popular open-source\n3D first-person shooting game, allowing agents to play Doom by interacting with screen\nbuffers and game variables [37]. From a technical performance perspective, the ViZDoom\nenvironment demonstrates excellent optimization results. At a resolution of 320 × 240, the\nenvironment achieves an average rendering rate of 2500 frames per second. At a lower\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nresolution of 160 × 120, even single-threaded CPUs can achieve up to 7000 frames per\nsecond. For reinforcement learning research, the ViZDoom simulator runs in synchronous\nmode, where the game engine pauses to await decisions from the learning agent. As a result,\nthe learning system can progress at its optimal pace without time restrictions. Additionally,\nthe environment also comes with multiple pre-built scenarios specifically designed to train\nfundamental skills like shooting and navigation. Based on the technical advantages, the\nViZDoom environment provides an ideal experimental platform for our research.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.8**t== 0.2**l== 0.3**r== 0.4**\n3.1.2. Reinforcement Learning with POMDP\n**BLOCK**fs== 10.0**p== 4.0**b== 0.7**t== 0.2**l== 0.3**r== 0.1**\nIn the reinforcement learning framework, the environment and agent continuously\ninteract in order to maximize rewards [38]. The Partially Observable Markov Decision\nProcess (POMDP) provides a formal mathematical model for analyzing and characterizing\nagent–environment interactions, denoted as a five-tuple < S, A, R, P, γ >.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nIn POMDP, we denote st ∈ S as the state space set, where st refers to the state variables\nobtained by the agent from the environment at time slot t. We denote at ∈ A as the\naction space set, where at refers to the specific action taken by the agent to interact with\nthe environment at time slot t. Following the execution of an action, the agent receives\nenvironmental feedback, which is formally designated as the reward signal. We denote R as\nthe reward function, where R(st, at) refers to the immediate feedback received by the agent\nwhen executing action at in state st at time slot t. Thus, we denote P as the state transition\nprobability function, where P(st+1|st, at) characterizes the probability distribution of the\nsystem transitioning from state st to the next state st+1 through action at. Finally, we denote\nγ ∈ [0, 1] as the discount factor, regulating the trade-off between immediate and long-term\nrewards. A larger discount factor γ emphasizes long-term gains, while a smaller discount\nfactor γ focuses more on immediate returns. During the continuous interaction between\nthe agent and environment, the system produces an ordered sequence of state–action pairs,\nwhich forms a temporal transition sequence parameterized by the time slot t. We define\nthe sequence of state–action pairs as trajectory\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.4**r== 0.2**\nτ = {s1, a1, s2, a2, . . . , st, at, st+1, at+1, . . . sT, aT}\n**BLOCK**fs== 10.0**p== 4.0**b== 0.4**t== 0.6**l== 0.3**r== 0.4**\nwhere T is the termination time of the interaction.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nIn this paper, we consider a multi-agent POMDP, where I agents share information and\ncollaborate to achieve a common goal. We denote i ∈ I as the set of agents. All agents share\nthe same state space S and discount factor γ. Due to different agents having unique action\nspaces, we redefine the action space A in multi-agent POMDP as a composite action space.\nt ∈ Ai ∈ A as the action taken by the agent i to interact with the environment\nWe denote ai\nat time t; thus, the action space for the whole system satisfies at = {ai=1\nt } at time t.\nUltimately, the agent i updates its policy πi according to different reward functions.\n**BLOCK**fs== 10.0**p== 4.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nAs shown in Figure 1, the environment interaction of the multi-agent system follows\nthe process below: Based on the environment state st, each agent i independently selects\naction ai\nt, and the individual decisions collectively form the system’s joint action. After the\nagents execute the joint action at and interact with the environment, the state transitions\nfrom state st to state st+1 and receives a reward rt. Based on the next state st+1 and reward\nrt, the system continues making decisions, and the cycle ultimately generates a complete\ninteraction trajectory τ in Equation (1).\n**BLOCK**fs== 9.0**p== 5.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nFigure 1. Agent–environment interaction in DRL for ViZDoom. The figure illustrates the interaction\nmechanism between multi-agent systems and the environment. Based on the current state, the system\ngenerates agent actions, and subsequently influences the environment through executing the joint\naction. The environment accordingly transitions to a new state and generates corresponding rewards,\nthereby constructing a complete feedback control loop. The environment section in the figure shows\na game scene from the training environment.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\n3.2. Multi-Agent POMDP Formulation\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nIn the multi-agent POMDP, the agent i first observes the state st in the ViZDoom\nenvironment, then selects corresponding actions ai=1\nfrom the action spaces\nAi=1 and Ai=2, respectively. The system then executes the combined joint action at in the\nViZDoom environment. Following execution, the system receives both the next state st+1\nand reward rt+1 from the environment interaction before proceeding to the next decision\ncycle. Since the ViZDoom simulator updates all agent-observable information in real-time,\nthe next state space st+1 is independent of previous states st and actions at, satisfying the\nMDP property. The POMDP formulation is as follows.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.4**t== 0.6**l== 0.3**r== 0.1**\nWe adopt the ViZDoom Basic environment as the experimental platform. The system\nis configured with a dual-agent architecture, i.e., I = 2. Both agents share the same state\nobservation information, satisfying\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nThe state space is composed of game images directly obtained by the multi-agent\nsystem, which is a discrete state space. The state space consists of a series of post-interaction\nimages obtained directly from the ViZDoom environment, which is a discrete state space\ncontaining key decision-making information, such as player weapon orientation, enemy\npositions, ammunition levels, terrain features, and player health status.\n**BLOCK**fs== 10.0**p== 5.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\n3.2.2. Action\n**BLOCK**fs== 10.0**p== 5.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nTo align with the ViZDoom environment, we define four basic operations for the\nagents, i.e., stay still, move left, move right, and fire. We construct a multi-agent system\ncomposed of two agents with differentiated action spaces to control the player unit in the\nenvironment. For the agents i, we establish a clear division of action spaces, denoted as\n**BLOCK**fs== 7.6**p== 5.0**b== 0.1**t== 0.9**l== 0.5**r== 0.3**\nai=1\nt ∈ Ai=1 = {astay, ale f t, aright}\nt ∈ Ai=2 = {ahold, ashoot}\nai=2\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nwhere the agent i = 1 is responsible for controlling the player’s position movement, and\nits action space contains three actions: astay represents the agent maintaining a station-\nary position without movement, ale f t represents the agent moving to the left, and aright\nrepresents the agent moving to the right. The second agent is specifically responsible for\nshooting decisions, with its action space containing two actions: ahold represents the agent\nholding a weapon without firing, and ashoot represents the agent holding a weapon and\nfiring. Through the collaborative mechanism, the multi-agent system achieves complete\ncontrol over player behavior and interacts with the environment.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.8**t== 0.2**l== 0.3**r== 0.6**\n3.2.3. Reward\n**BLOCK**fs== 10.0**p== 6.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nThe reward function settings adopted in our research represent the measurement\nof the multi-agent system’s actual performance in the game. To achieve differentiated\nbehavior guidance, we establish different evaluation criteria for each agent in the system,\nas follows:\n**BLOCK**fs== 7.6**p== 6.0**b== 0.7**t== 0.3**l== 0.5**r== 0.3**\nri=1\nt = rmove + rhit\nri=2\nt = rshoot + rhit\n**BLOCK**fs== 10.0**p== 6.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nThe reward function adopted in this paper represents the measurement of the multi-\nagent system’s actual performance in the game. When the system successfully hits the\ntarget, it receives a positive reward rhit. Meanwhile, we introduce rmove and rshoot as\nbehavioral penalty factors, corresponding to the costs of movement and shooting actions.\nThese two penalties are designed to optimize the system’s behavioral strategy, encouraging\nagents to adopt more strategic movement patterns with the aim of achieving more efficient\nshooting performance under limited ammunition conditions.\n**BLOCK**fs== 12.0**p== 6.0**b== 0.5**t== 0.5**l== 0.3**r== 0.5**\n4. Proposed Algorithm\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nThe core scheme adopted in this paper is the Proximal Policy Optimization (PPO)\nalgorithm. In this section, we first extend the PPO algorithm to a multi-agent architecture.\nThen, we present a comprehensive analysis of the optimization mechanisms underlying\nthese algorithm variants, along with a detailed examination of their respective network\narchitectures.\n**BLOCK**fs== 10.0**p== 6.0**b== 0.4**t== 0.6**l== 0.3**r== 0.5**\n4.1. Proximal Policy Optimization\n**BLOCK**fs== 10.0**p== 6.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nAs an advanced method in DRL, PPO achieves high training efficiency while main-\ntaining learning stability, making it particularly suitable for agent decision training in\ncomplex environments. PPO is based on an actor–critic architecture design, where the\ncritic network is responsible for evaluating the state value function and plays an evaluative\nrole in the policy optimization process. Within the ViZDoom environment, the agent i\nperceives the state si\nt at the beginning of the time slot t. Subsequently, the agent i engages\nt ∈ Ai.\nwith the environment by selecting and executing the action from a discrete set ai\nThen, the agent i observes an immediate reward ri\nt from the ViZDoom environment before\ntransitioning to the next state si\nt+1. Through agent–environment interactions, we obtain\nthe interaction trajectory τ. We input the state transition and corresponding reward from\nthe trajectory τ into the critic network to calculate the state target value Vtarget:\n**BLOCK**fs== 7.6**p== 6.0**b== 0.2**t== 0.8**l== 0.5**r== 0.3**\nVtarget = rt + γV · VΘ(st+1)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.9**t== 0.1**l== 0.3**r== 0.1**\nwhere γV is the discount factor for value function and Θ represents the weight of the critic\nnetwork. Based on the critic network’s estimated value for the current state and the target\nvalue Vtarget, we construct the following loss function:\n**BLOCK**fs== 7.6**p== 7.0**b== 0.8**t== 0.2**l== 0.5**r== 0.4**\nLVF(Θ) = ˆEt\n**BLOCK**fs== 7.6**p== 7.0**b== 0.8**t== 0.1**l== 0.6**r== 0.3**\nVΘ(st) − Vtarget\n**BLOCK**fs== 10.0**p== 7.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nBy applying the Adam optimizer, we minimize the loss function LVF(Θ) to update the\nweight of the critic network Θ. The loss function LVF(Θ) serves to minimize the disparity\nbetween the estimated value of critic model and the target value, thereby enhancing the\nmodel’s capacity to accurately assess the quality of the current state.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.7**t== 0.3**l== 0.3**r== 0.1**\nIn terms of the actor network, its main responsibility is to generate action decisions.\nTo optimize the actor network, we first need to use the Generalized Advantage Estimator\n(GAE) method to calculate the advantage estimate value ˆAt:\n**BLOCK**fs== 10.4**p== 7.0**b== 0.7**t== 0.3**l== 0.4**r== 0.2**\nˆAt = δt + (γA · λ)δt+1 + · · · + (γA · λ)T−t+1δT−1\n**BLOCK**fs== 10.0**p== 7.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nwhere δt = rt + γA · VΘ(st+1) − VΘ(st). During the estimation process, the state values\nVΘ(st+1) and VΘ(s) are provided by the critic network, γA is the discount coefficient for\nthe advantage function, and λ is used to balance bias and variance.\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nWe denote the weights of the actor network as θ, and the network weights before\nupdating as θold. To prevent drastic gradient fluctuations during parameter updates, the\nPPO algorithm employs a clipping mechanism to constrain the difference between new\nand old policies πθ and πθold. Let πθ(at | st) denote the probability of policy πθ selecting\naction at under state st, and define the probability ratio between new and old policies as\npt(θ) = πθ (at|st)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.4**r== 0.1**\n(at|st) . Therefore, we adopt the following loss function for the PPO scheme:\n**BLOCK**fs== 7.6**p== 7.0**b== 0.5**t== 0.5**l== 0.5**r== 0.4**\nLclip (θ) = ˆEt\n**BLOCK**fs== 10.0**p== 7.0**b== 0.5**t== 0.5**l== 0.6**r== 0.3**\npt(θ) ˆAt, pclip (θ) ˆAt\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.5**l== 0.3**r== 0.4**\nwhere the clip function pclip (θ) is denoted as\n**BLOCK**fs== 7.6**p== 7.0**b== 0.4**t== 0.6**l== 0.4**r== 0.5**\npclip (θ) =\n**BLOCK**fs== 10.0**p== 7.0**b== 0.4**t== 0.6**l== 0.5**r== 0.2**\n1 − ϵ, if pt(θ) < 1 − ϵ\npt(θ), if 1 − ϵ < pt(θ) < 1 + ϵ\n1 + ϵ, if 1 + ϵ < pt(θ)\n**BLOCK**fs== 10.0**p== 7.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nFigure 2 shows how the loss function Lclip (θ) varies with the probability ratio pt under\ndifferent advantage functions. The loss function Lclip (θ) aims to provide the actor model\nwith insights regarding policy advantages while limiting the magnitude of single updates\nto ensure controlled optimization. Here, ϵ is a hyper-parameter used to limit the clipping\nrange. Finally, we update the weight of the actor network θ, utilizing the Adam optimizer\nbased on the loss function Lclip (θ).\n**BLOCK**fs== 9.0**p== 7.0**b== 0.1**t== 0.9**l== 0.3**r== 0.6**\nFigure 2. Cont.\n**BLOCK**fs== 9.0**p== 8.0**b== 0.6**t== 0.2**l== 0.3**r== 0.1**\nFigure 2. Graph of the loss function Lclip (θ) varying with ratio pt(θ) under different advantage\nfunctions A. The graphical analysis shows the relationship changes between the loss function Lclip (θ)\nand ratio pt(θ) under two scenarios, where the advantage function A is positive and negative.\nWhen advantage function A is positive, the loss function Lclip (θ) is also positive, showing a linear\ngrowth trend in the interval pt(θ)∈[0,1 + ϵ], while maintaining a horizontal trend in the interval\npt(θ)∈[1 + ϵ,+∞]. Conversely, when advantage function A is negative, the loss function Lclip (θ)\nis negative, maintaining a horizontal trend in the interval pt(θ)∈[0,1 − ϵ], while exhibiting a linear\ndecreasing trend in the interval pt(θ)∈[1 − ϵ,+∞].\n**BLOCK**fs== 10.0**p== 8.0**b== 0.6**t== 0.4**l== 0.3**r== 0.4**\n4.2. Multi-Agent-Based RL Framework for ViZDoom\n**BLOCK**fs== 10.0**p== 8.0**b== 0.5**t== 0.4**l== 0.3**r== 0.1**\nWe systematically preprocess the game screen output from the ViZDoom environment\nto optimize the model input. Specifically, the ViZDoom simulator outputs a three-channel\ncolor image with a resolution of 240 × 320. After selective cropping and gray scale con-\nversion, the image is resized to a single-channel feature of 84 × 84. To enhance temporal\ninformation expression, we concatenate four frames of images together, ultimately forming\na state input with four channels of 84 × 84 features. The preprocessing scheme effec-\ntively preserves the dynamic characteristics of the environment while providing sufficient\ncontextual information for the agent.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nIt is worth noting that only one frame of the image is available in the game’s initial\nstate. Therefore, when processing the initial state, we replicate the first frame four times\nand concatenate them to construct the initial state s0. It not only ensures the uniformity\nof input dimensions but also provides a stable and coherent learning foundation for the\nmodel. Through the above standardized processing, we achieve continuous and consistent\nstate representations from the beginning to the end of the game, and provide the agent\nwith a stable learning starting point.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nIn the actor network architecture responsible for shooting control, we use the prepro-\ncessed game information as the model input. Then, it goes through multiple convolutional\nnetwork processing: in the first convolutional layer, a 5 × 5 kernel operates with a stride\nof 2, followed by a ReLU activation function; in the second convolutional layer, a 4 × 4\nkernel operates with a stride of 2, followed by a ReLU activation function; in the third\nconvolutional layer, a 3 × 3 kernel operates with a stride of 2, followed by a ReLU activation\nfunction; and in the fourth convolutional layer, a 3 × 3 kernel operates with a stride of 2,\nproducing output dimensions of (batch size, 32, 9, 9). Subsequently, the output is flattened\nthrough a flatten layer, and then passes through three fully connected layers, i.e., outputting\n512, 64, and 2 units, respectively. Each is followed by a ReLU activation function. Finally, a\nsoftmax layer generates an action probability distribution to determine whether to fire.\n**BLOCK**fs== 10.0**p== 8.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nThe actor network architecture for movement control is essentially identical to the\nshooting model, with only the output dimension in the final layer changed to 3, used to\ncontrol left movement, right movement, or staying still. The two agents share the same critic\nnetwork structure. It maintains the same input processing method and convolutional layer\nconfiguration, and through a similar network architecture, ultimately outputs a single state\nvalue estimate. Specifically, the critic network’s input will go through four convolutional\n**BLOCK**fs== 10.0**p== 9.0**b== 0.9**t== 0.1**l== 0.3**r== 0.1**\nlayers. After flattening, it passes through fully connected layers with dimensions of 512, 64,\nand 1, each followed by a ReLU activation function, ultimately outputting the state value\nassessment. The specific process is shown in Figure 3.\n**BLOCK**fs== 9.0**p== 9.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nFigure 3. The MA-PPO algorithm network architecture diagram. The diagram elaborates on the\nnetwork architecture of the MA-PPO algorithm in the study, which primarily consists of a critic\nnetwork and an actor network. Both networks employ a combined structure of convolutional layers\nand fully connected layers. The critic network outputs a value evaluation metric to quantify the utility\nof the current state. The actor network generates a probability distribution over possible actions in\nthe model’s action space, providing a decision-making basis for the system. These two networks\ncontinuously adjust policy parameters and value estimates through a collaborative optimization\nmechanism, thereby continuously improving algorithm performance.\n**BLOCK**fs== 10.0**p== 9.0**b== 0.1**t== 0.6**l== 0.3**r== 0.1**\nAccording to the MA-PPO training process in Algorithm 1, we extend the original\nPPO algorithm to implement a dual-agent collaborative control system. Compared to the\nPPO pseudocode table Algorithm A1, we design the simultaneous training and updating of\nmultiple agents in the MA-PPO training process. Two independently trained agents jointly\ncontrol a game character, with their policy updates occurring relatively independently.\nThe algorithm accepts several input variables, i.e., the maximum number of epochs η,\nmaximum number of steps ξ, maximum number of training repetitions υ, and environment\nstate st, and then outputs the control strategy. During practical application, the agent\naccepts the same inputs to generate joint actions at as output. The training procedure\nfollows the process below as follows. After initializing the system parameters and model\narchitecture for the two agents in the system, a training loop is entered into, consisting of\nη epochs, with each epoch containing ξ training steps. During the training process, the\nagent first interacts with the environment until the end of a game round, then the system\nrecords the interaction trajectory τ and updates the counter, followed by υ iterations of\noptimization on the collected data for both agents. During the optimization phase, the\nsystem first calculates the state target value Vtarget based on trajectory τ, constructs the critic\nnetwork’s loss function LVF(Θ), and updates the relevant parameters through the Adam\noptimizer. Next, the system evaluates the advantage function ˆAt based on trajectory τ,\nwhich is used to construct the actor network’s loss function Lclip (θ), and similarly employs\nthe Adam optimizer for parameter updates. Finally, the control strategy π is formed. These\nsteps collectively form the core optimization mechanism of the MA-PPO algorithm.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.9**t== 0.1**l== 0.3**r== 0.3**\nAlgorithm 1 Multi-Agent Proximal Policy Optimization.\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.3**r== 0.4**\nInput: state from environment st, η, ξ, υ;\nOutput: control strategy;\n1: for agent i = 1, 2 do\n2:\n3:\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.1**l== 0.3**r== 0.3**\ninitialize critic parameters Θ and actor parameters θ\ninitialize the learning rate βlr and optimizer\n**BLOCK**fs== 10.0**p== 10.0**b== 0.8**t== 0.2**l== 0.3**r== 0.5**\n4: EndFor\n5: for epoch k = 1, 2, · · · , η do\nfor step t = 1, 2, · · · , ξ do\n6:\n7:\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.2**l== 0.4**r== 0.3**\nplay the game under parameters Θ and θ\nfor game is not over do\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.4**r== 0.3**\nthe agent obtains environment information\nthe agent executes actions\n**BLOCK**fs== 10.0**p== 10.0**b== 0.7**t== 0.3**l== 0.4**r== 0.5**\nEndFor\ngain the trajectory τ\nrecord the game steps\nfor agent i = 1, 2 do\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.3**l== 0.4**r== 0.3**\nfor repeat training times j = 1, 2, · · · , υ do\n**BLOCK**fs== 10.0**p== 10.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\ncompute Vtarget according to Equation (5)\ncompute LVF(Θ) according to Equation (6)\nupdate parameters of critic network Θ\ncompute ˆAt according to Equation (7)\ncompute Lclip (θ) according to Equation (8)\nupdate parameters of actor network θ\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.4**l== 0.4**r== 0.6**\nEndFor\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.4**r== 0.6**\nEndFor\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.6**\nEndFor\n**BLOCK**fs== 10.0**p== 10.0**b== 0.5**t== 0.5**l== 0.3**r== 0.3**\n24:\n25: EndFor\n26: form a control strategy π for the whole system\n**BLOCK**fs== 12.0**p== 10.0**b== 0.4**t== 0.5**l== 0.3**r== 0.5**\n5. Results and Analysis\n5.1. Experiment Setup\n**BLOCK**fs== 10.0**p== 10.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nTo assess the efficacy of our multi-agent deep reinforcement learning framework in\nfirst-person shooting scenarios, we conduct comprehensive experiments utilizing the open-\nsource platform, VizDoom. The simulation is conducted on a workstation with an Intel\nCore i7-9700K processor which is manufactured by Intel Corporation in Santa Clara, CA,\nUSA. The operation system is Ubuntu 20.04.6 LTS (Focal Fossa). The code is written in\nPython 3.6.0 using Pytorch 1.6.1 and ViZDoom 1.2.4. The parameters are listed in Table 2.\nThe learning rate βlr gradually decreases from 1 × 10−5 to 1 × 10−7. The discount factors\nγA and γV are both 0.98 according to Section 5.3.2. Bias λ is multiplied with discount factor\nγA when calculating the advantage function. Following the recommendation in the PPO,\nwe set the range of clip operation ϵ = 0.2. For the training iteration variables η, ξ, and υ, we\nselect values that enable algorithm convergence during the actual training process.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.4**\nTable 2. Parameters of the MA-PPO training settings.\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.3**r== 0.6**\nParameter\n**BLOCK**fs== 9.0**p== 10.0**b== 0.2**t== 0.8**l== 0.5**r== 0.4**\nDescription\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.3**r== 0.7**\nβlr\nγV\nγA\nλ\nϵ\nη\nξ\nυ\n**BLOCK**fs== 9.0**p== 10.0**b== 0.1**t== 0.8**l== 0.4**r== 0.3**\nLearning rate\nDiscount factor for calculating target value\nDiscount factor for calculating advantage function\nBias between 0 and 1\nRange of clip operation\nTraining epoch\nTraining step\nrepeat training times\n**BLOCK**fs== 10.0**p== 11.0**b== 0.9**t== 0.1**l== 0.3**r== 0.5**\n5.2. Performance Evaluation\n5.2.1. Baseline\n**BLOCK**fs== 10.0**p== 11.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nWe employ five baseline algorithms for experimental evaluation and comparative\nanalysis, i.e., PPO, MA-PPO, A2C, MA-A2C, and DQN. The following will elaborate on the\ncharacteristics and implementation methods of each algorithm.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.6**t== 0.2**l== 0.3**r== 0.1**\nProximal Policy Optimization (PPO) [39]: PPO was proposed by Schulman et al. in\n2017, and is an advanced reinforcement learning method. PPO adopts an actor–critic archi-\ntecture, which can be applied to both discrete and continuous action spaces, demonstrating\nstrong versatility in reinforcement learning problems. The most distinctive feature of PPO\nlies in the clip operations, which limits the magnitude of single policy updates, greatly\nenhancing its stability. Therefore, we develop MA-PPO, extending the PPO algorithm\nfor application within a multi-agent system framework. Compared to the original PPO\nalgorithm, we change the task allocation structure and design two agents responsible for\nmovement and shooting, respectively. The two agents are both updated according to the\nPPO algorithm and jointly control the player’s behavior. The specific algorithm details are\nelaborated on in Section 4.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nAdvantage Actor–Critic (A2C) [9]: The A2C algorithm is an efficient policy optimiza-\ntion method, which employs an actor–critic architecture. The algorithm integrates policy\ngradient methods with value function estimation, and introduces advantage functions to\noptimize the training process. The actor network is responsible for action decision-making\nand updates based on the advantage function, while the critic network evaluates action\nvalues and optimizes parameters in a manner similar to PPO. Correspondingly, MA-A2C is\nour improved version of the A2C algorithm after adapting it to a multi-agent framework.\nDeep Q-Network (DQN) [40]: DQN is a deep reinforcement learning algorithm devel-\noped by the DeepMind team in 2013. DQN approximates the Q-value function through\ndeep neural networks to handle complex high-dimensional input data. DQN introduces an\nexperience replay mechanism, storing the agent’s interactions with the environment in a\nreplay buffer, and conducts training through random sampling, effectively reducing data\ncorrelation and significantly improving training efficiency and stability.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\n5.2.2. Convergence\n**BLOCK**fs== 10.0**p== 11.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nWe evaluate the convergence performance of the proposed multi-agent architecture\nthrough a training period of 1000 epochs. We conduct systematic comparative analysis\nwith PPO, MA-PPO, A2C, MA-A2C, and DQN to validate the performance advantages of\nour architecture.\n**BLOCK**fs== 10.0**p== 11.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nIn the analysis of Figure 4a, the results show that MA-A2C demonstrates optimal per-\nformance during the convergence phase, followed by DQN and A2C. DQN demonstrates\nsignificant rapid convergence characteristics, reaching a stable state at around 50 epochs.\nThe efficient convergence performance can be attributed to its streamlined algorithm struc-\nture and lower parameter complexity. A2C converges and maintains stability around epoch\n80. The MA-A2C learning curve exhibits unique dynamic characteristics. The conver-\ngence curve exhibits a significant drop at epoch 86, i.e., reward value −313, followed by\na strong recovery. MA-A2C surpasses the performance levels of A2C at epoch 130 and\nDQN at epoch 140, before achieving stable convergence at epoch 150. The performance\ncurve characteristics reflect the collaborative learning challenges of the multi-agent system\nin the initial phase and the effective cooperation mechanism subsequently established\nthrough continuous environmental interaction. The results in Figure 4b show that MA-\nPPO consistently maintains a leading advantage, while PPO performs better than DQN\nafter convergence. Specifically, PPO achieves initial convergence at epoch 30, followed by\n**BLOCK**fs== 10.0**p== 12.0**b== 0.7**t== 0.1**l== 0.3**r== 0.1**\na continuous optimization trend, surpassing DQN in overall performance at epoch 250.\nMA-PPO reaches convergence at epoch 50, demonstrating excellent performance stability.\nThe comprehensive evaluation results in Figure 4c indicate that MA-PPO demonstrate\nfar superior convergence compared to the other four baselines, i.e., PPO, MA-A2C, DQN,\nand A2C. After convergence, the rewards for MA-PPO, PPO, MA-A2C, and DQN are\n75, 52, 51, and 31, respectively. Quantitative analysis shows that MA-PPO achieves test\nperformance improvements of 30.67%, 32.00%, and 58.67% compared to PPO, MA-A2C,\nand DQN, respectively. Meanwhile, compared to their original versions, both the MA-PPO\nalgorithm versus the PPO algorithm, and the MA-A2C algorithm versus the A2C algorithm\nshow highly significant improvements in reward data from the experiments. Therefore, the\nexperimental data confirm that the algorithm variants based on the multi-agent architecture,\ni.e., MA-PPO and MA-A2C, achieve significant performance improvements compared\nto their original versions, fully validating the effectiveness of the proposed multi-agent\narchitecture in optimizing reinforcement learning performance.\n**BLOCK**fs== 9.0**p== 12.0**b== 0.1**t== 0.8**l== 0.3**r== 0.6**\nFigure 4. Cont.\n**BLOCK**fs== 9.0**p== 13.0**b== 0.6**t== 0.3**l== 0.3**r== 0.1**\nFigure 4. Evaluation for the baselines in the ViZDoom environment. (a) Comparison of average\nreward using MA-A2C, A2C, and DQN during the training process. (b) Comparison of average\nreward using MA-PPO, PPO, and DQN during the training process. (c) Comparison results with the\nproposed algorithm vs. baselines on average reward. The legend is the same as in (a,b).\n**BLOCK**fs== 10.0**p== 13.0**b== 0.6**t== 0.4**l== 0.3**r== 0.5**\n5.3. Performance Comparison\n5.3.1. Rendering\n**BLOCK**fs== 10.0**p== 13.0**b== 0.4**t== 0.4**l== 0.3**r== 0.1**\nFigure 5 shows the results of our visualization-based comparative analysis of the five\nbaselines’ performance in the game environment. As shown in Table 3, the multi-agent\narchitecture MA-PPO demonstrates optimal performance, efficiently completing the task\nwith a reward of 76, 20 action steps, and 48 remaining ammunition. The PPO algorithm is\nranked second, achieving a reward of 56, 35 action steps, and 47 remaining ammunition.\nMA-A2C achieves a reward of 47, takes 44 steps, and maintains 47 remaining ammunition.\nDQN achieves a reward of 36, took 55 steps, and has 47 ammunition remaining. The\nA2C algorithm shows relatively weak performance, obtaining a reward of −109, taking\n165 steps, and having 40 ammunition remaining.\n**BLOCK**fs== 10.0**p== 13.0**b== 0.1**t== 0.6**l== 0.3**r== 0.1**\nThen, we conduct a detailed analysis of the visualization-based results from the\nperspective of each agent’s actions. MA-PPO executes shooting actions at steps 7 and 20,\nsuccessfully hitting the enemy at step 20, while rapidly approaching the target during the\nintermediate phases. PPO executes shooting actions at steps 12, 25, and 35, successfully\nhitting the enemy at step 35, while slowly approaching the target during the intermediate\nphases. MA-A2C executes shooting actions at steps 10, 21, and 44, successfully hitting the\nenemy at step 44, with a brief stationary period between steps 27 and 32, while slowly\napproaching the target during the intermediate phases. DQN executes shooting actions at\nsteps 20, 37, and 55, successfully hitting the enemy at step 55, with a brief stationary period\nbetween steps 25 and 35, while slowly approaching the target during the intermediate\nphases. A2C executed a total of 10 shots, hitting the enemy at step 165, with the intermediate\nphases involving frequent lateral oscillations and stationary periods. The experimental\ndata clearly demonstrate that algorithm variants based on multi-agent architecture, i.e.,\nMA-PPO and MA-A2C, outperform their corresponding baselines across all performance\nmetrics, with particularly notable improvements in the case of the A2C algorithm. The\nempirical results strongly confirm that the proposed multi-agent system has significant\nadvantages in improving agent game performance.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nFigure 5. The visualized results of MA-PPO with other baselines. The figure shows the actual\nperformance of each baseline model after completing training, visualized through frame-by-frame\nrendering for comparison. The model’s task completion efficiency is reflected through a combination\nof minimized step count and maximized reward value. The figure shows, from top to bottom, the\nactual running results of the MA-PPO, PPO, MA-A2C, DQN, and A2C.\n**BLOCK**fs== 9.0**p== 14.0**b== 0.4**t== 0.6**l== 0.3**r== 0.3**\nTable 3. ViZDoom testing results for MA-PPO and other baselines.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.6**l== 0.3**r== 0.6**\nScheme\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.6**l== 0.4**r== 0.4**\nAverage Reward ↑\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.6**l== 0.6**r== 0.3**\nAverage Step ↓\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.6**l== 0.7**r== 0.1**\nAmmunition (AMMO) ↑\n**BLOCK**fs== 10.0**p== 14.0**b== 0.3**t== 0.7**l== 0.3**r== 0.6**\nPPO\nA2C\nDQN\nMA-A2C\nMA-PPO (Ours)\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\n5.3.2. Parameter Experiments\n**BLOCK**fs== 10.0**p== 14.0**b== 0.2**t== 0.8**l== 0.3**r== 0.1**\nWe conduct systematic parameter experiments on the discount factors γA, γV for\nestimating target value Vtarget and advantage function ˆAt to evaluate how their different\ncombinations affect model training. Through the analysis of 1000 training epochs, we\nobtain the following key findings.\n**BLOCK**fs== 10.0**p== 14.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nFigure 6a shows the impact of different γA values (0.98, 0.95, 0.90, and 0.85) on model\nconvergence when γV is fixed at 0.98. The experimental results show that when γA = 0.98,\nit not only demonstrates optimal training stability but also achieves the highest reward\nvalue. The data show that as the γA value approaches 1, the model performance becomes\nmore superior.\n**BLOCK**fs== 9.0**p== 15.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nFigure 6. Comparison of model training effects under different (γA,γV) combinations. In the picture,\na refers to γA, and v refers to γV. (a) Comparison of convergence curves with varying γA under the\ncondition of γV = 0.98. (b) Comparison of convergence curves with varying γV under the condition of\nγA = 0.98. (c) Heatmap comparison of final training effects under different (γA and γV) combinations.\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nFigure 6b shows the experimental results with different γV values (0.98, 0.95, 0.90, and\n0.85) when γA is fixed at 0.98. The study finds that changes in γV can lead to significant\nfluctuations in the model training process, but as the γV value approaches 1, the model\ntraining becomes more stable and can achieve higher reward levels.\n**BLOCK**fs== 10.0**p== 16.0**b== 0.8**t== 0.2**l== 0.3**r== 0.1**\nFigure 6c visualizes the effects of 16 combinations of γA and γV through a heatmap,\nwhere darker regions represent superior model performance. The experimental results\nclearly demonstrate that the parameter combination of γA = 0.98 and γV = 0.98 produces\nthe best performance, indicating that the combination achieves an ideal balance between\nbias and variance in reward function estimation. Above all, we accordingly determine the\nfinal parameter configuration.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.7**t== 0.3**l== 0.3**r== 0.6**\n6. Conclusions\n**BLOCK**fs== 10.0**p== 16.0**b== 0.5**t== 0.3**l== 0.3**r== 0.1**\nIn this paper, we propose a multi-agent reinforcement learning framework called\nMA-PPO that achieves predetermined objectives through continuous interaction with the\nViZDoom environment under specific constraints. Specifically, the primary objective is to\nachieve target acquisition with optimal efficiency while adhering to specified ammunition\nand time limitations. Comprehensive performance evaluation shows that the improved\nMA-PPO algorithm achieves a 30.67% improvement in convergence performance compared\nto the baseline algorithm. Through systematic parameter experiments, we validate the\nscientific basis and effectiveness of our chosen discount factor parameters. Through a series\nof simulation experiments, it is demonstrated that the proposed multi-agent architecture\nhas good generality and can be integrated with various actor–critic frameworks to enhance\noverall performance.\n**BLOCK**fs== 10.0**p== 16.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nFuture work will be expanded in the following direction. For practice, we will explore\nthe potential applications of multi-agent reinforcement learning algorithms in broader\nand more complex game environments to validate their generality and practical appli-\ncation value. We plan to conduct in-depth research on optimizing the decision-making\nmechanisms and develop algorithm architectures that better adapt to diverse gaming\nenvironments. Furthermore, we will focus on resource efficiency issues in multi-agent\nsystems, emphasizing research on the optimal balance point between agent scale expansion\nand computational resource consumption, aiming to achieve an ideal trade-off between\nperformance improvement and computational efficiency.\n**BLOCK**fs== 9.0**p== 16.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nAuthor Contributions: Conceptualization, H.Z. and S.J.; Methodology, Z.C. and H.Z.; Software, Z.C.;\nValidation, Z.C.; Formal analysis, Z.Z.; Writing—original draft, Z.C. and H.Z.; Writing—review &\nediting, K.D., H.Z., Z.Z. and S.J.; Supervision, K.D. All authors have read and agreed to the published\nversion of the manuscript.\n**BLOCK**fs== 9.0**p== 16.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nFunding: This work was supported in part by the NSFC Programs under Grant 62403121.\n**BLOCK**fs== 9.0**p== 16.0**b== 0.2**t== 0.7**l== 0.3**r== 0.1**\nData Availability Statement: The original contributions presented in the study are included in\nthe article, further inquiries can be directed to the corresponding author. Project page at https:\n//lintian106.github.io/MAppo2VizDoom (accessed on 23 February 2025).\n**BLOCK**fs== 9.0**p== 16.0**b== 0.2**t== 0.8**l== 0.3**r== 0.3**\nConflicts of Interest: The authors declare no conflicts of interest.\n**BLOCK**fs== 12.0**p== 16.0**b== 0.2**t== 0.8**l== 0.3**r== 0.5**\nAppendix A. PPO Algorithm\n**BLOCK**fs== 10.0**p== 16.0**b== 0.1**t== 0.8**l== 0.3**r== 0.1**\nBased on the PPO algorithm’s training process shown in Algorithm A1, the algorithm\naccepts several input variables, i.e., the maximum number of epochs η, maximum number\nof steps ξ, maximum number of training repetitions υ, environment state st, and then\noutputs both the trained critic and actor networks. During practical application, the agent\naccepts the same inputs to generate agent actions at as output. The training procedure\nfollows the process below as follows. After initializing the system parameters and model\n**BLOCK**fs== 10.0**p== 17.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\narchitecture, we enter a training loop consisting of η epochs, with each epoch containing ξ\ntraining steps. During the training process, the agent first interacts with the environment\nuntil the end of a game round, then the system records the interaction trajectory τ and\nupdates the counter, followed by υ iterations of optimization on the collected data. During\nthe optimization phase, the system first calculates the state target value Vtarget based on\ntrajectory τ, constructs the critic network’s loss function LVF(Θ), and updates the relevant\nparameters through the Adam optimizer. Next, the system evaluates the advantage function\nˆAt based on trajectory τ, which is used to construct the actor network’s loss function Lclip (θ),\nand similarly employs the Adam optimizer for parameter updates. These steps collectively\nform the core optimization mechanism of the PPO algorithm.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.7**t== 0.3**l== 0.3**r== 0.4**\nAlgorithm A1 Proximal Policy Optimization.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.3**l== 0.3**r== 0.3**\nInput: state from environment st, η, ξ, υ;\nOutput: actor network, critic network;\n1: initialize critic parameters Θ and actor parameters θ\n2: initialize the learning rate βlr and optimizer\n3: for epoch k = 1, 2, · · · , η do\nfor step t = 1, 2, · · · , ξ do\n4:\n5:\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\nplay the game under parameters Θ and θ\nfor game is not over do\n**BLOCK**fs== 10.0**p== 17.0**b== 0.6**t== 0.4**l== 0.4**r== 0.3**\nthe agent obtains environment information\nthe agent executes actions\n**BLOCK**fs== 10.0**p== 17.0**b== 0.5**t== 0.4**l== 0.4**r== 0.3**\nEndFor\ngain the trajectory τ\nrecord the game steps\nfor repeat training times j = 1, 2, · · · , υ do\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.5**l== 0.4**r== 0.3**\ncompute Vtarget according to Equation (5)\ncompute LVF(Θ) according to Equation (6)\nupdate parameters of critic network Θ\ncompute ˆAt according to Equation (7)\ncompute Lclip (θ) according to Equation (8)\nupdate parameters of actor network θ\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.4**r== 0.6**\nEndFor\n**BLOCK**fs== 10.0**p== 17.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\nEndFor\n**BLOCK**fs== 8.0**p== 17.0**b== 0.4**t== 0.6**l== 0.3**r== 0.6**\n20:\n21: EndFor\n**BLOCK**fs== 12.0**p== 17.0**b== 0.3**t== 0.6**l== 0.3**r== 0.1**\nAppendix B. Performance Comparison with SAC and MADDPG\n**BLOCK**fs== 10.0**p== 17.0**b== 0.3**t== 0.7**l== 0.3**r== 0.1**\nDespite the availability of various established algorithm in the DRL field, i.e.,SAC, and\nmulti-agent frameworks, i.e., MADDPG, our research is focused on developing an enhanced\nmulti-agent architecture leveraging PPO. In the following section, we will examine the SAC\nalgorithm and MADDPG framework as reference points to illustrate the rationality and\ninnovation of the algorithm adopted and proposed in our work.\n**BLOCK**fs== 10.0**p== 17.0**b== 0.1**t== 0.7**l== 0.3**r== 0.1**\nSoft Actor–Critic (SAC) [41], introduced by Haarnoja et al., implements an actor–\ncritic architecture with entropy-based exploration mechanisms, demonstrating exceptional\nperformance across various tasks. However, to address bootstrapping issues, SAC utilizes\na configuration of four critic models and one actor model, whereas PPO, another state-of-\nthe-art DRL method, operates with a single actor–critic model. The implementation of SAC\nin a multi-agent framework would necessitate significantly greater training resources and\nmemory allocation compared to MA-PPO, as the resource requirements would scale with\nthe number of agents,which leads us to adopt the more streamlined PPO algorithm for our\nmulti-agent framework. Performance comparisons with SAC are presented in Figure A1.\nMADDPG [33], introduced by Lowe et al., represents a multi-agent architecture that\ndirectly outputs agent actions rather than probability distributions. MADDPG employs a\n**BLOCK**fs== 10.0**p== 18.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\ncentralized training with a decentralized execution learning framework, allowing models to\naccess global information during training while operating with limited perspective during\nexecution. In contrast, our proposed MA-PPO algorithm employs a task-allocation learning\nframework in the ViZDoom environment, enabling concurrent specialized training for\ndistinct agents on different tasks, which is a more streamlined and efficient approach that\nprovides more possibilities for collaboration and coordination between different agents.\nAs demonstrated in the comparative analysis presented in the appendix, the proposed\nMA-PPO algorithm exhibits superior performance metrics.\n**BLOCK**fs== 9.0**p== 18.0**b== 0.5**t== 0.5**l== 0.3**r== 0.1**\nFigure A1. Comparison of average reward using MA-PPO, MADDPG, PPO, and SAC during the\ntraining process.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nWe evaluate the convergence performance of each baseline through a training period\nof 1000 epochs. We conduct a systematic comparative analysis between MA-PPO and\nMADDPG to validate the performance advantages of our architecture. Meanwhile, we\ncompare PPO with SAC to explain our rationale for choosing PPO as the baseline for\nmulti-agent improvements.\n**BLOCK**fs== 10.0**p== 18.0**b== 0.2**t== 0.6**l== 0.3**r== 0.1**\nIn the analysis shown in Figure A1, the results demonstrate that MA-PPO exhibits the\nbest performance during the convergence phase, followed by MADDPG, PPO, and SAC.\nMA-PPO reaches convergence at epoch 50, demonstrating excellent performance stability.\nMADDPG converges at epoch 30, showing similar stability but with lower performance\ncompared to MA-PPO. SAC converges at epoch 60, with slight performance fluctuations\nthroughout the training process. PPO achieves convergence at epoch 30, followed by\na continuous optimization trend, surpassing SAC in overall performance at epoch 800.\nAfter convergence, the rewards for MA-PPO, MADDPG, PPO, and SAC are 75, 60, 52,\nand 50, respectively. Quantitative analysis shows that MA-PPO achieves test performance\nimprovements of 20.00%, 30.67%, and 33.33% compared to MADDPG, PPO, and SAC,\nrespectively. Meanwhile, the performance of PPO is slightly higher than that of SAC\nafter convergence. Therefore, the experimental data confirm that the proposed MA-PPO\ndemonstrates performance superiority compared to existing multi-agent algorithms, and\nPPO is a more reasonable baseline choice.\n**BLOCK**fs== 12.0**p== 18.0**b== 0.1**t== 0.8**l== 0.3**r== 0.2**\nAppendix C. Performance Evaluation with Error Bars\n**BLOCK**fs== 10.0**p== 18.0**b== 0.1**t== 0.9**l== 0.3**r== 0.1**\nWe develop the testing procedure according to the VizDoom simulator [37]. We\nsave the converged baselines, and then to control variables, and conduct 100 games in a\nfixed scenario with controlled environmental conditions, i.e., enemy positions and initial\npositions, recording the reward values obtained by the baseline in each game. In Figure A2,\n**BLOCK**fs== 10.0**p== 19.0**b== 0.8**t== 0.1**l== 0.3**r== 0.1**\nthe blue bars indicate the average rewards from the testing procedure, while the black lines\nindicate the standard deviation of the rewards. In the analysis shown in Figure A2, the\nresults show that MA-PPO achieves the highest average reward, followed by MADDPG,\nPPO, MA-A2C, SAC, and DQN, with average reward values of 75.12, 59.60, 52.24, 51.64,\n49.82, and 31.34 respectively, and standard deviation values of 1.85, 1.87, 2.10, 8.59, 5.15, and\n7.78, respectively. Therefore, the algorithm with the highest stability remains the proposed\nMA-PPO, followed by MADDPG, PPO, SAC, DQN, and MA-A2C. Thus, the experimental\ndata confirm that the proposed MA-PPO demonstrates the best performance and stability.\n**BLOCK**fs== 9.0**p== 19.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\nFigure A2. Comparison of baseline performance after convergence with error bars.\n**BLOCK**fs== 12.0**p== 19.0**b== 0.5**t== 0.5**l== 0.3**r== 0.2**\nAppendix D. Parameter Experiments of Learning Rate\n**BLOCK**fs== 10.0**p== 19.0**b== 0.4**t== 0.5**l== 0.3**r== 0.1**\nWe conduct systematic parameter experiments on the learning rate βlr to evaluate\nthe impact of variable and fixed learning rates on model training. Through the analysis\nof 1000 training epochs, we find that variable learning rates can significantly improve\nthe model’s performance. Figure A3 shows the convergence curves of MA-PPO under\nvariable and fixed learning rates. When using variable learning rates, the model converges\nat 100 epochs, demonstrating excellent performance stability and better convergence. When\nusing fixed learning rates, the model converges at epoch 50, with slight fluctuations during\nthe training process. Therefore, the experimental data confirm that variable learning rates\nsignificantly improve the model’s performance and stability.\n**BLOCK**fs== 9.0**p== 19.0**b== 0.1**t== 0.9**l== 0.3**r== 0.2**\nFigure A3. Comparison of model training effects under different learning rates.",
         "Article Deep Reinforcement Learning-Based Multi-Agent System with Advanced Actor–Critic Framework for Complex Environment Zihao Cui 1,2, Kailian Deng 1,2,*, Hongtao Zhang 1,2,†, Zhongyi Zha 1,3 and Sayed Jobaer 1,2 Abstract: The development of artificial intelligence (AI) game agents that use deep rein- forcement learning (DRL) algorithms to process visual information for decision-making has emerged as a key research focus in both academia and industry. However, previous game agents have struggled to execute multiple commands simultaneously in a single decision, failing to accurately replicate the complex control patterns that characterize human game- play. In this paper, we utilize the ViZDoom environment as the DRL research platform and transform the agent–environment interactions into a Partially Observable Markov Decision Process (POMDP). We introduce an advanced multi-agent deep reinforcement learning (DRL) framework, specifically a Multi-Agent Proximal Policy Optimization (MA-PPO), designed to optimize target acquisition while operating within defined ammunition and time constraints. In MA-PPO, each agent handles distinct parallel tasks with custom reward functions for per- formance evaluation. The agents make independent decisions while simultaneously executing multiple commands to mimic human-like gameplay behavior. Our evaluation compares MA-PPO against other DRL algorithms, showing a 30.67% performance improvement over the baseline algorithm. Keywords: deep reinforcement learning; convolution neural network; partially observable Markov decision process; multi-agent system Recent advancements in fundamental physics have been facilitated by the implemen- tation of artificial neural networks and machine learning methodologies [1]. In parallel, AlphaFold, an innovative system integrating deep learning and reinforcement learning methodologies, was honored with the Nobel Prize in Chemistry for its revolutionary ad- vancements in the field of protein structure prediction [2]. The progression from AlphaStar and AlphaGo’s notable successes in gaming to AlphaFold’s groundbreaking applications in biology exemplifies the versatility of deep reinforcement learning (DRL) technology [3]. DRL, which integrates neural networks with reinforcement learning principles, has not only demonstrated remarkable efficacy in gaming scenarios but also continues to significantly advance various domains of scientific research [4,5]. DRL has achieved substantial attention across both industry and academia [6], demon- strating its capability as a model-free methodology for addressing complex decision-making challenges in industrial environments [7]. AlphaGo, an artificial intelligence (AI) system for the ancient game of Go, achieved a historic milestone by defeating human Go champions [8]. The system utilizes a sophisticated dual-phase approach, initially employing supervised learning on human data before transitioning to reinforcement learning through self-play iterations. Leveraging the powerful function approximation capabilities of deep neural net- works, DRL agents demonstrate remarkable proficiency in acquiring knowledge through interactions with unknown, information-limited environments, ultimately leading to robust real-time decision-making processes. Building upon the exceptional adaptability of DRL agents in complex environments, DRL-based algorithms have demonstrated significant value across multiple domains, including intraday scheduling for home energy systems [9], flight trajectory optimization for unmanned aerial vehicles [10], and energy trading between electric vehicles and power grids [11]. The foundation for these achievements stems is built on the extensive testing and validation of DRL frameworks through diverse gaming environments and simulators, establishing it as an advanced and effective paradigm [12,13]. The journey commenced with DeepMind’s groundbreaking implementation of DRL technology in Atari games [14], where artificial intelligence agents demonstrated exceptional capabilities in mastering and subsequently surpassing human performance levels [15]. While AlphaStar showcased unprecedented mastery by outperforming 99.8% of human players in StarCraft through its precise real-time execution, it encountered limitations in certain scenar- ios due to deficiencies in cognitive reasoning and strategic planning capabilities. Currently, OpenAI Gym provides a diverse range of game interfaces for training and evaluating DRL algorithms, i.e., SC2LE [16], ViZDoom [17], and Mujoco [18], establishing a robust founda- tion for developing more sophisticated game AI [19]. Therefore, our research is focused on optimizing the implementation of advanced DRL frameworks within ViZDoom, a simulation environment that incorporates complex multi-dimensional action controls. Moreover, collaborative interaction between multiple agents has been demonstrated to be an effective approach for converging toward near-optimal solutions [20,21]. With the ad- vancement of single-agent DRL implementations, multi-agent DRL has sparked a wave of enthusiasm [22,23]. Multi-agent reinforcement learning enables collaboration by maximiz- ing collective rewards, which expands traditional reinforcement learning from individual problem-solving to cooperative achievement [24]. The methodology has shown remarkable effectiveness in advanced applications including multiplayer games [25], coordinated UAV operations [26], and robot swarm control systems [27]. Since real-world scenarios often involve multiple interacting agents, we incorporate a multi-agent framework into the DRL paradigm to improve agent performance in ViZDoom. In reinforcement learning, developing sophisticated agents capable of replicating human- like behavioral patterns within gaming environments remains a significant challenge. To address this challenge, we introduce MA-PPO, an advanced reinforcement learning algorithm framework specifically designed for complex gaming scenarios. Using the first-person shooter game ViZDoom as our experimental platform, we model environmental interactions as a Partially Observable Markov Decision Process. Our MA-PPO algorithm incorporates an advanced multi-agent architecture that overcomes a key limitation of traditional reinforcement learning: instead of executing only one action per decision, it enables agents to perform multiple commands simultaneously, much like human players. To ensure genuine intelligence rather than scripted behavior, we implement a distributed task allocation mechanism, where agents operate independently on parallel objectives, avoiding control conflicts. Through comprehensive empirical evaluation against other reinforcement learning algorithms, our framework achieves superior performance in the ViZDoom environment. The main contributions of our work are summarized as follows: • We transform the interactions between the ViZDoom environment and agents into a Par- tially Observable Markov Decision Process, and systematically define the corresponding states, actions, and reward functions. The reward functions serve as key indicators for assessing the effectiveness of each agent in executing their designated specialized tasks. • We propose an innovative multi-agent reinforcement learning algorithm framework MA-PPO based on PPO. Our framework utilizes image information as input and outputs joint actions composed of multiple individual actions to interact with the ViZDoom environment, achieving predefined objectives in a manner that better ap- proximates human players. Simulation experiments show that compared to original PPO, MA-PPO achieved a 30.67% reward gain, while compared to three other benchmark algorithms including DQN, MA-PPO achieves at least 32.00% performance improvement. Visual analysis shows that MA-PPO achieves optimal task completion with minimal steps required, and parameter experiment results indicate that all selected parameters are optimal. The reminder of this paper is organized as follows. Section 2 introduces the related work. Section 3 first introduces the ViZDoom simulator and the multi-agent POMDP formulation. Section 4 describes the update process of the proposed MA-PPO algorithm and the network architecture. Section 5 evaluates the performance of the proposed algorithm through simulations and conducts a parameter experiment. Finally Section 6 concludes the paper. The main symbols used in this paper are summarized in Table 1. State transition probability function Discount factor Set of agents, agent number Termination time, time slot Reward function, reward at time slot t Penalty of movement and shooting Reward of hitting the target State space set, state at time slot t Action space set, action made by the agent at time slot t Action space set of agent i Stay still, move to the left or right Hold a weapon without firing, fire Reward,state or action at time slot t of agent i Trajectory Target value Parameter of critic network Value calculated by critic network with Θ Loss function of critic network with Θ Estimated value of advantage function Measurement of the loss estimated by critic network Parameter of actor network Old parameter of actor network before updating Policy of actor network Old policy of actor network before updating Probability of policy πθ taking action at at state st Ratio of πθ to πθold in taking action at at state st Loss function for updating actor network Value of pt(θ) after clip operation In this section, we review the related works, including applications of the actor–critic framework in RL. Although RL has demonstrated remarkable efficacy in practical applications, there remain several critical areas that need further exploration and research. Traditional tabular- based RL methods, i.e., Q-learning and Sarsa, employ a tabular structure to maintain states and actions, facilitating value function retrieval through systematic table consultation. Li et al. introduced Approximate Dynamic Programming (ADP) as an innovative methodol- ogy for optimizing long-term operational costs in microgrid systems [28]. The real-time scheduling problem was modeled as a finite-horizon Markov decision process. Through the implementation of neural networks for power generation forecasting, the ADP approach demonstrated effectiveness when evaluated using authentic power grid data simulations. Anderson et al. conducted research on modeling player interactions in StarCraft through Nash equilibrium theory, with findings indicating that the implementation of minimax-Q algorithms led to enhanced performance for AI agents in StarCraft tournaments [29]. However, value function-based tabular RL algorithms are limited to handling only discrete action and state spaces, and encounter the problem of decision fatigue. As a result, the implementation of the actor–critic framework presents an effective solution to address the operational limitations. Wang et al. implemented an actor–critic network in home energy systems to deal with continuous battery charging and discharging actions [9]. The actor–critic-based RL scheme enhances the economic efficiency of battery scheduling, while maintaining safety constraints throughout daily operations. Zha et al. introduced an actor–critic algorithm named Advanced Actor–Critic (AAC) that trains agents to match human-level skill in the complex strategy game StarCraft II [30]. The AAC-based AI demonstrates rapid convergence despite encountering vast state and action spaces. Although reinforcement learning has advanced significantly across many fields, re- search has primarily focused on single-agent scenarios, even though real-world applications often involve multiple decision-makers working together [31]. Thus, multi-agent rein- forcement learning has emerged as a powerful approach for tackling complex real-world problems [32]. Lowe et al. first introduced the multi-agent actor–critic framework, i.e., multi-agent deep deterministic policy gradient (MADDPG), which handles environmental non-stationarity through a system of multiple trained sub-policies, with random policy selection during each episode [33]. MADDPG, as a versatile multi-agent reinforcement learning framework, has made significant contributions through its centralized training and distributed execution strategy in multi-robot collaborative systems [34], human behavior imitation [35], and Data Center Digital Twins [36]. 3. Modeling in ViZDoom In this section, we introduce the ViZDoom simulator, a gaming platform widely used for training DRL agents. We then present the concept of Partially Observable Markov Decision Process (POMDP) and its extension to a multi-agent framework. Finally, we detail the construction process and theoretical foundations of multi-agent POMDP. ViZDoom is a reinforcement learning research platform built on a popular open-source 3D first-person shooting game, allowing agents to play Doom by interacting with screen buffers and game variables [37]. From a technical performance perspective, the ViZDoom environment demonstrates excellent optimization results. At a resolution of 320 × 240, the environment achieves an average rendering rate of 2500 frames per second. At a lower resolution of 160 × 120, even single-threaded CPUs can achieve up to 7000 frames per second. For reinforcement learning research, the ViZDoom simulator runs in synchronous mode, where the game engine pauses to await decisions from the learning agent. As a result, the learning system can progress at its optimal pace without time restrictions. Additionally, the environment also comes with multiple pre-built scenarios specifically designed to train fundamental skills like shooting and navigation. Based on the technical advantages, the ViZDoom environment provides an ideal experimental platform for our research. 3.1.2. Reinforcement Learning with POMDP In the reinforcement learning framework, the environment and agent continuously interact in order to maximize rewards [38]. The Partially Observable Markov Decision Process (POMDP) provides a formal mathematical model for analyzing and characterizing agent–environment interactions, denoted as a five-tuple < S, A, R, P, γ >. In POMDP, we denote st ∈ S as the state space set, where st refers to the state variables obtained by the agent from the environment at time slot t. We denote at ∈ A as the action space set, where at refers to the specific action taken by the agent to interact with the environment at time slot t. Following the execution of an action, the agent receives environmental feedback, which is formally designated as the reward signal. We denote R as the reward function, where R(st, at) refers to the immediate feedback received by the agent when executing action at in state st at time slot t. Thus, we denote P as the state transition probability function, where P(st+1|st, at) characterizes the probability distribution of the system transitioning from state st to the next state st+1 through action at. Finally, we denote γ ∈ [0, 1] as the discount factor, regulating the trade-off between immediate and long-term rewards. A larger discount factor γ emphasizes long-term gains, while a smaller discount factor γ focuses more on immediate returns. During the continuous interaction between the agent and environment, the system produces an ordered sequence of state–action pairs, which forms a temporal transition sequence parameterized by the time slot t. We define the sequence of state–action pairs as trajectory τ = {s1, a1, s2, a2, . . . , st, at, st+1, at+1, . . . sT, aT} where T is the termination time of the interaction. In this paper, we consider a multi-agent POMDP, where I agents share information and collaborate to achieve a common goal. We denote i ∈ I as the set of agents. All agents share the same state space S and discount factor γ. Due to different agents having unique action spaces, we redefine the action space A in multi-agent POMDP as a composite action space. t ∈ Ai ∈ A as the action taken by the agent i to interact with the environment We denote ai at time t; thus, the action space for the whole system satisfies at = {ai=1 t } at time t. Ultimately, the agent i updates its policy πi according to different reward functions. As shown in Figure 1, the environment interaction of the multi-agent system follows the process below: Based on the environment state st, each agent i independently selects action ai t, and the individual decisions collectively form the system’s joint action. After the agents execute the joint action at and interact with the environment, the state transitions from state st to state st+1 and receives a reward rt. Based on the next state st+1 and reward rt, the system continues making decisions, and the cycle ultimately generates a complete interaction trajectory τ in Equation (1). In the multi-agent POMDP, the agent i first observes the state st in the ViZDoom environment, then selects corresponding actions ai=1 from the action spaces Ai=1 and Ai=2, respectively. The system then executes the combined joint action at in the ViZDoom environment. Following execution, the system receives both the next state st+1 and reward rt+1 from the environment interaction before proceeding to the next decision cycle. Since the ViZDoom simulator updates all agent-observable information in real-time, the next state space st+1 is independent of previous states st and actions at, satisfying the MDP property. The POMDP formulation is as follows. We adopt the ViZDoom Basic environment as the experimental platform. The system is configured with a dual-agent architecture, i.e., I = 2. Both agents share the same state observation information, satisfying The state space is composed of game images directly obtained by the multi-agent system, which is a discrete state space. The state space consists of a series of post-interaction images obtained directly from the ViZDoom environment, which is a discrete state space containing key decision-making information, such as player weapon orientation, enemy positions, ammunition levels, terrain features, and player health status. To align with the ViZDoom environment, we define four basic operations for the agents, i.e., stay still, move left, move right, and fire. We construct a multi-agent system composed of two agents with differentiated action spaces to control the player unit in the environment. For the agents i, we establish a clear division of action spaces, denoted as where the agent i = 1 is responsible for controlling the player’s position movement, and its action space contains three actions: astay represents the agent maintaining a station- ary position without movement, ale f t represents the agent moving to the left, and aright represents the agent moving to the right. The second agent is specifically responsible for shooting decisions, with its action space containing two actions: ahold represents the agent holding a weapon without firing, and ashoot represents the agent holding a weapon and firing. Through the collaborative mechanism, the multi-agent system achieves complete control over player behavior and interacts with the environment. The reward function settings adopted in our research represent the measurement of the multi-agent system’s actual performance in the game. To achieve differentiated behavior guidance, we establish different evaluation criteria for each agent in the system, as follows: The reward function adopted in this paper represents the measurement of the multi- agent system’s actual performance in the game. When the system successfully hits the target, it receives a positive reward rhit. Meanwhile, we introduce rmove and rshoot as behavioral penalty factors, corresponding to the costs of movement and shooting actions. These two penalties are designed to optimize the system’s behavioral strategy, encouraging agents to adopt more strategic movement patterns with the aim of achieving more efficient shooting performance under limited ammunition conditions. The core scheme adopted in this paper is the Proximal Policy Optimization (PPO) algorithm. In this section, we first extend the PPO algorithm to a multi-agent architecture. Then, we present a comprehensive analysis of the optimization mechanisms underlying these algorithm variants, along with a detailed examination of their respective network architectures. As an advanced method in DRL, PPO achieves high training efficiency while main- taining learning stability, making it particularly suitable for agent decision training in complex environments. PPO is based on an actor–critic architecture design, where the critic network is responsible for evaluating the state value function and plays an evaluative role in the policy optimization process. Within the ViZDoom environment, the agent i perceives the state si t at the beginning of the time slot t. Subsequently, the agent i engages t ∈ Ai. with the environment by selecting and executing the action from a discrete set ai Then, the agent i observes an immediate reward ri t from the ViZDoom environment before transitioning to the next state si t+1. Through agent–environment interactions, we obtain the interaction trajectory τ. We input the state transition and corresponding reward from the trajectory τ into the critic network to calculate the state target value Vtarget: where γV is the discount factor for value function and Θ represents the weight of the critic network. Based on the critic network’s estimated value for the current state and the target value Vtarget, we construct the following loss function: By applying the Adam optimizer, we minimize the loss function LVF(Θ) to update the weight of the critic network Θ. The loss function LVF(Θ) serves to minimize the disparity between the estimated value of critic model and the target value, thereby enhancing the model’s capacity to accurately assess the quality of the current state. In terms of the actor network, its main responsibility is to generate action decisions. To optimize the actor network, we first need to use the Generalized Advantage Estimator (GAE) method to calculate the advantage estimate value ˆAt: ˆAt = δt + (γA · λ)δt+1 + · · · + (γA · λ)T−t+1δT−1 where δt = rt + γA · VΘ(st+1) − VΘ(st). During the estimation process, the state values VΘ(st+1) and VΘ(s) are provided by the critic network, γA is the discount coefficient for the advantage function, and λ is used to balance bias and variance. We denote the weights of the actor network as θ, and the network weights before updating as θold. To prevent drastic gradient fluctuations during parameter updates, the PPO algorithm employs a clipping mechanism to constrain the difference between new and old policies πθ and πθold. Let πθ(at | st) denote the probability of policy πθ selecting action at under state st, and define the probability ratio between new and old policies as pt(θ) = πθ (at|st) (at|st) . Therefore, we adopt the following loss function for the PPO scheme: pt(θ) ˆAt, pclip (θ) ˆAt where the clip function pclip (θ) is denoted as 1 − ϵ, if pt(θ) < 1 − ϵ pt(θ), if 1 − ϵ < pt(θ) < 1 + ϵ 1 + ϵ, if 1 + ϵ < pt(θ) Figure 2 shows how the loss function Lclip (θ) varies with the probability ratio pt under different advantage functions. The loss function Lclip (θ) aims to provide the actor model with insights regarding policy advantages while limiting the magnitude of single updates to ensure controlled optimization. Here, ϵ is a hyper-parameter used to limit the clipping range. Finally, we update the weight of the actor network θ, utilizing the Adam optimizer based on the loss function Lclip (θ). 4.2. Multi-Agent-Based RL Framework for ViZDoom We systematically preprocess the game screen output from the ViZDoom environment to optimize the model input. Specifically, the ViZDoom simulator outputs a three-channel color image with a resolution of 240 × 320. After selective cropping and gray scale con- version, the image is resized to a single-channel feature of 84 × 84. To enhance temporal information expression, we concatenate four frames of images together, ultimately forming a state input with four channels of 84 × 84 features. The preprocessing scheme effec- tively preserves the dynamic characteristics of the environment while providing sufficient contextual information for the agent. It is worth noting that only one frame of the image is available in the game’s initial state. Therefore, when processing the initial state, we replicate the first frame four times and concatenate them to construct the initial state s0. It not only ensures the uniformity of input dimensions but also provides a stable and coherent learning foundation for the model. Through the above standardized processing, we achieve continuous and consistent state representations from the beginning to the end of the game, and provide the agent with a stable learning starting point. In the actor network architecture responsible for shooting control, we use the prepro- cessed game information as the model input. Then, it goes through multiple convolutional network processing: in the first convolutional layer, a 5 × 5 kernel operates with a stride of 2, followed by a ReLU activation function; in the second convolutional layer, a 4 × 4 kernel operates with a stride of 2, followed by a ReLU activation function; in the third convolutional layer, a 3 × 3 kernel operates with a stride of 2, followed by a ReLU activation function; and in the fourth convolutional layer, a 3 × 3 kernel operates with a stride of 2, producing output dimensions of (batch size, 32, 9, 9). Subsequently, the output is flattened through a flatten layer, and then passes through three fully connected layers, i.e., outputting 512, 64, and 2 units, respectively. Each is followed by a ReLU activation function. Finally, a softmax layer generates an action probability distribution to determine whether to fire. The actor network architecture for movement control is essentially identical to the shooting model, with only the output dimension in the final layer changed to 3, used to control left movement, right movement, or staying still. The two agents share the same critic network structure. It maintains the same input processing method and convolutional layer configuration, and through a similar network architecture, ultimately outputs a single state value estimate. Specifically, the critic network’s input will go through four convolutional layers. After flattening, it passes through fully connected layers with dimensions of 512, 64, and 1, each followed by a ReLU activation function, ultimately outputting the state value assessment. The specific process is shown in Figure 3. According to the MA-PPO training process in Algorithm 1, we extend the original PPO algorithm to implement a dual-agent collaborative control system. Compared to the PPO pseudocode table Algorithm A1, we design the simultaneous training and updating of multiple agents in the MA-PPO training process. Two independently trained agents jointly control a game character, with their policy updates occurring relatively independently. The algorithm accepts several input variables, i.e., the maximum number of epochs η, maximum number of steps ξ, maximum number of training repetitions υ, and environment state st, and then outputs the control strategy. During practical application, the agent accepts the same inputs to generate joint actions at as output. The training procedure follows the process below as follows. After initializing the system parameters and model architecture for the two agents in the system, a training loop is entered into, consisting of η epochs, with each epoch containing ξ training steps. During the training process, the agent first interacts with the environment until the end of a game round, then the system records the interaction trajectory τ and updates the counter, followed by υ iterations of optimization on the collected data for both agents. During the optimization phase, the system first calculates the state target value Vtarget based on trajectory τ, constructs the critic network’s loss function LVF(Θ), and updates the relevant parameters through the Adam optimizer. Next, the system evaluates the advantage function ˆAt based on trajectory τ, which is used to construct the actor network’s loss function Lclip (θ), and similarly employs the Adam optimizer for parameter updates. Finally, the control strategy π is formed. These steps collectively form the core optimization mechanism of the MA-PPO algorithm. Input: state from environment st, η, ξ, υ; Output: control strategy; 1: for agent i = 1, 2 do 2: 3: initialize critic parameters Θ and actor parameters θ initialize the learning rate βlr and optimizer 4: EndFor 5: for epoch k = 1, 2, · · · , η do for step t = 1, 2, · · · , ξ do 6: 7: play the game under parameters Θ and θ for game is not over do the agent obtains environment information the agent executes actions EndFor gain the trajectory τ record the game steps for agent i = 1, 2 do for repeat training times j = 1, 2, · · · , υ do compute Vtarget according to Equation (5) compute LVF(Θ) according to Equation (6) update parameters of critic network Θ compute ˆAt according to Equation (7) compute Lclip (θ) according to Equation (8) update parameters of actor network θ 24: 25: EndFor 26: form a control strategy π for the whole system 5. Results and Analysis 5.1. Experiment Setup To assess the efficacy of our multi-agent deep reinforcement learning framework in first-person shooting scenarios, we conduct comprehensive experiments utilizing the open- source platform, VizDoom. The simulation is conducted on a workstation with an Intel Core i7-9700K processor which is manufactured by Intel Corporation in Santa Clara, CA, USA. The operation system is Ubuntu 20.04.6 LTS (Focal Fossa). The code is written in Python 3.6.0 using Pytorch 1.6.1 and ViZDoom 1.2.4. The parameters are listed in Table 2. The learning rate βlr gradually decreases from 1 × 10−5 to 1 × 10−7. The discount factors γA and γV are both 0.98 according to Section 5.3.2. Bias λ is multiplied with discount factor γA when calculating the advantage function. Following the recommendation in the PPO, we set the range of clip operation ϵ = 0.2. For the training iteration variables η, ξ, and υ, we select values that enable algorithm convergence during the actual training process. We employ five baseline algorithms for experimental evaluation and comparative analysis, i.e., PPO, MA-PPO, A2C, MA-A2C, and DQN. The following will elaborate on the characteristics and implementation methods of each algorithm. Proximal Policy Optimization (PPO) [39]: PPO was proposed by Schulman et al. in 2017, and is an advanced reinforcement learning method. PPO adopts an actor–critic archi- tecture, which can be applied to both discrete and continuous action spaces, demonstrating strong versatility in reinforcement learning problems. The most distinctive feature of PPO lies in the clip operations, which limits the magnitude of single policy updates, greatly enhancing its stability. Therefore, we develop MA-PPO, extending the PPO algorithm for application within a multi-agent system framework. Compared to the original PPO algorithm, we change the task allocation structure and design two agents responsible for movement and shooting, respectively. The two agents are both updated according to the PPO algorithm and jointly control the player’s behavior. The specific algorithm details are elaborated on in Section 4. Advantage Actor–Critic (A2C) [9]: The A2C algorithm is an efficient policy optimiza- tion method, which employs an actor–critic architecture. The algorithm integrates policy gradient methods with value function estimation, and introduces advantage functions to optimize the training process. The actor network is responsible for action decision-making and updates based on the advantage function, while the critic network evaluates action values and optimizes parameters in a manner similar to PPO. Correspondingly, MA-A2C is our improved version of the A2C algorithm after adapting it to a multi-agent framework. Deep Q-Network (DQN) [40]: DQN is a deep reinforcement learning algorithm devel- oped by the DeepMind team in 2013. DQN approximates the Q-value function through deep neural networks to handle complex high-dimensional input data. DQN introduces an experience replay mechanism, storing the agent’s interactions with the environment in a replay buffer, and conducts training through random sampling, effectively reducing data correlation and significantly improving training efficiency and stability. We evaluate the convergence performance of the proposed multi-agent architecture through a training period of 1000 epochs. We conduct systematic comparative analysis with PPO, MA-PPO, A2C, MA-A2C, and DQN to validate the performance advantages of our architecture. In the analysis of Figure 4a, the results show that MA-A2C demonstrates optimal per- formance during the convergence phase, followed by DQN and A2C. DQN demonstrates significant rapid convergence characteristics, reaching a stable state at around 50 epochs. The efficient convergence performance can be attributed to its streamlined algorithm struc- ture and lower parameter complexity. A2C converges and maintains stability around epoch 80. The MA-A2C learning curve exhibits unique dynamic characteristics. The conver- gence curve exhibits a significant drop at epoch 86, i.e., reward value −313, followed by a strong recovery. MA-A2C surpasses the performance levels of A2C at epoch 130 and DQN at epoch 140, before achieving stable convergence at epoch 150. The performance curve characteristics reflect the collaborative learning challenges of the multi-agent system in the initial phase and the effective cooperation mechanism subsequently established through continuous environmental interaction. The results in Figure 4b show that MA- PPO consistently maintains a leading advantage, while PPO performs better than DQN after convergence. Specifically, PPO achieves initial convergence at epoch 30, followed by a continuous optimization trend, surpassing DQN in overall performance at epoch 250. MA-PPO reaches convergence at epoch 50, demonstrating excellent performance stability. The comprehensive evaluation results in Figure 4c indicate that MA-PPO demonstrate far superior convergence compared to the other four baselines, i.e., PPO, MA-A2C, DQN, and A2C. After convergence, the rewards for MA-PPO, PPO, MA-A2C, and DQN are 75, 52, 51, and 31, respectively. Quantitative analysis shows that MA-PPO achieves test performance improvements of 30.67%, 32.00%, and 58.67% compared to PPO, MA-A2C, and DQN, respectively. Meanwhile, compared to their original versions, both the MA-PPO algorithm versus the PPO algorithm, and the MA-A2C algorithm versus the A2C algorithm show highly significant improvements in reward data from the experiments. Therefore, the experimental data confirm that the algorithm variants based on the multi-agent architecture, i.e., MA-PPO and MA-A2C, achieve significant performance improvements compared to their original versions, fully validating the effectiveness of the proposed multi-agent architecture in optimizing reinforcement learning performance. Figure 5 shows the results of our visualization-based comparative analysis of the five baselines’ performance in the game environment. As shown in Table 3, the multi-agent architecture MA-PPO demonstrates optimal performance, efficiently completing the task with a reward of 76, 20 action steps, and 48 remaining ammunition. The PPO algorithm is ranked second, achieving a reward of 56, 35 action steps, and 47 remaining ammunition. MA-A2C achieves a reward of 47, takes 44 steps, and maintains 47 remaining ammunition. DQN achieves a reward of 36, took 55 steps, and has 47 ammunition remaining. The A2C algorithm shows relatively weak performance, obtaining a reward of −109, taking 165 steps, and having 40 ammunition remaining. Then, we conduct a detailed analysis of the visualization-based results from the perspective of each agent’s actions. MA-PPO executes shooting actions at steps 7 and 20, successfully hitting the enemy at step 20, while rapidly approaching the target during the intermediate phases. PPO executes shooting actions at steps 12, 25, and 35, successfully hitting the enemy at step 35, while slowly approaching the target during the intermediate phases. MA-A2C executes shooting actions at steps 10, 21, and 44, successfully hitting the enemy at step 44, with a brief stationary period between steps 27 and 32, while slowly approaching the target during the intermediate phases. DQN executes shooting actions at steps 20, 37, and 55, successfully hitting the enemy at step 55, with a brief stationary period between steps 25 and 35, while slowly approaching the target during the intermediate phases. A2C executed a total of 10 shots, hitting the enemy at step 165, with the intermediate phases involving frequent lateral oscillations and stationary periods. The experimental data clearly demonstrate that algorithm variants based on multi-agent architecture, i.e., MA-PPO and MA-A2C, outperform their corresponding baselines across all performance metrics, with particularly notable improvements in the case of the A2C algorithm. The empirical results strongly confirm that the proposed multi-agent system has significant advantages in improving agent game performance. Average Reward ↑ Average Step ↓ Ammunition (AMMO) ↑ We conduct systematic parameter experiments on the discount factors γA, γV for estimating target value Vtarget and advantage function ˆAt to evaluate how their different combinations affect model training. Through the analysis of 1000 training epochs, we obtain the following key findings. Figure 6a shows the impact of different γA values (0.98, 0.95, 0.90, and 0.85) on model convergence when γV is fixed at 0.98. The experimental results show that when γA = 0.98, it not only demonstrates optimal training stability but also achieves the highest reward value. The data show that as the γA value approaches 1, the model performance becomes more superior. Figure 6b shows the experimental results with different γV values (0.98, 0.95, 0.90, and 0.85) when γA is fixed at 0.98. The study finds that changes in γV can lead to significant fluctuations in the model training process, but as the γV value approaches 1, the model training becomes more stable and can achieve higher reward levels. Figure 6c visualizes the effects of 16 combinations of γA and γV through a heatmap, where darker regions represent superior model performance. The experimental results clearly demonstrate that the parameter combination of γA = 0.98 and γV = 0.98 produces the best performance, indicating that the combination achieves an ideal balance between bias and variance in reward function estimation. Above all, we accordingly determine the final parameter configuration. In this paper, we propose a multi-agent reinforcement learning framework called MA-PPO that achieves predetermined objectives through continuous interaction with the ViZDoom environment under specific constraints. Specifically, the primary objective is to achieve target acquisition with optimal efficiency while adhering to specified ammunition and time limitations. Comprehensive performance evaluation shows that the improved MA-PPO algorithm achieves a 30.67% improvement in convergence performance compared to the baseline algorithm. Through systematic parameter experiments, we validate the scientific basis and effectiveness of our chosen discount factor parameters. Through a series of simulation experiments, it is demonstrated that the proposed multi-agent architecture has good generality and can be integrated with various actor–critic frameworks to enhance overall performance. Future work will be expanded in the following direction. For practice, we will explore the potential applications of multi-agent reinforcement learning algorithms in broader and more complex game environments to validate their generality and practical appli- cation value. We plan to conduct in-depth research on optimizing the decision-making mechanisms and develop algorithm architectures that better adapt to diverse gaming environments. Furthermore, we will focus on resource efficiency issues in multi-agent systems, emphasizing research on the optimal balance point between agent scale expansion and computational resource consumption, aiming to achieve an ideal trade-off between performance improvement and computational efficiency. Based on the PPO algorithm’s training process shown in Algorithm A1, the algorithm accepts several input variables, i.e., the maximum number of epochs η, maximum number of steps ξ, maximum number of training repetitions υ, environment state st, and then outputs both the trained critic and actor networks. During practical application, the agent accepts the same inputs to generate agent actions at as output. The training procedure follows the process below as follows. After initializing the system parameters and model architecture, we enter a training loop consisting of η epochs, with each epoch containing ξ training steps. During the training process, the agent first interacts with the environment until the end of a game round, then the system records the interaction trajectory τ and updates the counter, followed by υ iterations of optimization on the collected data. During the optimization phase, the system first calculates the state target value Vtarget based on trajectory τ, constructs the critic network’s loss function LVF(Θ), and updates the relevant parameters through the Adam optimizer. Next, the system evaluates the advantage function ˆAt based on trajectory τ, which is used to construct the actor network’s loss function Lclip (θ), and similarly employs the Adam optimizer for parameter updates. These steps collectively form the core optimization mechanism of the PPO algorithm. Input: state from environment st, η, ξ, υ; Output: actor network, critic network; 1: initialize critic parameters Θ and actor parameters θ 2: initialize the learning rate βlr and optimizer 3: for epoch k = 1, 2, · · · , η do for step t = 1, 2, · · · , ξ do 4: 5: play the game under parameters Θ and θ for game is not over do the agent obtains environment information the agent executes actions EndFor gain the trajectory τ record the game steps for repeat training times j = 1, 2, · · · , υ do compute Vtarget according to Equation (5) compute LVF(Θ) according to Equation (6) update parameters of critic network Θ compute ˆAt according to Equation (7) compute Lclip (θ) according to Equation (8) update parameters of actor network θ Appendix B. Performance Comparison with SAC and MADDPG Despite the availability of various established algorithm in the DRL field, i.e.,SAC, and multi-agent frameworks, i.e., MADDPG, our research is focused on developing an enhanced multi-agent architecture leveraging PPO. In the following section, we will examine the SAC algorithm and MADDPG framework as reference points to illustrate the rationality and innovation of the algorithm adopted and proposed in our work. Soft Actor–Critic (SAC) [41], introduced by Haarnoja et al., implements an actor– critic architecture with entropy-based exploration mechanisms, demonstrating exceptional performance across various tasks. However, to address bootstrapping issues, SAC utilizes a configuration of four critic models and one actor model, whereas PPO, another state-of- the-art DRL method, operates with a single actor–critic model. The implementation of SAC in a multi-agent framework would necessitate significantly greater training resources and memory allocation compared to MA-PPO, as the resource requirements would scale with the number of agents,which leads us to adopt the more streamlined PPO algorithm for our multi-agent framework. Performance comparisons with SAC are presented in Figure A1. MADDPG [33], introduced by Lowe et al., represents a multi-agent architecture that directly outputs agent actions rather than probability distributions. MADDPG employs a centralized training with a decentralized execution learning framework, allowing models to access global information during training while operating with limited perspective during execution. In contrast, our proposed MA-PPO algorithm employs a task-allocation learning framework in the ViZDoom environment, enabling concurrent specialized training for distinct agents on different tasks, which is a more streamlined and efficient approach that provides more possibilities for collaboration and coordination between different agents. As demonstrated in the comparative analysis presented in the appendix, the proposed MA-PPO algorithm exhibits superior performance metrics. We evaluate the convergence performance of each baseline through a training period of 1000 epochs. We conduct a systematic comparative analysis between MA-PPO and MADDPG to validate the performance advantages of our architecture. Meanwhile, we compare PPO with SAC to explain our rationale for choosing PPO as the baseline for multi-agent improvements. In the analysis shown in Figure A1, the results demonstrate that MA-PPO exhibits the best performance during the convergence phase, followed by MADDPG, PPO, and SAC. MA-PPO reaches convergence at epoch 50, demonstrating excellent performance stability. MADDPG converges at epoch 30, showing similar stability but with lower performance compared to MA-PPO. SAC converges at epoch 60, with slight performance fluctuations throughout the training process. PPO achieves convergence at epoch 30, followed by a continuous optimization trend, surpassing SAC in overall performance at epoch 800. After convergence, the rewards for MA-PPO, MADDPG, PPO, and SAC are 75, 60, 52, and 50, respectively. Quantitative analysis shows that MA-PPO achieves test performance improvements of 20.00%, 30.67%, and 33.33% compared to MADDPG, PPO, and SAC, respectively. Meanwhile, the performance of PPO is slightly higher than that of SAC after convergence. Therefore, the experimental data confirm that the proposed MA-PPO demonstrates performance superiority compared to existing multi-agent algorithms, and PPO is a more reasonable baseline choice. Appendix C. Performance Evaluation with Error Bars We develop the testing procedure according to the VizDoom simulator [37]. We save the converged baselines, and then to control variables, and conduct 100 games in a fixed scenario with controlled environmental conditions, i.e., enemy positions and initial positions, recording the reward values obtained by the baseline in each game. In Figure A2, the blue bars indicate the average rewards from the testing procedure, while the black lines indicate the standard deviation of the rewards. In the analysis shown in Figure A2, the results show that MA-PPO achieves the highest average reward, followed by MADDPG, PPO, MA-A2C, SAC, and DQN, with average reward values of 75.12, 59.60, 52.24, 51.64, 49.82, and 31.34 respectively, and standard deviation values of 1.85, 1.87, 2.10, 8.59, 5.15, and 7.78, respectively. Therefore, the algorithm with the highest stability remains the proposed MA-PPO, followed by MADDPG, PPO, SAC, DQN, and MA-A2C. Thus, the experimental data confirm that the proposed MA-PPO demonstrates the best performance and stability. Appendix D. Parameter Experiments of Learning Rate We conduct systematic parameter experiments on the learning rate βlr to evaluate the impact of variable and fixed learning rates on model training. Through the analysis of 1000 training epochs, we find that variable learning rates can significantly improve the model’s performance. Figure A3 shows the convergence curves of MA-PPO under variable and fixed learning rates. When using variable learning rates, the model converges at 100 epochs, demonstrating excellent performance stability and better convergence. When using fixed learning rates, the model converges at epoch 50, with slight fluctuations during the training process. Therefore, the experimental data confirm that variable learning rates significantly improve the model’s performance and stability.",
         "https://www.mdpi.com/2227-7390/13/5/754/pdf?version=1740497280",
         "extracted",
         "None",
         "",
         "Deep Reinforcement Learning-Based Multi-Agent System with Advanced Actor–Critic Framework for Complex Environment"
        ],
        [
         "49",
         "022103bcb2f73b22a217aaa1bb92d4f8df4a75c2",
         "Existing models of human growth provide little insight into underlying mechanisms responsible for inter-individual and inter-population variation in children’s growth trajectories. Building on general theories linking growth to metabolic rates, we develop a causal parametric model of height and weight growth incorporating a representation of human body allometry and a process-partitioned representation of ontogeny. This model permits separation of metabolic causes of growth variation, potentially influenced by nutrition and disease, from allometric factors, potentially under stronger genetic control. We estimate model parameters using a Bayesian multilevel statistical design applied to temporally-dense height and weight measurements of U.S. children, and temporally-sparse measurements of Indigenous Amazonian children. This facilitates a comparison of the contributions of metabolism and allometry to observed cross-cultural variation in the growth trajectories of the two populations, and permits simulation of the effects of healthcare interventions on growth. This theoretical model provides a new framework for exploring the causes of growth variation in our species, while potentially guiding the development of appropriate, and desired, healthcare interventions in societies confronting growth-related health challenges, such as malnutrition and stunting.",
         "J. Bunce,Catalina I. Fernández,Caissa Revilla-Minaya",
         "None",
         "None",
         "https://www.biorxiv.org/content/biorxiv/early/2022/10/12/2022.10.10.511559.full.pdf",
         "None",
         "None",
         "",
         "A causal model of human growth and its estimation using temporally-sparse data"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5162
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authorName</th>\n",
       "      <th>full_text</th>\n",
       "      <th>main_text</th>\n",
       "      <th>openAccessPdf</th>\n",
       "      <th>pdf_status</th>\n",
       "      <th>ref_text</th>\n",
       "      <th>referenceTitles</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000160a2fe73e426cad54f5ba7d1e45703a77b98</td>\n",
       "      <td>None</td>\n",
       "      <td>Panagiotis I. Nikolaidis,John S. Baras</td>\n",
       "      <td>\\n**BLOCK**fs== 23.9**p== 0.0**b== 0.8**t== 0....</td>\n",
       "      <td>Robust Resource Sharing in Network Slicing via...</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.1...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Robust Resource Sharing in Network Slicing via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004c478be53ae7cc93461846992842c73778e7e</td>\n",
       "      <td>None</td>\n",
       "      <td>Louis Golowich,V. Guruswami</td>\n",
       "      <td>\\n**BLOCK**fs== 17.2**p== 0.0**b== 0.8**t== 0....</td>\n",
       "      <td>. . . . . . . . . . . . . . . . . . . . . . . ...</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.0...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Quantum Locally Recoverable Codes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a3e6667afb4ca8476ce15555b05244c3b458a</td>\n",
       "      <td>Accurately extracting organs from medical imag...</td>\n",
       "      <td>Fenghui Lian,Yingjie Sun,Meiyu Li</td>\n",
       "      <td>\\n**BLOCK**fs== 26.0**p== 0.0**b== 0.6**t== 0....</td>\n",
       "      <td>Extracting organs of interest from medical ima...</td>\n",
       "      <td>https://www.nature.com/articles/s41598-025-860...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td>Pancreas segmentation based on an adversarial ...</td>\n",
       "      <td>Extracting organs of interest from medical ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c965a4857c0da7d9df07065b48920a6a756c6</td>\n",
       "      <td>None</td>\n",
       "      <td>Sandeep Reddy,Sameer Shaikh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://eprints.qut.edu.au/252096/1/9284-PB1-6...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>The long road ahead: navigating obstacles and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00139e24da15df3f2f4ef70a92a781ccf315ef47</td>\n",
       "      <td>Repair of DNA damage is essential for genome i...</td>\n",
       "      <td>Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.biorxiv.org/content/biorxiv/early/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>DdiA, an XRE family transcriptional regulator,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>ffb10b00b180a9ca1311a3f282489901cd244203</td>\n",
       "      <td>Microservice architecture is increasingly favo...</td>\n",
       "      <td>Angelo Marchese,O. Tomarchio</td>\n",
       "      <td>\\n**BLOCK**fs== 8.5**p== 0.0**b== 0.9**t== 0.1...</td>\n",
       "      <td>· Orazio Tomarchio1 Abstract Microservice arch...</td>\n",
       "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td>A Multiobjective Metaheuristic-Based Container...</td>\n",
       "      <td>Enhancing the Kubernetes Platform with a Load-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>ffb7e36315a3c3329d01e54f68bfdf595c1b4a8a</td>\n",
       "      <td>None</td>\n",
       "      <td>Leyla A. Kabuli,Nalini M. Singh,Laura Waller</td>\n",
       "      <td>\\n**BLOCK**fs== 15.9**p== 0.0**b== 0.8**t== 0....</td>\n",
       "      <td>Estimation-theoretic analysis of lensless imag...</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.1...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Estimation-theoretic analysis of lensless imaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>ffd00ce568f98d0febe6aeb407b54f9075ea732b</td>\n",
       "      <td>None</td>\n",
       "      <td>Pietro Vischia</td>\n",
       "      <td>\\n**BLOCK**fs== 16.2**p== 0.0**b== 0.7**t== 0....</td>\n",
       "      <td>AI-assisted design of experiments at the front...</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.0...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>AI-assisted design of experiments at the front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>ffd1a1c82aeef26f1e84a8574cc3a0c600112b9e</td>\n",
       "      <td>None</td>\n",
       "      <td>Robin Armstrong,Alex Buzali,Anil Damle</td>\n",
       "      <td>\\n**BLOCK**fs== 10.0**p== 0.0**b== 0.8**t== 0....</td>\n",
       "      <td>1. Introduction. Countless numerical algorithm...</td>\n",
       "      <td>gs://arxiv-dataset/arxiv/arxiv/pdf/2310/2310.0...</td>\n",
       "      <td>extracted</td>\n",
       "      <td>None</td>\n",
       "      <td>Simpler is better: a comparative study of rand...</td>\n",
       "      <td>Structure-Aware Analyses and Algorithms for In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>ffeee44908c472ac7fe276498c41826e82a6b5b9</td>\n",
       "      <td>Abstract Background Rapid and precise aetiolog...</td>\n",
       "      <td>Wenting Jin,Ying Shao,Yaozong Gao,Bijie Hu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pubs.acs.org/doi/pdf/10.1021/cen-v030n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Does race matter? An experimental vignette stu...</td>\n",
       "      <td>P-651. An Artiﬁcial Intelligence Model Outperf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5162 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paperId  \\\n",
       "0     000160a2fe73e426cad54f5ba7d1e45703a77b98   \n",
       "1     0004c478be53ae7cc93461846992842c73778e7e   \n",
       "2     000a3e6667afb4ca8476ce15555b05244c3b458a   \n",
       "3     000c965a4857c0da7d9df07065b48920a6a756c6   \n",
       "4     00139e24da15df3f2f4ef70a92a781ccf315ef47   \n",
       "...                                        ...   \n",
       "5157  ffb10b00b180a9ca1311a3f282489901cd244203   \n",
       "5158  ffb7e36315a3c3329d01e54f68bfdf595c1b4a8a   \n",
       "5159  ffd00ce568f98d0febe6aeb407b54f9075ea732b   \n",
       "5160  ffd1a1c82aeef26f1e84a8574cc3a0c600112b9e   \n",
       "5161  ffeee44908c472ac7fe276498c41826e82a6b5b9   \n",
       "\n",
       "                                               abstract  \\\n",
       "0                                                  None   \n",
       "1                                                  None   \n",
       "2     Accurately extracting organs from medical imag...   \n",
       "3                                                  None   \n",
       "4     Repair of DNA damage is essential for genome i...   \n",
       "...                                                 ...   \n",
       "5157  Microservice architecture is increasingly favo...   \n",
       "5158                                               None   \n",
       "5159                                               None   \n",
       "5160                                               None   \n",
       "5161  Abstract Background Rapid and precise aetiolog...   \n",
       "\n",
       "                                             authorName  \\\n",
       "0                Panagiotis I. Nikolaidis,John S. Baras   \n",
       "1                           Louis Golowich,V. Guruswami   \n",
       "2                     Fenghui Lian,Yingjie Sun,Meiyu Li   \n",
       "3                           Sandeep Reddy,Sameer Shaikh   \n",
       "4     Jana Jung,Timo Glatter,Marco Herfurth,L. Søgaa...   \n",
       "...                                                 ...   \n",
       "5157                       Angelo Marchese,O. Tomarchio   \n",
       "5158       Leyla A. Kabuli,Nalini M. Singh,Laura Waller   \n",
       "5159                                     Pietro Vischia   \n",
       "5160             Robin Armstrong,Alex Buzali,Anil Damle   \n",
       "5161         Wenting Jin,Ying Shao,Yaozong Gao,Bijie Hu   \n",
       "\n",
       "                                              full_text  \\\n",
       "0     \\n**BLOCK**fs== 23.9**p== 0.0**b== 0.8**t== 0....   \n",
       "1     \\n**BLOCK**fs== 17.2**p== 0.0**b== 0.8**t== 0....   \n",
       "2     \\n**BLOCK**fs== 26.0**p== 0.0**b== 0.6**t== 0....   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "5157  \\n**BLOCK**fs== 8.5**p== 0.0**b== 0.9**t== 0.1...   \n",
       "5158  \\n**BLOCK**fs== 15.9**p== 0.0**b== 0.8**t== 0....   \n",
       "5159  \\n**BLOCK**fs== 16.2**p== 0.0**b== 0.7**t== 0....   \n",
       "5160  \\n**BLOCK**fs== 10.0**p== 0.0**b== 0.8**t== 0....   \n",
       "5161                                               None   \n",
       "\n",
       "                                              main_text  \\\n",
       "0     Robust Resource Sharing in Network Slicing via...   \n",
       "1     . . . . . . . . . . . . . . . . . . . . . . . ...   \n",
       "2     Extracting organs of interest from medical ima...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "5157  · Orazio Tomarchio1 Abstract Microservice arch...   \n",
       "5158  Estimation-theoretic analysis of lensless imag...   \n",
       "5159  AI-assisted design of experiments at the front...   \n",
       "5160  1. Introduction. Countless numerical algorithm...   \n",
       "5161                                               None   \n",
       "\n",
       "                                          openAccessPdf pdf_status ref_text  \\\n",
       "0     gs://arxiv-dataset/arxiv/arxiv/pdf/2404/2404.1...  extracted     None   \n",
       "1     gs://arxiv-dataset/arxiv/arxiv/pdf/2311/2311.0...  extracted     None   \n",
       "2     https://www.nature.com/articles/s41598-025-860...  extracted     None   \n",
       "3     https://eprints.qut.edu.au/252096/1/9284-PB1-6...       None     None   \n",
       "4     https://www.biorxiv.org/content/biorxiv/early/...       None     None   \n",
       "...                                                 ...        ...      ...   \n",
       "5157  https://link.springer.com/content/pdf/10.1007/...  extracted     None   \n",
       "5158  gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.1...  extracted     None   \n",
       "5159  gs://arxiv-dataset/arxiv/arxiv/pdf/2501/2501.0...  extracted     None   \n",
       "5160  gs://arxiv-dataset/arxiv/arxiv/pdf/2310/2310.0...  extracted     None   \n",
       "5161  https://pubs.acs.org/doi/pdf/10.1021/cen-v030n...       None     None   \n",
       "\n",
       "                                        referenceTitles  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2     Pancreas segmentation based on an adversarial ...   \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "5157  A Multiobjective Metaheuristic-Based Container...   \n",
       "5158                                                      \n",
       "5159                                                      \n",
       "5160  Simpler is better: a comparative study of rand...   \n",
       "5161  Does race matter? An experimental vignette stu...   \n",
       "\n",
       "                                                  title  \n",
       "0     Robust Resource Sharing in Network Slicing via...  \n",
       "1                     Quantum Locally Recoverable Codes  \n",
       "2     Extracting organs of interest from medical ima...  \n",
       "3     The long road ahead: navigating obstacles and ...  \n",
       "4     DdiA, an XRE family transcriptional regulator,...  \n",
       "...                                                 ...  \n",
       "5157  Enhancing the Kubernetes Platform with a Load-...  \n",
       "5158  Estimation-theoretic analysis of lensless imaging  \n",
       "5159  AI-assisted design of experiments at the front...  \n",
       "5160  Structure-Aware Analyses and Algorithms for In...  \n",
       "5161  P-651. An Artiﬁcial Intelligence Model Outperf...  \n",
       "\n",
       "[5162 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paperdata = load_data(2025)\n",
    "display(paperdata['metadata'])\n",
    "display(paperdata['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((paperdata['metadata']['referenceIds'].str.len()>2) & (paperdata['text']['pdf_status']!='None')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.download import filter_arXiv_database, load_arX_dataset\n",
    "import config\n",
    "\n",
    "arXiv_downloads_dir = config.TMP_PATH / \"arXiv\"\n",
    "arX_data = load_arX_dataset(arXiv_downloads_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_arX_data = filter_arXiv_database(arX_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161495, 178275)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2020\n",
    "len(filt_arX_data[filt_arX_data['publicationYear']==year]), len(arX_data[arX_data['publicationYear']==year])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asxai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
