{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa62c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import config\n",
    "from asxai.vectorDB.generate import OllamaManager\n",
    "\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f452cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from groq import AsyncGroq\n",
    "\n",
    "client = AsyncGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),  # This is the default and can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb9ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    " \n",
    "chat_completion = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the role of the prefrontal cortex?\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\", #\"llama3-8b-8192\",\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9afcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prefrontal cortex (PFC) is a critical region in the brain that plays a key role in various higher-order cognitive functions, decision-making, and behavioral regulation. The prefrontal cortex is located in the frontal lobe, at the front of the brain, and is responsible for:\n",
      "\n",
      "1. **Executive functions**: The PFC is involved in executive functions, such as planning, decision-making, problem-solving, and goal-directed behavior. It helps to prioritize tasks, monitor progress, and adjust plans as needed.\n",
      "2. **Working memory**: The PFC is responsible for working memory, which is the ability to hold and manipulate information in mind over short periods of time. This allows us to keep track of information, reason, and make decisions.\n",
      "3. **Attention**: The PFC helps regulate attention, enabling us to focus on relevant information, filter out distractions, and switch between tasks.\n",
      "4. **Emotional regulation**: The PFC is involved in the regulation of emotions, including the management of stress, anxiety, and impulse control. It helps to modulate the emotional responses generated by the amygdala, a structure involved in emotional processing.\n",
      "5. **Impulse control**: The PFC helps to control impulses, allowing us to delay gratification, resist temptation, and make decisions that are in our long-term best interests.\n",
      "6. **Personality**: The PFC is thought to contribute to the development and expression of personality traits, such as extraversion, agreeableness, and conscientiousness.\n",
      "7. **Social behavior**: The PFC is involved in social behavior, including cooperation, empathy, and theory of mind (the ability to understand others' mental states).\n",
      "8. **Decision-making**: The PFC is responsible for decision-making, including weighing the pros and cons of different options, assessing risk, and making choices based on expected outcomes.\n",
      "9. **Motor planning**: The PFC is also involved in motor planning, helping to coordinate and plan complex movements.\n",
      "\n",
      "Damage to the prefrontal cortex, such as through traumatic brain injury or neurodegenerative diseases like frontal lobe dementia, can lead to a range of cognitive, emotional, and behavioral deficits, including:\n",
      "\n",
      "* Impaired decision-making and judgment\n",
      "* Difficulty with planning and organization\n",
      "* Impulsivity and poor impulse control\n",
      "* Emotional dysregulation\n",
      "* Social behavior abnormalities\n",
      "* Decreased working memory and attention\n",
      "\n",
      "Overall, the prefrontal cortex is a critical brain region that plays a central role in enabling us to think, learn, and behave in a flexible, adaptive, and goal-directed manner."
     ]
    }
   ],
   "source": [
    "async for chunk in chat_completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46788fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the role of the prefrontal cortex?\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\", #\"llama3-8b-8192\",\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "893495c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"paperId\": \"000a3e6667afb4ca8476ce15555b05244c3b458a\",\n",
      "    \"externalIds\": {\n",
      "      \"PubMedCentral\": \"11736126\",\n",
      "      \"DOI\": \"10.1038/s41598-025-86087-8\",\n",
      "      \"CorpusId\": 275580743,\n",
      "      \"PubMed\": \"39814795\"\n",
      "    },\n",
      "    \"title\": \"Extracting organs of interest from medical images based on convolutional neural network with auxiliary and refined constraints\",\n",
      "    \"citationCount\": 0,\n",
      "    \"openAccessPdf\": {\n",
      "      \"url\": \"https://www.nature.com/articles/s41598-025-86087-8.pdf\",\n",
      "      \"status\": \"GOLD\",\n",
      "      \"license\": \"CCBYNCND\",\n",
      "      \"disclaimer\": \"Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11736126, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.\"\n",
      "    },\n",
      "    \"authors\": [\n",
      "      {\n",
      "        \"authorId\": \"2064292642\",\n",
      "        \"name\": \"Fenghui Lian\"\n",
      "      },\n",
      "      {\n",
      "        \"authorId\": \"2340550389\",\n",
      "        \"name\": \"Yingjie Sun\"\n",
      "      },\n",
      "      {\n",
      "        \"authorId\": \"2109040952\",\n",
      "        \"name\": \"Meiyu Li\"\n",
      "      }\n",
      "    ],\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"a7d548167ae65df1b46782fe4055babbe968aaba\",\n",
      "        \"title\": \"Pancreas segmentation based on an adversarial model under two-tier constraints\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8d1e042add48525b4538d4630158b5cac0364797\",\n",
      "        \"title\": \"Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b618d43e7c0ca2606b0e31fe9ca0b67e0bd026d7\",\n",
      "        \"title\": \"Globally Guided Progressive Fusion Network for 3D Pancreas Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"eb1769438fdcac2564d250eb0726029471cda7da\",\n",
      "        \"title\": \"Fully Automatic Liver Attenuation Estimation Combing CNN Segmentation and Morphological Operations\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"27cebb08aca785444166209593fc0ec740469b1b\",\n",
      "        \"title\": \"Automatic liver tumor segmentation in CT with fully convolutional neural networks and object-based postprocessing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a8705cfb2d080592bcb55feff48b5883063cbbe7\",\n",
      "        \"title\": \"A Novel Bayesian Model Incorporating Deep Neural Network and Statistical Shape Model for Pancreas Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"cede0ad429de07437698421f453b0c161c9f4b0b\",\n",
      "        \"title\": \"Fully automated organ segmentation in male pelvic CT images\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"49ca9597280aa43d65df291d7991b25059cf8a3c\",\n",
      "        \"title\": \"Interleaved 3D-CNNs for joint segmentation of small-volume structures in head and neck CT images.\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2a4595d4156aa43d9980f7eb079d81cc9b05157c\",\n",
      "        \"title\": \"Automatic Organ Segmentation for CT Scans Based on Super-Pixel and Convolutional Neural Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0bffe8c90fda09f7181a97e1b1b705aab483755b\",\n",
      "        \"title\": \"Recurrent Saliency Transformation Network: Incorporating Multi-stage Visual Cues for Small Organ Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"01035661ccdb5388a3c040df42d5309f71101316\",\n",
      "        \"title\": \"3D U-net with Multi-level Deep Supervision: Fully Automatic Segmentation of Proximal Femur in 3D MR Images\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"65147d0652741e886243549123dab142699e07eb\",\n",
      "        \"title\": \"Improving Deep Pancreas Segmentation in CT and MRI Images via Recurrent Neural Contextual Learning and Direct Loss Function\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e0067a9c3f30aab46d9e6f8844dc36e83c85869f\",\n",
      "        \"title\": \"Automatic Brain Tumor Detection and Segmentation Using U-Net Based Fully Convolutional Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"3d44a1a97b6c768ae3080adf717326167457b0ad\",\n",
      "        \"title\": \"Spatial aggregation of holistically\\u2010nested convolutional neural networks for automated pancreas localization and segmentation\\u2606\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"569977bdb3f31d4b7c78ab3834fd34b370330e4e\",\n",
      "        \"title\": \"A Fixed-Point Model for Pancreas Segmentation in Abdominal CT Scans\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"59249dcd2e67bab1ab68e771092138392479d7ea\",\n",
      "        \"title\": \"Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"729b60c364f8ff04352681204260616d3861dd4f\",\n",
      "        \"title\": \"Efficient liver segmentation in CT images based on graph cuts and bottleneck detection.\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9e2d1a10e5732c1d9efca5ec72193a3252869b02\",\n",
      "        \"title\": \"3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ee13f51bd226aadac440b68c2825a907275c217c\",\n",
      "        \"title\": \"Shape\\u2013intensity prior level set combining probabilistic atlas and probability map constrains for automatic liver segmentation from abdominal CT images\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"3c1156945fb82e59d85f88fe3d0de37a22c3aece\",\n",
      "        \"title\": \"Automatic Liver Segmentation on Volumetric CT Images Using Supervoxel-Based Graph Cuts\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5dd2e5b21d7d72696920069225e0a252fee402e3\",\n",
      "        \"title\": \"Automatic Liver Segmentation Based on Shape Constraints and Deformable Graph Cut in CT Images\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ca29aaab1ecdd80120b80a405ecec530ec4d63a8\",\n",
      "        \"title\": \"DeepOrgan: Multi-level Deep Convolutional Networks for Automated Pancreas Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\n",
      "        \"title\": \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"62a9e7308622a4a42e850ed97dc231b774027a11\",\n",
      "        \"title\": \"A Generic, Robust and Fully-Automatic Workflow for 3D CT Liver Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"251c39c1b9372f3055cd53d0001fc122bfb2e418\",\n",
      "        \"title\": \"The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"75352a06f8f39701d59c3a3a78e5cce6dd469ea9\",\n",
      "        \"title\": \"Comparison and Evaluation of Methods for Liver Segmentation From CT Datasets\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"3964ba947347eb59c19d4b42d7a5623e357a81d5\",\n",
      "        \"title\": \"Automatic Pancreas Segmentation via Coarse Location and Ensemble Learning\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"c68796f833a7151f0a63d1d1608dc902b4fdc9b6\",\n",
      "        \"title\": \"GENERATIVE ADVERSARIAL NETS\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Data from Pancreas-CT\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"paperId\": \"26adf66ef7577fb7852c58145be3676b3df85b0b\",\n",
      "    \"externalIds\": {\n",
      "      \"ArXiv\": \"2404.18254\",\n",
      "      \"DBLP\": \"journals/corr/abs-2404-18254\",\n",
      "      \"DOI\": \"10.1109/TNSM.2025.3556752\",\n",
      "      \"CorpusId\": 269449113\n",
      "    },\n",
      "    \"title\": \"Robust Resource Sharing in Network Slicing via Hypothesis Testing\",\n",
      "    \"citationCount\": 0,\n",
      "    \"openAccessPdf\": {\n",
      "      \"url\": \"http://arxiv.org/pdf/2404.18254\",\n",
      "      \"status\": \"GREEN\",\n",
      "      \"license\": null,\n",
      "      \"disclaimer\": \"Notice: Paper or abstract available at https://arxiv.org/abs/2404.18254, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.\"\n",
      "    },\n",
      "    \"authors\": [\n",
      "      {\n",
      "        \"authorId\": \"2152052057\",\n",
      "        \"name\": \"Panagiotis I. Nikolaidis\"\n",
      "      },\n",
      "      {\n",
      "        \"authorId\": \"2268674717\",\n",
      "        \"name\": \"John S. Baras\"\n",
      "      }\n",
      "    ],\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"7dc457d3284aab6aeaa0c4b5e89a118a6d1b9486\",\n",
      "        \"title\": \"Malicious Lateral Movement in 5G Core With Network Slicing And Its Detection\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8283a9abe1794479c96fa4032928c19c755bf1d9\",\n",
      "        \"title\": \"Data-driven Bandwidth Adaptation for Radio Access Network Slices\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0680c76e55e3ed55aff69efea7fff2746474c47c\",\n",
      "        \"title\": \"Digital Twins for Next-Generation Mobile Networks: Applications and Solutions\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1ddc20644fa7e2a09b86034f4c2a40efc8725c9a\",\n",
      "        \"title\": \"kaNSaaS: Combining Deep Learning and Optimization for Practical Overbooking of Network Slices\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4b0b663b9c25cf4c9363495f261b58d5fe3371b9\",\n",
      "        \"title\": \"Characterizing and Modeling Mobile Networks User Traffic at Millisecond Level\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a7cb939acef9b4f30cc841790995ceca2cedc295\",\n",
      "        \"title\": \"Resource Efficiency vs Performance Isolation Tradeoff in Network Slicing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5fcba00cfd42cc5abc42a1142955f91176414f58\",\n",
      "        \"title\": \"In-depth study of RNTI management in mobile networks: Allocation strategies and implications on data trace analysis\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"c669112b8f955157fc5f82395481d49fc085a5c4\",\n",
      "        \"title\": \"A Distributed Online Learning Approach to Detect Anomalies for Virtualized Network Slicing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a5f2704a7c5bc9ceb7b89541443719c7f33ae00b\",\n",
      "        \"title\": \"Hoeffding's Inequality for General Markov Chains and Its Applications to Statistical Learning\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"eba46c316010d1dda7a55c765bf5f2cd9e08e55c\",\n",
      "        \"title\": \"On Provisioning Slices and Overbooking Resources in Service Tailored Networks of the Future\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1940803c185c7d57289b421fa332785356375290\",\n",
      "        \"title\": \"The Isolation Concept in the 5G Network Slicing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ae34501ccff71b40c080e1b492f40c8594982d34\",\n",
      "        \"title\": \"A Hoeffding Inequality for Finite State Markov Chains and its Applications to Markovian Bandits\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1264d9db012fe5c546fc5bf2ce08ba5c7c692be8\",\n",
      "        \"title\": \"FALCON: An Accurate Real-Time Monitor for Client-Based Mobile Network Data Analytics\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5d87a766897ee7de5d65fc57e9bbf5affc40433d\",\n",
      "        \"title\": \"RAN Resource Usage Prediction for a 5G Slice Broker\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"af9ace3830afa147ffa327a52b0d80bfd05ca69d\",\n",
      "        \"title\": \"Resource Sharing Efficiency in Network Slicing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"28c6b9172045ecb6605d26163ddf070420c060b1\",\n",
      "        \"title\": \"B4 and after: managing hierarchy, partitioning, and asymmetry for availability and scale in google's software-defined WAN\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f4f921e71a6c05e516e7bc4fef1603dc9af6682b\",\n",
      "        \"title\": \"iOverbook: Intelligent Resource-Overbooking to Support Soft Real-Time Applications in the Cloud\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"43d75d3a22db904d052d4c435e2d1f22be3887e0\",\n",
      "        \"title\": \"Outlier Detection for Temporal Data: A Survey\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"77933925f35e69fe39297f138cfe491d2a2dba76\",\n",
      "        \"title\": \"Performance Isolation and Fairness for Multi-Tenant Cloud Storage\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"53df899e1a18082b8654677b4c0aa95dbd96f0e0\",\n",
      "        \"title\": \"Anomaly Detection for Discrete Sequences: A Survey\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"56ca204b1133c63832207624b51bbd2528f316ae\",\n",
      "        \"title\": \"Towards an Understanding of Oversubscription in Cloud\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9ab32a45b871b7fe36c8184efaa7805fd8b1d38a\",\n",
      "        \"title\": \"The Knapsack Problem\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"71d1ac92ad36b62a04f32ed75a10ad3259a7218d\",\n",
      "        \"title\": \"Anomaly detection: A survey\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9dcc4d4fe864f34a93803039db50d83a8584f63c\",\n",
      "        \"title\": \"Fundamentals of statistical signal processing: estimation theory\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e7c6e7f142c42a4fe0d32cfe3b78339dff808f58\",\n",
      "        \"title\": \"Application-Level Service Assurance with 5G RAN Slicing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0b54943695938be548442c53447f7f146710a8af\",\n",
      "        \"title\": \"Machine Learning in Network Anomaly Detection: A Survey\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e26a1153aede1c3fe2a8e18c69e4861738c006c4\",\n",
      "        \"title\": \"Resource Allocation for Network Slicing in Mobile Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Physical Layer Procedures, Version 12.4.0\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"\\u201cLTE; E-UTRA; Physical layer procedures,\\u201d\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"\\u201cChapter 6 - quickest change detection,\\u201d\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"\\u201cStochastic network optimization with application to communication and queueing systems,\\u201d\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Dynamic Programming and Optimal Control, Vol. II , 3rd ed\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"visit with the KTH Royal Institute of Technology, Stockholm, Sweden in 2024\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"IEEE) received the Diploma degree in electrical and computer engineering from the Aristotle University of Thessaloniki, Thessaloniki, Greece\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"\\u201cGraph-based inter-pretable anomaly detection framework for network slice management in beyond 5G networks,\\u201d\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "    params={'fields': 'references,citationCount,title,externalIds'},\n",
    "    json={\"ids\": [\"000a3e6667afb4ca8476ce15555b05244c3b458a\", \"000160a2fe73e426cad54f5ba7d1e45703a77b98\"]}\n",
    ")\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34af3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sseclient\n",
    "import os\n",
    "\n",
    "DEV_BYPASS_TOKEN = os.getenv(\"DEV_BYPASS_TOKEN\", None)\n",
    "dev_headers = {\n",
    "    \"X-Dev-Bypass\": DEV_BYPASS_TOKEN,\n",
    "    \"admin\": 'true', #or remove it if you don't don't like admin rights\n",
    "    \"user_id\": \"your_name\",\n",
    "}\n",
    "\n",
    "API_URL = \"http://localhost:8000\" #Port of the chat-service\n",
    "notebook_id = \"your_notebook_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c448a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = None\n",
    "print(a is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e20d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"deleted_user_ids\":[\"f011efcda9ce2d71febe\",\"d9923d4bf38d7993ce96\",\"f01ce9c09d3e1636773f\",\"5c022ffb48a537cbf1e0\",\"2a97516c354b68848cdb\"]}'\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(f\"{API_URL}/admin/delete_ghost_users\", headers=headers)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73444aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat submitted: {'status': 'submitted', 'task_id': 'f011efcda9ce2d71febe/my-notebook', 'query_id': '8a4e581cc3387ca1fe13', 'user_id': 'f011efcda9ce2d71febe', 'notebook_id': 'my-notebook'}\n"
     ]
    }
   ],
   "source": [
    "message = \"What is NREM sleep?\"\n",
    "model = 'gemma3:12b'#'deepseek-r1:32b' #\n",
    "\n",
    "\n",
    "res = requests.post(f\"{API_URL}/notebook/{notebook_id}/chat\", \n",
    "                    json={\n",
    "                        \"message\": message,\n",
    "                        \"model\": model,\n",
    "                        \"topK\": 5,\n",
    "                        \"paperLock\": False\n",
    "                        },\n",
    "                    headers=dev_headers)\n",
    "\n",
    "print(\"Chat submitted:\", res.json())\n",
    "task_id = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df80bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧑[You]: What is NREM sleep?\n",
      "\n",
      "🤖[asXai]\n",
      "\n",
      "\n",
      "\n",
      "NREM sleep, also known as non-rapid eye movement sleep, is a stage of sleep characterized by slower brain waves, reduced physiological activity (like heart rate and breathing), and the absence of rapid eye movements. It's divided into three distinct stages (N1, N2, and N3) each with progressively deeper sleep. NREM sleep is crucial for physical restoration, immune system function, and memory consolidation. (id: 101)\n",
      "\n",
      "SEARCHING: What are the characteristics and functions of non-rapid eye movement sleep?\n",
      "------------------\n",
      "NREM sleep, also known as non-rapid eye movement sleep, is a stage of sleep characterized by distinct electrophysiological properties and rhythmic waveforms. It's a prominent sleep stage, with N2/3 stages predominating in many datasets (ARTICLE_ID: 033a24661b6865c08c45c49383378f4bd80c5310).\n",
      "\n",
      "Here's a breakdown of what the provided articles tell us about NREM sleep:\n",
      "\n",
      "*   **Distinct Stages:** NREM sleep includes stages N1, N2, and N3 (ARTICLE_ID: 033a24661b6865c08c45c49383378f4bd80c5310).\n",
      "*   **Sleep Spindles:** NREM-stage 2 (NREM2) sleep is characterized by sleep spindles, which are short bursts of waxing and waning 11-16 Hz oscillations (ARTICLE_ID: 16b73c560b91b5f55f8338b786745f6b4004013f).\n",
      "*   **Network Segregation:** Functional networks are more segregated during NREM sleep than during wakefulness (ARTICLE_ID: b5e3053da44fa9da057ea987b6684efbf378aa94).\n",
      "*   **Changes in Neuronal Processing:**  Abrupt changes in neuronal silent periods and gradual increases in population synchrony occur during transitions into and out of NREM sleep (ARTICLE_ID: ebfd3b56656b804fcb271b897e95fa2ba05657c5).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<END_OF_MESSAGE>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Stream response\n",
    "stream_response = requests.get(f\"{API_URL}/notebook/{notebook_id}/chat/stream\", stream=True, headers=headers)\n",
    "client = sseclient.SSEClient(stream_response)\n",
    "print(f\"🧑[You]: {message}\")\n",
    "print(f\"\\n🤖[asXai]\\n\\n\")\n",
    "for event in client.events():\n",
    "    print(event.data, end=\"\\n\", flush=True)\n",
    "    if \"<END_OF_MESSAGE>\" in event.data:\n",
    "        print(\" \")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c08bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'query': 'What are the characteristics, stages, and physiological functions of non-rapid eye movement sleep, as described in scientific publications focusing on sleep physiology and brain activity?',\n",
       "  'query_id': '79b1a1f1c36db196fac6',\n",
       "  'user_id': 'jul',\n",
       "  'notebook_id': 'my-notebook',\n",
       "  'qdrant_model': 'intfloat/multilingual-e5-large-instruct',\n",
       "  'rerank_model': '1-2025-05-18',\n",
       "  'blend_weights': {},\n",
       "  'timestamp': 1748419245.6279957,\n",
       "  'parsed_query': {'query': 'What are the key characteristics, typical stages, and physiological functions of non-rapid eye movement (NREM) sleep, including associated brain activity patterns and neurophysiological mechanisms?',\n",
       "   'authorName': None,\n",
       "   'publicationDate_start': None,\n",
       "   'publicationDate_end': None},\n",
       "  'query_embedding': [],\n",
       "  'paperIdQ': '2e38bdd1-d5d7-5310-96c4-9557f4f12bfd',\n",
       "  'influentialCitationCount': 0.0,\n",
       "  'publicationDate': '2025-02-17',\n",
       "  'paperId': '033a24661b6865c08c45c49383378f4bd80c5310',\n",
       "  'authorName': 'Haiteng Wang,Qihong Zou,Jinbo Zhang,Jiahong Gao,Yunzhe Liu',\n",
       "  'venue': 'bioRxiv',\n",
       "  'fieldsOfStudy': 'Biology',\n",
       "  'openAccessPdf': 'https://www.biorxiv.org/content/biorxiv/early/2024/10/16/2024.10.14.618165.full.pdf',\n",
       "  'title': 'Human Brain-Wide Activation of Sleep Rhythms',\n",
       "  'main_text': [],\n",
       "  'citationCount': 0,\n",
       "  'abstract': 'During sleep, our brain undergoes highly synchronized activity, orchestrated by distinct neural rhythms. Little is known about the associated brain activation during these sleep rhythms, and even less about their functional implications. In this study, we investigated the brain-wide activation underlying human sleep rhythms by employing simultaneous electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) in 107 participants during nocturnal nap (first half of the night). We identified robust coupling between slow oscillations (SOs) and fast spindles during deep non-rapid eye movement (NREM) sleep (N2/3 stages), with spindle peaks consistently occurring just before the SO UP-state. This SO-spindle coupling was linked to elevated activation in both the thalamus and hippocampus, alongside increased functional connectivity from the hippocampus to the thalamus and from the thalamus to the medial prefrontal cortex (mPFC). An open-ended cognitive state decoding analysis suggested that these activations may relate to episodic memory processes, yet were distinct from task-related networks. Together, these findings highlight the thalamus as a key coordinator of hippocampal-cortical communication during sleep and provide new insights into the mechanisms by which synchronized sleep rhythms may support memory consolidation.',\n",
       "  'publicationYear': 2025,\n",
       "  'best_chunks': [\"Keywords: slow oscillation (SO), spindle, hippocampus, thalamus, simultaneous EEG-fMRI During sleep, the human brain engages in highly synchronized activity driven by distinct rhythms. In non-rapid eye movement (NREM) sleep, the emergence and coordination of slow oscillations (SOs) and sleep spindles are key features (Ngo, Fell, & Staresina, 2020; Schreiner et al., 2022; Staresina et al., 2015; Staresina et al., 2023). However, the brain activation patterns associated with these rhythms and their coordination remain largely unexplored, and their functional implications are even less understood. SOs (~1 Hz) represent shifts in neuronal membrane potential between periods of silence ('hyperpolarization', or ‘DOWN’ state) and excitation ('depolarization',or ‘UP’ state) (Amzica & Steriade, 2002; Steriade, McCormick, & Sejnowski, 1993). These oscillations originate spontaneously in neocortical regions, particularly the medial prefrontal cortex (mPFC), during NREM sleep (Dang- Vu et al., 2008; Massimini et al., 2004; Nir et al., 2011). The depolarization phase of SOs is believed to trigger sleep spindles in the thalamus, producing oscillations in the 11–16 Hz range (Fernandez & L üthi, 2020; Mak-McCully et al., 2017). These spindles align with the excitable UP-states of SOs and synchronize with hippocampal ripples (Buzsáki, 2015; Helfrich et al., 2019; Joo & Frank, 2018; Ngo, Fell, & Staresina, 2020).\"],\n",
       "  'qdrant_score': 0.8868688,\n",
       "  'rerank_score': 0.8457192182540894,\n",
       "  'user_score': None,\n",
       "  'blended_score': 0.8457192182540894,\n",
       "  'score': 0.8457192182540894},\n",
       " {'id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'query': 'What are the characteristics, stages, and physiological functions of non-rapid eye movement sleep, as described in scientific publications focusing on sleep physiology and brain activity?',\n",
       "  'query_id': '79b1a1f1c36db196fac6',\n",
       "  'user_id': 'jul',\n",
       "  'notebook_id': 'my-notebook',\n",
       "  'qdrant_model': 'intfloat/multilingual-e5-large-instruct',\n",
       "  'rerank_model': '1-2025-05-18',\n",
       "  'blend_weights': {},\n",
       "  'timestamp': 1748419245.6279957,\n",
       "  'parsed_query': {'query': 'What are the key characteristics, typical stages, and physiological functions of non-rapid eye movement (NREM) sleep, including associated brain activity patterns and neurophysiological mechanisms?',\n",
       "   'authorName': None,\n",
       "   'publicationDate_start': None,\n",
       "   'publicationDate_end': None},\n",
       "  'query_embedding': [],\n",
       "  'paperIdQ': '4d63f749-bbb8-5c05-8f82-f663a8b8274a',\n",
       "  'influentialCitationCount': 0.0,\n",
       "  'publicationDate': '2025-03-20',\n",
       "  'paperId': 'b5e3053da44fa9da057ea987b6684efbf378aa94',\n",
       "  'authorName': 'Daiki Kiyooka,Ikumi Oomoto,Jun Kitazono,Yoshihito Saito,Midori Kobayashi,Chie Matsubara,Kenta Kobayashi,Masanori Murayama,Masafumi Oizumi',\n",
       "  'venue': 'bioRxiv',\n",
       "  'fieldsOfStudy': 'Biology',\n",
       "  'openAccessPdf': 'https://www.biorxiv.org/content/biorxiv/early/2023/09/15/2023.09.14.557838.full.pdf',\n",
       "  'title': 'Single-cell resolution functional networks during unconsciousness are segregated into spatially intermixed modules',\n",
       "  'main_text': [],\n",
       "  'citationCount': 2,\n",
       "  'abstract': 'The common neural mechanisms underlying the reduction of consciousness during sleep and anesthesia remain unclear. Previous studies have examined changes in network structure only using recordings with limited spatial resolution, which has hindered the investigation of the critical spatial scales from the micro (single neurons) to the meso (groups of neurons) for the reduction of consciousness. To address this issue, by leveraging fast, single-cell resolution, and wide-field two-photon microscopy, we recorded calcium signals from approximately 10,000 neurons across multiple cortical regions in awake, sleeping, and anesthetized mice. This single-cell resolution data enabled us to investigate the scales at which changes in network structure compared to an awake state are commonly observed during sleep and anesthesia. We found that at the single-cell scale, both sleep and anesthesia exhibited higher network modularity, indicating a segregated network, compared to an awake state. Despite this segregation, modules were spatially intermixed in all three states. In contrast, at the mesoscale, there were no consistent differences in modularity between states, and modules were spatially localized. Our multi-scale analysis provides novel insights into the cellular-scale organization of functional networks commonly associated with the reduction of consciousness and highlights a scale-dependent organization of network structures.',\n",
       "  'publicationYear': 2025,\n",
       "  'best_chunks': ['Such network-level understanding is pivotal for elucidating the neural underpinnings of reduced consciousness during sleep. Current empirical findings from studies using macro/mesoscale neural recordings, such as functional MRI (fMRI) and electroencephalography (EEG), suggest that functional networks are more segregated during non-rapid eye movement (NREM) sleep than during wakefulness [8–15]; that is, interactions across brain regions are diminished. For example, a perturbational approach using transcranial mag- netic stimulation (TMS) has shown that TMS-evoked EEG potentials do not propagate across brain regions during NREM sleep, but do so during wakefulness, implying a breakdown of cortical effec- tive connectivity during NREM sleep [12]. Another approach, using a graph-theoretic measure called modularity, has shown that functional networks are more segregated into spatially localized modules during NREM sleep than during wakefulness [9, 14]. While many past studies have focused on the macro/mesoscale properties of networks [9, 11, 14– 26], a crucial aspect that has not been adequately explored is understanding the brain network as a multiscale entity and relating network properties at one spatial scale to those at another [27, 28]. Among different spatial scales, it is evidently important to gain insight into the brain network at the cellular-scale because (1) the neuron is one of the most elementary components of the network [29] and (2) based on single-cell resolution data, it is possible to search for the most relevant functional units, regardless of whether they are single neurons or groups of neurons [30, 31].'],\n",
       "  'qdrant_score': 0.88656616,\n",
       "  'rerank_score': 0.8439433574676514,\n",
       "  'user_score': None,\n",
       "  'blended_score': 0.8439433574676514,\n",
       "  'score': 0.8439433574676514},\n",
       " {'id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'query': 'What are the characteristics, stages, and physiological functions of non-rapid eye movement sleep, as described in scientific publications focusing on sleep physiology and brain activity?',\n",
       "  'query_id': '79b1a1f1c36db196fac6',\n",
       "  'user_id': 'jul',\n",
       "  'notebook_id': 'my-notebook',\n",
       "  'qdrant_model': 'intfloat/multilingual-e5-large-instruct',\n",
       "  'rerank_model': '1-2025-05-18',\n",
       "  'blend_weights': {},\n",
       "  'timestamp': 1748419245.6279957,\n",
       "  'parsed_query': {'query': 'What are the key characteristics, typical stages, and physiological functions of non-rapid eye movement (NREM) sleep, including associated brain activity patterns and neurophysiological mechanisms?',\n",
       "   'authorName': None,\n",
       "   'publicationDate_start': None,\n",
       "   'publicationDate_end': None},\n",
       "  'query_embedding': [],\n",
       "  'paperIdQ': '7742ba48-2026-5af5-b08e-5dc94ad3dff1',\n",
       "  'influentialCitationCount': 0.0,\n",
       "  'publicationDate': '2025-04-25',\n",
       "  'paperId': 'cc1c86ee094940189bf45ecca4014062b4901227',\n",
       "  'authorName': 'M. Uji,Xuemei Li,An Saotome,Ryosuke Katsumata,R. Waggoner,Chisato Suzuki,Kenichi Ueno,Sayaka Aritake,Masako Tamaki',\n",
       "  'venue': 'bioRxiv',\n",
       "  'fieldsOfStudy': 'Biology',\n",
       "  'openAccessPdf': 'https://www.biorxiv.org/content/biorxiv/early/2024/08/30/2024.08.30.610454.full.pdf',\n",
       "  'title': 'Human deep sleep facilitates faster cerebrospinal fluid dynamics linked to brain oscillations for sleep homeostasis and memory',\n",
       "  'main_text': [],\n",
       "  'citationCount': 1,\n",
       "  'abstract': 'How sleep maintains our healthy brain function has remained one of the biggest mysteries in neuroscience, medical settings, and daily lives. While cerebrospinal fluid (CSF) during sleep have been implicated in metabolic waste reduction in animals, how CSF dynamics are driven in the healthy human brain during deep sleep remains elusive. A myriad of research has shown that crucial cognitive processing manifests in slow wave and rapid-eye movement (REM) sleep, suggesting that a key to maintaining brain functions lies in deep sleep. By leveraging a simultaneous sparse-fMRI and polysomnography method, we demonstrate that deep sleep-specific faster CSF dynamics are associated with spontaneous brain oscillations in healthy young human participants. Slow waves and sleep spindles during slow-wave sleep and rapid eye movements and sawtooth waves during rapid eye movement (REM) sleep are tightly linked to low-amplitude faster CSF fluctuations. In contrast, slow waves during light sleep and arousals produced large but slower CSF signal changes. Furthermore, CSF signals are significantly faster in frequency during deep than light sleep. These brain oscillations during light and deep sleep recruited essentially different brain networks, with deep sleep involving memory and homeostatic circuits. Thus, human deep sleep has a unique way of enabling faster CSF dynamics that are distinctive from arousal mechanisms. Significance Statement Sleep is indispensable to our life, but its functions remain a significant mystery in the field of neuroscience. One of the most enigmatic issues in sleep is whether and how sleep regulates the CSF. The present study demonstrates deep sleep-specific faster CSF dynamics time locked to sleep brain oscillations in healthy young human participants. Slow waves and sleep spindles during slow-wave sleep and rapid eye movements and sawtooth waves during REM sleep are tightly linked to CSF fluctuations, contributing to faster CSF signals. Our results consistently demonstrate that human deep sleep has a unique way of enabling faster CSF dynamics that are distinctive from arousal mechanisms.',\n",
       "  'publicationYear': 2025,\n",
       "  'best_chunks': ['Cerebrospinal fluid (CSF) dynamics during sleep have recently been proposed as one of the essential mechanisms for supporting brain functions. Research on animal models has suggested that brain metabolite waste is reduced specifically during sleep5. This process relies on CSF dynamics to wash out metabolic waste from the brain6,7. In rodents, CSF dynamics reach maximum levels during deep nonrapid-eye-movement (NREM) sleep or slow-wave sleep5. Empirical measurements of CSF dynamics during human sleep are scarce, but CSF dynamics during sleep may also play a similar role in humans. One study has shown that CSF tracer molecules are spread out and then cleared from the brain during sleep, whereas sleep deprivation impairs these processes6. Furthermore, sleep quality was also correlated with the amount of clearance8. The current dominant view of CSF regulation during human sleep is the ascending arousal model for CSF dynamics9,10. By measuring functional MRI (fMRI) during light NREM sleep, which comprises the N1 and N2 sleep stages, the slow frequency component (~0.05 Hz) in the CSF signals was found to be stronger during sleep than during wakefulness9–11. This slow frequency component is likely to be produced by K-complexes during light NREM sleep9, which are known to be associated with arousal12–15. However, the type of sleep that has a strong reciprocal relationship with brain health is deep stable sleep, which includes slow-wave sleep and rapid eye movement (REM) sleep. Aging and sleep disorders increase arousal, resulting in decreased deep sleep16,17. Along with evidence showing the roles of slow-wave sleep and REM sleep in memory18– 23, deep sleep stages should play a critical role in both maintaining and facilitating brain functions.'],\n",
       "  'qdrant_score': 0.88526034,\n",
       "  'rerank_score': 0.8437848091125488,\n",
       "  'user_score': None,\n",
       "  'blended_score': 0.8437848091125488,\n",
       "  'score': 0.8437848091125488},\n",
       " {'id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'query': 'What are the characteristics, stages, and physiological functions of non-rapid eye movement sleep, as described in scientific publications focusing on sleep physiology and brain activity?',\n",
       "  'query_id': '79b1a1f1c36db196fac6',\n",
       "  'user_id': 'jul',\n",
       "  'notebook_id': 'my-notebook',\n",
       "  'qdrant_model': 'intfloat/multilingual-e5-large-instruct',\n",
       "  'rerank_model': '1-2025-05-18',\n",
       "  'blend_weights': {},\n",
       "  'timestamp': 1748419245.6279957,\n",
       "  'parsed_query': {'query': 'What are the key characteristics, typical stages, and physiological functions of non-rapid eye movement (NREM) sleep, including associated brain activity patterns and neurophysiological mechanisms?',\n",
       "   'authorName': None,\n",
       "   'publicationDate_start': None,\n",
       "   'publicationDate_end': None},\n",
       "  'query_embedding': [],\n",
       "  'paperIdQ': 'ffe6bda3-500a-5d22-b66e-45b3bd7a5a4b',\n",
       "  'influentialCitationCount': 0.0,\n",
       "  'publicationDate': '2025-03-31',\n",
       "  'paperId': '16b73c560b91b5f55f8338b786745f6b4004013f',\n",
       "  'authorName': 'Adrien Conessa,Damien Léger,Arnaud Boutin',\n",
       "  'venue': 'bioRxiv',\n",
       "  'fieldsOfStudy': 'Biology',\n",
       "  'openAccessPdf': 'https://www.biorxiv.org/content/biorxiv/early/2024/07/26/2024.07.26.605262.full.pdf',\n",
       "  'title': 'Temporal clustering of sleep spindles and coupling with slow oscillations in the consolidation and generalization of motor memory',\n",
       "  'main_text': [],\n",
       "  'citationCount': 0,\n",
       "  'abstract': 'Sleep benefits memory consolidation through periodic sleep spindle activity and associated memory reactivations. Recent evidence highlights that iterative spindle onsets follow two periodic rhythms: an infraslow periodicity (∼0.02 Hz) and a mesoscale periodicity rhythm (∼0.2-0.3 Hz). Consequently, spindles tend to cluster in “trains” on a low-frequency time scale every 50 seconds during which spindles iterate every 3 to 4 seconds. Such temporal organization of spindles in trains is considered a critical sleep mechanism for the timed and repeated reactivation of memories. Additionally, current trends indicate that a timely phase-locking between slow oscillations (SO) and spindles promotes learning-related synaptic plasticity. In this study, we explored how spindle clustering and coupling with SO contribute to motor memory consolidation by inducing a local reduction in synaptic efficacy over sensorimotor cortical regions through upper-limb immobilization after motor sequence learning. We also evaluated memory generalization using two transfer tests designed to assess the ability to transfer or generalize the newly acquired skill to another one (new sequence) or another effector (inter-limb transfer). Our results reveal that the temporal cluster-based organization of spindles is independent of daytime sensorimotor experience, while distinct overnight behavioral outcomes were elicited. Interestingly, immobilization induced a phase shift in the SO-spindle coupling for spindles grouped in trains, but not when isolated outside trains. In addition, the proportion of grouped spindles relative to isolated spindles was positively associated with skill consolidation and negatively correlated with skill generalization following sensorimotor restriction. These results suggest that spindle trains may promote skill-specific strengthening of motor memories, while isolated spindles may instead create memory-instability conditions that facilitate skill generalization.',\n",
       "  'publicationYear': 2025,\n",
       "  'best_chunks': ['Sleep spindle activity is an electrophysiological hallmark of NREM-stage2 (NREM2) sleep involving short (0.3-2 sec) synchronous bursts of waxing and waning 11-16 Hz oscillations8,14,18. Boutin and colleagues (2020)8 recently developed a framework for motor memory consolidation that outlines the essential contribution of the clustering and hierarchical rhythmicity of spindle activity during this sleep-dependent process. More specifically, sleep spindles tend to cluster in ‘trains’ on a low-frequency time scale of approximately 50 seconds (~0.02 Hz infraslow rhythm) during NREM sleep, interspersed with relative spindle-free periods where sporadic isolated spindles may occur. This NREM sleep infraslow periodicity has been considered a crucial neurophysiological regulatory mechanism providing transient temporal windows of optimal neural conditions for the reactivation of memory traces through spindle activity20–22. In addition to the periodic clustering of spindles, recent findings unveiled a recurring pattern where spindles tend to reoccur approximately every 3-4 seconds during trains (~0.2-0.3 Hz mesoscale rhythm). In theory, such inter-spindle intervals during trains represent periods of refractoriness that are assumed to be crucial for the timely and organized segregation of spindle-induced memory reactivations, thus regulating the cyclic interference-free reprocessing of memory traces for efficient memory Accompanying this multi-scale rhythmicity of spindle activity, it has been proposed that cross-frequency coupling and hierarchical nesting of NREM sleep rhythms may be critical for memory consolidation.'],\n",
       "  'qdrant_score': 0.8812914,\n",
       "  'rerank_score': 0.8377442359924316,\n",
       "  'user_score': None,\n",
       "  'blended_score': 0.8377442359924316,\n",
       "  'score': 0.8377442359924316},\n",
       " {'id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82',\n",
       "  'query': 'What are the characteristics, stages, and physiological functions of non-rapid eye movement sleep, as described in scientific publications focusing on sleep physiology and brain activity?',\n",
       "  'query_id': '79b1a1f1c36db196fac6',\n",
       "  'user_id': 'jul',\n",
       "  'notebook_id': 'my-notebook',\n",
       "  'qdrant_model': 'intfloat/multilingual-e5-large-instruct',\n",
       "  'rerank_model': '1-2025-05-18',\n",
       "  'blend_weights': {},\n",
       "  'timestamp': 1748419245.6279957,\n",
       "  'parsed_query': {'query': 'What are the key characteristics, typical stages, and physiological functions of non-rapid eye movement (NREM) sleep, including associated brain activity patterns and neurophysiological mechanisms?',\n",
       "   'authorName': None,\n",
       "   'publicationDate_start': None,\n",
       "   'publicationDate_end': None},\n",
       "  'query_embedding': [],\n",
       "  'paperIdQ': 'f58f48ef-d3ae-5316-a875-f5d68de94a91',\n",
       "  'influentialCitationCount': 0.0,\n",
       "  'publicationDate': '2025-02-27',\n",
       "  'paperId': '6377099c7027244109d5f90ac228f2a7ed2bd43a',\n",
       "  'authorName': 'Aozora Ito,Tohishisa Tanaka',\n",
       "  'venue': 'bioRxiv',\n",
       "  'fieldsOfStudy': 'Computer Science,Biology',\n",
       "  'openAccessPdf': 'https://www.biorxiv.org/content/biorxiv/early/2024/08/06/2024.08.02.606301.full.pdf',\n",
       "  'title': 'SleepSatelightFTC: A Lightweight and Interpretable Deep Learning Model for Single-Channel EEG-Based Sleep Stage Classification',\n",
       "  'main_text': [],\n",
       "  'citationCount': 2,\n",
       "  'abstract': 'None',\n",
       "  'publicationYear': 2025,\n",
       "  'best_chunks': ['Sleep is critical to physical and mental well-being. Like during the awake state, the brain shows characteristic activity during sleep [1]. Sleep progresses through distinct stages, each characterized by specific patterns of brain activity, eye movement, and muscle tone. Understanding the sleep stages is essential for diagnosing and treating various sleep disorders as well as investigating the role of sleep on overall health and disease. Electroencephalography (EEG) is commonly used to investigate brain activ- ity and is necessary for diagnosing sleep-related disorders. In fact, polysomnog- raphy involves simultaneous recordings of various biological signals throughout the night, including EEG, electrooculography, and electromyography signals, aiming to diagnose sleep disorders. Additionally, sleep recordings are essential in routine EEG examinations because they may unveil valuable information for diagnosing epilepsy and other neurological disorders. Based on recorded sig- nals, experts can evaluate the sleep stages in 30 s epochs according to the sleep scoring manual of the American Academy of Sleep Medicine [2]. The manual defines five sleep stages: Wake (W), rapid eye movement (REM or R), non-REM 1 (N1), non-REM 2 (N2), and non-REM 3 (N3). The decision rules to identify the sleep stages are based on temporal and frequency features specific to each stage in the acquired biological signals. In addition, some sleep stages can be determined by considering context from adjacent stages. Manual sleep scoring is time-consuming and labor-intensive for knowledge- able and experienced experts [3]. Even a skilled expert can take up to 2 hours to score approximately 8 hours of sleep data [4].'],\n",
       "  'qdrant_score': 0.8818108,\n",
       "  'rerank_score': 0.8353881239891052,\n",
       "  'user_score': None,\n",
       "  'blended_score': 0.8353881239891052,\n",
       "  'score': 0.8353881239891052}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(f\"{API_URL}/notebook/{task_id}/chat/final\").json()\n",
    "res['papers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffa3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 5512607f33f02b67101c0bebe84b336cc8cae03f\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/11/2024.08.11.607487.full.pdf\n",
      "  TITLE: AmygdalaGo-BOLT: an open and reliable AI tool to trace boundaries of human amygdala\n",
      "  AUTHORS: Quan Zhou,Bo Dong,Peng Gao,Jintao Wei,Jiale Xiao,Wei Wang,Peipeng Liang,Danhua Lin,Xiaoli Zuo,Hongjian He\n",
      "  PUBLICATION DATE: 2025-05-13\n",
      "  EXCERPT: 'AmygdalaGo-BOLT3D: A boundary learning transformer for tracing human amygdala 1Center for Brain Imaging Science and Technology, Zhejiang University, Hangzhou, 310027, Zhejiang, China. 2College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, 310027, China. 3State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, 100875, China. 4Faculty of Psychology, Beijing Normal University, Beijing, 100875, Beijing, China. 5School of Psychology, Capital Normal University, Beijing, 100190, China. 6School of Physics, Zhejiang University, Hangzhou, 310058, Zhejiang, China. 7State Key Laboratory of Brain-Machine Intelligence, Zhejiang University, Hangzhou, 310058, Zhejiang, China. 8Developmental Population Neuroscience Research Center, IDG/McGovern Institute for Brain Research, Beijing Normal University, Beijing, 100875, China. 9National Basic Science Data Center, Beijing, 100190, China. 10Developmental Population Neuroscience Research Base for Education, Nanning Normal University, Nanning, 530001, China. *Corresponding author(s). E-mail(s): hhezju@zju.edu.cn; xinian.zuo@bnu.edu.cn; †These authors contributed equally to this work. The amygdala is indispensable for mood regulation, cognitive learning, and memory consolidation, and has been closely associated with behavioral pathologies, particularly during critical stages of socio-emotional maturation such as childhood and adoles- cence (Sammallahti et al, 2023; Chai et al, 2023; Par ́e and Headley, 2023).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: c49d611c1f405e4231faf69edeafdf8240ed8cc8\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/11/2024.08.11.607487.full.pdf\n",
      "  TITLE: AmygdalaGo-BOLT3D: A fast and valid transformer tracing boundaries of amygdala from brain images\n",
      "  AUTHORS: Bo Dong,Quan Zhou,Peng Gao,Jintao Wei,Jiale Xiao,Wei Wang,Peipeng Liang,Danhua Lin,Hongjian He,Xiaoli Zuo\n",
      "  PUBLICATION DATE: 2025-03-16\n",
      "  EXCERPT: 'AmygdalaGo-BOLT3D: A boundary learning transformer for tracing human amygdala 1Center for Brain Imaging Science and Technology, Zhejiang University, Hangzhou, 310027, Zhejiang, China. 2College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, 310027, China. 3State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, 100875, China. 4Faculty of Psychology, Beijing Normal University, Beijing, 100875, Beijing, China. 5School of Psychology, Capital Normal University, Beijing, 100190, China. 6School of Physics, Zhejiang University, Hangzhou, 310058, Zhejiang, China. 7State Key Laboratory of Brain-Machine Intelligence, Zhejiang University, Hangzhou, 310058, Zhejiang, China. 8Developmental Population Neuroscience Research Center, IDG/McGovern Institute for Brain Research, Beijing Normal University, Beijing, 100875, China. 9National Basic Science Data Center, Beijing, 100190, China. 10Developmental Population Neuroscience Research Base for Education, Nanning Normal University, Nanning, 530001, China. *Corresponding author(s). E-mail(s): hhezju@zju.edu.cn; xinian.zuo@bnu.edu.cn; †These authors contributed equally to this work. The amygdala is indispensable for mood regulation, cognitive learning, and memory consolidation, and has been closely associated with behavioral pathologies, particularly during critical stages of socio-emotional maturation such as childhood and adoles- cence (Sammallahti et al, 2023; Chai et al, 2023; Par ́e and Headley, 2023).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/16/2024.10.14.618356.full.pdf\n",
      "  TITLE: A top-down insular cortex circuit crucial for non-nociceptive fear learning\n",
      "  AUTHORS: Junho Han,Boin Suh,Jin-Hee Han\n",
      "  PUBLICATION DATE: 2025-03-06\n",
      "  EXCERPT: 'Early lesion studies showed that regions such as the basolateral amygdala (BLA) (39) and ventral hippocampus (vHPC) (40), which are involved in shock conditioning, are also required for predator odor-induced fear learning. Additionally, the medial amygdala (MeA) (41), which is not involved in shock conditioning, was identified as a novel component of the fear learning in this context. Recent research using muscimol inactivation indicates that the posterior insular cortex (pIC) is crucial for both the formation and recall of predator odor-induced contextual fear memories (42) The insular cortex has been associated with processing negative emotions and cognitive information related to fear, anxiety, and disgust (11, 43). Animal studies have demonstrated that optogenetic activation of pIC induces an aversive state in mice (44) and insular cortex activity is crucial for the maintenance of learned fear (45). In humans, the affective and social pain correlates with activity in the ACC and insular (11, 46, 47). Also, in a fear learning using aversive pictures as US, the insular cortex shows increased activation when exposed to both the aversive picture and the CS (48, 49). Moreover, lesions in the insular cortex can result in pain asymbolia (50), where pain sensation is present but the unpleasantness is not perceived. These findings suggest that the insular cortex plays a crucial role in representing negative emotions and affect rather than processing somatosensory information related to nociception. Notably, the insular cortex has substantial reciprocal connections with the PBN (51, 52). The insular cortex may convey affective information to the PBN.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 8f213bf668b4bce273b7e0e000da41ff790bb1a8\n",
      "- PDF URL: https://www.researchsquare.com/article/rs-3939709/latest.pdf\n",
      "  TITLE: Tac1-expressing neurons in the central amygdala predominantly mediate histamine-induced itch by receiving inputs from parabrachial Tac1-expressing neurons\n",
      "  AUTHORS: Yingning Zhang,Sujuan Shi,E. Mao,Yuling Chen,Jing Chen,Miao Tian,Fensheng Huang,Zhiping Cai,Yunqing Li,Zhenzhen Kou\n",
      "  PUBLICATION DATE: 2025-02-01\n",
      "  EXCERPT: 'The central amygdala (CeA) is a critical part of the amygdala and is primarily composed of gamma-aminobutyric acid-ergic (GABAergic) medium-spiny neurons [14]. Anatomically, the structure of the CeA is divided into three parts: medial (CeM), lateral (CeL), and pericentral (CeC) [15–18]. Research has shown that Tac1+ neurons are also expressed in the CeA [19]. However, little was known about the role of CeATac1 neurons in itch. Both the PBN and CeA can be signicantly activated by itch stimuli [20, 21]. Studies have shown that the majority of PBNCGRP neurons co-express Tac1, can be activated by itch stimuli and project their axons mainly to the CeA [5, 10]. Therefore, these Tac1+ neurons located in the PBN might project to the CeA and be involved in the transmission of itch. Therefore, we hypothesized that PBNTac1 neurons project to the CeA, and it is possible that CeATac1 neurons may be involved in the sensation of itch. We used morphological, behavioral, and chemogenetic approaches to investigate the role of the PBN-CeA pathway on itch regulation and to differentiate between various types of itch. This study was approved by the Ethics Committee of the Laboratory Animal Center at the Fourth Military Medical University. Mice were housed in a 12 h light/dark cycle (7 a.m. to 7 p.m.) with free access to water and food. The mice were kept at optimal temperatures (22–26°C) and humidity levels (40–70%), with no more than six mice in each cage. Adult male wild-type (WT) C57BL/6J mice were purchased from the Laboratory Animal Center of the Fourth Military Medical University.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf\n",
      "  TITLE: Representation of sex-specific social memory in ventral CA1 neurons\n",
      "  AUTHORS: Akiyuki Watarai,Kentaro Tao,T. Okuyama\n",
      "  PUBLICATION DATE: 2025-02-15\n",
      "  EXCERPT: 'We found that neurons in the ventral CA1 region (vCA1) of the mouse hippocampus encoded the identities and social properties, specifically sex and strain, of familiar conspecifics by using both rate and theta-based temporal coding. Optogenetic reactivation of social memories of females, but not males, induced place preference. Ablation of the upstream medial amygdala (MeA) or the hippocampal dorsal CA2 region (dCA2) disrupted the representation of sex and the sexual dimorphism of social memory valence. Selective reactivation of overlapping neural populations of distinct female social memories representing the female sex was sufficient to induce preference. Thus, vCA1 neurons employ dual coding schemes to represent the identities and social properties of familiar conspecifics as a cohesive memory. Social memory in the mouse ventral hippocampus maps the identities and social properties of familiar conspecifics. The hippocampus plays a crucial role in the integration of multimodal information into a conceptualized cognitive map, which is fundamental for recalling specific experiences and guiding behaviors (1). Social memory is a key component of episodic or declarative memory, which enables the recognition of familiar individuals. Extensive animal studies, particularly using rodent models, have underscored the crucial role of the hippocampus in processing social memory. Located along the hippocampal septotemporal axis, the dorsal CA2 region (dCA2) specializes in encoding social stimuli (2, 3), whereas the ventral CA1 region (vCA1), which receives projections from the dCA2 (4), is responsible for storing memories of familiar conspecifics (5) through the temporal coordination of neuronal population activities (6). Notably, a recent study of rats revealed that neuronal responses in the vCA1 to familiar conspecifics showed greater variability among individual females than the responses among males (7), and this suggested a potential sexually dimorphic component in hippocampal social memory.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " What is the role of the amygdala?\n",
      "\n",
      "🤖[asXai]\n",
      " The amygdala plays a crucial role in processing emotions, particularly fear and aggression, and in forming emotional memories. It's involved in rapidly assessing the emotional significance of stimuli and triggering physiological responses associated with those emotions. It also contributes to learning through emotional conditioning.The amygdala plays a crucial role in several functions, including mood regulation, cognitive learning, and memory consolidation. It's also closely associated with behavioral pathologies, particularly during critical stages of socio-emotional maturation. (ARTICLE ID: 5512607f33f02b67101c0bebe84b336cc8cae03f, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/11/2024.08.11.607487.full.pdf; ARTICLE ID: c49d611c1f405e4231faf69edeafdf8240ed8cc8, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/11/2024.08.11.607487.full.pdf).\n",
      "\n",
      "Specifically, the central amygdala (CeA) is a critical part of the amygdala and is primarily composed of gamma-aminobutyric acid-ergic (GABAergic) medium-spiny neurons (ARTICLE ID: 8f213bf668b4bce273b7e0e000da41ff790bb1a8, PDF URL: https://www.researchsquare.com/article/rs-3939709/latest.pdf). The medial amygdala (MeA) is involved in fear learning (ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/16/2024.10.14.618356.full.pdf).\n",
      "\n",
      "\n",
      "\n",
      "**No information was found in the article database. This response is all based on my previous knowledge**\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf\n",
      "  TITLE: Representation of sex-specific social memory in ventral CA1 neurons\n",
      "  AUTHORS: Akiyuki Watarai,Kentaro Tao,T. Okuyama\n",
      "  PUBLICATION DATE: 2025-02-15\n",
      "  EXCERPT: 'We found that neurons in the ventral CA1 region (vCA1) of the mouse hippocampus encoded the identities and social properties, specifically sex and strain, of familiar conspecifics by using both rate and theta-based temporal coding. Optogenetic reactivation of social memories of females, but not males, induced place preference. Ablation of the upstream medial amygdala (MeA) or the hippocampal dorsal CA2 region (dCA2) disrupted the representation of sex and the sexual dimorphism of social memory valence. Selective reactivation of overlapping neural populations of distinct female social memories representing the female sex was sufficient to induce preference. Thus, vCA1 neurons employ dual coding schemes to represent the identities and social properties of familiar conspecifics as a cohesive memory. Social memory in the mouse ventral hippocampus maps the identities and social properties of familiar conspecifics. The hippocampus plays a crucial role in the integration of multimodal information into a conceptualized cognitive map, which is fundamental for recalling specific experiences and guiding behaviors (1). Social memory is a key component of episodic or declarative memory, which enables the recognition of familiar individuals. Extensive animal studies, particularly using rodent models, have underscored the crucial role of the hippocampus in processing social memory. Located along the hippocampal septotemporal axis, the dorsal CA2 region (dCA2) specializes in encoding social stimuli (2, 3), whereas the ventral CA1 region (vCA1), which receives projections from the dCA2 (4), is responsible for storing memories of familiar conspecifics (5) through the temporal coordination of neuronal population activities (6). Notably, a recent study of rats revealed that neuronal responses in the vCA1 to familiar conspecifics showed greater variability among individual females than the responses among males (7), and this suggested a potential sexually dimorphic component in hippocampal social memory.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf\n",
      "  TITLE: Dorso-ventral hippocampus neural assemblies reactivate during sleep following an aversive experience\n",
      "  AUTHORS: JF Morici,I. Paiva-Lima,A. Silva,É. Pronier,G. Girardeau\n",
      "  PUBLICATION DATE: 2025-04-25\n",
      "  EXCERPT: 'The hippocampal formation is heterogeneous; the dHPC processes mostly contextual information, while the ventral part (vHPC) encodes valence and anxiety. We propose that dorsal- ventral communication during sleep is involved in the consolidation of emotional memories, potentially integrating or segregating contextual and valence information. To test this, we recorded the electrophysiological activity in the dHPC and vHPC in rats during reward and aversion-motivated exploration of a linear track and subsequent sleep. We detected dorsal and ventral SWRs during NREM sleep as well as neuronal assemblies during each exploration type and identified dorsal, ventral, and joint (dorso-ventral) assemblies. We found that dorso-ventral hippocampal coordination involves coordinated ripples and bursts of ripples. Aversive joint assemblies exhibited higher reactivation during non-REM sleep than the joint assemblies from the reward condition. Interestingly, joint aversive assemblies reactivated selectively during dorso-ventral coordinated ripples. Furthermore, their reactivation strength positively correlated with their strength of activation during the task. These results suggest the existence of dorsal-ventral hippocampal functional communication capable of sustaining the selective reactivation of experiences based on their emotional valence. Episodic memory is supported by the hippocampus, a heterogeneous brain structure with distinct functional and anatomical properties along its dorsoventral axis (Fanselow and Dong 2010; Bannerman et al. 2004; Strange et al. 2014). The dorsal hippocampus (dHPC) encodes spatial representations of the environment through the activity of place cells, which code for specific locations called place fields (O’Keefe 1976; M. a Wilson and McNaughton 1993).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf\n",
      "  TITLE: Memory System Maladaptation Impairs CA1-Dependent Temporal Binding and Declarative Memory in the Cntnap2 Knockout Mouse Model of Autism\n",
      "  AUTHORS: E. C. Rawlinson,Michael H. McCullough,A. Sellami,A. Marighetto,A. S. Al Abed,N. Dehorter\n",
      "  PUBLICATION DATE: 2025-01-02\n",
      "  EXCERPT: 'While most research in autism has focused on the dysregulation of the prefrontal cortex and the basal ganglia, recent studies have highlighted that hippocampal disruption are key in the pathophysiology of ASD (Banker et al.,2021) Yet, how hippocampal subfield activity, such as the dorsal CA1 (dCA1), drives episodic memory atypicalities in ASD is currently unknown. Here, we aimed to dissect declarative memory atypicality and the role of the dCA1-dependent processing in related cognitive deficits in ASD. We used the Cntnap2 knock out (KO) mouse model of ASD, that exhibits autism-like phenotypes, including social behavior deficits, hyperactivity, and seizures (Peñagarikano et al., 2011; Peñagarikano & Geschwind, 2012). We demonstrate that Cntnap2 KO mice present with reduction of temporal binding capabilities and dCA1 activation during temporal binding-dependent memory tasks, which support deficits in declarative memory. Cntnap2 KO mice demonstrate reduced temporal binding capability. The capacity to bridge temporally distant events, called temporal binding, is critical to enable declarative memory formation (Sellami et al., 2017). To test this elemental process, we tested Cntnap2 KO mouse model in the trace fear conditioning paradigm (TFC; Fig. 1A). In this paradigm, mice are required to associate a tone (Conditioned Stimulus) with a mild electric foot-shock (Unconditioned Stimulus), separated by a time interval (i.e. Trace, (Sellami et al., 2017)). In the first step, the conditioning, independent groups of mice were exposed to three tone-shock pairings separated by time intervals between 5 and 60 sec (i.e.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: df41c731980e045f18ac37d883bf278834aa3826\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/07/25/2024.07.24.605041.full.pdf\n",
      "  TITLE: Differential Reactivation of Task-Demand-Associated Firing Patterns in Subicular and CA1 Place Cells during a Hippocampal Memory Task\n",
      "  AUTHORS: Jae-Min Seol,Su-Min Lee,Inah Lee\n",
      "  PUBLICATION DATE: 2025-01-14\n",
      "  EXCERPT: 'campus is pivotal for memory consolidation, yet the SWR dynamics between the hippocampus and its neighboring subiculum remain underexplored. This study examined the differential SWR-associated reactivations of task- demand-associated representations in the subiculum and CA1 during a visual scene memory task in rats. In the task, the spiking activities of place-cell ensembles were reactivated during a SWR event according to task demands. These reactivations were more frequent and associated with more heterogeneous task-demand types in the subiculum compared to CA1. These subicular characteristics were driven by multiple subfields within the subicular place field, parcellated by the theta phase precession cycle. In contrast, CA1 exhibited a higher incidence of spatial replay than the subiculum. These findings indicate that the subiculum plays a key role in transmitting task- specific variables from the hippocampus to other brain regions. The subiculum more frequently and dynamically reactivates the neural representations linked to task demands than the hippocampal CA1. Episodic memory involves the recollection of events within a spatial context. Such memories comprise not only the locations where events occurred but also encompass other related elements such as objects and background contexts. It has been widely postulated that the hippocampus is vital for both the formation and retrieval of these event memories (1,2). Additionally, research indicates that the consolidation of event memory requires specific physiological mechanisms in the hippocampus, particularly sharp wave ripples (SWRs), which are believed to play a crucial role during the process of memory consolidation in learning (3-5).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 998f666db5925020bb18605791bf2d9ac4d0fa7e\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/03/2024.07.31.605652.full.pdf\n",
      "  TITLE: Integration of sensory and fear memories in the rat medial temporal lobe\n",
      "  AUTHORS: F. Wong,Alina B. Thomas,Simon Killcross,Vincent Laurent,Fredrick R. Westbrook,Nathan M. Holmes\n",
      "  PUBLICATION DATE: 2025-01-09\n",
      "  EXCERPT: 'TITLE: Integration of sensory and fear memories in the rat medial temporal lobe: advancing research by Wong et al. (2019). AUTHORS: Francesca S. Wong, Alina B. Thomas, Simon Killcross, Vincent Laurent, R. Frederick Westbrook & Nathan M. Holmes AUTHOR AFFILIATION: School of Psychology, University of New South Wales, Wong et al. (2019) used a sensory preconditioning protocol to examine how sensory and fear memories are integrated in the rat medial temporal lobe. In this protocol, rats integrate a sound-light (sensory) memory that forms in stage 1 with a light-shock (fear) memory that forms in stage 2 to generate fear responses (freezing) across test presentations of the sound in stage 3. Here, we advance this research by showing that: 1) how/when rats integrate the sound-light and light-shock memories (online in stage 2 or at test in stage 3) changes with the number of sound-light pairings in stage 1; and 2) regardless of how/when it occurs, the integration requires communication between two regions of the medial temporal lobe: the perirhinal cortex and basolateral amygdala complex. Thus, “event familiarity” determines how/when sensory and fear memories are integrated but not the circuitry by which the integration occurs: this remains the same. Memory is the means by which the past connects with the present to guide our future interactions with the environment. One of the ways it achieves this feat is by integrating the sensory and emotional elements of experiences that are separated in time (e.g., experiences that occur days, weeks or months apart). This allows people and animals to better anticipate and react to different types of situations.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " How neural assemblies on ventral and dorsal hippocampus relate to aversive experiences?\n",
      "\n",
      "🤖[asXai]\n",
      " Neural assemblies in the dorsal CA2 region of the hippocampus are involved in encoding social stimuli, while the ventral CA1 region stores memories of familiar conspecifics. Ablation of the hippocampal dorsal CA2 region disrupted the representation of sex and the sexual dimorphism of social memory valence (ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf). Furthermore, neurons in the ventral CA1 region encoded the identities and social properties, specifically sex and strain, of familiar conspecifics by using both rate and theta-based temporal coding (ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf).Neural assemblies in both the dorsal and ventral hippocampus play distinct roles in relation to aversive experiences, particularly during sleep. Here's a breakdown based on the provided articles:\n",
      "\n",
      "**Dorsal Hippocampus (dHPC):**\n",
      "\n",
      "*   **Contextual Information:** The dHPC primarily processes contextual information. (ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf)\n",
      "*   **Aversive Joint Assemblies:** During sleep following aversive experiences, dorsal-ventral hippocampal coordinated ripples lead to the reactivation of aversive joint assemblies. These assemblies exhibit higher reactivation during non-REM sleep than reward-related assemblies. Their reactivation strength correlates positively with their activation strength during the task. (ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf)\n",
      "\n",
      "**Ventral Hippocampus (vHPC):**\n",
      "\n",
      "*   **Task-Specific Variables:** The subiculum, a part of the vHPC, plays a key role in transmitting task-specific variables from the hippocampus to other brain regions. It more frequently and dynamically reactivates representations linked to task demands compared to the dHPC. (ARTICLE ID: df41c731980e045f18ac37d883bf278834aa3826, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/07/25/2024.07.24.605041.full.pdf)\n",
      "*   **Sensory and Fear Memories:** Wong et al. (2019) demonstrated that sensory and fear memories are integrated in the vHPC, allowing for the generation of fear responses to previously neutral stimuli. (ARTICLE ID: 998f666db5925020bb18605791bf2d9ac4d0fa7e, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/03/2024.07.31.605652.full.pdf)\n",
      "\n",
      "\n",
      "\n",
      "**Relationship:** The dorsal and ventral hippocampus work together during sleep to consolidate aversive memories. The dHPC processes the context of the experience, while the vHPC integrates sensory and fear components, allowing for the generation of conditioned fear responses. The coordinated ripples during sleep facilitate this integration and transfer of information.\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(f\"{API_URL}/notebook/{task_id}/history\").json()\n",
    "chat_history = res\n",
    "for msg in chat_history:\n",
    "    if msg['role'] == 'user':\n",
    "        print(f\"\\n🧑[You]\\n\", msg[\"content\"])\n",
    "    elif msg['role'] == 'assistant':\n",
    "        print(\"\\n🤖[asXai]\\n\", msg[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asxai.services.chat.chat_api import app\n",
    "from asxai.services.chat.chat_workers import start_chat_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import uvicorn\n",
    "\n",
    "def start_chat_api():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8100, reload=False)\n",
    "\n",
    "api_thread = threading.Thread(target=start_chat_api, daemon=True)\n",
    "api_thread.start()\n",
    "print(\"Chat API started on http://127.0.0.1:8100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5197f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_thread = start_chat_worker()\n",
    "print(\"Chat worker started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae55675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 5c022ffb48a537cbf1e0/47f210eacb89414efd82\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sseclient\n",
    "\n",
    "# Input data\n",
    "base_url = \"http://127.0.0.1:8100\"\n",
    "user_id = \"jul\"\n",
    "notebook_id = \"my-notebook\"\n",
    "instruct_msg = \" If you can't find an accurate answer to this question in the context of the conversation, \\\n",
    "     expand the question by rephrasing it in a more descriptive and complete sentence, \\\n",
    "     suitable for retrieving relevant scientific documents. Correct any spelling mistake when necessary. \\\n",
    "     Do not return anything else than just ASK_QDRANT: <query> where ,<query> is the expanded query\"\n",
    "message = \"Using information from all 10 articles provided above — not just one — summarize how the amygdala interacts with the hippocampus.\"\n",
    "message = \"What is the main conclusion of article #9?\"\n",
    "message = \"what type of recording technique do they use in article #7?\"\n",
    "message = \"how does the amygdala interacts with the hippocampus?\"\n",
    "message = \"how do ventral and dorsal hippocampus contributes to emotional memory encoding?\"\n",
    "# message = \"what is the role of the amygdala according to Girardeau as from her papers published between 2023 and 2025?\"\n",
    "# message = \"Does the cerebellum influence spatial coding in the hippocampus?\"\n",
    "# message = \"Is there any connection between the piriform cortex and the hippocampus?\"\n",
    "# message = \"is this connection direct?\"\n",
    "# message = \"is the visual cortex one of these intermediate structure?\"\n",
    "# message = \"ok but so the visual cortex is not involved then\"\n",
    "# message = \"Which intermediate structure are involved??\"\n",
    "# message = \"what is the text from the article that you provided which backup this fact?\"\n",
    "# message = \"but there is no mention of visual cortex in this sentence\"\n",
    "# message = \"is PCx also connected to the visual cortex?\"\n",
    "# message = \"is there any link between cerebellum and navigation?\"\n",
    "# message = \"is the connection from hippocampus to cerebellum direct?\"\n",
    "# message = \"what is nuclear fusion?\"\n",
    "# message = \"Do they show neural assemblies?\"\n",
    "# message = \"Can you summarize this article for me?\"\n",
    "# message = \"How to identify boundaries of the amygdala in MRI scans?\"\n",
    "# message = \"I'm looking for an article entitled: Dorso-ventral hippocampal neural assemblies are preferentially reactivated during NREM sleep following an aversive experience. \\\n",
    "#     Run a search and summarize it for me\"\n",
    "# message = \"Run a search and summarize it again\"\n",
    "# message = \"Can you make a longer, structured summary please?\"\n",
    "# message = \"Reformulate the question into a context rich query to search through the QDRANT database. \\\n",
    "#            Return the results as a dictionnary with the reformulated query and the references of the articles we should search into in the following fields:\\\n",
    "#             \\\"qdrant_query\\\" \\\"article_refs\\\"\\\n",
    "#             If you can't find any relevant article reference in the conversation context, fill that field with 'null'.\"\n",
    "# message = \"How to identify the boundaries of the amygdala in MRI scans?\"\n",
    "# message = \"what is nuclear fusion?\"\n",
    "model = 'gemma3:12b'#'deepseek-r1:32b' #\n",
    "\n",
    "res = requests.get(f\"{base_url}/notebook/task_id\", params={\n",
    "    \"user_id\": user_id,\n",
    "    \"notebook_id\": notebook_id\n",
    "})\n",
    "task_id = res.json()[\"task_id\"]\n",
    "print(\"Task ID:\", task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e3787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992e6674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat submitted: {'status': 'submitted', 'task_id': '5c022ffb48a537cbf1e0/47f210eacb89414efd82'}\n"
     ]
    }
   ],
   "source": [
    "res = requests.post(f\"{base_url}/notebook/{task_id}/chat\", json={\n",
    "    \"message\": message,\n",
    "    \"user_id\": user_id,\n",
    "    \"notebook_id\": notebook_id,\n",
    "    \"model\": model\n",
    "})\n",
    "print(\"Chat submitted:\", res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee701f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📡 Streaming response:\n",
      "\n",
      "\n",
      "🧑[You]:\n",
      "\n",
      "how do ventral and dorsal hippocampus contributes to emotional memory encoding?\n",
      "\n",
      "🤖[asXai]\n",
      "\n",
      "How do the ventral and dorsal hippocampus differentially contribute to the encoding of emotional memories\n",
      ", specifically concerning contextual and valence information?\n",
      "\n",
      "SEARCHING: \"hippocampal subregion ventral\n",
      "dorsal emotional memory encoding context valence\"\n",
      "<SEARCHING>\n",
      "Here's a summary of how the ventral and dorsal hippocampus contribute to emotional memory encoding, based\n",
      "on the provided articles:\n",
      "\n",
      "**Ventral and Dorsal Hippocampus and Emotional Memory**\n",
      "\n",
      "The provided articles\n",
      "highlight a specialized division of labor within the hippocampus regarding emotional memory encoding\n",
      ". Here's a breakdown:\n",
      "\n",
      "*   **Dorsal Hippocampus (dHPC):** Primarily processes contextual information and\n",
      "spatial representations of the environment through place cells. (ARTICLE ID: ad68b16410200b91448dc2bc\n",
      "40656db3dab519de, PDF URL: [https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.59891\n",
      "8.full.pdf](https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf))\n",
      "*\n",
      "**Ventral Hippocampus (vHPC):**  Encodes valence (emotional significance) and anxiety. It's involved in\n",
      "storing memories of familiar conspecifics and their social properties, including sex and strain. (ARTICLE\n",
      "ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b, PDF URL: [https://www.biorxiv.org/content/biorxiv/early\n",
      "/2024/04/02/2024.04.01.587523.full.pdf](https://www.biorxiv.org/content/biorxiv/early/2024/04/01.5875\n",
      "23.full.pdf))\n",
      "*   **Dorso-Ventral Communication:**  There's evidence of communication between the dorsal\n",
      "and ventral hippocampus during sleep, which is proposed to be involved in the consolidation of emotional\n",
      "memories.  Aversive joint assemblies (those representing aversive experiences) exhibit higher reactivation\n",
      "during non-REM sleep than those from reward conditions.  This reactivation is linked to coordinated ripples\n",
      "and bursts of ripples. (ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de, PDF URL: [https://www.\n",
      "biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf](https://www.biorxiv.org/content\n",
      "/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf))\n",
      "\n",
      "\n",
      "\n",
      "I hope this helps!\n",
      "<END_OF_MESSAGE>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1748351648.771|FAIL|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator: localhost:29092: Disconnected (after 7948948ms in state UP)\n",
      "%6|1748351648.771|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected (after 7948901ms in state UP)\n",
      "%6|1748351648.772|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY)\n",
      "%6|1748351648.772|FAIL|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator: localhost:29092: Disconnected (after 0ms in state APIVERSION_QUERY, 1 identical error(s) suppressed)\n",
      "%6|1748351648.825|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY)\n",
      "%6|1748351648.978|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY, 1 identical error(s) suppressed)\n",
      "%6|1748351648.983|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY, 1 identical error(s) suppressed)\n",
      "%6|1748351649.859|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY)\n",
      "%6|1748351649.959|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY)\n",
      "%6|1748351650.115|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY, 1 identical error(s) suppressed)\n",
      "%6|1748351650.146|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY, 1 identical error(s) suppressed)\n",
      "%3|1748351653.014|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1748351653.665|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1748351653.969|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1748351654.045|FAIL|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator: localhost:29092: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1748351654.685|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1748351679.026|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 507 identical error(s) suppressed)\n",
      "%3|1748351680.606|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 3 identical error(s) suppressed)\n",
      "%3|1748351680.671|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 13 identical error(s) suppressed)\n",
      "%3|1748351680.754|FAIL|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator: localhost:29092: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 3 identical error(s) suppressed)\n",
      "%3|1748351685.674|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 16 identical error(s) suppressed)\n",
      "%4|1748351692.899|SESSTMOUT|rdkafka#consumer-4| [thrd:main]: Consumer group session timed out (in join-state steady) after 45018 ms without a successful response from the group coordinator (broker 1, last error was Success): revoking assignment and rejoining group\n",
      "%3|1748351709.027|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 472 identical error(s) suppressed)\n",
      "%3|1748351710.616|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 131 identical error(s) suppressed)\n",
      "%3|1748351711.684|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Connect to ipv4#127.0.0.1:29092 failed: Connection refused (after 0ms in state CONNECT, 16 identical error(s) suppressed)\n",
      "%6|1748351712.613|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY)\n",
      "%6|1748351712.664|FAIL|rdkafka#consumer-4| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY)\n",
      "%6|1748351712.685|FAIL|rdkafka#producer-1| [thrd:localhost:29092/bootstrap]: localhost:29092/bootstrap: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY)\n",
      "%6|1748351712.736|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 0ms in state APIVERSION_QUERY)\n",
      "%6|1748351717.126|FAIL|rdkafka#producer-1| [thrd:localhost:29092/1]: localhost:29092/1: Disconnected while requesting ApiVersion: might be caused by incorrect security.protocol configuration (connecting to a SSL listener?) or broker version is < 0.10 (see api.version.request) (after 1ms in state APIVERSION_QUERY, 3 identical error(s) suppressed)\n",
      "%6|1748351718.227|FAIL|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator: localhost:29092: Disconnected (after 1ms in state APIVERSION_QUERY)\n",
      "%5|1748351732.548|PARTCNT|rdkafka#consumer-4| [thrd:main]: Topic notebook-requests partition count changed from 1 to 0\n",
      "%4|1748351732.548|CLUSTERID|rdkafka#consumer-4| [thrd:main]: Broker GroupCoordinator/1 reports different ClusterId \"FOK5tf_kQzSw5z61peq7xg\" than previously known \"o_J_AQM9TWGqkWz3YSUcsg\": a client must not be simultaneously connected to multiple clusters\n",
      "%4|1748351799.517|CLUSTERID|rdkafka#producer-1| [thrd:main]: Broker localhost:29092/1 reports different ClusterId \"FOK5tf_kQzSw5z61peq7xg\" than previously known \"o_J_AQM9TWGqkWz3YSUcsg\": a client must not be simultaneously connected to multiple clusters\n"
     ]
    }
   ],
   "source": [
    "# Stream response\n",
    "stream_response = requests.get(f\"{base_url}/notebook/{task_id}/stream\", stream=True)\n",
    "client = sseclient.SSEClient(stream_response)\n",
    "\n",
    "print(\"\\n📡 Streaming response:\\n\")\n",
    "for event in client.events():\n",
    "    print(event.data, end=\"\\n\", flush=True)\n",
    "    if \"<END_OF_MESSAGE>\" in event.data:\n",
    "        print(\" \")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf55c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 'hippocampus cerebellar connectionspathways indirect routes'\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"he connection from the hippocampus to the cerebellum is indirect. While there isn't a direct, monosynaptic\\\n",
    "projection, the hippocampus influences cerebellar function via several intermediary structures, primarily\\\n",
    "through the entorhinal cortex and the pontine nuclei.\\\n",
    "SEARCHING: 'hippocampus cerebellar connections\\\n",
    "pathways indirect routes'\"\n",
    "s.split('SEARCHING:', 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f2f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧑[You]\n",
      " how does the amygdala interacts with the hippocampus?\n",
      "\n",
      "🤖[asXai]\n",
      " This article **does not discuss the interaction between the amygdala and the hippocampus.** It focuses specifically on the piriform cortex (PCx), lateral entorhinal cortex (LEC), and hippocampus, and their roles in encoding odor and place information.\n",
      "\n",
      "\n",
      "\n",
      "Therefore, the provided text offers no information about the amygdala's involvement.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.get(f\"{base_url}/notebook/{task_id}/chat/final\")\n",
    "print(f\"\\n🧑[You]\\n\", res.json()[\"user\"])\n",
    "print(\"\\n🤖[asXai]\\n\", res.json()[\"assistant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da8aa584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 3dbeea89304fbd0f4e718c6c8df2a1a0fdcc144a\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/05/10/2024.05.10.593498.full.pdf\n",
      "  TITLE: Evidence of spatial periodic firing in the subiculum of mice\n",
      "  AUTHORS: P. Abad-Perez,R. Scott,V. Borrell,L. Martínez-Otero,J. R. Brotons-Mas\n",
      "MOST RELEVANT EXCERPT: 'Introduction Since the discovery of hippocampal place cells -neurons that code for space being active in specific locations of the environment (O’Keefe and Dostrovsky, 1971)- multiple efforts have aimed to understand the computational bases of spatial navigation. As result, different types of spatially modulated neurons have been described across brain regions: head direction cells, (HD); border and boundary vector cells (BVC), coding for the geometry of the environment in medial entorhinal cortex (MEC) and the SUB; and grid cells (GC) in the medial entorhinal cortex (MEC) (Taube et al., 1990; Sharp and Green, 1994; Hafting et al., 2005; Fyhn et al., 2008; Solstad et al., 2008; Lever et al., 2009; Brotons-Mas et al., 2017a). These neurons are either strongly involved in the codification of external information, such as BVC coding for geometry, or in egocentric related information. This is the case of GC, which tessellating regular firing was related with the representation of the metrics of space and therefore necessary for path integration, the capability of navigate in the absence of external cues (McNaughton et al., 2006). The integration of both streams of information, allocentric and egocentric, is instrumental for the generation of an efficient spatial representation. Multiple computational models have aimed to unveil the possible mechanisms underlying the integration of these different types of spatial signals.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 22e4c57aec231f8692b333d10f9a856641580324\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2023/10/08/2023.10.05.561119.full.pdf\n",
      "  TITLE: Differential encoding of odor and place in mouse piriform and entorhinal cortex\n",
      "  AUTHORS: Wilson Mena,Keeley Baker,Alon Rubin,Shaun Kohli,Yun Yoo,Brice Bathellier,Yaniv Ziv,Shahab Rezaei-Mazinani,Alexander Fleischmann\n",
      "MOST RELEVANT EXCERPT: 'The hippocampus has long been recognized for its role in encoding spatial and contextual information. Hippocampal place cells, for example, selectively fire when an animal traverses a particular location and are considered a neural substrate of spatial memory16,17,19,20. Interestingly, odor cues at defined locations in space can serve as spatial landmarks and refine spatially dependent neuronal activity in the hippocampus8,10. On the other hand, in rats performing an olfactory navigation task, PCx neurons robustly encode spatial information about the environment11. Together, these observations suggest that information about odors and their location in space is communicated across olfactory and hippocampal circuits. The LEC is reciprocally interconnected with PCx and hippocampus and a prime candidate for integrating olfactory and spatial information. LEC receives direct olfactory inputs via projections from olfactory bulb mitral cells, and indirectly via PCx neurons3,15,24. LEC receives spatial information via projections from hippocampus CA1 and subiculum, and indirectly via extensive reciprocal connections within the entorhinal-hippocampal network2,22,25. Therefore, a comparative analysis of odor-evoked and location-dependent neuronal activity along the PCx – LEC – hippocampal axis is critical for understanding neural circuit mechanisms for odor-place associations. Here, we recorded neural activity in the PCx and LEC, in mice passively exposed to odors and in mice exploring odor cues in a linear track. We found that odor identity information was more accurately encoded in PCx than in LEC, independent of behavioral state. Place information, in contrast, was accurately represented in both LEC and in PCx.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 5948f042653fc7d7ebc9dcfd4bc36a5d26d8630f\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/03/14/2024.03.14.585049.full.pdf\n",
      "  TITLE: Decoding the Cognitive map: Learning place cells and remapping\n",
      "  AUTHORS: M. Pettersen,V. Schøyen,Anders Malthe-Sørenssen,M. Lepperød\n",
      "MOST RELEVANT EXCERPT: 'For instance, place cells tend to mature prior to grid cells in rodent development [25], [26]. Also, place cell inactivation has been associated with abolished grid cell activity, rather than the other way around [27]. Another approach is to suggest that non-grid spatial cells are responsible [9], [27], [28]. However, the exact origins of place fields and their remapping behavior remain undetermined. How, then, would one go about modeling place cells in a way that allows for discovering how place fields emerge, how remapping occurs, and how different cell types relate? An exciting recent alternative is to leverage normative models of the Hippocampus and surrounding regions, using neural networks optimized for a navigation task. When trained, such models learn tuning profiles similar to their biological counterparts [22], [29]–[35]. To the best of our knowledge, however, no normative models have seriously tackled the problem of place cell formation and remapping. Only some address remapping, but do so for other cell types [22], [35], [36]. Using our definition of a cognitive map, we therefore propose a normative model of spatial navigation with the flexibility required to study place cells and remapping in one framework. In our model, the output representations of a neural network are decoded into a position estimate. Simultaneously, the network is tasked with accurate position reconstruction while path integrating. Crucially, the non-trainable decoding operation is inspired by the localized firing patterns of place cells, but with minimal constraints on their individual tuning profile, and their population coding properties. We find that our model learns representations with spatial tuning profiles similar to those found in the mammalian brain, including place units in the downstream output layer and predominantly border-tuned units in the upstream recurrent layer.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 60cdeb9b9be11a54c7bedf6f5c36e94039308466\n",
      "- PDF URL: gs://arxiv-dataset/arxiv/arxiv/pdf/2502/2502.05680v1.pdf\n",
      "  TITLE: Spaces and sequences in the hippocampus: a homological perspective\n",
      "  AUTHORS: A. Babichev,Vladimir Vashin,Y. Dabaghian\n",
      "MOST RELEVANT EXCERPT: 'One of the central tasks in neuroscience is to explain learning and memory through neuronal activity [1]. A key role in enabling these phenomena is played by the hippocampus—one of the brain’s fundamental regions, both functionally and phylogenetically. Broadly, there are currently two perspectives on the organization of hippocampal neuronal activity. On the one hand, it is believed that memory episodes may be encoded and invoked by the firings of individual cells and their combinations, known as cell assemblies1. Specifically, hippocampal neurons, called place cells, learn to activate in specific areas within an environment—their respective place fields. Subsequent firings of these cells may be triggered not only by the animal’s physical visits to these fields but also by the recall of previous visits or anticipation of upcoming ones [2–5]. Suppressing the firing of select place cells using electrophys- iological or optogenetic tools can prevent the animal from entering corresponding fields, whereas their stimulation can prompt such visits [6, 7]. Curiously, hippocampal cells may also learn to selectively respond to odors, visual cues, objects, memory episodes, and more, thus mapping out not only spatial but also mnemonic information [8–12]. On the other hand, the hippocampus also enables animals to understand event sequences, plan series of actions, learn cue sequences, and more [13–15]. For instance, rats with hippocampal lesions can recognize odors but struggle to memorize their order [13]; lesioned monkeys have dif- ficulty learning new sequences of stimuli [13, 16]; and humans with hippocampal damage lose the ability to rank the positions of objects in learned sequences [17–20].'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 1656e06457bf14c996c6d6fd9aa92f9ba503646a\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2023/11/15/2023.02.19.529130.full.pdf\n",
      "  TITLE: Experience replay facilitates the rapid formation of multi-scale hexagonal patterns of grid cells\n",
      "  AUTHORS: Bo Zhang,Lei Ma,Jia Liu\n",
      "MOST RELEVANT EXCERPT: 'Functionally, a scale-dependent functional separation of grid cells are observed in modulating responses to novel versus familiar experiences (Barry et al., 2012). Previous studies suggest that the formation of hexagonal patterns of entorhinal grid cells may be influenced by the experience replay of hippocampal place cells. This is evidenced by reversed reactivations of hippocampal place cell representing unique object sequence structures (Wu and Foster, 2014; Liu et al., 2019; Liu et al., 2021) and the deficits in structured representations resulting from impaired hippocampal replay as reported in both humans with schizophrenia (Nour et al., 2021) and rodent models (Suh et al., 2013). Furthermore, experience replay is detected immediately after linear- track movements lasting less than 10 seconds (Pfeiffer, 2020) and following the first lap of a U- shaped track (Foster & Wilson 2006), aligning with the rapid formation of hexagonal patterns of grid cells (Nau et al., 2018; Killian & Buffalo, 2018; Staudigl et al., 2018; Julian et al., 2018; Wilming et al., 2018).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " Does the cerebellum influence spatial coding in the hippocampus?\n",
      "\n",
      "🤖[asXai]\n",
      " \"cerebellum hippocampus spatial coding place cells grid cells\"**No information found in the database**\n",
      "\n",
      "Based on my own knowledge, the cerebellum does not directly influence spatial coding in the hippocampus. While the cerebellum is crucial for motor coordination and balance, and has connections to the hippocampus, its primary role isn't in the generation of spatial representations like place cells or grid cells. The hippocampus and entorhinal cortex are the key areas responsible for these spatial coding mechanisms. The cerebellum's influence is more indirect, potentially impacting the accuracy of movements within a spatial environment, which could then affect how spatial information is processed by the hippocampus.\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 434ba7e1bf11665bb8ef520623af7dc5e73819d9\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2023/11/13/2023.11.09.565503.full.pdf\n",
      "  TITLE: Hippocampus facilitates reinforcement learning under partial observability\n",
      "  AUTHORS: Dabal Pedamonti,S. Mohinta,Martin V. Dimitrov,Hugo Malagon-Vina,Stéphane Ciocchi,Rui Ponte Costa\n",
      "MOST RELEVANT EXCERPT: 'In summary, our findings suggest a key role of hippocampal networks in facilitating learning in naturalistic environments. Introduction As we navigate new environments, we must learn to integrate incomplete sensory information towards desired goals. How biological neural networks perform this feat is not fully understood. The hippocampus is classically associated with building a cognitive map of the environment and the storage of episodic memories [1–3]. However, growing evidence suggests that the hippocampus also supports goal-driven be- haviour [4–8]. For example, Wikenheiser and Redish [4] showed that the hippocampus is indeed involved in planning routes towards desired goals. Moreover, their work suggests that hippocampal sequence events, known as \"replay\", serve as a mechanism for goal-directed navigation, facilitating memory-based trajectory planning and guiding subse- quent navigational behaviour. Other studies have shown that the hippocampus, and the hippocampal CA3 region in particular, is involved in maintaining information in working memory that is needed during navigational tasks when sensory cues are no longer present [9–11]. Given that in most naturalistic conditions animals do not have contin- uous access to the full environment, we postulate that the hippocampus may have evolved to support goal-driven navigation in environments in which sensory information is not always present. The hippocampus has been traditionally conceptualised using Hopfield neural networks, known for their capacity for autoassociative memory storage [12, 13]. More recent studies have demonstrated that recurrent neural network models of the hippocampus, trained for navigation tasks, exhibit specific cell types tuned to spatial information [14– 17], including the commonly observed place cells and grid cells [18, 19]. Furthermore, some of these models have also considered the role of hippocampal networks in reward-based navigation tasks [6, 7, 20].'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 22e4c57aec231f8692b333d10f9a856641580324\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2023/10/08/2023.10.05.561119.full.pdf\n",
      "  TITLE: Differential encoding of odor and place in mouse piriform and entorhinal cortex\n",
      "  AUTHORS: Wilson Mena,Keeley Baker,Alon Rubin,Shaun Kohli,Yun Yoo,Brice Bathellier,Yaniv Ziv,Shahab Rezaei-Mazinani,Alexander Fleischmann\n",
      "MOST RELEVANT EXCERPT: 'The hippocampus has long been recognized for its role in encoding spatial and contextual information. Hippocampal place cells, for example, selectively fire when an animal traverses a particular location and are considered a neural substrate of spatial memory16,17,19,20. Interestingly, odor cues at defined locations in space can serve as spatial landmarks and refine spatially dependent neuronal activity in the hippocampus8,10. On the other hand, in rats performing an olfactory navigation task, PCx neurons robustly encode spatial information about the environment11. Together, these observations suggest that information about odors and their location in space is communicated across olfactory and hippocampal circuits. The LEC is reciprocally interconnected with PCx and hippocampus and a prime candidate for integrating olfactory and spatial information. LEC receives direct olfactory inputs via projections from olfactory bulb mitral cells, and indirectly via PCx neurons3,15,24. LEC receives spatial information via projections from hippocampus CA1 and subiculum, and indirectly via extensive reciprocal connections within the entorhinal-hippocampal network2,22,25. Therefore, a comparative analysis of odor-evoked and location-dependent neuronal activity along the PCx – LEC – hippocampal axis is critical for understanding neural circuit mechanisms for odor-place associations. Here, we recorded neural activity in the PCx and LEC, in mice passively exposed to odors and in mice exploring odor cues in a linear track. We found that odor identity information was more accurately encoded in PCx than in LEC, independent of behavioral state. Place information, in contrast, was accurately represented in both LEC and in PCx.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 60cdeb9b9be11a54c7bedf6f5c36e94039308466\n",
      "- PDF URL: gs://arxiv-dataset/arxiv/arxiv/pdf/2502/2502.05680v1.pdf\n",
      "  TITLE: Spaces and sequences in the hippocampus: a homological perspective\n",
      "  AUTHORS: A. Babichev,Vladimir Vashin,Y. Dabaghian\n",
      "MOST RELEVANT EXCERPT: 'One of the central tasks in neuroscience is to explain learning and memory through neuronal activity [1]. A key role in enabling these phenomena is played by the hippocampus—one of the brain’s fundamental regions, both functionally and phylogenetically. Broadly, there are currently two perspectives on the organization of hippocampal neuronal activity. On the one hand, it is believed that memory episodes may be encoded and invoked by the firings of individual cells and their combinations, known as cell assemblies1. Specifically, hippocampal neurons, called place cells, learn to activate in specific areas within an environment—their respective place fields. Subsequent firings of these cells may be triggered not only by the animal’s physical visits to these fields but also by the recall of previous visits or anticipation of upcoming ones [2–5]. Suppressing the firing of select place cells using electrophys- iological or optogenetic tools can prevent the animal from entering corresponding fields, whereas their stimulation can prompt such visits [6, 7]. Curiously, hippocampal cells may also learn to selectively respond to odors, visual cues, objects, memory episodes, and more, thus mapping out not only spatial but also mnemonic information [8–12]. On the other hand, the hippocampus also enables animals to understand event sequences, plan series of actions, learn cue sequences, and more [13–15]. For instance, rats with hippocampal lesions can recognize odors but struggle to memorize their order [13]; lesioned monkeys have dif- ficulty learning new sequences of stimuli [13, 16]; and humans with hippocampal damage lose the ability to rank the positions of objects in learned sequences [17–20].'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 3dbeea89304fbd0f4e718c6c8df2a1a0fdcc144a\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/05/10/2024.05.10.593498.full.pdf\n",
      "  TITLE: Evidence of spatial periodic firing in the subiculum of mice\n",
      "  AUTHORS: P. Abad-Perez,R. Scott,V. Borrell,L. Martínez-Otero,J. R. Brotons-Mas\n",
      "MOST RELEVANT EXCERPT: 'Introduction Since the discovery of hippocampal place cells -neurons that code for space being active in specific locations of the environment (O’Keefe and Dostrovsky, 1971)- multiple efforts have aimed to understand the computational bases of spatial navigation. As result, different types of spatially modulated neurons have been described across brain regions: head direction cells, (HD); border and boundary vector cells (BVC), coding for the geometry of the environment in medial entorhinal cortex (MEC) and the SUB; and grid cells (GC) in the medial entorhinal cortex (MEC) (Taube et al., 1990; Sharp and Green, 1994; Hafting et al., 2005; Fyhn et al., 2008; Solstad et al., 2008; Lever et al., 2009; Brotons-Mas et al., 2017a). These neurons are either strongly involved in the codification of external information, such as BVC coding for geometry, or in egocentric related information. This is the case of GC, which tessellating regular firing was related with the representation of the metrics of space and therefore necessary for path integration, the capability of navigate in the absence of external cues (McNaughton et al., 2006). The integration of both streams of information, allocentric and egocentric, is instrumental for the generation of an efficient spatial representation. Multiple computational models have aimed to unveil the possible mechanisms underlying the integration of these different types of spatial signals.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 27e0c25ee8bcef70917ad52111ef7d9328632ea2\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/07/25/2024.07.25.604757.full.pdf\n",
      "  TITLE: Control of tongue movements by the Purkinje cells of the cerebellum\n",
      "  AUTHORS: Paul Hage,M. Fakharian,Alden M. Shoup,Jay S. Pi,Ehsan Sedaghat-Nejad,Simon P. Orozco,In Kyu Jang,Vivian Looi,Hisham Y. Elseweifi,Nazanin Mohammadrezaei,Alexander N. Vasserman,Toren Arginteanu,R. Shadmehr\n",
      "MOST RELEVANT EXCERPT: 'Data availability: https://osf.io/WDXU4/ Abstract To quantify the cerebellum’s contributions to control of the tongue, we trained head-fixed marmosets to make dexterous movements, harvesting food from small tubes that were placed orthogonal to the mouth. We identified the lingual regions in lobule VI of the vermis and recorded from hundreds of Purkinje cells (P-cells), each in sessions where the subject produced thousands of licks. Most movements aimed for one of the small tubes, while other movements groomed the mouth area. To quantify contributions of a P-cell to control of the tongue, we relied on the fact that in a small fraction of the licks, the input from the inferior olive produced a complex spike (CS), which then briefly but completely silenced the P-cell. When the movements were targeting a tube, the CS rates increased during protraction for both ipsilateral and contralateral targets, thus identifying the preferred axis of motion in the olivary input, termed CS-on. However, for grooming movements this modulation was absent. We compared the tongue’s trajectory in the targeted movement that had experienced the CS with temporally adjacent targeted licks that had not. When the SS suppression occurred during protraction, the tongue exhibited hypermetria, and when the suppression took place during retraction, the tongue exhibited slowing. These effects amplified when two P-cells were simultaneously suppressed. Therefore, CS-induced suppression of P-cells in the lingual vermis disrupted the forces that would normally decelerate the tongue as it approached the target, demonstrating a specialization in stopping the movement. Because the CS-on direction tended to align with the direction of downstream forces produced during P-cell suppression, this suggests that for targeted licks, the olivary input defined an axis of control for the P-cells.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " is there any link between cerebellum and navigation?\n",
      "\n",
      "🤖[asXai]\n",
      " \"cerebellum motor coordination spatial navigation hippocampus\"**No information found in the database**\n",
      "\n",
      "Based on my own knowledge, there is a growing body of evidence suggesting a link between the cerebellum and navigation, although the nature of this connection is still being investigated. While the hippocampus and entorhinal cortex are traditionally considered the primary brain regions for spatial navigation, the cerebellum plays a supporting role.\n",
      "\n",
      "Here's a breakdown of how the cerebellum is thought to be involved:\n",
      "\n",
      "*   **Motor Coordination and Balance:** Navigation inherently involves movement. The cerebellum's primary function is to coordinate movement, maintain balance, and ensure smooth motor execution. Accurate navigation requires precise motor control, and the cerebellum is essential for this.\n",
      "*   **Spatial Processing:** Recent research suggests the cerebellum is not just involved in motor control but also contributes to spatial processing. Studies have found cerebellar neurons that respond to spatial information, similar to place cells in the hippocampus. These cerebellar neurons may encode aspects of the environment or contribute to path integration.\n",
      "*   **Error Correction and Adaptation:** The cerebellum is crucial for error correction and adapting movements based on sensory feedback. During navigation, this allows for adjustments to routes and movements based on environmental cues and feedback.\n",
      "*   **Integration of Sensory Information:** The cerebellum receives input from various sensory systems, including visual, vestibular, and proprioceptive information, which is vital for spatial orientation and navigation.\n",
      "\n",
      "While the provided articles don't directly address the cerebellum's role in navigation, they do highlight the cerebellum's involvement in motor control and sensory processing, which are essential components of navigation. ARTICLE ID: 27e0c25ee8bcef70917ad52111ef7d9328632ea2 (Control of tongue movements by the Purkinje cells of the cerebellum) illustrates how cerebellar Purkinje cells contribute to precise movements, which are fundamental for navigation.\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 998f666db5925020bb18605791bf2d9ac4d0fa7e\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/08/03/2024.07.31.605652.full.pdf\n",
      "  TITLE: Integration of sensory and fear memories in the rat medial temporal lobe\n",
      "  AUTHORS: F. Wong,Alina B. Thomas,Simon Killcross,Vincent Laurent,Fredrick R. Westbrook,Nathan M. Holmes\n",
      "MOST RELEVANT EXCERPT: 'TITLE: Integration of sensory and fear memories in the rat medial temporal lobe: advancing research by Wong et al. (2019). AUTHORS: Francesca S. Wong, Alina B. Thomas, Simon Killcross, Vincent Laurent, R. Frederick Westbrook & Nathan M. Holmes AUTHOR AFFILIATION: School of Psychology, University of New South Wales, Wong et al. (2019) used a sensory preconditioning protocol to examine how sensory and fear memories are integrated in the rat medial temporal lobe. In this protocol, rats integrate a sound-light (sensory) memory that forms in stage 1 with a light-shock (fear) memory that forms in stage 2 to generate fear responses (freezing) across test presentations of the sound in stage 3. Here, we advance this research by showing that: 1) how/when rats integrate the sound-light and light-shock memories (online in stage 2 or at test in stage 3) changes with the number of sound-light pairings in stage 1; and 2) regardless of how/when it occurs, the integration requires communication between two regions of the medial temporal lobe: the perirhinal cortex and basolateral amygdala complex. Thus, “event familiarity” determines how/when sensory and fear memories are integrated but not the circuitry by which the integration occurs: this remains the same. Memory is the means by which the past connects with the present to guide our future interactions with the environment. One of the ways it achieves this feat is by integrating the sensory and emotional elements of experiences that are separated in time (e.g., experiences that occur days, weeks or months apart). This allows people and animals to better anticipate and react to different types of situations.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf\n",
      "  TITLE: Dorso-ventral hippocampus neural assemblies reactivate during sleep following an aversive experience\n",
      "  AUTHORS: JF Morici,I. Paiva-Lima,A. Silva,É. Pronier,G. Girardeau\n",
      "MOST RELEVANT EXCERPT: 'The hippocampal formation is heterogeneous; the dHPC processes mostly contextual information, while the ventral part (vHPC) encodes valence and anxiety. We propose that dorsal- ventral communication during sleep is involved in the consolidation of emotional memories, potentially integrating or segregating contextual and valence information. To test this, we recorded the electrophysiological activity in the dHPC and vHPC in rats during reward and aversion-motivated exploration of a linear track and subsequent sleep. We detected dorsal and ventral SWRs during NREM sleep as well as neuronal assemblies during each exploration type and identified dorsal, ventral, and joint (dorso-ventral) assemblies. We found that dorso-ventral hippocampal coordination involves coordinated ripples and bursts of ripples. Aversive joint assemblies exhibited higher reactivation during non-REM sleep than the joint assemblies from the reward condition. Interestingly, joint aversive assemblies reactivated selectively during dorso-ventral coordinated ripples. Furthermore, their reactivation strength positively correlated with their strength of activation during the task. These results suggest the existence of dorsal-ventral hippocampal functional communication capable of sustaining the selective reactivation of experiences based on their emotional valence. Episodic memory is supported by the hippocampus, a heterogeneous brain structure with distinct functional and anatomical properties along its dorsoventral axis (Fanselow and Dong 2010; Bannerman et al. 2004; Strange et al. 2014). The dorsal hippocampus (dHPC) encodes spatial representations of the environment through the activity of place cells, which code for specific locations called place fields (O’Keefe 1976; M. a Wilson and McNaughton 1993).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf\n",
      "  TITLE: Representation of sex-specific social memory in ventral CA1 neurons\n",
      "  AUTHORS: Akiyuki Watarai,Kentaro Tao,T. Okuyama\n",
      "MOST RELEVANT EXCERPT: 'We found that neurons in the ventral CA1 region (vCA1) of the mouse hippocampus encoded the identities and social properties, specifically sex and strain, of familiar conspecifics by using both rate and theta-based temporal coding. Optogenetic reactivation of social memories of females, but not males, induced place preference. Ablation of the upstream medial amygdala (MeA) or the hippocampal dorsal CA2 region (dCA2) disrupted the representation of sex and the sexual dimorphism of social memory valence. Selective reactivation of overlapping neural populations of distinct female social memories representing the female sex was sufficient to induce preference. Thus, vCA1 neurons employ dual coding schemes to represent the identities and social properties of familiar conspecifics as a cohesive memory. Social memory in the mouse ventral hippocampus maps the identities and social properties of familiar conspecifics. The hippocampus plays a crucial role in the integration of multimodal information into a conceptualized cognitive map, which is fundamental for recalling specific experiences and guiding behaviors (1). Social memory is a key component of episodic or declarative memory, which enables the recognition of familiar individuals. Extensive animal studies, particularly using rodent models, have underscored the crucial role of the hippocampus in processing social memory. Located along the hippocampal septotemporal axis, the dorsal CA2 region (dCA2) specializes in encoding social stimuli (2, 3), whereas the ventral CA1 region (vCA1), which receives projections from the dCA2 (4), is responsible for storing memories of familiar conspecifics (5) through the temporal coordination of neuronal population activities (6). Notably, a recent study of rats revealed that neuronal responses in the vCA1 to familiar conspecifics showed greater variability among individual females than the responses among males (7), and this suggested a potential sexually dimorphic component in hippocampal social memory.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf\n",
      "  TITLE: Memory System Maladaptation Impairs CA1-Dependent Temporal Binding and Declarative Memory in the Cntnap2 Knockout Mouse Model of Autism\n",
      "  AUTHORS: E. C. Rawlinson,Michael H. McCullough,A. Sellami,A. Marighetto,A. S. Al Abed,N. Dehorter\n",
      "MOST RELEVANT EXCERPT: 'The hippocampus plays a critical role in episodic memory formation and maintenance (Eichenbaum, 2004). In particular, the CA1 region of the hippocampus is essential for integrating temporal information and creating a cohesive sense of time (Eichenbaum, 2014; Sellami et al., 2017). Disruptions in this function affect the ability to sequence events and develop temporal relationships, which are often impaired in individuals with ASD (Maister & Plaisted-Grant, 2011; Vogel et al., 2022). While most research in autism has focused on the dysregulation of the prefrontal cortex and the basal ganglia, recent studies have highlighted that hippocampal disruption are key in the pathophysiology of ASD (Banker et al.,2021) Yet, how hippocampal subfield activity, such as the dorsal CA1 (dCA1), drives episodic memory atypicalities in ASD is currently unknown. Here, we aimed to dissect declarative memory atypicality and the role of the dCA1-dependent processing in related cognitive deficits in ASD. We used the Cntnap2 knock out (KO) mouse model of ASD, that exhibits autism-like phenotypes, including social behavior deficits, hyperactivity, and seizures (Peñagarikano et al., 2011; Peñagarikano & Geschwind, 2012). We demonstrate that Cntnap2 KO mice present with reduction of temporal binding capabilities and dCA1 activation during temporal binding-dependent memory tasks, which support deficits in declarative memory. Cntnap2 KO mice demonstrate reduced temporal binding capability. The capacity to bridge temporally distant events, called temporal binding, is critical to enable declarative memory formation (Sellami et al., 2017).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 38c94cf5005fb20a92dd8dfc19a97dc895a92c35\n",
      "- PDF URL: https://ojs.sin-chn.com/index.php/mcb/article/download/1343/695\n",
      "  TITLE: Molecular and cellular mechanisms of episodic memory formation through hippocampal synaptic plasticity\n",
      "  AUTHORS: Xi Chen\n",
      "MOST RELEVANT EXCERPT: 'This process allows for the dissociation between short-term and long-term modification of synaptic connections, which is crucial for memory formation [5,6]. 2.4. Functional implications AMPA and NMDA receptors, as well as the signaling pathways that follow their activation, form the basis of Hebbian learning. These mechanisms do not only enhance the strength of individual synapses but are also involved in the generation of circuits that support specific memories. In addition, since these molecular processes are synapse specific and cooperative, they have the potential of effectively filtering out the noise for storage of important information [6]. 3. Hippocampus and episodic memory 3.1. Hippocampus-dependent memory system Hippocampus, which is situated in the medial temporal lobe, is vital for declarative memory. Which includes both episodic and semantic memory. Declarative memory is the memory of facts and events. While episodic memory is specifically the memory of events and experiences in time and space. Hippocampus is one of the most complex structures of the brain. And is known for its functional features to combine spatial, temporal, and contextual information, and this makes it an essential part of the episodic memory formation. Hippocampal-dependent memory processes can be explained by molecular markers like c-Fos and Arc proteins. These are the immediate early genes which are expressed only in the short term during the activation of neurons and are useful in identifying the neural circuits used during encoding and retrieval of memory [7]. c-Fos: This transcription factor controls downstream genes that are essential for synaptic plasticity. It is most pronounced during the acquisition of new information and decreases as the information is stored in the brain, thus supporting its function in the initial encoding of new information [7,8]. ⚫ Arc: Arc protein plays a role in the internalization of AMPA receptors and synaptic reorganization.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " how does the amygdala interacts with the hippocampus?\n",
      "\n",
      "🤖[asXai]\n",
      " \"amygdala hippocampus emotional memory contextual processing interaction\"**No information found in the database**\n",
      "\n",
      "Based on my own knowledge, here's how the amygdala interacts with the hippocampus:\n",
      "\n",
      "The amygdala and hippocampus have a complex and crucial interaction that is vital for forming and retrieving emotionally charged memories, particularly those related to fear. While the hippocampus is primarily involved in forming declarative memories (facts and events), the amygdala processes emotions, especially fear.\n",
      "\n",
      "Here's a breakdown of their interaction:\n",
      "\n",
      "*   **Emotional Tagging:** When an event occurs, the hippocampus encodes the sensory details (what, where, when). Simultaneously, the amygdala assesses the emotional significance of the event. The amygdala then \"tags\" the hippocampal memory with an emotional charge. This emotional tag is crucial for later recall; emotionally charged memories are typically remembered more vividly.\n",
      "*   **Modulation of Hippocampal Activity:** The amygdala sends projections to the hippocampus, modulating its activity. This modulation can enhance or suppress hippocampal memory formation, depending on the emotional intensity of the experience. Strong emotional experiences lead to stronger hippocampal memory consolidation.\n",
      "*   **Retrieval:** During memory retrieval, the amygdala and hippocampus work together. The hippocampus retrieves the contextual details of the memory, and the amygdala retrieves the associated emotional response. This combined retrieval process allows us to re-experience the emotional context of past events.\n",
      "*   **Fear Conditioning:** A classic example of amygdala-hippocampal interaction is fear conditioning. During fear conditioning, a neutral stimulus (e.g., a tone) is paired with an aversive stimulus (e.g., a shock). The hippocampus encodes the association between the tone and the context, while the amygdala learns to associate the tone with fear. Later, the tone alone can elicit a fear response due to the combined activity of the hippocampus and amygdala.\n",
      "\n",
      "🧑[You]\n",
      " how do ventral and dorsal hippocampus contributes to emotional memory encoding?\n",
      "\n",
      "🤖[asXai]\n",
      " The dorsal hippocampus (dHPC) primarily encodes spatial and contextual information, while the ventral hippocampus (vHPC) encodes valence and emotional information related to experiences. The dHPC contributes to emotional memory encoding by providing the spatial and contextual framework within which emotional events are experienced. The vHPC, on the other hand, is more directly involved in processing the emotional content of experiences, particularly those related to fear and social interactions.\n",
      "\n",
      "This division of labor is evident in several ways: the vHPC shows greater variability in responses to familiar conspecifics among females than males (ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e, PDF URL: https://ojs.sin-chn.com/index.php/mcb/article/download/1343/695).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " Can you run a search to make that sure?\n",
      "\n",
      "🤖[asXai]\n",
      " The dorsal hippocampus (dHPC) primarily encodes spatial and contextual information, while the ventral hippocampus (vHPC) encodes valence and emotional information related to experiences. The dHPC contributes to emotional memory encoding by providing the spatial and contextual framework within which emotional events are experienced. The vHPC, on the other hand, is more directly involved in processing the emotional content of experiences, particularly those related to fear and social interactions. This is supported by the observation that the vHPC shows greater variability in responses to familiar conspecifics among females than males (ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e, PDF URL: https://ojs.sin-chn.com/index.php/mcb/article/download/1343/695).\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: ad68b16410200b91448dc2bc40656db3dab519de\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/13/2024.06.13.598918.full.pdf\n",
      "  TITLE: Dorso-ventral hippocampus neural assemblies reactivate during sleep following an aversive experience\n",
      "  AUTHORS: JF Morici,I. Paiva-Lima,A. Silva,É. Pronier,G. Girardeau\n",
      "MOST RELEVANT EXCERPT: 'To study the respective and conjoint roles of the dHPC and the vHPC in the sleep-dependent processing of emotionally valenced experiences, we recorded neuronal activity in both regions simultaneously in rats performing a new task specifically designed to elicit the same behavior in the same spatial environments, but with opposing valences. These rats were subjected to aversive or reward-motivated exploration on a linear track, preceded and followed by sleep periods. We identified dorsal, ventral, and dorsoventral joint cell assemblies in the hippocampus that represented the aversive and reward conditions of the task. We then investigated whether those assemblies were reactivated during subsequent NREM sleep, the extent to which they coincide with the dorsoventral coordination of SWRs, and how these were influenced by emotional valence. Rats can perform the same exploratory behavior motivated by either reward or avoidance. To study dorsal-ventral hippocampal joint reactivations, we developed a behavioral task where animals have to perform the same exploratory behavior on a linear track but under different motivational contingencies associated with opposite valences. In the reward-motivated, positive contingency, the rats have to run back and forth on the linear track to obtain a drop of water at the end of each lap (Rewarded Run). The avoidance-motivated, aversive contingency was conducted on the same linear track and signaled by a single, constant light cue. During this session, animals were running back and forth to avoid an eyelid shock (Aversive Run) delivered after 20-30 seconds of immobility. (Figure 1A-B). During pre-training, the animals very rapidly learned to alternate for rewards, but the shock condition had to be gradually introduced to preserve the mobility and alternation behavior (Figure S1A). The experiments started at plateau performance for the number of shocks.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: e291789f736b602b93d6d5d82df15edf0f4c5c6b\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/04/02/2024.04.01.587523.full.pdf\n",
      "  TITLE: Representation of sex-specific social memory in ventral CA1 neurons\n",
      "  AUTHORS: Akiyuki Watarai,Kentaro Tao,T. Okuyama\n",
      "MOST RELEVANT EXCERPT: 'We found that neurons in the ventral CA1 region (vCA1) of the mouse hippocampus encoded the identities and social properties, specifically sex and strain, of familiar conspecifics by using both rate and theta-based temporal coding. Optogenetic reactivation of social memories of females, but not males, induced place preference. Ablation of the upstream medial amygdala (MeA) or the hippocampal dorsal CA2 region (dCA2) disrupted the representation of sex and the sexual dimorphism of social memory valence. Selective reactivation of overlapping neural populations of distinct female social memories representing the female sex was sufficient to induce preference. Thus, vCA1 neurons employ dual coding schemes to represent the identities and social properties of familiar conspecifics as a cohesive memory. Social memory in the mouse ventral hippocampus maps the identities and social properties of familiar conspecifics. The hippocampus plays a crucial role in the integration of multimodal information into a conceptualized cognitive map, which is fundamental for recalling specific experiences and guiding behaviors (1). Social memory is a key component of episodic or declarative memory, which enables the recognition of familiar individuals. Extensive animal studies, particularly using rodent models, have underscored the crucial role of the hippocampus in processing social memory. Located along the hippocampal septotemporal axis, the dorsal CA2 region (dCA2) specializes in encoding social stimuli (2, 3), whereas the ventral CA1 region (vCA1), which receives projections from the dCA2 (4), is responsible for storing memories of familiar conspecifics (5) through the temporal coordination of neuronal population activities (6). Notably, a recent study of rats revealed that neuronal responses in the vCA1 to familiar conspecifics showed greater variability among individual females than the responses among males (7), and this suggested a potential sexually dimorphic component in hippocampal social memory.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 2cdfb4a613eb19e19651a8e77cd91b198e804a87\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/06/16/2024.06.14.598683.full.pdf\n",
      "  TITLE: Taking the perspective of an embodied avatar modulates the temporal dynamics of vicarious pain and pleasure: a combined Immersive Virtual Reality and EEG study\n",
      "  AUTHORS: V. Nicolardi,M. P. Lisi,M. Mello,M. Fusaro,G. Tieri,S. Aglioti\n",
      "MOST RELEVANT EXCERPT: 'We focused on cortical responses related to salience, arousal, attentional engagement, and affective salience. In particular, the N2-Visual Evoked Potential, indexed selective attention and stimulus intrinsic relevance (Olofsson, 2008; Luck and Kappenman, 2013; Valentini et al., 2017a); the LPP, reflected the arousal and the motivational salience of the stimulus (Cuthbert et al., 2000; Luck and Kappenman, 2011; Hajcak et al., 2009; Valentini et al., 2015), and the EPN reflected automatic emotion-related influences on information processing (e.g., Olofsson et al., 2008; Schupp et al., 2004). We also focused on: fronto-central theta and centro-lateral alpha power that seem modulated by vicarious experience (Sarlo et al., 2005; González-Franco et al., 2014; Fabi and Leuthold, 2017); fronto-central theta rhythm (Moreau et al., 2020; Valentini et al., 2017a; Cavanagh et al., 2012) that is enhanced by observation of pain and affective touch compared to control condition (Mu et al., 2008). Finally, we computed central alpha/mu power that appears to decrease when observing painful situations (Mu et al., 2008; Riečanský et al., 2014).'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/16/2024.10.14.618356.full.pdf\n",
      "  TITLE: A top-down insular cortex circuit crucial for non-nociceptive fear learning\n",
      "  AUTHORS: Junho Han,Boin Suh,Jin-Hee Han\n",
      "MOST RELEVANT EXCERPT: 'Early lesion studies showed that regions such as the basolateral amygdala (BLA) (39) and ventral hippocampus (vHPC) (40), which are involved in shock conditioning, are also required for predator odor-induced fear learning. Additionally, the medial amygdala (MeA) (41), which is not involved in shock conditioning, was identified as a novel component of the fear learning in this context. Recent research using muscimol inactivation indicates that the posterior insular cortex (pIC) is crucial for both the formation and recall of predator odor-induced contextual fear memories (42) The insular cortex has been associated with processing negative emotions and cognitive information related to fear, anxiety, and disgust (11, 43). Animal studies have demonstrated that optogenetic activation of pIC induces an aversive state in mice (44) and insular cortex activity is crucial for the maintenance of learned fear (45). In humans, the affective and social pain correlates with activity in the ACC and insular (11, 46, 47). Also, in a fear learning using aversive pictures as US, the insular cortex shows increased activation when exposed to both the aversive picture and the CS (48, 49). Moreover, lesions in the insular cortex can result in pain asymbolia (50), where pain sensation is present but the unpleasantness is not perceived. These findings suggest that the insular cortex plays a crucial role in representing negative emotions and affect rather than processing somatosensory information related to nociception. Notably, the insular cortex has substantial reciprocal connections with the PBN (51, 52). The insular cortex may convey affective information to the PBN.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " ---------\n",
      "- ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e\n",
      "- PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf\n",
      "  TITLE: Memory System Maladaptation Impairs CA1-Dependent Temporal Binding and Declarative Memory in the Cntnap2 Knockout Mouse Model of Autism\n",
      "  AUTHORS: E. C. Rawlinson,Michael H. McCullough,A. Sellami,A. Marighetto,A. S. Al Abed,N. Dehorter\n",
      "MOST RELEVANT EXCERPT: 'While most research in autism has focused on the dysregulation of the prefrontal cortex and the basal ganglia, recent studies have highlighted that hippocampal disruption are key in the pathophysiology of ASD (Banker et al.,2021) Yet, how hippocampal subfield activity, such as the dorsal CA1 (dCA1), drives episodic memory atypicalities in ASD is currently unknown. Here, we aimed to dissect declarative memory atypicality and the role of the dCA1-dependent processing in related cognitive deficits in ASD. We used the Cntnap2 knock out (KO) mouse model of ASD, that exhibits autism-like phenotypes, including social behavior deficits, hyperactivity, and seizures (Peñagarikano et al., 2011; Peñagarikano & Geschwind, 2012). We demonstrate that Cntnap2 KO mice present with reduction of temporal binding capabilities and dCA1 activation during temporal binding-dependent memory tasks, which support deficits in declarative memory. Cntnap2 KO mice demonstrate reduced temporal binding capability. The capacity to bridge temporally distant events, called temporal binding, is critical to enable declarative memory formation (Sellami et al., 2017). To test this elemental process, we tested Cntnap2 KO mouse model in the trace fear conditioning paradigm (TFC; Fig. 1A). In this paradigm, mice are required to associate a tone (Conditioned Stimulus) with a mild electric foot-shock (Unconditioned Stimulus), separated by a time interval (i.e. Trace, (Sellami et al., 2017)). In the first step, the conditioning, independent groups of mice were exposed to three tone-shock pairings separated by time intervals between 5 and 60 sec (i.e.'\n",
      "\n",
      "\n",
      "\n",
      "🧑[You]\n",
      " Run a search to make that sure?\n",
      "\n",
      "🤖[asXai]\n",
      " \"dorsal hippocampus ventral hippocampus emotional memory encoding valence fear social interactions differential activity\"Here's a summary of how the dorsal and ventral hippocampus contribute to emotional memory encoding, based on the provided articles:\n",
      "\n",
      "**Dorsal Hippocampus (dHPC):**\n",
      "\n",
      "*   **Spatial and Contextual Framework:** The dHPC primarily encodes spatial and contextual information, providing the framework within which emotional events are experienced (ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf).\n",
      "*   **Temporal Binding and Declarative Memory:** The dHPC is involved in temporal binding, which is critical for declarative memory formation. Deficits in dHPC activation during temporal binding-dependent memory tasks are associated with declarative memory atypicalities (ARTICLE ID: 815b5b606e47a73306b11d839ffced7e7eb8640e, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf).\n",
      "\n",
      "**Ventral Hippocampus (vHPC):**\n",
      "\n",
      "*   **Storing Memories of Familiar Conspecifics:** The vHPC is responsible for storing memories of familiar conspecifics and receives projections from the dCA2 (ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf).\n",
      "*   **Sexually Dimorphic Component in Social Memory:** Responses in the vHPC to familiar conspecifics show greater variability among individual females than males, suggesting a potential sexually dimorphic component in hippocampal social memory (ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf).\n",
      "*   **Integration of Multimodal Information:** The hippocampus, including the vHPC, plays a crucial role in the integration of multimodal information into a conceptualized cognitive map (ARTICLE ID: a40e0c42e734299e7427c56ae6cdcea24cd8fb35, PDF URL: https://www.biorxiv.org/content/biorxiv/early/2024/10/29/2024.10.29.620866.full.pdf).\n",
      "\n",
      "\n",
      "\n",
      "It's important to note that the dHPC and vHPC work together in emotional memory encoding. The dHPC provides the spatial and contextual framework, while the vHPC stores the specific memories of individuals and their associated emotional significance.\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(f\"{base_url}/notebook/{task_id}/history\").json()\n",
    "chat_history = res\n",
    "for msg in chat_history:\n",
    "    if msg['role'] == 'user':\n",
    "        print(f\"\\n🧑[You]\\n\", msg[\"content\"])\n",
    "    elif msg['role'] == 'assistant':\n",
    "        print(\"\\n🤖[asXai]\\n\", msg[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430e78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = {\n",
    "    \"user_id\": \"julien\",\n",
    "    \"notebook_id\": \"neuroscience\",\n",
    "    \"message\": \"Summarize the role of the prefrontal cortex\"\n",
    "}\n",
    "task_id = \"5c022ffb48a537cbf1e0/47f210eacb89414efd82\"  # or use the /notebook/task_id endpoint to generate one\n",
    "\n",
    "res = requests.post(f\"http://localhost:8100/notebook/{task_id}/chat\", json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7fa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"http://localhost:8100/notebook/{task_id}/stream\"\n",
    "response = requests.get(url, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a17b75c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:8100/notebook/5c022ffb48a537cbf1e0/47f210eacb89414efd82/stream'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24d2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is Paris\n",
      "Paris is the capital city of **France**.\n",
      "\n",
      "Here's a more detailed breakdown of its location:\n",
      "\n",
      "*   **Continent:** Europe\n",
      "*   **Country:** France\n",
      "*   **Region:** Île-de-France (Paris is the heart of this region)\n",
      "*   **Coordinates:** 48.8566° N, 2.3522° E (approximately)\n",
      "\n",
      "It's located in the north-central part of France, on the Seine River.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to know anything more specific about its location, like its proximity to other cities or landmarks?How many people live there?\n",
      "Okay, let's break down the population of Paris. It gets a little complicated because \"Paris\" can refer to different areas:\n",
      "\n",
      "**1. City of Paris (Ville de Paris):**\n",
      "\n",
      "*   This is the core, central Paris, the area within the official city limits.\n",
      "*   **Population:** Roughly **2.14 million** people (as of 2023 estimates).\n",
      "\n",
      "**2. Greater Paris (Grand Paris):**\n",
      "\n",
      "*   This is a larger metropolitan area including the city of Paris and surrounding suburbs. It's often used for planning and statistical purposes.\n",
      "*   **Population:** Around **13 million** people (as of 2023 estimates). This makes it one of the largest metropolitan areas in Europe.\n",
      "\n",
      "**3. Île-de-France Region:**\n",
      "\n",
      "*   This is the entire region surrounding Paris, which includes many towns and cities beyond just the \"Greater Paris\" area.\n",
      "*   **Population:** Approximately **12.3 million** people (as of 2023 estimates).\n",
      "\n",
      "\n",
      "\n",
      "So, depending on what you consider \"Paris,\" the population varies significantly!"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "ollama_manager = OllamaManager()\n",
    "messages = [{'role': 'user', 'content': 'Where is Paris', 'task_id': 0}]\n",
    "async def ollama_chat(msg):\n",
    "    print(msg[-1]['content'])\n",
    "    streamer = asyncio.run(ollama_manager.client.chat(model=ollama_manager.model_name, messages=msg, stream=True))\n",
    "    full_response = \"\"\n",
    "    async for chunk in streamer:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\")\n",
    "        full_response += chunk[\"message\"][\"content\"]\n",
    "    return full_response\n",
    "\n",
    "full_response = asyncio.run(ollama_chat(messages))\n",
    "messages += [{'role': 'assistant', 'content': full_response, 'task_id': 0}]\n",
    "\n",
    "messages += [{'role': 'user', 'content': \"How many people live there?\", 'task_id': 0}]\n",
    "full_response = asyncio.run(ollama_chat(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f90d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Where is Paris', 'task_id': 0},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Paris is the capital city of **France**.\\n\\nHere's a more detailed breakdown of its location:\\n\\n*   **Continent:** Europe\\n*   **Country:** France\\n*   **Region:** Île-de-France (Paris is the heart of this region)\\n*   **Coordinates:** 48.8566° N, 2.3522° E (approximately)\\n\\nIt's located in the north-central part of France, on the Seine River.\\n\\n\\n\\nDo you want to know anything more specific about its location, like its proximity to other cities or landmarks?\",\n",
       "  'task_id': 0},\n",
       " {'role': 'user', 'content': 'How many people live there?', 'task_id': 0}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a70ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cleaned_query\": \"What is the role of the prefrontal cortex in cognitive functions, and what specific insights regarding its function were presented?\",\n",
      "  \"author_names\": [\"Carandini\", \"Harris\"],\n",
      "  \"start_date\": \"2016-01-01\",\n",
      "  \"end_date\": \"2021-12-31\"\n",
      "}\n",
      "{'cleaned_query': 'What is the role of the prefrontal cortex in cognitive functions, and what specific insights regarding its function were presented?', 'author_names': ['Carandini', 'Harris'], 'start_date': '2016-01-01', 'end_date': '2021-12-31'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'query': 'What is the role of the prefrontal cortex in cognitive functions, and what specific insights regarding its function were presented?',\n",
       "  'authorName': ['Carandini', 'Harris'],\n",
       "  'publicationDate_start': '2016-01-01',\n",
       "  'publicationDate_end': '2021-12-31',\n",
       "  'original_query': 'What is the role of the prefrontal cortex in cognitive functions, and what specific insights regarding its function were presented by Matteo Carandini and Kenneth Harris in their peer-reviewed publications between 2016 and 2021?'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the the role of the prefrontal cortex? I'm mostly interested in what Matteo Carandini and Keneth Harris said about that in their papers from 2016 to 2021?\"\n",
    "asyncio.run(ollama_manager.expand_parse_batch(queries=[query], options={'temperature': 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import config\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "from ollama import AsyncClient, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f4a164b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='gemma3:12b', modified_at=datetime.datetime(2025, 5, 19, 13, 40, 23, 526266, tzinfo=TzInfo(UTC)), digest='f4031aab637d1ffa37b42570452ae0e4fad0314754d17ded67322e4b95836f8a', size=8149190253, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='12.2B', quantization_level='Q4_K_M')),\n",
       " Model(model='mistral-small3.1:latest', modified_at=datetime.datetime(2025, 5, 19, 12, 41, 21, 742826, tzinfo=TzInfo(UTC)), digest='b9aaf0c2586a8ed8105feab808c0f034bd4d346203822f048e2366165a13f4ea', size=15486899116, details=ModelDetails(parent_model='', format='gguf', family='mistral3', families=['mistral3'], parameter_size='24.0B', quantization_level='Q4_K_M')),\n",
       " Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 5, 19, 12, 23, 28, 152446, tzinfo=TzInfo(UTC)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')),\n",
       " Model(model='llama3.1:8b', modified_at=datetime.datetime(2025, 5, 19, 9, 53, 42, 419687, tzinfo=TzInfo(UTC)), digest='46e0c10c039e019119339687c3c1757cc81b9da49709a3b3924863ba87ca666e', size=4920753328, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syncclient = Client(\n",
    "  host='http://localhost:11434'\n",
    ")\n",
    "models = syncclient.list()\n",
    "models.models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5543f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncClient(\n",
    "  host='http://localhost:11434'\n",
    ")\n",
    "async def chat(query):\n",
    "  message = {'role': 'user', 'content': query}\n",
    "  response = await AsyncClient().chat(model='llama3.1:8b', messages=[message])\n",
    "  return response\n",
    "\n",
    "syncclient = Client(\n",
    "  host='http://localhost:11434'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a39cdc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='gemma3:12b', created_at='2025-05-20T12:48:52.37206379Z', done=True, done_reason='stop', total_duration=2523802723, load_duration=78874714, prompt_eval_count=13, prompt_eval_duration=254114791, eval_count=110, eval_duration=2189200787, message=Message(role='assistant', content='Please provide me with more context! \"That\" is a pronoun that refers to something previously mentioned or something that can be seen or understood. \\n\\nTo tell you what \"that\" is, I need to know **what you\\'re referring to.** \\n\\nFor example, tell me:\\n\\n* **What were you just talking about?**\\n* **What are you looking at?**\\n* **Where did you see \"that\"?**\\n\\n\\n\\nOnce you give me more information, I can tell you what \"that\" is.', images=None, tool_calls=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syncclient.chat(model=\"gemma3:12b\", messages=[{'role': 'user', 'content':'what is that?'}], options={'temperature': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "19390d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syncclient.pull('gemma3:12b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2d1f898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_cleaned_query_and_metadata(text: str):\n",
    "    try:\n",
    "        start = text.index('{')\n",
    "        end = text.rindex('}') + 1\n",
    "        json_block = text[start:end]\n",
    "        json_block = json_block.replace(\"None\", \"null\")\n",
    "        print(json_block)\n",
    "        return json.loads(json_block)\n",
    "    except (ValueError, json.JSONDecodeError):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "bb9bc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_query(query: str):\n",
    "    parse_instruction = (\n",
    "        \"You are a helpful assistant that parse queries sent by users and only return the requested fields.\\n\"\n",
    "        \"Parse the following search query to extract the cleaned query and any metadata it contains.\"\n",
    "        \"Specifically, identify and separate:\\n\"\n",
    "        \"- author last names\\n\"\n",
    "        \"- Date to start searching from (formatted as %Y-%m-%d even if there's just a year mentioned)\\n\"\n",
    "        \"- Date to stop searching at (formatted as %Y-%m-%d even if there's just a year mentioned)\\n\"\n",
    "        \"Then reformulate the query without sections specifying authors names or dates.\\n\"\n",
    "        \"Return results as a dictionary with cleaned query and fields:\\n\"\n",
    "        \"{\\\"cleaned_query\\\" \\\"author_names\\\", \\\"start_date\\\", \\\"end_date\\\"}\\n\\n\"\n",
    "        \"If you can't find answers for any of these fields just fill it with 'null'.\\n\"\n",
    "        \"Here is the original query:\\n\"\n",
    "        f\"'{query}'\"\n",
    "    )\n",
    "    message = {'role': 'user', 'content': parse_instruction}\n",
    "    response = await client.chat(model='gemma3:12b', messages=[message])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f1c29fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = asyncio.run(parse_query(\"what is the role of the the prefrontal cortex? I'm mostly interested in what Carandini and Harris said about that in their papers from 2016 to 2021?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "9db9498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_parsed_fields(text: str):\n",
    "    try:\n",
    "        start = text.index('{')\n",
    "        end = text.rindex('}') + 1\n",
    "        json_block = text[start:end]\n",
    "        json_block = json_block.replace(\"None\", \"null\")\n",
    "        dic = json.loads(json_block)\n",
    "        default = datetime(1, 1, 1)  # defaults everything to Jan 1\n",
    "        dt = parse(\"nov 2016\", default=default)\n",
    "        dt.strftime(\"%Y-%m-%d\")\n",
    "        norm_dic = {'query': [val for key, val in dic.items() if 'query' in key][0],\n",
    "                    'authorName': [val for key, val in dic.items() if 'name' in key][0],\n",
    "                    'publicationDate': [parse(val, default=default).strftime(\"%Y-%m-%d\") for key, val in dic.items() if 'date' in key and val!='null']}\n",
    "        norm_dic['publicationDate'] = sorted(norm_dic['publicationDate'])\n",
    "        return norm_dic\n",
    "    except (ValueError, json.JSONDecodeError):\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f8db10e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the functional role of the prefrontal cortex in spatial navigation, and how does it contribute to navigational processes?',\n",
       " 'authorName': 'null',\n",
       " 'publicationDate': ['2016-11-01', '2021-12-31']}"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = extract_parsed_fields(response)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "21ddae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def expand_query(query: str):\n",
    "    expand_instruction = (\n",
    "        \"You are a helpful assistant that expand queries sent by users to retrieve relevant scientific articles.\\n\"\n",
    "        \"Expand the following search query by rephrasing it in a more descriptive and complete sentence, \"\n",
    "        \"suitable for retrieving relevant scientific documents.\"\n",
    "        \"Do not return anything else than just the expanded query.\\n\\n\"\n",
    "        \"Here is the original query:\\n\"\n",
    "        f\"'{query}'\"\n",
    "    )\n",
    "    message = {'role': 'user', 'content': expand_instruction}\n",
    "    response = await client.chat(model='gemma3:12b', messages=[message])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "e3bf9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the functional role of the prefrontal cortex in spatial navigation, and how does it contribute to navigational processes, as investigated in scientific publications published between November 2016 and 2021?\n"
     ]
    }
   ],
   "source": [
    "response = asyncio.run(expand_query(\"what is the role of the the prefrontal cortex? Especially in the comntext of navigation.\\n I'm only interested in papers from nov 2016 to 2021\"))#(\"does the cerebellum influence place cell activity?\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "8cfce1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the functional role of the prefrontal cortex in spatial navigation, and how does it contribute to navigational processes?', 'authorName': 'null', 'publicationDate': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the functional role of the prefrontal cortex in spatial navigation, and how does it contribute to navigational processes?',\n",
       " 'authorName': 'null',\n",
       " 'publicationDate': []}"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = asyncio.run(parse_query(response))\n",
    "res = extract_parsed_fields(response)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7701496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us during the day because of a phenomenon called scattering. Scattering occurs when light from the sun interacts with the tiny molecules of gases in the Earth's atmosphere, such as nitrogen and oxygen.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When sunlight enters our atmosphere, it is made up of different colors of light, including red, orange, yellow, green, blue, indigo, and violet.\n",
      "2. **Light interacts with gas molecules**: As the sunlight travels through the atmosphere, it encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2). These molecules are randomly moving around due to thermal energy.\n",
      "3. **Scattering occurs**: When light hits these gas molecules, it scatters in all directions. This scattering effect is more pronounced for shorter wavelengths of light, which correspond to blue and violet colors.\n",
      "4. **Blue light is scattered more**: Since blue light has a shorter wavelength (around 450-495 nanometers), it is scattered more than other colors by the tiny gas molecules. This is known as Rayleigh scattering, named after the British physicist Lord Rayleigh who first described this phenomenon in the late 19th century.\n",
      "5. **Our eyes perceive the scattered blue light**: As a result of this scattering, we see the sky appear blue during the daytime. The blue color we perceive is actually a combination of all the scattered blue light from the sun that reaches our eyes.\n",
      "\n",
      "At sunrise and sunset, the sky can take on hues of red, orange, and pink. This is because the sunlight has to travel through more of the Earth's atmosphere to reach our eyes at these times, which scatters the shorter wavelengths (like blue) even more, leaving mainly longer wavelengths like red and orange visible.\n",
      "\n",
      "So, in summary, the sky appears blue due to the scattering of sunlight by tiny gas molecules in the Earth's atmosphere, which favors shorter wavelengths like blue light.\n",
      "\n",
      "Would you like me to explain any other related phenomena or clarify any parts of this explanation?\n"
     ]
    }
   ],
   "source": [
    "response = asyncio.run(chat('Why is the sky blue?'))\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e72996e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShowResponse(modified_at=datetime.datetime(2025, 5, 19, 9, 53, 42, 419687, tzinfo=TzInfo(UTC)), template='{{- if or .System .Tools }}<|start_header_id|>system<|end_header_id|>\\n{{- if .System }}\\n\\n{{ .System }}\\n{{- end }}\\n{{- if .Tools }}\\n\\nCutting Knowledge Date: December 2023\\n\\nWhen you receive a tool call response, use the output to format an answer to the orginal user question.\\n\\nYou are a helpful assistant with tool calling capabilities.\\n{{- end }}<|eot_id|>\\n{{- end }}\\n{{- range $i, $_ := .Messages }}\\n{{- $last := eq (len (slice $.Messages $i)) 1 }}\\n{{- if eq .Role \"user\" }}<|start_header_id|>user<|end_header_id|>\\n{{- if and $.Tools $last }}\\n\\nGiven the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\\n\\nRespond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables.\\n\\n{{ range $.Tools }}\\n{{- . }}\\n{{ end }}\\nQuestion: {{ .Content }}<|eot_id|>\\n{{- else }}\\n\\n{{ .Content }}<|eot_id|>\\n{{- end }}{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\\n\\n{{ end }}\\n{{- else if eq .Role \"assistant\" }}<|start_header_id|>assistant<|end_header_id|>\\n{{- if .ToolCalls }}\\n{{ range .ToolCalls }}\\n{\"name\": \"{{ .Function.Name }}\", \"parameters\": {{ .Function.Arguments }}}{{ end }}\\n{{- else }}\\n\\n{{ .Content }}\\n{{- end }}{{ if not $last }}<|eot_id|>{{ end }}\\n{{- else if eq .Role \"tool\" }}<|start_header_id|>ipython<|end_header_id|>\\n\\n{{ .Content }}<|eot_id|>{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\\n\\n{{ end }}\\n{{- end }}\\n{{- end }}', modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM llama3.1:8b\\n\\nFROM /root/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29\\nTEMPLATE \"\"\"{{- if or .System .Tools }}<|start_header_id|>system<|end_header_id|>\\n{{- if .System }}\\n\\n{{ .System }}\\n{{- end }}\\n{{- if .Tools }}\\n\\nCutting Knowledge Date: December 2023\\n\\nWhen you receive a tool call response, use the output to format an answer to the orginal user question.\\n\\nYou are a helpful assistant with tool calling capabilities.\\n{{- end }}<|eot_id|>\\n{{- end }}\\n{{- range $i, $_ := .Messages }}\\n{{- $last := eq (len (slice $.Messages $i)) 1 }}\\n{{- if eq .Role \"user\" }}<|start_header_id|>user<|end_header_id|>\\n{{- if and $.Tools $last }}\\n\\nGiven the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\\n\\nRespond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables.\\n\\n{{ range $.Tools }}\\n{{- . }}\\n{{ end }}\\nQuestion: {{ .Content }}<|eot_id|>\\n{{- else }}\\n\\n{{ .Content }}<|eot_id|>\\n{{- end }}{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\\n\\n{{ end }}\\n{{- else if eq .Role \"assistant\" }}<|start_header_id|>assistant<|end_header_id|>\\n{{- if .ToolCalls }}\\n{{ range .ToolCalls }}\\n{\"name\": \"{{ .Function.Name }}\", \"parameters\": {{ .Function.Arguments }}}{{ end }}\\n{{- else }}\\n\\n{{ .Content }}\\n{{- end }}{{ if not $last }}<|eot_id|>{{ end }}\\n{{- else if eq .Role \"tool\" }}<|start_header_id|>ipython<|end_header_id|>\\n\\n{{ .Content }}<|eot_id|>{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\\n\\n{{ end }}\\n{{- end }}\\n{{- end }}\"\"\"\\nPARAMETER stop <|start_header_id|>\\nPARAMETER stop <|end_header_id|>\\nPARAMETER stop <|eot_id|>\\nLICENSE \"LLAMA 3.1 COMMUNITY LICENSE AGREEMENT\\nLlama 3.1 Version Release Date: July 23, 2024\\n\\n“Agreement” means the terms and conditions for use, reproduction, distribution and modification of the\\nLlama Materials set forth herein.\\n\\n“Documentation” means the specifications, manuals and documentation accompanying Llama 3.1\\ndistributed by Meta at https://llama.meta.com/doc/overview.\\n\\n“Licensee” or “you” means you, or your employer or any other person or entity (if you are entering into\\nthis Agreement on such person or entity’s behalf), of the age required under applicable laws, rules or\\nregulations to provide legal consent and that has legal authority to bind your employer or such other\\nperson or entity if you are entering in this Agreement on their behalf.\\n\\n“Llama 3.1” means the foundational large language models and software and algorithms, including\\nmachine-learning model code, trained model weights, inference-enabling code, training-enabling code,\\nfine-tuning enabling code and other elements of the foregoing distributed by Meta at\\nhttps://llama.meta.com/llama-downloads.\\n\\n“Llama Materials” means, collectively, Meta’s proprietary Llama 3.1 and Documentation (and any\\nportion thereof) made available under this Agreement.\\n\\n“Meta” or “we” means Meta Platforms Ireland Limited (if you are located in or, if you are an entity, your\\nprincipal place of business is in the EEA or Switzerland) and Meta Platforms, Inc. (if you are located\\noutside of the EEA or Switzerland).\\n\\nBy clicking “I Accept” below or by using or distributing any portion or element of the Llama Materials,\\nyou agree to be bound by this Agreement.\\n\\n1. License Rights and Redistribution.\\n\\n  a. Grant of Rights. You are granted a non-exclusive, worldwide, non-transferable and royalty-free\\nlimited license under Meta’s intellectual property or other rights owned by Meta embodied in the Llama\\nMaterials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the\\nLlama Materials.\\n\\n  b. Redistribution and Use.\\n\\n      i. If you distribute or make available the Llama Materials (or any derivative works\\nthereof), or a product or service (including another AI model) that contains any of them, you shall (A)\\nprovide a copy of this Agreement with any such Llama Materials; and (B) prominently display “Built with\\nLlama” on a related website, user interface, blogpost, about page, or product documentation. If you use\\nthe Llama Materials or any outputs or results of the Llama Materials to create, train, fine tune, or\\notherwise improve an AI model, which is distributed or made available, you shall also include “Llama” at\\nthe beginning of any such AI model name.\\n\\n      ii. If you receive Llama Materials, or any derivative works thereof, from a Licensee as part \\nof an integrated end user product, then Section 2 of this Agreement will not apply to you.\\n\\n      iii. You must retain in all copies of the Llama Materials that you distribute the following\\nattribution notice within a “Notice” text file distributed as a part of such copies: “Llama 3.1 is\\nlicensed under the Llama 3.1 Community License, Copyright © Meta Platforms, Inc. All Rights\\nReserved.”\\n\\n      iv. Your use of the Llama Materials must comply with applicable laws and regulations\\n(including trade compliance laws and regulations) and adhere to the Acceptable Use Policy for the Llama\\nMaterials (available at https://llama.meta.com/llama3_1/use-policy), which is hereby incorporated by\\nreference into this Agreement.\\n\\n2. Additional Commercial Terms. If, on the Llama 3.1 version release date, the monthly active users\\nof the products or services made available by or for Licensee, or Licensee’s affiliates, is greater than 700\\nmillion monthly active users in the preceding calendar month, you must request a license from Meta,\\nwhich Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the\\nrights under this Agreement unless or until Meta otherwise expressly grants you such rights.\\n\\n3. Disclaimer of Warranty. UNLESS REQUIRED BY APPLICABLE LAW, THE LLAMA MATERIALS AND ANY\\nOUTPUT AND RESULTS THEREFROM ARE PROVIDED ON AN “AS IS” BASIS, WITHOUT WARRANTIES OF\\nANY KIND, AND META DISCLAIMS ALL WARRANTIES OF ANY KIND, BOTH EXPRESS AND IMPLIED,\\nINCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OF TITLE, NON-INFRINGEMENT,\\nMERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE FOR\\nDETERMINING THE APPROPRIATENESS OF USING OR REDISTRIBUTING THE LLAMA MATERIALS AND\\nASSUME ANY RISKS ASSOCIATED WITH YOUR USE OF THE LLAMA MATERIALS AND ANY OUTPUT AND\\nRESULTS.\\n\\n4. Limitation of Liability. IN NO EVENT WILL META OR ITS AFFILIATES BE LIABLE UNDER ANY THEORY OF\\nLIABILITY, WHETHER IN CONTRACT, TORT, NEGLIGENCE, PRODUCTS LIABILITY, OR OTHERWISE, ARISING\\nOUT OF THIS AGREEMENT, FOR ANY LOST PROFITS OR ANY INDIRECT, SPECIAL, CONSEQUENTIAL,\\nINCIDENTAL, EXEMPLARY OR PUNITIVE DAMAGES, EVEN IF META OR ITS AFFILIATES HAVE BEEN ADVISED\\nOF THE POSSIBILITY OF ANY OF THE FOREGOING.\\n\\n5. Intellectual Property.\\n\\n  a. No trademark licenses are granted under this Agreement, and in connection with the Llama\\nMaterials, neither Meta nor Licensee may use any name or mark owned by or associated with the other\\nor any of its affiliates, except as required for reasonable and customary use in describing and\\nredistributing the Llama Materials or as set forth in this Section 5(a). Meta hereby grants you a license to\\nuse “Llama” (the “Mark”) solely as required to comply with the last sentence of Section 1.b.i. You will\\ncomply with Meta’s brand guidelines (currently accessible at\\nhttps://about.meta.com/brand/resources/meta/company-brand/ ). All goodwill arising out of your use\\nof the Mark will inure to the benefit of Meta.\\n\\n  b. Subject to Meta’s ownership of Llama Materials and derivatives made by or for Meta, with\\nrespect to any derivative works and modifications of the Llama Materials that are made by you, as\\nbetween you and Meta, you are and will be the owner of such derivative works and modifications.\\n\\n  c. If you institute litigation or other proceedings against Meta or any entity (including a\\ncross-claim or counterclaim in a lawsuit) alleging that the Llama Materials or Llama 3.1 outputs or\\nresults, or any portion of any of the foregoing, constitutes infringement of intellectual property or other\\nrights owned or licensable by you, then any licenses granted to you under this Agreement shall\\nterminate as of the date such litigation or claim is filed or instituted. You will indemnify and hold\\nharmless Meta from and against any claim by any third party arising out of or related to your use or\\ndistribution of the Llama Materials.\\n\\n6. Term and Termination. The term of this Agreement will commence upon your acceptance of this\\nAgreement or access to the Llama Materials and will continue in full force and effect until terminated in\\naccordance with the terms and conditions herein. Meta may terminate this Agreement if you are in\\nbreach of any term or condition of this Agreement. Upon termination of this Agreement, you shall delete\\nand cease use of the Llama Materials. Sections 3, 4 and 7 shall survive the termination of this\\nAgreement.\\n\\n7. Governing Law and Jurisdiction. This Agreement will be governed and construed under the laws of\\nthe State of California without regard to choice of law principles, and the UN Convention on Contracts\\nfor the International Sale of Goods does not apply to this Agreement. The courts of California shall have\\nexclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n# Llama 3.1 Acceptable Use Policy\\n\\nMeta is committed to promoting safe and fair use of its tools and features, including Llama 3.1. If you\\naccess or use Llama 3.1, you agree to this Acceptable Use Policy (“Policy”). The most recent copy of\\nthis policy can be found at [https://llama.meta.com/llama3_1/use-policy](https://llama.meta.com/llama3_1/use-policy)\\n\\n## Prohibited Uses\\n\\nWe want everyone to use Llama 3.1 safely and responsibly. You agree you will not use, or allow\\nothers to use, Llama 3.1 to:\\n\\n1. Violate the law or others’ rights, including to:\\n    1. Engage in, promote, generate, contribute to, encourage, plan, incite, or further illegal or unlawful activity or content, such as:\\n        1. Violence or terrorism\\n        2. Exploitation or harm to children, including the solicitation, creation, acquisition, or dissemination of child exploitative content or failure to report Child Sexual Abuse Material\\n        3. Human trafficking, exploitation, and sexual violence\\n        4. The illegal distribution of information or materials to minors, including obscene materials, or failure to employ legally required age-gating in connection with such information or materials.\\n        5. Sexual solicitation\\n        6. Any other criminal activity\\n    3. Engage in, promote, incite, or facilitate the harassment, abuse, threatening, or bullying of individuals or groups of individuals\\n    4. Engage in, promote, incite, or facilitate discrimination or other unlawful or harmful conduct in the provision of employment, employment benefits, credit, housing, other economic benefits, or other essential goods and services\\n    5. Engage in the unauthorized or unlicensed practice of any profession including, but not limited to, financial, legal, medical/health, or related professional practices\\n    6. Collect, process, disclose, generate, or infer health, demographic, or other sensitive personal or private information about individuals without rights and consents required by applicable laws\\n    7. Engage in or facilitate any action or generate any content that infringes, misappropriates, or otherwise violates any third-party rights, including the outputs or results of any products or services using the Llama Materials\\n    8. Create, generate, or facilitate the creation of malicious code, malware, computer viruses or do anything else that could disable, overburden, interfere with or impair the proper working, integrity, operation or appearance of a website or computer system\\n\\n2. Engage in, promote, incite, facilitate, or assist in the planning or development of activities that present a risk of death or bodily harm to individuals, including use of Llama 3.1 related to the following:\\n    1. Military, warfare, nuclear industries or applications, espionage, use for materials or activities that are subject to the International Traffic Arms Regulations (ITAR) maintained by the United States Department of State\\n    2. Guns and illegal weapons (including weapon development)\\n    3. Illegal drugs and regulated/controlled substances\\n    4. Operation of critical infrastructure, transportation technologies, or heavy machinery\\n    5. Self-harm or harm to others, including suicide, cutting, and eating disorders\\n    6. Any content intended to incite or promote violence, abuse, or any infliction of bodily harm to an individual\\n\\n3. Intentionally deceive or mislead others, including use of Llama 3.1 related to the following:\\n    1. Generating, promoting, or furthering fraud or the creation or promotion of disinformation\\n    2. Generating, promoting, or furthering defamatory content, including the creation of defamatory statements, images, or other content\\n    3. Generating, promoting, or further distributing spam\\n    4. Impersonating another individual without consent, authorization, or legal right\\n    5. Representing that the use of Llama 3.1 or outputs are human-generated\\n    6. Generating or facilitating false online engagement, including fake reviews and other means of fake online engagement\\n\\n4. Fail to appropriately disclose to end users any known dangers of your AI system\\n\\nPlease report any violation of this Policy, software “bug,” or other problems that could lead to a violation\\nof this Policy through one of the following means:\\n\\n* Reporting issues with the model: [https://github.com/meta-llama/llama-models/issues](https://github.com/meta-llama/llama-models/issues)\\n* Reporting risky content generated by the model: developers.facebook.com/llama_output_feedback\\n* Reporting bugs and security concerns: facebook.com/whitehat/info\\n* Reporting violations of the Acceptable Use Policy or unlicensed uses of Llama 3.1: LlamaUseReport@meta.com\"\\n', license='LLAMA 3.1 COMMUNITY LICENSE AGREEMENT\\nLlama 3.1 Version Release Date: July 23, 2024\\n\\n“Agreement” means the terms and conditions for use, reproduction, distribution and modification of the\\nLlama Materials set forth herein.\\n\\n“Documentation” means the specifications, manuals and documentation accompanying Llama 3.1\\ndistributed by Meta at https://llama.meta.com/doc/overview.\\n\\n“Licensee” or “you” means you, or your employer or any other person or entity (if you are entering into\\nthis Agreement on such person or entity’s behalf), of the age required under applicable laws, rules or\\nregulations to provide legal consent and that has legal authority to bind your employer or such other\\nperson or entity if you are entering in this Agreement on their behalf.\\n\\n“Llama 3.1” means the foundational large language models and software and algorithms, including\\nmachine-learning model code, trained model weights, inference-enabling code, training-enabling code,\\nfine-tuning enabling code and other elements of the foregoing distributed by Meta at\\nhttps://llama.meta.com/llama-downloads.\\n\\n“Llama Materials” means, collectively, Meta’s proprietary Llama 3.1 and Documentation (and any\\nportion thereof) made available under this Agreement.\\n\\n“Meta” or “we” means Meta Platforms Ireland Limited (if you are located in or, if you are an entity, your\\nprincipal place of business is in the EEA or Switzerland) and Meta Platforms, Inc. (if you are located\\noutside of the EEA or Switzerland).\\n\\nBy clicking “I Accept” below or by using or distributing any portion or element of the Llama Materials,\\nyou agree to be bound by this Agreement.\\n\\n1. License Rights and Redistribution.\\n\\n  a. Grant of Rights. You are granted a non-exclusive, worldwide, non-transferable and royalty-free\\nlimited license under Meta’s intellectual property or other rights owned by Meta embodied in the Llama\\nMaterials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the\\nLlama Materials.\\n\\n  b. Redistribution and Use.\\n\\n      i. If you distribute or make available the Llama Materials (or any derivative works\\nthereof), or a product or service (including another AI model) that contains any of them, you shall (A)\\nprovide a copy of this Agreement with any such Llama Materials; and (B) prominently display “Built with\\nLlama” on a related website, user interface, blogpost, about page, or product documentation. If you use\\nthe Llama Materials or any outputs or results of the Llama Materials to create, train, fine tune, or\\notherwise improve an AI model, which is distributed or made available, you shall also include “Llama” at\\nthe beginning of any such AI model name.\\n\\n      ii. If you receive Llama Materials, or any derivative works thereof, from a Licensee as part \\nof an integrated end user product, then Section 2 of this Agreement will not apply to you.\\n\\n      iii. You must retain in all copies of the Llama Materials that you distribute the following\\nattribution notice within a “Notice” text file distributed as a part of such copies: “Llama 3.1 is\\nlicensed under the Llama 3.1 Community License, Copyright © Meta Platforms, Inc. All Rights\\nReserved.”\\n\\n      iv. Your use of the Llama Materials must comply with applicable laws and regulations\\n(including trade compliance laws and regulations) and adhere to the Acceptable Use Policy for the Llama\\nMaterials (available at https://llama.meta.com/llama3_1/use-policy), which is hereby incorporated by\\nreference into this Agreement.\\n\\n2. Additional Commercial Terms. If, on the Llama 3.1 version release date, the monthly active users\\nof the products or services made available by or for Licensee, or Licensee’s affiliates, is greater than 700\\nmillion monthly active users in the preceding calendar month, you must request a license from Meta,\\nwhich Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the\\nrights under this Agreement unless or until Meta otherwise expressly grants you such rights.\\n\\n3. Disclaimer of Warranty. UNLESS REQUIRED BY APPLICABLE LAW, THE LLAMA MATERIALS AND ANY\\nOUTPUT AND RESULTS THEREFROM ARE PROVIDED ON AN “AS IS” BASIS, WITHOUT WARRANTIES OF\\nANY KIND, AND META DISCLAIMS ALL WARRANTIES OF ANY KIND, BOTH EXPRESS AND IMPLIED,\\nINCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OF TITLE, NON-INFRINGEMENT,\\nMERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE FOR\\nDETERMINING THE APPROPRIATENESS OF USING OR REDISTRIBUTING THE LLAMA MATERIALS AND\\nASSUME ANY RISKS ASSOCIATED WITH YOUR USE OF THE LLAMA MATERIALS AND ANY OUTPUT AND\\nRESULTS.\\n\\n4. Limitation of Liability. IN NO EVENT WILL META OR ITS AFFILIATES BE LIABLE UNDER ANY THEORY OF\\nLIABILITY, WHETHER IN CONTRACT, TORT, NEGLIGENCE, PRODUCTS LIABILITY, OR OTHERWISE, ARISING\\nOUT OF THIS AGREEMENT, FOR ANY LOST PROFITS OR ANY INDIRECT, SPECIAL, CONSEQUENTIAL,\\nINCIDENTAL, EXEMPLARY OR PUNITIVE DAMAGES, EVEN IF META OR ITS AFFILIATES HAVE BEEN ADVISED\\nOF THE POSSIBILITY OF ANY OF THE FOREGOING.\\n\\n5. Intellectual Property.\\n\\n  a. No trademark licenses are granted under this Agreement, and in connection with the Llama\\nMaterials, neither Meta nor Licensee may use any name or mark owned by or associated with the other\\nor any of its affiliates, except as required for reasonable and customary use in describing and\\nredistributing the Llama Materials or as set forth in this Section 5(a). Meta hereby grants you a license to\\nuse “Llama” (the “Mark”) solely as required to comply with the last sentence of Section 1.b.i. You will\\ncomply with Meta’s brand guidelines (currently accessible at\\nhttps://about.meta.com/brand/resources/meta/company-brand/ ). All goodwill arising out of your use\\nof the Mark will inure to the benefit of Meta.\\n\\n  b. Subject to Meta’s ownership of Llama Materials and derivatives made by or for Meta, with\\nrespect to any derivative works and modifications of the Llama Materials that are made by you, as\\nbetween you and Meta, you are and will be the owner of such derivative works and modifications.\\n\\n  c. If you institute litigation or other proceedings against Meta or any entity (including a\\ncross-claim or counterclaim in a lawsuit) alleging that the Llama Materials or Llama 3.1 outputs or\\nresults, or any portion of any of the foregoing, constitutes infringement of intellectual property or other\\nrights owned or licensable by you, then any licenses granted to you under this Agreement shall\\nterminate as of the date such litigation or claim is filed or instituted. You will indemnify and hold\\nharmless Meta from and against any claim by any third party arising out of or related to your use or\\ndistribution of the Llama Materials.\\n\\n6. Term and Termination. The term of this Agreement will commence upon your acceptance of this\\nAgreement or access to the Llama Materials and will continue in full force and effect until terminated in\\naccordance with the terms and conditions herein. Meta may terminate this Agreement if you are in\\nbreach of any term or condition of this Agreement. Upon termination of this Agreement, you shall delete\\nand cease use of the Llama Materials. Sections 3, 4 and 7 shall survive the termination of this\\nAgreement.\\n\\n7. Governing Law and Jurisdiction. This Agreement will be governed and construed under the laws of\\nthe State of California without regard to choice of law principles, and the UN Convention on Contracts\\nfor the International Sale of Goods does not apply to this Agreement. The courts of California shall have\\nexclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n# Llama 3.1 Acceptable Use Policy\\n\\nMeta is committed to promoting safe and fair use of its tools and features, including Llama 3.1. If you\\naccess or use Llama 3.1, you agree to this Acceptable Use Policy (“Policy”). The most recent copy of\\nthis policy can be found at [https://llama.meta.com/llama3_1/use-policy](https://llama.meta.com/llama3_1/use-policy)\\n\\n## Prohibited Uses\\n\\nWe want everyone to use Llama 3.1 safely and responsibly. You agree you will not use, or allow\\nothers to use, Llama 3.1 to:\\n\\n1. Violate the law or others’ rights, including to:\\n    1. Engage in, promote, generate, contribute to, encourage, plan, incite, or further illegal or unlawful activity or content, such as:\\n        1. Violence or terrorism\\n        2. Exploitation or harm to children, including the solicitation, creation, acquisition, or dissemination of child exploitative content or failure to report Child Sexual Abuse Material\\n        3. Human trafficking, exploitation, and sexual violence\\n        4. The illegal distribution of information or materials to minors, including obscene materials, or failure to employ legally required age-gating in connection with such information or materials.\\n        5. Sexual solicitation\\n        6. Any other criminal activity\\n    3. Engage in, promote, incite, or facilitate the harassment, abuse, threatening, or bullying of individuals or groups of individuals\\n    4. Engage in, promote, incite, or facilitate discrimination or other unlawful or harmful conduct in the provision of employment, employment benefits, credit, housing, other economic benefits, or other essential goods and services\\n    5. Engage in the unauthorized or unlicensed practice of any profession including, but not limited to, financial, legal, medical/health, or related professional practices\\n    6. Collect, process, disclose, generate, or infer health, demographic, or other sensitive personal or private information about individuals without rights and consents required by applicable laws\\n    7. Engage in or facilitate any action or generate any content that infringes, misappropriates, or otherwise violates any third-party rights, including the outputs or results of any products or services using the Llama Materials\\n    8. Create, generate, or facilitate the creation of malicious code, malware, computer viruses or do anything else that could disable, overburden, interfere with or impair the proper working, integrity, operation or appearance of a website or computer system\\n\\n2. Engage in, promote, incite, facilitate, or assist in the planning or development of activities that present a risk of death or bodily harm to individuals, including use of Llama 3.1 related to the following:\\n    1. Military, warfare, nuclear industries or applications, espionage, use for materials or activities that are subject to the International Traffic Arms Regulations (ITAR) maintained by the United States Department of State\\n    2. Guns and illegal weapons (including weapon development)\\n    3. Illegal drugs and regulated/controlled substances\\n    4. Operation of critical infrastructure, transportation technologies, or heavy machinery\\n    5. Self-harm or harm to others, including suicide, cutting, and eating disorders\\n    6. Any content intended to incite or promote violence, abuse, or any infliction of bodily harm to an individual\\n\\n3. Intentionally deceive or mislead others, including use of Llama 3.1 related to the following:\\n    1. Generating, promoting, or furthering fraud or the creation or promotion of disinformation\\n    2. Generating, promoting, or furthering defamatory content, including the creation of defamatory statements, images, or other content\\n    3. Generating, promoting, or further distributing spam\\n    4. Impersonating another individual without consent, authorization, or legal right\\n    5. Representing that the use of Llama 3.1 or outputs are human-generated\\n    6. Generating or facilitating false online engagement, including fake reviews and other means of fake online engagement\\n\\n4. Fail to appropriately disclose to end users any known dangers of your AI system\\n\\nPlease report any violation of this Policy, software “bug,” or other problems that could lead to a violation\\nof this Policy through one of the following means:\\n\\n* Reporting issues with the model: [https://github.com/meta-llama/llama-models/issues](https://github.com/meta-llama/llama-models/issues)\\n* Reporting risky content generated by the model: developers.facebook.com/llama_output_feedback\\n* Reporting bugs and security concerns: facebook.com/whitehat/info\\n* Reporting violations of the Acceptable Use Policy or unlicensed uses of Llama 3.1: LlamaUseReport@meta.com', details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M'), modelinfo={'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'general.file_type': 15, 'general.finetune': 'Instruct', 'general.languages': None, 'general.license': 'llama3.1', 'general.parameter_count': 8030261312, 'general.quantization_version': 2, 'general.size_label': '8B', 'general.tags': None, 'general.type': 'model', 'llama.attention.head_count': 32, 'llama.attention.head_count_kv': 8, 'llama.attention.layer_norm_rms_epsilon': 1e-05, 'llama.block_count': 32, 'llama.context_length': 131072, 'llama.embedding_length': 4096, 'llama.feed_forward_length': 14336, 'llama.rope.dimension_count': 128, 'llama.rope.freq_base': 500000, 'llama.vocab_size': 128256, 'tokenizer.ggml.bos_token_id': 128000, 'tokenizer.ggml.eos_token_id': 128009, 'tokenizer.ggml.merges': None, 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None}, parameters='stop                           \"<|start_header_id|>\"\\nstop                           \"<|end_header_id|>\"\\nstop                           \"<|eot_id|>\"')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.show('llama3.1:8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfb4563c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedResponse(model='llama3.1:8b', created_at=None, done=None, done_reason=None, total_duration=13771611708, load_duration=13003152423, prompt_eval_count=5, prompt_eval_duration=None, eval_count=None, eval_duration=None, embeddings=[[-0.01936673, -0.016335309, 0.010500235, 0.012640309, -0.008382397, -0.0070123547, 0.010018112, -0.0062295045, 0.0076110763, -0.005243266, -0.0044069276, -0.009778513, -0.009192616, -0.0014424049, -4.105383e-07, 0.016774597, -0.022383217, -0.0002904055, -0.012512874, -0.0043807593, 0.019863166, -0.003627686, 0.0072256173, 0.01554155, -0.034741744, 0.0053445566, 0.013533217, 0.008982903, -0.011085375, -0.006031583, 0.003782622, 0.00787297, 0.022760691, 0.019526439, 0.053972542, -0.0017905999, 0.0031078288, 0.00977626, -0.0032927021, -0.013046428, 0.015456431, -0.0142626995, 0.010109175, 0.019162072, 0.015664848, -0.017895551, 0.0059482628, -0.0041574384, -0.002735969, -0.010922659, 0.011959368, 0.0074782264, 0.0009846555, 0.015870022, 0.011377611, -0.010752006, -0.0017778949, 0.011590376, -0.007632955, -0.005650016, -0.018031573, 0.0061018565, -0.030155946, 0.025146559, 0.0069150203, 0.00757003, 0.009986782, 0.008801019, -0.009108993, -0.019093161, -0.004326404, -0.011431535, -0.013544404, -0.006782254, 0.019734181, 0.011543013, -0.002273234, -0.0035494892, -0.010332128, -0.0012650582, -0.026337937, 0.01598951, 0.0059669, 0.016901588, -0.005212787, 0.00038520043, 0.02086635, -0.004768656, 0.00575605, 0.0015826874, 0.018581595, 0.008263711, -0.001957999, 0.0046948423, 0.009523908, -0.017491946, -0.018386943, 0.011629744, 0.0050029596, -0.01340788, 0.0041009653, -0.026279557, -0.013456625, 0.013655817, 0.003963238, 0.013147614, 0.025179774, -0.007405599, -0.011510507, 0.008689846, -0.0046357284, 0.0014052371, 0.010524598, -0.002458913, -0.001179606, 0.013112459, -0.016390055, -0.0057263435, -0.0025790348, -0.011985274, -0.0021818597, -0.017571675, -0.019434478, -0.0026768069, -0.005046154, 0.010310598, 0.03595003, -0.005596783, 0.027721666, -0.016734265, -0.005560116, 0.006611392, 0.0021726585, -0.008704152, -0.008998917, 0.002440663, 0.010752719, -0.022042327, 0.011333004, -0.008132854, -0.015918715, -0.0044668, -0.006115632, -0.0062834765, -0.008378522, 0.03063939, 0.018164247, -0.01926634, 0.0096027125, -0.007868175, 0.018834824, 0.014809134, 0.0045505967, -0.0141751, -0.015041681, -0.016460584, -0.009817271, 0.015136239, 0.009158881, -0.03258298, 0.017455317, -0.015371969, -0.0071744067, -0.013789971, -0.009893661, -0.0031286124, -0.00064947933, -0.0039757853, 0.0045101815, 0.012193808, -0.016182788, 0.008748229, -0.0066361674, -0.016484048, -0.0057847076, -0.004484171, -0.012636289, 0.0025478215, -0.001254994, -0.0035180412, -0.0054733544, 0.011094326, 0.014863666, -0.010345958, 0.14546022, 0.00027198403, -0.025841191, 0.01000871, 0.014459454, 0.010513021, -0.00020454734, 0.008601284, 0.007281848, 0.006365457, -0.006922241, -0.01077107, 0.0013473746, 0.02118757, 0.021654738, 0.0024429017, -0.030078206, -0.007476821, 0.0040669157, -0.01937094, 0.017576935, -0.007166298, -0.0020981382, -0.0044201748, -0.0023127533, -0.0102035245, 0.015839228, 0.010470776, -0.028673029, -0.01665707, 0.034928616, 0.021511592, 0.015672017, 0.021552622, 0.01593119, 0.0066678333, -0.0064845663, -0.013658969, -0.011561023, -0.0140775265, 0.012885354, 0.014397963, 0.00885561, -0.008579238, -0.000780538, -0.009813488, -0.0049400576, -0.01676294, -0.016915724, -0.016760493, -0.0018350077, -0.017006518, 0.022671876, 0.007743339, 0.002079503, 0.006923304, 0.0044597303, 0.0031563477, -0.02041442, 0.019485706, 0.016673632, 0.018042002, 0.0074120597, -0.010079773, -0.016738864, -0.010935283, -0.014302883, 0.0010626059, -0.014123086, -0.0075826366, -0.014132683, 0.012087986, 0.006777525, -0.00651412, -0.0066453135, -0.0013582478, -0.0019423729, 0.0008254703, 0.013652626, -0.015685193, -0.010236884, 0.010901309, -0.0012521175, 0.016434336, -0.011513456, -0.016561357, -0.0056253937, -0.015127933, -0.0039349967, -0.0042921146, 0.0023649489, -0.008821205, -0.0066792187, 0.0021705304, -0.029677905, 0.011736857, 0.0036719625, 0.033677116, 0.0009681049, 0.025154881, -0.014057896, 0.009972103, 0.006666627, -0.0037244135, 0.016828839, -0.0894874, 0.011004652, -0.0038619626, 0.026748395, -0.028076487, -0.012476369, -0.004498816, 0.006387546, -0.007003626, -0.008732674, -0.02197896, 0.0044699432, -0.00911936, -0.0050249775, -0.014215919, 0.0003628692, -0.012965081, 0.013524474, -0.034156207, -0.00084100483, -0.01447705, 0.0033357493, 0.03345524, -0.010577185, -0.00048334457, 0.0061412766, 0.012434184, -0.00010722409, 0.021425243, -0.020881834, 0.013946476, 0.018743705, -0.013591277, -0.00861278, 9.220292e-05, -0.01767464, 0.010329953, -0.009310987, -0.0014011727, 0.003195523, 0.011585375, 0.0014089923, -0.013423421, -0.019152468, -0.0027329857, -0.0043036807, 0.004754416, 0.026815515, 0.013084333, 0.0009848684, -0.0075599495, 0.0016825915, 0.025669098, -0.0021216548, 0.017970912, -0.0062116575, 0.008696311, -0.007989013, -0.011294775, -0.0055153193, -0.020389033, 0.009752342, 0.028454145, -0.0014795209, 0.01081549, -0.009482775, -0.017601036, 0.008877399, -0.008786729, 0.0077584786, 0.0053554294, 0.018067623, -0.003055518, 0.006281299, 0.017999448, -0.00014102155, -0.013217517, -0.0070832786, 0.016178776, -0.010266006, 0.022248125, -0.003673902, 0.0036131763, 0.010100344, 0.0070002135, -0.0047545535, -0.0028936348, 0.0095190415, 0.008235501, -0.0031481585, -0.012113668, 0.0007164768, 0.002070056, -0.0021265089, 0.022317713, 0.02208759, 0.00336486, -0.0012732602, -0.008217461, -0.0054378724, -0.0067773154, 0.008581613, 0.024022458, -0.0033090867, -0.0077179326, 0.0197398, -0.0058797845, 0.011920708, 0.024021652, 0.003814174, 0.00883618, 0.013833818, 0.00048882863, -0.060619194, -0.029393839, 0.009844157, 0.011242465, 0.04457909, 0.0014097191, 0.011802413, -0.019305488, -0.007549859, 0.0038086579, 0.014801292, 0.002531149, 0.0091306865, 0.007612461, 0.010012579, -0.025806408, -0.026022175, 0.0025963483, -0.01958587, 0.012720469, 0.0057886094, -0.021406412, -0.017386327, 0.00248606, -0.02022044, -0.01049608, -0.0147204595, -0.023724064, 0.0048634233, -0.009733347, 0.0071658962, -0.017069496, 0.0020590818, -0.0073346836, 0.0024721115, -0.0024628604, -0.0012933994, 0.0073227086, 0.011856264, -0.009613136, -0.0042213514, 0.00440663, -0.018665958, 0.012592436, -0.0041667526, -0.0062682647, 0.028428394, 0.016938047, 0.0021687758, -0.016745217, 0.01955662, 0.018237017, 0.028667185, 0.013777958, -0.023737691, 0.008960851, -0.07753053, -0.0030773422, 0.0024467895, 0.014418399, -0.0043038125, 0.013002803, -0.0023949961, 0.012290775, -0.002879508, 0.017642757, -0.007394273, 0.013591992, -0.00754321, -0.015665889, -0.009117531, -0.008548785, 0.010221672, 0.009450759, 0.026394902, 0.017555144, -0.0038226463, -0.025637023, 0.016820678, -0.0053486936, 0.0012494191, 0.0144635355, 0.02630975, 0.008327395, -0.0018587789, 0.008730562, -0.0019090762, -0.0033241413, 0.013214934, -0.027023533, -0.015281993, -0.007695836, 0.0028110626, 0.009793612, -0.007880838, -0.029046427, -0.01967791, -0.0017550486, -0.0039636306, -0.005481251, 0.0048729503, -0.016596682, 0.0035417117, -0.013644295, -0.012373431, 0.0020025047, -0.0020301163, 0.008161077, -0.002860392, 0.0032698854, -0.023015948, -0.0033518446, -0.0056421324, -0.010188262, -0.024717981, -0.017672615, 0.047276124, -0.014695839, 0.017813446, 0.0055525885, 0.0038258866, 0.020923719, 0.005561141, 0.0042209122, -0.009250494, 0.00083293946, -0.019324893, -0.0056568854, 0.0005103884, 0.019132063, 0.01348936, -0.005541375, -0.003966878, 0.013504612, -0.0015017522, -0.00447544, -0.013295081, -0.007407345, -0.013641448, -0.005266626, -0.010712984, 0.0021578283, -0.005952492, -0.011805271, 0.013523631, 0.014746374, -0.01207845, 0.004827455, -0.015162965, -0.0048645255, 0.008435131, -0.013763122, 0.011138842, 0.013267843, 0.007950033, 0.003463912, -0.00056530593, -0.0011370439, -0.0073042554, 0.0065566353, 0.0020137622, -0.019871004, -0.015597129, 0.022873638, 0.008499622, 0.0072082747, -0.0025663883, -0.0026737899, 0.0025664277, 0.02523455, 0.0074665956, -0.0081942985, 0.005429278, -0.002697756, -0.018209869, 0.025016818, -0.040102344, 0.007017754, -0.0062996172, 0.0015389094, -0.015371726, 0.01868182, 0.010075777, -0.008392175, 0.012023537, 0.014870531, 0.008305263, -0.0027233176, 0.0026855664, -0.0019338853, -0.005361962, -0.01101482, 0.004559058, 0.004462271, 0.0115465075, -0.0028840953, -0.0109330425, 0.02074828, -0.0018913749, -0.009896005, 0.012055841, 0.014643014, 0.01453716, -0.003888567, 0.017658142, -0.02042488, -0.0061949454, -0.0036496753, -0.0015234763, 0.025765853, -0.0021210748, 0.03127635, -0.004823271, 0.01247412, 0.010193235, 0.017668389, -0.033056617, -0.010527049, -0.00891201, 0.035185482, 0.002117115, -0.0013362528, 0.017187672, -0.016545802, 0.02004752, -0.0041110865, 0.0030494349, -0.011299952, -0.011108666, 0.024413418, 0.00466516, 0.005242068, 0.0031948972, 0.019448366, 0.014173472, -0.029900197, 0.015197436, -0.01832307, 0.0056839404, 0.062289648, 0.023102017, 0.012041779, -0.017771171, -0.002149143, 0.0015230603, -0.0112072835, -0.0008965632, 0.014059027, 0.00807353, -0.0035103457, -0.015761092, 0.031553697, -0.0027907307, -0.0073797903, 0.010079425, -0.0041596666, 0.0015916306, 0.00047868246, 0.018311117, 0.013682544, -0.011906504, -0.01499641, 0.0032075047, -0.0042046662, -0.018391507, 0.0019665344, -0.010216358, -0.00045190717, 0.014885533, -0.0140937595, -0.002201788, 0.0012058098, 0.019019786, 0.0071394653, 0.019187648, 0.00825804, -0.014071908, -0.0026848777, -0.010921147, -0.020515904, 0.011232828, -0.0034793164, 0.01438567, -0.0217062, -0.0011107359, 0.0066108927, -0.020545427, -0.0026381009, -0.008009726, 0.013534794, 0.025228336, 0.005647422, 0.016793901, -0.016251229, 0.018130258, 0.041598383, 0.021631908, -0.0025833612, 0.0038742106, -0.0019431972, 0.01543803, 0.01189455, -0.0038631172, -0.0134591535, -0.0037969653, 0.004004102, 0.026439557, -0.0206965, 0.01034722, -0.006005365, -0.014385266, -0.0072782785, 0.009532148, -0.009736496, 0.0057617244, -0.02397773, 0.0052351924, -0.015576838, -0.0053498796, 0.025750995, 0.014747073, 0.016334359, 0.0142251, -0.010356582, -0.004344561, 0.0034272803, 0.02705442, -0.00011482391, -0.02618869, 0.007837703, -0.020485267, -0.001398603, 0.003210434, -0.0049499264, -0.010196701, -0.017047543, 0.02579427, 0.0023146858, -0.007215896, 0.017588882, 0.004978847, 0.0029768317, 0.008704354, 0.020842694, -0.01588716, 0.0011634601, -0.0059223715, 0.010220214, 0.0045687505, -0.003586281, 0.021835893, -0.024051446, 0.023706717, 0.004949662, 0.008931667, -0.009694135, 0.028441722, 0.016759496, -0.006245974, -0.030765986, -0.0029480192, -0.0076224413, 0.014612777, 0.007875278, 0.010038835, -0.009947416, 0.024398481, 0.005959892, -0.002554682, -0.005696531, -0.012350401, -0.016232269, 0.010765024, -0.0006604136, -0.0074669234, -0.00944072, -0.0012537105, 0.000500922, 0.0016829771, 0.02142741, -0.030845584, 0.0059162527, -0.014258214, 0.012825984, -0.014205702, -0.00517732, -0.0068415273, 0.0038737024, 0.009538878, -0.01279813, 0.0006116062, 0.020024806, -0.010171663, 0.003728061, -0.011068249, 0.013392108, 0.0011203461, 0.012096648, -0.028143806, 0.01773184, -0.009920678, -0.012656221, -0.0154884355, 0.009657275, -0.0050663995, 0.016500408, -0.010898344, 0.017300349, 0.0061057955, 0.018503055, -0.010857369, 0.012982937, 0.015095436, -0.0022589625, -0.008966261, -0.01401277, 0.0025829761, -0.0056025414, -0.0012373945, -0.0015996448, -0.0014708705, 0.010267228, -0.012864364, -0.024875633, 0.009557708, -0.0042803762, -0.0117446855, 0.013823255, -0.013397453, -0.014219041, -0.018418616, 0.010609657, 0.003951357, 0.0022403023, -0.01162164, 0.0106601715, 0.0019457114, 0.018343253, -0.023332214, -0.0126523925, 0.009783008, -0.007857696, 0.0030789848, 0.008851906, -0.046557862, 0.008722245, 0.009230406, 0.0012004131, 0.004408159, 0.002414409, -0.0006452787, 0.013459397, -0.005372331, 0.020510197, 0.010049155, -0.026206128, 0.012862665, -0.0052423435, -0.023215137, 5.3842985e-05, -0.004630768, -0.02084918, -0.011205212, 0.016327912, 0.007885367, 0.005870096, 0.0030617511, -0.0092433, -0.014075523, 0.023322891, -0.0018839429, 0.003695999, -0.0001958342, -0.008269514, -0.005411319, 0.015891666, 0.012254454, -0.01533402, -0.007922363, -0.0078077083, 0.0001309031, 0.011210728, -0.010441955, 0.030731672, 0.031937648, 0.007707338, -0.023381665, -0.04954632, -0.01483137, -0.0079083955, 0.005187822, 0.058221962, -0.002897461, -0.01978676, 0.010171973, -0.007933887, -0.006058946, 0.012309008, -0.014878336, 0.011271038, 0.017573798, 0.004161158, -0.017675363, -0.007031663, 0.027672978, 0.014049677, -0.00785275, -0.022309262, -0.116876125, -0.0038195995, -0.010550682, 0.022518575, -0.008335221, -0.0032784794, 0.016319925, 0.003368503, 0.004593295, -0.008711954, 0.00264438, 0.002248293, -0.001911628, -0.0029854826, -0.0023887218, 0.006683926, 0.0073875245, 0.017205076, -0.013652837, 0.0131530985, 0.00052228844, 0.009699237, 0.002192796, -0.0015588255, -0.0015471195, 0.0027722092, 0.005290511, -0.009649412, -0.0071810423, -0.011332481, 0.1017773, 0.0015584674, 0.014058007, -0.01634771, 0.007248641, -0.013376335, -0.023097618, 0.007563591, -0.025681853, -0.00028289144, 0.006920917, 0.02603994, 0.0044778064, 0.008701298, -0.0005457335, -0.0036963779, 0.008066196, 0.009121783, -0.023704315, -0.0031575405, -0.025266457, 0.0011849822, -0.0026789024, -0.001956892, 0.010588038, 0.0033749086, 0.016535219, 0.0035539104, -0.01948927, 0.013060489, 0.020957172, -0.0015050645, 0.00074879214, 0.005014239, -0.008401562, 0.0035843942, -0.0019708227, -0.0591898, 0.026755989, 0.004344032, 0.012532604, 0.010884459, 0.003751072, 0.011680534, -0.014039077, -0.003744714, 0.0143943, -0.0061341566, 0.004609881, -0.01761439, 0.03063407, 0.004746972, -0.0039999182, -0.0011502391, 0.008293543, 0.01434003, -0.0004544651, -0.0037608973, 0.0030715256, 0.01678912, -0.008411889, -0.0013678572, 0.0037790595, 0.0049573197, 0.0013570182, 0.012356246, 0.0073391995, -0.0006510118, -0.010031866, 0.0077056396, 0.0052975295, -0.000810359, 0.017284073, -0.023880873, -0.0053342804, 0.025934508, 0.0037535406, 0.007083231, -0.017182704, -0.012961641, -0.015284157, 0.012864774, 0.005959319, 0.017356075, 0.01910918, -0.020193571, -0.020649496, -0.02884352, 0.007525925, 0.010077933, -0.0013211672, -0.011628036, 0.014640971, 0.015492999, 0.0199598, 0.0023891795, 0.021965554, -0.01426809, 0.0013533472, -0.019880816, -0.0039228173, -0.0050508827, -0.012787362, -0.007453313, -0.0008017687, -0.0068504927, 0.017206045, -0.0047665955, 0.002744035, -0.0011495069, 0.018716604, 0.011883956, -0.0010341753, 0.006303791, -0.013472449, -0.0063345362, -0.014701727, -0.018093161, -0.012978976, -0.008080938, 0.005034997, -0.035737175, -0.016562518, 0.01802401, -0.0012550749, 0.011345178, -0.0006184469, 0.04363367, 0.013827557, 0.024354879, -0.0012863954, -0.010248051, 0.020183848, -0.017019209, -0.0004207924, -0.0075777513, 0.019592673, 0.0074815843, 0.018585226, -0.006172435, -0.0048126825, -0.008570491, 0.009065352, -0.005630014, 0.013239539, -0.014780592, -0.007790076, 0.01589226, 0.0050953985, 0.010287118, 0.0065362547, 0.0027348176, -0.004963791, -0.013906152, 0.0040137204, 0.003965004, -0.0036102952, -0.0179758, 0.017426005, -0.013651923, -0.001134463, -0.031490196, -0.007936992, -0.0043881307, 0.0071596424, 0.0063063717, 0.011675212, 0.020567495, 0.022585664, 0.024936724, 0.01615293, -0.019804016, -0.011937332, -0.011784592, 0.005933929, -0.012801501, -0.010325027, -0.016356168, -0.018910427, 0.0152435955, -0.009808631, 0.0025089271, -0.013735947, 0.005007464, 0.010751767, -0.02682574, -0.0148634715, -0.010572733, 0.018051337, 0.009145868, -0.0057030986, 0.0002744955, -0.0009901561, -0.011568864, -0.005943813, -0.0059337155, 0.0014382395, -0.01874113, 0.006687948, 0.025237417, -0.01654397, -0.023471529, 0.0012088483, 0.012618784, 0.009409514, -0.016762165, 0.013223758, -0.012208598, -0.009185384, 0.0098105, 0.023578078, -0.0025804385, 0.008157984, 0.00183667, -0.0044946256, 0.030371541, 0.0179554, 0.0068809125, 0.0007180042, 0.0033682752, 0.0111499205, -0.008736853, 0.004057257, 0.009742586, 0.02423206, 0.0016961072, -0.00032172588, -0.008849885, 0.012782709, -0.01338062, 0.00043003823, -0.012974898, -0.0060822144, -0.005448392, 0.0008741597, -0.010243329, -0.021095563, 0.029900165, 0.009296177, 0.005194503, -0.0029276814, -0.0025991243, -0.0011523546, 0.0037019071, -0.0024014409, -0.0016370459, -0.004611427, -0.004781429, 0.051791765, 0.06781077, 0.018453624, 0.0026749286, 0.0028629908, 0.015616499, -0.00054380373, 0.017610557, 0.013966327, -0.008200699, 0.029232616, -0.022033608, -0.0021968642, -0.010645194, -0.009888892, -0.02250835, -0.005658513, -0.006170813, -0.027678533, -0.010355719, -0.0035076803, 0.015800674, -0.0050485455, -0.0001622738, -0.018005842, -0.00910639, 0.014102414, -0.011242712, 0.027493274, 0.010950912, -0.012036606, 0.0026323786, -0.0072731487, 0.016729863, -0.0016460427, -0.0037714746, -0.027251204, 0.009071755, -0.004192277, -0.0011989662, -0.011915774, 0.0066548646, -0.019499803, -0.02229194, 0.024669796, 0.006983692, -0.00090176833, 0.01057515, 0.008200774, 0.017552683, -0.0015108383, -0.005660301, 0.03816476, 0.0019544356, -0.016018035, 0.00088500977, 0.0143001685, 0.011171615, -0.007948407, 0.008704749, -0.022058612, -0.021317327, -0.0097943265, 0.009478604, 0.012384394, 0.006340799, 0.022447199, -7.983521e-05, -0.021953769, -0.0072198072, 0.0013748503, 0.010558555, -0.009817757, 0.0006468815, -0.0040541072, -0.00094435207, -0.006625282, -0.0069759185, -0.021245915, -0.024182882, -0.020309355, -0.027320633, 0.0010732461, 0.0016809503, -0.0045968457, 0.0105341, -0.009533696, -0.0073533626, -0.0076751, 0.0011247686, -0.018323306, -0.018308382, 0.02367109, 0.019345634, 0.003005258, 0.006062522, 0.0017870455, 0.00971813, -0.038092677, -0.028474048, 0.0028223528, 0.0064210994, 0.025165793, 0.0119979335, 0.011896973, -0.014360338, 0.0073109264, -0.024990408, 0.0026393821, -0.008257902, 0.030613856, -0.005776984, 0.0077961734, -0.014639965, -0.020284528, -0.0063866368, 0.0035624842, 0.004534853, 0.004681895, -0.011421133, 0.008841777, -0.0010800477, -0.014829762, -0.010905111, 0.013140922, 0.012145487, -0.056136873, -0.013031701, -0.0004092707, -0.010856826, -0.0036982477, -0.008560922, -0.041225996, -0.0034690388, 0.016525708, -0.003822215, -0.0044438546, 0.019639648, -0.00040250376, 0.0055632554, -0.00607499, 0.0064340546, 0.0014977743, -0.0011609613, -0.0017533445, 0.013665679, -0.0120636085, -0.004877641, -0.008994603, -0.0033233678, -0.031734373, -0.0023293442, -0.0068338024, 0.029626377, -0.006533504, 0.0013577695, -0.029219052, 0.007249833, 0.0020012343, 0.014408189, -0.013251796, -0.04322225, 0.0077031096, 0.0017275561, -0.009612908, -0.015116759, 0.009716504, 0.005077729, -0.0028758158, -0.0027518303, 0.0027728006, 0.005578258, -0.012346342, 0.023916889, 0.012688464, 0.013663598, 0.007217975, -0.019972244, 0.0077840593, 0.008233291, -0.01520386, 0.008545392, -0.008866444, -0.0011303853, -0.007600382, 0.023949467, -0.00052669994, 1.8481945e-06, -0.004280595, -0.0011891115, -0.0003754278, -0.011769113, -0.007688734, -0.01130245, -0.051580597, -0.009527611, -0.0022771298, -0.021336248, -0.019537698, 0.015566179, 0.0039650155, -0.027068324, 0.018762361, 0.018140974, -0.015109366, -0.023382526, 0.013856724, 0.004739679, 0.0036847687, 0.010020688, -0.0072758896, 0.007041646, 0.011854467, 0.01926619, -0.0015263594, 0.00045088943, 0.012041261, 0.0007668756, -0.018047716, 0.0063700015, 0.01780805, 0.019570302, -0.014421908, -0.0029705046, -0.02240469, -0.0076220687, 0.017235689, 0.0038302706, -0.010109279, -0.010383168, -0.009076739, -0.0064533297, 0.022220183, 0.0016606512, -0.0012722228, 0.018160166, -0.021242552, 0.009575734, 0.0045153154, -0.0014550317, 0.0064978125, -0.0061610555, 0.001759122, -0.008621004, -0.030803258, -0.009485423, -0.0036281773, -0.00043812743, -0.0048974864, 0.0047585233, -0.004904135, 0.010512786, 0.012531685, -0.006530112, -0.017369715, -0.021276927, 0.012371646, 0.004499703, -0.0073605534, -0.016856551, -0.0060597067, 0.010591249, 0.0061269007, 0.056553986, -0.017221568, 0.002765618, -0.004074067, -0.013322545, 0.018316464, -0.011285506, -0.009838232, 0.015848897, 0.026461447, 0.0074692178, 0.00038414204, 0.0015193557, 0.0011676928, 0.012925999, -0.012599606, -0.022978898, -0.02464077, -0.004500029, 0.011878341, 0.02589131, 0.02361763, 0.012557549, 0.002355776, 0.001530378, 0.00042494418, 0.00013452429, -0.00037867573, -0.0016761931, 0.012281337, 0.026359286, 0.006458843, -0.030007776, 0.04465725, -0.020273393, -0.014389531, 0.0056646294, -0.01088561, -0.017755352, -0.0038682912, -0.0096942, 0.010205404, 0.002424728, -0.0029119148, -0.01957153, -0.010844673, 0.020180488, 0.0035348588, -0.0031755755, 0.016643291, 0.0097527215, 0.01834595, -0.0036753307, -0.0025699958, -0.003155526, -0.0018519989, -0.0050047105, 0.022106618, 0.0008128477, -0.0013883914, -0.020740116, -0.021341393, 0.005099716, -0.016473765, -0.005677903, 0.013510501, 0.00060340285, 0.019701865, 0.0019820728, 0.0001016231, 0.00025505814, 0.004127868, 0.0046019955, -0.0005199545, -0.013401275, -0.008711947, 0.004757357, -0.0015300501, -0.015693793, -0.007858906, -0.023266241, -0.01718112, 0.008921328, 0.011223853, -0.022166545, -0.008182644, 0.0047570206, 0.010896131, -0.004725257, -0.0029813386, 0.023337752, -0.033919036, -0.006296903, -0.011023766, 0.018430287, 0.000919374, 0.0021230113, 0.016482897, -0.015339213, -0.009590993, 0.00064945716, -0.019109474, -0.025748974, -0.0038436993, 0.0053550517, -0.007833265, 7.754034e-06, 0.0027249975, 0.015169735, 0.007219902, -0.014578049, -0.019153064, -0.011188659, 0.0031561784, -0.009371299, 0.012996158, 0.022311341, 0.008420842, 0.014682507, 0.011229483, -0.0007173036, 0.032746825, -0.010361316, -0.013638345, 0.010099985, -0.0027394972, 0.013494035, -0.003827643, -0.016903568, 0.0036992917, 0.003188527, 0.0039156605, -0.009792797, -0.011353114, 0.023377124, -0.0030924336, 0.01881513, -0.0034128595, 0.013226925, 0.027346734, -0.007920409, -0.0010316016, 0.026278349, -0.013088449, 0.030410137, 0.022505743, -0.024852816, -0.000671947, 0.02114132, -0.01349263, -0.0022601732, 0.007144698, 0.005177132, 0.007265956, -0.015518868, -0.0051333, -0.011182553, -0.014828579, 0.0057942066, -0.019462325, -0.005165971, -0.0039628986, 0.004519567, -0.008202464, 0.017534517, 0.0015125466, -0.00038069728, 0.01678152, 0.009019419, 0.016087582, 0.005347076, 0.0012483293, 0.004715336, 0.012457885, -0.0009666274, 0.0388839, 0.0052692294, 0.005985728, -0.012246317, -0.010408335, 0.02661981, 0.010833596, 0.017936753, 0.022126548, 0.010530314, -0.0030987966, 0.015006373, 0.0051887184, 0.0023669, 0.00490661, 0.017027766, -0.013867262, 0.054117497, 0.007702287, 0.00077213853, -0.015672684, 0.0036881175, -0.0002152237, -0.009912199, 0.014591467, -0.009577857, -0.016394686, 0.012878471, -0.03177785, 0.014076756, -0.008106557, 0.015616499, -0.015977055, 0.014860547, 0.007568921, -0.010491887, -0.0030851606, 0.005271141, -0.01613529, 0.00053812633, 0.022613006, -0.018314028, -0.0072624604, 0.016105998, -0.017101593, 0.008177639, -0.012581622, 0.010429084, -0.014863787, -0.0018181362, 0.0024155637, -0.0048591555, -0.009565828, -0.004949874, 0.0050927526, -0.033832792, 0.0066199102, 0.002353641, -0.018859228, -0.018555267, -0.0024411231, -0.0042294348, 0.012275094, 0.009303557, 0.029893087, 0.008658124, -0.0046681166, 0.009788466, 0.00649101, -0.0044446653, -0.001333934, -0.009406435, 0.004469391, 0.010952013, -0.010526499, -0.0028200005, -0.011277347, -0.0039293887, 0.012049722, -0.0059593986, -0.026806785, -0.010164981, -0.0053158673, 0.012092571, -0.015423933, -0.01257333, 0.002926987, 0.004488516, -0.08931619, -0.011715459, -0.0036713795, 0.007424432, -0.0017977894, -0.0018531047, -0.006634155, -0.016762782, 0.012219184, -0.0062636524, -0.014238362, -0.008056104, 0.050479915, -0.012510744, -0.020772211, -0.00020791245, -0.00662114, -0.024377776, -0.014685821, 0.012572499, -0.009742656, -0.009086685, 0.022690821, 0.008662665, -0.0006012382, -0.0075867316, 0.025661327, -2.5100597e-05, 0.0073748864, -0.026008299, -0.008422995, 0.012668926, 0.013567953, -0.015896935, -0.0012509857, 0.016879836, 0.039454393, -0.006992968, 0.008985722, 0.11268508, -0.016412724, -0.024753077, -0.009702303, 0.034067195, -0.011300487, -0.0139905745, 0.018644271, 0.0037310561, -0.0045743193, -9.459842e-05, -0.005246354, 0.009507792, -0.028260522, 0.005385855, 0.010635269, -0.005630562, 0.011725626, -0.009933793, 0.011405017, 0.0012587991, 0.0014306309, 0.005680571, 0.009392795, -0.009995182, 0.0005020407, 0.0063080117, 0.006704153, -0.004769983, -0.022570664, -0.0048996774, -0.0029962559, -0.013975082, -0.025222288, 0.0059558842, 7.2046176e-05, 0.010685127, 0.0033413074, -0.00909072, 0.0010708629, 0.0058850776, -0.00020484986, -0.031722445, 0.015389641, -0.009241023, -0.011370303, -0.018785637, 0.0077833524, 0.010140617, 0.009692906, -0.0034231618, 0.001934119, 0.0100879865, -0.013372506, -0.013938198, 0.0077733467, 0.0033002743, 0.01925578, -0.014846146, 0.01563031, 0.0041232393, -0.014031545, 0.038650226, -0.0006123009, -0.023726592, 0.01950151, -0.00079788576, 0.012449605, -0.010446553, 0.0031836438, 0.008110492, 0.006468701, -0.007798219, 0.0075579644, -0.022006616, -0.008501151, -0.0032581284, -0.0037365595, -0.01370038, 0.017359799, 0.008179306, -0.023458976, -0.013802294, -0.005953077, -0.003806721, 0.010727489, 0.0041278754, 0.014780457, -0.013171392, 0.0016762213, -0.00036273472, -0.0040465267, -0.023722645, -0.0036029385, 0.0073198834, -0.00047170432, -0.019383054, -0.0042789495, 0.007987853, -0.027170528, 0.003439058, 0.01492651, -0.010499549, 0.001490711, 0.0065144, -0.0064310026, -0.024378283, 0.023727482, -0.0010041401, 0.017752925, -0.003632732, -0.00599966, 0.002792019, 0.005064727, 0.005119427, -0.002614703, -0.006829296, -0.0028327936, 0.004202442, -0.0075439056, -0.013580567, 0.000623994, 0.001284112, -0.007835186, -0.022331806, 0.0019442018, 0.010072028, -0.0059542125, -0.008336268, 0.022744559, -0.014621574, -0.015451711, 0.0013411338, 0.00930353, 0.00078606675, 0.0081248125, -0.015993902, -0.0005138868, -0.014747694, 0.0034719359, 0.018600093, -0.0032013308, -0.018045763, -0.0018437211, -0.007968272, 0.0019037087, -0.009481505, -0.0027654117, 0.014912124, 0.014228897, -0.009735763, -0.010195093, 0.015350242, 0.010406145, 0.007951907, 0.0043755225, 0.023729907, 0.018702706, 0.016801596, 0.019246904, -0.017184235, 0.021348393, -0.017779829, 0.0063654734, 0.09146671, -0.03162835, -0.023026982, -0.019685602, 0.0046901954, -0.01834138, 0.006607655, 0.019875562, -0.010231983, -0.0032038535, -0.0059709516, 0.0007465201, 0.013705489, 0.0026638312, -0.0067233797, -0.0043643755, 0.0058696484, -0.013326066, -0.007786569, -0.005777954, -0.00024224611, 0.0041920515, 0.002588114, -0.005358666, 0.020714018, -0.0032325007, -0.0031879167, 0.037110906, -0.005649444, -0.031976826, -0.0010951437, -0.01853854, -0.034234233, -0.031773455, 0.022562513, -0.009990563, -0.021343747, 0.0035919116, 0.01198772, 0.004389047, -0.010618399, 0.0046209306, -0.026552862, -0.005293462, 0.0043246197, -0.009821227, -0.016236855, -0.020254958, -0.012145104, 0.0043047303, 0.004518409, -0.007465909, -0.025085503, 0.017825872, -0.064309314, 0.03096187, 0.0013451118, 0.009493706, 0.019526875, -0.010409689, -0.00943641, 0.003001136, -0.0060923467, -0.0043216194, -0.0063433, 0.0027018122, -0.013739405, 0.009258292, 0.0063886433, 0.024764894, 0.010109668, -0.0030140572, -0.010428724, 0.011361218, -0.0064148847, 0.009364471, -0.0037198928, -0.009649749, -0.0014711005, -0.003804802, 0.0048291567, -0.023628244, -0.000284082, -0.019551482, -0.018002512, 0.0072125336, -0.007977113, 0.02376884, 0.004803392, 0.004077014, -0.0053913826, -0.02703388, -0.0011865918, -0.00786863, -0.017157426, 0.01778984, -0.014212548, -0.0048214654, -0.001270508, -0.01617614, 0.01111599, 0.0015486968, -0.0037920766, 0.0033244619, -0.0025732426, -0.011215148, -0.041377824, 0.025699139, 0.0029937543, 0.025537632, -0.0008599825, 0.0015326972, 0.0054537207, -0.0012608841, -0.006610777, -0.016043669, -0.0017038791, -0.00061955093, 0.008824453, 0.01184021, -0.015848368, -0.0017083826, -0.0060986094, 0.014598202, 0.019059088, -0.0050910874, 0.007787628, -0.019026466, -0.04089869, -0.009109186, -0.022427645, 0.02454169, -0.009081457, 0.022751238, -0.0035585377, 0.010722367, 0.021361118, -0.007840322, 0.020757316, -0.00572116, 0.006295188, -0.017220227, 0.01460403, -3.122613e-05, 0.002339584, -0.01683506, 0.013347748, -0.017547753, -0.020280493, -0.018588874, -0.0043645953, -0.015459902, 0.020605322, 0.0018329285, -0.008881364, -0.034636784, 0.0142286625, 0.004657626, -0.018094577, 0.06264297, 0.0003305539, 0.0073253647, -0.007401051, 0.004196385, -0.0026942212, -0.0055049835, 0.0097886, -0.03129383, -0.010766181, -0.026246717, -0.0060088467, -0.003318127, -0.016450312, -0.0018290867, -0.009093257, 0.019852513, 0.00559289, -0.01794287, 0.0033585061, -0.005347767, -0.0075527816, -0.02365644, -0.0027965144, -0.0015897973, -0.0075327917, 0.015582371, -0.009601705, 0.031568106, 0.002935674, -0.015847297, -0.010228958, 0.020921266, 0.020497443, -0.011113891, 0.004774254, -0.0217376, 0.015791288, 0.007979793, -0.0024555216, 0.044265702, -0.008621126, 0.0012052524, -0.026167378, 0.010700895, 0.002672427, -0.001632623, -0.011325659, 0.00065237033, 0.006232172, 0.00811646, 0.029578468, -0.010684901, 0.0023815432, -0.038255002, -0.002452105, -0.012477667, -0.018232225, -0.00598508, -0.0045516556, 0.017340181, 0.004941234, -0.010153002, -0.008991175, -0.0018539898, -0.012244681, -0.027181033, -0.0044675083, 0.0011671544, 0.0061974395, 0.0069240397, 0.011498556, -0.0009280929, -0.014075331, -0.010188169, -0.012400633, -0.016405314, 0.008647729, 0.0010756403, 0.009581856, 0.013106994, -0.007830917, -0.0047664796, 0.014279693, -0.0063685826, 0.016220719, 0.013317213, 0.0061042863, -0.011639291, -0.007078354, 0.011669426, 0.009882481, 0.031396665, 0.009164618, -0.007864078, -0.0073779654, -0.0033791037, 0.0038358679, 0.012854571, -0.0044708676, -0.041867476, 0.030826835, -0.01484758, -0.024670055, -0.0062045665, 0.014929795, 0.0048145875, 0.008270152, -0.0014148529, 0.005705878, -0.007860773, 0.01841934, 0.006455159, 0.014012054, -0.0047785724, 0.0061209486, 0.002515904, 0.019374507, 0.02663943, -0.0018284111, -0.021292496, 0.004240378, 0.0030565273, -0.0017679223, -0.015800655, -0.0047853566, -0.025111672, -0.0107299145, -0.0037058706, -0.006272675, 0.009529202, -0.020888973, -0.0082808575, 0.007032811, 0.0036801714, -0.0063384734, -0.0013849958, 0.018630393, 0.0027898895, 0.010016508, -0.011650309, 0.018576713, -0.011545682, 0.014604304, -0.0122023225, 0.02295853, 0.005445009, -0.0017149593, 0.01388251, 0.022956448, -0.008148215, -0.004299947, 0.004019795, 0.010215997, -0.016756013, 0.010654469, -0.0027567286, 0.0066523296, -0.018746328, 0.023740638, -0.005402715, 0.005856961, 0.0071967943, -0.020001227, 0.015546351, -0.013415028, 0.009419881, 0.022947017, -0.0125141805, 0.005218554, 0.0053685587, 0.0025394678, -0.011858857, -0.0033825221, 0.005581437, -0.024451757, -0.033842977, 0.00027532977, -0.0075015635, 0.009447031, 0.017591681, 0.0050986423, 0.024364084, -0.0041898102, -0.0110901175, 0.0005953625, -0.011464894, 0.04490897, -0.0030368355, -0.007820998, -0.010463408, -0.012516761, 0.017535402, 0.018991005, -0.0018233968, -0.0149058495, 0.0062395865, -0.00836628, -0.012458459, 0.004214479, 0.0010699051, -0.0074837063, 0.008707378, 0.007935708, 0.008305551, 0.00021101453, 0.007092434, 0.023534099, -0.01076642, 0.002591574, 0.0062940875, -0.027733775, -0.0024492433, 0.001873393, 0.0150896385, 0.0016613943, 0.014624474, 0.0151847, -0.013922004, -0.01789192, 0.022993982, 0.0030688287, 0.0064344266, 0.0076673334, 0.0213619, -0.01579176, -0.005572242, 0.029948303, -0.020951206, -0.006225922, -0.0019950203, 0.0051082247, 0.0011556699, -0.003214899, 0.011935263, -0.012897614, -0.0055875485, -0.034265738, 0.008057234, 0.00016609929, -0.024717096, -0.0028587154, -0.016264683, -0.019298827, -0.004589967, 0.01302965, -0.027069394, 0.008348559, -0.008604941, -0.0004778504, -0.02031454, 0.013239828, -0.019092796, -0.020710789, 0.0021455614, -0.00919578, -0.0033636105, 0.009736497, -0.024944903, -0.021116162, -0.0059340857, -0.023578035, -0.014020578, 0.014593259, -0.009316141, 0.00072474947, -0.019983843, -0.0155985085, 0.012169558, 0.007980929, -0.010998571, -0.01997166, -0.00036713303, 0.008407812, -0.016662631, 0.0012379487, -0.0037758686, 0.02256453, 0.00991368, 0.016006775, -0.035216507, -0.0070092776, 0.0019537134, -0.0069353026, -0.015219878, -0.0014571566, 0.0067342217, -0.0020269908, -0.0058388147, 0.019220604, -0.019804116, 0.016315704, -0.028380485, 0.009157574, -0.0165993, 0.0071201767, 0.0038544403, -0.01463005, 0.0062247375, 0.0017576151, -0.013379874, 0.000761391, -0.00263255, 0.008625972, 0.0056602852, -0.014605741, -0.017142737, -0.021537602, 0.017293194, 0.005236337, 0.0018593754, -0.009303896, 0.028144706, -0.008615878, -0.03352375, -0.012454628, -0.038774498, -0.00304386, -0.0030250237, 0.0036866849, 0.00090104796, -0.024567144, -0.013173643, 0.0022132602, 0.0017967058, 0.004096327, 0.027848838, 0.004095939, 0.0013533355, 0.005699952, -0.007020716, -0.007336228, 0.0070801973, -0.010377589, -0.019657679, -0.0033234716, -0.0026354913, 0.009028564, 0.0048623695, -0.0013497155, -0.009356008, -0.004671319, -0.00025713982, -0.004479344, -0.027570086, -0.004186933, 0.006521375, -0.0026638717, 0.0005790405, 0.0154523, 0.019843815, 0.010056904, 0.0047598295, -0.0031413424, 0.007165598, 0.016795147, 0.0013295524, -0.010873166, -0.02386367, 0.0076849624, -0.008173651, 0.019172203, 0.0049415324, 0.016195249, -0.010773785, -0.005117348, 0.0047146343, 0.0023202847, -0.015055246, -0.005041409, -0.0048291646, 0.01965153, -0.0022151684, 0.005948889, -0.0069963266, -0.02403523, 0.0036352742, -0.014244847, -0.004589592, -0.029403234, -0.0052146055, 0.012861531, -0.0042263027, 0.0066579925, 0.018169502, 0.008870159, 0.0005308217, 0.02170863, 0.009358723, -0.0002705779, -0.019206123, 0.0071156565, -0.007381565, 0.00044251847, -0.009483921, 0.009617175, 0.0055459337, 0.008250152, -0.0015396571, -0.025497332, 0.0058504776, 0.0012521179, -0.0017629644, 0.005794376, -0.0050406903, -0.0033104608, 0.0035930406, 0.0027308024, -0.007308411, 0.0017771284, 0.018814553, -0.00747751, -0.0045522787, 0.0054937205, 0.009279228, -0.01000567, -0.008141607, -0.0062200213, -0.012775584, -0.013470145, 0.017029472, 0.06315161, 0.011964702, 0.04240911, 0.0036939122, 0.0073626423, 0.004384181, -0.0039996617, 0.00929436, -0.00736844, -0.0062520923, -0.024166249, 0.0036701267, 0.0017601721, -0.016356977, 0.011925187, -0.010121809, 0.014555829, 0.0020560015, -0.00019170309, -0.001938993, -0.021470642, 0.004781903, -0.012901881, 0.027774144, 0.0074919416, 0.009714891, 0.018363208, 0.0106714405, -0.013137507, 0.0071303723, -0.02691239, 0.019372188, 0.0017551234, -0.011677429, -0.008221253, 0.010432512, -0.011327439, 0.039814778, -0.0059242817, -0.03116088, -0.00438102, 0.010532104, 0.014452731, 0.0030413317, -0.028997896, -0.020299172, -0.009429802, -0.023679143, -0.014516342, -0.025368083, 0.0070253126, -0.008850781, 0.00047586777, -0.012251334, 0.0013213196, 0.021885363, 0.016885875, 0.013999868, -0.0042283065, -0.016181227, -0.010780715, -0.0083117755, -0.006387278, -0.011585286, -0.008215416, 0.019241726, -0.006135888, -0.0027216875, -0.005067036, 0.0018512675, 0.0016796958, 0.019943535, -0.01244863, -0.00037101677, 0.022915555, 0.014760566, -0.0033630081, 0.0061639976, -0.0019343577, -0.013258819, 0.008545749, -0.0062814155, -0.024838485, -0.025948517, 0.0059766467, 0.009519405, 0.010002025, -0.04908707, 0.0025750282, -0.020202998, -0.0052651917, 0.013090938, -0.0041194893, 0.014857065, 0.0074180183, -0.0069943215, -0.013200164, -0.031898685, 0.006513524, 0.021760158, -0.015144624, -0.017843012, 0.0062631583, -0.010939322, -0.006526563, -0.011898412, 0.0065826927, 0.0057813674, -0.0007842406, 0.0048779384, -0.013524789, 0.0070978147, 0.0017809353, 0.005514557, -0.013477133, 0.0049402486, 0.0044039576, 0.02227664, 0.0007812173, 0.003207358, 0.011879466, 0.020025989, 0.0072028735, -0.0028537572, 0.023091292, -0.00018577113, 0.021094104, -0.012876649, 0.003960237, 5.5953526e-05, -0.012306509, 0.01867784, -0.0031588883, -0.008824956, 0.019565934, 0.029453756, 0.020647742, -0.004064417, -0.01701494, 0.0011689767, -0.010706623, 0.02322694, -0.014776828, 0.009090278, -0.0030195033, -0.007905437, -0.0030009367, 0.005497723, -0.02692518, -0.0058496315, 0.007544209, 0.0149242515, -0.021589575, 0.0057914876, -0.012311323, 0.0040466157, -0.012055275, -0.00031449954, 0.029962512, 0.001404089, -0.003356891, -0.016537232, 0.011805075, -0.0010569413, 0.013352798, -0.03534795, 0.031058999, -0.004106929, -0.004450002, 0.014397525, -0.022944449, -0.0092651835, 0.008774648, 0.010389638, -0.0009675511, 0.0001913361, 0.019472158, 0.025055915, 0.006259518, 0.0045122635, 0.0065401155, -0.006799061, -0.004194924, 0.017821154, -0.023191348, -0.0073183286, 0.0068496573, -0.009589395, -0.017388178, -0.009693818, 0.007938312, 0.0004058018, 0.0006828408, 0.008103531, -0.01729262, -0.0032290434, -0.0012671348, -0.004225013, 0.018532198, 0.0005971496, 0.0013733185, 0.0074149305, -0.0044971216, -0.0070041753, 0.009347575, 0.002450542, -0.01378061, 0.017843094, 0.013376213, -0.004652913, -0.021155236, 0.024640895, -0.0005156185, 0.015063932, -0.009547675, 0.009677565, -0.01614848, 0.014487601, 0.03592236, 0.014139393, -0.007719875, 0.010172782, -0.02765874, -0.009841701, -0.0046612467, -0.0053689457, 0.0014917518, 0.009813718, 0.003765122, -0.001345538, -0.0048210365, -0.01293066, -0.0062473062, -0.035130132, -0.005942775, -0.009865553, -0.0042703347, -0.0043745595, -0.021095293, 0.011259164, 0.003206082, 0.006505125, 9.665088e-05, -0.020994008, -0.013898216, -0.0038382977, 0.0062374556, 0.014109027, -0.013857453, -0.0038677086, -0.009943113, 0.0044348473, -0.0027669847, 0.017638505, 0.013060012, 0.007545376, -0.0057339077, 0.014444644, -0.011805444, -0.016088963, -0.004906445, -0.00385565, 0.016333181, 0.022393249, 0.0032682738, -0.0013747363, 0.008801483, 0.0040816464, -0.009915361, 0.02261866, -0.020984603, 0.000843085, -0.0075411387, -0.023311831, 0.009576056, -0.013151265, -0.015157684, 0.008339063, -0.00056839164, 0.005000328, 0.024831725, 0.0012736046, -0.01648829, -0.0029206225, -0.008432741, 0.012281481, 0.010691067, -0.0053804456, 0.00062976434, -0.009791501, -0.018633964, 0.006307004, -0.008127796, 0.0011191049, -0.0061602993, 0.0133316275, -0.023068888, -0.0070187002, 0.0047837854, 0.007903899, -0.0039912947, -0.005389599, -0.03376631, -0.009870264, -0.009850333, 0.0070481393, 0.0094647175, 0.0004524878, -0.011655433, 0.017559363, -0.018037658, -0.0065733166, 0.014934517, -0.0060929405, -0.010315542, 0.00048631386, -0.004101899, -0.00076497416, -0.028817669, 0.0331848, 0.0015793793, -0.0069332183, 0.0031364262, 0.009587778, 0.005859858, -0.0145632485, 0.0034529394, 0.029724218, -0.0088729635, -0.022999708, -0.011810983, 0.020978322, 0.007544859, 0.0117583675, 0.020521715, -0.01599642, -0.00561861, 0.015974868, -0.011862057, 0.0050855572, -0.008483202, 0.0051965998, -0.0056863194, -0.013494464, -0.0022134087, -0.026982674, -0.010199169, -0.018038323, 0.008548548, 0.006152186, 0.0040531815, -0.0014547257, -0.023334637, -0.02694853, -0.009930631, 0.011260988, -8.1071785e-06, -0.006370758, -0.0010912317, -0.0033035662, -0.01988986, 0.007328966, -0.00317793, -0.0071578887, -0.0042273155, -0.0066239988, -0.00053277274, 0.0037190255, -0.017153814, -0.009248271, -0.019324731, 0.009926315, 0.0030623397, 0.0024249277, -0.0063323183, -0.012039313, 0.018211585, 0.007150624, 0.013582396, 0.0009909946, -0.0014311604, -0.009218341, 0.014610251, -0.007564405, 0.021753332, 0.024238236, -0.005553549, -0.012620293, 0.008305046, 0.012134516, 0.017846588, -0.013409684, -0.006246638, -0.010883603, -0.013153011, -0.006151834, -0.005305446, -0.0027892354, -0.012340328, -0.010590077, 0.0041547157, -0.019123247, -0.023432212, 0.0063890866, -0.009152316, 0.024056295, 0.010228768, -0.0058839037, -0.0070992922, 0.019914962, -0.0030798255, -0.00762393, 0.008152478, 0.006925834, -0.006727704, -0.0014324305, -0.0008716137, 0.002034783, -0.0087075755, 0.01448116, -0.006128207, 8.765794e-06, -0.031035526, 0.010229985, 0.008626498, -0.006758602, 0.01519312, -0.015810443, -0.010631647, 0.008344258, -0.0025102461, -0.013552928, 0.0054288716, 0.0079899095, -0.00789745, 0.020828795, -0.0058959164, 0.031351067, 0.0035348597, 0.0060289195, -0.0021893815, -0.013606377, 0.01843867, -0.0076405006, -0.017679539, 0.005228933, 0.044355866, 0.019827928, -0.030548709, 0.004330885, -0.0019131684, 0.023397641, 0.010483277, -0.00019688862, 0.008506111, -0.031456087, 0.022565221, -0.005377252, 0.010186255, -0.009678783, 0.013348643, 0.016780427, -0.0016575643, -0.0077618915, 0.0153043335, -0.00557345, 0.0065885796, -0.009122197, -0.014065003, 0.0047721076, -0.0004452089, 0.025780054, -0.018250473, -0.00083021366, -0.008054432, -0.001564943, -0.0032601405, -0.019192701, 0.012969507, 0.009853346, -0.15855633, 0.0048122127, -0.020178147, 0.002339783, -0.00041914746, 0.0073779435, -0.014930327, 0.003394612, -0.00019141435, -0.011849127, -0.030079935, 0.008188059, 0.012704854, 0.008973435, 0.0015236551, 2.3701445e-05, 0.018477283, -0.003971997, -0.02488101, -0.0044515687, -0.0015112875, 0.012159061, -0.014338779, -0.006309562, -0.03818645, -0.0050339946, -0.006289652, 0.012938484, 0.0016499339, -0.021097256, 0.024744026, 0.0055458443, -0.0046846275, 0.008586573, 0.011724421, -0.0085712625, -0.016919449, 0.013733267, -0.019947426, -0.010931504, 0.0018275429, 0.015710482, 0.003520593, -0.0014750729, -0.0024456764, 0.006119738, 0.01747814, 0.0069811963, -0.0031194473, 0.030290466, -0.021243075, -0.009945384, 0.020692276, 0.025972482, 0.03202165, 0.0061035757, -0.0010245547, 0.0077934405, 0.011730449, -0.030446794, 0.01691323, -0.015947701, -0.0013052814, 0.014444823, 0.0048451107, 0.0041271267, -0.0010603504, -0.0004024338, 0.035153523, -0.001626644, 0.0038284638, 0.021080377, 0.020707408, 0.012791507, 0.009860661, -0.019293316, -0.00228912, 0.00754136, -0.01711892, 0.010501921, 0.0010815249, 0.011407751, 0.0015704191, -0.009161001, 0.00885664, -0.02574757, 0.015096807, 0.026868906, 0.0018685623, -0.0029258882, 0.016934998, -0.034759644, 0.009966803, -0.009092337, 0.0058720275, -0.0011194579, -0.020414134, 0.021035524, -0.03850698, -0.019933524, 0.008549924, -0.007922746, 0.00944959, 0.01154351, 0.0065790988, -0.0068554524, 0.013641256, 0.0072596357, -0.010274018, -0.029015297, -0.0029442087, -0.013222107, -0.01845056, -0.019384824, -0.0060217115, -0.016165685, -0.006678008, -0.014510522, -0.010633636, -0.0006559999, 0.0070603476, 0.034669034, 0.0039774007, 0.00044260503, -0.036117304, -0.0055357045, 0.02691521, 0.01520004, 0.009375087, -0.0058721686, 0.009836204, 0.023489818, -0.0011206509, -0.0063950596, 0.0033054906, -0.0076437863, -0.0035868965, 0.010817734, 0.009745316, -0.0045062173, -0.0123880925, -0.032911282, -0.0036921909, -0.025674766, -0.00623548, -0.020240242, -0.011899196, -0.0025025967, -0.0067715165, -0.0025570511, -0.0029865194, 0.007914318, 0.0018834923, -0.0061035515, -0.02557286, -0.027691541, 0.014745707, -0.0047473237, 0.01760487, 0.028859006, -0.013183319, -0.029335015, -0.01646646, -0.020195682, 0.0098078, -0.009875392, 0.03627119, -0.01387039, 0.0035116535, -0.020819956, -0.008721119, 0.011970209, -0.002400701, 0.009224402, 0.009126321, 0.011775536, 0.00028450525, -0.01316144, 0.010681076, 0.0062664216, -0.0047106943, -0.0027931395, 0.023061864, -0.01052485, 0.010038137, -0.0030715608, 0.009562251, -0.009525513, 0.014987005, 0.017210547, 0.0046172533, 0.0016171688, 0.033848494, 0.0034101098, 0.0033887587, 0.022780955, 0.01552475, -0.005124905, -0.02461298, 0.027410239, -0.03621577, -0.0006897381, -0.0043035583, 0.005347395, 0.0068838396, 0.0004946018, 0.01655465, -0.020088287, 0.00057344, 0.024399664, -0.00054522377, -0.019360553, 0.010574997, 0.023323363, -0.004995068, 0.0062515517, -0.002363608, -0.0031126307, 0.014870791, 0.023591205, 0.016385378, -0.0051356927, -0.016481213, 0.00053131196, 0.0070351316, -0.008622213, -0.0014945067, 0.017283875, 0.0020267717, 4.3495922e-05, 9.003123e-05, 0.010262058, 0.0024837554, 0.004569486, -0.009979149, 0.009436234, 0.03175047, -0.020356918, -0.0035017733, -0.008456299, -0.005046942, 0.0072204494, -0.015404751, 0.0100127915, -0.010191947, 0.0050874776, -0.015046422, -0.0057045077, 0.00699822, 0.011864111, 0.022728039, -0.043599077, -0.014328826, -0.0099284565, -0.01743313, 0.0036781954, -0.008111703, -0.006780144, 0.012487302, 0.015371979, 0.0067260247, 0.014886487, -0.0097341975, -0.0044049136, 0.012954487, 0.011073094, -0.00945529, 0.0071862116, -0.0043735607, 0.03854261, -0.014663457, -0.00026709083, 0.013744928, -0.0052517923, 0.025407927, 0.024416769, 0.022813119, 0.0064070467, -0.0003993299, -0.009101926, 0.0046396423, -0.010656973, -0.00042798568, 0.001291721, -0.01375776, -0.004147013, -0.0002215026, 0.010410864, 0.027149037, 0.0028735118, -0.0077828066, -0.01888917, -0.017377071, -0.0059307683, 0.024318224, 0.004336716, -0.01368995, -0.016017085, 0.028428389, 0.0075898087, 0.004872301, 0.01691355, 0.0048712045, 0.012548124, 0.009306482, -0.0055774953, 0.022494426, 0.014827764, -0.021376241, 0.0038917896, 0.0054654647, -0.0073703993, -0.0037439999, -0.016931484, 0.001081462, -0.017850129, 0.012190718, -0.019374909, -0.0049213055, -0.0019132858, 0.0204057, 0.01972062, 0.0044691158, 0.009872917, 0.005144578, 0.0050366223, 0.010301735, -0.014526841, 0.0067845173, 0.0116581125, 0.0016218736, -0.016294058, -0.001295891, -0.024000822, 0.008330399, 0.003262464, -0.0005232694, 0.020652806, -0.010357093, 0.024398282, 0.026891502, -0.013354825, -0.0020715792, -0.008502596, 0.030004848, 0.004250116, -7.708838e-05, 0.00504428, -0.0008684148, -0.0072436444, -0.0031633135, 0.06833509, -0.011117374, -0.039284196, 1.4319485e-05, 0.01397761, 0.004352702, 0.01568135, 0.00044888933, -0.012393724, 0.0036441816, 0.004326052, -0.0019935837, -0.030612784, 0.008698738, 0.009215379, 0.0011369758, 0.00919716, -0.010636651, 0.018771086, -0.0013988758, 0.010977407, 0.02848083, 0.00499683, -0.01274809, 0.007953812, -0.0021474124, -0.025495132, -0.016488811, -0.014251983, 0.018699907, 0.009201477, -0.049356483, -0.0053497367, -0.003182046, -0.016643967, -0.02885332, -0.008060686, -0.014924745, 0.016366819, -0.021652194, -0.014100401, 0.0009177963, -0.0038665296, -0.00996536, 0.035083216, -0.008516663, -0.035474405, 0.0037737698, 0.014799828, 0.0021824606, -0.0047366116, 0.004754479, -0.0042069964, -0.005469389, -0.0017362254, -0.003222691, -0.006032862, 0.008100852, 0.006356846, 0.004384462, 0.009482159, -0.006224056, 0.0131638115, 3.3521002e-07, 0.016877651, -0.018630976, -0.027405117, 0.013609076, -0.012237185, 0.016088203, 0.014738876, -0.008650214, -0.014130271, 0.024641493, 0.012029723, -0.018355314, -0.011733578, -0.00017256396, -0.025116837, -0.031722017, -0.0013769576, 0.0077766576, -0.0014427411, 0.0125168245, 0.01175807, 0.003534368, -0.026599772, 0.011449816, -0.006416519, -0.013898725, 0.01657462, -0.006745988, -0.018349124, 0.005051356, 0.0005042816, 0.0077704587, -0.019539837, -0.00903046, -0.017344043, -0.005901756, -0.0067791166, -0.0036382892, 0.0088627245, -0.0038265695, 0.033269048, 0.011071261, -0.00535417, 0.003952265, 0.015011873, 0.010390176, 0.0027859607, -0.016385663, -0.032846745, -0.013138953, -0.029470287, -0.015736151, -0.009961381, 0.004255019, 0.024693243, -0.011082315, -0.0033498707, 0.012044336, 0.0199565, 0.0042449133, -0.012608134, 0.007446035, 0.010884388, 0.023958063, -0.0049475995, -0.005068732, -0.016531331, 0.005837668, 0.0006445404, -0.013910495, -0.005409302, -0.0053707417, 0.01111944, 0.001144906, 0.011096047, -0.007288683, -0.0035759765, 0.020187235, -0.029080343, 0.00838895, -0.011652083, 0.01782721, -0.021418007, 0.0015497045, 0.021626053, -0.008853656, 0.004868814, 0.0008881345, -0.01626819, -0.0023078318, 0.008616524, 0.0044801836, 0.01543831, -0.014085523, -0.0006257144, 0.009013144, -0.00047934905, -0.0012697403, 0.013048828, -0.007408442, -0.009541387, -0.010379551, -0.009787507, 0.0038687056, -0.00277584, 0.0046621375, 0.022071809, 0.010027054, -0.008365052, 0.005215544, -0.005506676, 0.004573229, 0.0020236017, -0.023436135, -0.006248018, 0.017368333, -0.006364344, -0.001633428, -0.002859971, 0.02283931, 0.009040132, -0.0061260625, 0.008467379, -0.018101672, -0.050091848, -0.014906002, 0.020242509, -0.005414793, 0.012705495, -0.010913011, -0.011142954, 0.0050571295, -0.00870069, -0.007317144, 0.028053401, 0.017690226, -0.0058352654, -0.018516291, 0.011980983, -0.028908009, 0.012210104, 0.010510705, 0.0026430453, 0.010252061, -0.012720602, 0.0016118474, 0.013916263, 0.03124962, 0.018664898, 0.019761177, -0.0014378647, -0.008293644, -0.010544964, 0.0010015598, -0.02608455, 0.0028843787, 0.0066248304, -0.044717424, -0.0071082544, 0.013838155, 0.007344509, -0.000121955694, 0.0056872987, 0.016784227, 0.0076354365, 0.007377142, -0.007945435, -0.006295754, -0.0046604555, 0.008930235, -0.002785858, -0.018954562, 6.455441e-05, -0.005566378, 0.016702734, -0.008559434, -0.0046242946, 0.02561497, -0.0099039525, 7.64997e-05, -0.0027835688, 0.010738034, -0.0033396473, 0.0017078898, 0.00202138, -0.004603765, -0.0023213099, 0.011631595, -0.005073609, 0.022739727, 0.023305375, 0.0066140774, -0.008717748, 0.01551031, -0.016347209, 0.008410572, 0.00057006505, 0.021660546, 0.014376302, 0.019248389, 0.00666874, -0.0056483927, -0.0012649619, 0.0015253531, -0.0034810356, 0.045579176, -0.0030161836, 0.018216018, -0.014307648, 0.01953752, 0.004713986, 0.014506862, -0.0072764484, 0.022891834, 0.0059824404, -0.018381145, -0.005288025, 0.005195452, -0.0065981713, 0.021974873, 0.0057550245, 0.01087501, -0.015988788, 0.012453876, -0.018370742, 0.0105378, -0.007446831, -0.011886076, 0.027690565, 0.012497529, -0.013889445, -0.01928992, 0.03073709, 0.0020204957, 0.023631418, 0.016770849, -0.0010385985, -0.010939895, 0.0061227796, 0.013203651, 0.016876964, -0.009946525, -0.0047479626, 0.014743406, 0.0023649142, 0.01952095, 0.0016057226, -0.0038616573, -0.010671829, 0.016598403, -0.00796215, 0.010375811, -0.0143065415, -0.018592015, 0.007674625, 0.010951444, -0.021302136, 5.1422838e-05, -0.0005376675, -0.020871975, -0.0010400589, -0.006849585, -0.010732816, 0.025858153, 0.0081936475, -0.004813414, 0.01695226, -0.011484583, 0.0072017713, 0.024323212, 0.020277254, 0.0063704373, -0.005351558, -0.009837049, -0.0016774482, -0.00014829182, 0.020988896, 0.018917989, -0.014863429, -0.0026266123, -0.023225116, 0.0025533081, 0.019426066, -0.011216483, 0.0026806984, -0.0002730621, 0.0024764105, 0.0028391276, -0.000991599, 0.016155148, -0.0066296547, -0.010600195, -0.024161901, -0.023223957, -0.023506844, -0.00540451, 0.009613135, 0.012106808, 0.023426203, 0.003875805, 0.0032681243, 0.0002705798, 0.01892434, 0.0078121005, 0.02484251, 0.013113731, 0.012995572, 0.010394455, -0.037679438, 0.014358453, -0.008591578, 0.014743491, -0.0069865244, -0.01117767, -0.018075684, -0.018657532, -0.006010273, -0.006343019, 0.018199963, 0.015296892, -0.012687921, -0.0024454417, 0.01481226, -0.008294976, 0.0031373804, 0.0005439455, 0.0014335819, 0.006273442, 0.0022105766, 0.012416897, 0.020263003, 0.00833994, -0.0047434047, -0.0038377147, 0.005558448, 0.0017951397, -0.01227235, -0.015521118, -0.012080401, -0.00021754645, -0.008830341, 0.00019245365, 0.00426259, -0.015195634, 0.027791163, 0.0365805, 0.0009892895, -0.002037709, 0.017602194, 0.013103973, -0.01238052, 0.011481066, 0.0153145455, 0.0098711075, 0.013494469, 0.00029278605, -0.013316406, -0.0013218486, -0.01574158, 0.00012954728, -0.016433181, 0.009792442, -0.0017350309, -0.005354682, 0.00012925747, 0.0043740617, 0.011686516, -0.00937955, 0.016339624, 0.02572011, 0.004618742, 0.008938588, -0.021937612, 0.0032022465, -0.021679705, 0.0066283247, 0.013725543, 0.010584684, -0.0053208508, 0.0029061765, -0.0104834065, -0.05818063, -0.0067362804, -0.0041065314, 0.011415664, -0.0030197871, -0.020203032, -0.032164223, -0.025210831, 0.005411664, 0.008839013, 0.013658905, 0.002368154, -0.0071653556, 0.005759868, -0.0054643853, -0.005680282, 0.019113166, 0.009616687, -0.009173253, 0.0061830254, -0.0034536307, -0.021667926, -0.035081323, 0.026402634, -0.0075249085, 0.010133036, 0.0017621785, -0.015310349, 0.0127053885, 0.0041684485, 0.0025924705, -0.016313449, -0.0011757831, -0.015453912, 0.0002603733, 0.01833576, 0.013150593, -0.0030086648, 0.0038193716, 0.0011881473, -0.0017341824, -0.0066478946, 0.0101068625, 0.00017145899, 0.012041332, 0.011967795, -0.007792026, -0.041041072, -0.005332637, -0.011419582, 0.002195052, -0.013662904, -0.0036161048, 0.0046850503, -0.00060833973, 0.0017952158, -0.0030873914, -0.0005879184, -0.012854942, -0.00756802, -0.032137174, 0.008549995, -0.009785756, 0.0075924653, 0.0011596956, -0.00017742439, -0.0063848244, 0.02552572, 0.00052528456, 0.008070642, 0.023747379, 0.014103434, -0.002165507, -0.006610687, 0.032032926, 0.009199498, -0.012006445, -0.006694696, 0.0037823108, -0.032452006, 0.0019748583, -0.03607171, -0.0065971576, 0.01728707, -0.0019408319, 0.015770538, -0.015318222, 0.0060468167, -0.00087200804, 0.005969937, -0.0068410323, 0.02063204, -0.008951814, -0.03455774, 0.008341894, -0.017021269, -0.01944624, 0.012145345, 0.004331457, -0.0055277343, -0.0020473737, 0.014042229, -0.01752907, 0.0068792473, -0.0037757552, -0.01206779, 0.0052902056, 0.013689217, -0.009145792, 0.006685871, 0.02420377, -0.028192623, 0.0015196726, -0.0023668695, -0.0017794423, -0.0163822, -0.013253037, 0.025640495, -0.00051287713, -0.021287428, -0.004371447, 0.00058057456, 0.005473965, -0.004025554, 0.016971435, -0.0087202815, 0.0038812438, -0.010954617, -0.005430017, 0.01375553, -0.013890074, 0.012571424, 0.0033567182, -0.0009596068, 0.006378224, 0.00646248, -0.00806684, -0.0062675434, 0.008939783, -0.0042531188, 0.0192993, 0.001171669, -0.005112908, 0.004865806, -0.0057068286, -0.023555635, 0.007706485, 0.00632175, 0.015654428, 0.005759143, 0.011384344, -0.022096494, -0.0028423988, 0.005209793, 0.010692624, 0.18361579, -0.017407302, -0.00066411175, 0.0065386132, -0.009789966, -0.0052260477, 0.011434512, -0.005615133, -0.016554266, 0.006952178, 0.010904331, 0.0026662543, -0.012312494, 0.011626308, 0.0025905403, 0.017720422, 0.009559011, -0.014391365, 0.0006807168, -0.021212157, 0.006606041, -0.034779575, 0.01497223, 0.0671152, 0.046236407, -0.016719533, 0.0064604045, 0.009995092, -0.022118848, 0.0070164213, 0.0026408143, 0.004190094, 0.013949796, 0.02155408, -0.0020922045, -0.014771223, 0.016911298, 0.06688327, 0.002528811, 0.001854747, -0.0043146536, 0.0028271577, -0.001353123, -0.0060343714, 0.02365576, 0.012177991, 0.014067749, 0.009129118, -0.013801654, 0.029211413, 0.00034347744, -0.0019205597, -0.006151782, 0.009796692, 0.019653894, -0.006763564, -0.007635076, -0.0054962486, 0.0037050052, 0.021949397, 0.0045763934, 0.019356262, -0.00068981864, -0.0028071736, -0.025288958, -0.024093937, 0.0048550023, 0.011633045, 0.016025936, -0.0091970125, -0.0011761308, -0.02145573, 0.0057736775, 0.005276907, 0.014782691, 0.01726455, -0.100993596, -0.011261109, 0.009441147, -0.0057479194, -0.0002284893, 0.03439264, 0.024471736, 0.006771385, -0.012097711, -0.00036314325, -0.01237029, -0.0011468099, -0.00392141, -0.023319697, -0.013849001, 0.013594814, 0.0086585395, 0.013827593, -0.0015444185, 0.006618348, 0.0036108727, -0.0060601505, -0.012861122, 0.011595771, -0.00038001477, -0.004651327, -0.005332882, -0.0018749228, -0.003102733, 0.008938517, 0.0027064667, 0.010081434, -0.0023072464, -0.0040548374, 0.021100003, 0.013251912, -0.0064258375, 0.02665077, 0.0061346544, 0.0061542103, 0.008931596, 0.0094336895, -0.014725485, -0.018370284, 0.005496743, -0.004348937, 0.026160832, -0.022206303, 0.022404138, -0.008133059, 0.0084542, -0.050502997, -0.007190721, 0.015263875, -0.0055930703, -0.019724442, 0.002271005, 0.010438355, 0.007534596, -0.012758861, -0.009090529, -0.029923225, 0.0026111798, 0.0029312402, 0.0011577832, 0.0049963547, 0.010179677, -0.003381016, -0.0107925795, -0.002607094, -0.045687445, 0.007715206, 0.009103906, -0.016412744, 0.00041969217, 0.022203568, -0.03415878, 0.0066224774, -0.0025016898, -0.022400735, -0.0054442836, -0.0070135267, 0.013554442, -0.0008694412, 0.0016779532, 0.0026616452, -0.002936267, -0.0030723573, 0.027808102, 0.02731677, 0.012320746, 0.0072085382]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeds = client.embed(model='llama3.1:8b', input=[\"what defines a species?\"])\n",
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d006b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to a phenomenon called Rayleigh scattering. As sunlight reaches Earth's atmosphere, it is made up of different colors, which are essentially different wavelengths of light. Shorter wavelengths (like blue and violet) are scattered in all directions more than other colors like red, yellow, or green, which have longer wavelengths.\n",
      "\n",
      "Even though violet light is scattered even more than blue light, the sky appears blue, not violet, because our eyes are more sensitive to blue light and because the sun emits less violet light compared to blue light. Additionally, some of the violet light gets absorbed by the atmosphere, further tipping the balance in favor of blue.\n",
      "\n",
      "So, the combination of these factors makes the sky appear blue to us on a clear day.\n"
     ]
    }
   ],
   "source": [
    "response = syncclient.chat(model='mistral-small3.1:latest', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "189f4618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out how to answer this question about the amygdala's role. First, I remember that the amygdala is part of the brain, specifically in the almond-shaped area at the base of the skull. It's often called the \"little brain.\" But what exactly does it do?\n",
      "\n",
      "I think it's mainly involved with emotions like fear and anger. Maybe it processes things like sounds or sights that could be dangerous? I've heard terms like conditioned reflexes related to amygdala function. Also, during stress, the amygdala might get more active.\n",
      "\n",
      "Wait, isn't there something about the prefrontal cortex interacting with the amygdala? Oh right, the amygdala helps regulate emotions and behaviors that prepare the body for action in case of danger. So when it detects a threat, it triggers fear responses. But how does it do that exactly?\n",
      "\n",
      "I also recall that the amygdala is linked to memory, maybe storing past experiences with trauma or scary situations. That could explain why people are more fearful after traumatic events.\n",
      "\n",
      "Additionally, during sleep stages like REM, the amygdala becomes active again, which might be related to REM Dreams and emotional processing during sleep.\n",
      "\n",
      "So putting it all together: the amygdala is crucial for detecting threats, regulating fear responses, preparing the body, associating with memories of danger, and even playing a role in emotional experiences during sleep.\n",
      "</think>\n",
      "\n",
      "The amygdala plays a vital role as a part of the brain located at the base of the skull. Primarily known for its involvement in processing emotions such as fear and anger, it acts as a detector for potential threats or dangers. The amygdala's activation can lead to conditioned reflexes and stress responses. It interacts with other brain regions like the prefrontal cortex to regulate fear responses and prepare the body for action. Additionally, it is linked to memory formation, particularly storing experiences of trauma or danger. Furthermore, during REM sleep, the amygdala becomes active again, contributing to emotional processing during sleep stages.\n",
      "\n",
      "Answer: The amygdala functions as a critical region in the brain responsible for detecting potential threats and regulating fear responses. It activates conditioned reflexes and prepares the body for action, often under stress. The amygdala also links with memory formation, particularly for trauma-related experiences, and plays a role in emotional processing during REM sleep.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat(model='deepseek-r1:7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'reformulate the following query into a keyword rich one of more than 150 words. Just return the expanded query without any other sentence: what is the role of the amygdala?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636abff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asXai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
